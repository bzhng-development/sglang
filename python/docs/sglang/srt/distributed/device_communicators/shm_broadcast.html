<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1">
<meta name="generator" content="pdoc3 0.11.6">
<title>sglang.srt.distributed.device_communicators.shm_broadcast API documentation</title>
<meta name="description" content="">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/13.0.0/sanitize.min.css" integrity="sha512-y1dtMcuvtTMJc1yPgEqF0ZjQbhnc/bFhyvIyVNb9Zk5mIGtqVaAB1Ttl28su8AvFMOY0EwRbAe+HCLqj6W7/KA==" crossorigin>
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/13.0.0/typography.min.css" integrity="sha512-Y1DYSb995BAfxobCkKepB1BqJJTPrOp3zPL74AWFugHHmmdcvO+C48WLrUOlhGMc0QG7AE3f7gmvvcrmX2fDoA==" crossorigin>
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/styles/default.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:1.5em;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:2em 0 .50em 0}h3{font-size:1.4em;margin:1.6em 0 .7em 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .2s ease-in-out}a:visited{color:#503}a:hover{color:#b62}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900;font-weight:bold}pre code{font-size:.8em;line-height:1.4em;padding:1em;display:block}code{background:#f3f3f3;font-family:"DejaVu Sans Mono",monospace;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source > summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible;min-width:max-content}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em 1em;margin:1em 0}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul ul{padding-left:1em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/highlight.min.js" integrity="sha512-D9gUyxqja7hBtkWpPWGt9wfbfaMGVt9gnyCvYa+jojwwPHLCzUm5i8rpk7vD7wNee9bA35eYIjobYPaQuKS1MQ==" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => {
hljs.configure({languages: ['bash', 'css', 'diff', 'graphql', 'ini', 'javascript', 'json', 'plaintext', 'python', 'python-repl', 'rust', 'shell', 'sql', 'typescript', 'xml', 'yaml']});
hljs.highlightAll();
/* Collapse source docstrings */
setTimeout(() => {
[...document.querySelectorAll('.hljs.language-python > .hljs-string')]
.filter(el => el.innerHTML.length > 200 && ['"""', "'''"].includes(el.innerHTML.substring(0, 3)))
.forEach(el => {
let d = document.createElement('details');
d.classList.add('hljs-string');
d.innerHTML = '<summary>"""</summary>' + el.innerHTML.substring(3);
el.replaceWith(d);
});
}, 100);
})</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>sglang.srt.distributed.device_communicators.shm_broadcast</code></h1>
</header>
<section id="section-intro">
</section>
<section>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="sglang.srt.distributed.device_communicators.shm_broadcast.Handle"><code class="flex name class">
<span>class <span class="ident">Handle</span></span>
<span>(</span><span>connect_ip: str,<br>local_reader_ranks: List[int] = &lt;factory&gt;,<br>buffer: <a title="sglang.srt.distributed.device_communicators.shm_broadcast.ShmRingBuffer" href="#sglang.srt.distributed.device_communicators.shm_broadcast.ShmRingBuffer">ShmRingBuffer</a> | None = None,<br>local_subscribe_port: int | None = None,<br>remote_subscribe_port: int | None = None)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@dataclass
class Handle:
    connect_ip: str
    local_reader_ranks: List[int] = field(default_factory=list)

    buffer: Optional[ShmRingBuffer] = None
    local_subscribe_port: Optional[int] = None
    remote_subscribe_port: Optional[int] = None</code></pre>
</details>
<div class="desc"><p>Handle(connect_ip: str, local_reader_ranks: List[int] = <factory>, buffer: Optional[sglang.srt.distributed.device_communicators.shm_broadcast.ShmRingBuffer] = None, local_subscribe_port: Optional[int] = None, remote_subscribe_port: Optional[int] = None)</p></div>
<h3>Instance variables</h3>
<dl>
<dt id="sglang.srt.distributed.device_communicators.shm_broadcast.Handle.buffer"><code class="name">var <span class="ident">buffer</span> : <a title="sglang.srt.distributed.device_communicators.shm_broadcast.ShmRingBuffer" href="#sglang.srt.distributed.device_communicators.shm_broadcast.ShmRingBuffer">ShmRingBuffer</a> | None</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="sglang.srt.distributed.device_communicators.shm_broadcast.Handle.connect_ip"><code class="name">var <span class="ident">connect_ip</span> : str</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="sglang.srt.distributed.device_communicators.shm_broadcast.Handle.local_reader_ranks"><code class="name">var <span class="ident">local_reader_ranks</span> : List[int]</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="sglang.srt.distributed.device_communicators.shm_broadcast.Handle.local_subscribe_port"><code class="name">var <span class="ident">local_subscribe_port</span> : int | None</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="sglang.srt.distributed.device_communicators.shm_broadcast.Handle.remote_subscribe_port"><code class="name">var <span class="ident">remote_subscribe_port</span> : int | None</code></dt>
<dd>
<div class="desc"></div>
</dd>
</dl>
</dd>
<dt id="sglang.srt.distributed.device_communicators.shm_broadcast.MessageQueue"><code class="flex name class">
<span>class <span class="ident">MessageQueue</span></span>
<span>(</span><span>n_reader,<br>n_local_reader,<br>local_reader_ranks: List[int] | None = None,<br>max_chunk_bytes: int = 10485760,<br>max_chunks: int = 10,<br>connect_ip: str | None = None)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class MessageQueue:

    def __init__(
        self,
        n_reader,  # number of all readers
        n_local_reader,  # number of local readers through shared memory
        local_reader_ranks: Optional[List[int]] = None,
        max_chunk_bytes: int = 1024 * 1024 * 10,
        max_chunks: int = 10,
        connect_ip: Optional[str] = None,
    ):
        if local_reader_ranks is None:
            local_reader_ranks = list(range(n_local_reader))
        else:
            assert len(local_reader_ranks) == n_local_reader
        self.n_local_reader = n_local_reader
        n_remote_reader = n_reader - n_local_reader
        self.n_remote_reader = n_remote_reader

        if connect_ip is None:
            connect_ip = get_ip() if n_remote_reader &gt; 0 else &#34;127.0.0.1&#34;

        context = Context()

        if n_local_reader &gt; 0:
            # for local readers, we will:
            # 1. create a shared memory ring buffer to communicate small data
            # 2. create a publish-subscribe socket to communicate large data
            self.buffer = ShmRingBuffer(n_local_reader, max_chunk_bytes, max_chunks)

            # XPUB is very similar to PUB,
            # except that it can receive subscription messages
            # to confirm the number of subscribers
            self.local_socket = context.socket(XPUB)
            # set the verbose option so that we can receive every subscription
            # message. otherwise, we will only receive the first subscription
            # see http://api.zeromq.org/3-3:zmq-setsockopt for more details
            self.local_socket.setsockopt(XPUB_VERBOSE, True)
            local_subscribe_port = get_open_port()
            socket_addr = f&#34;tcp://127.0.0.1:{local_subscribe_port}&#34;
            logger.debug(&#34;Binding to %s&#34;, socket_addr)
            self.local_socket.bind(socket_addr)

            self.current_idx = 0

        else:
            self.buffer = None  # type: ignore
            local_subscribe_port = None
            self.local_socket = None
            self.current_idx = -1

        if n_remote_reader &gt; 0:
            # for remote readers, we will:
            # create a publish-subscribe socket to communicate large data
            self.remote_socket = context.socket(XPUB)
            self.remote_socket.setsockopt(XPUB_VERBOSE, True)
            remote_subscribe_port = get_open_port()
            if is_valid_ipv6_address(connect_ip):
                self.remote_socket.setsockopt(IPV6, 1)
            self.remote_socket.bind(
                format_tcp_address(connect_ip, remote_subscribe_port)
            )

        else:
            remote_subscribe_port = None
            self.remote_socket = None

        self._is_writer = True
        self._is_local_reader = False
        self.local_reader_rank = -1
        # rank does not matter for remote readers
        self._is_remote_reader = False

        self.handle = Handle(
            connect_ip=connect_ip,
            local_reader_ranks=local_reader_ranks,
            buffer=self.buffer,
            local_subscribe_port=local_subscribe_port,
            remote_subscribe_port=remote_subscribe_port,
        )

        logger.debug(&#34;Message queue communication handle: %s&#34;, self.handle)

    def export_handle(self) -&gt; Handle:
        return self.handle

    @staticmethod
    def create_from_handle(handle: Handle, rank) -&gt; &#34;MessageQueue&#34;:
        self = MessageQueue.__new__(MessageQueue)
        self.handle = handle
        self._is_writer = False

        context = Context()

        if rank in handle.local_reader_ranks:
            assert handle.buffer is not None
            self.buffer = handle.buffer
            self.current_idx = 0
            self.local_reader_rank = handle.local_reader_ranks.index(rank)
            self._is_local_reader = True
            self._is_remote_reader = False

            self.local_socket = context.socket(SUB)
            self.local_socket.setsockopt_string(SUBSCRIBE, &#34;&#34;)
            socket_addr = f&#34;tcp://127.0.0.1:{handle.local_subscribe_port}&#34;
            logger.debug(&#34;Connecting to %s&#34;, socket_addr)
            self.local_socket.connect(socket_addr)

            self.remote_socket = None
        else:
            self.buffer = None  # type: ignore
            self.current_idx = -1
            self.local_reader_rank = -1
            self._is_local_reader = False
            self._is_remote_reader = True

            self.local_socket = None

            self.remote_socket = context.socket(SUB)
            self.remote_socket.setsockopt_string(SUBSCRIBE, &#34;&#34;)
            if is_valid_ipv6_address(handle.connect_ip):
                self.remote_socket.setsockopt(IPV6, 1)
            socket_addr = format_tcp_address(
                handle.connect_ip, handle.remote_subscribe_port
            )
            logger.debug(&#34;Connecting to %s&#34;, socket_addr)
            self.remote_socket.connect(socket_addr)

        return self

    def wait_until_ready(self):
        &#34;&#34;&#34;This is a collective operation. All processes (including the
        readers and the writer) should call this function.
        &#34;&#34;&#34;
        if self._is_writer:
            # wait for all readers to connect

            # local readers
            for i in range(self.n_local_reader):
                # wait for subscription messages from all local readers
                self.local_socket.recv()
            if self.n_local_reader &gt; 0:
                # send a message to all local readers
                # to make sure the publish channel is working
                self.local_socket.send(b&#34;READY&#34;)

            # remote readers
            for i in range(self.n_remote_reader):
                # wait for subscription messages from all remote readers
                self.remote_socket.recv()
            if self.n_remote_reader &gt; 0:
                # send a message to all remote readers
                # to make sure the publish channel is working
                self.remote_socket.send(b&#34;READY&#34;)
        elif self._is_local_reader:
            # wait for the writer to send a message
            recv = self.local_socket.recv()
            assert recv == b&#34;READY&#34;
        elif self._is_remote_reader:
            # wait for the writer to send a message
            recv = self.remote_socket.recv()
            assert recv == b&#34;READY&#34;

    @contextmanager
    def acquire_write(self):
        assert self._is_writer, &#34;Only writers can acquire write&#34;
        start_time = time.monotonic()
        n_warning = 1
        while True:
            with self.buffer.get_metadata(self.current_idx) as metadata_buffer:
                read_count = sum(metadata_buffer[1:])
                written_flag = metadata_buffer[0]
                if written_flag and read_count != self.buffer.n_reader:
                    # this block is written and not read by all readers
                    # for writers, `self.current_idx` is the next block to write
                    # if this block is not ready to write,
                    # we need to wait until it is read by all readers

                    # Release the processor to other threads
                    os.sched_yield()

                    # if we wait for a long time, we should warn the user
                    if (
                        time.monotonic() - start_time
                        &gt; SGLANG_RINGBUFFER_WARNING_INTERVAL * n_warning
                    ):
                        logger.warning(
                            &#34;No available block found in %s second. &#34;,
                            SGLANG_RINGBUFFER_WARNING_INTERVAL,
                        )
                        n_warning += 1

                    continue
                # found a block that is either
                # (1) not written
                # (2) read by all readers

                # mark the block as not written
                metadata_buffer[0] = 0
                # let caller write to the buffer
                with self.buffer.get_data(self.current_idx) as buf:
                    yield buf

                # caller has written to the buffer
                # NOTE: order is important here
                # first set the read flags to 0
                # then set the written flag to 1
                # otherwise, the readers may think they already read the block
                for i in range(1, self.buffer.n_reader + 1):
                    # set read flag to 0, meaning it is not read yet
                    metadata_buffer[i] = 0
                # mark the block as written
                metadata_buffer[0] = 1
                self.current_idx = (self.current_idx + 1) % self.buffer.max_chunks
                break

    @contextmanager
    def acquire_read(self):
        assert self._is_local_reader, &#34;Only readers can acquire read&#34;
        start_time = time.monotonic()
        n_warning = 1
        while True:
            with self.buffer.get_metadata(self.current_idx) as metadata_buffer:
                read_flag = metadata_buffer[self.local_reader_rank + 1]
                written_flag = metadata_buffer[0]
                if not written_flag or read_flag:
                    # this block is either
                    # (1) not written
                    # (2) already read by this reader

                    # for readers, `self.current_idx` is the next block to read
                    # if this block is not ready,
                    # we need to wait until it is written

                    # Release the processor to other threads
                    os.sched_yield()

                    # if we wait for a long time, we should warn the user
                    if (
                        time.monotonic() - start_time
                        &gt; SGLANG_RINGBUFFER_WARNING_INTERVAL * n_warning
                    ):
                        logger.warning(
                            &#34;No available block found in %s second. &#34;,
                            SGLANG_RINGBUFFER_WARNING_INTERVAL,
                        )
                        n_warning += 1

                    continue
                # found a block that is not read by this reader
                # let caller read from the buffer
                with self.buffer.get_data(self.current_idx) as buf:
                    yield buf

                # caller has read from the buffer
                # set the read flag
                metadata_buffer[self.local_reader_rank + 1] = 1
                self.current_idx = (self.current_idx + 1) % self.buffer.max_chunks
                break

    def enqueue(self, obj):
        assert self._is_writer, &#34;Only writers can enqueue&#34;
        serialized_obj = pickle.dumps(obj, protocol=pickle.HIGHEST_PROTOCOL)
        if self.n_local_reader &gt; 0:
            if len(serialized_obj) &gt;= self.buffer.max_chunk_bytes:
                with self.acquire_write() as buf:
                    buf[0] = 1  # overflow
                self.local_socket.send(serialized_obj)
            else:
                with self.acquire_write() as buf:
                    buf[0] = 0  # not overflow
                    buf[1 : len(serialized_obj) + 1] = serialized_obj
        if self.n_remote_reader &gt; 0:
            self.remote_socket.send(serialized_obj)

    def dequeue(self):
        if self._is_local_reader:
            with self.acquire_read() as buf:
                overflow = buf[0] == 1
                if not overflow:
                    # no need to know the size of serialized object
                    # pickle format contains the size information internally
                    # see https://docs.python.org/3/library/pickle.html
                    obj = pickle.loads(buf[1:])
            if overflow:
                recv = self.local_socket.recv()
                obj = pickle.loads(recv)
        elif self._is_remote_reader:
            recv = self.remote_socket.recv()
            obj = pickle.loads(recv)
        else:
            raise RuntimeError(&#34;Only readers can dequeue&#34;)
        return obj

    def broadcast_object(self, obj=None):
        if self._is_writer:
            self.enqueue(obj)
            return obj
        else:
            return self.dequeue()

    @staticmethod
    def create_from_process_group(
        pg: ProcessGroup, max_chunk_bytes, max_chunks, writer_rank=0
    ) -&gt; &#34;MessageQueue&#34;:
        group_rank = dist.get_rank(pg)
        group_world_size = dist.get_world_size(pg)
        global_ranks = dist.get_process_group_ranks(pg)

        from sglang.srt.distributed.parallel_state import in_the_same_node_as

        status = in_the_same_node_as(pg, source_rank=writer_rank)
        same_node_ranks = [i for i, s in enumerate(status) if s]
        n_reader = group_world_size - 1
        n_local_reader = len(same_node_ranks) - 1
        local_reader_ranks = [i for i in same_node_ranks if i != writer_rank]
        buffer_io: MessageQueue
        if group_rank == writer_rank:
            buffer_io = MessageQueue(
                n_reader=n_reader,
                n_local_reader=n_local_reader,
                local_reader_ranks=local_reader_ranks,
                max_chunk_bytes=max_chunk_bytes,
                max_chunks=max_chunks,
            )
            handle = buffer_io.export_handle()
            dist.broadcast_object_list(
                [handle], src=global_ranks[writer_rank], group=pg
            )
        else:
            recv = [None]
            dist.broadcast_object_list(recv, src=global_ranks[writer_rank], group=pg)
            handle = recv[0]  # type: ignore
            buffer_io = MessageQueue.create_from_handle(handle, group_rank)
        buffer_io.wait_until_ready()
        return buffer_io</code></pre>
</details>
<div class="desc"></div>
<h3>Static methods</h3>
<dl>
<dt id="sglang.srt.distributed.device_communicators.shm_broadcast.MessageQueue.create_from_handle"><code class="name flex">
<span>def <span class="ident">create_from_handle</span></span>(<span>handle: <a title="sglang.srt.distributed.device_communicators.shm_broadcast.Handle" href="#sglang.srt.distributed.device_communicators.shm_broadcast.Handle">Handle</a>,<br>rank) ‑> <a title="sglang.srt.distributed.device_communicators.shm_broadcast.MessageQueue" href="#sglang.srt.distributed.device_communicators.shm_broadcast.MessageQueue">MessageQueue</a></span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@staticmethod
def create_from_handle(handle: Handle, rank) -&gt; &#34;MessageQueue&#34;:
    self = MessageQueue.__new__(MessageQueue)
    self.handle = handle
    self._is_writer = False

    context = Context()

    if rank in handle.local_reader_ranks:
        assert handle.buffer is not None
        self.buffer = handle.buffer
        self.current_idx = 0
        self.local_reader_rank = handle.local_reader_ranks.index(rank)
        self._is_local_reader = True
        self._is_remote_reader = False

        self.local_socket = context.socket(SUB)
        self.local_socket.setsockopt_string(SUBSCRIBE, &#34;&#34;)
        socket_addr = f&#34;tcp://127.0.0.1:{handle.local_subscribe_port}&#34;
        logger.debug(&#34;Connecting to %s&#34;, socket_addr)
        self.local_socket.connect(socket_addr)

        self.remote_socket = None
    else:
        self.buffer = None  # type: ignore
        self.current_idx = -1
        self.local_reader_rank = -1
        self._is_local_reader = False
        self._is_remote_reader = True

        self.local_socket = None

        self.remote_socket = context.socket(SUB)
        self.remote_socket.setsockopt_string(SUBSCRIBE, &#34;&#34;)
        if is_valid_ipv6_address(handle.connect_ip):
            self.remote_socket.setsockopt(IPV6, 1)
        socket_addr = format_tcp_address(
            handle.connect_ip, handle.remote_subscribe_port
        )
        logger.debug(&#34;Connecting to %s&#34;, socket_addr)
        self.remote_socket.connect(socket_addr)

    return self</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="sglang.srt.distributed.device_communicators.shm_broadcast.MessageQueue.create_from_process_group"><code class="name flex">
<span>def <span class="ident">create_from_process_group</span></span>(<span>pg: torch.distributed.distributed_c10d.ProcessGroup,<br>max_chunk_bytes,<br>max_chunks,<br>writer_rank=0) ‑> <a title="sglang.srt.distributed.device_communicators.shm_broadcast.MessageQueue" href="#sglang.srt.distributed.device_communicators.shm_broadcast.MessageQueue">MessageQueue</a></span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@staticmethod
def create_from_process_group(
    pg: ProcessGroup, max_chunk_bytes, max_chunks, writer_rank=0
) -&gt; &#34;MessageQueue&#34;:
    group_rank = dist.get_rank(pg)
    group_world_size = dist.get_world_size(pg)
    global_ranks = dist.get_process_group_ranks(pg)

    from sglang.srt.distributed.parallel_state import in_the_same_node_as

    status = in_the_same_node_as(pg, source_rank=writer_rank)
    same_node_ranks = [i for i, s in enumerate(status) if s]
    n_reader = group_world_size - 1
    n_local_reader = len(same_node_ranks) - 1
    local_reader_ranks = [i for i in same_node_ranks if i != writer_rank]
    buffer_io: MessageQueue
    if group_rank == writer_rank:
        buffer_io = MessageQueue(
            n_reader=n_reader,
            n_local_reader=n_local_reader,
            local_reader_ranks=local_reader_ranks,
            max_chunk_bytes=max_chunk_bytes,
            max_chunks=max_chunks,
        )
        handle = buffer_io.export_handle()
        dist.broadcast_object_list(
            [handle], src=global_ranks[writer_rank], group=pg
        )
    else:
        recv = [None]
        dist.broadcast_object_list(recv, src=global_ranks[writer_rank], group=pg)
        handle = recv[0]  # type: ignore
        buffer_io = MessageQueue.create_from_handle(handle, group_rank)
    buffer_io.wait_until_ready()
    return buffer_io</code></pre>
</details>
<div class="desc"></div>
</dd>
</dl>
<h3>Methods</h3>
<dl>
<dt id="sglang.srt.distributed.device_communicators.shm_broadcast.MessageQueue.acquire_read"><code class="name flex">
<span>def <span class="ident">acquire_read</span></span>(<span>self)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@contextmanager
def acquire_read(self):
    assert self._is_local_reader, &#34;Only readers can acquire read&#34;
    start_time = time.monotonic()
    n_warning = 1
    while True:
        with self.buffer.get_metadata(self.current_idx) as metadata_buffer:
            read_flag = metadata_buffer[self.local_reader_rank + 1]
            written_flag = metadata_buffer[0]
            if not written_flag or read_flag:
                # this block is either
                # (1) not written
                # (2) already read by this reader

                # for readers, `self.current_idx` is the next block to read
                # if this block is not ready,
                # we need to wait until it is written

                # Release the processor to other threads
                os.sched_yield()

                # if we wait for a long time, we should warn the user
                if (
                    time.monotonic() - start_time
                    &gt; SGLANG_RINGBUFFER_WARNING_INTERVAL * n_warning
                ):
                    logger.warning(
                        &#34;No available block found in %s second. &#34;,
                        SGLANG_RINGBUFFER_WARNING_INTERVAL,
                    )
                    n_warning += 1

                continue
            # found a block that is not read by this reader
            # let caller read from the buffer
            with self.buffer.get_data(self.current_idx) as buf:
                yield buf

            # caller has read from the buffer
            # set the read flag
            metadata_buffer[self.local_reader_rank + 1] = 1
            self.current_idx = (self.current_idx + 1) % self.buffer.max_chunks
            break</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="sglang.srt.distributed.device_communicators.shm_broadcast.MessageQueue.acquire_write"><code class="name flex">
<span>def <span class="ident">acquire_write</span></span>(<span>self)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@contextmanager
def acquire_write(self):
    assert self._is_writer, &#34;Only writers can acquire write&#34;
    start_time = time.monotonic()
    n_warning = 1
    while True:
        with self.buffer.get_metadata(self.current_idx) as metadata_buffer:
            read_count = sum(metadata_buffer[1:])
            written_flag = metadata_buffer[0]
            if written_flag and read_count != self.buffer.n_reader:
                # this block is written and not read by all readers
                # for writers, `self.current_idx` is the next block to write
                # if this block is not ready to write,
                # we need to wait until it is read by all readers

                # Release the processor to other threads
                os.sched_yield()

                # if we wait for a long time, we should warn the user
                if (
                    time.monotonic() - start_time
                    &gt; SGLANG_RINGBUFFER_WARNING_INTERVAL * n_warning
                ):
                    logger.warning(
                        &#34;No available block found in %s second. &#34;,
                        SGLANG_RINGBUFFER_WARNING_INTERVAL,
                    )
                    n_warning += 1

                continue
            # found a block that is either
            # (1) not written
            # (2) read by all readers

            # mark the block as not written
            metadata_buffer[0] = 0
            # let caller write to the buffer
            with self.buffer.get_data(self.current_idx) as buf:
                yield buf

            # caller has written to the buffer
            # NOTE: order is important here
            # first set the read flags to 0
            # then set the written flag to 1
            # otherwise, the readers may think they already read the block
            for i in range(1, self.buffer.n_reader + 1):
                # set read flag to 0, meaning it is not read yet
                metadata_buffer[i] = 0
            # mark the block as written
            metadata_buffer[0] = 1
            self.current_idx = (self.current_idx + 1) % self.buffer.max_chunks
            break</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="sglang.srt.distributed.device_communicators.shm_broadcast.MessageQueue.broadcast_object"><code class="name flex">
<span>def <span class="ident">broadcast_object</span></span>(<span>self, obj=None)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def broadcast_object(self, obj=None):
    if self._is_writer:
        self.enqueue(obj)
        return obj
    else:
        return self.dequeue()</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="sglang.srt.distributed.device_communicators.shm_broadcast.MessageQueue.dequeue"><code class="name flex">
<span>def <span class="ident">dequeue</span></span>(<span>self)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def dequeue(self):
    if self._is_local_reader:
        with self.acquire_read() as buf:
            overflow = buf[0] == 1
            if not overflow:
                # no need to know the size of serialized object
                # pickle format contains the size information internally
                # see https://docs.python.org/3/library/pickle.html
                obj = pickle.loads(buf[1:])
        if overflow:
            recv = self.local_socket.recv()
            obj = pickle.loads(recv)
    elif self._is_remote_reader:
        recv = self.remote_socket.recv()
        obj = pickle.loads(recv)
    else:
        raise RuntimeError(&#34;Only readers can dequeue&#34;)
    return obj</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="sglang.srt.distributed.device_communicators.shm_broadcast.MessageQueue.enqueue"><code class="name flex">
<span>def <span class="ident">enqueue</span></span>(<span>self, obj)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def enqueue(self, obj):
    assert self._is_writer, &#34;Only writers can enqueue&#34;
    serialized_obj = pickle.dumps(obj, protocol=pickle.HIGHEST_PROTOCOL)
    if self.n_local_reader &gt; 0:
        if len(serialized_obj) &gt;= self.buffer.max_chunk_bytes:
            with self.acquire_write() as buf:
                buf[0] = 1  # overflow
            self.local_socket.send(serialized_obj)
        else:
            with self.acquire_write() as buf:
                buf[0] = 0  # not overflow
                buf[1 : len(serialized_obj) + 1] = serialized_obj
    if self.n_remote_reader &gt; 0:
        self.remote_socket.send(serialized_obj)</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="sglang.srt.distributed.device_communicators.shm_broadcast.MessageQueue.export_handle"><code class="name flex">
<span>def <span class="ident">export_handle</span></span>(<span>self) ‑> <a title="sglang.srt.distributed.device_communicators.shm_broadcast.Handle" href="#sglang.srt.distributed.device_communicators.shm_broadcast.Handle">Handle</a></span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def export_handle(self) -&gt; Handle:
    return self.handle</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="sglang.srt.distributed.device_communicators.shm_broadcast.MessageQueue.wait_until_ready"><code class="name flex">
<span>def <span class="ident">wait_until_ready</span></span>(<span>self)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def wait_until_ready(self):
    &#34;&#34;&#34;This is a collective operation. All processes (including the
    readers and the writer) should call this function.
    &#34;&#34;&#34;
    if self._is_writer:
        # wait for all readers to connect

        # local readers
        for i in range(self.n_local_reader):
            # wait for subscription messages from all local readers
            self.local_socket.recv()
        if self.n_local_reader &gt; 0:
            # send a message to all local readers
            # to make sure the publish channel is working
            self.local_socket.send(b&#34;READY&#34;)

        # remote readers
        for i in range(self.n_remote_reader):
            # wait for subscription messages from all remote readers
            self.remote_socket.recv()
        if self.n_remote_reader &gt; 0:
            # send a message to all remote readers
            # to make sure the publish channel is working
            self.remote_socket.send(b&#34;READY&#34;)
    elif self._is_local_reader:
        # wait for the writer to send a message
        recv = self.local_socket.recv()
        assert recv == b&#34;READY&#34;
    elif self._is_remote_reader:
        # wait for the writer to send a message
        recv = self.remote_socket.recv()
        assert recv == b&#34;READY&#34;</code></pre>
</details>
<div class="desc"><p>This is a collective operation. All processes (including the
readers and the writer) should call this function.</p></div>
</dd>
</dl>
</dd>
<dt id="sglang.srt.distributed.device_communicators.shm_broadcast.ShmRingBuffer"><code class="flex name class">
<span>class <span class="ident">ShmRingBuffer</span></span>
<span>(</span><span>n_reader: int, max_chunk_bytes: int, max_chunks: int, name: str | None = None)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class ShmRingBuffer:

    def __init__(
        self,
        n_reader: int,
        max_chunk_bytes: int,
        max_chunks: int,
        name: Optional[str] = None,
    ):
        &#34;&#34;&#34;
        A shared memory ring buffer implementation for broadcast communication.
        Essentially, it is a queue where only one will `enqueue` and multiple
        will `dequeue`. The max size of each item, together with the max number
        of items that can be stored in the buffer are known in advance.
        In this case, we don&#39;t need to synchronize the access to
         the buffer.

        Buffer memory layout:
                  data                                 metadata
                    |                                      |
                    | (current_idx)                        | (current_idx)
                    v                                      v
        +-------------------------------+----------------------------------------+
        | chunk0 | chunk1 | ... | chunk | metadata0 | metadata1 | ... | metadata |
        +-------------------------------+----------------------------------------+
        | max_chunks x max_chunk_bytes  | max_chunks x (1 + n_reader) bytes      |

        metadata memory layout: each byte is a flag, the first byte is the written
        flag, and the rest are reader flags. The flags are set to 0 by default.
        +--------------+--------------+--------------+-----+--------------+
        | written_flag | reader0_flag | reader1_flag | ... | readerN_flag |
        +--------------+--------------+--------------+-----+--------------+

        The state of metadata is as follows:

        (case 1) 0???...???: the block is not written yet, cannot read, can write
        (case 2) 1000...000: the block is just written, can read, cannot write
        (case 3) 1???...???: the block is written and read by some readers, can read if not read, cannot write
        (case 4) 1111...111: the block is written and read by all readers, cannot read, can write

        State transition for readers:

        When a reader finds a block that it can read (case 2 or 3), it can yield the block for caller to read.
        Only after the caller finishes reading the block, the reader can mark the block as read.
        Readers only mark the block as read (from 0 to 1), the writer marks the block as ready to read (from 1 to 0).

        State transition for writer:

        When the writer writes to a block (case 1 or 4), it first resets the written flag to 0, converting either case
        to case 1. Then it can yield the block for caller to write. After the caller finishes writing the block, the writer
        can reset the reader flags to 0, and mark the block as written (from 0 to 1).
        NOTE: the order is important here, first reset the reader flags (so that we are still in case 1), then mark the block as written. The state transition is atomic. If we do it in the reverse order, it will go through case 3 and then back to case 2, and readers might read the intermediate case 3, which is not correct.

        During creation, `name` is None and the buffer is created. We can pass the
        created object to other processes by pickling it. The other processes will
        get the name of the shared memory and open it, so that they can access the
        same shared memory buffer.
        &#34;&#34;&#34;  # noqa
        self.n_reader = n_reader
        self.metadata_size = 1 + n_reader
        self.max_chunk_bytes = max_chunk_bytes
        self.max_chunks = max_chunks
        self.total_bytes_of_buffer = (
            self.max_chunk_bytes + self.metadata_size
        ) * self.max_chunks
        self.data_offset = 0
        self.metadata_offset = self.max_chunk_bytes * self.max_chunks

        if name is None:
            # we are creating a buffer
            self.is_creator = True
            self.shared_memory = shared_memory.SharedMemory(
                create=True, size=self.total_bytes_of_buffer
            )
            # initialize the metadata section to 0
            with memoryview(
                self.shared_memory.buf[self.metadata_offset :]
            ) as metadata_buffer:
                torch.frombuffer(metadata_buffer, dtype=torch.uint8).fill_(0)
        else:
            # we are opening an existing buffer
            self.is_creator = False
            # fix to https://stackoverflow.com/q/62748654/9191338
            # Python incorrectly tracks shared memory even if it is not
            # created by the process. The following patch is a workaround.
            with patch(
                &#34;multiprocessing.resource_tracker.register&#34;,
                lambda *args, **kwargs: None,
            ):
                try:
                    self.shared_memory = shared_memory.SharedMemory(name=name)
                    assert self.shared_memory.size == self.total_bytes_of_buffer
                except FileNotFoundError:
                    # we might deserialize the object in a different node
                    # in this case, this object is not used,
                    # and we should suppress the error
                    pass

    def __reduce__(self):
        return (
            self.__class__,
            (
                self.n_reader,
                self.max_chunk_bytes,
                self.max_chunks,
                self.shared_memory.name,
            ),
        )

    def __del__(self):
        if hasattr(self, &#34;shared_memory&#34;):
            self.shared_memory.close()
            if self.is_creator:
                self.shared_memory.unlink()

    @contextmanager
    def get_data(self, current_idx: int):
        start = self.data_offset + current_idx * self.max_chunk_bytes
        end = start + self.max_chunk_bytes
        with memoryview(self.shared_memory.buf[start:end]) as buf:
            yield buf

    @contextmanager
    def get_metadata(self, current_idx: int):
        start = self.metadata_offset + current_idx * self.metadata_size
        end = start + self.metadata_size
        with memoryview(self.shared_memory.buf[start:end]) as buf:
            yield buf</code></pre>
</details>
<div class="desc"><p>A shared memory ring buffer implementation for broadcast communication.
Essentially, it is a queue where only one will <code>enqueue</code> and multiple
will <code>dequeue</code>. The max size of each item, together with the max number
of items that can be stored in the buffer are known in advance.
In this case, we don't need to synchronize the access to
the buffer.</p>
<p>Buffer memory layout:
data
metadata
|
|
| (current_idx)
| (current_idx)
v
v
+-------------------------------+----------------------------------------+
| chunk0 | chunk1 | &hellip; | chunk | metadata0 | metadata1 | &hellip; | metadata |
+-------------------------------+----------------------------------------+
| max_chunks x max_chunk_bytes
| max_chunks x (1 + n_reader) bytes
|</p>
<p>metadata memory layout: each byte is a flag, the first byte is the written
flag, and the rest are reader flags. The flags are set to 0 by default.
+--------------+--------------+--------------+-----+--------------+
| written_flag | reader0_flag | reader1_flag | &hellip; | readerN_flag |
+--------------+--------------+--------------+-----+--------------+</p>
<p>The state of metadata is as follows:</p>
<p>(case 1) 0???&hellip;???: the block is not written yet, cannot read, can write
(case 2) 1000&hellip;000: the block is just written, can read, cannot write
(case 3) 1???&hellip;???: the block is written and read by some readers, can read if not read, cannot write
(case 4) 1111&hellip;111: the block is written and read by all readers, cannot read, can write</p>
<p>State transition for readers:</p>
<p>When a reader finds a block that it can read (case 2 or 3), it can yield the block for caller to read.
Only after the caller finishes reading the block, the reader can mark the block as read.
Readers only mark the block as read (from 0 to 1), the writer marks the block as ready to read (from 1 to 0).</p>
<p>State transition for writer:</p>
<p>When the writer writes to a block (case 1 or 4), it first resets the written flag to 0, converting either case
to case 1. Then it can yield the block for caller to write. After the caller finishes writing the block, the writer
can reset the reader flags to 0, and mark the block as written (from 0 to 1).
NOTE: the order is important here, first reset the reader flags (so that we are still in case 1), then mark the block as written. The state transition is atomic. If we do it in the reverse order, it will go through case 3 and then back to case 2, and readers might read the intermediate case 3, which is not correct.</p>
<p>During creation, <code>name</code> is None and the buffer is created. We can pass the
created object to other processes by pickling it. The other processes will
get the name of the shared memory and open it, so that they can access the
same shared memory buffer.</p></div>
<h3>Methods</h3>
<dl>
<dt id="sglang.srt.distributed.device_communicators.shm_broadcast.ShmRingBuffer.get_data"><code class="name flex">
<span>def <span class="ident">get_data</span></span>(<span>self, current_idx: int)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@contextmanager
def get_data(self, current_idx: int):
    start = self.data_offset + current_idx * self.max_chunk_bytes
    end = start + self.max_chunk_bytes
    with memoryview(self.shared_memory.buf[start:end]) as buf:
        yield buf</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="sglang.srt.distributed.device_communicators.shm_broadcast.ShmRingBuffer.get_metadata"><code class="name flex">
<span>def <span class="ident">get_metadata</span></span>(<span>self, current_idx: int)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@contextmanager
def get_metadata(self, current_idx: int):
    start = self.metadata_offset + current_idx * self.metadata_size
    end = start + self.metadata_size
    with memoryview(self.shared_memory.buf[start:end]) as buf:
        yield buf</code></pre>
</details>
<div class="desc"></div>
</dd>
</dl>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="sglang.srt.distributed.device_communicators" href="index.html">sglang.srt.distributed.device_communicators</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="sglang.srt.distributed.device_communicators.shm_broadcast.Handle" href="#sglang.srt.distributed.device_communicators.shm_broadcast.Handle">Handle</a></code></h4>
<ul class="">
<li><code><a title="sglang.srt.distributed.device_communicators.shm_broadcast.Handle.buffer" href="#sglang.srt.distributed.device_communicators.shm_broadcast.Handle.buffer">buffer</a></code></li>
<li><code><a title="sglang.srt.distributed.device_communicators.shm_broadcast.Handle.connect_ip" href="#sglang.srt.distributed.device_communicators.shm_broadcast.Handle.connect_ip">connect_ip</a></code></li>
<li><code><a title="sglang.srt.distributed.device_communicators.shm_broadcast.Handle.local_reader_ranks" href="#sglang.srt.distributed.device_communicators.shm_broadcast.Handle.local_reader_ranks">local_reader_ranks</a></code></li>
<li><code><a title="sglang.srt.distributed.device_communicators.shm_broadcast.Handle.local_subscribe_port" href="#sglang.srt.distributed.device_communicators.shm_broadcast.Handle.local_subscribe_port">local_subscribe_port</a></code></li>
<li><code><a title="sglang.srt.distributed.device_communicators.shm_broadcast.Handle.remote_subscribe_port" href="#sglang.srt.distributed.device_communicators.shm_broadcast.Handle.remote_subscribe_port">remote_subscribe_port</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="sglang.srt.distributed.device_communicators.shm_broadcast.MessageQueue" href="#sglang.srt.distributed.device_communicators.shm_broadcast.MessageQueue">MessageQueue</a></code></h4>
<ul class="">
<li><code><a title="sglang.srt.distributed.device_communicators.shm_broadcast.MessageQueue.acquire_read" href="#sglang.srt.distributed.device_communicators.shm_broadcast.MessageQueue.acquire_read">acquire_read</a></code></li>
<li><code><a title="sglang.srt.distributed.device_communicators.shm_broadcast.MessageQueue.acquire_write" href="#sglang.srt.distributed.device_communicators.shm_broadcast.MessageQueue.acquire_write">acquire_write</a></code></li>
<li><code><a title="sglang.srt.distributed.device_communicators.shm_broadcast.MessageQueue.broadcast_object" href="#sglang.srt.distributed.device_communicators.shm_broadcast.MessageQueue.broadcast_object">broadcast_object</a></code></li>
<li><code><a title="sglang.srt.distributed.device_communicators.shm_broadcast.MessageQueue.create_from_handle" href="#sglang.srt.distributed.device_communicators.shm_broadcast.MessageQueue.create_from_handle">create_from_handle</a></code></li>
<li><code><a title="sglang.srt.distributed.device_communicators.shm_broadcast.MessageQueue.create_from_process_group" href="#sglang.srt.distributed.device_communicators.shm_broadcast.MessageQueue.create_from_process_group">create_from_process_group</a></code></li>
<li><code><a title="sglang.srt.distributed.device_communicators.shm_broadcast.MessageQueue.dequeue" href="#sglang.srt.distributed.device_communicators.shm_broadcast.MessageQueue.dequeue">dequeue</a></code></li>
<li><code><a title="sglang.srt.distributed.device_communicators.shm_broadcast.MessageQueue.enqueue" href="#sglang.srt.distributed.device_communicators.shm_broadcast.MessageQueue.enqueue">enqueue</a></code></li>
<li><code><a title="sglang.srt.distributed.device_communicators.shm_broadcast.MessageQueue.export_handle" href="#sglang.srt.distributed.device_communicators.shm_broadcast.MessageQueue.export_handle">export_handle</a></code></li>
<li><code><a title="sglang.srt.distributed.device_communicators.shm_broadcast.MessageQueue.wait_until_ready" href="#sglang.srt.distributed.device_communicators.shm_broadcast.MessageQueue.wait_until_ready">wait_until_ready</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="sglang.srt.distributed.device_communicators.shm_broadcast.ShmRingBuffer" href="#sglang.srt.distributed.device_communicators.shm_broadcast.ShmRingBuffer">ShmRingBuffer</a></code></h4>
<ul class="">
<li><code><a title="sglang.srt.distributed.device_communicators.shm_broadcast.ShmRingBuffer.get_data" href="#sglang.srt.distributed.device_communicators.shm_broadcast.ShmRingBuffer.get_data">get_data</a></code></li>
<li><code><a title="sglang.srt.distributed.device_communicators.shm_broadcast.ShmRingBuffer.get_metadata" href="#sglang.srt.distributed.device_communicators.shm_broadcast.ShmRingBuffer.get_metadata">get_metadata</a></code></li>
</ul>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc" title="pdoc: Python API documentation generator"><cite>pdoc</cite> 0.11.6</a>.</p>
</footer>
</body>
</html>
