<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1">
<meta name="generator" content="pdoc3 0.11.6">
<title>sglang.srt.multimodal.processors.step3_vl API documentation</title>
<meta name="description" content="">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/13.0.0/sanitize.min.css" integrity="sha512-y1dtMcuvtTMJc1yPgEqF0ZjQbhnc/bFhyvIyVNb9Zk5mIGtqVaAB1Ttl28su8AvFMOY0EwRbAe+HCLqj6W7/KA==" crossorigin>
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/13.0.0/typography.min.css" integrity="sha512-Y1DYSb995BAfxobCkKepB1BqJJTPrOp3zPL74AWFugHHmmdcvO+C48WLrUOlhGMc0QG7AE3f7gmvvcrmX2fDoA==" crossorigin>
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/styles/default.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:1.5em;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:2em 0 .50em 0}h3{font-size:1.4em;margin:1.6em 0 .7em 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .2s ease-in-out}a:visited{color:#503}a:hover{color:#b62}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900;font-weight:bold}pre code{font-size:.8em;line-height:1.4em;padding:1em;display:block}code{background:#f3f3f3;font-family:"DejaVu Sans Mono",monospace;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source > summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible;min-width:max-content}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em 1em;margin:1em 0}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul ul{padding-left:1em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/highlight.min.js" integrity="sha512-D9gUyxqja7hBtkWpPWGt9wfbfaMGVt9gnyCvYa+jojwwPHLCzUm5i8rpk7vD7wNee9bA35eYIjobYPaQuKS1MQ==" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => {
hljs.configure({languages: ['bash', 'css', 'diff', 'graphql', 'ini', 'javascript', 'json', 'plaintext', 'python', 'python-repl', 'rust', 'shell', 'sql', 'typescript', 'xml', 'yaml']});
hljs.highlightAll();
/* Collapse source docstrings */
setTimeout(() => {
[...document.querySelectorAll('.hljs.language-python > .hljs-string')]
.filter(el => el.innerHTML.length > 200 && ['"""', "'''"].includes(el.innerHTML.substring(0, 3)))
.forEach(el => {
let d = document.createElement('details');
d.classList.add('hljs-string');
d.innerHTML = '<summary>"""</summary>' + el.innerHTML.substring(3);
el.replaceWith(d);
});
}, 100);
})</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>sglang.srt.multimodal.processors.step3_vl</code></h1>
</header>
<section id="section-intro">
</section>
<section>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="sglang.srt.multimodal.processors.step3_vl.GPUToTensor"><code class="flex name class">
<span>class <span class="ident">GPUToTensor</span></span>
<span>(</span><span>*args, **kwargs)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class GPUToTensor(torch.nn.Module):

    def forward(self, raw_image: Union[np.ndarray, Image.Image]) -&gt; torch.Tensor:
        if isinstance(raw_image, Image.Image):
            return transforms.ToTensor()(raw_image)
        if raw_image.ndim == 2:
            raw_image = raw_image[:, :, None].repeat(3, -1)
        if torch.cuda.is_available():
            device = torch.device(&#34;cuda&#34;)
        else:
            device = torch.device(&#34;cpu&#34;)
        image_tensor = torch.from_numpy(raw_image).to(device)
        image_tensor = torch.permute(image_tensor, (2, 0, 1)).contiguous()
        if image_tensor.dtype == torch.uint8:
            image_tensor = image_tensor.to(torch.float32).div(255)
        return image_tensor</code></pre>
</details>
<div class="desc"><p>Base class for all neural network modules.</p>
<p>Your models should also subclass this class.</p>
<p>Modules can also contain other Modules, allowing them to be nested in
a tree structure. You can assign the submodules as regular attributes::</p>
<pre><code>import torch.nn as nn
import torch.nn.functional as F


class Model(nn.Module):
    def __init__(self) -&gt; None:
        super().__init__()
        self.conv1 = nn.Conv2d(1, 20, 5)
        self.conv2 = nn.Conv2d(20, 20, 5)

    def forward(self, x):
        x = F.relu(self.conv1(x))
        return F.relu(self.conv2(x))
</code></pre>
<p>Submodules assigned in this way will be registered, and will also have their
parameters converted when you call :meth:<code>to</code>, etc.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>As per the example above, an <code>__init__()</code> call to the parent class
must be made before assignment on the child.</p>
</div>
<p>:ivar training: Boolean represents whether this module is in training or
evaluation mode.
:vartype training: bool</p>
<p>Initialize internal Module state, shared by both nn.Module and ScriptModule.</p></div>
<h3>Ancestors</h3>
<ul class="hlist">
<li>torch.nn.modules.module.Module</li>
</ul>
<h3>Methods</h3>
<dl>
<dt id="sglang.srt.multimodal.processors.step3_vl.GPUToTensor.forward"><code class="name flex">
<span>def <span class="ident">forward</span></span>(<span>self, raw_image: numpy.ndarray | PIL.Image.Image) ‑> torch.Tensor</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def forward(self, raw_image: Union[np.ndarray, Image.Image]) -&gt; torch.Tensor:
    if isinstance(raw_image, Image.Image):
        return transforms.ToTensor()(raw_image)
    if raw_image.ndim == 2:
        raw_image = raw_image[:, :, None].repeat(3, -1)
    if torch.cuda.is_available():
        device = torch.device(&#34;cuda&#34;)
    else:
        device = torch.device(&#34;cpu&#34;)
    image_tensor = torch.from_numpy(raw_image).to(device)
    image_tensor = torch.permute(image_tensor, (2, 0, 1)).contiguous()
    if image_tensor.dtype == torch.uint8:
        image_tensor = image_tensor.to(torch.float32).div(255)
    return image_tensor</code></pre>
</details>
<div class="desc"><p>Define the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the :class:<code>Module</code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div></div>
</dd>
</dl>
</dd>
<dt id="sglang.srt.multimodal.processors.step3_vl.ImagePatcher"><code class="flex name class">
<span>class <span class="ident">ImagePatcher</span></span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class ImagePatcher:

    def determine_window_size(self, long: int, short: int) -&gt; int:
        if long &lt;= 728:
            return short if long / short &gt; 1.5 else 0
        return min(short, 504) if long / short &gt; 4 else 504

    def slide_window(
        self,
        width: int,
        height: int,
        sizes: list[tuple[int, int]],
        steps: list[tuple[int, int]],
        img_rate_thr: float = 0.6,
    ) -&gt; tuple[list[tuple[int, int, int, int]], tuple[int, int]]:
        assert 1 &gt;= img_rate_thr &gt;= 0, &#34;The `in_rate_thr` should lie in 0~1&#34;
        windows = []
        # Sliding windows.
        for size, step in zip(sizes, steps):
            size_w, size_h = size
            step_w, step_h = step

            x_num = 1 if width &lt;= size_w else math.ceil((width - size_w) / step_w + 1)
            x_start = [step_w * i for i in range(x_num)]
            if len(x_start) &gt; 1 and x_start[-1] + size_w &gt; width:
                x_start[-1] = width - size_w

            y_num = 1 if height &lt;= size_h else math.ceil((height - size_h) / step_h + 1)
            y_start = [step_h * i for i in range(y_num)]
            if len(y_start) &gt; 1 and y_start[-1] + size_h &gt; height:
                y_start[-1] = height - size_h

            start = np.array(list(product(y_start, x_start)), dtype=int)
            start[:, [0, 1]] = start[:, [1, 0]]
            windows.append(np.concatenate([start, start + size], axis=1))
        windows = np.concatenate(windows, axis=0)

        return [
            (int(box[0]), int(box[1]), int(box[2] - box[0]), int(box[3] - box[1]))
            for box in windows
        ], (x_num, y_num)

    def square_pad(self, img: Image.Image) -&gt; Image.Image:
        w, h = img.size
        if w == h:
            return img
        size = max(w, h)
        padded = Image.new(img.mode, (size, size), 0)
        padded.paste(img, (0, 0))
        return padded

    def get_image_size_for_padding(
        self, img_width: int, img_height: int
    ) -&gt; tuple[int, int]:
        ratio = img_width / img_height
        if min(img_height, img_width) &lt; 32 and (ratio &gt; 4 or ratio &lt; 1 / 4):
            new_size = max(img_height, img_width)
            return new_size, new_size
        return img_width, img_height

    def get_image_size_for_preprocess(
        self, img_width: int, img_height: int
    ) -&gt; tuple[int, int]:

        if max(img_height, img_width) &gt; 3024:
            scale_factor = 3024 / max(img_height, img_width)
            img_width = int(img_width * scale_factor)
            img_height = int(img_height * scale_factor)
            return img_width, img_height
        else:
            return img_width, img_height

    def get_image_size_for_crop(
        self, img_width: int, img_height: int, window_size: int
    ):
        w_ratio = img_width / window_size
        h_ratio = img_height / window_size

        if w_ratio &lt; 1:
            width_new = img_width
        else:
            decimal_w = w_ratio - img_width // window_size
            w_ratio = int(w_ratio) + 1 if decimal_w &gt; 0.2 else int(w_ratio)
            width_new = window_size * w_ratio
        if h_ratio &lt; 1:
            height_new = img_height
        else:
            decimal_h = h_ratio - img_height // window_size
            h_ratio = int(h_ratio) + 1 if decimal_h &gt; 0.2 else int(h_ratio)
            height_new = window_size * h_ratio
        return int(width_new), int(height_new)

    def patch_crop(self, img: Image.Image, i: int, j: int, th: int, tw: int):
        target = img.crop((j, i, j + tw, i + th))
        return target

    def get_num_patches(self, img_width: int, img_height: int) -&gt; tuple[int, int]:
        img_width, img_height = self.get_image_size_for_padding(img_width, img_height)
        img_width, img_height = self.get_image_size_for_preprocess(
            img_width, img_height
        )
        window_size = self.determine_window_size(
            max(img_height, img_width), min(img_height, img_width)
        )
        if window_size == 0:
            return 0, 0
        else:
            img_width, img_height = self.get_image_size_for_crop(
                img_width, img_height, window_size
            )
            center_list, (x_num, y_num) = self.slide_window(
                img_width,
                img_height,
                [(window_size, window_size)],
                [(window_size, window_size)],
            )
            full_rows = (len(center_list) - 1) // x_num + 1
            if len(center_list) &gt; 0 and len(center_list) % x_num == 0:
                full_rows -= 1
            return len(center_list), full_rows

    def __call__(
        self, img: Image.Image
    ) -&gt; tuple[Image.Image, list[Image.Image], list[bool] | None]:
        img_width, img_height = img.size
        new_img_width, new_img_height = self.get_image_size_for_padding(
            img_width, img_height
        )
        if new_img_width != img_width or new_img_height != img_height:
            img = self.square_pad(img)
            img_width, img_height = img.size

        new_img_width, new_img_height = self.get_image_size_for_preprocess(
            img_width, img_height
        )
        img = img.resize((new_img_width, new_img_height), Image.Resampling.BILINEAR)
        window_size = self.determine_window_size(
            max(new_img_height, new_img_width), min(new_img_height, new_img_width)
        )
        if window_size == 0:
            return img, [], None
        else:
            new_img_width, new_img_height = self.get_image_size_for_crop(
                new_img_width, new_img_height, window_size
            )
            if (new_img_width, new_img_height) != (img_width, img_height):
                img_for_crop = img.resize(
                    (new_img_width, new_img_height), Image.Resampling.BILINEAR
                )
            else:
                img_for_crop = img

            patches = []
            newlines = []
            center_list, (x_num, y_num) = self.slide_window(
                new_img_width,
                new_img_height,
                [(window_size, window_size)],
                [(window_size, window_size)],
            )
            for patch_id, center_lf_point in enumerate(center_list):
                x, y, patch_w, patch_h = center_lf_point
                big_patch = self.patch_crop(img_for_crop, y, x, patch_h, patch_w)
                patches.append(big_patch)
                if (patch_id + 1) % x_num == 0:
                    newlines.append(patch_id)

            if newlines and newlines[-1] == len(patches) - 1:
                newlines.pop()

            return (
                img,
                patches,
                (
                    [i in newlines for i in range(len(patches))]
                    if len(patches) &gt; 0
                    else None
                ),
            )</code></pre>
</details>
<div class="desc"></div>
<h3>Methods</h3>
<dl>
<dt id="sglang.srt.multimodal.processors.step3_vl.ImagePatcher.determine_window_size"><code class="name flex">
<span>def <span class="ident">determine_window_size</span></span>(<span>self, long: int, short: int) ‑> int</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def determine_window_size(self, long: int, short: int) -&gt; int:
    if long &lt;= 728:
        return short if long / short &gt; 1.5 else 0
    return min(short, 504) if long / short &gt; 4 else 504</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="sglang.srt.multimodal.processors.step3_vl.ImagePatcher.get_image_size_for_crop"><code class="name flex">
<span>def <span class="ident">get_image_size_for_crop</span></span>(<span>self, img_width: int, img_height: int, window_size: int)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_image_size_for_crop(
    self, img_width: int, img_height: int, window_size: int
):
    w_ratio = img_width / window_size
    h_ratio = img_height / window_size

    if w_ratio &lt; 1:
        width_new = img_width
    else:
        decimal_w = w_ratio - img_width // window_size
        w_ratio = int(w_ratio) + 1 if decimal_w &gt; 0.2 else int(w_ratio)
        width_new = window_size * w_ratio
    if h_ratio &lt; 1:
        height_new = img_height
    else:
        decimal_h = h_ratio - img_height // window_size
        h_ratio = int(h_ratio) + 1 if decimal_h &gt; 0.2 else int(h_ratio)
        height_new = window_size * h_ratio
    return int(width_new), int(height_new)</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="sglang.srt.multimodal.processors.step3_vl.ImagePatcher.get_image_size_for_padding"><code class="name flex">
<span>def <span class="ident">get_image_size_for_padding</span></span>(<span>self, img_width: int, img_height: int) ‑> tuple[int, int]</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_image_size_for_padding(
    self, img_width: int, img_height: int
) -&gt; tuple[int, int]:
    ratio = img_width / img_height
    if min(img_height, img_width) &lt; 32 and (ratio &gt; 4 or ratio &lt; 1 / 4):
        new_size = max(img_height, img_width)
        return new_size, new_size
    return img_width, img_height</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="sglang.srt.multimodal.processors.step3_vl.ImagePatcher.get_image_size_for_preprocess"><code class="name flex">
<span>def <span class="ident">get_image_size_for_preprocess</span></span>(<span>self, img_width: int, img_height: int) ‑> tuple[int, int]</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_image_size_for_preprocess(
    self, img_width: int, img_height: int
) -&gt; tuple[int, int]:

    if max(img_height, img_width) &gt; 3024:
        scale_factor = 3024 / max(img_height, img_width)
        img_width = int(img_width * scale_factor)
        img_height = int(img_height * scale_factor)
        return img_width, img_height
    else:
        return img_width, img_height</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="sglang.srt.multimodal.processors.step3_vl.ImagePatcher.get_num_patches"><code class="name flex">
<span>def <span class="ident">get_num_patches</span></span>(<span>self, img_width: int, img_height: int) ‑> tuple[int, int]</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_num_patches(self, img_width: int, img_height: int) -&gt; tuple[int, int]:
    img_width, img_height = self.get_image_size_for_padding(img_width, img_height)
    img_width, img_height = self.get_image_size_for_preprocess(
        img_width, img_height
    )
    window_size = self.determine_window_size(
        max(img_height, img_width), min(img_height, img_width)
    )
    if window_size == 0:
        return 0, 0
    else:
        img_width, img_height = self.get_image_size_for_crop(
            img_width, img_height, window_size
        )
        center_list, (x_num, y_num) = self.slide_window(
            img_width,
            img_height,
            [(window_size, window_size)],
            [(window_size, window_size)],
        )
        full_rows = (len(center_list) - 1) // x_num + 1
        if len(center_list) &gt; 0 and len(center_list) % x_num == 0:
            full_rows -= 1
        return len(center_list), full_rows</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="sglang.srt.multimodal.processors.step3_vl.ImagePatcher.patch_crop"><code class="name flex">
<span>def <span class="ident">patch_crop</span></span>(<span>self, img: PIL.Image.Image, i: int, j: int, th: int, tw: int)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def patch_crop(self, img: Image.Image, i: int, j: int, th: int, tw: int):
    target = img.crop((j, i, j + tw, i + th))
    return target</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="sglang.srt.multimodal.processors.step3_vl.ImagePatcher.slide_window"><code class="name flex">
<span>def <span class="ident">slide_window</span></span>(<span>self,<br>width: int,<br>height: int,<br>sizes: list[tuple[int, int]],<br>steps: list[tuple[int, int]],<br>img_rate_thr: float = 0.6) ‑> tuple[list[tuple[int, int, int, int]], tuple[int, int]]</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def slide_window(
    self,
    width: int,
    height: int,
    sizes: list[tuple[int, int]],
    steps: list[tuple[int, int]],
    img_rate_thr: float = 0.6,
) -&gt; tuple[list[tuple[int, int, int, int]], tuple[int, int]]:
    assert 1 &gt;= img_rate_thr &gt;= 0, &#34;The `in_rate_thr` should lie in 0~1&#34;
    windows = []
    # Sliding windows.
    for size, step in zip(sizes, steps):
        size_w, size_h = size
        step_w, step_h = step

        x_num = 1 if width &lt;= size_w else math.ceil((width - size_w) / step_w + 1)
        x_start = [step_w * i for i in range(x_num)]
        if len(x_start) &gt; 1 and x_start[-1] + size_w &gt; width:
            x_start[-1] = width - size_w

        y_num = 1 if height &lt;= size_h else math.ceil((height - size_h) / step_h + 1)
        y_start = [step_h * i for i in range(y_num)]
        if len(y_start) &gt; 1 and y_start[-1] + size_h &gt; height:
            y_start[-1] = height - size_h

        start = np.array(list(product(y_start, x_start)), dtype=int)
        start[:, [0, 1]] = start[:, [1, 0]]
        windows.append(np.concatenate([start, start + size], axis=1))
    windows = np.concatenate(windows, axis=0)

    return [
        (int(box[0]), int(box[1]), int(box[2] - box[0]), int(box[3] - box[1]))
        for box in windows
    ], (x_num, y_num)</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="sglang.srt.multimodal.processors.step3_vl.ImagePatcher.square_pad"><code class="name flex">
<span>def <span class="ident">square_pad</span></span>(<span>self, img: PIL.Image.Image) ‑> PIL.Image.Image</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def square_pad(self, img: Image.Image) -&gt; Image.Image:
    w, h = img.size
    if w == h:
        return img
    size = max(w, h)
    padded = Image.new(img.mode, (size, size), 0)
    padded.paste(img, (0, 0))
    return padded</code></pre>
</details>
<div class="desc"></div>
</dd>
</dl>
</dd>
<dt id="sglang.srt.multimodal.processors.step3_vl.Step3VLImageProcessor"><code class="flex name class">
<span>class <span class="ident">Step3VLImageProcessor</span></span>
<span>(</span><span>hf_config, server_args, _processor, *args, **kwargs)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class Step3VLImageProcessor(SGLangBaseProcessor):
    models = [Step3VLForConditionalGeneration]

    def __init__(self, hf_config, server_args, _processor, *args, **kwargs):
        # TODO, check _processor is tokenizer or processor.
        processor = Step3VLProcessor(hf_config, _processor)
        super().__init__(hf_config, server_args, processor, *args, **kwargs)
        self.IM_TOKEN_ID = 128001
        self.mm_tokens = MultimodalSpecialTokens(
            image_token=&#34;&lt;im_patch&gt;&#34;,
            image_token_id=128001,
            image_token_regex=re.compile(r&#34;(?:&lt;im_patch&gt;)&#34;),
        ).build(_processor)

        mean = [0.48145466, 0.4578275, 0.40821073]
        std = [0.26862954, 0.26130258, 0.27577711]

    def preprocess(self, image):
        return {&#34;pixel_values&#34;: self.transform(image).unsqueeze(0)}

    def __call__(self, image):
        return self.preprocess(image)

    async def process_mm_data_async(
        self,
        image_data: List[Union[str, bytes]],
        input_text: str | List[int],
        request_obj,
        *args,
        **kwargs,
    ):
        base_output = self.load_mm_data(
            prompt=input_text,
            image_data=image_data,
            video_data=request_obj.video_data,
            multimodal_tokens=self.mm_tokens,
        )

        mm_items, input_ids, ret = self.process_and_combine_mm_data(
            base_output, self.mm_tokens
        )

        return {
            &#34;input_ids&#34;: input_ids.tolist(),
            &#34;mm_items&#34;: mm_items,
            &#34;im_token_id&#34;: self.mm_tokens.image_token_id,
        }</code></pre>
</details>
<div class="desc"><p>Helper class that provides a standard way to create an ABC using
inheritance.</p></div>
<h3>Ancestors</h3>
<ul class="hlist">
<li><a title="sglang.srt.multimodal.processors.base_processor.BaseMultimodalProcessor" href="base_processor.html#sglang.srt.multimodal.processors.base_processor.BaseMultimodalProcessor">BaseMultimodalProcessor</a></li>
<li>abc.ABC</li>
</ul>
<h3>Class variables</h3>
<dl>
<dt id="sglang.srt.multimodal.processors.step3_vl.Step3VLImageProcessor.models"><code class="name">var <span class="ident">models</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
</dl>
<h3>Methods</h3>
<dl>
<dt id="sglang.srt.multimodal.processors.step3_vl.Step3VLImageProcessor.preprocess"><code class="name flex">
<span>def <span class="ident">preprocess</span></span>(<span>self, image)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def preprocess(self, image):
    return {&#34;pixel_values&#34;: self.transform(image).unsqueeze(0)}</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="sglang.srt.multimodal.processors.step3_vl.Step3VLImageProcessor.process_mm_data_async"><code class="name flex">
<span>async def <span class="ident">process_mm_data_async</span></span>(<span>self,<br>image_data: List[str | bytes],<br>input_text: str | List[int],<br>request_obj,<br>*args,<br>**kwargs)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">async def process_mm_data_async(
    self,
    image_data: List[Union[str, bytes]],
    input_text: str | List[int],
    request_obj,
    *args,
    **kwargs,
):
    base_output = self.load_mm_data(
        prompt=input_text,
        image_data=image_data,
        video_data=request_obj.video_data,
        multimodal_tokens=self.mm_tokens,
    )

    mm_items, input_ids, ret = self.process_and_combine_mm_data(
        base_output, self.mm_tokens
    )

    return {
        &#34;input_ids&#34;: input_ids.tolist(),
        &#34;mm_items&#34;: mm_items,
        &#34;im_token_id&#34;: self.mm_tokens.image_token_id,
    }</code></pre>
</details>
<div class="desc"></div>
</dd>
</dl>
<h3>Inherited members</h3>
<ul class="hlist">
<li><code><b><a title="sglang.srt.multimodal.processors.base_processor.BaseMultimodalProcessor" href="base_processor.html#sglang.srt.multimodal.processors.base_processor.BaseMultimodalProcessor">BaseMultimodalProcessor</a></b></code>:
<ul class="hlist">
<li><code><a title="sglang.srt.multimodal.processors.base_processor.BaseMultimodalProcessor.collect_mm_items_from_processor_output" href="base_processor.html#sglang.srt.multimodal.processors.base_processor.BaseMultimodalProcessor.collect_mm_items_from_processor_output">collect_mm_items_from_processor_output</a></code></li>
<li><code><a title="sglang.srt.multimodal.processors.base_processor.BaseMultimodalProcessor.get_estimated_frames_list" href="base_processor.html#sglang.srt.multimodal.processors.base_processor.BaseMultimodalProcessor.get_estimated_frames_list">get_estimated_frames_list</a></code></li>
<li><code><a title="sglang.srt.multimodal.processors.base_processor.BaseMultimodalProcessor.get_mm_items_offset" href="base_processor.html#sglang.srt.multimodal.processors.base_processor.BaseMultimodalProcessor.get_mm_items_offset">get_mm_items_offset</a></code></li>
<li><code><a title="sglang.srt.multimodal.processors.base_processor.BaseMultimodalProcessor.load_mm_data" href="base_processor.html#sglang.srt.multimodal.processors.base_processor.BaseMultimodalProcessor.load_mm_data">load_mm_data</a></code></li>
<li><code><a title="sglang.srt.multimodal.processors.base_processor.BaseMultimodalProcessor.process_and_combine_mm_data" href="base_processor.html#sglang.srt.multimodal.processors.base_processor.BaseMultimodalProcessor.process_and_combine_mm_data">process_and_combine_mm_data</a></code></li>
<li><code><a title="sglang.srt.multimodal.processors.base_processor.BaseMultimodalProcessor.process_mm_data" href="base_processor.html#sglang.srt.multimodal.processors.base_processor.BaseMultimodalProcessor.process_mm_data">process_mm_data</a></code></li>
<li><code><a title="sglang.srt.multimodal.processors.base_processor.BaseMultimodalProcessor.submit_data_loading_tasks" href="base_processor.html#sglang.srt.multimodal.processors.base_processor.BaseMultimodalProcessor.submit_data_loading_tasks">submit_data_loading_tasks</a></code></li>
</ul>
</li>
</ul>
</dd>
<dt id="sglang.srt.multimodal.processors.step3_vl.Step3VLProcessor"><code class="flex name class">
<span>class <span class="ident">Step3VLProcessor</span></span>
<span>(</span><span>config, tokenizer)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class Step3VLProcessor:
    def __init__(
        self,
        config,
        tokenizer,
    ) -&gt; None:
        super().__init__()

        self.config = config
        if isinstance(tokenizer, ProcessorMixin):
            tokenizer = tokenizer.tokenizer
        self.tokenizer = tokenizer

        self.image_size = 728
        self.patch_size = 504
        self.image_preprocessor = Step3VisionProcessor(
            self.image_size, &#34;bilinear&#34;, self.patch_size
        )

        self.num_image_feature_size = 169
        self.num_patch_feature_size = 81
        self.image_token = &#34;&lt;im_patch&gt;&#34;
        self.image_feature_placeholder = self.image_token * self.num_image_feature_size
        self.patch_feature_placeholder = self.image_token * self.num_patch_feature_size

        self.patcher = ImagePatcher()

    @property
    def image_token_id(self) -&gt; int:
        return self.tokenizer.get_vocab()[self.image_token]

    def get_num_image_tokens(self, img_width: int, img_height: int) -&gt; int:
        num_patches, num_newlines = self.patcher.get_num_patches(img_width, img_height)

        return (
            num_patches * (self.num_patch_feature_size + 2)
            + self.num_image_feature_size
            + 2
            + num_newlines
        )

    def _split_images(self, images: list[Image.Image]) -&gt; list[ImageWithPatches]:
        result = []
        for img in images:
            result.append(self.patcher(img))
        return result

    def _convert_images_to_pixel_values(
        self,
        images: list[Image.Image],
        is_patch: bool = False,
    ) -&gt; list[torch.Tensor]:
        return [
            self.image_preprocessor(img, is_patch=is_patch)[&#34;pixel_values&#34;]
            for img in images
        ]

    def _get_patch_repl(
        self,
        num_patches: int,
        patch_newline_mask: list[bool] | None,
    ) -&gt; tuple[str, list[int]]:
        text = &#34;&#34;
        token_ids = []
        for i in range(num_patches):
            assert len(patch_newline_mask) == num_patches
            text += f&#34;&lt;patch_start&gt;{self.patch_feature_placeholder}&lt;patch_end&gt;&#34;
            token_ids.extend(
                [self.tokenizer.convert_tokens_to_ids(&#34;&lt;patch_start&gt;&#34;)]
                + [self.image_token_id] * self.num_patch_feature_size
                + [self.tokenizer.convert_tokens_to_ids(&#34;&lt;patch_end&gt;&#34;)]
            )
            if patch_newline_mask and patch_newline_mask[i]:
                text += &#34;&lt;patch_newline&gt;&#34;
                token_ids.append(
                    self.tokenizer.convert_tokens_to_ids(&#34;&lt;patch_newline&gt;&#34;)
                )
        return text, token_ids

    def _get_image_repl(
        self,
        num_images: int,
    ) -&gt; tuple[str, list[int]]:
        text = f&#34;&lt;im_start&gt;{self.image_feature_placeholder}&lt;im_end&gt;&#34;
        token_ids = (
            [self.tokenizer.convert_tokens_to_ids(&#34;&lt;im_start&gt;&#34;)]
            + [self.image_token_id] * self.num_image_feature_size
            + [self.tokenizer.convert_tokens_to_ids(&#34;&lt;im_end&gt;&#34;)]
        )
        return text * num_images, token_ids * num_images

    def _get_image_repl_features(
        self,
        num_images: int,
        num_patches: int,
        patch_new_line_idx: Optional[list[bool]],
    ) -&gt; tuple[str, list[int]]:
        if num_patches &gt; 0:
            patch_repl, patch_repl_ids = self._get_patch_repl(
                num_patches, patch_new_line_idx
            )
        else:
            patch_repl = &#34;&#34;
            patch_repl_ids = []
        image_repl, image_repl_ids = self._get_image_repl(num_images)
        return patch_repl + image_repl, patch_repl_ids + image_repl_ids

    def replace_placeholder(self, text: str, placeholder: str, repls: list[str]) -&gt; str:
        parts = text.split(placeholder)

        if len(parts) - 1 != len(repls):
            raise ValueError(
                &#34;The number of placeholders does not match the number of replacements.&#34;  # noqa: E501
            )

        result = [parts[0]]
        for i, repl in enumerate(repls):
            result.append(repl)
            result.append(parts[i + 1])

        return &#34;&#34;.join(result)

    def __call__(
        self,
        text: Optional[Union[str, list[str]]] = None,
        images: Optional[Union[Image.Image, list[Image.Image]]] = None,
        return_tensors: Optional[Union[str, TensorType]] = None,
        *args,
        **kwargs,
    ) -&gt; BatchFeature:
        if text is None:
            text = []
        if not isinstance(text, list):
            text = [text]
        if images is None:
            images = []
        if not isinstance(images, list):
            images = [images]

        if len(images) == 0:
            image_inputs = {}
            text_inputs = self.tokenizer(text)
        else:
            splitted_images_data = self._split_images(images)
            pixel_values_lst = []
            patch_pixel_values_lst = []
            patch_newline_mask_lst = []
            image_repl_str_lst = []
            image_repl_ids_lst = []
            num_patches = []
            for (
                raw_img,
                img_patches,
                patch_newline_mask,
            ) in splitted_images_data:  # noqa: E501
                pixel_values_lst.extend(self._convert_images_to_pixel_values([raw_img]))

                if len(img_patches) &gt; 0:
                    patch_pixel_values_lst.extend(
                        self._convert_images_to_pixel_values(img_patches, is_patch=True)
                    )
                num_patches.append(len(img_patches))

                image_repl_str, image_repl_ids = self._get_image_repl_features(
                    1, len(img_patches), patch_newline_mask
                )
                image_repl_str_lst.append(image_repl_str)
                image_repl_ids_lst.extend(image_repl_ids)

                if patch_newline_mask is not None:
                    patch_newline_mask_lst.extend(patch_newline_mask)

            image_inputs = {
                &#34;pixel_values&#34;: torch.cat(pixel_values_lst),
                &#34;num_patches&#34;: num_patches,
            }
            if patch_pixel_values_lst:
                image_inputs[&#34;patch_pixel_values&#34;] = torch.cat(patch_pixel_values_lst)
            if patch_newline_mask_lst:
                image_inputs[&#34;patch_newline_mask&#34;] = torch.tensor(
                    patch_newline_mask_lst, dtype=torch.bool
                )

            text = [
                self.replace_placeholder(t, self.image_token, image_repl_str_lst)
                for t in text
            ]
            text_inputs = self.tokenizer(text)

        return BatchFeature(
            {
                **text_inputs,
                **image_inputs,
            },
            tensor_type=return_tensors,
        )</code></pre>
</details>
<div class="desc"></div>
<h3>Instance variables</h3>
<dl>
<dt id="sglang.srt.multimodal.processors.step3_vl.Step3VLProcessor.image_token_id"><code class="name">prop <span class="ident">image_token_id</span> : int</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@property
def image_token_id(self) -&gt; int:
    return self.tokenizer.get_vocab()[self.image_token]</code></pre>
</details>
<div class="desc"></div>
</dd>
</dl>
<h3>Methods</h3>
<dl>
<dt id="sglang.srt.multimodal.processors.step3_vl.Step3VLProcessor.get_num_image_tokens"><code class="name flex">
<span>def <span class="ident">get_num_image_tokens</span></span>(<span>self, img_width: int, img_height: int) ‑> int</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_num_image_tokens(self, img_width: int, img_height: int) -&gt; int:
    num_patches, num_newlines = self.patcher.get_num_patches(img_width, img_height)

    return (
        num_patches * (self.num_patch_feature_size + 2)
        + self.num_image_feature_size
        + 2
        + num_newlines
    )</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="sglang.srt.multimodal.processors.step3_vl.Step3VLProcessor.replace_placeholder"><code class="name flex">
<span>def <span class="ident">replace_placeholder</span></span>(<span>self, text: str, placeholder: str, repls: list[str]) ‑> str</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def replace_placeholder(self, text: str, placeholder: str, repls: list[str]) -&gt; str:
    parts = text.split(placeholder)

    if len(parts) - 1 != len(repls):
        raise ValueError(
            &#34;The number of placeholders does not match the number of replacements.&#34;  # noqa: E501
        )

    result = [parts[0]]
    for i, repl in enumerate(repls):
        result.append(repl)
        result.append(parts[i + 1])

    return &#34;&#34;.join(result)</code></pre>
</details>
<div class="desc"></div>
</dd>
</dl>
</dd>
<dt id="sglang.srt.multimodal.processors.step3_vl.Step3VisionProcessor"><code class="flex name class">
<span>class <span class="ident">Step3VisionProcessor</span></span>
<span>(</span><span>size, interpolation_mode='bicubic', patch_size=None)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class Step3VisionProcessor:
    def __init__(self, size, interpolation_mode=&#34;bicubic&#34;, patch_size=None):
        mean = [0.48145466, 0.4578275, 0.40821073]
        std = [0.26862954, 0.26130258, 0.27577711]
        patch_size = patch_size if patch_size is not None else size

        self.transform = transforms.Compose(
            [
                GPUToTensor(),
                transforms.Normalize(mean, std),
                transforms.Resize(
                    (size, size),
                    interpolation=(
                        InterpolationMode.BICUBIC
                        if interpolation_mode == &#34;bicubic&#34;
                        else InterpolationMode.BILINEAR
                    ),
                    antialias=True,
                ),
            ]
        )

        self.patch_transform = (
            transforms.Compose(
                [
                    GPUToTensor(),
                    transforms.Normalize(mean, std),
                    transforms.Resize(
                        (patch_size, patch_size),
                        interpolation=(
                            InterpolationMode.BICUBIC
                            if interpolation_mode == &#34;bicubic&#34;
                            else InterpolationMode.BILINEAR
                        ),
                        antialias=True,
                    ),
                ]
            )
            if patch_size is not None
            else None
        )

    def __call__(self, image, is_patch=False):
        if is_patch:
            return {&#34;pixel_values&#34;: self.patch_transform(image).unsqueeze(0)}
        else:
            return {&#34;pixel_values&#34;: self.transform(image).unsqueeze(0)}</code></pre>
</details>
<div class="desc"></div>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="sglang.srt.multimodal.processors" href="index.html">sglang.srt.multimodal.processors</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="sglang.srt.multimodal.processors.step3_vl.GPUToTensor" href="#sglang.srt.multimodal.processors.step3_vl.GPUToTensor">GPUToTensor</a></code></h4>
<ul class="">
<li><code><a title="sglang.srt.multimodal.processors.step3_vl.GPUToTensor.forward" href="#sglang.srt.multimodal.processors.step3_vl.GPUToTensor.forward">forward</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="sglang.srt.multimodal.processors.step3_vl.ImagePatcher" href="#sglang.srt.multimodal.processors.step3_vl.ImagePatcher">ImagePatcher</a></code></h4>
<ul class="">
<li><code><a title="sglang.srt.multimodal.processors.step3_vl.ImagePatcher.determine_window_size" href="#sglang.srt.multimodal.processors.step3_vl.ImagePatcher.determine_window_size">determine_window_size</a></code></li>
<li><code><a title="sglang.srt.multimodal.processors.step3_vl.ImagePatcher.get_image_size_for_crop" href="#sglang.srt.multimodal.processors.step3_vl.ImagePatcher.get_image_size_for_crop">get_image_size_for_crop</a></code></li>
<li><code><a title="sglang.srt.multimodal.processors.step3_vl.ImagePatcher.get_image_size_for_padding" href="#sglang.srt.multimodal.processors.step3_vl.ImagePatcher.get_image_size_for_padding">get_image_size_for_padding</a></code></li>
<li><code><a title="sglang.srt.multimodal.processors.step3_vl.ImagePatcher.get_image_size_for_preprocess" href="#sglang.srt.multimodal.processors.step3_vl.ImagePatcher.get_image_size_for_preprocess">get_image_size_for_preprocess</a></code></li>
<li><code><a title="sglang.srt.multimodal.processors.step3_vl.ImagePatcher.get_num_patches" href="#sglang.srt.multimodal.processors.step3_vl.ImagePatcher.get_num_patches">get_num_patches</a></code></li>
<li><code><a title="sglang.srt.multimodal.processors.step3_vl.ImagePatcher.patch_crop" href="#sglang.srt.multimodal.processors.step3_vl.ImagePatcher.patch_crop">patch_crop</a></code></li>
<li><code><a title="sglang.srt.multimodal.processors.step3_vl.ImagePatcher.slide_window" href="#sglang.srt.multimodal.processors.step3_vl.ImagePatcher.slide_window">slide_window</a></code></li>
<li><code><a title="sglang.srt.multimodal.processors.step3_vl.ImagePatcher.square_pad" href="#sglang.srt.multimodal.processors.step3_vl.ImagePatcher.square_pad">square_pad</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="sglang.srt.multimodal.processors.step3_vl.Step3VLImageProcessor" href="#sglang.srt.multimodal.processors.step3_vl.Step3VLImageProcessor">Step3VLImageProcessor</a></code></h4>
<ul class="">
<li><code><a title="sglang.srt.multimodal.processors.step3_vl.Step3VLImageProcessor.models" href="#sglang.srt.multimodal.processors.step3_vl.Step3VLImageProcessor.models">models</a></code></li>
<li><code><a title="sglang.srt.multimodal.processors.step3_vl.Step3VLImageProcessor.preprocess" href="#sglang.srt.multimodal.processors.step3_vl.Step3VLImageProcessor.preprocess">preprocess</a></code></li>
<li><code><a title="sglang.srt.multimodal.processors.step3_vl.Step3VLImageProcessor.process_mm_data_async" href="#sglang.srt.multimodal.processors.step3_vl.Step3VLImageProcessor.process_mm_data_async">process_mm_data_async</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="sglang.srt.multimodal.processors.step3_vl.Step3VLProcessor" href="#sglang.srt.multimodal.processors.step3_vl.Step3VLProcessor">Step3VLProcessor</a></code></h4>
<ul class="">
<li><code><a title="sglang.srt.multimodal.processors.step3_vl.Step3VLProcessor.get_num_image_tokens" href="#sglang.srt.multimodal.processors.step3_vl.Step3VLProcessor.get_num_image_tokens">get_num_image_tokens</a></code></li>
<li><code><a title="sglang.srt.multimodal.processors.step3_vl.Step3VLProcessor.image_token_id" href="#sglang.srt.multimodal.processors.step3_vl.Step3VLProcessor.image_token_id">image_token_id</a></code></li>
<li><code><a title="sglang.srt.multimodal.processors.step3_vl.Step3VLProcessor.replace_placeholder" href="#sglang.srt.multimodal.processors.step3_vl.Step3VLProcessor.replace_placeholder">replace_placeholder</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="sglang.srt.multimodal.processors.step3_vl.Step3VisionProcessor" href="#sglang.srt.multimodal.processors.step3_vl.Step3VisionProcessor">Step3VisionProcessor</a></code></h4>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc" title="pdoc: Python API documentation generator"><cite>pdoc</cite> 0.11.6</a>.</p>
</footer>
</body>
</html>
