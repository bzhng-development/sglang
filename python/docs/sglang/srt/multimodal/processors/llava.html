<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1">
<meta name="generator" content="pdoc3 0.11.6">
<title>sglang.srt.multimodal.processors.llava API documentation</title>
<meta name="description" content="">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/13.0.0/sanitize.min.css" integrity="sha512-y1dtMcuvtTMJc1yPgEqF0ZjQbhnc/bFhyvIyVNb9Zk5mIGtqVaAB1Ttl28su8AvFMOY0EwRbAe+HCLqj6W7/KA==" crossorigin>
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/13.0.0/typography.min.css" integrity="sha512-Y1DYSb995BAfxobCkKepB1BqJJTPrOp3zPL74AWFugHHmmdcvO+C48WLrUOlhGMc0QG7AE3f7gmvvcrmX2fDoA==" crossorigin>
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/styles/default.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:1.5em;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:2em 0 .50em 0}h3{font-size:1.4em;margin:1.6em 0 .7em 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .2s ease-in-out}a:visited{color:#503}a:hover{color:#b62}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900;font-weight:bold}pre code{font-size:.8em;line-height:1.4em;padding:1em;display:block}code{background:#f3f3f3;font-family:"DejaVu Sans Mono",monospace;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source > summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible;min-width:max-content}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em 1em;margin:1em 0}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul ul{padding-left:1em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/highlight.min.js" integrity="sha512-D9gUyxqja7hBtkWpPWGt9wfbfaMGVt9gnyCvYa+jojwwPHLCzUm5i8rpk7vD7wNee9bA35eYIjobYPaQuKS1MQ==" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => {
hljs.configure({languages: ['bash', 'css', 'diff', 'graphql', 'ini', 'javascript', 'json', 'plaintext', 'python', 'python-repl', 'rust', 'shell', 'sql', 'typescript', 'xml', 'yaml']});
hljs.highlightAll();
/* Collapse source docstrings */
setTimeout(() => {
[...document.querySelectorAll('.hljs.language-python > .hljs-string')]
.filter(el => el.innerHTML.length > 200 && ['"""', "'''"].includes(el.innerHTML.substring(0, 3)))
.forEach(el => {
let d = document.createElement('details');
d.classList.add('hljs-string');
d.innerHTML = '<summary>"""</summary>' + el.innerHTML.substring(3);
el.replaceWith(d);
});
}, 100);
})</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>sglang.srt.multimodal.processors.llava</code></h1>
</header>
<section id="section-intro">
</section>
<section>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="sglang.srt.multimodal.processors.llava.LlavaImageProcessor"><code class="flex name class">
<span>class <span class="ident">LlavaImageProcessor</span></span>
<span>(</span><span>hf_config, server_args, _processor, *args, **kwargs)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class LlavaImageProcessor(BaseMultimodalProcessor):
    models = [
        LlavaLlamaForCausalLM,
        LlavaVidForCausalLM,
        LlavaQwenForCausalLM,
        LlavaMistralForCausalLM,
    ]

    def __init__(self, hf_config, server_args, _processor, *args, **kwargs):
        super().__init__(hf_config, server_args, _processor, *args, **kwargs)

    @staticmethod
    def _process_single_image_task(
        image_data: Union[str, bytes, ImageData],
        image_aspect_ratio: Optional[str] = None,
        image_grid_pinpoints: Optional[str] = None,
        processor=None,
    ):

        image_processor = processor.image_processor

        try:
            url = image_data.url if isinstance(image_data, ImageData) else image_data
            image, image_size = load_image(url)
            if image_size is not None:
                # It is a video with multiple images
                image_hash = hash(url)
                pixel_values = image_processor(image)[&#34;pixel_values&#34;]
                for _ in range(len(pixel_values)):
                    pixel_values[_] = pixel_values[_].astype(np.float16)
                pixel_values = np.stack(pixel_values, axis=0)
                return pixel_values, image_hash, image_size
            else:
                # It is an image
                image_hash = hash(url)
                if image_aspect_ratio == &#34;pad&#34;:
                    image = expand2square(
                        image,
                        tuple(int(x * 255) for x in image_processor.image_mean),
                    )
                    pixel_values = image_processor(image.convert(&#34;RGB&#34;))[
                        &#34;pixel_values&#34;
                    ][0]
                elif image_aspect_ratio == &#34;anyres&#34; or (
                    image_aspect_ratio is not None
                    and &#34;anyres_max&#34; in image_aspect_ratio
                ):
                    pixel_values = process_anyres_image(
                        image, image_processor, image_grid_pinpoints
                    )
                else:
                    pixel_values = image_processor(image)[&#34;pixel_values&#34;][0]

                if isinstance(pixel_values, np.ndarray):
                    pixel_values = pixel_values.astype(np.float16)

                return pixel_values, image_hash, image.size
        except Exception:
            logger.error(&#34;Exception in TokenizerManager:\n&#34; + get_exception_traceback())

    async def _process_single_image(
        self,
        image_data: Union[bytes, str, ImageData],
        aspect_ratio: str,
        grid_pinpoints: str,
    ):
        if self.cpu_executor is not None:
            loop = asyncio.get_event_loop()
            return await loop.run_in_executor(
                self.cpu_executor,
                LlavaImageProcessor._process_single_image_task,
                image_data,
                aspect_ratio,
                grid_pinpoints,
                self._processor,
            )
        else:
            return self._process_single_image_task(
                image_data,
                aspect_ratio,
                grid_pinpoints,
                self._processor.image_processor,
            )

    async def process_mm_data_async(
        self,
        image_data: List[Union[str, bytes, ImageData]],
        input_text,
        request_obj,
        *args,
        **kwargs,
    ):
        modalities = request_obj.modalities or [&#34;image&#34;]
        aspect_ratio = getattr(self.hf_config, &#34;image_aspect_ratio&#34;, None)
        grid_pinpoints = (
            self.hf_config.image_grid_pinpoints
            if hasattr(self.hf_config, &#34;image_grid_pinpoints&#34;)
            and &#34;anyres&#34; in aspect_ratio
            else None
        )

        if isinstance(image_data, list) and len(image_data) &gt; 0:
            if &#34;multi-images&#34; in modalities or &#34;video&#34; in modalities:
                # Multiple images
                aspect_ratio = &#34;pad&#34;  # LLaVA OneVision Handling: more than one image --&gt; interleaved image mode or video mode. We do not use anyres
                pixel_values, data_hashes, image_sizes = [], [], []
                res = []
                for img_data in image_data:
                    res.append(
                        self._process_single_image(
                            img_data, aspect_ratio, grid_pinpoints
                        )
                    )

                res = await asyncio.gather(*res)
                for pixel_v, image_h, image_s in res:
                    pixel_values.append(pixel_v)
                    data_hashes.append(image_h)
                    image_sizes.append(image_s)

                if isinstance(pixel_values[0], np.ndarray):
                    pixel_values = np.stack(pixel_values, axis=0)
            else:
                # A single image
                pixel_values, image_hash, image_size = await self._process_single_image(
                    image_data[0], aspect_ratio, grid_pinpoints
                )
                image_sizes = [image_size]
        else:
            raise ValueError(f&#34;Invalid image data: {image_data}&#34;)
        modality = Modality.IMAGE
        if isinstance(request_obj.modalities, list):
            if request_obj.modalities[0] == &#34;multi-images&#34;:
                modality = Modality.MULTI_IMAGES
            elif request_obj.modalities[0] == &#34;video&#34;:
                modality = Modality.VIDEO

        return {
            &#34;mm_items&#34;: [
                MultimodalDataItem(
                    feature=pixel_values,
                    model_specific_data={
                        &#34;image_sizes&#34;: image_sizes,
                    },
                    modality=modality,
                )
            ],
        }</code></pre>
</details>
<div class="desc"><p>Helper class that provides a standard way to create an ABC using
inheritance.</p></div>
<h3>Ancestors</h3>
<ul class="hlist">
<li><a title="sglang.srt.multimodal.processors.base_processor.BaseMultimodalProcessor" href="base_processor.html#sglang.srt.multimodal.processors.base_processor.BaseMultimodalProcessor">BaseMultimodalProcessor</a></li>
<li>abc.ABC</li>
</ul>
<h3>Class variables</h3>
<dl>
<dt id="sglang.srt.multimodal.processors.llava.LlavaImageProcessor.models"><code class="name">var <span class="ident">models</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
</dl>
<h3>Methods</h3>
<dl>
<dt id="sglang.srt.multimodal.processors.llava.LlavaImageProcessor.process_mm_data_async"><code class="name flex">
<span>async def <span class="ident">process_mm_data_async</span></span>(<span>self,<br>image_data: List[str | bytes | <a title="sglang.srt.utils.ImageData" href="../../utils.html#sglang.srt.utils.ImageData">ImageData</a>],<br>input_text,<br>request_obj,<br>*args,<br>**kwargs)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">async def process_mm_data_async(
    self,
    image_data: List[Union[str, bytes, ImageData]],
    input_text,
    request_obj,
    *args,
    **kwargs,
):
    modalities = request_obj.modalities or [&#34;image&#34;]
    aspect_ratio = getattr(self.hf_config, &#34;image_aspect_ratio&#34;, None)
    grid_pinpoints = (
        self.hf_config.image_grid_pinpoints
        if hasattr(self.hf_config, &#34;image_grid_pinpoints&#34;)
        and &#34;anyres&#34; in aspect_ratio
        else None
    )

    if isinstance(image_data, list) and len(image_data) &gt; 0:
        if &#34;multi-images&#34; in modalities or &#34;video&#34; in modalities:
            # Multiple images
            aspect_ratio = &#34;pad&#34;  # LLaVA OneVision Handling: more than one image --&gt; interleaved image mode or video mode. We do not use anyres
            pixel_values, data_hashes, image_sizes = [], [], []
            res = []
            for img_data in image_data:
                res.append(
                    self._process_single_image(
                        img_data, aspect_ratio, grid_pinpoints
                    )
                )

            res = await asyncio.gather(*res)
            for pixel_v, image_h, image_s in res:
                pixel_values.append(pixel_v)
                data_hashes.append(image_h)
                image_sizes.append(image_s)

            if isinstance(pixel_values[0], np.ndarray):
                pixel_values = np.stack(pixel_values, axis=0)
        else:
            # A single image
            pixel_values, image_hash, image_size = await self._process_single_image(
                image_data[0], aspect_ratio, grid_pinpoints
            )
            image_sizes = [image_size]
    else:
        raise ValueError(f&#34;Invalid image data: {image_data}&#34;)
    modality = Modality.IMAGE
    if isinstance(request_obj.modalities, list):
        if request_obj.modalities[0] == &#34;multi-images&#34;:
            modality = Modality.MULTI_IMAGES
        elif request_obj.modalities[0] == &#34;video&#34;:
            modality = Modality.VIDEO

    return {
        &#34;mm_items&#34;: [
            MultimodalDataItem(
                feature=pixel_values,
                model_specific_data={
                    &#34;image_sizes&#34;: image_sizes,
                },
                modality=modality,
            )
        ],
    }</code></pre>
</details>
<div class="desc"></div>
</dd>
</dl>
<h3>Inherited members</h3>
<ul class="hlist">
<li><code><b><a title="sglang.srt.multimodal.processors.base_processor.BaseMultimodalProcessor" href="base_processor.html#sglang.srt.multimodal.processors.base_processor.BaseMultimodalProcessor">BaseMultimodalProcessor</a></b></code>:
<ul class="hlist">
<li><code><a title="sglang.srt.multimodal.processors.base_processor.BaseMultimodalProcessor.collect_mm_items_from_processor_output" href="base_processor.html#sglang.srt.multimodal.processors.base_processor.BaseMultimodalProcessor.collect_mm_items_from_processor_output">collect_mm_items_from_processor_output</a></code></li>
<li><code><a title="sglang.srt.multimodal.processors.base_processor.BaseMultimodalProcessor.get_estimated_frames_list" href="base_processor.html#sglang.srt.multimodal.processors.base_processor.BaseMultimodalProcessor.get_estimated_frames_list">get_estimated_frames_list</a></code></li>
<li><code><a title="sglang.srt.multimodal.processors.base_processor.BaseMultimodalProcessor.get_mm_items_offset" href="base_processor.html#sglang.srt.multimodal.processors.base_processor.BaseMultimodalProcessor.get_mm_items_offset">get_mm_items_offset</a></code></li>
<li><code><a title="sglang.srt.multimodal.processors.base_processor.BaseMultimodalProcessor.load_mm_data" href="base_processor.html#sglang.srt.multimodal.processors.base_processor.BaseMultimodalProcessor.load_mm_data">load_mm_data</a></code></li>
<li><code><a title="sglang.srt.multimodal.processors.base_processor.BaseMultimodalProcessor.process_and_combine_mm_data" href="base_processor.html#sglang.srt.multimodal.processors.base_processor.BaseMultimodalProcessor.process_and_combine_mm_data">process_and_combine_mm_data</a></code></li>
<li><code><a title="sglang.srt.multimodal.processors.base_processor.BaseMultimodalProcessor.process_mm_data" href="base_processor.html#sglang.srt.multimodal.processors.base_processor.BaseMultimodalProcessor.process_mm_data">process_mm_data</a></code></li>
<li><code><a title="sglang.srt.multimodal.processors.base_processor.BaseMultimodalProcessor.submit_data_loading_tasks" href="base_processor.html#sglang.srt.multimodal.processors.base_processor.BaseMultimodalProcessor.submit_data_loading_tasks">submit_data_loading_tasks</a></code></li>
</ul>
</li>
</ul>
</dd>
<dt id="sglang.srt.multimodal.processors.llava.LlavaMultimodalProcessor"><code class="flex name class">
<span>class <span class="ident">LlavaMultimodalProcessor</span></span>
<span>(</span><span>hf_config, server_args, _processor, *args, **kwargs)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class LlavaMultimodalProcessor(BaseMultimodalProcessor):
    &#34;&#34;&#34;
    This is a wrapper class used to identify the multimodal processor for Llava architectures&#39; vision model.
    &#34;&#34;&#34;

    models = [LlavaForConditionalGeneration, Mistral3ForConditionalGeneration]

    def _get_sgl_processor_cls(self, model_type: str):
        if hf_name := HF_MAPPING_NAMES.get(model_type):
            sgl_mm_processor_set = sgl_mm_processor_utils.PROCESSOR_MAPPING.values()
            sgl_processor_cls = list(
                filter(lambda p: p.__name__ == hf_name, sgl_mm_processor_set)
            )
            if sgl_processor_cls:
                return sgl_processor_cls[0]
        raise ValueError(
            f&#34;Cannot find corresponding multimodal processor registered in sglang for model type `{model_type}`&#34;
        )

    def __init__(self, hf_config, server_args, _processor, *args, **kwargs):
        assert hasattr(hf_config, &#34;vision_config&#34;)
        assert hasattr(hf_config, &#34;text_config&#34;)
        self.vision_config = hf_config.vision_config
        self.text_config = hf_config.text_config
        self.hf_config = hf_config

        if vision_type := getattr(self.vision_config, &#34;model_type&#34;):
            self.inner = self._get_sgl_processor_cls(vision_type)(
                hf_config, server_args, _processor, *args, **kwargs
            )
        else:
            raise ValueError(
                f&#34;Required `vision_config.model_type` is not found in hf_config: `{hf_config}`&#34;
            )

    async def process_mm_data_async(self, *args, **kwargs):
        return await self.inner.process_mm_data_async(*args, **kwargs)</code></pre>
</details>
<div class="desc"><p>This is a wrapper class used to identify the multimodal processor for Llava architectures' vision model.</p></div>
<h3>Ancestors</h3>
<ul class="hlist">
<li><a title="sglang.srt.multimodal.processors.base_processor.BaseMultimodalProcessor" href="base_processor.html#sglang.srt.multimodal.processors.base_processor.BaseMultimodalProcessor">BaseMultimodalProcessor</a></li>
<li>abc.ABC</li>
</ul>
<h3>Class variables</h3>
<dl>
<dt id="sglang.srt.multimodal.processors.llava.LlavaMultimodalProcessor.models"><code class="name">var <span class="ident">models</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
</dl>
<h3>Methods</h3>
<dl>
<dt id="sglang.srt.multimodal.processors.llava.LlavaMultimodalProcessor.process_mm_data_async"><code class="name flex">
<span>async def <span class="ident">process_mm_data_async</span></span>(<span>self, *args, **kwargs)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">async def process_mm_data_async(self, *args, **kwargs):
    return await self.inner.process_mm_data_async(*args, **kwargs)</code></pre>
</details>
<div class="desc"></div>
</dd>
</dl>
<h3>Inherited members</h3>
<ul class="hlist">
<li><code><b><a title="sglang.srt.multimodal.processors.base_processor.BaseMultimodalProcessor" href="base_processor.html#sglang.srt.multimodal.processors.base_processor.BaseMultimodalProcessor">BaseMultimodalProcessor</a></b></code>:
<ul class="hlist">
<li><code><a title="sglang.srt.multimodal.processors.base_processor.BaseMultimodalProcessor.collect_mm_items_from_processor_output" href="base_processor.html#sglang.srt.multimodal.processors.base_processor.BaseMultimodalProcessor.collect_mm_items_from_processor_output">collect_mm_items_from_processor_output</a></code></li>
<li><code><a title="sglang.srt.multimodal.processors.base_processor.BaseMultimodalProcessor.get_estimated_frames_list" href="base_processor.html#sglang.srt.multimodal.processors.base_processor.BaseMultimodalProcessor.get_estimated_frames_list">get_estimated_frames_list</a></code></li>
<li><code><a title="sglang.srt.multimodal.processors.base_processor.BaseMultimodalProcessor.get_mm_items_offset" href="base_processor.html#sglang.srt.multimodal.processors.base_processor.BaseMultimodalProcessor.get_mm_items_offset">get_mm_items_offset</a></code></li>
<li><code><a title="sglang.srt.multimodal.processors.base_processor.BaseMultimodalProcessor.load_mm_data" href="base_processor.html#sglang.srt.multimodal.processors.base_processor.BaseMultimodalProcessor.load_mm_data">load_mm_data</a></code></li>
<li><code><a title="sglang.srt.multimodal.processors.base_processor.BaseMultimodalProcessor.process_and_combine_mm_data" href="base_processor.html#sglang.srt.multimodal.processors.base_processor.BaseMultimodalProcessor.process_and_combine_mm_data">process_and_combine_mm_data</a></code></li>
<li><code><a title="sglang.srt.multimodal.processors.base_processor.BaseMultimodalProcessor.process_mm_data" href="base_processor.html#sglang.srt.multimodal.processors.base_processor.BaseMultimodalProcessor.process_mm_data">process_mm_data</a></code></li>
<li><code><a title="sglang.srt.multimodal.processors.base_processor.BaseMultimodalProcessor.submit_data_loading_tasks" href="base_processor.html#sglang.srt.multimodal.processors.base_processor.BaseMultimodalProcessor.submit_data_loading_tasks">submit_data_loading_tasks</a></code></li>
</ul>
</li>
</ul>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="sglang.srt.multimodal.processors" href="index.html">sglang.srt.multimodal.processors</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="sglang.srt.multimodal.processors.llava.LlavaImageProcessor" href="#sglang.srt.multimodal.processors.llava.LlavaImageProcessor">LlavaImageProcessor</a></code></h4>
<ul class="">
<li><code><a title="sglang.srt.multimodal.processors.llava.LlavaImageProcessor.models" href="#sglang.srt.multimodal.processors.llava.LlavaImageProcessor.models">models</a></code></li>
<li><code><a title="sglang.srt.multimodal.processors.llava.LlavaImageProcessor.process_mm_data_async" href="#sglang.srt.multimodal.processors.llava.LlavaImageProcessor.process_mm_data_async">process_mm_data_async</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="sglang.srt.multimodal.processors.llava.LlavaMultimodalProcessor" href="#sglang.srt.multimodal.processors.llava.LlavaMultimodalProcessor">LlavaMultimodalProcessor</a></code></h4>
<ul class="">
<li><code><a title="sglang.srt.multimodal.processors.llava.LlavaMultimodalProcessor.models" href="#sglang.srt.multimodal.processors.llava.LlavaMultimodalProcessor.models">models</a></code></li>
<li><code><a title="sglang.srt.multimodal.processors.llava.LlavaMultimodalProcessor.process_mm_data_async" href="#sglang.srt.multimodal.processors.llava.LlavaMultimodalProcessor.process_mm_data_async">process_mm_data_async</a></code></li>
</ul>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc" title="pdoc: Python API documentation generator"><cite>pdoc</cite> 0.11.6</a>.</p>
</footer>
</body>
</html>
