<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1">
<meta name="generator" content="pdoc3 0.11.6">
<title>sglang.srt.layers.moe.ep_moe.layer API documentation</title>
<meta name="description" content="">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/13.0.0/sanitize.min.css" integrity="sha512-y1dtMcuvtTMJc1yPgEqF0ZjQbhnc/bFhyvIyVNb9Zk5mIGtqVaAB1Ttl28su8AvFMOY0EwRbAe+HCLqj6W7/KA==" crossorigin>
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/13.0.0/typography.min.css" integrity="sha512-Y1DYSb995BAfxobCkKepB1BqJJTPrOp3zPL74AWFugHHmmdcvO+C48WLrUOlhGMc0QG7AE3f7gmvvcrmX2fDoA==" crossorigin>
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/styles/default.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:1.5em;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:2em 0 .50em 0}h3{font-size:1.4em;margin:1.6em 0 .7em 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .2s ease-in-out}a:visited{color:#503}a:hover{color:#b62}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900;font-weight:bold}pre code{font-size:.8em;line-height:1.4em;padding:1em;display:block}code{background:#f3f3f3;font-family:"DejaVu Sans Mono",monospace;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source > summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible;min-width:max-content}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em 1em;margin:1em 0}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul ul{padding-left:1em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/highlight.min.js" integrity="sha512-D9gUyxqja7hBtkWpPWGt9wfbfaMGVt9gnyCvYa+jojwwPHLCzUm5i8rpk7vD7wNee9bA35eYIjobYPaQuKS1MQ==" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => {
hljs.configure({languages: ['bash', 'css', 'diff', 'graphql', 'ini', 'javascript', 'json', 'plaintext', 'python', 'python-repl', 'rust', 'shell', 'sql', 'typescript', 'xml', 'yaml']});
hljs.highlightAll();
/* Collapse source docstrings */
setTimeout(() => {
[...document.querySelectorAll('.hljs.language-python > .hljs-string')]
.filter(el => el.innerHTML.length > 200 && ['"""', "'''"].includes(el.innerHTML.substring(0, 3)))
.forEach(el => {
let d = document.createElement('details');
d.classList.add('hljs-string');
d.innerHTML = '<summary>"""</summary>' + el.innerHTML.substring(3);
el.replaceWith(d);
});
}, 100);
})</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>sglang.srt.layers.moe.ep_moe.layer</code></h1>
</header>
<section id="section-intro">
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-functions">Functions</h2>
<dl>
<dt id="sglang.srt.layers.moe.ep_moe.layer.get_moe_impl_class"><code class="name flex">
<span>def <span class="ident">get_moe_impl_class</span></span>(<span>quant_config: Optional[QuantizationConfig] = None)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_moe_impl_class(quant_config: Optional[QuantizationConfig] = None):
    if get_moe_a2a_backend().is_deepep():
        return DeepEPMoE

    # NEW: Direct FP4 detection (bypasses EP requirements)
    # Check for FP4 quantization with TRTLLM flag, regardless of EP
    if get_moe_runner_backend().is_flashinfer_trtllm():
        # FlashInferFP4MoE must be paired with ModelOptNvFp4FusedMoEMethod.
        # If UnquantizedFusedMoEMethod is detected, fall back to FusedMoE instead.
        if quant_config is None:
            return FusedMoE
        try:
            # Check the quantization argument directly
            quantization = global_server_args_dict.get(&#34;quantization&#34;)
            if quantization == &#34;modelopt_fp4&#34;:
                from sglang.srt.layers.moe.fused_moe_triton.layer import (
                    FlashInferFP4MoE,
                )

                return FlashInferFP4MoE
        except:
            pass

    if should_use_flashinfer_trtllm_moe():
        return FlashInferFusedMoE
    if get_moe_runner_backend().is_flashinfer_cutlass():
        return FusedMoE
    if get_moe_expert_parallel_world_size() &gt; 1:
        return EPMoE
    return FusedMoE</code></pre>
</details>
<div class="desc"></div>
</dd>
</dl>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="sglang.srt.layers.moe.ep_moe.layer.DeepEPMoE"><code class="flex name class">
<span>class <span class="ident">DeepEPMoE</span></span>
<span>(</span><span>num_experts: int,<br>top_k: int,<br>hidden_size: int,<br>intermediate_size: int,<br>layer_id: int,<br>num_fused_shared_experts: int = 0,<br>params_dtype: Optional[torch.dtype] = None,<br>quant_config: Optional[QuantizationConfig] = None,<br>prefix: str = '',<br>activation: str = 'silu',<br>routed_scaling_factor: Optional[float] = None)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class DeepEPMoE(EPMoE):
    &#34;&#34;&#34;
    MoE Expert Parallel Impl based on DeepEP (https://github.com/deepseek-ai/DeepEP/tree/main)
    &#34;&#34;&#34;

    _has_printed = False

    def __init__(
        self,
        num_experts: int,
        top_k: int,
        hidden_size: int,
        intermediate_size: int,
        layer_id: int,
        num_fused_shared_experts: int = 0,
        params_dtype: Optional[torch.dtype] = None,
        quant_config: Optional[QuantizationConfig] = None,
        prefix: str = &#34;&#34;,
        activation: str = &#34;silu&#34;,
        routed_scaling_factor: Optional[float] = None,
    ):
        super().__init__(
            num_experts=num_experts,
            top_k=top_k,
            hidden_size=hidden_size,
            intermediate_size=intermediate_size,
            layer_id=layer_id,
            num_fused_shared_experts=num_fused_shared_experts,
            params_dtype=params_dtype,
            quant_config=quant_config,
            prefix=prefix,
            activation=activation,
            routed_scaling_factor=routed_scaling_factor,
        )
        self.deepep_mode = get_deepep_mode()

        # TODO: move to the beginning of the file
        from sglang.srt.distributed.parallel_state import get_tp_group
        from sglang.srt.two_batch_overlap import MaybeTboDeepEPDispatcher

        self.deepep_dispatcher = MaybeTboDeepEPDispatcher(
            group=get_tp_group().device_group,
            router_topk=self.top_k,
            permute_fusion=True,
            num_experts=self.num_experts,
            num_local_experts=self.num_local_experts,
            hidden_size=hidden_size,
            params_dtype=params_dtype,
            deepep_mode=self.deepep_mode,
            async_finish=True,  # TODO
            return_recv_hook=True,
        )

        if self.deepep_mode.enable_low_latency() and not _is_npu:
            # NPU supports low_latency deepep without deepgemm
            assert (
                deep_gemm_wrapper.ENABLE_JIT_DEEPGEMM
            ), f&#34;DeepEP {self.deepep_mode} mode requires deep_gemm&#34;
        if _use_aiter:
            # expert_mask is of size (self.num_local_experts + 1),
            # the extra 1 is for invalid rank_id (in original deepep, the invalid rank_id is -1, but aiter does not allow -1, we use a mask to make those ids invalid)
            # for instance, if we have 4 experts on this rank, we would have a expert_mask like:
            #     self.expert_mask = [1, 1, 1, 1, 0]
            # idx from 0-3 is valid and will be processed, while idx == 4 will be masked out
            self.expert_mask = torch.zeros(
                (self.num_local_experts + 1),
                device=torch.cuda.current_device(),
                dtype=torch.int,
            )
            # the last one is invalid rank_id
            self.expert_mask[:-1] = 1
        elif not _is_npu:
            self.w13_weight_fp8 = (
                self.w13_weight,
                (
                    self.w13_weight_scale_inv
                    if self.use_block_quant
                    else self.w13_weight_scale
                ),
            )
            self.w2_weight_fp8 = (
                self.w2_weight,
                (
                    self.w2_weight_scale_inv
                    if self.use_block_quant
                    else self.w2_weight_scale
                ),
            )

    def forward(
        self,
        hidden_states: torch.Tensor,
        topk_idx: torch.Tensor,
        topk_weights: torch.Tensor,
        forward_batch: ForwardBatch,
    ):
        dispatch_output = self.dispatch(
            hidden_states, topk_idx, topk_weights, forward_batch
        )
        hidden_states = self.moe_impl(dispatch_output)
        hidden_states = self.combine(
            hidden_states,
            dispatch_output.topk_idx,
            dispatch_output.topk_weights,
            forward_batch,
        )
        return hidden_states

    def dispatch(
        self,
        hidden_states: torch.Tensor,
        topk_idx: torch.Tensor,
        topk_weights: torch.Tensor,
        forward_batch: ForwardBatch,
    ):
        return self.deepep_dispatcher.dispatch(
            hidden_states=hidden_states,
            topk_idx=topk_idx,
            topk_weights=topk_weights,
            forward_batch=forward_batch,
        )

    def moe_impl(self, dispatch_output: DispatchOutput):
        from sglang.srt.layers.moe.token_dispatcher import DispatchOutputChecker

        if _use_aiter:
            assert DispatchOutputChecker.format_is_deepep(dispatch_output)
            # in forward_aiter, we skip token permutation and unpermutation, which have been fused inside aiter kernel
            return self.forward_aiter(dispatch_output)
        if _is_npu:
            assert DispatchOutputChecker.format_is_ascent_ll(dispatch_output)
            return self.forward_npu(dispatch_output)
        if DispatchOutputChecker.format_is_deepep_normal(dispatch_output):
            assert deep_gemm_wrapper.ENABLE_JIT_DEEPGEMM and self.use_fp8_w8a8
            return self.forward_deepgemm_contiguous(dispatch_output)
        elif DispatchOutputChecker.format_is_deepep_ll(dispatch_output):
            assert deep_gemm_wrapper.ENABLE_JIT_DEEPGEMM and self.use_fp8_w8a8
            return self.forward_deepgemm_masked(dispatch_output)
        else:
            raise ValueError(
                f&#34;Dispatch output format {dispatch_output.format} is not supported&#34;
            )

    def combine(
        self,
        hidden_states: torch.Tensor,
        topk_idx: torch.Tensor,
        topk_weights: torch.Tensor,
        forward_batch: ForwardBatch,
    ):
        return self.deepep_dispatcher.combine(
            hidden_states=hidden_states,
            topk_idx=topk_idx,
            topk_weights=topk_weights,
            forward_batch=forward_batch,
        )

    def forward_aiter(
        self,
        dispatch_output: Union[DeepEPNormalOutput, DeepEPLLOutput],
    ):
        hidden_states, topk_idx, topk_weights = (
            dispatch_output.hidden_states,
            dispatch_output.topk_idx,
            dispatch_output.topk_weights,
        )
        if hidden_states.shape[0] == 0:
            return hidden_states
        # in original deepep, idx == -1 meaning invalid and will not be processed.
        # aiter does not accept -1, we use a expert mask to make these idx invalid
        # (idx == num_local_experts) meaning not used in aiter fused_moe
        topk_idx_copy = topk_idx.to(torch.int32)
        topk_idx_copy[topk_idx_copy == -1] = self.num_local_experts

        return fused_moe(
            hidden_states,
            self.w13_weight,
            self.w2_weight,
            topk_weights,
            topk_idx_copy,
            w1_scale=self.w13_weight_scale_inv,
            w2_scale=self.w2_weight_scale_inv,
            quant_type=QuantType.per_128x128,
            activation=(
                ActivationType.Silu
                if self.moe_runner_config.activation == &#34;silu&#34;
                else ActivationType.Gelu
            ),
            expert_mask=self.expert_mask,
        )

    def forward_deepgemm_contiguous(
        self,
        dispatch_output: DeepEPNormalOutput,
    ):
        hidden_states_fp8, topk_idx, topk_weights, num_recv_tokens_per_expert = (
            dispatch_output
        )
        hidden_states_fp8, hidden_states_scale = hidden_states_fp8
        assert self.quant_method is not None
        assert self.moe_runner_config.activation == &#34;silu&#34;
        if num_recv_tokens_per_expert is None:
            return hidden_states_fp8.bfloat16()
        all_tokens = sum(num_recv_tokens_per_expert)
        if all_tokens &lt;= 0:
            return hidden_states_fp8.bfloat16()
        M, K = hidden_states_fp8.size()
        N = self.w13_weight.size(1)
        scale_block_size = 128

        hidden_states_fp8_shape = hidden_states_fp8.shape
        hidden_states_fp8_device = hidden_states_fp8.device
        hidden_states_fp8_dtype = hidden_states_fp8.dtype

        input_tensor = [
            torch.empty(
                (all_tokens, K),
                device=hidden_states_fp8.device,
                dtype=hidden_states_fp8.dtype,
            ),
            (
                # TODO check whether need `zeros`
                torch.zeros(
                    (ceil_div(K // 128, 4), all_tokens),
                    device=hidden_states_fp8.device,
                    dtype=torch.int,
                ).transpose(0, 1)
                if deep_gemm_wrapper.DEEPGEMM_SCALE_UE8M0
                else torch.empty(
                    (all_tokens, K // 128),
                    device=hidden_states_fp8.device,
                    dtype=torch.float32,
                )
            ),
        ]
        m_indices = torch.empty(
            all_tokens, device=hidden_states_fp8.device, dtype=torch.int32
        )
        output_index = torch.empty_like(topk_idx)

        num_recv_tokens_per_expert_gpu = torch.tensor(
            num_recv_tokens_per_expert,
            dtype=torch.int32,
            pin_memory=True,
            device=&#34;cpu&#34;,
        ).cuda(non_blocking=True)
        expert_start_loc = torch.empty_like(num_recv_tokens_per_expert_gpu)

        ep_scatter(
            hidden_states_fp8,
            hidden_states_scale,
            topk_idx,
            num_recv_tokens_per_expert_gpu,
            expert_start_loc,
            input_tensor[0],
            input_tensor[1],
            m_indices,
            output_index,
            scale_ue8m0=deep_gemm_wrapper.DEEPGEMM_SCALE_UE8M0,
        )
        dispose_tensor(hidden_states_fp8)

        gateup_output = torch.empty(
            (all_tokens, N),
            device=hidden_states_fp8_device,
            dtype=torch.bfloat16,
        )
        if not deep_gemm_wrapper.DEEPGEMM_SCALE_UE8M0:
            input_tensor[1] = tma_align_input_scale(input_tensor[1])
        deep_gemm_wrapper.grouped_gemm_nt_f8f8bf16_contig(
            input_tensor, self.w13_weight_fp8, gateup_output, m_indices
        )
        del input_tensor
        down_input = torch.empty(
            (
                all_tokens,
                N // 2,
            ),
            device=gateup_output.device,
            dtype=torch.bfloat16,
        )
        silu_and_mul(gateup_output.view(-1, N), down_input)
        del gateup_output
        down_output = torch.empty(
            (all_tokens, K),
            device=hidden_states_fp8_device,
            dtype=torch.bfloat16,
        )
        down_input_fp8, down_input_scale = sglang_per_token_group_quant_fp8(
            down_input,
            scale_block_size,
            column_major_scales=deep_gemm_wrapper.DEEPGEMM_SCALE_UE8M0,
            scale_tma_aligned=deep_gemm_wrapper.DEEPGEMM_SCALE_UE8M0,
            scale_ue8m0=deep_gemm_wrapper.DEEPGEMM_SCALE_UE8M0,
        )
        del down_input
        if not deep_gemm_wrapper.DEEPGEMM_SCALE_UE8M0:
            down_input_scale = tma_align_input_scale(down_input_scale)
        deep_gemm_wrapper.grouped_gemm_nt_f8f8bf16_contig(
            (down_input_fp8, down_input_scale),
            self.w2_weight_fp8,
            down_output,
            m_indices,
        )
        del down_input_fp8, down_input_scale

        gather_out = torch.empty(
            hidden_states_fp8_shape,
            device=hidden_states_fp8_device,
            dtype=torch.bfloat16,
        )
        ep_gather(down_output, topk_idx, topk_weights, output_index, gather_out)

        return gather_out

    def forward_deepgemm_masked(
        self,
        dispatch_output: DeepEPLLOutput,
    ):
        hidden_states_fp8, _, _, masked_m, expected_m = dispatch_output
        assert self.quant_method is not None
        assert self.moe_runner_config.activation == &#34;silu&#34;

        # GroupGemm-0
        num_groups, m, k = hidden_states_fp8[0].size()
        n = self.w13_weight.size(1)
        expected_m = min(expected_m, m)
        gateup_output = torch.empty(
            (num_groups, m, n), device=hidden_states_fp8[0].device, dtype=torch.bfloat16
        )
        deep_gemm_wrapper.grouped_gemm_nt_f8f8bf16_masked(
            hidden_states_fp8,
            self.w13_weight_fp8,
            gateup_output,
            masked_m,
            expected_m,
        )
        dispose_tensor(hidden_states_fp8[0])

        # Act
        down_input = torch.empty(
            (
                gateup_output.shape[0],
                gateup_output.shape[1],
                gateup_output.shape[2] // 2,
            ),
            device=gateup_output.device,
            dtype=self.fp8_dtype,
        )
        scale_block_size = 128
        down_input_scale = torch.empty(
            (
                gateup_output.shape[0],
                gateup_output.shape[1],
                gateup_output.shape[2] // 2 // scale_block_size,
            ),
            device=gateup_output.device,
            dtype=torch.float32,
        )
        silu_and_mul_masked_post_quant_fwd(
            gateup_output,
            down_input,
            down_input_scale,
            scale_block_size,
            masked_m,
            scale_ue8m0=deep_gemm_wrapper.DEEPGEMM_SCALE_UE8M0,
        )
        del gateup_output

        # GroupGemm-1
        n = self.w2_weight.size(1)
        down_input_fp8 = (
            down_input,
            (
                down_input_scale
                if deep_gemm_wrapper.DEEPGEMM_SCALE_UE8M0
                else deep_gemm_wrapper.get_mn_major_tma_aligned_tensor(down_input_scale)
            ),
        )
        down_output = torch.empty(
            (num_groups, m, n), device=down_input.device, dtype=torch.bfloat16
        )
        deep_gemm_wrapper.grouped_gemm_nt_f8f8bf16_masked(
            down_input_fp8,
            self.w2_weight_fp8,
            down_output,
            masked_m,
            expected_m,
        )

        return down_output

    def forward_npu(
        self,
        dispatch_output: DeepEPLLOutput,
    ):
        if TYPE_CHECKING:
            assert isinstance(dispatch_output, AscendDeepEPLLOutput)
        hidden_states, topk_idx, topk_weights, _, seg_indptr, _ = dispatch_output
        assert self.quant_method is not None
        assert self.moe_runner_config.activation == &#34;silu&#34;

        # NOTE: Ascend&#39;s Dispatch &amp; Combine does not support FP16
        output_dtype = torch.bfloat16

        pertoken_scale = hidden_states[1]
        hidden_states = hidden_states[0]

        group_list_type = 1
        seg_indptr = seg_indptr.to(torch.int64)

        import torch_npu

        # gmm1: gate_up_proj
        hidden_states = torch_npu.npu_grouped_matmul(
            x=[hidden_states],
            weight=[self.w13_weight],
            split_item=2,
            group_list_type=group_list_type,
            group_type=0,
            group_list=seg_indptr,
            output_dtype=torch.int32,
        )[0]

        # act_fn: swiglu
        hidden_states, swiglu_out_scale = torch_npu.npu_dequant_swiglu_quant(
            x=hidden_states,
            weight_scale=self.w13_weight_scale.to(torch.float32),
            activation_scale=pertoken_scale,
            bias=None,
            quant_scale=None,
            quant_offset=None,
            group_index=seg_indptr,
            activate_left=True,
            quant_mode=1,
        )

        # gmm2: down_proj
        hidden_states = torch_npu.npu_grouped_matmul(
            x=[hidden_states],
            weight=[self.w2_weight],
            scale=[self.w2_weight_scale.to(output_dtype)],
            per_token_scale=[swiglu_out_scale],
            split_item=2,
            group_list_type=group_list_type,
            group_type=0,
            group_list=seg_indptr,
            output_dtype=output_dtype,
        )[0]

        return hidden_states</code></pre>
</details>
<div class="desc"><p>MoE Expert Parallel Impl based on DeepEP (<a href="https://github.com/deepseek-ai/DeepEP/tree/main">https://github.com/deepseek-ai/DeepEP/tree/main</a>)</p>
<p>Initialize internal Module state, shared by both nn.Module and ScriptModule.</p></div>
<h3>Ancestors</h3>
<ul class="hlist">
<li><a title="sglang.srt.layers.moe.ep_moe.layer.EPMoE" href="#sglang.srt.layers.moe.ep_moe.layer.EPMoE">EPMoE</a></li>
<li><a title="sglang.srt.layers.moe.fused_moe_triton.layer.FusedMoE" href="../fused_moe_triton/layer.html#sglang.srt.layers.moe.fused_moe_triton.layer.FusedMoE">FusedMoE</a></li>
<li>torch.nn.modules.module.Module</li>
</ul>
<h3>Methods</h3>
<dl>
<dt id="sglang.srt.layers.moe.ep_moe.layer.DeepEPMoE.combine"><code class="name flex">
<span>def <span class="ident">combine</span></span>(<span>self,<br>hidden_states: torch.Tensor,<br>topk_idx: torch.Tensor,<br>topk_weights: torch.Tensor,<br>forward_batch: ForwardBatch)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def combine(
    self,
    hidden_states: torch.Tensor,
    topk_idx: torch.Tensor,
    topk_weights: torch.Tensor,
    forward_batch: ForwardBatch,
):
    return self.deepep_dispatcher.combine(
        hidden_states=hidden_states,
        topk_idx=topk_idx,
        topk_weights=topk_weights,
        forward_batch=forward_batch,
    )</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="sglang.srt.layers.moe.ep_moe.layer.DeepEPMoE.dispatch"><code class="name flex">
<span>def <span class="ident">dispatch</span></span>(<span>self,<br>hidden_states: torch.Tensor,<br>topk_idx: torch.Tensor,<br>topk_weights: torch.Tensor,<br>forward_batch: ForwardBatch)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def dispatch(
    self,
    hidden_states: torch.Tensor,
    topk_idx: torch.Tensor,
    topk_weights: torch.Tensor,
    forward_batch: ForwardBatch,
):
    return self.deepep_dispatcher.dispatch(
        hidden_states=hidden_states,
        topk_idx=topk_idx,
        topk_weights=topk_weights,
        forward_batch=forward_batch,
    )</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="sglang.srt.layers.moe.ep_moe.layer.DeepEPMoE.forward_aiter"><code class="name flex">
<span>def <span class="ident">forward_aiter</span></span>(<span>self, dispatch_output: Union[DeepEPNormalOutput, DeepEPLLOutput])</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def forward_aiter(
    self,
    dispatch_output: Union[DeepEPNormalOutput, DeepEPLLOutput],
):
    hidden_states, topk_idx, topk_weights = (
        dispatch_output.hidden_states,
        dispatch_output.topk_idx,
        dispatch_output.topk_weights,
    )
    if hidden_states.shape[0] == 0:
        return hidden_states
    # in original deepep, idx == -1 meaning invalid and will not be processed.
    # aiter does not accept -1, we use a expert mask to make these idx invalid
    # (idx == num_local_experts) meaning not used in aiter fused_moe
    topk_idx_copy = topk_idx.to(torch.int32)
    topk_idx_copy[topk_idx_copy == -1] = self.num_local_experts

    return fused_moe(
        hidden_states,
        self.w13_weight,
        self.w2_weight,
        topk_weights,
        topk_idx_copy,
        w1_scale=self.w13_weight_scale_inv,
        w2_scale=self.w2_weight_scale_inv,
        quant_type=QuantType.per_128x128,
        activation=(
            ActivationType.Silu
            if self.moe_runner_config.activation == &#34;silu&#34;
            else ActivationType.Gelu
        ),
        expert_mask=self.expert_mask,
    )</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="sglang.srt.layers.moe.ep_moe.layer.DeepEPMoE.forward_deepgemm_contiguous"><code class="name flex">
<span>def <span class="ident">forward_deepgemm_contiguous</span></span>(<span>self, dispatch_output: DeepEPNormalOutput)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def forward_deepgemm_contiguous(
    self,
    dispatch_output: DeepEPNormalOutput,
):
    hidden_states_fp8, topk_idx, topk_weights, num_recv_tokens_per_expert = (
        dispatch_output
    )
    hidden_states_fp8, hidden_states_scale = hidden_states_fp8
    assert self.quant_method is not None
    assert self.moe_runner_config.activation == &#34;silu&#34;
    if num_recv_tokens_per_expert is None:
        return hidden_states_fp8.bfloat16()
    all_tokens = sum(num_recv_tokens_per_expert)
    if all_tokens &lt;= 0:
        return hidden_states_fp8.bfloat16()
    M, K = hidden_states_fp8.size()
    N = self.w13_weight.size(1)
    scale_block_size = 128

    hidden_states_fp8_shape = hidden_states_fp8.shape
    hidden_states_fp8_device = hidden_states_fp8.device
    hidden_states_fp8_dtype = hidden_states_fp8.dtype

    input_tensor = [
        torch.empty(
            (all_tokens, K),
            device=hidden_states_fp8.device,
            dtype=hidden_states_fp8.dtype,
        ),
        (
            # TODO check whether need `zeros`
            torch.zeros(
                (ceil_div(K // 128, 4), all_tokens),
                device=hidden_states_fp8.device,
                dtype=torch.int,
            ).transpose(0, 1)
            if deep_gemm_wrapper.DEEPGEMM_SCALE_UE8M0
            else torch.empty(
                (all_tokens, K // 128),
                device=hidden_states_fp8.device,
                dtype=torch.float32,
            )
        ),
    ]
    m_indices = torch.empty(
        all_tokens, device=hidden_states_fp8.device, dtype=torch.int32
    )
    output_index = torch.empty_like(topk_idx)

    num_recv_tokens_per_expert_gpu = torch.tensor(
        num_recv_tokens_per_expert,
        dtype=torch.int32,
        pin_memory=True,
        device=&#34;cpu&#34;,
    ).cuda(non_blocking=True)
    expert_start_loc = torch.empty_like(num_recv_tokens_per_expert_gpu)

    ep_scatter(
        hidden_states_fp8,
        hidden_states_scale,
        topk_idx,
        num_recv_tokens_per_expert_gpu,
        expert_start_loc,
        input_tensor[0],
        input_tensor[1],
        m_indices,
        output_index,
        scale_ue8m0=deep_gemm_wrapper.DEEPGEMM_SCALE_UE8M0,
    )
    dispose_tensor(hidden_states_fp8)

    gateup_output = torch.empty(
        (all_tokens, N),
        device=hidden_states_fp8_device,
        dtype=torch.bfloat16,
    )
    if not deep_gemm_wrapper.DEEPGEMM_SCALE_UE8M0:
        input_tensor[1] = tma_align_input_scale(input_tensor[1])
    deep_gemm_wrapper.grouped_gemm_nt_f8f8bf16_contig(
        input_tensor, self.w13_weight_fp8, gateup_output, m_indices
    )
    del input_tensor
    down_input = torch.empty(
        (
            all_tokens,
            N // 2,
        ),
        device=gateup_output.device,
        dtype=torch.bfloat16,
    )
    silu_and_mul(gateup_output.view(-1, N), down_input)
    del gateup_output
    down_output = torch.empty(
        (all_tokens, K),
        device=hidden_states_fp8_device,
        dtype=torch.bfloat16,
    )
    down_input_fp8, down_input_scale = sglang_per_token_group_quant_fp8(
        down_input,
        scale_block_size,
        column_major_scales=deep_gemm_wrapper.DEEPGEMM_SCALE_UE8M0,
        scale_tma_aligned=deep_gemm_wrapper.DEEPGEMM_SCALE_UE8M0,
        scale_ue8m0=deep_gemm_wrapper.DEEPGEMM_SCALE_UE8M0,
    )
    del down_input
    if not deep_gemm_wrapper.DEEPGEMM_SCALE_UE8M0:
        down_input_scale = tma_align_input_scale(down_input_scale)
    deep_gemm_wrapper.grouped_gemm_nt_f8f8bf16_contig(
        (down_input_fp8, down_input_scale),
        self.w2_weight_fp8,
        down_output,
        m_indices,
    )
    del down_input_fp8, down_input_scale

    gather_out = torch.empty(
        hidden_states_fp8_shape,
        device=hidden_states_fp8_device,
        dtype=torch.bfloat16,
    )
    ep_gather(down_output, topk_idx, topk_weights, output_index, gather_out)

    return gather_out</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="sglang.srt.layers.moe.ep_moe.layer.DeepEPMoE.forward_deepgemm_masked"><code class="name flex">
<span>def <span class="ident">forward_deepgemm_masked</span></span>(<span>self, dispatch_output: DeepEPLLOutput)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def forward_deepgemm_masked(
    self,
    dispatch_output: DeepEPLLOutput,
):
    hidden_states_fp8, _, _, masked_m, expected_m = dispatch_output
    assert self.quant_method is not None
    assert self.moe_runner_config.activation == &#34;silu&#34;

    # GroupGemm-0
    num_groups, m, k = hidden_states_fp8[0].size()
    n = self.w13_weight.size(1)
    expected_m = min(expected_m, m)
    gateup_output = torch.empty(
        (num_groups, m, n), device=hidden_states_fp8[0].device, dtype=torch.bfloat16
    )
    deep_gemm_wrapper.grouped_gemm_nt_f8f8bf16_masked(
        hidden_states_fp8,
        self.w13_weight_fp8,
        gateup_output,
        masked_m,
        expected_m,
    )
    dispose_tensor(hidden_states_fp8[0])

    # Act
    down_input = torch.empty(
        (
            gateup_output.shape[0],
            gateup_output.shape[1],
            gateup_output.shape[2] // 2,
        ),
        device=gateup_output.device,
        dtype=self.fp8_dtype,
    )
    scale_block_size = 128
    down_input_scale = torch.empty(
        (
            gateup_output.shape[0],
            gateup_output.shape[1],
            gateup_output.shape[2] // 2 // scale_block_size,
        ),
        device=gateup_output.device,
        dtype=torch.float32,
    )
    silu_and_mul_masked_post_quant_fwd(
        gateup_output,
        down_input,
        down_input_scale,
        scale_block_size,
        masked_m,
        scale_ue8m0=deep_gemm_wrapper.DEEPGEMM_SCALE_UE8M0,
    )
    del gateup_output

    # GroupGemm-1
    n = self.w2_weight.size(1)
    down_input_fp8 = (
        down_input,
        (
            down_input_scale
            if deep_gemm_wrapper.DEEPGEMM_SCALE_UE8M0
            else deep_gemm_wrapper.get_mn_major_tma_aligned_tensor(down_input_scale)
        ),
    )
    down_output = torch.empty(
        (num_groups, m, n), device=down_input.device, dtype=torch.bfloat16
    )
    deep_gemm_wrapper.grouped_gemm_nt_f8f8bf16_masked(
        down_input_fp8,
        self.w2_weight_fp8,
        down_output,
        masked_m,
        expected_m,
    )

    return down_output</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="sglang.srt.layers.moe.ep_moe.layer.DeepEPMoE.forward_npu"><code class="name flex">
<span>def <span class="ident">forward_npu</span></span>(<span>self, dispatch_output: DeepEPLLOutput)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def forward_npu(
    self,
    dispatch_output: DeepEPLLOutput,
):
    if TYPE_CHECKING:
        assert isinstance(dispatch_output, AscendDeepEPLLOutput)
    hidden_states, topk_idx, topk_weights, _, seg_indptr, _ = dispatch_output
    assert self.quant_method is not None
    assert self.moe_runner_config.activation == &#34;silu&#34;

    # NOTE: Ascend&#39;s Dispatch &amp; Combine does not support FP16
    output_dtype = torch.bfloat16

    pertoken_scale = hidden_states[1]
    hidden_states = hidden_states[0]

    group_list_type = 1
    seg_indptr = seg_indptr.to(torch.int64)

    import torch_npu

    # gmm1: gate_up_proj
    hidden_states = torch_npu.npu_grouped_matmul(
        x=[hidden_states],
        weight=[self.w13_weight],
        split_item=2,
        group_list_type=group_list_type,
        group_type=0,
        group_list=seg_indptr,
        output_dtype=torch.int32,
    )[0]

    # act_fn: swiglu
    hidden_states, swiglu_out_scale = torch_npu.npu_dequant_swiglu_quant(
        x=hidden_states,
        weight_scale=self.w13_weight_scale.to(torch.float32),
        activation_scale=pertoken_scale,
        bias=None,
        quant_scale=None,
        quant_offset=None,
        group_index=seg_indptr,
        activate_left=True,
        quant_mode=1,
    )

    # gmm2: down_proj
    hidden_states = torch_npu.npu_grouped_matmul(
        x=[hidden_states],
        weight=[self.w2_weight],
        scale=[self.w2_weight_scale.to(output_dtype)],
        per_token_scale=[swiglu_out_scale],
        split_item=2,
        group_list_type=group_list_type,
        group_type=0,
        group_list=seg_indptr,
        output_dtype=output_dtype,
    )[0]

    return hidden_states</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="sglang.srt.layers.moe.ep_moe.layer.DeepEPMoE.moe_impl"><code class="name flex">
<span>def <span class="ident">moe_impl</span></span>(<span>self, dispatch_output: DispatchOutput)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def moe_impl(self, dispatch_output: DispatchOutput):
    from sglang.srt.layers.moe.token_dispatcher import DispatchOutputChecker

    if _use_aiter:
        assert DispatchOutputChecker.format_is_deepep(dispatch_output)
        # in forward_aiter, we skip token permutation and unpermutation, which have been fused inside aiter kernel
        return self.forward_aiter(dispatch_output)
    if _is_npu:
        assert DispatchOutputChecker.format_is_ascent_ll(dispatch_output)
        return self.forward_npu(dispatch_output)
    if DispatchOutputChecker.format_is_deepep_normal(dispatch_output):
        assert deep_gemm_wrapper.ENABLE_JIT_DEEPGEMM and self.use_fp8_w8a8
        return self.forward_deepgemm_contiguous(dispatch_output)
    elif DispatchOutputChecker.format_is_deepep_ll(dispatch_output):
        assert deep_gemm_wrapper.ENABLE_JIT_DEEPGEMM and self.use_fp8_w8a8
        return self.forward_deepgemm_masked(dispatch_output)
    else:
        raise ValueError(
            f&#34;Dispatch output format {dispatch_output.format} is not supported&#34;
        )</code></pre>
</details>
<div class="desc"></div>
</dd>
</dl>
<h3>Inherited members</h3>
<ul class="hlist">
<li><code><b><a title="sglang.srt.layers.moe.ep_moe.layer.EPMoE" href="#sglang.srt.layers.moe.ep_moe.layer.EPMoE">EPMoE</a></b></code>:
<ul class="hlist">
<li><code><a title="sglang.srt.layers.moe.ep_moe.layer.EPMoE.forward" href="../fused_moe_triton/layer.html#sglang.srt.layers.moe.fused_moe_triton.layer.FusedMoE.forward">forward</a></code></li>
</ul>
</li>
</ul>
</dd>
<dt id="sglang.srt.layers.moe.ep_moe.layer.EPMoE"><code class="flex name class">
<span>class <span class="ident">EPMoE</span></span>
<span>(</span><span>num_experts: int,<br>top_k: int,<br>hidden_size: int,<br>intermediate_size: int,<br>layer_id: int,<br>num_fused_shared_experts: int = 0,<br>params_dtype: Optional[torch.dtype] = None,<br>quant_config: Optional[QuantizationConfig] = None,<br>prefix: str = '',<br>activation: str = 'silu',<br>routed_scaling_factor: Optional[float] = None,<br>gemm1_alpha: Optional[float] = None,<br>gemm1_clamp_limit: Optional[float] = None,<br>with_bias: bool = False)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class EPMoE(FusedMoE):
    &#34;&#34;&#34;
    MoE Expert Parallel Impl


    &#34;&#34;&#34;

    def __init__(
        self,
        num_experts: int,
        top_k: int,
        hidden_size: int,
        intermediate_size: int,
        layer_id: int,
        num_fused_shared_experts: int = 0,
        params_dtype: Optional[torch.dtype] = None,
        quant_config: Optional[QuantizationConfig] = None,
        prefix: str = &#34;&#34;,
        activation: str = &#34;silu&#34;,
        routed_scaling_factor: Optional[float] = None,
        gemm1_alpha: Optional[float] = None,
        gemm1_clamp_limit: Optional[float] = None,
        with_bias: bool = False,
    ):
        super().__init__(
            num_experts=num_experts,
            hidden_size=hidden_size,
            intermediate_size=intermediate_size,
            num_fused_shared_experts=num_fused_shared_experts,
            layer_id=layer_id,
            top_k=top_k,
            params_dtype=params_dtype,
            quant_config=quant_config,
            prefix=prefix,
            activation=activation,
            # apply_router_weight_on_input=apply_router_weight_on_input,
            routed_scaling_factor=routed_scaling_factor,
            gemm1_alpha=gemm1_alpha,
            gemm1_clamp_limit=gemm1_clamp_limit,
            with_bias=with_bias,
        )

        self.start_expert_id = self.moe_ep_rank * self.num_local_experts
        self.end_expert_id = self.start_expert_id + self.num_local_experts - 1

        self.intermediate_size = intermediate_size

        if isinstance(quant_config, Fp8Config):
            self.use_block_quant = getattr(self.quant_method, &#34;block_quant&#34;, False)
            self.block_shape = (
                self.quant_method.quant_config.weight_block_size
                if self.use_block_quant
                else None
            )
            self.use_fp8_w8a8 = True
            self.fp8_dtype = torch.float8_e4m3fn
            self.activation_scheme = quant_config.activation_scheme
        else:
            self.use_fp8_w8a8 = False
            self.use_block_quant = False
            self.block_shape = None
            self.activation_scheme = None

    def forward(self, hidden_states: torch.Tensor, topk_output: TopKOutput):
        if deep_gemm_wrapper.ENABLE_JIT_DEEPGEMM and self.use_fp8_w8a8:
            return self.forward_deepgemm(hidden_states, topk_output)
        else:
            return super().forward(hidden_states, topk_output)

    def forward_deepgemm(
        self,
        hidden_states: torch.Tensor,
        topk_output: TopKOutput,
    ):

        self.w13_weight_fp8 = (
            self.w13_weight,
            (
                self.w13_weight_scale_inv
                if self.use_block_quant
                else self.w13_weight_scale
            ),
        )
        self.w2_weight_fp8 = (
            self.w2_weight,
            self.w2_weight_scale_inv if self.use_block_quant else self.w2_weight_scale,
        )

        assert self.quant_method is not None
        assert self.moe_runner_config.activation == &#34;silu&#34;

        hidden_states_shape = hidden_states.shape
        hidden_states_dtype = hidden_states.dtype
        hidden_states_device = hidden_states.device

        topk_weights, topk_ids, _ = topk_output

        if not self.use_block_quant:
            # Convert per-tensor quant to per-block quant by repeating scales for forward_deepgemm
            scale_block_size = 128
            w13_weight_scale_n = 2 * (
                (self.intermediate_size + scale_block_size - 1) // scale_block_size
            )
            w13_weight_scale_k = (
                hidden_states_shape[-1] + scale_block_size - 1
            ) // scale_block_size
            w13_weight_scale = (
                self.w13_weight_scale.unsqueeze(1)
                .repeat_interleave(w13_weight_scale_n, dim=1)
                .unsqueeze(2)
                .repeat_interleave(w13_weight_scale_k, dim=2)
            )
            self.w13_weight_fp8 = (
                self.w13_weight,
                w13_weight_scale,
            )
            w2_weight_scale_n = (
                hidden_states_shape[-1] + scale_block_size - 1
            ) // scale_block_size
            w2_weight_scale_k = (
                self.intermediate_size + scale_block_size - 1
            ) // scale_block_size
            w2_weight_scale = (
                self.w2_weight_scale.unsqueeze(1)
                .repeat_interleave(w2_weight_scale_n, dim=1)
                .unsqueeze(2)
                .repeat_interleave(w2_weight_scale_k, dim=2)
            )
            self.w2_weight_fp8 = (
                self.w2_weight,
                w2_weight_scale,
            )

        # PreReorder
        m_max, masked_m, expected_m, src2dst, gateup_input, gateup_input_scale = (
            moe_ep_deepgemm_preprocess(
                topk_ids,
                self.num_experts,
                hidden_states,
                self.top_k,
                self.start_expert_id,
                self.end_expert_id,
                self.block_shape,
            )
        )

        dispose_tensor(hidden_states)

        if deep_gemm_wrapper.DEEPGEMM_SCALE_UE8M0:
            b, s_mn, s_k = gateup_input_scale.shape
            assert (
                s_mn % 4 == 0 and s_k % 4 == 0
            ), f&#34;scales must be aligned to 4, but got ({b}, {s_mn}, {s_k})&#34;

        # GroupGemm-0
        gateup_input_fp8 = (
            gateup_input,
            (
                _cast_to_e8m0_with_rounding_up(gateup_input_scale)
                if deep_gemm_wrapper.DEEPGEMM_SCALE_UE8M0
                else deep_gemm_wrapper.get_col_major_tma_aligned_tensor(
                    gateup_input_scale
                )
            ),
        )
        num_groups, m, k = gateup_input_fp8[0].size()
        n = self.w13_weight.size(1)
        gateup_output = torch.empty(
            (num_groups, m, n), device=hidden_states_device, dtype=torch.bfloat16
        )
        deep_gemm_wrapper.grouped_gemm_nt_f8f8bf16_masked(
            gateup_input_fp8,
            self.w13_weight_fp8,
            gateup_output,
            masked_m,
            expected_m,
        )
        del gateup_input
        del gateup_input_fp8

        # Act
        down_input = torch.empty(
            (
                gateup_output.shape[0],
                gateup_output.shape[1],
                gateup_output.shape[2] // 2,
            ),
            device=hidden_states_device,
            dtype=self.fp8_dtype,
        )
        scale_block_size = 128
        down_input_scale = torch.empty(
            (
                gateup_output.shape[0],
                gateup_output.shape[1],
                gateup_output.shape[2] // 2 // scale_block_size,
            ),
            device=hidden_states_device,
            dtype=torch.float32,
        )
        silu_and_mul_masked_post_quant_fwd(
            gateup_output,
            down_input,
            down_input_scale,
            scale_block_size,
            masked_m,
            scale_ue8m0=deep_gemm_wrapper.DEEPGEMM_SCALE_UE8M0,
        )
        del gateup_output

        # GroupGemm-1
        n = self.w2_weight.size(1)
        down_input_fp8 = (
            down_input,
            (
                down_input_scale
                if deep_gemm_wrapper.DEEPGEMM_SCALE_UE8M0
                else deep_gemm_wrapper.get_col_major_tma_aligned_tensor(
                    down_input_scale
                )
            ),
        )
        down_output = torch.empty(
            (num_groups, m, n), device=hidden_states_device, dtype=torch.bfloat16
        )
        deep_gemm_wrapper.grouped_gemm_nt_f8f8bf16_masked(
            down_input_fp8,
            self.w2_weight_fp8,
            down_output,
            masked_m,
            expected_m,
        )
        del down_input
        del down_input_fp8

        # PostReorder
        output = torch.empty(
            hidden_states_shape, dtype=hidden_states_dtype, device=hidden_states_device
        )
        post_reorder_triton_kernel[(hidden_states_shape[0],)](
            down_output,
            output,
            src2dst,
            topk_ids,
            topk_weights,
            self.start_expert_id,
            self.end_expert_id,
            self.top_k,
            hidden_states_shape[1],
            m_max * self.start_expert_id,
            BLOCK_SIZE=512,
        )
        if self.moe_runner_config.routed_scaling_factor is not None:
            output *= self.moe_runner_config.routed_scaling_factor
        return output</code></pre>
</details>
<div class="desc"><p>MoE Expert Parallel Impl</p>
<p>Initialize internal Module state, shared by both nn.Module and ScriptModule.</p></div>
<h3>Ancestors</h3>
<ul class="hlist">
<li><a title="sglang.srt.layers.moe.fused_moe_triton.layer.FusedMoE" href="../fused_moe_triton/layer.html#sglang.srt.layers.moe.fused_moe_triton.layer.FusedMoE">FusedMoE</a></li>
<li>torch.nn.modules.module.Module</li>
</ul>
<h3>Subclasses</h3>
<ul class="hlist">
<li><a title="sglang.srt.layers.moe.ep_moe.layer.DeepEPMoE" href="#sglang.srt.layers.moe.ep_moe.layer.DeepEPMoE">DeepEPMoE</a></li>
</ul>
<h3>Methods</h3>
<dl>
<dt id="sglang.srt.layers.moe.ep_moe.layer.EPMoE.forward_deepgemm"><code class="name flex">
<span>def <span class="ident">forward_deepgemm</span></span>(<span>self, hidden_states: torch.Tensor, topk_output: TopKOutput)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def forward_deepgemm(
    self,
    hidden_states: torch.Tensor,
    topk_output: TopKOutput,
):

    self.w13_weight_fp8 = (
        self.w13_weight,
        (
            self.w13_weight_scale_inv
            if self.use_block_quant
            else self.w13_weight_scale
        ),
    )
    self.w2_weight_fp8 = (
        self.w2_weight,
        self.w2_weight_scale_inv if self.use_block_quant else self.w2_weight_scale,
    )

    assert self.quant_method is not None
    assert self.moe_runner_config.activation == &#34;silu&#34;

    hidden_states_shape = hidden_states.shape
    hidden_states_dtype = hidden_states.dtype
    hidden_states_device = hidden_states.device

    topk_weights, topk_ids, _ = topk_output

    if not self.use_block_quant:
        # Convert per-tensor quant to per-block quant by repeating scales for forward_deepgemm
        scale_block_size = 128
        w13_weight_scale_n = 2 * (
            (self.intermediate_size + scale_block_size - 1) // scale_block_size
        )
        w13_weight_scale_k = (
            hidden_states_shape[-1] + scale_block_size - 1
        ) // scale_block_size
        w13_weight_scale = (
            self.w13_weight_scale.unsqueeze(1)
            .repeat_interleave(w13_weight_scale_n, dim=1)
            .unsqueeze(2)
            .repeat_interleave(w13_weight_scale_k, dim=2)
        )
        self.w13_weight_fp8 = (
            self.w13_weight,
            w13_weight_scale,
        )
        w2_weight_scale_n = (
            hidden_states_shape[-1] + scale_block_size - 1
        ) // scale_block_size
        w2_weight_scale_k = (
            self.intermediate_size + scale_block_size - 1
        ) // scale_block_size
        w2_weight_scale = (
            self.w2_weight_scale.unsqueeze(1)
            .repeat_interleave(w2_weight_scale_n, dim=1)
            .unsqueeze(2)
            .repeat_interleave(w2_weight_scale_k, dim=2)
        )
        self.w2_weight_fp8 = (
            self.w2_weight,
            w2_weight_scale,
        )

    # PreReorder
    m_max, masked_m, expected_m, src2dst, gateup_input, gateup_input_scale = (
        moe_ep_deepgemm_preprocess(
            topk_ids,
            self.num_experts,
            hidden_states,
            self.top_k,
            self.start_expert_id,
            self.end_expert_id,
            self.block_shape,
        )
    )

    dispose_tensor(hidden_states)

    if deep_gemm_wrapper.DEEPGEMM_SCALE_UE8M0:
        b, s_mn, s_k = gateup_input_scale.shape
        assert (
            s_mn % 4 == 0 and s_k % 4 == 0
        ), f&#34;scales must be aligned to 4, but got ({b}, {s_mn}, {s_k})&#34;

    # GroupGemm-0
    gateup_input_fp8 = (
        gateup_input,
        (
            _cast_to_e8m0_with_rounding_up(gateup_input_scale)
            if deep_gemm_wrapper.DEEPGEMM_SCALE_UE8M0
            else deep_gemm_wrapper.get_col_major_tma_aligned_tensor(
                gateup_input_scale
            )
        ),
    )
    num_groups, m, k = gateup_input_fp8[0].size()
    n = self.w13_weight.size(1)
    gateup_output = torch.empty(
        (num_groups, m, n), device=hidden_states_device, dtype=torch.bfloat16
    )
    deep_gemm_wrapper.grouped_gemm_nt_f8f8bf16_masked(
        gateup_input_fp8,
        self.w13_weight_fp8,
        gateup_output,
        masked_m,
        expected_m,
    )
    del gateup_input
    del gateup_input_fp8

    # Act
    down_input = torch.empty(
        (
            gateup_output.shape[0],
            gateup_output.shape[1],
            gateup_output.shape[2] // 2,
        ),
        device=hidden_states_device,
        dtype=self.fp8_dtype,
    )
    scale_block_size = 128
    down_input_scale = torch.empty(
        (
            gateup_output.shape[0],
            gateup_output.shape[1],
            gateup_output.shape[2] // 2 // scale_block_size,
        ),
        device=hidden_states_device,
        dtype=torch.float32,
    )
    silu_and_mul_masked_post_quant_fwd(
        gateup_output,
        down_input,
        down_input_scale,
        scale_block_size,
        masked_m,
        scale_ue8m0=deep_gemm_wrapper.DEEPGEMM_SCALE_UE8M0,
    )
    del gateup_output

    # GroupGemm-1
    n = self.w2_weight.size(1)
    down_input_fp8 = (
        down_input,
        (
            down_input_scale
            if deep_gemm_wrapper.DEEPGEMM_SCALE_UE8M0
            else deep_gemm_wrapper.get_col_major_tma_aligned_tensor(
                down_input_scale
            )
        ),
    )
    down_output = torch.empty(
        (num_groups, m, n), device=hidden_states_device, dtype=torch.bfloat16
    )
    deep_gemm_wrapper.grouped_gemm_nt_f8f8bf16_masked(
        down_input_fp8,
        self.w2_weight_fp8,
        down_output,
        masked_m,
        expected_m,
    )
    del down_input
    del down_input_fp8

    # PostReorder
    output = torch.empty(
        hidden_states_shape, dtype=hidden_states_dtype, device=hidden_states_device
    )
    post_reorder_triton_kernel[(hidden_states_shape[0],)](
        down_output,
        output,
        src2dst,
        topk_ids,
        topk_weights,
        self.start_expert_id,
        self.end_expert_id,
        self.top_k,
        hidden_states_shape[1],
        m_max * self.start_expert_id,
        BLOCK_SIZE=512,
    )
    if self.moe_runner_config.routed_scaling_factor is not None:
        output *= self.moe_runner_config.routed_scaling_factor
    return output</code></pre>
</details>
<div class="desc"></div>
</dd>
</dl>
<h3>Inherited members</h3>
<ul class="hlist">
<li><code><b><a title="sglang.srt.layers.moe.fused_moe_triton.layer.FusedMoE" href="../fused_moe_triton/layer.html#sglang.srt.layers.moe.fused_moe_triton.layer.FusedMoE">FusedMoE</a></b></code>:
<ul class="hlist">
<li><code><a title="sglang.srt.layers.moe.fused_moe_triton.layer.FusedMoE.forward" href="../fused_moe_triton/layer.html#sglang.srt.layers.moe.fused_moe_triton.layer.FusedMoE.forward">forward</a></code></li>
</ul>
</li>
</ul>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="sglang.srt.layers.moe.ep_moe" href="index.html">sglang.srt.layers.moe.ep_moe</a></code></li>
</ul>
</li>
<li><h3><a href="#header-functions">Functions</a></h3>
<ul class="">
<li><code><a title="sglang.srt.layers.moe.ep_moe.layer.get_moe_impl_class" href="#sglang.srt.layers.moe.ep_moe.layer.get_moe_impl_class">get_moe_impl_class</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="sglang.srt.layers.moe.ep_moe.layer.DeepEPMoE" href="#sglang.srt.layers.moe.ep_moe.layer.DeepEPMoE">DeepEPMoE</a></code></h4>
<ul class="">
<li><code><a title="sglang.srt.layers.moe.ep_moe.layer.DeepEPMoE.combine" href="#sglang.srt.layers.moe.ep_moe.layer.DeepEPMoE.combine">combine</a></code></li>
<li><code><a title="sglang.srt.layers.moe.ep_moe.layer.DeepEPMoE.dispatch" href="#sglang.srt.layers.moe.ep_moe.layer.DeepEPMoE.dispatch">dispatch</a></code></li>
<li><code><a title="sglang.srt.layers.moe.ep_moe.layer.DeepEPMoE.forward_aiter" href="#sglang.srt.layers.moe.ep_moe.layer.DeepEPMoE.forward_aiter">forward_aiter</a></code></li>
<li><code><a title="sglang.srt.layers.moe.ep_moe.layer.DeepEPMoE.forward_deepgemm_contiguous" href="#sglang.srt.layers.moe.ep_moe.layer.DeepEPMoE.forward_deepgemm_contiguous">forward_deepgemm_contiguous</a></code></li>
<li><code><a title="sglang.srt.layers.moe.ep_moe.layer.DeepEPMoE.forward_deepgemm_masked" href="#sglang.srt.layers.moe.ep_moe.layer.DeepEPMoE.forward_deepgemm_masked">forward_deepgemm_masked</a></code></li>
<li><code><a title="sglang.srt.layers.moe.ep_moe.layer.DeepEPMoE.forward_npu" href="#sglang.srt.layers.moe.ep_moe.layer.DeepEPMoE.forward_npu">forward_npu</a></code></li>
<li><code><a title="sglang.srt.layers.moe.ep_moe.layer.DeepEPMoE.moe_impl" href="#sglang.srt.layers.moe.ep_moe.layer.DeepEPMoE.moe_impl">moe_impl</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="sglang.srt.layers.moe.ep_moe.layer.EPMoE" href="#sglang.srt.layers.moe.ep_moe.layer.EPMoE">EPMoE</a></code></h4>
<ul class="">
<li><code><a title="sglang.srt.layers.moe.ep_moe.layer.EPMoE.forward_deepgemm" href="#sglang.srt.layers.moe.ep_moe.layer.EPMoE.forward_deepgemm">forward_deepgemm</a></code></li>
</ul>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc" title="pdoc: Python API documentation generator"><cite>pdoc</cite> 0.11.6</a>.</p>
</footer>
</body>
</html>
