<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1">
<meta name="generator" content="pdoc3 0.11.6">
<title>sglang.srt.mem_cache.memory_pool API documentation</title>
<meta name="description" content="Copyright 2023-2024 SGLang Team
Licensed under the Apache License, Version 2.0 (the &#34;License&#34;);
you may not use this file except in compliance with …">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/13.0.0/sanitize.min.css" integrity="sha512-y1dtMcuvtTMJc1yPgEqF0ZjQbhnc/bFhyvIyVNb9Zk5mIGtqVaAB1Ttl28su8AvFMOY0EwRbAe+HCLqj6W7/KA==" crossorigin>
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/13.0.0/typography.min.css" integrity="sha512-Y1DYSb995BAfxobCkKepB1BqJJTPrOp3zPL74AWFugHHmmdcvO+C48WLrUOlhGMc0QG7AE3f7gmvvcrmX2fDoA==" crossorigin>
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/styles/default.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:1.5em;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:2em 0 .50em 0}h3{font-size:1.4em;margin:1.6em 0 .7em 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .2s ease-in-out}a:visited{color:#503}a:hover{color:#b62}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900;font-weight:bold}pre code{font-size:.8em;line-height:1.4em;padding:1em;display:block}code{background:#f3f3f3;font-family:"DejaVu Sans Mono",monospace;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source > summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible;min-width:max-content}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em 1em;margin:1em 0}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul ul{padding-left:1em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/highlight.min.js" integrity="sha512-D9gUyxqja7hBtkWpPWGt9wfbfaMGVt9gnyCvYa+jojwwPHLCzUm5i8rpk7vD7wNee9bA35eYIjobYPaQuKS1MQ==" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => {
hljs.configure({languages: ['bash', 'css', 'diff', 'graphql', 'ini', 'javascript', 'json', 'plaintext', 'python', 'python-repl', 'rust', 'shell', 'sql', 'typescript', 'xml', 'yaml']});
hljs.highlightAll();
/* Collapse source docstrings */
setTimeout(() => {
[...document.querySelectorAll('.hljs.language-python > .hljs-string')]
.filter(el => el.innerHTML.length > 200 && ['"""', "'''"].includes(el.innerHTML.substring(0, 3)))
.forEach(el => {
let d = document.createElement('details');
d.classList.add('hljs-string');
d.innerHTML = '<summary>"""</summary>' + el.innerHTML.substring(3);
el.replaceWith(d);
});
}, 100);
})</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>sglang.srt.mem_cache.memory_pool</code></h1>
</header>
<section id="section-intro">
<p>Copyright 2023-2024 SGLang Team
Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at</p>
<pre><code>&lt;http://www.apache.org/licenses/LICENSE-2.0&gt;
</code></pre>
<p>Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.</p>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-functions">Functions</h2>
<dl>
<dt id="sglang.srt.mem_cache.memory_pool.set_mla_kv_buffer_triton"><code class="name flex">
<span>def <span class="ident">set_mla_kv_buffer_triton</span></span>(<span>kv_buffer: torch.Tensor,<br>loc: torch.Tensor,<br>cache_k_nope: torch.Tensor,<br>cache_k_rope: torch.Tensor)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def set_mla_kv_buffer_triton(
    kv_buffer: torch.Tensor,
    loc: torch.Tensor,
    cache_k_nope: torch.Tensor,
    cache_k_rope: torch.Tensor,
):
    nope_dim = cache_k_nope.shape[-1]
    rope_dim = cache_k_rope.shape[-1]
    total_dim = nope_dim + rope_dim
    BLOCK = 128
    n_loc = loc.numel()
    grid = (n_loc, triton.cdiv(total_dim, BLOCK))

    set_mla_kv_buffer_kernel[grid](
        kv_buffer,
        cache_k_nope,
        cache_k_rope,
        loc,
        kv_buffer.stride(0),
        cache_k_nope.stride(0),
        cache_k_rope.stride(0),
        nope_dim,
        rope_dim,
        BLOCK=BLOCK,
    )</code></pre>
</details>
<div class="desc"></div>
</dd>
</dl>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="sglang.srt.mem_cache.memory_pool.AscendMLAPagedTokenToKVPool"><code class="flex name class">
<span>class <span class="ident">AscendMLAPagedTokenToKVPool</span></span>
<span>(</span><span>size: int,<br>page_size: int,<br>dtype: torch.dtype,<br>kv_lora_rank: int,<br>qk_rope_head_dim: int,<br>layer_num: int,<br>device: str,<br>enable_memory_saver: bool,<br>start_layer: int | None = None,<br>end_layer: int | None = None)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class AscendMLAPagedTokenToKVPool(MLATokenToKVPool):
    def __init__(
        self,
        size: int,
        page_size: int,
        dtype: torch.dtype,
        kv_lora_rank: int,
        qk_rope_head_dim: int,
        layer_num: int,
        device: str,
        enable_memory_saver: bool,
        start_layer: Optional[int] = None,
        end_layer: Optional[int] = None,
    ):
        super(MLATokenToKVPool, self).__init__(
            size,
            page_size,
            dtype,
            layer_num,
            device,
            enable_memory_saver,
            start_layer,
            end_layer,
        )

        self.kv_lora_rank = kv_lora_rank
        self.qk_rope_head_dim = qk_rope_head_dim

        self.custom_mem_pool = None

        with self.memory_saver_adapter.region(GPU_MEMORY_TYPE_KV_CACHE):
            # The padded slot 0 is used for writing dummy outputs from padded tokens.
            self.k_buffer = torch.zeros(
                (
                    layer_num,
                    self.size // self.page_size + 1,
                    self.page_size,
                    1,
                    self.kv_lora_rank,
                ),
                dtype=self.store_dtype,
                device=self.device,
            )
            self.v_buffer = torch.zeros(
                (
                    layer_num,
                    self.size // self.page_size + 1,
                    self.page_size,
                    1,
                    self.qk_rope_head_dim,
                ),
                dtype=self.store_dtype,
                device=self.device,
            )

        self.layer_transfer_counter = None

        kv_size = self.get_kv_size_bytes()
        logger.info(
            f&#34;KV Cache is allocated. #tokens: {size}, KV size: {kv_size / GB:.2f} GB&#34;
        )
        self.mem_usage = kv_size / GB

    def get_kv_size_bytes(self):
        assert hasattr(self, &#34;k_buffer&#34;)
        assert hasattr(self, &#34;v_buffer&#34;)
        kv_size_bytes = 0
        for k_cache in self.k_buffer:
            kv_size_bytes += np.prod(k_cache.shape) * k_cache.dtype.itemsize
        for v_cache in self.v_buffer:
            kv_size_bytes += np.prod(v_cache.shape) * v_cache.dtype.itemsize
        return kv_size_bytes

    def get_kv_buffer(self, layer_id: int):
        if self.layer_transfer_counter is not None:
            self.layer_transfer_counter.wait_until(layer_id - self.start_layer)
        return (
            self.k_buffer[layer_id - self.start_layer],
            self.v_buffer[layer_id - self.start_layer],
        )

    def get_key_buffer(self, layer_id: int):
        if self.layer_transfer_counter is not None:
            self.layer_transfer_counter.wait_until(layer_id - self.start_layer)

        if self.store_dtype != self.dtype:
            return self.k_buffer[layer_id - self.start_layer].view(self.dtype)
        return self.k_buffer[layer_id - self.start_layer]

    def get_value_buffer(self, layer_id: int):
        if self.layer_transfer_counter is not None:
            self.layer_transfer_counter.wait_until(layer_id - self.start_layer)

        if self.store_dtype != self.dtype:
            return self.v_buffer[layer_id - self.start_layer].view(self.dtype)
        return self.v_buffer[layer_id - self.start_layer]

    # for disagg
    def get_contiguous_buf_infos(self):
        # MLA has only one kv_buffer, so only the information of this buffer needs to be returned.
        kv_data_ptrs = [self.k_buffer[i].data_ptr() for i in range(self.layer_num)] + [
            self.v_buffer[i].data_ptr() for i in range(self.layer_num)
        ]
        kv_data_lens = [self.k_buffer[i].nbytes for i in range(self.layer_num)] + [
            self.v_buffer[i].nbytes for i in range(self.layer_num)
        ]
        kv_item_lens = [self.k_buffer[i][0].nbytes for i in range(self.layer_num)] + [
            self.v_buffer[i][0].nbytes for i in range(self.layer_num)
        ]
        return kv_data_ptrs, kv_data_lens, kv_item_lens

    def set_kv_buffer(
        self,
        layer: RadixAttention,
        loc: torch.Tensor,
        cache_k: torch.Tensor,
        cache_v: torch.Tensor,
    ):
        layer_id = layer.layer_id
        if cache_k.dtype != self.dtype:
            cache_k = cache_k.to(self.dtype)
            cache_v = cache_v.to(self.dtype)

        if self.store_dtype != self.dtype:
            cache_k = cache_k.view(self.store_dtype)
            cache_v = cache_v.view(self.store_dtype)

        if cache_v is None:
            cache_k, cache_v = cache_k.split(
                [self.kv_lora_rank, self.qk_rope_head_dim], dim=-1
            )

        torch_npu.npu_scatter_nd_update_(
            self.k_buffer[layer_id - self.start_layer].view(-1, 1, self.kv_lora_rank),
            loc.view(-1, 1),
            cache_k.view(-1, 1, self.kv_lora_rank),
        )
        torch_npu.npu_scatter_nd_update_(
            self.v_buffer[layer_id - self.start_layer].view(
                -1, 1, self.qk_rope_head_dim
            ),
            loc.view(-1, 1),
            cache_v.view(-1, 1, self.qk_rope_head_dim),
        )</code></pre>
</details>
<div class="desc"><p>Helper class that provides a standard way to create an ABC using
inheritance.</p></div>
<h3>Ancestors</h3>
<ul class="hlist">
<li><a title="sglang.srt.mem_cache.memory_pool.MLATokenToKVPool" href="#sglang.srt.mem_cache.memory_pool.MLATokenToKVPool">MLATokenToKVPool</a></li>
<li><a title="sglang.srt.mem_cache.memory_pool.KVCache" href="#sglang.srt.mem_cache.memory_pool.KVCache">KVCache</a></li>
<li>abc.ABC</li>
</ul>
<h3>Methods</h3>
<dl>
<dt id="sglang.srt.mem_cache.memory_pool.AscendMLAPagedTokenToKVPool.get_contiguous_buf_infos"><code class="name flex">
<span>def <span class="ident">get_contiguous_buf_infos</span></span>(<span>self)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_contiguous_buf_infos(self):
    # MLA has only one kv_buffer, so only the information of this buffer needs to be returned.
    kv_data_ptrs = [self.k_buffer[i].data_ptr() for i in range(self.layer_num)] + [
        self.v_buffer[i].data_ptr() for i in range(self.layer_num)
    ]
    kv_data_lens = [self.k_buffer[i].nbytes for i in range(self.layer_num)] + [
        self.v_buffer[i].nbytes for i in range(self.layer_num)
    ]
    kv_item_lens = [self.k_buffer[i][0].nbytes for i in range(self.layer_num)] + [
        self.v_buffer[i][0].nbytes for i in range(self.layer_num)
    ]
    return kv_data_ptrs, kv_data_lens, kv_item_lens</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="sglang.srt.mem_cache.memory_pool.AscendMLAPagedTokenToKVPool.get_key_buffer"><code class="name flex">
<span>def <span class="ident">get_key_buffer</span></span>(<span>self, layer_id: int)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_key_buffer(self, layer_id: int):
    if self.layer_transfer_counter is not None:
        self.layer_transfer_counter.wait_until(layer_id - self.start_layer)

    if self.store_dtype != self.dtype:
        return self.k_buffer[layer_id - self.start_layer].view(self.dtype)
    return self.k_buffer[layer_id - self.start_layer]</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="sglang.srt.mem_cache.memory_pool.AscendMLAPagedTokenToKVPool.get_kv_buffer"><code class="name flex">
<span>def <span class="ident">get_kv_buffer</span></span>(<span>self, layer_id: int)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_kv_buffer(self, layer_id: int):
    if self.layer_transfer_counter is not None:
        self.layer_transfer_counter.wait_until(layer_id - self.start_layer)
    return (
        self.k_buffer[layer_id - self.start_layer],
        self.v_buffer[layer_id - self.start_layer],
    )</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="sglang.srt.mem_cache.memory_pool.AscendMLAPagedTokenToKVPool.get_kv_size_bytes"><code class="name flex">
<span>def <span class="ident">get_kv_size_bytes</span></span>(<span>self)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_kv_size_bytes(self):
    assert hasattr(self, &#34;k_buffer&#34;)
    assert hasattr(self, &#34;v_buffer&#34;)
    kv_size_bytes = 0
    for k_cache in self.k_buffer:
        kv_size_bytes += np.prod(k_cache.shape) * k_cache.dtype.itemsize
    for v_cache in self.v_buffer:
        kv_size_bytes += np.prod(v_cache.shape) * v_cache.dtype.itemsize
    return kv_size_bytes</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="sglang.srt.mem_cache.memory_pool.AscendMLAPagedTokenToKVPool.get_value_buffer"><code class="name flex">
<span>def <span class="ident">get_value_buffer</span></span>(<span>self, layer_id: int)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_value_buffer(self, layer_id: int):
    if self.layer_transfer_counter is not None:
        self.layer_transfer_counter.wait_until(layer_id - self.start_layer)

    if self.store_dtype != self.dtype:
        return self.v_buffer[layer_id - self.start_layer].view(self.dtype)
    return self.v_buffer[layer_id - self.start_layer]</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="sglang.srt.mem_cache.memory_pool.AscendMLAPagedTokenToKVPool.set_kv_buffer"><code class="name flex">
<span>def <span class="ident">set_kv_buffer</span></span>(<span>self,<br>layer: <a title="sglang.srt.layers.radix_attention.RadixAttention" href="../layers/radix_attention.html#sglang.srt.layers.radix_attention.RadixAttention">RadixAttention</a>,<br>loc: torch.Tensor,<br>cache_k: torch.Tensor,<br>cache_v: torch.Tensor)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def set_kv_buffer(
    self,
    layer: RadixAttention,
    loc: torch.Tensor,
    cache_k: torch.Tensor,
    cache_v: torch.Tensor,
):
    layer_id = layer.layer_id
    if cache_k.dtype != self.dtype:
        cache_k = cache_k.to(self.dtype)
        cache_v = cache_v.to(self.dtype)

    if self.store_dtype != self.dtype:
        cache_k = cache_k.view(self.store_dtype)
        cache_v = cache_v.view(self.store_dtype)

    if cache_v is None:
        cache_k, cache_v = cache_k.split(
            [self.kv_lora_rank, self.qk_rope_head_dim], dim=-1
        )

    torch_npu.npu_scatter_nd_update_(
        self.k_buffer[layer_id - self.start_layer].view(-1, 1, self.kv_lora_rank),
        loc.view(-1, 1),
        cache_k.view(-1, 1, self.kv_lora_rank),
    )
    torch_npu.npu_scatter_nd_update_(
        self.v_buffer[layer_id - self.start_layer].view(
            -1, 1, self.qk_rope_head_dim
        ),
        loc.view(-1, 1),
        cache_v.view(-1, 1, self.qk_rope_head_dim),
    )</code></pre>
</details>
<div class="desc"></div>
</dd>
</dl>
</dd>
<dt id="sglang.srt.mem_cache.memory_pool.AscendTokenToKVPool"><code class="flex name class">
<span>class <span class="ident">AscendTokenToKVPool</span></span>
<span>(</span><span>size: int,<br>page_size: int,<br>dtype: torch.dtype,<br>head_num: int,<br>head_dim: int,<br>layer_num: int,<br>device: str,<br>enable_memory_saver: bool,<br>start_layer: int | None = None,<br>end_layer: int | None = None)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class AscendTokenToKVPool(MHATokenToKVPool):

    def _create_buffers(self):
        with self.memory_saver_adapter.region(GPU_MEMORY_TYPE_KV_CACHE):
            # [size, head_num, head_dim] for each layer
            # The padded slot 0 is used for writing dummy outputs from padded tokens.
            # Continuous memory improves the efficiency of Ascend`s transmission backend,
            # while other backends remain unchanged.
            self.kv_buffer = torch.zeros(
                (
                    2,
                    self.layer_num,
                    self.size // self.page_size + 1,
                    self.page_size,
                    self.head_num,
                    self.head_dim,
                ),
                dtype=self.store_dtype,
                device=self.device,
            )
            self.k_buffer = self.kv_buffer[0]
            self.v_buffer = self.kv_buffer[1]

    # for disagg
    def get_contiguous_buf_infos(self):
        # layer_num x [seq_len, head_num, head_dim]
        # layer_num x [page_num, page_size, head_num, head_dim]
        kv_data_ptrs = [
            self.get_key_buffer(i).data_ptr()
            for i in range(self.start_layer, self.start_layer + self.layer_num)
        ] + [
            self.get_value_buffer(i).data_ptr()
            for i in range(self.start_layer, self.start_layer + self.layer_num)
        ]
        kv_data_lens = [
            self.get_key_buffer(i).nbytes
            for i in range(self.start_layer, self.start_layer + self.layer_num)
        ] + [
            self.get_value_buffer(i).nbytes
            for i in range(self.start_layer, self.start_layer + self.layer_num)
        ]
        kv_item_lens = [
            self.get_key_buffer(i)[0].nbytes
            for i in range(self.start_layer, self.start_layer + self.layer_num)
        ] + [
            self.get_value_buffer(i)[0].nbytes
            for i in range(self.start_layer, self.start_layer + self.layer_num)
        ]
        return kv_data_ptrs, kv_data_lens, kv_item_lens

    def set_kv_buffer(
        self,
        layer: RadixAttention,
        loc: torch.Tensor,
        cache_k: torch.Tensor,
        cache_v: torch.Tensor,
        k_scale: Optional[float] = None,
        v_scale: Optional[float] = None,
    ):
        layer_id = layer.layer_id
        if cache_k.dtype != self.dtype:
            if k_scale is not None:
                cache_k.div_(k_scale)
            if v_scale is not None:
                cache_v.div_(v_scale)
            cache_k = cache_k.to(self.dtype)
            cache_v = cache_v.to(self.dtype)

        if self.store_dtype != self.dtype:
            cache_k = cache_k.view(self.store_dtype)
            cache_v = cache_v.view(self.store_dtype)

        torch_npu._npu_reshape_and_cache(
            key=cache_k,
            value=cache_v,
            key_cache=self.k_buffer[layer_id].view(
                -1, self.page_size, self.head_num, self.head_dim
            ),
            value_cache=self.v_buffer[layer_id].view(
                -1, self.page_size, self.head_num, self.head_dim
            ),
            slot_indices=loc,
        )</code></pre>
</details>
<div class="desc"><p>Helper class that provides a standard way to create an ABC using
inheritance.</p></div>
<h3>Ancestors</h3>
<ul class="hlist">
<li><a title="sglang.srt.mem_cache.memory_pool.MHATokenToKVPool" href="#sglang.srt.mem_cache.memory_pool.MHATokenToKVPool">MHATokenToKVPool</a></li>
<li><a title="sglang.srt.mem_cache.memory_pool.KVCache" href="#sglang.srt.mem_cache.memory_pool.KVCache">KVCache</a></li>
<li>abc.ABC</li>
</ul>
<h3>Methods</h3>
<dl>
<dt id="sglang.srt.mem_cache.memory_pool.AscendTokenToKVPool.get_contiguous_buf_infos"><code class="name flex">
<span>def <span class="ident">get_contiguous_buf_infos</span></span>(<span>self)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_contiguous_buf_infos(self):
    # layer_num x [seq_len, head_num, head_dim]
    # layer_num x [page_num, page_size, head_num, head_dim]
    kv_data_ptrs = [
        self.get_key_buffer(i).data_ptr()
        for i in range(self.start_layer, self.start_layer + self.layer_num)
    ] + [
        self.get_value_buffer(i).data_ptr()
        for i in range(self.start_layer, self.start_layer + self.layer_num)
    ]
    kv_data_lens = [
        self.get_key_buffer(i).nbytes
        for i in range(self.start_layer, self.start_layer + self.layer_num)
    ] + [
        self.get_value_buffer(i).nbytes
        for i in range(self.start_layer, self.start_layer + self.layer_num)
    ]
    kv_item_lens = [
        self.get_key_buffer(i)[0].nbytes
        for i in range(self.start_layer, self.start_layer + self.layer_num)
    ] + [
        self.get_value_buffer(i)[0].nbytes
        for i in range(self.start_layer, self.start_layer + self.layer_num)
    ]
    return kv_data_ptrs, kv_data_lens, kv_item_lens</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="sglang.srt.mem_cache.memory_pool.AscendTokenToKVPool.set_kv_buffer"><code class="name flex">
<span>def <span class="ident">set_kv_buffer</span></span>(<span>self,<br>layer: <a title="sglang.srt.layers.radix_attention.RadixAttention" href="../layers/radix_attention.html#sglang.srt.layers.radix_attention.RadixAttention">RadixAttention</a>,<br>loc: torch.Tensor,<br>cache_k: torch.Tensor,<br>cache_v: torch.Tensor,<br>k_scale: float | None = None,<br>v_scale: float | None = None)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def set_kv_buffer(
    self,
    layer: RadixAttention,
    loc: torch.Tensor,
    cache_k: torch.Tensor,
    cache_v: torch.Tensor,
    k_scale: Optional[float] = None,
    v_scale: Optional[float] = None,
):
    layer_id = layer.layer_id
    if cache_k.dtype != self.dtype:
        if k_scale is not None:
            cache_k.div_(k_scale)
        if v_scale is not None:
            cache_v.div_(v_scale)
        cache_k = cache_k.to(self.dtype)
        cache_v = cache_v.to(self.dtype)

    if self.store_dtype != self.dtype:
        cache_k = cache_k.view(self.store_dtype)
        cache_v = cache_v.view(self.store_dtype)

    torch_npu._npu_reshape_and_cache(
        key=cache_k,
        value=cache_v,
        key_cache=self.k_buffer[layer_id].view(
            -1, self.page_size, self.head_num, self.head_dim
        ),
        value_cache=self.v_buffer[layer_id].view(
            -1, self.page_size, self.head_num, self.head_dim
        ),
        slot_indices=loc,
    )</code></pre>
</details>
<div class="desc"></div>
</dd>
</dl>
</dd>
<dt id="sglang.srt.mem_cache.memory_pool.DoubleSparseTokenToKVPool"><code class="flex name class">
<span>class <span class="ident">DoubleSparseTokenToKVPool</span></span>
<span>(</span><span>size: int,<br>page_size: int,<br>dtype: torch.dtype,<br>head_num: int,<br>head_dim: int,<br>layer_num: int,<br>device: str,<br>heavy_channel_num: int,<br>enable_memory_saver: bool,<br>start_layer: int | None = None,<br>end_layer: int | None = None)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class DoubleSparseTokenToKVPool(KVCache):
    def __init__(
        self,
        size: int,
        page_size: int,
        dtype: torch.dtype,
        head_num: int,
        head_dim: int,
        layer_num: int,
        device: str,
        heavy_channel_num: int,
        enable_memory_saver: bool,
        start_layer: Optional[int] = None,
        end_layer: Optional[int] = None,
    ):
        super().__init__(
            size,
            page_size,
            dtype,
            layer_num,
            device,
            enable_memory_saver,
            start_layer,
            end_layer,
        )

        with self.memory_saver_adapter.region(GPU_MEMORY_TYPE_KV_CACHE):
            # [size, head_num, head_dim] for each layer
            self.k_buffer = [
                torch.zeros(
                    (size + page_size, head_num, head_dim), dtype=dtype, device=device
                )
                for _ in range(layer_num)
            ]
            self.v_buffer = [
                torch.zeros(
                    (size + page_size, head_num, head_dim), dtype=dtype, device=device
                )
                for _ in range(layer_num)
            ]

            # [size, head_num, heavy_channel_num] for each layer
            self.label_buffer = [
                torch.zeros(
                    (size + 1, head_num, heavy_channel_num), dtype=dtype, device=device
                )
                for _ in range(layer_num)
            ]

    def get_key_buffer(self, layer_id: int):
        return self.k_buffer[layer_id - self.start_layer]

    def get_value_buffer(self, layer_id: int):
        return self.v_buffer[layer_id - self.start_layer]

    def get_label_buffer(self, layer_id: int):
        return self.label_buffer[layer_id - self.start_layer]

    def get_kv_buffer(self, layer_id: int):
        return (
            self.k_buffer[layer_id - self.start_layer],
            self.v_buffer[layer_id - self.start_layer],
        )

    def set_kv_buffer(
        self,
        layer: RadixAttention,
        loc: torch.Tensor,
        cache_k: torch.Tensor,
        cache_v: torch.Tensor,
        cache_label: torch.Tensor,
    ):
        # NOTE(Andy): ignore the dtype check
        layer_id = layer.layer_id
        self.k_buffer[layer_id - self.start_layer][loc] = cache_k
        self.v_buffer[layer_id - self.start_layer][loc] = cache_v
        self.label_buffer[layer_id - self.start_layer][loc] = cache_label</code></pre>
</details>
<div class="desc"><p>Helper class that provides a standard way to create an ABC using
inheritance.</p></div>
<h3>Ancestors</h3>
<ul class="hlist">
<li><a title="sglang.srt.mem_cache.memory_pool.KVCache" href="#sglang.srt.mem_cache.memory_pool.KVCache">KVCache</a></li>
<li>abc.ABC</li>
</ul>
<h3>Methods</h3>
<dl>
<dt id="sglang.srt.mem_cache.memory_pool.DoubleSparseTokenToKVPool.get_key_buffer"><code class="name flex">
<span>def <span class="ident">get_key_buffer</span></span>(<span>self, layer_id: int)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_key_buffer(self, layer_id: int):
    return self.k_buffer[layer_id - self.start_layer]</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="sglang.srt.mem_cache.memory_pool.DoubleSparseTokenToKVPool.get_kv_buffer"><code class="name flex">
<span>def <span class="ident">get_kv_buffer</span></span>(<span>self, layer_id: int)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_kv_buffer(self, layer_id: int):
    return (
        self.k_buffer[layer_id - self.start_layer],
        self.v_buffer[layer_id - self.start_layer],
    )</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="sglang.srt.mem_cache.memory_pool.DoubleSparseTokenToKVPool.get_label_buffer"><code class="name flex">
<span>def <span class="ident">get_label_buffer</span></span>(<span>self, layer_id: int)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_label_buffer(self, layer_id: int):
    return self.label_buffer[layer_id - self.start_layer]</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="sglang.srt.mem_cache.memory_pool.DoubleSparseTokenToKVPool.get_value_buffer"><code class="name flex">
<span>def <span class="ident">get_value_buffer</span></span>(<span>self, layer_id: int)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_value_buffer(self, layer_id: int):
    return self.v_buffer[layer_id - self.start_layer]</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="sglang.srt.mem_cache.memory_pool.DoubleSparseTokenToKVPool.set_kv_buffer"><code class="name flex">
<span>def <span class="ident">set_kv_buffer</span></span>(<span>self,<br>layer: <a title="sglang.srt.layers.radix_attention.RadixAttention" href="../layers/radix_attention.html#sglang.srt.layers.radix_attention.RadixAttention">RadixAttention</a>,<br>loc: torch.Tensor,<br>cache_k: torch.Tensor,<br>cache_v: torch.Tensor,<br>cache_label: torch.Tensor)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def set_kv_buffer(
    self,
    layer: RadixAttention,
    loc: torch.Tensor,
    cache_k: torch.Tensor,
    cache_v: torch.Tensor,
    cache_label: torch.Tensor,
):
    # NOTE(Andy): ignore the dtype check
    layer_id = layer.layer_id
    self.k_buffer[layer_id - self.start_layer][loc] = cache_k
    self.v_buffer[layer_id - self.start_layer][loc] = cache_v
    self.label_buffer[layer_id - self.start_layer][loc] = cache_label</code></pre>
</details>
<div class="desc"></div>
</dd>
</dl>
</dd>
<dt id="sglang.srt.mem_cache.memory_pool.KVCache"><code class="flex name class">
<span>class <span class="ident">KVCache</span></span>
<span>(</span><span>size: int,<br>page_size: int,<br>dtype: torch.dtype,<br>layer_num: int,<br>device: str,<br>enable_memory_saver: bool,<br>start_layer: int | None = None,<br>end_layer: int | None = None)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class KVCache(abc.ABC):
    @abc.abstractmethod
    def __init__(
        self,
        size: int,
        page_size: int,
        dtype: torch.dtype,
        layer_num: int,
        device: str,
        enable_memory_saver: bool,
        start_layer: Optional[int] = None,
        end_layer: Optional[int] = None,
    ):
        self.size = size
        self.page_size = page_size
        self.dtype = dtype
        self.device = device
        if dtype in (torch.float8_e5m2, torch.float8_e4m3fn):
            # NOTE: Store as torch.uint8 because Tensor.index_put is not implemented for torch.float8_e5m2
            self.store_dtype = torch.uint8
        else:
            self.store_dtype = dtype
        self.layer_num = layer_num
        self.start_layer = start_layer or 0
        self.end_layer = end_layer or layer_num - 1
        self.memory_saver_adapter = TorchMemorySaverAdapter.create(
            enable=enable_memory_saver
        )
        self.mem_usage = 0

        # used for chunked cpu-offloading
        self.cpu_offloading_chunk_size = 8192

    @abc.abstractmethod
    def get_key_buffer(self, layer_id: int) -&gt; torch.Tensor:
        raise NotImplementedError()

    @abc.abstractmethod
    def get_value_buffer(self, layer_id: int) -&gt; torch.Tensor:
        raise NotImplementedError()

    @abc.abstractmethod
    def get_kv_buffer(self, layer_id: int) -&gt; Tuple[torch.Tensor, torch.Tensor]:
        raise NotImplementedError()

    @abc.abstractmethod
    def set_kv_buffer(
        self,
        layer: RadixAttention,
        loc: torch.Tensor,
        cache_k: torch.Tensor,
        cache_v: torch.Tensor,
    ) -&gt; None:
        raise NotImplementedError()

    def register_layer_transfer_counter(self, layer_transfer_counter):
        self.layer_transfer_counter = layer_transfer_counter

    def get_cpu_copy(self, indices):
        raise NotImplementedError()

    def load_cpu_copy(self, kv_cache_cpu, indices):
        raise NotImplementedError()</code></pre>
</details>
<div class="desc"><p>Helper class that provides a standard way to create an ABC using
inheritance.</p></div>
<h3>Ancestors</h3>
<ul class="hlist">
<li>abc.ABC</li>
</ul>
<h3>Subclasses</h3>
<ul class="hlist">
<li><a title="sglang.srt.mem_cache.memory_pool.DoubleSparseTokenToKVPool" href="#sglang.srt.mem_cache.memory_pool.DoubleSparseTokenToKVPool">DoubleSparseTokenToKVPool</a></li>
<li><a title="sglang.srt.mem_cache.memory_pool.MHATokenToKVPool" href="#sglang.srt.mem_cache.memory_pool.MHATokenToKVPool">MHATokenToKVPool</a></li>
<li><a title="sglang.srt.mem_cache.memory_pool.MLATokenToKVPool" href="#sglang.srt.mem_cache.memory_pool.MLATokenToKVPool">MLATokenToKVPool</a></li>
<li><a title="sglang.srt.mem_cache.memory_pool.SWAKVPool" href="#sglang.srt.mem_cache.memory_pool.SWAKVPool">SWAKVPool</a></li>
</ul>
<h3>Methods</h3>
<dl>
<dt id="sglang.srt.mem_cache.memory_pool.KVCache.get_cpu_copy"><code class="name flex">
<span>def <span class="ident">get_cpu_copy</span></span>(<span>self, indices)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_cpu_copy(self, indices):
    raise NotImplementedError()</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="sglang.srt.mem_cache.memory_pool.KVCache.get_key_buffer"><code class="name flex">
<span>def <span class="ident">get_key_buffer</span></span>(<span>self, layer_id: int) ‑> torch.Tensor</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@abc.abstractmethod
def get_key_buffer(self, layer_id: int) -&gt; torch.Tensor:
    raise NotImplementedError()</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="sglang.srt.mem_cache.memory_pool.KVCache.get_kv_buffer"><code class="name flex">
<span>def <span class="ident">get_kv_buffer</span></span>(<span>self, layer_id: int) ‑> Tuple[torch.Tensor, torch.Tensor]</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@abc.abstractmethod
def get_kv_buffer(self, layer_id: int) -&gt; Tuple[torch.Tensor, torch.Tensor]:
    raise NotImplementedError()</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="sglang.srt.mem_cache.memory_pool.KVCache.get_value_buffer"><code class="name flex">
<span>def <span class="ident">get_value_buffer</span></span>(<span>self, layer_id: int) ‑> torch.Tensor</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@abc.abstractmethod
def get_value_buffer(self, layer_id: int) -&gt; torch.Tensor:
    raise NotImplementedError()</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="sglang.srt.mem_cache.memory_pool.KVCache.load_cpu_copy"><code class="name flex">
<span>def <span class="ident">load_cpu_copy</span></span>(<span>self, kv_cache_cpu, indices)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def load_cpu_copy(self, kv_cache_cpu, indices):
    raise NotImplementedError()</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="sglang.srt.mem_cache.memory_pool.KVCache.register_layer_transfer_counter"><code class="name flex">
<span>def <span class="ident">register_layer_transfer_counter</span></span>(<span>self, layer_transfer_counter)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def register_layer_transfer_counter(self, layer_transfer_counter):
    self.layer_transfer_counter = layer_transfer_counter</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="sglang.srt.mem_cache.memory_pool.KVCache.set_kv_buffer"><code class="name flex">
<span>def <span class="ident">set_kv_buffer</span></span>(<span>self,<br>layer: <a title="sglang.srt.layers.radix_attention.RadixAttention" href="../layers/radix_attention.html#sglang.srt.layers.radix_attention.RadixAttention">RadixAttention</a>,<br>loc: torch.Tensor,<br>cache_k: torch.Tensor,<br>cache_v: torch.Tensor) ‑> None</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@abc.abstractmethod
def set_kv_buffer(
    self,
    layer: RadixAttention,
    loc: torch.Tensor,
    cache_k: torch.Tensor,
    cache_v: torch.Tensor,
) -&gt; None:
    raise NotImplementedError()</code></pre>
</details>
<div class="desc"></div>
</dd>
</dl>
</dd>
<dt id="sglang.srt.mem_cache.memory_pool.MHATokenToKVPool"><code class="flex name class">
<span>class <span class="ident">MHATokenToKVPool</span></span>
<span>(</span><span>size: int,<br>page_size: int,<br>dtype: torch.dtype,<br>head_num: int,<br>head_dim: int,<br>layer_num: int,<br>device: str,<br>enable_memory_saver: bool,<br>start_layer: int | None = None,<br>end_layer: int | None = None)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class MHATokenToKVPool(KVCache):

    def __init__(
        self,
        size: int,
        page_size: int,
        dtype: torch.dtype,
        head_num: int,
        head_dim: int,
        layer_num: int,
        device: str,
        enable_memory_saver: bool,
        start_layer: Optional[int] = None,
        end_layer: Optional[int] = None,
    ):
        super().__init__(
            size,
            page_size,
            dtype,
            layer_num,
            device,
            enable_memory_saver,
            start_layer,
            end_layer,
        )
        self.head_num = head_num
        self.head_dim = head_dim

        # for disagg with nvlink
        self.enable_custom_mem_pool = get_bool_env_var(
            &#34;SGLANG_MOONCAKE_CUSTOM_MEM_POOL&#34;, &#34;false&#34;
        )
        if self.enable_custom_mem_pool:
            # TODO(shangming): abstract custom allocator class for more backends
            from mooncake.allocator import NVLinkAllocator

            allocator = NVLinkAllocator.get_allocator(self.device)
            self.custom_mem_pool = torch.cuda.MemPool(allocator.allocator())
        else:
            self.custom_mem_pool = None

        self._create_buffers()

        self.layer_transfer_counter = None
        self.device_module = torch.get_device_module(self.device)
        self.alt_stream = self.device_module.Stream() if _is_cuda else None

        k_size, v_size = self.get_kv_size_bytes()
        logger.info(
            f&#34;KV Cache is allocated. #tokens: {size}, K size: {k_size / GB:.2f} GB, V size: {v_size / GB:.2f} GB&#34;
        )
        self.mem_usage = (k_size + v_size) / GB

    def _create_buffers(self):
        with self.memory_saver_adapter.region(GPU_MEMORY_TYPE_KV_CACHE):
            with (
                torch.cuda.use_mem_pool(self.custom_mem_pool)
                if self.enable_custom_mem_pool
                else nullcontext()
            ):
                # [size, head_num, head_dim] for each layer
                # The padded slot 0 is used for writing dummy outputs from padded tokens.
                self.k_buffer = [
                    torch.zeros(
                        (self.size + self.page_size, self.head_num, self.head_dim),
                        dtype=self.store_dtype,
                        device=self.device,
                    )
                    for _ in range(self.layer_num)
                ]
                self.v_buffer = [
                    torch.zeros(
                        (self.size + self.page_size, self.head_num, self.head_dim),
                        dtype=self.store_dtype,
                        device=self.device,
                    )
                    for _ in range(self.layer_num)
                ]

        self.k_data_ptrs = torch.tensor(
            [x.data_ptr() for x in self.k_buffer],
            dtype=torch.uint64,
            device=self.device,
        )
        self.v_data_ptrs = torch.tensor(
            [x.data_ptr() for x in self.v_buffer],
            dtype=torch.uint64,
            device=self.device,
        )
        self.data_ptrs = torch.cat([self.k_data_ptrs, self.v_data_ptrs], dim=0)
        self.data_strides = torch.tensor(
            [
                np.prod(x.shape[1:]) * x.dtype.itemsize
                for x in self.k_buffer + self.v_buffer
            ],
            device=self.device,
        )

    def _clear_buffers(self):
        del self.k_buffer
        del self.v_buffer

    def get_kv_size_bytes(self):
        assert hasattr(self, &#34;k_buffer&#34;)
        assert hasattr(self, &#34;v_buffer&#34;)
        k_size_bytes = 0
        for k_cache in self.k_buffer:
            k_size_bytes += np.prod(k_cache.shape) * k_cache.dtype.itemsize
        v_size_bytes = 0
        for v_cache in self.v_buffer:
            v_size_bytes += np.prod(v_cache.shape) * v_cache.dtype.itemsize
        return k_size_bytes, v_size_bytes

    # for disagg
    def get_contiguous_buf_infos(self):
        # layer_num x [seq_len, head_num, head_dim]
        # layer_num x [page_num, page_size, head_num, head_dim]
        kv_data_ptrs = [
            self._get_key_buffer(i).data_ptr()
            for i in range(self.start_layer, self.start_layer + self.layer_num)
        ] + [
            self._get_value_buffer(i).data_ptr()
            for i in range(self.start_layer, self.start_layer + self.layer_num)
        ]
        kv_data_lens = [
            self._get_key_buffer(i).nbytes
            for i in range(self.start_layer, self.start_layer + self.layer_num)
        ] + [
            self._get_value_buffer(i).nbytes
            for i in range(self.start_layer, self.start_layer + self.layer_num)
        ]
        kv_item_lens = [
            self._get_key_buffer(i)[0].nbytes * self.page_size
            for i in range(self.start_layer, self.start_layer + self.layer_num)
        ] + [
            self._get_value_buffer(i)[0].nbytes * self.page_size
            for i in range(self.start_layer, self.start_layer + self.layer_num)
        ]
        return kv_data_ptrs, kv_data_lens, kv_item_lens

    def maybe_get_custom_mem_pool(self):
        return self.custom_mem_pool

    def get_cpu_copy(self, indices):
        torch.cuda.synchronize()
        kv_cache_cpu = []
        chunk_size = self.cpu_offloading_chunk_size
        for layer_id in range(self.layer_num):
            kv_cache_cpu.append([])
            for i in range(0, len(indices), chunk_size):
                chunk_indices = indices[i : i + chunk_size]
                k_cpu = self.k_buffer[layer_id][chunk_indices].to(
                    &#34;cpu&#34;, non_blocking=True
                )
                v_cpu = self.v_buffer[layer_id][chunk_indices].to(
                    &#34;cpu&#34;, non_blocking=True
                )
                kv_cache_cpu[-1].append([k_cpu, v_cpu])
        torch.cuda.synchronize()
        return kv_cache_cpu

    def load_cpu_copy(self, kv_cache_cpu, indices):
        torch.cuda.synchronize()
        chunk_size = self.cpu_offloading_chunk_size
        for layer_id in range(self.layer_num):
            for i in range(0, len(indices), chunk_size):
                chunk_indices = indices[i : i + chunk_size]
                k_cpu, v_cpu = (
                    kv_cache_cpu[layer_id][i // chunk_size][0],
                    kv_cache_cpu[layer_id][i // chunk_size][1],
                )
                assert k_cpu.shape[0] == v_cpu.shape[0] == len(chunk_indices)
                k_chunk = k_cpu.to(self.k_buffer[0].device, non_blocking=True)
                v_chunk = v_cpu.to(self.v_buffer[0].device, non_blocking=True)
                self.k_buffer[layer_id][chunk_indices] = k_chunk
                self.v_buffer[layer_id][chunk_indices] = v_chunk
        torch.cuda.synchronize()

    def _get_key_buffer(self, layer_id: int):
        # for internal use of referencing
        if self.store_dtype != self.dtype:
            return self.k_buffer[layer_id - self.start_layer].view(self.dtype)
        return self.k_buffer[layer_id - self.start_layer]

    def get_key_buffer(self, layer_id: int):
        # note: get_key_buffer is hooked with synchronization for layer-wise KV cache loading
        # it is supposed to be used only by attention backend not for information purpose
        # same applies to get_value_buffer and get_kv_buffer
        if self.layer_transfer_counter is not None:
            self.layer_transfer_counter.wait_until(layer_id - self.start_layer)

        return self._get_key_buffer(layer_id)

    def _get_value_buffer(self, layer_id: int):
        # for internal use of referencing
        if self.store_dtype != self.dtype:
            return self.v_buffer[layer_id - self.start_layer].view(self.dtype)
        return self.v_buffer[layer_id - self.start_layer]

    def get_value_buffer(self, layer_id: int):
        if self.layer_transfer_counter is not None:
            self.layer_transfer_counter.wait_until(layer_id - self.start_layer)
        return self._get_value_buffer(layer_id)

    def get_kv_buffer(self, layer_id: int):
        return self.get_key_buffer(layer_id), self.get_value_buffer(layer_id)

    def set_kv_buffer(
        self,
        layer: RadixAttention,
        loc: torch.Tensor,
        cache_k: torch.Tensor,
        cache_v: torch.Tensor,
        k_scale: Optional[float] = None,
        v_scale: Optional[float] = None,
        layer_id_override: Optional[int] = None,
    ):
        from sglang.srt.model_executor.cuda_graph_runner import get_is_capture_mode

        if layer_id_override is not None:
            layer_id = layer_id_override
        else:
            layer_id = layer.layer_id
        if cache_k.dtype != self.dtype:
            if k_scale is not None:
                cache_k.div_(k_scale)
            if v_scale is not None:
                cache_v.div_(v_scale)
            cache_k = cache_k.to(self.dtype)
            cache_v = cache_v.to(self.dtype)

        if self.store_dtype != self.dtype:
            cache_k = cache_k.view(self.store_dtype)
            cache_v = cache_v.view(self.store_dtype)

        if get_is_capture_mode() and self.alt_stream is not None:
            # Overlap the copy of K and V cache for small batch size
            current_stream = self.device_module.current_stream()
            self.alt_stream.wait_stream(current_stream)
            self.k_buffer[layer_id - self.start_layer][loc] = cache_k
            with self.device_module.stream(self.alt_stream):
                self.v_buffer[layer_id - self.start_layer][loc] = cache_v
            current_stream.wait_stream(self.alt_stream)
        else:
            self.k_buffer[layer_id - self.start_layer][loc] = cache_k
            self.v_buffer[layer_id - self.start_layer][loc] = cache_v

    def move_kv_cache(self, tgt_loc: torch.Tensor, src_loc: torch.Tensor):
        copy_all_layer_kv_cache[(len(self.data_ptrs),)](
            self.data_ptrs,
            self.data_strides,
            tgt_loc,
            src_loc,
            len(tgt_loc),
            next_power_of_2(len(tgt_loc)),
        )</code></pre>
</details>
<div class="desc"><p>Helper class that provides a standard way to create an ABC using
inheritance.</p></div>
<h3>Ancestors</h3>
<ul class="hlist">
<li><a title="sglang.srt.mem_cache.memory_pool.KVCache" href="#sglang.srt.mem_cache.memory_pool.KVCache">KVCache</a></li>
<li>abc.ABC</li>
</ul>
<h3>Subclasses</h3>
<ul class="hlist">
<li><a title="sglang.srt.mem_cache.memory_pool.AscendTokenToKVPool" href="#sglang.srt.mem_cache.memory_pool.AscendTokenToKVPool">AscendTokenToKVPool</a></li>
</ul>
<h3>Methods</h3>
<dl>
<dt id="sglang.srt.mem_cache.memory_pool.MHATokenToKVPool.get_contiguous_buf_infos"><code class="name flex">
<span>def <span class="ident">get_contiguous_buf_infos</span></span>(<span>self)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_contiguous_buf_infos(self):
    # layer_num x [seq_len, head_num, head_dim]
    # layer_num x [page_num, page_size, head_num, head_dim]
    kv_data_ptrs = [
        self._get_key_buffer(i).data_ptr()
        for i in range(self.start_layer, self.start_layer + self.layer_num)
    ] + [
        self._get_value_buffer(i).data_ptr()
        for i in range(self.start_layer, self.start_layer + self.layer_num)
    ]
    kv_data_lens = [
        self._get_key_buffer(i).nbytes
        for i in range(self.start_layer, self.start_layer + self.layer_num)
    ] + [
        self._get_value_buffer(i).nbytes
        for i in range(self.start_layer, self.start_layer + self.layer_num)
    ]
    kv_item_lens = [
        self._get_key_buffer(i)[0].nbytes * self.page_size
        for i in range(self.start_layer, self.start_layer + self.layer_num)
    ] + [
        self._get_value_buffer(i)[0].nbytes * self.page_size
        for i in range(self.start_layer, self.start_layer + self.layer_num)
    ]
    return kv_data_ptrs, kv_data_lens, kv_item_lens</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="sglang.srt.mem_cache.memory_pool.MHATokenToKVPool.get_cpu_copy"><code class="name flex">
<span>def <span class="ident">get_cpu_copy</span></span>(<span>self, indices)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_cpu_copy(self, indices):
    torch.cuda.synchronize()
    kv_cache_cpu = []
    chunk_size = self.cpu_offloading_chunk_size
    for layer_id in range(self.layer_num):
        kv_cache_cpu.append([])
        for i in range(0, len(indices), chunk_size):
            chunk_indices = indices[i : i + chunk_size]
            k_cpu = self.k_buffer[layer_id][chunk_indices].to(
                &#34;cpu&#34;, non_blocking=True
            )
            v_cpu = self.v_buffer[layer_id][chunk_indices].to(
                &#34;cpu&#34;, non_blocking=True
            )
            kv_cache_cpu[-1].append([k_cpu, v_cpu])
    torch.cuda.synchronize()
    return kv_cache_cpu</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="sglang.srt.mem_cache.memory_pool.MHATokenToKVPool.get_key_buffer"><code class="name flex">
<span>def <span class="ident">get_key_buffer</span></span>(<span>self, layer_id: int)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_key_buffer(self, layer_id: int):
    # note: get_key_buffer is hooked with synchronization for layer-wise KV cache loading
    # it is supposed to be used only by attention backend not for information purpose
    # same applies to get_value_buffer and get_kv_buffer
    if self.layer_transfer_counter is not None:
        self.layer_transfer_counter.wait_until(layer_id - self.start_layer)

    return self._get_key_buffer(layer_id)</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="sglang.srt.mem_cache.memory_pool.MHATokenToKVPool.get_kv_buffer"><code class="name flex">
<span>def <span class="ident">get_kv_buffer</span></span>(<span>self, layer_id: int)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_kv_buffer(self, layer_id: int):
    return self.get_key_buffer(layer_id), self.get_value_buffer(layer_id)</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="sglang.srt.mem_cache.memory_pool.MHATokenToKVPool.get_kv_size_bytes"><code class="name flex">
<span>def <span class="ident">get_kv_size_bytes</span></span>(<span>self)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_kv_size_bytes(self):
    assert hasattr(self, &#34;k_buffer&#34;)
    assert hasattr(self, &#34;v_buffer&#34;)
    k_size_bytes = 0
    for k_cache in self.k_buffer:
        k_size_bytes += np.prod(k_cache.shape) * k_cache.dtype.itemsize
    v_size_bytes = 0
    for v_cache in self.v_buffer:
        v_size_bytes += np.prod(v_cache.shape) * v_cache.dtype.itemsize
    return k_size_bytes, v_size_bytes</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="sglang.srt.mem_cache.memory_pool.MHATokenToKVPool.get_value_buffer"><code class="name flex">
<span>def <span class="ident">get_value_buffer</span></span>(<span>self, layer_id: int)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_value_buffer(self, layer_id: int):
    if self.layer_transfer_counter is not None:
        self.layer_transfer_counter.wait_until(layer_id - self.start_layer)
    return self._get_value_buffer(layer_id)</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="sglang.srt.mem_cache.memory_pool.MHATokenToKVPool.load_cpu_copy"><code class="name flex">
<span>def <span class="ident">load_cpu_copy</span></span>(<span>self, kv_cache_cpu, indices)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def load_cpu_copy(self, kv_cache_cpu, indices):
    torch.cuda.synchronize()
    chunk_size = self.cpu_offloading_chunk_size
    for layer_id in range(self.layer_num):
        for i in range(0, len(indices), chunk_size):
            chunk_indices = indices[i : i + chunk_size]
            k_cpu, v_cpu = (
                kv_cache_cpu[layer_id][i // chunk_size][0],
                kv_cache_cpu[layer_id][i // chunk_size][1],
            )
            assert k_cpu.shape[0] == v_cpu.shape[0] == len(chunk_indices)
            k_chunk = k_cpu.to(self.k_buffer[0].device, non_blocking=True)
            v_chunk = v_cpu.to(self.v_buffer[0].device, non_blocking=True)
            self.k_buffer[layer_id][chunk_indices] = k_chunk
            self.v_buffer[layer_id][chunk_indices] = v_chunk
    torch.cuda.synchronize()</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="sglang.srt.mem_cache.memory_pool.MHATokenToKVPool.maybe_get_custom_mem_pool"><code class="name flex">
<span>def <span class="ident">maybe_get_custom_mem_pool</span></span>(<span>self)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def maybe_get_custom_mem_pool(self):
    return self.custom_mem_pool</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="sglang.srt.mem_cache.memory_pool.MHATokenToKVPool.move_kv_cache"><code class="name flex">
<span>def <span class="ident">move_kv_cache</span></span>(<span>self, tgt_loc: torch.Tensor, src_loc: torch.Tensor)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def move_kv_cache(self, tgt_loc: torch.Tensor, src_loc: torch.Tensor):
    copy_all_layer_kv_cache[(len(self.data_ptrs),)](
        self.data_ptrs,
        self.data_strides,
        tgt_loc,
        src_loc,
        len(tgt_loc),
        next_power_of_2(len(tgt_loc)),
    )</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="sglang.srt.mem_cache.memory_pool.MHATokenToKVPool.set_kv_buffer"><code class="name flex">
<span>def <span class="ident">set_kv_buffer</span></span>(<span>self,<br>layer: <a title="sglang.srt.layers.radix_attention.RadixAttention" href="../layers/radix_attention.html#sglang.srt.layers.radix_attention.RadixAttention">RadixAttention</a>,<br>loc: torch.Tensor,<br>cache_k: torch.Tensor,<br>cache_v: torch.Tensor,<br>k_scale: float | None = None,<br>v_scale: float | None = None,<br>layer_id_override: int | None = None)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def set_kv_buffer(
    self,
    layer: RadixAttention,
    loc: torch.Tensor,
    cache_k: torch.Tensor,
    cache_v: torch.Tensor,
    k_scale: Optional[float] = None,
    v_scale: Optional[float] = None,
    layer_id_override: Optional[int] = None,
):
    from sglang.srt.model_executor.cuda_graph_runner import get_is_capture_mode

    if layer_id_override is not None:
        layer_id = layer_id_override
    else:
        layer_id = layer.layer_id
    if cache_k.dtype != self.dtype:
        if k_scale is not None:
            cache_k.div_(k_scale)
        if v_scale is not None:
            cache_v.div_(v_scale)
        cache_k = cache_k.to(self.dtype)
        cache_v = cache_v.to(self.dtype)

    if self.store_dtype != self.dtype:
        cache_k = cache_k.view(self.store_dtype)
        cache_v = cache_v.view(self.store_dtype)

    if get_is_capture_mode() and self.alt_stream is not None:
        # Overlap the copy of K and V cache for small batch size
        current_stream = self.device_module.current_stream()
        self.alt_stream.wait_stream(current_stream)
        self.k_buffer[layer_id - self.start_layer][loc] = cache_k
        with self.device_module.stream(self.alt_stream):
            self.v_buffer[layer_id - self.start_layer][loc] = cache_v
        current_stream.wait_stream(self.alt_stream)
    else:
        self.k_buffer[layer_id - self.start_layer][loc] = cache_k
        self.v_buffer[layer_id - self.start_layer][loc] = cache_v</code></pre>
</details>
<div class="desc"></div>
</dd>
</dl>
</dd>
<dt id="sglang.srt.mem_cache.memory_pool.MLATokenToKVPool"><code class="flex name class">
<span>class <span class="ident">MLATokenToKVPool</span></span>
<span>(</span><span>size: int,<br>page_size: int,<br>dtype: torch.dtype,<br>kv_lora_rank: int,<br>qk_rope_head_dim: int,<br>layer_num: int,<br>device: str,<br>enable_memory_saver: bool,<br>start_layer: int | None = None,<br>end_layer: int | None = None)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class MLATokenToKVPool(KVCache):
    def __init__(
        self,
        size: int,
        page_size: int,
        dtype: torch.dtype,
        kv_lora_rank: int,
        qk_rope_head_dim: int,
        layer_num: int,
        device: str,
        enable_memory_saver: bool,
        start_layer: Optional[int] = None,
        end_layer: Optional[int] = None,
    ):
        super().__init__(
            size,
            page_size,
            dtype,
            layer_num,
            device,
            enable_memory_saver,
            start_layer,
            end_layer,
        )

        self.kv_lora_rank = kv_lora_rank
        self.qk_rope_head_dim = qk_rope_head_dim

        # for disagg with nvlink
        self.enable_custom_mem_pool = get_bool_env_var(
            &#34;SGLANG_MOONCAKE_CUSTOM_MEM_POOL&#34;, &#34;false&#34;
        )
        if self.enable_custom_mem_pool:
            # TODO(shangming): abstract custom allocator class for more backends
            from mooncake.allocator import NVLinkAllocator

            allocator = NVLinkAllocator.get_allocator(self.device)
            self.custom_mem_pool = torch.cuda.MemPool(allocator.allocator())
        else:
            self.custom_mem_pool = None

        with self.memory_saver_adapter.region(GPU_MEMORY_TYPE_KV_CACHE):
            with (
                torch.cuda.use_mem_pool(self.custom_mem_pool)
                if self.custom_mem_pool
                else nullcontext()
            ):
                # The padded slot 0 is used for writing dummy outputs from padded tokens.
                self.kv_buffer = [
                    torch.zeros(
                        (size + page_size, 1, kv_lora_rank + qk_rope_head_dim),
                        dtype=self.store_dtype,
                        device=device,
                    )
                    for _ in range(layer_num)
                ]

        self.data_ptrs = torch.tensor(
            [x.data_ptr() for x in self.kv_buffer],
            dtype=torch.uint64,
            device=self.device,
        )
        self.layer_transfer_counter = None

        kv_size = self.get_kv_size_bytes()
        logger.info(
            f&#34;KV Cache is allocated. #tokens: {size}, KV size: {kv_size / GB:.2f} GB&#34;
        )
        self.mem_usage = kv_size / GB

    def get_kv_size_bytes(self):
        assert hasattr(self, &#34;kv_buffer&#34;)
        kv_size_bytes = 0
        for kv_cache in self.kv_buffer:
            kv_size_bytes += np.prod(kv_cache.shape) * kv_cache.dtype.itemsize
        return kv_size_bytes

    # for disagg
    def get_contiguous_buf_infos(self):
        # MLA has only one kv_buffer, so only the information of this buffer needs to be returned.
        kv_data_ptrs = [self.kv_buffer[i].data_ptr() for i in range(self.layer_num)]
        kv_data_lens = [self.kv_buffer[i].nbytes for i in range(self.layer_num)]
        kv_item_lens = [
            self.kv_buffer[i][0].nbytes * self.page_size for i in range(self.layer_num)
        ]
        return kv_data_ptrs, kv_data_lens, kv_item_lens

    def maybe_get_custom_mem_pool(self):
        return self.custom_mem_pool

    def get_key_buffer(self, layer_id: int):
        if self.layer_transfer_counter is not None:
            self.layer_transfer_counter.wait_until(layer_id - self.start_layer)

        if self.store_dtype != self.dtype:
            return self.kv_buffer[layer_id - self.start_layer].view(self.dtype)
        return self.kv_buffer[layer_id - self.start_layer]

    def get_value_buffer(self, layer_id: int):
        if self.layer_transfer_counter is not None:
            self.layer_transfer_counter.wait_until(layer_id - self.start_layer)

        if self.store_dtype != self.dtype:
            return self.kv_buffer[layer_id - self.start_layer][
                ..., : self.kv_lora_rank
            ].view(self.dtype)
        return self.kv_buffer[layer_id - self.start_layer][..., : self.kv_lora_rank]

    def get_kv_buffer(self, layer_id: int):
        return self.get_key_buffer(layer_id), self.get_value_buffer(layer_id)

    def set_kv_buffer(
        self,
        layer: RadixAttention,
        loc: torch.Tensor,
        cache_k: torch.Tensor,
        cache_v: torch.Tensor,
    ):
        layer_id = layer.layer_id
        if cache_k.dtype != self.dtype:
            cache_k = cache_k.to(self.dtype)
        if self.store_dtype != self.dtype:
            self.kv_buffer[layer_id - self.start_layer][loc] = cache_k.view(
                self.store_dtype
            )
        else:
            self.kv_buffer[layer_id - self.start_layer][loc] = cache_k

    def set_mla_kv_buffer(
        self,
        layer: RadixAttention,
        loc: torch.Tensor,
        cache_k_nope: torch.Tensor,
        cache_k_rope: torch.Tensor,
    ):
        layer_id = layer.layer_id
        if cache_k_nope.dtype != self.dtype:
            cache_k_nope = cache_k_nope.to(self.dtype)
            cache_k_rope = cache_k_rope.to(self.dtype)
        if self.store_dtype != self.dtype:
            cache_k_nope = cache_k_nope.view(self.store_dtype)
            cache_k_rope = cache_k_rope.view(self.store_dtype)

        set_mla_kv_buffer_triton(
            self.kv_buffer[layer_id - self.start_layer], loc, cache_k_nope, cache_k_rope
        )

    def get_cpu_copy(self, indices):
        torch.cuda.synchronize()
        kv_cache_cpu = []
        chunk_size = self.cpu_offloading_chunk_size
        for layer_id in range(self.layer_num):
            kv_cache_cpu.append([])
            for i in range(0, len(indices), chunk_size):
                chunk_indices = indices[i : i + chunk_size]
                kv_cpu = self.kv_buffer[layer_id][chunk_indices].to(
                    &#34;cpu&#34;, non_blocking=True
                )
                kv_cache_cpu[-1].append(kv_cpu)
        torch.cuda.synchronize()
        return kv_cache_cpu

    def load_cpu_copy(self, kv_cache_cpu, indices):
        torch.cuda.synchronize()
        chunk_size = self.cpu_offloading_chunk_size
        for layer_id in range(self.layer_num):
            for i in range(0, len(indices), chunk_size):
                chunk_indices = indices[i : i + chunk_size]
                kv_cpu = kv_cache_cpu[layer_id][i // chunk_size]
                assert kv_cpu.shape[0] == len(chunk_indices)
                kv_chunk = kv_cpu.to(self.kv_buffer[0].device, non_blocking=True)
                self.kv_buffer[layer_id][chunk_indices] = kv_chunk
        torch.cuda.synchronize()</code></pre>
</details>
<div class="desc"><p>Helper class that provides a standard way to create an ABC using
inheritance.</p></div>
<h3>Ancestors</h3>
<ul class="hlist">
<li><a title="sglang.srt.mem_cache.memory_pool.KVCache" href="#sglang.srt.mem_cache.memory_pool.KVCache">KVCache</a></li>
<li>abc.ABC</li>
</ul>
<h3>Subclasses</h3>
<ul class="hlist">
<li><a title="sglang.srt.mem_cache.memory_pool.AscendMLAPagedTokenToKVPool" href="#sglang.srt.mem_cache.memory_pool.AscendMLAPagedTokenToKVPool">AscendMLAPagedTokenToKVPool</a></li>
</ul>
<h3>Methods</h3>
<dl>
<dt id="sglang.srt.mem_cache.memory_pool.MLATokenToKVPool.get_contiguous_buf_infos"><code class="name flex">
<span>def <span class="ident">get_contiguous_buf_infos</span></span>(<span>self)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_contiguous_buf_infos(self):
    # MLA has only one kv_buffer, so only the information of this buffer needs to be returned.
    kv_data_ptrs = [self.kv_buffer[i].data_ptr() for i in range(self.layer_num)]
    kv_data_lens = [self.kv_buffer[i].nbytes for i in range(self.layer_num)]
    kv_item_lens = [
        self.kv_buffer[i][0].nbytes * self.page_size for i in range(self.layer_num)
    ]
    return kv_data_ptrs, kv_data_lens, kv_item_lens</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="sglang.srt.mem_cache.memory_pool.MLATokenToKVPool.get_cpu_copy"><code class="name flex">
<span>def <span class="ident">get_cpu_copy</span></span>(<span>self, indices)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_cpu_copy(self, indices):
    torch.cuda.synchronize()
    kv_cache_cpu = []
    chunk_size = self.cpu_offloading_chunk_size
    for layer_id in range(self.layer_num):
        kv_cache_cpu.append([])
        for i in range(0, len(indices), chunk_size):
            chunk_indices = indices[i : i + chunk_size]
            kv_cpu = self.kv_buffer[layer_id][chunk_indices].to(
                &#34;cpu&#34;, non_blocking=True
            )
            kv_cache_cpu[-1].append(kv_cpu)
    torch.cuda.synchronize()
    return kv_cache_cpu</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="sglang.srt.mem_cache.memory_pool.MLATokenToKVPool.get_key_buffer"><code class="name flex">
<span>def <span class="ident">get_key_buffer</span></span>(<span>self, layer_id: int)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_key_buffer(self, layer_id: int):
    if self.layer_transfer_counter is not None:
        self.layer_transfer_counter.wait_until(layer_id - self.start_layer)

    if self.store_dtype != self.dtype:
        return self.kv_buffer[layer_id - self.start_layer].view(self.dtype)
    return self.kv_buffer[layer_id - self.start_layer]</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="sglang.srt.mem_cache.memory_pool.MLATokenToKVPool.get_kv_buffer"><code class="name flex">
<span>def <span class="ident">get_kv_buffer</span></span>(<span>self, layer_id: int)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_kv_buffer(self, layer_id: int):
    return self.get_key_buffer(layer_id), self.get_value_buffer(layer_id)</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="sglang.srt.mem_cache.memory_pool.MLATokenToKVPool.get_kv_size_bytes"><code class="name flex">
<span>def <span class="ident">get_kv_size_bytes</span></span>(<span>self)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_kv_size_bytes(self):
    assert hasattr(self, &#34;kv_buffer&#34;)
    kv_size_bytes = 0
    for kv_cache in self.kv_buffer:
        kv_size_bytes += np.prod(kv_cache.shape) * kv_cache.dtype.itemsize
    return kv_size_bytes</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="sglang.srt.mem_cache.memory_pool.MLATokenToKVPool.get_value_buffer"><code class="name flex">
<span>def <span class="ident">get_value_buffer</span></span>(<span>self, layer_id: int)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_value_buffer(self, layer_id: int):
    if self.layer_transfer_counter is not None:
        self.layer_transfer_counter.wait_until(layer_id - self.start_layer)

    if self.store_dtype != self.dtype:
        return self.kv_buffer[layer_id - self.start_layer][
            ..., : self.kv_lora_rank
        ].view(self.dtype)
    return self.kv_buffer[layer_id - self.start_layer][..., : self.kv_lora_rank]</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="sglang.srt.mem_cache.memory_pool.MLATokenToKVPool.load_cpu_copy"><code class="name flex">
<span>def <span class="ident">load_cpu_copy</span></span>(<span>self, kv_cache_cpu, indices)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def load_cpu_copy(self, kv_cache_cpu, indices):
    torch.cuda.synchronize()
    chunk_size = self.cpu_offloading_chunk_size
    for layer_id in range(self.layer_num):
        for i in range(0, len(indices), chunk_size):
            chunk_indices = indices[i : i + chunk_size]
            kv_cpu = kv_cache_cpu[layer_id][i // chunk_size]
            assert kv_cpu.shape[0] == len(chunk_indices)
            kv_chunk = kv_cpu.to(self.kv_buffer[0].device, non_blocking=True)
            self.kv_buffer[layer_id][chunk_indices] = kv_chunk
    torch.cuda.synchronize()</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="sglang.srt.mem_cache.memory_pool.MLATokenToKVPool.maybe_get_custom_mem_pool"><code class="name flex">
<span>def <span class="ident">maybe_get_custom_mem_pool</span></span>(<span>self)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def maybe_get_custom_mem_pool(self):
    return self.custom_mem_pool</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="sglang.srt.mem_cache.memory_pool.MLATokenToKVPool.set_kv_buffer"><code class="name flex">
<span>def <span class="ident">set_kv_buffer</span></span>(<span>self,<br>layer: <a title="sglang.srt.layers.radix_attention.RadixAttention" href="../layers/radix_attention.html#sglang.srt.layers.radix_attention.RadixAttention">RadixAttention</a>,<br>loc: torch.Tensor,<br>cache_k: torch.Tensor,<br>cache_v: torch.Tensor)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def set_kv_buffer(
    self,
    layer: RadixAttention,
    loc: torch.Tensor,
    cache_k: torch.Tensor,
    cache_v: torch.Tensor,
):
    layer_id = layer.layer_id
    if cache_k.dtype != self.dtype:
        cache_k = cache_k.to(self.dtype)
    if self.store_dtype != self.dtype:
        self.kv_buffer[layer_id - self.start_layer][loc] = cache_k.view(
            self.store_dtype
        )
    else:
        self.kv_buffer[layer_id - self.start_layer][loc] = cache_k</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="sglang.srt.mem_cache.memory_pool.MLATokenToKVPool.set_mla_kv_buffer"><code class="name flex">
<span>def <span class="ident">set_mla_kv_buffer</span></span>(<span>self,<br>layer: <a title="sglang.srt.layers.radix_attention.RadixAttention" href="../layers/radix_attention.html#sglang.srt.layers.radix_attention.RadixAttention">RadixAttention</a>,<br>loc: torch.Tensor,<br>cache_k_nope: torch.Tensor,<br>cache_k_rope: torch.Tensor)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def set_mla_kv_buffer(
    self,
    layer: RadixAttention,
    loc: torch.Tensor,
    cache_k_nope: torch.Tensor,
    cache_k_rope: torch.Tensor,
):
    layer_id = layer.layer_id
    if cache_k_nope.dtype != self.dtype:
        cache_k_nope = cache_k_nope.to(self.dtype)
        cache_k_rope = cache_k_rope.to(self.dtype)
    if self.store_dtype != self.dtype:
        cache_k_nope = cache_k_nope.view(self.store_dtype)
        cache_k_rope = cache_k_rope.view(self.store_dtype)

    set_mla_kv_buffer_triton(
        self.kv_buffer[layer_id - self.start_layer], loc, cache_k_nope, cache_k_rope
    )</code></pre>
</details>
<div class="desc"></div>
</dd>
</dl>
</dd>
<dt id="sglang.srt.mem_cache.memory_pool.ReqToTokenPool"><code class="flex name class">
<span>class <span class="ident">ReqToTokenPool</span></span>
<span>(</span><span>size: int, max_context_len: int, device: str, enable_memory_saver: bool)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class ReqToTokenPool:
    &#34;&#34;&#34;A memory pool that maps a request to its token locations.&#34;&#34;&#34;

    def __init__(
        self,
        size: int,
        max_context_len: int,
        device: str,
        enable_memory_saver: bool,
    ):

        memory_saver_adapter = TorchMemorySaverAdapter.create(
            enable=enable_memory_saver
        )

        self.size = size
        self.max_context_len = max_context_len
        self.device = device
        with memory_saver_adapter.region(GPU_MEMORY_TYPE_KV_CACHE):
            self.req_to_token = torch.zeros(
                (size, max_context_len), dtype=torch.int32, device=device
            )

        self.free_slots = list(range(size))

    def write(self, indices, values):
        self.req_to_token[indices] = values

    def available_size(self):
        return len(self.free_slots)

    def alloc(self, need_size: int) -&gt; List[int]:
        if need_size &gt; len(self.free_slots):
            return None

        select_index = self.free_slots[:need_size]
        self.free_slots = self.free_slots[need_size:]

        return select_index

    def free(self, free_index: Union[int, List[int]]):
        if isinstance(free_index, (int,)):
            self.free_slots.append(free_index)
        else:
            self.free_slots.extend(free_index)

    def clear(self):
        self.free_slots = list(range(self.size))</code></pre>
</details>
<div class="desc"><p>A memory pool that maps a request to its token locations.</p></div>
<h3>Methods</h3>
<dl>
<dt id="sglang.srt.mem_cache.memory_pool.ReqToTokenPool.alloc"><code class="name flex">
<span>def <span class="ident">alloc</span></span>(<span>self, need_size: int) ‑> List[int]</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def alloc(self, need_size: int) -&gt; List[int]:
    if need_size &gt; len(self.free_slots):
        return None

    select_index = self.free_slots[:need_size]
    self.free_slots = self.free_slots[need_size:]

    return select_index</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="sglang.srt.mem_cache.memory_pool.ReqToTokenPool.available_size"><code class="name flex">
<span>def <span class="ident">available_size</span></span>(<span>self)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def available_size(self):
    return len(self.free_slots)</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="sglang.srt.mem_cache.memory_pool.ReqToTokenPool.clear"><code class="name flex">
<span>def <span class="ident">clear</span></span>(<span>self)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def clear(self):
    self.free_slots = list(range(self.size))</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="sglang.srt.mem_cache.memory_pool.ReqToTokenPool.free"><code class="name flex">
<span>def <span class="ident">free</span></span>(<span>self, free_index: int | List[int])</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def free(self, free_index: Union[int, List[int]]):
    if isinstance(free_index, (int,)):
        self.free_slots.append(free_index)
    else:
        self.free_slots.extend(free_index)</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="sglang.srt.mem_cache.memory_pool.ReqToTokenPool.write"><code class="name flex">
<span>def <span class="ident">write</span></span>(<span>self, indices, values)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def write(self, indices, values):
    self.req_to_token[indices] = values</code></pre>
</details>
<div class="desc"></div>
</dd>
</dl>
</dd>
<dt id="sglang.srt.mem_cache.memory_pool.SWAKVPool"><code class="flex name class">
<span>class <span class="ident">SWAKVPool</span></span>
<span>(</span><span>size: int,<br>size_swa: int,<br>dtype: torch.dtype,<br>head_num: int,<br>head_dim: int,<br>swa_attention_layer_ids: List[int],<br>full_attention_layer_ids: List[int],<br>enable_kvcache_transpose: bool,<br>device: str)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class SWAKVPool(KVCache):
    &#34;&#34;&#34;KV cache with separate pools for full and SWA attention layers.&#34;&#34;&#34;

    def __init__(
        self,
        size: int,
        size_swa: int,
        dtype: torch.dtype,
        head_num: int,
        head_dim: int,
        swa_attention_layer_ids: List[int],
        full_attention_layer_ids: List[int],
        enable_kvcache_transpose: bool,
        device: str,
    ):
        self.size = size
        self.size_swa = size_swa
        self.dtype = dtype
        self.device = device
        self.swa_layer_nums = len(swa_attention_layer_ids)
        self.full_layer_nums = len(full_attention_layer_ids)
        self.page_size = 1
        # TODO MHATransposedTokenToKVPool if enable_kvcache_transpose is True
        assert not enable_kvcache_transpose
        TokenToKVPoolClass = MHATokenToKVPool
        self.swa_kv_pool = TokenToKVPoolClass(
            size=size_swa,
            page_size=self.page_size,
            dtype=dtype,
            head_num=head_num,
            head_dim=head_dim,
            layer_num=self.swa_layer_nums,
            device=device,
            enable_memory_saver=False,
        )
        self.full_kv_pool = TokenToKVPoolClass(
            size=size,
            page_size=self.page_size,
            dtype=dtype,
            head_num=head_num,
            head_dim=head_dim,
            layer_num=self.full_layer_nums,
            device=device,
            enable_memory_saver=False,
        )
        self.layers_mapping: Dict[int, Tuple[int, bool]] = {}
        for full_attn_layer_id, global_layer_id in enumerate(full_attention_layer_ids):
            self.layers_mapping[global_layer_id] = (full_attn_layer_id, False)
        for swa_layer_id, global_layer_id in enumerate(swa_attention_layer_ids):
            self.layers_mapping[global_layer_id] = (swa_layer_id, True)
        self.full_to_swa_index_mapping: Optional[torch.Tensor] = None

        k_size, v_size = self.get_kv_size_bytes()
        self.mem_usage = (k_size + v_size) / GB

    def get_kv_size_bytes(self):
        k_size, v_size = self.full_kv_pool.get_kv_size_bytes()
        k_size_swa, v_size_swa = self.swa_kv_pool.get_kv_size_bytes()
        return k_size + k_size_swa, v_size + v_size_swa

    def get_contiguous_buf_infos(self):
        full_kv_data_ptrs, full_kv_data_lens, full_kv_item_lens = (
            self.full_kv_pool.get_contiguous_buf_infos()
        )
        swa_kv_data_ptrs, swa_kv_data_lens, swa_kv_item_lens = (
            self.swa_kv_pool.get_contiguous_buf_infos()
        )

        kv_data_ptrs = full_kv_data_ptrs + swa_kv_data_ptrs
        kv_data_lens = full_kv_data_lens + swa_kv_data_lens
        kv_item_lens = full_kv_item_lens + swa_kv_item_lens

        return kv_data_ptrs, kv_data_lens, kv_item_lens

    def get_key_buffer(self, layer_id: int):
        layer_id_pool, is_swa = self.layers_mapping[layer_id]
        if is_swa:
            return self.swa_kv_pool.get_key_buffer(layer_id_pool)
        else:
            return self.full_kv_pool.get_key_buffer(layer_id_pool)

    def get_value_buffer(self, layer_id: int):
        layer_id_pool, is_swa = self.layers_mapping[layer_id]
        if is_swa:
            return self.swa_kv_pool.get_value_buffer(layer_id_pool)
        else:
            return self.full_kv_pool.get_value_buffer(layer_id_pool)

    def get_kv_buffer(self, layer_id: int):
        layer_id_pool, is_swa = self.layers_mapping[layer_id]
        if is_swa:
            return self.swa_kv_pool.get_kv_buffer(layer_id_pool)
        else:
            return self.full_kv_pool.get_kv_buffer(layer_id_pool)

    def translate_loc_from_full_to_swa(self, kv_indices: torch.Tensor):
        assert self.full_to_swa_index_mapping is not None
        return self.full_to_swa_index_mapping[kv_indices].to(torch.int32)

    def set_kv_buffer(
        self,
        layer: RadixAttention,
        loc: torch.Tensor,
        cache_k: torch.Tensor,
        cache_v: torch.Tensor,
        k_scale: float = 1.0,
        v_scale: float = 1.0,
    ):

        layer_id = layer.layer_id
        layer_id_pool, is_swa = self.layers_mapping[layer_id]
        if is_swa:
            if self.full_to_swa_index_mapping is not None:
                loc = self.translate_loc_from_full_to_swa(loc)
            self.swa_kv_pool.set_kv_buffer(
                None,
                loc,
                cache_k,
                cache_v,
                k_scale,
                v_scale,
                layer_id_override=layer_id_pool,
            )
        else:
            self.full_kv_pool.set_kv_buffer(
                None,
                loc,
                cache_k,
                cache_v,
                k_scale,
                v_scale,
                layer_id_override=layer_id_pool,
            )</code></pre>
</details>
<div class="desc"><p>KV cache with separate pools for full and SWA attention layers.</p></div>
<h3>Ancestors</h3>
<ul class="hlist">
<li><a title="sglang.srt.mem_cache.memory_pool.KVCache" href="#sglang.srt.mem_cache.memory_pool.KVCache">KVCache</a></li>
<li>abc.ABC</li>
</ul>
<h3>Methods</h3>
<dl>
<dt id="sglang.srt.mem_cache.memory_pool.SWAKVPool.get_contiguous_buf_infos"><code class="name flex">
<span>def <span class="ident">get_contiguous_buf_infos</span></span>(<span>self)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_contiguous_buf_infos(self):
    full_kv_data_ptrs, full_kv_data_lens, full_kv_item_lens = (
        self.full_kv_pool.get_contiguous_buf_infos()
    )
    swa_kv_data_ptrs, swa_kv_data_lens, swa_kv_item_lens = (
        self.swa_kv_pool.get_contiguous_buf_infos()
    )

    kv_data_ptrs = full_kv_data_ptrs + swa_kv_data_ptrs
    kv_data_lens = full_kv_data_lens + swa_kv_data_lens
    kv_item_lens = full_kv_item_lens + swa_kv_item_lens

    return kv_data_ptrs, kv_data_lens, kv_item_lens</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="sglang.srt.mem_cache.memory_pool.SWAKVPool.get_key_buffer"><code class="name flex">
<span>def <span class="ident">get_key_buffer</span></span>(<span>self, layer_id: int)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_key_buffer(self, layer_id: int):
    layer_id_pool, is_swa = self.layers_mapping[layer_id]
    if is_swa:
        return self.swa_kv_pool.get_key_buffer(layer_id_pool)
    else:
        return self.full_kv_pool.get_key_buffer(layer_id_pool)</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="sglang.srt.mem_cache.memory_pool.SWAKVPool.get_kv_buffer"><code class="name flex">
<span>def <span class="ident">get_kv_buffer</span></span>(<span>self, layer_id: int)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_kv_buffer(self, layer_id: int):
    layer_id_pool, is_swa = self.layers_mapping[layer_id]
    if is_swa:
        return self.swa_kv_pool.get_kv_buffer(layer_id_pool)
    else:
        return self.full_kv_pool.get_kv_buffer(layer_id_pool)</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="sglang.srt.mem_cache.memory_pool.SWAKVPool.get_kv_size_bytes"><code class="name flex">
<span>def <span class="ident">get_kv_size_bytes</span></span>(<span>self)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_kv_size_bytes(self):
    k_size, v_size = self.full_kv_pool.get_kv_size_bytes()
    k_size_swa, v_size_swa = self.swa_kv_pool.get_kv_size_bytes()
    return k_size + k_size_swa, v_size + v_size_swa</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="sglang.srt.mem_cache.memory_pool.SWAKVPool.get_value_buffer"><code class="name flex">
<span>def <span class="ident">get_value_buffer</span></span>(<span>self, layer_id: int)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_value_buffer(self, layer_id: int):
    layer_id_pool, is_swa = self.layers_mapping[layer_id]
    if is_swa:
        return self.swa_kv_pool.get_value_buffer(layer_id_pool)
    else:
        return self.full_kv_pool.get_value_buffer(layer_id_pool)</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="sglang.srt.mem_cache.memory_pool.SWAKVPool.set_kv_buffer"><code class="name flex">
<span>def <span class="ident">set_kv_buffer</span></span>(<span>self,<br>layer: <a title="sglang.srt.layers.radix_attention.RadixAttention" href="../layers/radix_attention.html#sglang.srt.layers.radix_attention.RadixAttention">RadixAttention</a>,<br>loc: torch.Tensor,<br>cache_k: torch.Tensor,<br>cache_v: torch.Tensor,<br>k_scale: float = 1.0,<br>v_scale: float = 1.0)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def set_kv_buffer(
    self,
    layer: RadixAttention,
    loc: torch.Tensor,
    cache_k: torch.Tensor,
    cache_v: torch.Tensor,
    k_scale: float = 1.0,
    v_scale: float = 1.0,
):

    layer_id = layer.layer_id
    layer_id_pool, is_swa = self.layers_mapping[layer_id]
    if is_swa:
        if self.full_to_swa_index_mapping is not None:
            loc = self.translate_loc_from_full_to_swa(loc)
        self.swa_kv_pool.set_kv_buffer(
            None,
            loc,
            cache_k,
            cache_v,
            k_scale,
            v_scale,
            layer_id_override=layer_id_pool,
        )
    else:
        self.full_kv_pool.set_kv_buffer(
            None,
            loc,
            cache_k,
            cache_v,
            k_scale,
            v_scale,
            layer_id_override=layer_id_pool,
        )</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="sglang.srt.mem_cache.memory_pool.SWAKVPool.translate_loc_from_full_to_swa"><code class="name flex">
<span>def <span class="ident">translate_loc_from_full_to_swa</span></span>(<span>self, kv_indices: torch.Tensor)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def translate_loc_from_full_to_swa(self, kv_indices: torch.Tensor):
    assert self.full_to_swa_index_mapping is not None
    return self.full_to_swa_index_mapping[kv_indices].to(torch.int32)</code></pre>
</details>
<div class="desc"></div>
</dd>
</dl>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="sglang.srt.mem_cache" href="index.html">sglang.srt.mem_cache</a></code></li>
</ul>
</li>
<li><h3><a href="#header-functions">Functions</a></h3>
<ul class="">
<li><code><a title="sglang.srt.mem_cache.memory_pool.set_mla_kv_buffer_triton" href="#sglang.srt.mem_cache.memory_pool.set_mla_kv_buffer_triton">set_mla_kv_buffer_triton</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="sglang.srt.mem_cache.memory_pool.AscendMLAPagedTokenToKVPool" href="#sglang.srt.mem_cache.memory_pool.AscendMLAPagedTokenToKVPool">AscendMLAPagedTokenToKVPool</a></code></h4>
<ul class="">
<li><code><a title="sglang.srt.mem_cache.memory_pool.AscendMLAPagedTokenToKVPool.get_contiguous_buf_infos" href="#sglang.srt.mem_cache.memory_pool.AscendMLAPagedTokenToKVPool.get_contiguous_buf_infos">get_contiguous_buf_infos</a></code></li>
<li><code><a title="sglang.srt.mem_cache.memory_pool.AscendMLAPagedTokenToKVPool.get_key_buffer" href="#sglang.srt.mem_cache.memory_pool.AscendMLAPagedTokenToKVPool.get_key_buffer">get_key_buffer</a></code></li>
<li><code><a title="sglang.srt.mem_cache.memory_pool.AscendMLAPagedTokenToKVPool.get_kv_buffer" href="#sglang.srt.mem_cache.memory_pool.AscendMLAPagedTokenToKVPool.get_kv_buffer">get_kv_buffer</a></code></li>
<li><code><a title="sglang.srt.mem_cache.memory_pool.AscendMLAPagedTokenToKVPool.get_kv_size_bytes" href="#sglang.srt.mem_cache.memory_pool.AscendMLAPagedTokenToKVPool.get_kv_size_bytes">get_kv_size_bytes</a></code></li>
<li><code><a title="sglang.srt.mem_cache.memory_pool.AscendMLAPagedTokenToKVPool.get_value_buffer" href="#sglang.srt.mem_cache.memory_pool.AscendMLAPagedTokenToKVPool.get_value_buffer">get_value_buffer</a></code></li>
<li><code><a title="sglang.srt.mem_cache.memory_pool.AscendMLAPagedTokenToKVPool.set_kv_buffer" href="#sglang.srt.mem_cache.memory_pool.AscendMLAPagedTokenToKVPool.set_kv_buffer">set_kv_buffer</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="sglang.srt.mem_cache.memory_pool.AscendTokenToKVPool" href="#sglang.srt.mem_cache.memory_pool.AscendTokenToKVPool">AscendTokenToKVPool</a></code></h4>
<ul class="">
<li><code><a title="sglang.srt.mem_cache.memory_pool.AscendTokenToKVPool.get_contiguous_buf_infos" href="#sglang.srt.mem_cache.memory_pool.AscendTokenToKVPool.get_contiguous_buf_infos">get_contiguous_buf_infos</a></code></li>
<li><code><a title="sglang.srt.mem_cache.memory_pool.AscendTokenToKVPool.set_kv_buffer" href="#sglang.srt.mem_cache.memory_pool.AscendTokenToKVPool.set_kv_buffer">set_kv_buffer</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="sglang.srt.mem_cache.memory_pool.DoubleSparseTokenToKVPool" href="#sglang.srt.mem_cache.memory_pool.DoubleSparseTokenToKVPool">DoubleSparseTokenToKVPool</a></code></h4>
<ul class="">
<li><code><a title="sglang.srt.mem_cache.memory_pool.DoubleSparseTokenToKVPool.get_key_buffer" href="#sglang.srt.mem_cache.memory_pool.DoubleSparseTokenToKVPool.get_key_buffer">get_key_buffer</a></code></li>
<li><code><a title="sglang.srt.mem_cache.memory_pool.DoubleSparseTokenToKVPool.get_kv_buffer" href="#sglang.srt.mem_cache.memory_pool.DoubleSparseTokenToKVPool.get_kv_buffer">get_kv_buffer</a></code></li>
<li><code><a title="sglang.srt.mem_cache.memory_pool.DoubleSparseTokenToKVPool.get_label_buffer" href="#sglang.srt.mem_cache.memory_pool.DoubleSparseTokenToKVPool.get_label_buffer">get_label_buffer</a></code></li>
<li><code><a title="sglang.srt.mem_cache.memory_pool.DoubleSparseTokenToKVPool.get_value_buffer" href="#sglang.srt.mem_cache.memory_pool.DoubleSparseTokenToKVPool.get_value_buffer">get_value_buffer</a></code></li>
<li><code><a title="sglang.srt.mem_cache.memory_pool.DoubleSparseTokenToKVPool.set_kv_buffer" href="#sglang.srt.mem_cache.memory_pool.DoubleSparseTokenToKVPool.set_kv_buffer">set_kv_buffer</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="sglang.srt.mem_cache.memory_pool.KVCache" href="#sglang.srt.mem_cache.memory_pool.KVCache">KVCache</a></code></h4>
<ul class="">
<li><code><a title="sglang.srt.mem_cache.memory_pool.KVCache.get_cpu_copy" href="#sglang.srt.mem_cache.memory_pool.KVCache.get_cpu_copy">get_cpu_copy</a></code></li>
<li><code><a title="sglang.srt.mem_cache.memory_pool.KVCache.get_key_buffer" href="#sglang.srt.mem_cache.memory_pool.KVCache.get_key_buffer">get_key_buffer</a></code></li>
<li><code><a title="sglang.srt.mem_cache.memory_pool.KVCache.get_kv_buffer" href="#sglang.srt.mem_cache.memory_pool.KVCache.get_kv_buffer">get_kv_buffer</a></code></li>
<li><code><a title="sglang.srt.mem_cache.memory_pool.KVCache.get_value_buffer" href="#sglang.srt.mem_cache.memory_pool.KVCache.get_value_buffer">get_value_buffer</a></code></li>
<li><code><a title="sglang.srt.mem_cache.memory_pool.KVCache.load_cpu_copy" href="#sglang.srt.mem_cache.memory_pool.KVCache.load_cpu_copy">load_cpu_copy</a></code></li>
<li><code><a title="sglang.srt.mem_cache.memory_pool.KVCache.register_layer_transfer_counter" href="#sglang.srt.mem_cache.memory_pool.KVCache.register_layer_transfer_counter">register_layer_transfer_counter</a></code></li>
<li><code><a title="sglang.srt.mem_cache.memory_pool.KVCache.set_kv_buffer" href="#sglang.srt.mem_cache.memory_pool.KVCache.set_kv_buffer">set_kv_buffer</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="sglang.srt.mem_cache.memory_pool.MHATokenToKVPool" href="#sglang.srt.mem_cache.memory_pool.MHATokenToKVPool">MHATokenToKVPool</a></code></h4>
<ul class="">
<li><code><a title="sglang.srt.mem_cache.memory_pool.MHATokenToKVPool.get_contiguous_buf_infos" href="#sglang.srt.mem_cache.memory_pool.MHATokenToKVPool.get_contiguous_buf_infos">get_contiguous_buf_infos</a></code></li>
<li><code><a title="sglang.srt.mem_cache.memory_pool.MHATokenToKVPool.get_cpu_copy" href="#sglang.srt.mem_cache.memory_pool.MHATokenToKVPool.get_cpu_copy">get_cpu_copy</a></code></li>
<li><code><a title="sglang.srt.mem_cache.memory_pool.MHATokenToKVPool.get_key_buffer" href="#sglang.srt.mem_cache.memory_pool.MHATokenToKVPool.get_key_buffer">get_key_buffer</a></code></li>
<li><code><a title="sglang.srt.mem_cache.memory_pool.MHATokenToKVPool.get_kv_buffer" href="#sglang.srt.mem_cache.memory_pool.MHATokenToKVPool.get_kv_buffer">get_kv_buffer</a></code></li>
<li><code><a title="sglang.srt.mem_cache.memory_pool.MHATokenToKVPool.get_kv_size_bytes" href="#sglang.srt.mem_cache.memory_pool.MHATokenToKVPool.get_kv_size_bytes">get_kv_size_bytes</a></code></li>
<li><code><a title="sglang.srt.mem_cache.memory_pool.MHATokenToKVPool.get_value_buffer" href="#sglang.srt.mem_cache.memory_pool.MHATokenToKVPool.get_value_buffer">get_value_buffer</a></code></li>
<li><code><a title="sglang.srt.mem_cache.memory_pool.MHATokenToKVPool.load_cpu_copy" href="#sglang.srt.mem_cache.memory_pool.MHATokenToKVPool.load_cpu_copy">load_cpu_copy</a></code></li>
<li><code><a title="sglang.srt.mem_cache.memory_pool.MHATokenToKVPool.maybe_get_custom_mem_pool" href="#sglang.srt.mem_cache.memory_pool.MHATokenToKVPool.maybe_get_custom_mem_pool">maybe_get_custom_mem_pool</a></code></li>
<li><code><a title="sglang.srt.mem_cache.memory_pool.MHATokenToKVPool.move_kv_cache" href="#sglang.srt.mem_cache.memory_pool.MHATokenToKVPool.move_kv_cache">move_kv_cache</a></code></li>
<li><code><a title="sglang.srt.mem_cache.memory_pool.MHATokenToKVPool.set_kv_buffer" href="#sglang.srt.mem_cache.memory_pool.MHATokenToKVPool.set_kv_buffer">set_kv_buffer</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="sglang.srt.mem_cache.memory_pool.MLATokenToKVPool" href="#sglang.srt.mem_cache.memory_pool.MLATokenToKVPool">MLATokenToKVPool</a></code></h4>
<ul class="">
<li><code><a title="sglang.srt.mem_cache.memory_pool.MLATokenToKVPool.get_contiguous_buf_infos" href="#sglang.srt.mem_cache.memory_pool.MLATokenToKVPool.get_contiguous_buf_infos">get_contiguous_buf_infos</a></code></li>
<li><code><a title="sglang.srt.mem_cache.memory_pool.MLATokenToKVPool.get_cpu_copy" href="#sglang.srt.mem_cache.memory_pool.MLATokenToKVPool.get_cpu_copy">get_cpu_copy</a></code></li>
<li><code><a title="sglang.srt.mem_cache.memory_pool.MLATokenToKVPool.get_key_buffer" href="#sglang.srt.mem_cache.memory_pool.MLATokenToKVPool.get_key_buffer">get_key_buffer</a></code></li>
<li><code><a title="sglang.srt.mem_cache.memory_pool.MLATokenToKVPool.get_kv_buffer" href="#sglang.srt.mem_cache.memory_pool.MLATokenToKVPool.get_kv_buffer">get_kv_buffer</a></code></li>
<li><code><a title="sglang.srt.mem_cache.memory_pool.MLATokenToKVPool.get_kv_size_bytes" href="#sglang.srt.mem_cache.memory_pool.MLATokenToKVPool.get_kv_size_bytes">get_kv_size_bytes</a></code></li>
<li><code><a title="sglang.srt.mem_cache.memory_pool.MLATokenToKVPool.get_value_buffer" href="#sglang.srt.mem_cache.memory_pool.MLATokenToKVPool.get_value_buffer">get_value_buffer</a></code></li>
<li><code><a title="sglang.srt.mem_cache.memory_pool.MLATokenToKVPool.load_cpu_copy" href="#sglang.srt.mem_cache.memory_pool.MLATokenToKVPool.load_cpu_copy">load_cpu_copy</a></code></li>
<li><code><a title="sglang.srt.mem_cache.memory_pool.MLATokenToKVPool.maybe_get_custom_mem_pool" href="#sglang.srt.mem_cache.memory_pool.MLATokenToKVPool.maybe_get_custom_mem_pool">maybe_get_custom_mem_pool</a></code></li>
<li><code><a title="sglang.srt.mem_cache.memory_pool.MLATokenToKVPool.set_kv_buffer" href="#sglang.srt.mem_cache.memory_pool.MLATokenToKVPool.set_kv_buffer">set_kv_buffer</a></code></li>
<li><code><a title="sglang.srt.mem_cache.memory_pool.MLATokenToKVPool.set_mla_kv_buffer" href="#sglang.srt.mem_cache.memory_pool.MLATokenToKVPool.set_mla_kv_buffer">set_mla_kv_buffer</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="sglang.srt.mem_cache.memory_pool.ReqToTokenPool" href="#sglang.srt.mem_cache.memory_pool.ReqToTokenPool">ReqToTokenPool</a></code></h4>
<ul class="">
<li><code><a title="sglang.srt.mem_cache.memory_pool.ReqToTokenPool.alloc" href="#sglang.srt.mem_cache.memory_pool.ReqToTokenPool.alloc">alloc</a></code></li>
<li><code><a title="sglang.srt.mem_cache.memory_pool.ReqToTokenPool.available_size" href="#sglang.srt.mem_cache.memory_pool.ReqToTokenPool.available_size">available_size</a></code></li>
<li><code><a title="sglang.srt.mem_cache.memory_pool.ReqToTokenPool.clear" href="#sglang.srt.mem_cache.memory_pool.ReqToTokenPool.clear">clear</a></code></li>
<li><code><a title="sglang.srt.mem_cache.memory_pool.ReqToTokenPool.free" href="#sglang.srt.mem_cache.memory_pool.ReqToTokenPool.free">free</a></code></li>
<li><code><a title="sglang.srt.mem_cache.memory_pool.ReqToTokenPool.write" href="#sglang.srt.mem_cache.memory_pool.ReqToTokenPool.write">write</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="sglang.srt.mem_cache.memory_pool.SWAKVPool" href="#sglang.srt.mem_cache.memory_pool.SWAKVPool">SWAKVPool</a></code></h4>
<ul class="">
<li><code><a title="sglang.srt.mem_cache.memory_pool.SWAKVPool.get_contiguous_buf_infos" href="#sglang.srt.mem_cache.memory_pool.SWAKVPool.get_contiguous_buf_infos">get_contiguous_buf_infos</a></code></li>
<li><code><a title="sglang.srt.mem_cache.memory_pool.SWAKVPool.get_key_buffer" href="#sglang.srt.mem_cache.memory_pool.SWAKVPool.get_key_buffer">get_key_buffer</a></code></li>
<li><code><a title="sglang.srt.mem_cache.memory_pool.SWAKVPool.get_kv_buffer" href="#sglang.srt.mem_cache.memory_pool.SWAKVPool.get_kv_buffer">get_kv_buffer</a></code></li>
<li><code><a title="sglang.srt.mem_cache.memory_pool.SWAKVPool.get_kv_size_bytes" href="#sglang.srt.mem_cache.memory_pool.SWAKVPool.get_kv_size_bytes">get_kv_size_bytes</a></code></li>
<li><code><a title="sglang.srt.mem_cache.memory_pool.SWAKVPool.get_value_buffer" href="#sglang.srt.mem_cache.memory_pool.SWAKVPool.get_value_buffer">get_value_buffer</a></code></li>
<li><code><a title="sglang.srt.mem_cache.memory_pool.SWAKVPool.set_kv_buffer" href="#sglang.srt.mem_cache.memory_pool.SWAKVPool.set_kv_buffer">set_kv_buffer</a></code></li>
<li><code><a title="sglang.srt.mem_cache.memory_pool.SWAKVPool.translate_loc_from_full_to_swa" href="#sglang.srt.mem_cache.memory_pool.SWAKVPool.translate_loc_from_full_to_swa">translate_loc_from_full_to_swa</a></code></li>
</ul>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc" title="pdoc: Python API documentation generator"><cite>pdoc</cite> 0.11.6</a>.</p>
</footer>
</body>
</html>
