<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1">
<meta name="generator" content="pdoc3 0.11.6">
<title>sglang.srt.disaggregation.mooncake.conn API documentation</title>
<meta name="description" content="">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/13.0.0/sanitize.min.css" integrity="sha512-y1dtMcuvtTMJc1yPgEqF0ZjQbhnc/bFhyvIyVNb9Zk5mIGtqVaAB1Ttl28su8AvFMOY0EwRbAe+HCLqj6W7/KA==" crossorigin>
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/13.0.0/typography.min.css" integrity="sha512-Y1DYSb995BAfxobCkKepB1BqJJTPrOp3zPL74AWFugHHmmdcvO+C48WLrUOlhGMc0QG7AE3f7gmvvcrmX2fDoA==" crossorigin>
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/styles/default.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:1.5em;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:2em 0 .50em 0}h3{font-size:1.4em;margin:1.6em 0 .7em 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .2s ease-in-out}a:visited{color:#503}a:hover{color:#b62}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900;font-weight:bold}pre code{font-size:.8em;line-height:1.4em;padding:1em;display:block}code{background:#f3f3f3;font-family:"DejaVu Sans Mono",monospace;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source > summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible;min-width:max-content}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em 1em;margin:1em 0}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul ul{padding-left:1em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/highlight.min.js" integrity="sha512-D9gUyxqja7hBtkWpPWGt9wfbfaMGVt9gnyCvYa+jojwwPHLCzUm5i8rpk7vD7wNee9bA35eYIjobYPaQuKS1MQ==" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => {
hljs.configure({languages: ['bash', 'css', 'diff', 'graphql', 'ini', 'javascript', 'json', 'plaintext', 'python', 'python-repl', 'rust', 'shell', 'sql', 'typescript', 'xml', 'yaml']});
hljs.highlightAll();
/* Collapse source docstrings */
setTimeout(() => {
[...document.querySelectorAll('.hljs.language-python > .hljs-string')]
.filter(el => el.innerHTML.length > 200 && ['"""', "'''"].includes(el.innerHTML.substring(0, 3)))
.forEach(el => {
let d = document.createElement('details');
d.classList.add('hljs-string');
d.innerHTML = '<summary>"""</summary>' + el.innerHTML.substring(3);
el.replaceWith(d);
});
}, 100);
})</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>sglang.srt.disaggregation.mooncake.conn</code></h1>
</header>
<section id="section-intro">
</section>
<section>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="sglang.srt.disaggregation.mooncake.conn.AuxDataCodec"><code class="flex name class">
<span>class <span class="ident">AuxDataCodec</span></span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class AuxDataCodec:
    &#34;&#34;&#34;Handles serialization and deserialization of auxiliary data buffers&#34;&#34;&#34;

    @staticmethod
    def serialize_data_from_buffer(src_addr, data_length):
        &#34;&#34;&#34;Serialize data from memory buffer to bytes&#34;&#34;&#34;
        buffer = (ctypes.c_byte * data_length).from_address(src_addr)
        return bytes(buffer)

    @staticmethod
    def deserialize_data_to_buffer(kv_args, buffer_index, aux_index, data):
        &#34;&#34;&#34;Deserialize bytes into target memory buffer&#34;&#34;&#34;
        dst_aux_ptr = kv_args.aux_data_ptrs[buffer_index]
        item_len = kv_args.aux_item_lens[buffer_index]
        dst_addr = dst_aux_ptr + item_len * aux_index
        buffer = (ctypes.c_byte * len(data)).from_address(dst_addr)
        buffer[:] = data
        return</code></pre>
</details>
<div class="desc"><p>Handles serialization and deserialization of auxiliary data buffers</p></div>
<h3>Static methods</h3>
<dl>
<dt id="sglang.srt.disaggregation.mooncake.conn.AuxDataCodec.deserialize_data_to_buffer"><code class="name flex">
<span>def <span class="ident">deserialize_data_to_buffer</span></span>(<span>kv_args, buffer_index, aux_index, data)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@staticmethod
def deserialize_data_to_buffer(kv_args, buffer_index, aux_index, data):
    &#34;&#34;&#34;Deserialize bytes into target memory buffer&#34;&#34;&#34;
    dst_aux_ptr = kv_args.aux_data_ptrs[buffer_index]
    item_len = kv_args.aux_item_lens[buffer_index]
    dst_addr = dst_aux_ptr + item_len * aux_index
    buffer = (ctypes.c_byte * len(data)).from_address(dst_addr)
    buffer[:] = data
    return</code></pre>
</details>
<div class="desc"><p>Deserialize bytes into target memory buffer</p></div>
</dd>
<dt id="sglang.srt.disaggregation.mooncake.conn.AuxDataCodec.serialize_data_from_buffer"><code class="name flex">
<span>def <span class="ident">serialize_data_from_buffer</span></span>(<span>src_addr, data_length)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@staticmethod
def serialize_data_from_buffer(src_addr, data_length):
    &#34;&#34;&#34;Serialize data from memory buffer to bytes&#34;&#34;&#34;
    buffer = (ctypes.c_byte * data_length).from_address(src_addr)
    return bytes(buffer)</code></pre>
</details>
<div class="desc"><p>Serialize data from memory buffer to bytes</p></div>
</dd>
</dl>
</dd>
<dt id="sglang.srt.disaggregation.mooncake.conn.KVArgsRegisterInfo"><code class="flex name class">
<span>class <span class="ident">KVArgsRegisterInfo</span></span>
<span>(</span><span>room: str,<br>endpoint: str,<br>dst_port: int,<br>mooncake_session_id: str,<br>dst_kv_ptrs: list[int],<br>dst_aux_ptrs: list[int],<br>dst_tp_rank: int,<br>dst_attn_tp_size: int,<br>dst_kv_item_len: int)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@dataclasses.dataclass
class KVArgsRegisterInfo:
    room: str
    endpoint: str
    dst_port: int
    mooncake_session_id: str
    dst_kv_ptrs: list[int]
    dst_aux_ptrs: list[int]
    dst_tp_rank: int
    dst_attn_tp_size: int
    dst_kv_item_len: int

    @classmethod
    def from_zmq(cls, msg: List[bytes]):
        return cls(
            room=str(msg[0].decode(&#34;ascii&#34;)),
            endpoint=msg[1].decode(&#34;ascii&#34;),
            dst_port=int(msg[2].decode(&#34;ascii&#34;)),
            mooncake_session_id=msg[3].decode(&#34;ascii&#34;),
            dst_kv_ptrs=list(struct.unpack(f&#34;{len(msg[4])//8}Q&#34;, msg[4])),
            dst_aux_ptrs=list(struct.unpack(f&#34;{len(msg[5])//8}Q&#34;, msg[5])),
            dst_tp_rank=int(msg[6].decode(&#34;ascii&#34;)),
            dst_attn_tp_size=int(msg[7].decode(&#34;ascii&#34;)),
            dst_kv_item_len=int(msg[8].decode(&#34;ascii&#34;)),
        )</code></pre>
</details>
<div class="desc"><p>KVArgsRegisterInfo(room: 'str', endpoint: 'str', dst_port: 'int', mooncake_session_id: 'str', dst_kv_ptrs: 'list[int]', dst_aux_ptrs: 'list[int]', dst_tp_rank: 'int', dst_attn_tp_size: 'int', dst_kv_item_len: 'int')</p></div>
<h3>Static methods</h3>
<dl>
<dt id="sglang.srt.disaggregation.mooncake.conn.KVArgsRegisterInfo.from_zmq"><code class="name flex">
<span>def <span class="ident">from_zmq</span></span>(<span>msg: List[bytes])</span>
</code></dt>
<dd>
<div class="desc"></div>
</dd>
</dl>
<h3>Instance variables</h3>
<dl>
<dt id="sglang.srt.disaggregation.mooncake.conn.KVArgsRegisterInfo.dst_attn_tp_size"><code class="name">var <span class="ident">dst_attn_tp_size</span> : int</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="sglang.srt.disaggregation.mooncake.conn.KVArgsRegisterInfo.dst_aux_ptrs"><code class="name">var <span class="ident">dst_aux_ptrs</span> : list[int]</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="sglang.srt.disaggregation.mooncake.conn.KVArgsRegisterInfo.dst_kv_item_len"><code class="name">var <span class="ident">dst_kv_item_len</span> : int</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="sglang.srt.disaggregation.mooncake.conn.KVArgsRegisterInfo.dst_kv_ptrs"><code class="name">var <span class="ident">dst_kv_ptrs</span> : list[int]</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="sglang.srt.disaggregation.mooncake.conn.KVArgsRegisterInfo.dst_port"><code class="name">var <span class="ident">dst_port</span> : int</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="sglang.srt.disaggregation.mooncake.conn.KVArgsRegisterInfo.dst_tp_rank"><code class="name">var <span class="ident">dst_tp_rank</span> : int</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="sglang.srt.disaggregation.mooncake.conn.KVArgsRegisterInfo.endpoint"><code class="name">var <span class="ident">endpoint</span> : str</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="sglang.srt.disaggregation.mooncake.conn.KVArgsRegisterInfo.mooncake_session_id"><code class="name">var <span class="ident">mooncake_session_id</span> : str</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="sglang.srt.disaggregation.mooncake.conn.KVArgsRegisterInfo.room"><code class="name">var <span class="ident">room</span> : str</code></dt>
<dd>
<div class="desc"></div>
</dd>
</dl>
</dd>
<dt id="sglang.srt.disaggregation.mooncake.conn.KVTransferError"><code class="flex name class">
<span>class <span class="ident">KVTransferError</span></span>
<span>(</span><span>bootstrap_room: int, failure_reason: str)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class KVTransferError(Exception):
    def __init__(self, bootstrap_room: int, failure_reason: str):
        super().__init__(failure_reason)
        self.bootstrap_room = bootstrap_room
        self.failure_reason = failure_reason

    def __str__(self):
        return f&#34;KVTransferError(bootstrap_room={self.bootstrap_room}): {self.failure_reason}&#34;</code></pre>
</details>
<div class="desc"><p>Common base class for all non-exit exceptions.</p></div>
<h3>Ancestors</h3>
<ul class="hlist">
<li>builtins.Exception</li>
<li>builtins.BaseException</li>
</ul>
</dd>
<dt id="sglang.srt.disaggregation.mooncake.conn.MooncakeKVBootstrapServer"><code class="flex name class">
<span>class <span class="ident">MooncakeKVBootstrapServer</span></span>
<span>(</span><span>port: int)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class MooncakeKVBootstrapServer(BaseKVBootstrapServer):
    def __init__(self, port: int):
        self.port = port
        self.app = web.Application()
        self.store = dict()
        self.lock = asyncio.Lock()
        self._setup_routes()
        self.pp_size = None
        self.attn_tp_size = None
        self.dp_size = None
        self.prefill_port_table: Dict[
            int, Dict[int, Dict[int, Dict[str, Union[str, int]]]]
        ] = {}

        # Start bootstrap server
        self.thread = threading.Thread(target=self._run_server, daemon=True)
        self.run()

    def run(self):
        self.thread.start()

    def _setup_routes(self):
        self.app.router.add_route(&#34;*&#34;, &#34;/route&#34;, self._handle_route)
        self.app.router.add_get(&#34;/health&#34;, self._handle_health_check)

    async def _handle_health_check(self, request):
        return web.Response(text=&#34;OK&#34;, status=200)

    async def _handle_route(self, request: web.Request):
        method = request.method
        if method == &#34;PUT&#34;:
            return await self._handle_route_put(request)
        elif method == &#34;GET&#34;:
            return await self._handle_route_get(request)
        else:
            return web.Response(
                text=&#34;Method not allowed&#34;, status=405, content_type=&#34;application/json&#34;
            )

    async def _handle_route_put(self, request: web.Request):
        data = await request.json()
        role = data[&#34;role&#34;]
        attn_tp_size = data[&#34;attn_tp_size&#34;]
        attn_tp_rank = data[&#34;attn_tp_rank&#34;]
        attn_dp_size = data[&#34;attn_dp_size&#34;]
        attn_dp_rank = data[&#34;attn_dp_rank&#34;]
        pp_size = data[&#34;pp_size&#34;]
        pp_rank = data[&#34;pp_rank&#34;]
        system_dp_size = data[&#34;system_dp_size&#34;]
        system_dp_rank = data[&#34;system_dp_rank&#34;]
        rank_ip = data[&#34;rank_ip&#34;]
        rank_port = int(data[&#34;rank_port&#34;])

        if self.attn_tp_size is None:
            self.attn_tp_size = attn_tp_size

        if self.dp_size is None:
            self.dp_size = attn_dp_size if system_dp_size == 1 else system_dp_size

        if self.pp_size is None:
            self.pp_size = pp_size

        if role == &#34;Prefill&#34;:
            if system_dp_size == 1:
                dp_group = attn_dp_rank
            else:
                dp_group = system_dp_rank

            # Add lock to make sure thread-safe
            async with self.lock:
                if dp_group not in self.prefill_port_table:
                    self.prefill_port_table[dp_group] = {}
                if attn_tp_rank not in self.prefill_port_table[dp_group]:
                    self.prefill_port_table[dp_group][attn_tp_rank] = {}

            self.prefill_port_table[dp_group][attn_tp_rank][pp_rank] = {
                &#34;rank_ip&#34;: rank_ip,
                &#34;rank_port&#34;: rank_port,
            }
            logger.debug(
                f&#34;Register prefill bootstrap: DP{dp_group} TP{attn_tp_rank} PP{pp_rank} with rank_ip: {rank_ip} and rank_port: {rank_port}&#34;
            )

        return web.Response(text=&#34;OK&#34;, status=200)

    async def _handle_route_get(self, request: web.Request):
        engine_rank = request.query.get(&#34;engine_rank&#34;)
        target_dp_group = request.query.get(&#34;target_dp_group&#34;)
        target_pp_rank = request.query.get(&#34;target_pp_rank&#34;)
        if not engine_rank or not target_dp_group or not target_pp_rank:
            return web.Response(text=&#34;Missing inputs for bootstrap server.&#34;, status=400)

        # Currently we use engine_rank == -1 and target_dp_group == -1 to sync dp size
        if (
            int(engine_rank) == -1
            and int(target_dp_group) == -1
            and int(target_pp_rank) == -1
        ):
            prefill_parallel_info = {
                &#34;prefill_attn_tp_size&#34;: self.attn_tp_size,
                &#34;prefill_dp_size&#34;: self.dp_size,
                &#34;prefill_pp_size&#34;: self.pp_size,
            }
            return web.json_response(prefill_parallel_info, status=200)

        # Find corresponding prefill info
        async with self.lock:
            bootstrap_info = self.prefill_port_table[int(target_dp_group)][
                int(engine_rank)
            ][int(target_pp_rank)]

        if bootstrap_info is not None:
            return web.json_response(bootstrap_info, status=200)
        else:
            return web.Response(text=&#34;Bootstrap info not Found&#34;, status=404)

    def _run_server(self):
        try:
            # Event Loop
            self._loop = asyncio.new_event_loop()
            asyncio.set_event_loop(self._loop)

            access_log = None
            if logging.getLogger(__name__).getEffectiveLevel() &lt;= logging.DEBUG:
                access_log = self.app.logger

            self._runner = web.AppRunner(self.app, access_log=access_log)
            self._loop.run_until_complete(self._runner.setup())

            site = web.TCPSite(self._runner, port=self.port)
            self._loop.run_until_complete(site.start())
            self._loop.run_forever()
        except Exception as e:
            logger.error(f&#34;Server error: {str(e)}&#34;)
        finally:
            # Cleanup
            self._loop.run_until_complete(self._runner.cleanup())
            self._loop.close()

    def close(self):
        &#34;&#34;&#34;Shutdown&#34;&#34;&#34;
        if self._loop is not None and self._loop.is_running():
            self._loop.call_soon_threadsafe(self._loop.stop)
            logger.info(&#34;Stopping server loop...&#34;)

        if self.thread.is_alive():
            self.thread.join(timeout=2)
            logger.info(&#34;Server thread stopped&#34;)

    def poll(self) -&gt; KVPoll: ...</code></pre>
</details>
<div class="desc"><p>Helper class that provides a standard way to create an ABC using
inheritance.</p></div>
<h3>Ancestors</h3>
<ul class="hlist">
<li><a title="sglang.srt.disaggregation.base.conn.BaseKVBootstrapServer" href="../base/conn.html#sglang.srt.disaggregation.base.conn.BaseKVBootstrapServer">BaseKVBootstrapServer</a></li>
<li>abc.ABC</li>
</ul>
<h3>Subclasses</h3>
<ul class="hlist">
<li><a title="sglang.srt.disaggregation.ascend.conn.AscendKVBootstrapServer" href="../ascend/conn.html#sglang.srt.disaggregation.ascend.conn.AscendKVBootstrapServer">AscendKVBootstrapServer</a></li>
</ul>
<h3>Methods</h3>
<dl>
<dt id="sglang.srt.disaggregation.mooncake.conn.MooncakeKVBootstrapServer.close"><code class="name flex">
<span>def <span class="ident">close</span></span>(<span>self)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def close(self):
    &#34;&#34;&#34;Shutdown&#34;&#34;&#34;
    if self._loop is not None and self._loop.is_running():
        self._loop.call_soon_threadsafe(self._loop.stop)
        logger.info(&#34;Stopping server loop...&#34;)

    if self.thread.is_alive():
        self.thread.join(timeout=2)
        logger.info(&#34;Server thread stopped&#34;)</code></pre>
</details>
<div class="desc"><p>Shutdown</p></div>
</dd>
<dt id="sglang.srt.disaggregation.mooncake.conn.MooncakeKVBootstrapServer.poll"><code class="name flex">
<span>def <span class="ident">poll</span></span>(<span>self) ‑> <a title="sglang.srt.disaggregation.base.conn.KVPoll" href="../base/conn.html#sglang.srt.disaggregation.base.conn.KVPoll">KVPoll</a></span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def poll(self) -&gt; KVPoll: ...</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="sglang.srt.disaggregation.mooncake.conn.MooncakeKVBootstrapServer.run"><code class="name flex">
<span>def <span class="ident">run</span></span>(<span>self)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def run(self):
    self.thread.start()</code></pre>
</details>
<div class="desc"></div>
</dd>
</dl>
</dd>
<dt id="sglang.srt.disaggregation.mooncake.conn.MooncakeKVManager"><code class="flex name class">
<span>class <span class="ident">MooncakeKVManager</span></span>
<span>(</span><span>args: KVArgs,<br>disaggregation_mode: DisaggregationMode,<br>server_args: ServerArgs,<br>is_mla_backend: Optional[bool] = False)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class MooncakeKVManager(BaseKVManager):
    AUX_DATA_HEADER = b&#34;AUX_DATA&#34;

    def __init__(
        self,
        args: KVArgs,
        disaggregation_mode: DisaggregationMode,
        server_args: ServerArgs,
        is_mla_backend: Optional[bool] = False,
    ):
        self.kv_args = args
        self.local_ip = get_local_ip_auto()
        self.is_mla_backend = is_mla_backend
        self.disaggregation_mode = disaggregation_mode
        self.init_engine()
        # for p/d multi node infer
        self.bootstrap_port = server_args.disaggregation_bootstrap_port
        self.dist_init_addr = server_args.dist_init_addr
        self.attn_tp_size = get_attention_tp_size()
        self.attn_tp_rank = get_attention_tp_rank()
        self.attn_dp_size = get_attention_dp_size()
        self.attn_dp_rank = get_attention_dp_rank()
        self.system_dp_size = (
            1 if server_args.enable_dp_attention else server_args.dp_size
        )
        self.system_dp_rank = (
            self.kv_args.system_dp_rank if self.kv_args.system_dp_rank else 0
        )
        self.pp_size = server_args.pp_size
        self.pp_rank = self.kv_args.pp_rank
        self.request_status: Dict[int, KVPoll] = {}
        self.rank_port = None
        self.server_socket = zmq.Context().socket(zmq.PULL)
        if is_valid_ipv6_address(self.local_ip):
            self.server_socket.setsockopt(zmq.IPV6, 1)

        self.register_buffer_to_engine()
        if self.disaggregation_mode == DisaggregationMode.PREFILL:
            self.transfer_infos: Dict[int, Dict[str, TransferInfo]] = {}
            self.decode_kv_args_table: Dict[str, KVArgsRegisterInfo] = {}
            self.start_prefill_thread()
            self._register_to_bootstrap()
            self.session_failures = defaultdict(int)
            self.failed_sessions = set()
            self.session_lock = threading.Lock()
            self.pp_group = get_pp_group()
            # Determine the number of threads to use for kv sender
            cpu_count = os.cpu_count()
            transfer_thread_pool_size = get_int_env_var(
                &#34;SGLANG_DISAGGREGATION_THREAD_POOL_SIZE&#34;,
                min(max(4, int(0.75 * cpu_count) // 8), 12),
            )
            transfer_queue_size = get_int_env_var(&#34;SGLANG_DISAGGREGATION_QUEUE_SIZE&#34;, 4)
            self.transfer_queues: List[FastQueue] = [
                FastQueue() for _ in range(transfer_queue_size)
            ]
            assert transfer_thread_pool_size &gt;= transfer_queue_size, (
                f&#34;The environment variable SGLANG_DISAGGREGATION_THREAD_POOL_SIZE={transfer_thread_pool_size} must be &#34;
                f&#34;greater than or equal to SGLANG_DISAGGREGATION_QUEUE_SIZE={transfer_queue_size}.&#34;
            )
            self.executors = [
                concurrent.futures.ThreadPoolExecutor(
                    transfer_thread_pool_size // transfer_queue_size
                )
                for _ in range(transfer_queue_size)
            ]
            for queue, executor in zip(self.transfer_queues, self.executors):
                threading.Thread(
                    target=self.transfer_worker, args=(queue, executor), daemon=True
                ).start()
            # If a timeout happens on the prefill side, it means prefill instances
            # fail to receive the KV indices from the decode instance of this request.
            # These timeout requests should be aborted to release the tree cache.
            self.bootstrap_timeout = get_int_env_var(
                &#34;SGLANG_DISAGGREGATION_BOOTSTRAP_TIMEOUT&#34;, 300
            )

            self.enable_custom_mem_pool = get_bool_env_var(
                &#34;SGLANG_MOONCAKE_CUSTOM_MEM_POOL&#34;, &#34;false&#34;
            )
        elif self.disaggregation_mode == DisaggregationMode.DECODE:
            self.heartbeat_failures = {}
            self.session_pool = defaultdict(requests.Session)
            self.session_pool_lock = threading.Lock()
            self.addr_to_rooms_tracker = defaultdict(set)
            self.connection_lock = threading.Lock()
            self.required_prefill_response_num_table: Dict[int, int] = {}
            self.prefill_response_tracker: Dict[int, Set[int]] = defaultdict(set)
            # Heartbeat interval should be at least 2 seconds
            self.heartbeat_interval = max(
                float(os.getenv(&#34;SGLANG_DISAGGREGATION_HEARTBEAT_INTERVAL&#34;, 5.0)), 2.0
            )
            # Heartbeat failure should be at least 1
            self.max_failures = max(
                get_int_env_var(&#34;SGLANG_DISAGGREGATION_HEARTBEAT_MAX_FAILURE&#34;, 2), 1
            )
            self.start_decode_thread()
            self.connection_pool: Dict[str, Dict[str, Union[str, int]]] = {}
            self.prefill_attn_tp_size_table: Dict[str, int] = {}
            self.prefill_dp_size_table: Dict[str, int] = {}
            self.prefill_pp_size_table: Dict[str, int] = {}
            # If a timeout happens on the decode side, it means decode instances
            # fail to receive the KV Cache transfer done signal after bootstrapping.
            # These timeout requests should be aborted to release the tree cache.
            self.waiting_timeout = get_int_env_var(
                &#34;SGLANG_DISAGGREGATION_WAITING_TIMEOUT&#34;, 300
            )
        else:
            raise ValueError(
                f&#34;Unsupported DisaggregationMode: {self.disaggregation_mode}&#34;
            )

        self.failure_records: Dict[int, str] = {}
        self.failure_lock = threading.Lock()

    def init_engine(self):
        self.engine = MooncakeTransferEngine(
            hostname=self.local_ip,
            gpu_id=self.kv_args.gpu_id,
            ib_device=self.kv_args.ib_device,
        )

    def register_buffer_to_engine(self):
        # Batch register KV data buffers
        if self.kv_args.kv_data_ptrs and self.kv_args.kv_data_lens:
            self.engine.batch_register(
                self.kv_args.kv_data_ptrs, self.kv_args.kv_data_lens
            )

        # Batch register auxiliary data buffers
        if self.kv_args.aux_data_ptrs and self.kv_args.aux_data_lens:
            self.engine.batch_register(
                self.kv_args.aux_data_ptrs, self.kv_args.aux_data_lens
            )

    @cache
    def _connect(self, endpoint: str, is_ipv6: bool = False):
        socket = zmq.Context().socket(zmq.PUSH)
        if is_ipv6:
            socket.setsockopt(zmq.IPV6, 1)
        socket.connect(endpoint)
        return socket

    def _transfer_data(self, mooncake_session_id, transfer_blocks):
        if not transfer_blocks:
            return 0

        src_addrs, dst_addrs, lengths = zip(*transfer_blocks)
        return self.engine.batch_transfer_sync(
            mooncake_session_id, list(src_addrs), list(dst_addrs), list(lengths)
        )

    def send_kvcache(
        self,
        mooncake_session_id: str,
        prefill_kv_indices: npt.NDArray[np.int32],
        dst_kv_ptrs: list[int],
        dst_kv_indices: npt.NDArray[np.int32],
        executor: concurrent.futures.ThreadPoolExecutor,
    ):
        # Group by indices
        prefill_kv_blocks, dst_kv_blocks = group_concurrent_contiguous(
            prefill_kv_indices, dst_kv_indices
        )

        layers_params = None

        # pp is not supported on the decode side yet
        start_layer = self.kv_args.prefill_start_layer
        end_layer = start_layer + len(self.kv_args.kv_data_ptrs)
        if self.is_mla_backend:
            src_kv_ptrs = self.kv_args.kv_data_ptrs
            layers_per_pp_stage = len(src_kv_ptrs)
            dst_kv_ptrs = dst_kv_ptrs[start_layer:end_layer]
            kv_item_len = self.kv_args.kv_item_lens[0]
            layers_params = [
                (
                    src_kv_ptrs[layer_id],
                    dst_kv_ptrs[layer_id],
                    kv_item_len,
                )
                for layer_id in range(layers_per_pp_stage)
            ]
        else:
            num_kv_layers = len(self.kv_args.kv_data_ptrs) // 2
            dst_num_total_layers = num_kv_layers * self.pp_size
            src_k_ptrs = self.kv_args.kv_data_ptrs[:num_kv_layers]
            src_v_ptrs = self.kv_args.kv_data_ptrs[num_kv_layers:]
            layers_per_pp_stage = len(src_k_ptrs)
            dst_k_ptrs = dst_kv_ptrs[start_layer:end_layer]
            dst_v_ptrs = dst_kv_ptrs[
                dst_num_total_layers + start_layer : dst_num_total_layers + end_layer
            ]
            kv_item_len = self.kv_args.kv_item_lens[0]
            layers_params = [
                (
                    src_k_ptrs[layer_id],
                    dst_k_ptrs[layer_id],
                    kv_item_len,
                )
                for layer_id in range(layers_per_pp_stage)
            ] + [
                (
                    src_v_ptrs[layer_id],
                    dst_v_ptrs[layer_id],
                    kv_item_len,
                )
                for layer_id in range(layers_per_pp_stage)
            ]
        assert layers_params is not None

        def set_transfer_blocks(
            src_ptr: int, dst_ptr: int, item_len: int
        ) -&gt; List[Tuple[int, int, int]]:
            transfer_blocks = []
            for prefill_index, decode_index in zip(prefill_kv_blocks, dst_kv_blocks):
                src_addr = src_ptr + int(prefill_index[0]) * item_len
                dst_addr = dst_ptr + int(decode_index[0]) * item_len
                length = item_len * len(prefill_index)
                transfer_blocks.append((src_addr, dst_addr, length))
            return transfer_blocks

        # Worker function for processing a single layer
        def process_layer(src_ptr: int, dst_ptr: int, item_len: int) -&gt; int:
            transfer_blocks = set_transfer_blocks(src_ptr, dst_ptr, item_len)
            return self._transfer_data(mooncake_session_id, transfer_blocks)

        # Worker function for processing all layers in a batch
        def process_layers(layers_params: List[Tuple[int, int, int]]) -&gt; int:
            transfer_blocks = []
            for src_ptr, dst_ptr, item_len in layers_params:
                transfer_blocks.extend(set_transfer_blocks(src_ptr, dst_ptr, item_len))
            return self._transfer_data(mooncake_session_id, transfer_blocks)

        if self.enable_custom_mem_pool:
            futures = [
                executor.submit(
                    process_layer,
                    src_ptr,
                    dst_ptr,
                    item_len,
                )
                for (src_ptr, dst_ptr, item_len) in layers_params
            ]
            for future in concurrent.futures.as_completed(futures):
                status = future.result()
                if status != 0:
                    for f in futures:
                        f.cancel()
                    return status
        else:
            # Combining all layers&#39; params in one batch transfer is more efficient
            # compared to using multiple threads
            return process_layers(layers_params)

        return 0

    def send_kvcache_slice(
        self,
        mooncake_session_id: str,
        prefill_kv_indices: npt.NDArray[np.int64],
        dst_kv_ptrs: list[int],
        dst_kv_indices: npt.NDArray[np.int64],
        dst_tp_rank: int,
        dst_attn_tp_size: int,
        dst_kv_item_len: int,
        executor: concurrent.futures.ThreadPoolExecutor,
    ):
        &#34;&#34;&#34;
        Sends KV cache slices from this Prefill rank to a target Decode rank,
        supporting generic M-to-N TP size configurations.

        NOTE: This implementation calls the transfer engine for each token slot within
        each page to ensure correctness for any page_size and head-slicing configuration.
        This may introduce performance overhead (increased TTFT) for long sequences.
        &#34;&#34;&#34;
        # Extract configuration
        local_tp_rank_in_group = self.kv_args.engine_rank % self.attn_tp_size
        src_kv_item_len = self.kv_args.kv_item_lens[0]
        dst_tp_rank_in_group = dst_tp_rank % dst_attn_tp_size
        num_kv_heads = self.kv_args.kv_head_num
        num_layers = len(self.kv_args.kv_data_ptrs)
        page_size = self.kv_args.page_size

        # Calculate head distribution
        src_heads_per_rank = num_kv_heads
        dst_heads_per_rank = num_kv_heads * self.attn_tp_size // dst_attn_tp_size
        bytes_per_head_slice_to_send = (
            dst_kv_item_len // page_size // dst_heads_per_rank
        )

        # Determine slicing parameters based on TP configuration
        if self.attn_tp_size &gt; dst_attn_tp_size:
            # Send KVCache from multiple prefill instances to 1 decode instance
            src_head_start_offset = 0
            num_heads_to_send = src_heads_per_rank
            dst_head_start_offset = local_tp_rank_in_group * src_heads_per_rank
        else:
            # Send KVCache from 1 prefill instance to multiple decode instances
            src_head_start_offset = dst_tp_rank_in_group * dst_heads_per_rank
            num_heads_to_send = dst_heads_per_rank
            dst_head_start_offset = 0

        # pp is not supported on the decode side yet
        num_kv_layers = len(self.kv_args.kv_data_ptrs) // 2
        dst_num_total_layers = num_kv_layers * self.pp_size
        src_k_ptrs = self.kv_args.kv_data_ptrs[:num_kv_layers]
        src_v_ptrs = self.kv_args.kv_data_ptrs[num_kv_layers:]
        layers_per_pp_stage = len(src_k_ptrs)
        start_layer = self.pp_rank * layers_per_pp_stage
        end_layer = start_layer + layers_per_pp_stage
        dst_k_ptrs = dst_kv_ptrs[start_layer:end_layer]
        dst_v_ptrs = dst_kv_ptrs[
            dst_num_total_layers + start_layer : dst_num_total_layers + end_layer
        ]

        # Calculate precise byte offset and length for the sub-slice within the token
        src_head_slice_offset = src_head_start_offset * bytes_per_head_slice_to_send
        dst_head_slice_offset = dst_head_start_offset * bytes_per_head_slice_to_send
        heads_bytes_per_token_to_send = num_heads_to_send * bytes_per_head_slice_to_send

        # Sanity check: The data sub-slice to be sent should fit into the dst buffer.
        # This means heads_bytes_per_token_to_send &lt;= (dst_kv_item_len // page_size)
        if heads_bytes_per_token_to_send &gt; (dst_kv_item_len // page_size):
            logger.error(
                f&#34;[{mooncake_session_id}] slice size ({heads_bytes_per_token_to_send}) exceeds &#34;
                f&#34;target token slot size ({dst_kv_item_len // page_size})&#34;
            )
            return -1

        layers_params = [
            (
                src_k_ptrs[layer_id],
                dst_k_ptrs[layer_id],
                src_kv_item_len,
                dst_kv_item_len,
                src_head_slice_offset,
                dst_head_slice_offset,
                heads_bytes_per_token_to_send,
            )
            for layer_id in range(layers_per_pp_stage)
        ] + [
            (
                src_v_ptrs[layer_id],
                dst_v_ptrs[layer_id],
                src_kv_item_len,
                dst_kv_item_len,
                src_head_slice_offset,
                dst_head_slice_offset,
                heads_bytes_per_token_to_send,
            )
            for layer_id in range(layers_per_pp_stage)
        ]

        def process_layer_tp_aware(layer_params):
            (
                src_ptr,
                dst_ptr,
                src_item_len,
                dst_item_len,
                src_head_slice_offset,
                dst_head_slice_offset,
                heads_bytes_per_token_to_send,
            ) = layer_params
            src_addr_list = []
            dst_addr_list = []
            length_list = []

            # Calculate strides for a single token slot
            bytes_per_token_on_prefill = src_item_len // page_size
            bytes_per_token_on_decode = dst_item_len // page_size

            for i in range(len(prefill_kv_indices)):
                prefill_page_idx = int(prefill_kv_indices[i])
                decode_page_idx = int(dst_kv_indices[i])

                # Get the starting addresses for the current src and dst pages
                src_page_start_addr = src_ptr + prefill_page_idx * src_item_len
                dst_page_start_addr = dst_ptr + decode_page_idx * dst_item_len

                # Iterate through each valid token slot within the current page
                for token_slot_in_page in range(page_size):
                    # Calculate the start address of the current token slot
                    src_token_slot_start_addr = (
                        src_page_start_addr
                        + token_slot_in_page * bytes_per_token_on_prefill
                    )
                    dst_token_slot_start_addr = (
                        dst_page_start_addr
                        + token_slot_in_page * bytes_per_token_on_decode
                    )

                    # Calculate final src and dst addresses by applying head-slice offsets
                    src_slice_addr = src_token_slot_start_addr + src_head_slice_offset
                    dst_slice_addr = dst_token_slot_start_addr + dst_head_slice_offset

                    src_addr_list.append(src_slice_addr)
                    dst_addr_list.append(dst_slice_addr)
                    length_list.append(heads_bytes_per_token_to_send)

            return self.engine.batch_transfer_sync(
                mooncake_session_id, src_addr_list, dst_addr_list, length_list
            )

        futures = [
            executor.submit(
                process_layer_tp_aware,
                layer_params,
            )
            for layer_params in layers_params
        ]

        for future in concurrent.futures.as_completed(futures):
            status = future.result()
            if status != 0:
                for f in futures:
                    f.cancel()
                return status

        return 0

    def send_aux(
        self,
        req: TransferInfo,
        prefill_aux_index: int,
        dst_aux_ptrs: list[int],
    ):
        # TODO(shangming): Fix me when nvlink_transport of Mooncake is bug-free
        if self.enable_custom_mem_pool:
            return self.send_aux_tcp(req, prefill_aux_index, dst_aux_ptrs)

        transfer_blocks = []
        prefill_aux_ptrs = self.kv_args.aux_data_ptrs
        prefill_aux_item_lens = self.kv_args.aux_item_lens

        for i, dst_aux_ptr in enumerate(dst_aux_ptrs):
            length = prefill_aux_item_lens[i]
            src_addr = prefill_aux_ptrs[i] + length * prefill_aux_index
            dst_addr = dst_aux_ptrs[i] + length * req.dst_aux_index
            transfer_blocks.append((src_addr, dst_addr, length))

        return self._transfer_data(req.mooncake_session_id, transfer_blocks)

    def send_aux_tcp(
        self,
        req: TransferInfo,
        prefill_aux_index: int,
        dst_aux_ptrs: list[int],
    ):
        prefill_aux_ptrs = self.kv_args.aux_data_ptrs
        prefill_aux_item_lens = self.kv_args.aux_item_lens

        for i in range(len(prefill_aux_ptrs)):
            length = prefill_aux_item_lens[i]
            src_addr = prefill_aux_ptrs[i] + length * prefill_aux_index
            data = AuxDataCodec.serialize_data_from_buffer(src_addr, length)

            self.send_aux_data_to_endpoint(
                remote=req.endpoint,
                dst_port=req.dst_port,
                room=req.room,
                buffer_index=i,
                aux_index=req.dst_aux_index,
                data=data,
            )

        return 0

    def send_aux_data_to_endpoint(
        self,
        remote: str,
        dst_port: int,
        room: int,
        buffer_index: int,
        aux_index: int,
        data: bytes,
    ):
        socket = self._connect(
            format_tcp_address(remote, dst_port), is_ipv6=is_valid_ipv6_address(remote)
        )

        socket.send_multipart(
            [
                MooncakeKVManager.AUX_DATA_HEADER,
                str(room).encode(&#34;ascii&#34;),
                str(buffer_index).encode(&#34;ascii&#34;),
                str(aux_index).encode(&#34;ascii&#34;),
                struct.pack(&#34;&gt;I&#34;, len(data)),
                data,
            ]
        )

    def sync_status_to_decode_endpoint(
        self, remote: str, dst_port: int, room: int, status: int, prefill_rank: int
    ):
        self._connect(
            format_tcp_address(remote, dst_port), is_ipv6=is_valid_ipv6_address(remote)
        ).send_multipart(
            [
                str(room).encode(&#34;ascii&#34;),
                str(status).encode(&#34;ascii&#34;),
                str(prefill_rank).encode(&#34;ascii&#34;),
            ]
        )

    def transfer_worker(
        self, queue: FastQueue, executor: concurrent.futures.ThreadPoolExecutor
    ):
        while True:
            try:
                kv_chunk: TransferKVChunk = queue.get()
                reqs_to_be_processed = (
                    self.transfer_infos[kv_chunk.room].values()
                    if kv_chunk.room in self.transfer_infos
                    else []
                )
                polls = []
                dst_ranks_infos = []
                local_rank = self.attn_tp_rank * self.pp_size + self.pp_rank
                for req in reqs_to_be_processed:
                    if not req.is_dummy:
                        # Early exit if the request has failed
                        with self.session_lock:
                            if req.mooncake_session_id in self.failed_sessions:
                                self.record_failure(
                                    kv_chunk.room,
                                    f&#34;Decode instance could be dead, remote mooncake session {req.mooncake_session_id} is not alive&#34;,
                                )
                                self.update_status(kv_chunk.room, KVPoll.Failed)
                                self.sync_status_to_decode_endpoint(
                                    req.endpoint,
                                    req.dst_port,
                                    req.room,
                                    KVPoll.Failed,
                                    local_rank,
                                )
                                break

                        chunked_dst_kv_indice = req.dst_kv_indices[kv_chunk.index_slice]

                        # NOTE: This is temporarily a workaround to deal with the case where the prefill_kv_indices
                        # is mismatched with the dst_kv_indices when page size &gt; 1, this should never happen.
                        if len(chunked_dst_kv_indice) &lt; len(
                            kv_chunk.prefill_kv_indices
                        ):
                            logger.warning(
                                f&#34;len(chunked_dst_kv_indice) = {len(chunked_dst_kv_indice)}, len(kv_chunk.prefill_kv_indices) = {len(kv_chunk.prefill_kv_indices)}&#34;
                            )
                            kv_chunk.prefill_kv_indices = kv_chunk.prefill_kv_indices[
                                : len(chunked_dst_kv_indice)
                            ]

                        target_rank_registration_info: KVArgsRegisterInfo = (
                            self.decode_kv_args_table[req.mooncake_session_id]
                        )
                        if self.is_mla_backend or (
                            self.attn_tp_size
                            == target_rank_registration_info.dst_attn_tp_size
                        ):
                            ret = self.send_kvcache(
                                req.mooncake_session_id,
                                kv_chunk.prefill_kv_indices,
                                target_rank_registration_info.dst_kv_ptrs,
                                chunked_dst_kv_indice,
                                executor,
                            )
                        else:
                            ret = self.send_kvcache_slice(
                                req.mooncake_session_id,
                                kv_chunk.prefill_kv_indices,
                                target_rank_registration_info.dst_kv_ptrs,
                                chunked_dst_kv_indice,
                                target_rank_registration_info.dst_tp_rank,
                                target_rank_registration_info.dst_attn_tp_size,
                                target_rank_registration_info.dst_kv_item_len,
                                executor,
                            )
                        if ret != 0:
                            with self.session_lock:
                                self.session_failures[req.mooncake_session_id] += 1
                                # Failures should never happen if the session is not dead, if the session fails once, mark it as failed
                                if self.session_failures[req.mooncake_session_id] &gt;= 1:
                                    self.failed_sessions.add(req.mooncake_session_id)
                                    logger.error(
                                        f&#34;Session {req.mooncake_session_id} failed.&#34;
                                    )
                            self.record_failure(
                                kv_chunk.room,
                                f&#34;Failed to send kv chunk of {kv_chunk.room} to {req.endpoint}:{req.dst_port}&#34;,
                            )
                            self.update_status(kv_chunk.room, KVPoll.Failed)
                            self.sync_status_to_decode_endpoint(
                                req.endpoint,
                                req.dst_port,
                                req.room,
                                KVPoll.Failed,
                                local_rank,
                            )
                            break

                        if kv_chunk.is_last:
                            if self.pp_group.is_last_rank:
                                # Only the last chunk we need to send the aux data
                                ret = self.send_aux(
                                    req,
                                    kv_chunk.prefill_aux_index,
                                    target_rank_registration_info.dst_aux_ptrs,
                                )
                            polls.append(True if ret == 0 else False)
                            dst_ranks_infos.append(
                                (req.endpoint, req.dst_port, req.room)
                            )

                            # Only sync status when all the dst ranks have received the kvcache
                            if len(polls) == req.required_dst_info_num:
                                status = KVPoll.Success if all(polls) else KVPoll.Failed
                                self.update_status(req.room, status)
                                for endpoint, dst_port, room in dst_ranks_infos:
                                    self.sync_status_to_decode_endpoint(
                                        endpoint, dst_port, room, status, local_rank
                                    )
                    else:
                        # Dummy request means the decode instance is not used, so its status can be marked as success directly
                        # Dummy request does not need to sync status to decode endpoint
                        if kv_chunk.is_last and req.room in self.request_status:
                            self.update_status(req.room, KVPoll.Success)

                if (
                    kv_chunk.room not in self.request_status
                    or self.check_status(kv_chunk.room) == KVPoll.Success
                ):
                    if kv_chunk.room in self.transfer_infos:
                        self.transfer_infos.pop(kv_chunk.room)

            except Exception as e:
                # NOTE(shangming): Remove this when we make sure the transfer thread is bug-free
                raise RuntimeError(
                    f&#34;Transfer thread failed because of {e}. Prefill instance with bootstrap_port={self.bootstrap_port} is dead.&#34;
                )

    def _bind_server_socket(self):
        self.server_socket.bind(format_tcp_address(self.local_ip, self.rank_port))

    def start_prefill_thread(self):
        self.rank_port = get_free_port()
        self._bind_server_socket()

        def bootstrap_thread():
            &#34;&#34;&#34;This thread recvs pre-alloc notification from the decode engine&#34;&#34;&#34;
            # KVPoll.Bootstrapping -&gt; KVPoll.WaitingForInput
            while True:
                waiting_req_bytes = self.server_socket.recv_multipart()
                room = waiting_req_bytes[0].decode(&#34;ascii&#34;)
                mooncake_session_id = waiting_req_bytes[3].decode(&#34;ascii&#34;)
                if room == &#34;None&#34;:
                    self.decode_kv_args_table[mooncake_session_id] = (
                        KVArgsRegisterInfo.from_zmq(waiting_req_bytes)
                    )
                    with self.session_lock:
                        if mooncake_session_id in self.failed_sessions:
                            self.failed_sessions.remove(mooncake_session_id)
                        if mooncake_session_id in self.session_failures:
                            del self.session_failures[mooncake_session_id]
                    logger.debug(
                        f&#34;Register KVArgs from {mooncake_session_id} successfully&#34;
                    )
                    continue
                else:
                    required_dst_info_num = int(waiting_req_bytes[6].decode(&#34;ascii&#34;))
                    room = int(room)
                    if room not in self.transfer_infos:
                        self.transfer_infos[room] = {}

                    self.transfer_infos[room][mooncake_session_id] = (
                        TransferInfo.from_zmq(waiting_req_bytes)
                    )
                    # NOTE: after bootstrapping we can mark the req as waiting for input
                    if len(self.transfer_infos[room]) == required_dst_info_num:
                        self.update_status(room, KVPoll.WaitingForInput)

        threading.Thread(target=bootstrap_thread).start()

    def _handle_aux_data(self, msg: List[bytes]):
        &#34;&#34;&#34;Handle AUX_DATA messages received by the decode thread.&#34;&#34;&#34;
        room = int(msg[1].decode(&#34;ascii&#34;))
        buffer_index = int(msg[2].decode(&#34;ascii&#34;))
        aux_index = int(msg[3].decode(&#34;ascii&#34;))
        data_length = struct.unpack(&#34;&gt;I&#34;, msg[4])[0]
        data = msg[5]

        if len(data) != data_length:
            logger.error(f&#34;AUX_DATA length mismatch for bootstrap_room {room}&#34;)
            return

        AuxDataCodec.deserialize_data_to_buffer(
            self.kv_args, buffer_index, aux_index, data
        )

        logger.debug(
            f&#34;Received AUX_DATA for bootstrap_room {room} with length:{len(data)}&#34;
        )

    def start_decode_thread(self):
        self.rank_port = get_free_port()
        self._bind_server_socket()

        def decode_thread():
            while True:
                msg = self.server_socket.recv_multipart()
                if msg[0] == MooncakeKVManager.AUX_DATA_HEADER:
                    self._handle_aux_data(msg)
                    continue

                (bootstrap_room, status, prefill_rank) = msg
                status = int(status.decode(&#34;ascii&#34;))
                bootstrap_room = int(bootstrap_room.decode(&#34;ascii&#34;))
                prefill_rank = int(prefill_rank.decode(&#34;ascii&#34;))

                if status == KVPoll.Success:
                    if bootstrap_room in self.request_status:
                        self.prefill_response_tracker[bootstrap_room].add(prefill_rank)
                        expected_response_num = (
                            self.required_prefill_response_num_table[bootstrap_room]
                        )
                        arrived_response_num = len(
                            self.prefill_response_tracker[bootstrap_room]
                        )
                        if arrived_response_num == expected_response_num:
                            self.update_status(bootstrap_room, KVPoll.Success)
                elif status == KVPoll.Failed:
                    self.record_failure(
                        bootstrap_room,
                        f&#34;Failed to get kvcache from prefill instance, it might be dead&#34;,
                    )
                    self.update_status(bootstrap_room, status)

        def heartbeat_checker():
            while True:
                time.sleep(self.heartbeat_interval)
                with self.connection_lock:
                    addresses = list(self.prefill_dp_size_table.keys())

                for bootstrap_addr in addresses:
                    session = None
                    try:
                        with self.session_pool_lock:
                            session = self.session_pool[bootstrap_addr]
                        response = session.get(
                            f&#34;http://{bootstrap_addr}/health&#34;,
                            timeout=(2, 3),
                            headers={&#34;Connection&#34;: &#34;keep-alive&#34;},
                        )
                        if response.status_code == 200:
                            self.heartbeat_failures[bootstrap_addr] = 0

                            current_rooms = self.addr_to_rooms_tracker[
                                bootstrap_addr
                            ].copy()

                            for bootstrap_room in current_rooms:
                                # Remove KVPoll.Success requests from the tracker
                                if bootstrap_room not in self.request_status:
                                    self.addr_to_rooms_tracker[bootstrap_addr].discard(
                                        bootstrap_room
                                    )
                        else:
                            logger.info(
                                f&#34;Attempting to reconnect to {bootstrap_addr}...&#34;
                            )
                            self.heartbeat_failures[bootstrap_addr] = (
                                self.heartbeat_failures.get(bootstrap_addr, 0) + 1
                            )
                            with self.session_pool_lock:
                                if bootstrap_addr in self.session_pool:
                                    del self.session_pool[bootstrap_addr]
                    except Exception:
                        logger.info(f&#34;Attempting to reconnect to {bootstrap_addr}...&#34;)
                        self.heartbeat_failures[bootstrap_addr] = (
                            self.heartbeat_failures.get(bootstrap_addr, 0) + 1
                        )

                    if (
                        self.heartbeat_failures.get(bootstrap_addr, 0)
                        &gt;= self.max_failures
                    ):
                        self._handle_node_failure(bootstrap_addr)
                        with self.session_pool_lock:
                            if bootstrap_addr in self.session_pool:
                                del self.session_pool[bootstrap_addr]

        threading.Thread(target=decode_thread).start()
        threading.Thread(target=heartbeat_checker).start()

    def add_transfer_request(
        self,
        bootstrap_room: int,
        kv_indices: npt.NDArray[np.int32],
        index_slice: slice,
        is_last: bool,
        aux_index: Optional[int] = None,
    ):
        assert self.disaggregation_mode == DisaggregationMode.PREFILL
        assert not is_last or (is_last and aux_index is not None)

        if (
            bootstrap_room not in self.request_status
            or self.check_status(bootstrap_room) == KVPoll.Failed
        ):
            logger.debug(
                &#34;Request with bootstrap_room=%s already failed&#34;, bootstrap_room
            )
            return

        if bootstrap_room not in self.transfer_infos:
            # This means that the current rank is a dummy rank for this request,
            # and it has already been marked as success, so there is no need to
            # add further chunks into the transfer queue.
            return

        # NOTE(shangming): sharding according to the dst_infos to make sure
        # requests with the same dst_sessions will be added into the same
        # queue, which enables early abort with failed sessions.
        dst_infos = self.transfer_infos[bootstrap_room].keys()
        session_port_sum = sum(int(session.rsplit(&#34;:&#34;, 1)[1]) for session in dst_infos)
        shard_idx = session_port_sum % len(self.transfer_queues)

        self.transfer_queues[shard_idx].put(
            TransferKVChunk(
                room=bootstrap_room,
                prefill_kv_indices=kv_indices,
                index_slice=index_slice,
                is_last=is_last,
                prefill_aux_index=aux_index,
            )
        )

    def check_status(self, bootstrap_room: int):
        return self.request_status[bootstrap_room]

    def update_status(self, bootstrap_room: int, status: KVPoll):
        if bootstrap_room not in self.request_status:
            self.request_status[bootstrap_room] = status
        else:
            # NOTE: status is only allowed to be incremented unless it is KVPoll.Failed
            if status == KVPoll.Failed:
                self.request_status[bootstrap_room] = KVPoll.Failed
            else:
                self.request_status[bootstrap_room] = max(
                    self.request_status[bootstrap_room], status
                )

    def record_failure(self, bootstrap_room: int, failure_reason: str):
        with self.failure_lock:
            self.failure_records[bootstrap_room] = failure_reason

    def get_session_id(self):
        return self.engine.get_session_id()

    def _register_to_bootstrap(self):
        &#34;&#34;&#34;Register KVSender to bootstrap server via HTTP POST.&#34;&#34;&#34;
        if self.dist_init_addr:
            if self.dist_init_addr.startswith(&#34;[&#34;):  # [ipv6]:port or [ipv6]
                if self.dist_init_addr.endswith(&#34;]&#34;):
                    host = self.dist_init_addr
                else:
                    host, _ = self.dist_init_addr.rsplit(&#34;:&#34;, 1)
            else:
                host = socket.gethostbyname(self.dist_init_addr.rsplit(&#34;:&#34;, 1)[0])
        else:
            host = get_ip()
            host = maybe_wrap_ipv6_address(host)

        bootstrap_server_url = f&#34;{host}:{self.bootstrap_port}&#34;
        url = f&#34;http://{bootstrap_server_url}/route&#34;
        payload = {
            &#34;role&#34;: &#34;Prefill&#34;,
            &#34;attn_tp_size&#34;: self.attn_tp_size,
            &#34;attn_tp_rank&#34;: self.attn_tp_rank,
            &#34;attn_dp_size&#34;: self.attn_dp_size,
            &#34;attn_dp_rank&#34;: self.attn_dp_rank,
            &#34;pp_size&#34;: self.pp_size,
            &#34;pp_rank&#34;: self.pp_rank,
            &#34;system_dp_size&#34;: self.system_dp_size,
            &#34;system_dp_rank&#34;: self.system_dp_rank,
            &#34;rank_ip&#34;: self.local_ip,
            &#34;rank_port&#34;: self.rank_port,
        }

        try:
            response = requests.put(url, json=payload, timeout=5)
            if response.status_code == 200:
                logger.debug(&#34;Prefill successfully registered to bootstrap server.&#34;)
            else:
                logger.error(
                    f&#34;Prefill instance failed to connect to bootstrap server: {response.status_code}, {response.text}&#34;
                )
        except Exception as e:
            logger.error(
                f&#34;Prefill instance failed to register to bootstrap server: {e}&#34;
            )

    def _handle_node_failure(self, failed_bootstrap_addr):
        with self.connection_lock:
            keys_to_remove = [
                k for k in self.connection_pool if k.startswith(failed_bootstrap_addr)
            ]
            for k in keys_to_remove:
                del self.connection_pool[k]
            if failed_bootstrap_addr in self.prefill_attn_tp_size_table:
                del self.prefill_attn_tp_size_table[failed_bootstrap_addr]
            if failed_bootstrap_addr in self.prefill_dp_size_table:
                del self.prefill_dp_size_table[failed_bootstrap_addr]
            if failed_bootstrap_addr in self.prefill_pp_size_table:
                del self.prefill_pp_size_table[failed_bootstrap_addr]

            possible_affected_rooms = self.addr_to_rooms_tracker.get(
                failed_bootstrap_addr, []
            )
            if failed_bootstrap_addr in self.addr_to_rooms_tracker:
                del self.addr_to_rooms_tracker[failed_bootstrap_addr]

        # Report the requests associated with the failed bootstrap addr and mark their status as KVPoll.Failed
        affected_rooms = []
        for room in possible_affected_rooms:
            if (
                room in self.request_status
                and self.check_status(room) != KVPoll.Success
            ):
                self.record_failure(
                    room,
                    f&#34;Losing connection with prefill instance (bootstrap_addr: {failed_bootstrap_addr})&#34;,
                )
                self.update_status(room, KVPoll.Failed)
                affected_rooms.append(room)
        logger.error(
            f&#34;Losing connection with prefill instance (bootstrap_addr: {failed_bootstrap_addr}), {len(affected_rooms)} requests affected&#34;
        )</code></pre>
</details>
<div class="desc"><p>Base class for managing transfers states</p></div>
<h3>Ancestors</h3>
<ul class="hlist">
<li><a title="sglang.srt.disaggregation.base.conn.BaseKVManager" href="../base/conn.html#sglang.srt.disaggregation.base.conn.BaseKVManager">BaseKVManager</a></li>
<li>abc.ABC</li>
</ul>
<h3>Subclasses</h3>
<ul class="hlist">
<li><a title="sglang.srt.disaggregation.ascend.conn.AscendKVManager" href="../ascend/conn.html#sglang.srt.disaggregation.ascend.conn.AscendKVManager">AscendKVManager</a></li>
</ul>
<h3>Class variables</h3>
<dl>
<dt id="sglang.srt.disaggregation.mooncake.conn.MooncakeKVManager.AUX_DATA_HEADER"><code class="name">var <span class="ident">AUX_DATA_HEADER</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
</dl>
<h3>Methods</h3>
<dl>
<dt id="sglang.srt.disaggregation.mooncake.conn.MooncakeKVManager.add_transfer_request"><code class="name flex">
<span>def <span class="ident">add_transfer_request</span></span>(<span>self,<br>bootstrap_room: int,<br>kv_indices: npt.NDArray[np.int32],<br>index_slice: slice,<br>is_last: bool,<br>aux_index: Optional[int] = None)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def add_transfer_request(
    self,
    bootstrap_room: int,
    kv_indices: npt.NDArray[np.int32],
    index_slice: slice,
    is_last: bool,
    aux_index: Optional[int] = None,
):
    assert self.disaggregation_mode == DisaggregationMode.PREFILL
    assert not is_last or (is_last and aux_index is not None)

    if (
        bootstrap_room not in self.request_status
        or self.check_status(bootstrap_room) == KVPoll.Failed
    ):
        logger.debug(
            &#34;Request with bootstrap_room=%s already failed&#34;, bootstrap_room
        )
        return

    if bootstrap_room not in self.transfer_infos:
        # This means that the current rank is a dummy rank for this request,
        # and it has already been marked as success, so there is no need to
        # add further chunks into the transfer queue.
        return

    # NOTE(shangming): sharding according to the dst_infos to make sure
    # requests with the same dst_sessions will be added into the same
    # queue, which enables early abort with failed sessions.
    dst_infos = self.transfer_infos[bootstrap_room].keys()
    session_port_sum = sum(int(session.rsplit(&#34;:&#34;, 1)[1]) for session in dst_infos)
    shard_idx = session_port_sum % len(self.transfer_queues)

    self.transfer_queues[shard_idx].put(
        TransferKVChunk(
            room=bootstrap_room,
            prefill_kv_indices=kv_indices,
            index_slice=index_slice,
            is_last=is_last,
            prefill_aux_index=aux_index,
        )
    )</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="sglang.srt.disaggregation.mooncake.conn.MooncakeKVManager.check_status"><code class="name flex">
<span>def <span class="ident">check_status</span></span>(<span>self, bootstrap_room: int)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def check_status(self, bootstrap_room: int):
    return self.request_status[bootstrap_room]</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="sglang.srt.disaggregation.mooncake.conn.MooncakeKVManager.get_session_id"><code class="name flex">
<span>def <span class="ident">get_session_id</span></span>(<span>self)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_session_id(self):
    return self.engine.get_session_id()</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="sglang.srt.disaggregation.mooncake.conn.MooncakeKVManager.init_engine"><code class="name flex">
<span>def <span class="ident">init_engine</span></span>(<span>self)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def init_engine(self):
    self.engine = MooncakeTransferEngine(
        hostname=self.local_ip,
        gpu_id=self.kv_args.gpu_id,
        ib_device=self.kv_args.ib_device,
    )</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="sglang.srt.disaggregation.mooncake.conn.MooncakeKVManager.record_failure"><code class="name flex">
<span>def <span class="ident">record_failure</span></span>(<span>self, bootstrap_room: int, failure_reason: str)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def record_failure(self, bootstrap_room: int, failure_reason: str):
    with self.failure_lock:
        self.failure_records[bootstrap_room] = failure_reason</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="sglang.srt.disaggregation.mooncake.conn.MooncakeKVManager.register_buffer_to_engine"><code class="name flex">
<span>def <span class="ident">register_buffer_to_engine</span></span>(<span>self)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def register_buffer_to_engine(self):
    # Batch register KV data buffers
    if self.kv_args.kv_data_ptrs and self.kv_args.kv_data_lens:
        self.engine.batch_register(
            self.kv_args.kv_data_ptrs, self.kv_args.kv_data_lens
        )

    # Batch register auxiliary data buffers
    if self.kv_args.aux_data_ptrs and self.kv_args.aux_data_lens:
        self.engine.batch_register(
            self.kv_args.aux_data_ptrs, self.kv_args.aux_data_lens
        )</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="sglang.srt.disaggregation.mooncake.conn.MooncakeKVManager.send_aux"><code class="name flex">
<span>def <span class="ident">send_aux</span></span>(<span>self,<br>req: <a title="sglang.srt.disaggregation.mooncake.conn.TransferInfo" href="#sglang.srt.disaggregation.mooncake.conn.TransferInfo">TransferInfo</a>,<br>prefill_aux_index: int,<br>dst_aux_ptrs: list[int])</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def send_aux(
    self,
    req: TransferInfo,
    prefill_aux_index: int,
    dst_aux_ptrs: list[int],
):
    # TODO(shangming): Fix me when nvlink_transport of Mooncake is bug-free
    if self.enable_custom_mem_pool:
        return self.send_aux_tcp(req, prefill_aux_index, dst_aux_ptrs)

    transfer_blocks = []
    prefill_aux_ptrs = self.kv_args.aux_data_ptrs
    prefill_aux_item_lens = self.kv_args.aux_item_lens

    for i, dst_aux_ptr in enumerate(dst_aux_ptrs):
        length = prefill_aux_item_lens[i]
        src_addr = prefill_aux_ptrs[i] + length * prefill_aux_index
        dst_addr = dst_aux_ptrs[i] + length * req.dst_aux_index
        transfer_blocks.append((src_addr, dst_addr, length))

    return self._transfer_data(req.mooncake_session_id, transfer_blocks)</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="sglang.srt.disaggregation.mooncake.conn.MooncakeKVManager.send_aux_data_to_endpoint"><code class="name flex">
<span>def <span class="ident">send_aux_data_to_endpoint</span></span>(<span>self,<br>remote: str,<br>dst_port: int,<br>room: int,<br>buffer_index: int,<br>aux_index: int,<br>data: bytes)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def send_aux_data_to_endpoint(
    self,
    remote: str,
    dst_port: int,
    room: int,
    buffer_index: int,
    aux_index: int,
    data: bytes,
):
    socket = self._connect(
        format_tcp_address(remote, dst_port), is_ipv6=is_valid_ipv6_address(remote)
    )

    socket.send_multipart(
        [
            MooncakeKVManager.AUX_DATA_HEADER,
            str(room).encode(&#34;ascii&#34;),
            str(buffer_index).encode(&#34;ascii&#34;),
            str(aux_index).encode(&#34;ascii&#34;),
            struct.pack(&#34;&gt;I&#34;, len(data)),
            data,
        ]
    )</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="sglang.srt.disaggregation.mooncake.conn.MooncakeKVManager.send_aux_tcp"><code class="name flex">
<span>def <span class="ident">send_aux_tcp</span></span>(<span>self,<br>req: <a title="sglang.srt.disaggregation.mooncake.conn.TransferInfo" href="#sglang.srt.disaggregation.mooncake.conn.TransferInfo">TransferInfo</a>,<br>prefill_aux_index: int,<br>dst_aux_ptrs: list[int])</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def send_aux_tcp(
    self,
    req: TransferInfo,
    prefill_aux_index: int,
    dst_aux_ptrs: list[int],
):
    prefill_aux_ptrs = self.kv_args.aux_data_ptrs
    prefill_aux_item_lens = self.kv_args.aux_item_lens

    for i in range(len(prefill_aux_ptrs)):
        length = prefill_aux_item_lens[i]
        src_addr = prefill_aux_ptrs[i] + length * prefill_aux_index
        data = AuxDataCodec.serialize_data_from_buffer(src_addr, length)

        self.send_aux_data_to_endpoint(
            remote=req.endpoint,
            dst_port=req.dst_port,
            room=req.room,
            buffer_index=i,
            aux_index=req.dst_aux_index,
            data=data,
        )

    return 0</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="sglang.srt.disaggregation.mooncake.conn.MooncakeKVManager.send_kvcache"><code class="name flex">
<span>def <span class="ident">send_kvcache</span></span>(<span>self,<br>mooncake_session_id: str,<br>prefill_kv_indices: npt.NDArray[np.int32],<br>dst_kv_ptrs: list[int],<br>dst_kv_indices: npt.NDArray[np.int32],<br>executor: concurrent.futures.ThreadPoolExecutor)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def send_kvcache(
    self,
    mooncake_session_id: str,
    prefill_kv_indices: npt.NDArray[np.int32],
    dst_kv_ptrs: list[int],
    dst_kv_indices: npt.NDArray[np.int32],
    executor: concurrent.futures.ThreadPoolExecutor,
):
    # Group by indices
    prefill_kv_blocks, dst_kv_blocks = group_concurrent_contiguous(
        prefill_kv_indices, dst_kv_indices
    )

    layers_params = None

    # pp is not supported on the decode side yet
    start_layer = self.kv_args.prefill_start_layer
    end_layer = start_layer + len(self.kv_args.kv_data_ptrs)
    if self.is_mla_backend:
        src_kv_ptrs = self.kv_args.kv_data_ptrs
        layers_per_pp_stage = len(src_kv_ptrs)
        dst_kv_ptrs = dst_kv_ptrs[start_layer:end_layer]
        kv_item_len = self.kv_args.kv_item_lens[0]
        layers_params = [
            (
                src_kv_ptrs[layer_id],
                dst_kv_ptrs[layer_id],
                kv_item_len,
            )
            for layer_id in range(layers_per_pp_stage)
        ]
    else:
        num_kv_layers = len(self.kv_args.kv_data_ptrs) // 2
        dst_num_total_layers = num_kv_layers * self.pp_size
        src_k_ptrs = self.kv_args.kv_data_ptrs[:num_kv_layers]
        src_v_ptrs = self.kv_args.kv_data_ptrs[num_kv_layers:]
        layers_per_pp_stage = len(src_k_ptrs)
        dst_k_ptrs = dst_kv_ptrs[start_layer:end_layer]
        dst_v_ptrs = dst_kv_ptrs[
            dst_num_total_layers + start_layer : dst_num_total_layers + end_layer
        ]
        kv_item_len = self.kv_args.kv_item_lens[0]
        layers_params = [
            (
                src_k_ptrs[layer_id],
                dst_k_ptrs[layer_id],
                kv_item_len,
            )
            for layer_id in range(layers_per_pp_stage)
        ] + [
            (
                src_v_ptrs[layer_id],
                dst_v_ptrs[layer_id],
                kv_item_len,
            )
            for layer_id in range(layers_per_pp_stage)
        ]
    assert layers_params is not None

    def set_transfer_blocks(
        src_ptr: int, dst_ptr: int, item_len: int
    ) -&gt; List[Tuple[int, int, int]]:
        transfer_blocks = []
        for prefill_index, decode_index in zip(prefill_kv_blocks, dst_kv_blocks):
            src_addr = src_ptr + int(prefill_index[0]) * item_len
            dst_addr = dst_ptr + int(decode_index[0]) * item_len
            length = item_len * len(prefill_index)
            transfer_blocks.append((src_addr, dst_addr, length))
        return transfer_blocks

    # Worker function for processing a single layer
    def process_layer(src_ptr: int, dst_ptr: int, item_len: int) -&gt; int:
        transfer_blocks = set_transfer_blocks(src_ptr, dst_ptr, item_len)
        return self._transfer_data(mooncake_session_id, transfer_blocks)

    # Worker function for processing all layers in a batch
    def process_layers(layers_params: List[Tuple[int, int, int]]) -&gt; int:
        transfer_blocks = []
        for src_ptr, dst_ptr, item_len in layers_params:
            transfer_blocks.extend(set_transfer_blocks(src_ptr, dst_ptr, item_len))
        return self._transfer_data(mooncake_session_id, transfer_blocks)

    if self.enable_custom_mem_pool:
        futures = [
            executor.submit(
                process_layer,
                src_ptr,
                dst_ptr,
                item_len,
            )
            for (src_ptr, dst_ptr, item_len) in layers_params
        ]
        for future in concurrent.futures.as_completed(futures):
            status = future.result()
            if status != 0:
                for f in futures:
                    f.cancel()
                return status
    else:
        # Combining all layers&#39; params in one batch transfer is more efficient
        # compared to using multiple threads
        return process_layers(layers_params)

    return 0</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="sglang.srt.disaggregation.mooncake.conn.MooncakeKVManager.send_kvcache_slice"><code class="name flex">
<span>def <span class="ident">send_kvcache_slice</span></span>(<span>self,<br>mooncake_session_id: str,<br>prefill_kv_indices: npt.NDArray[np.int64],<br>dst_kv_ptrs: list[int],<br>dst_kv_indices: npt.NDArray[np.int64],<br>dst_tp_rank: int,<br>dst_attn_tp_size: int,<br>dst_kv_item_len: int,<br>executor: concurrent.futures.ThreadPoolExecutor)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def send_kvcache_slice(
    self,
    mooncake_session_id: str,
    prefill_kv_indices: npt.NDArray[np.int64],
    dst_kv_ptrs: list[int],
    dst_kv_indices: npt.NDArray[np.int64],
    dst_tp_rank: int,
    dst_attn_tp_size: int,
    dst_kv_item_len: int,
    executor: concurrent.futures.ThreadPoolExecutor,
):
    &#34;&#34;&#34;
    Sends KV cache slices from this Prefill rank to a target Decode rank,
    supporting generic M-to-N TP size configurations.

    NOTE: This implementation calls the transfer engine for each token slot within
    each page to ensure correctness for any page_size and head-slicing configuration.
    This may introduce performance overhead (increased TTFT) for long sequences.
    &#34;&#34;&#34;
    # Extract configuration
    local_tp_rank_in_group = self.kv_args.engine_rank % self.attn_tp_size
    src_kv_item_len = self.kv_args.kv_item_lens[0]
    dst_tp_rank_in_group = dst_tp_rank % dst_attn_tp_size
    num_kv_heads = self.kv_args.kv_head_num
    num_layers = len(self.kv_args.kv_data_ptrs)
    page_size = self.kv_args.page_size

    # Calculate head distribution
    src_heads_per_rank = num_kv_heads
    dst_heads_per_rank = num_kv_heads * self.attn_tp_size // dst_attn_tp_size
    bytes_per_head_slice_to_send = (
        dst_kv_item_len // page_size // dst_heads_per_rank
    )

    # Determine slicing parameters based on TP configuration
    if self.attn_tp_size &gt; dst_attn_tp_size:
        # Send KVCache from multiple prefill instances to 1 decode instance
        src_head_start_offset = 0
        num_heads_to_send = src_heads_per_rank
        dst_head_start_offset = local_tp_rank_in_group * src_heads_per_rank
    else:
        # Send KVCache from 1 prefill instance to multiple decode instances
        src_head_start_offset = dst_tp_rank_in_group * dst_heads_per_rank
        num_heads_to_send = dst_heads_per_rank
        dst_head_start_offset = 0

    # pp is not supported on the decode side yet
    num_kv_layers = len(self.kv_args.kv_data_ptrs) // 2
    dst_num_total_layers = num_kv_layers * self.pp_size
    src_k_ptrs = self.kv_args.kv_data_ptrs[:num_kv_layers]
    src_v_ptrs = self.kv_args.kv_data_ptrs[num_kv_layers:]
    layers_per_pp_stage = len(src_k_ptrs)
    start_layer = self.pp_rank * layers_per_pp_stage
    end_layer = start_layer + layers_per_pp_stage
    dst_k_ptrs = dst_kv_ptrs[start_layer:end_layer]
    dst_v_ptrs = dst_kv_ptrs[
        dst_num_total_layers + start_layer : dst_num_total_layers + end_layer
    ]

    # Calculate precise byte offset and length for the sub-slice within the token
    src_head_slice_offset = src_head_start_offset * bytes_per_head_slice_to_send
    dst_head_slice_offset = dst_head_start_offset * bytes_per_head_slice_to_send
    heads_bytes_per_token_to_send = num_heads_to_send * bytes_per_head_slice_to_send

    # Sanity check: The data sub-slice to be sent should fit into the dst buffer.
    # This means heads_bytes_per_token_to_send &lt;= (dst_kv_item_len // page_size)
    if heads_bytes_per_token_to_send &gt; (dst_kv_item_len // page_size):
        logger.error(
            f&#34;[{mooncake_session_id}] slice size ({heads_bytes_per_token_to_send}) exceeds &#34;
            f&#34;target token slot size ({dst_kv_item_len // page_size})&#34;
        )
        return -1

    layers_params = [
        (
            src_k_ptrs[layer_id],
            dst_k_ptrs[layer_id],
            src_kv_item_len,
            dst_kv_item_len,
            src_head_slice_offset,
            dst_head_slice_offset,
            heads_bytes_per_token_to_send,
        )
        for layer_id in range(layers_per_pp_stage)
    ] + [
        (
            src_v_ptrs[layer_id],
            dst_v_ptrs[layer_id],
            src_kv_item_len,
            dst_kv_item_len,
            src_head_slice_offset,
            dst_head_slice_offset,
            heads_bytes_per_token_to_send,
        )
        for layer_id in range(layers_per_pp_stage)
    ]

    def process_layer_tp_aware(layer_params):
        (
            src_ptr,
            dst_ptr,
            src_item_len,
            dst_item_len,
            src_head_slice_offset,
            dst_head_slice_offset,
            heads_bytes_per_token_to_send,
        ) = layer_params
        src_addr_list = []
        dst_addr_list = []
        length_list = []

        # Calculate strides for a single token slot
        bytes_per_token_on_prefill = src_item_len // page_size
        bytes_per_token_on_decode = dst_item_len // page_size

        for i in range(len(prefill_kv_indices)):
            prefill_page_idx = int(prefill_kv_indices[i])
            decode_page_idx = int(dst_kv_indices[i])

            # Get the starting addresses for the current src and dst pages
            src_page_start_addr = src_ptr + prefill_page_idx * src_item_len
            dst_page_start_addr = dst_ptr + decode_page_idx * dst_item_len

            # Iterate through each valid token slot within the current page
            for token_slot_in_page in range(page_size):
                # Calculate the start address of the current token slot
                src_token_slot_start_addr = (
                    src_page_start_addr
                    + token_slot_in_page * bytes_per_token_on_prefill
                )
                dst_token_slot_start_addr = (
                    dst_page_start_addr
                    + token_slot_in_page * bytes_per_token_on_decode
                )

                # Calculate final src and dst addresses by applying head-slice offsets
                src_slice_addr = src_token_slot_start_addr + src_head_slice_offset
                dst_slice_addr = dst_token_slot_start_addr + dst_head_slice_offset

                src_addr_list.append(src_slice_addr)
                dst_addr_list.append(dst_slice_addr)
                length_list.append(heads_bytes_per_token_to_send)

        return self.engine.batch_transfer_sync(
            mooncake_session_id, src_addr_list, dst_addr_list, length_list
        )

    futures = [
        executor.submit(
            process_layer_tp_aware,
            layer_params,
        )
        for layer_params in layers_params
    ]

    for future in concurrent.futures.as_completed(futures):
        status = future.result()
        if status != 0:
            for f in futures:
                f.cancel()
            return status

    return 0</code></pre>
</details>
<div class="desc"><p>Sends KV cache slices from this Prefill rank to a target Decode rank,
supporting generic M-to-N TP size configurations.</p>
<p>NOTE: This implementation calls the transfer engine for each token slot within
each page to ensure correctness for any page_size and head-slicing configuration.
This may introduce performance overhead (increased TTFT) for long sequences.</p></div>
</dd>
<dt id="sglang.srt.disaggregation.mooncake.conn.MooncakeKVManager.start_decode_thread"><code class="name flex">
<span>def <span class="ident">start_decode_thread</span></span>(<span>self)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def start_decode_thread(self):
    self.rank_port = get_free_port()
    self._bind_server_socket()

    def decode_thread():
        while True:
            msg = self.server_socket.recv_multipart()
            if msg[0] == MooncakeKVManager.AUX_DATA_HEADER:
                self._handle_aux_data(msg)
                continue

            (bootstrap_room, status, prefill_rank) = msg
            status = int(status.decode(&#34;ascii&#34;))
            bootstrap_room = int(bootstrap_room.decode(&#34;ascii&#34;))
            prefill_rank = int(prefill_rank.decode(&#34;ascii&#34;))

            if status == KVPoll.Success:
                if bootstrap_room in self.request_status:
                    self.prefill_response_tracker[bootstrap_room].add(prefill_rank)
                    expected_response_num = (
                        self.required_prefill_response_num_table[bootstrap_room]
                    )
                    arrived_response_num = len(
                        self.prefill_response_tracker[bootstrap_room]
                    )
                    if arrived_response_num == expected_response_num:
                        self.update_status(bootstrap_room, KVPoll.Success)
            elif status == KVPoll.Failed:
                self.record_failure(
                    bootstrap_room,
                    f&#34;Failed to get kvcache from prefill instance, it might be dead&#34;,
                )
                self.update_status(bootstrap_room, status)

    def heartbeat_checker():
        while True:
            time.sleep(self.heartbeat_interval)
            with self.connection_lock:
                addresses = list(self.prefill_dp_size_table.keys())

            for bootstrap_addr in addresses:
                session = None
                try:
                    with self.session_pool_lock:
                        session = self.session_pool[bootstrap_addr]
                    response = session.get(
                        f&#34;http://{bootstrap_addr}/health&#34;,
                        timeout=(2, 3),
                        headers={&#34;Connection&#34;: &#34;keep-alive&#34;},
                    )
                    if response.status_code == 200:
                        self.heartbeat_failures[bootstrap_addr] = 0

                        current_rooms = self.addr_to_rooms_tracker[
                            bootstrap_addr
                        ].copy()

                        for bootstrap_room in current_rooms:
                            # Remove KVPoll.Success requests from the tracker
                            if bootstrap_room not in self.request_status:
                                self.addr_to_rooms_tracker[bootstrap_addr].discard(
                                    bootstrap_room
                                )
                    else:
                        logger.info(
                            f&#34;Attempting to reconnect to {bootstrap_addr}...&#34;
                        )
                        self.heartbeat_failures[bootstrap_addr] = (
                            self.heartbeat_failures.get(bootstrap_addr, 0) + 1
                        )
                        with self.session_pool_lock:
                            if bootstrap_addr in self.session_pool:
                                del self.session_pool[bootstrap_addr]
                except Exception:
                    logger.info(f&#34;Attempting to reconnect to {bootstrap_addr}...&#34;)
                    self.heartbeat_failures[bootstrap_addr] = (
                        self.heartbeat_failures.get(bootstrap_addr, 0) + 1
                    )

                if (
                    self.heartbeat_failures.get(bootstrap_addr, 0)
                    &gt;= self.max_failures
                ):
                    self._handle_node_failure(bootstrap_addr)
                    with self.session_pool_lock:
                        if bootstrap_addr in self.session_pool:
                            del self.session_pool[bootstrap_addr]

    threading.Thread(target=decode_thread).start()
    threading.Thread(target=heartbeat_checker).start()</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="sglang.srt.disaggregation.mooncake.conn.MooncakeKVManager.start_prefill_thread"><code class="name flex">
<span>def <span class="ident">start_prefill_thread</span></span>(<span>self)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def start_prefill_thread(self):
    self.rank_port = get_free_port()
    self._bind_server_socket()

    def bootstrap_thread():
        &#34;&#34;&#34;This thread recvs pre-alloc notification from the decode engine&#34;&#34;&#34;
        # KVPoll.Bootstrapping -&gt; KVPoll.WaitingForInput
        while True:
            waiting_req_bytes = self.server_socket.recv_multipart()
            room = waiting_req_bytes[0].decode(&#34;ascii&#34;)
            mooncake_session_id = waiting_req_bytes[3].decode(&#34;ascii&#34;)
            if room == &#34;None&#34;:
                self.decode_kv_args_table[mooncake_session_id] = (
                    KVArgsRegisterInfo.from_zmq(waiting_req_bytes)
                )
                with self.session_lock:
                    if mooncake_session_id in self.failed_sessions:
                        self.failed_sessions.remove(mooncake_session_id)
                    if mooncake_session_id in self.session_failures:
                        del self.session_failures[mooncake_session_id]
                logger.debug(
                    f&#34;Register KVArgs from {mooncake_session_id} successfully&#34;
                )
                continue
            else:
                required_dst_info_num = int(waiting_req_bytes[6].decode(&#34;ascii&#34;))
                room = int(room)
                if room not in self.transfer_infos:
                    self.transfer_infos[room] = {}

                self.transfer_infos[room][mooncake_session_id] = (
                    TransferInfo.from_zmq(waiting_req_bytes)
                )
                # NOTE: after bootstrapping we can mark the req as waiting for input
                if len(self.transfer_infos[room]) == required_dst_info_num:
                    self.update_status(room, KVPoll.WaitingForInput)

    threading.Thread(target=bootstrap_thread).start()</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="sglang.srt.disaggregation.mooncake.conn.MooncakeKVManager.sync_status_to_decode_endpoint"><code class="name flex">
<span>def <span class="ident">sync_status_to_decode_endpoint</span></span>(<span>self, remote: str, dst_port: int, room: int, status: int, prefill_rank: int)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def sync_status_to_decode_endpoint(
    self, remote: str, dst_port: int, room: int, status: int, prefill_rank: int
):
    self._connect(
        format_tcp_address(remote, dst_port), is_ipv6=is_valid_ipv6_address(remote)
    ).send_multipart(
        [
            str(room).encode(&#34;ascii&#34;),
            str(status).encode(&#34;ascii&#34;),
            str(prefill_rank).encode(&#34;ascii&#34;),
        ]
    )</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="sglang.srt.disaggregation.mooncake.conn.MooncakeKVManager.transfer_worker"><code class="name flex">
<span>def <span class="ident">transfer_worker</span></span>(<span>self, queue: FastQueue, executor: concurrent.futures.ThreadPoolExecutor)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def transfer_worker(
    self, queue: FastQueue, executor: concurrent.futures.ThreadPoolExecutor
):
    while True:
        try:
            kv_chunk: TransferKVChunk = queue.get()
            reqs_to_be_processed = (
                self.transfer_infos[kv_chunk.room].values()
                if kv_chunk.room in self.transfer_infos
                else []
            )
            polls = []
            dst_ranks_infos = []
            local_rank = self.attn_tp_rank * self.pp_size + self.pp_rank
            for req in reqs_to_be_processed:
                if not req.is_dummy:
                    # Early exit if the request has failed
                    with self.session_lock:
                        if req.mooncake_session_id in self.failed_sessions:
                            self.record_failure(
                                kv_chunk.room,
                                f&#34;Decode instance could be dead, remote mooncake session {req.mooncake_session_id} is not alive&#34;,
                            )
                            self.update_status(kv_chunk.room, KVPoll.Failed)
                            self.sync_status_to_decode_endpoint(
                                req.endpoint,
                                req.dst_port,
                                req.room,
                                KVPoll.Failed,
                                local_rank,
                            )
                            break

                    chunked_dst_kv_indice = req.dst_kv_indices[kv_chunk.index_slice]

                    # NOTE: This is temporarily a workaround to deal with the case where the prefill_kv_indices
                    # is mismatched with the dst_kv_indices when page size &gt; 1, this should never happen.
                    if len(chunked_dst_kv_indice) &lt; len(
                        kv_chunk.prefill_kv_indices
                    ):
                        logger.warning(
                            f&#34;len(chunked_dst_kv_indice) = {len(chunked_dst_kv_indice)}, len(kv_chunk.prefill_kv_indices) = {len(kv_chunk.prefill_kv_indices)}&#34;
                        )
                        kv_chunk.prefill_kv_indices = kv_chunk.prefill_kv_indices[
                            : len(chunked_dst_kv_indice)
                        ]

                    target_rank_registration_info: KVArgsRegisterInfo = (
                        self.decode_kv_args_table[req.mooncake_session_id]
                    )
                    if self.is_mla_backend or (
                        self.attn_tp_size
                        == target_rank_registration_info.dst_attn_tp_size
                    ):
                        ret = self.send_kvcache(
                            req.mooncake_session_id,
                            kv_chunk.prefill_kv_indices,
                            target_rank_registration_info.dst_kv_ptrs,
                            chunked_dst_kv_indice,
                            executor,
                        )
                    else:
                        ret = self.send_kvcache_slice(
                            req.mooncake_session_id,
                            kv_chunk.prefill_kv_indices,
                            target_rank_registration_info.dst_kv_ptrs,
                            chunked_dst_kv_indice,
                            target_rank_registration_info.dst_tp_rank,
                            target_rank_registration_info.dst_attn_tp_size,
                            target_rank_registration_info.dst_kv_item_len,
                            executor,
                        )
                    if ret != 0:
                        with self.session_lock:
                            self.session_failures[req.mooncake_session_id] += 1
                            # Failures should never happen if the session is not dead, if the session fails once, mark it as failed
                            if self.session_failures[req.mooncake_session_id] &gt;= 1:
                                self.failed_sessions.add(req.mooncake_session_id)
                                logger.error(
                                    f&#34;Session {req.mooncake_session_id} failed.&#34;
                                )
                        self.record_failure(
                            kv_chunk.room,
                            f&#34;Failed to send kv chunk of {kv_chunk.room} to {req.endpoint}:{req.dst_port}&#34;,
                        )
                        self.update_status(kv_chunk.room, KVPoll.Failed)
                        self.sync_status_to_decode_endpoint(
                            req.endpoint,
                            req.dst_port,
                            req.room,
                            KVPoll.Failed,
                            local_rank,
                        )
                        break

                    if kv_chunk.is_last:
                        if self.pp_group.is_last_rank:
                            # Only the last chunk we need to send the aux data
                            ret = self.send_aux(
                                req,
                                kv_chunk.prefill_aux_index,
                                target_rank_registration_info.dst_aux_ptrs,
                            )
                        polls.append(True if ret == 0 else False)
                        dst_ranks_infos.append(
                            (req.endpoint, req.dst_port, req.room)
                        )

                        # Only sync status when all the dst ranks have received the kvcache
                        if len(polls) == req.required_dst_info_num:
                            status = KVPoll.Success if all(polls) else KVPoll.Failed
                            self.update_status(req.room, status)
                            for endpoint, dst_port, room in dst_ranks_infos:
                                self.sync_status_to_decode_endpoint(
                                    endpoint, dst_port, room, status, local_rank
                                )
                else:
                    # Dummy request means the decode instance is not used, so its status can be marked as success directly
                    # Dummy request does not need to sync status to decode endpoint
                    if kv_chunk.is_last and req.room in self.request_status:
                        self.update_status(req.room, KVPoll.Success)

            if (
                kv_chunk.room not in self.request_status
                or self.check_status(kv_chunk.room) == KVPoll.Success
            ):
                if kv_chunk.room in self.transfer_infos:
                    self.transfer_infos.pop(kv_chunk.room)

        except Exception as e:
            # NOTE(shangming): Remove this when we make sure the transfer thread is bug-free
            raise RuntimeError(
                f&#34;Transfer thread failed because of {e}. Prefill instance with bootstrap_port={self.bootstrap_port} is dead.&#34;
            )</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="sglang.srt.disaggregation.mooncake.conn.MooncakeKVManager.update_status"><code class="name flex">
<span>def <span class="ident">update_status</span></span>(<span>self, bootstrap_room: int, status: KVPoll)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def update_status(self, bootstrap_room: int, status: KVPoll):
    if bootstrap_room not in self.request_status:
        self.request_status[bootstrap_room] = status
    else:
        # NOTE: status is only allowed to be incremented unless it is KVPoll.Failed
        if status == KVPoll.Failed:
            self.request_status[bootstrap_room] = KVPoll.Failed
        else:
            self.request_status[bootstrap_room] = max(
                self.request_status[bootstrap_room], status
            )</code></pre>
</details>
<div class="desc"></div>
</dd>
</dl>
</dd>
<dt id="sglang.srt.disaggregation.mooncake.conn.MooncakeKVReceiver"><code class="flex name class">
<span>class <span class="ident">MooncakeKVReceiver</span></span>
<span>(</span><span>mgr: <a title="sglang.srt.disaggregation.mooncake.conn.MooncakeKVManager" href="#sglang.srt.disaggregation.mooncake.conn.MooncakeKVManager">MooncakeKVManager</a>,<br>bootstrap_addr: str,<br>bootstrap_room: Optional[int] = None,<br>data_parallel_rank: Optional[int] = None)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class MooncakeKVReceiver(BaseKVReceiver):
    _ctx = zmq.Context()
    _socket_cache = {}
    _socket_locks = {}
    _global_lock = threading.Lock()

    def __init__(
        self,
        mgr: MooncakeKVManager,
        bootstrap_addr: str,
        bootstrap_room: Optional[int] = None,
        data_parallel_rank: Optional[int] = None,
    ):
        self.bootstrap_room = bootstrap_room
        self.bootstrap_addr = bootstrap_addr
        self.kv_mgr = mgr
        self.session_id = self.kv_mgr.get_session_id()
        self.kv_mgr.update_status(self.bootstrap_room, KVPoll.Bootstrapping)
        self.conclude_state = None
        self.init_time = None
        self.data_parallel_rank = data_parallel_rank

        if self.bootstrap_addr not in self.kv_mgr.prefill_dp_size_table:
            (
                self.prefill_attn_tp_size,
                self.prefill_dp_size,
                self.prefill_pp_size,
            ) = self._get_prefill_parallel_info_from_server()
            if (
                self.prefill_attn_tp_size is None
                or self.prefill_dp_size is None
                or self.prefill_pp_size is None
            ):
                self.kv_mgr.record_failure(
                    self.bootstrap_room,
                    f&#34;Could not fetch prefill parallel info from bootstrap_addr: {self.bootstrap_addr}&#34;,
                )
                self.kv_mgr.update_status(self.bootstrap_room, KVPoll.Failed)
                return
            else:
                logger.debug(
                    f&#34;Fetch prefill parallel info from [{self.bootstrap_addr}]: DP size:{self.prefill_dp_size}, TP size:{self.prefill_attn_tp_size} PP size:{self.prefill_pp_size}&#34;
                )
                self.kv_mgr.prefill_attn_tp_size_table[self.bootstrap_addr] = (
                    self.prefill_attn_tp_size
                )
                self.kv_mgr.prefill_dp_size_table[self.bootstrap_addr] = (
                    self.prefill_dp_size
                )
                self.kv_mgr.prefill_pp_size_table[self.bootstrap_addr] = (
                    self.prefill_pp_size
                )
        else:
            self.prefill_attn_tp_size = self.kv_mgr.prefill_attn_tp_size_table[
                self.bootstrap_addr
            ]
            self.prefill_dp_size = self.kv_mgr.prefill_dp_size_table[
                self.bootstrap_addr
            ]
            self.prefill_pp_size = self.kv_mgr.prefill_pp_size_table[
                self.bootstrap_addr
            ]

        # Currently, we don&#39;t allow prefill instance and decode instance to
        # have different TP sizes per DP rank, except for models using MLA.
        if self.kv_mgr.attn_tp_size == self.prefill_attn_tp_size:
            self.target_tp_rank = (
                self.kv_mgr.kv_args.engine_rank % self.kv_mgr.attn_tp_size
            )
            self.required_dst_info_num = 1
            self.required_prefill_response_num = 1 * (
                self.prefill_pp_size // self.kv_mgr.pp_size
            )
            self.target_tp_ranks = [self.target_tp_rank]
        elif self.kv_mgr.attn_tp_size &gt; self.prefill_attn_tp_size:
            if not self.kv_mgr.is_mla_backend:
                logger.warning_once(
                    &#34;Performance is NOT guaranteed when using different TP sizes for non-MLA models. &#34;
                )
            self.target_tp_rank = (
                self.kv_mgr.kv_args.engine_rank % self.kv_mgr.attn_tp_size
            ) // (self.kv_mgr.attn_tp_size // self.prefill_attn_tp_size)
            self.required_dst_info_num = (
                self.kv_mgr.attn_tp_size // self.prefill_attn_tp_size
            )
            self.required_prefill_response_num = 1 * (
                self.prefill_pp_size // self.kv_mgr.pp_size
            )
            self.target_tp_ranks = [self.target_tp_rank]
        else:
            if not self.kv_mgr.is_mla_backend:
                logger.warning_once(
                    &#34;Performance is NOT guaranteed when using different TP sizes for non-MLA models. &#34;
                )
            # For non-MLA models, one decode rank needs to retrieve KVCache from multiple prefill ranks for non MLA models;
            self.target_tp_ranks = [
                rank
                for rank in range(
                    (self.kv_mgr.kv_args.engine_rank % self.kv_mgr.attn_tp_size)
                    * (self.prefill_attn_tp_size // self.kv_mgr.attn_tp_size),
                    (self.kv_mgr.kv_args.engine_rank % self.kv_mgr.attn_tp_size + 1)
                    * (self.prefill_attn_tp_size // self.kv_mgr.attn_tp_size),
                )
            ]

            # For MLA models, we can retrieve KVCache from only one prefill rank, but we still need to maintain
            # multiple connections in the connection pool and have to send dummy requests to other prefill ranks,
            # or the KVPoll will never be set correctly
            self.target_tp_rank = self.target_tp_ranks[0]
            self.required_dst_info_num = 1
            if self.kv_mgr.is_mla_backend:
                self.required_prefill_response_num = (
                    self.prefill_pp_size // self.kv_mgr.pp_size
                )
            else:
                self.required_prefill_response_num = (
                    self.prefill_attn_tp_size // self.kv_mgr.attn_tp_size
                ) * (self.prefill_pp_size // self.kv_mgr.pp_size)

        if self.data_parallel_rank is not None:
            logger.debug(f&#34;Targeting DP rank: {self.data_parallel_rank}&#34;)
            self.target_dp_group = self.data_parallel_rank
        else:
            self.target_dp_group = bootstrap_room % self.prefill_dp_size

        self.kv_mgr.required_prefill_response_num_table[self.bootstrap_room] = (
            self.required_prefill_response_num
        )
        # NOTE: key distinguished by bootstrap_addr, target_dp_group, and target_tp_rank
        bootstrap_key = (
            f&#34;{self.bootstrap_addr}_{self.target_dp_group}_{self.target_tp_rank}&#34;
        )

        if bootstrap_key not in self.kv_mgr.connection_pool:
            bootstrap_infos = []
            for target_tp_rank in self.target_tp_ranks:
                for target_pp_rank in range(self.prefill_pp_size):
                    bootstrap_info = self._get_bootstrap_info_from_server(
                        target_tp_rank, self.target_dp_group, target_pp_rank
                    )
                    if bootstrap_info is not None:
                        if self.kv_mgr.is_mla_backend:
                            # For MLA: target_tp_rank is the selected real rank, others are dummy ranks
                            bootstrap_info[&#34;is_dummy&#34;] = not bool(
                                target_tp_rank == self.target_tp_rank
                                or self.target_tp_rank is None
                            )
                        else:
                            # For non-MLA: all target_tp_ranks are selected real ranks
                            bootstrap_info[&#34;is_dummy&#34;] = False
                        logger.debug(
                            f&#34;Fetched bootstrap info: {bootstrap_info} for DP {self.target_dp_group} TP {target_tp_rank} PP {target_pp_rank}&#34;
                        )
                        bootstrap_infos.append(bootstrap_info)
                    else:
                        self.kv_mgr.record_failure(
                            self.bootstrap_room,
                            f&#34;Could not fetch bootstrap info for engine rank: {self.kv_mgr.kv_args.engine_rank} and target_dp_group: {self.target_dp_group} and target_pp_rank {target_pp_rank}&#34;,
                        )
                        self.kv_mgr.update_status(self.bootstrap_room, KVPoll.Failed)
                        return

            self.bootstrap_infos = bootstrap_infos
            self.kv_mgr.connection_pool[bootstrap_key] = self.bootstrap_infos

            # Register kv_args only once to prefill KVManager according to the info fetched from the bootstrap server
            self._register_kv_args()
        else:
            self.bootstrap_infos = self.kv_mgr.connection_pool[bootstrap_key]

        assert len(self.bootstrap_infos) &gt; 0
        self.kv_mgr.addr_to_rooms_tracker[self.bootstrap_addr].add(self.bootstrap_room)
        self.kv_mgr.update_status(self.bootstrap_room, KVPoll.WaitingForInput)

    def _get_bootstrap_info_from_server(
        self, engine_rank, target_dp_group, target_pp_rank
    ):
        &#34;&#34;&#34;Fetch the bootstrap info from the bootstrap server.&#34;&#34;&#34;
        try:
            url = f&#34;http://{self.bootstrap_addr}/route?engine_rank={engine_rank}&amp;target_dp_group={target_dp_group}&amp;target_pp_rank={target_pp_rank}&#34;
            response = requests.get(url, timeout=5)
            if response.status_code == 200:
                bootstrap_info = response.json()
                return bootstrap_info
            else:
                logger.error(
                    f&#34;Failed to get prefill server info: {response.status_code}, {response.text}&#34;
                )
                return None
        except Exception as e:
            logger.error(f&#34;Error fetching prefill info from bootstrap: {e}&#34;)
            return None

    def _get_prefill_parallel_info_from_server(
        self,
    ) -&gt; Tuple[Optional[int], Optional[int], Optional[int]]:
        &#34;&#34;&#34;Fetch the prefill parallel info from the bootstrap server.&#34;&#34;&#34;
        try:
            url = f&#34;http://{self.bootstrap_addr}/route?engine_rank={-1}&amp;target_dp_group={-1}&amp;target_pp_rank={-1}&#34;
            response = requests.get(url)
            if response.status_code == 200:
                prefill_parallel_info = response.json()
                return (
                    int(prefill_parallel_info[&#34;prefill_attn_tp_size&#34;]),
                    int(prefill_parallel_info[&#34;prefill_dp_size&#34;]),
                    int(prefill_parallel_info[&#34;prefill_pp_size&#34;]),
                )
            else:
                logger.error(
                    f&#34;Failed to get prefill parallel info: {response.status_code}, {response.text}&#34;
                )
                return None, None, None
        except Exception as e:
            logger.error(f&#34;Error fetching prefill parallel info from bootstrap: {e}&#34;)
            return None, None, None

    def _register_kv_args(self):
        for bootstrap_info in self.bootstrap_infos:
            packed_kv_data_ptrs = b&#34;&#34;.join(
                struct.pack(&#34;Q&#34;, ptr) for ptr in self.kv_mgr.kv_args.kv_data_ptrs
            )
            packed_aux_data_ptrs = b&#34;&#34;.join(
                struct.pack(&#34;Q&#34;, ptr) for ptr in self.kv_mgr.kv_args.aux_data_ptrs
            )
            # Note(shangming): No need to add pp rank here since pp is not supported on the decode side yet
            tp_rank = self.kv_mgr.kv_args.engine_rank
            kv_item_len = self.kv_mgr.kv_args.kv_item_lens[0]
            dst_tp_rank = str(tp_rank).encode(&#34;ascii&#34;)
            dst_attn_tp_size = str(self.kv_mgr.attn_tp_size).encode(&#34;ascii&#34;)
            dst_kv_item_len = str(kv_item_len).encode(&#34;ascii&#34;)

            sock, lock = self._connect_to_bootstrap_server(bootstrap_info)
            with lock:
                sock.send_multipart(
                    [
                        &#34;None&#34;.encode(&#34;ascii&#34;),
                        self.kv_mgr.local_ip.encode(&#34;ascii&#34;),
                        str(self.kv_mgr.rank_port).encode(&#34;ascii&#34;),
                        self.session_id.encode(&#34;ascii&#34;),
                        packed_kv_data_ptrs,
                        packed_aux_data_ptrs,
                        dst_tp_rank,
                        dst_attn_tp_size,
                        dst_kv_item_len,
                    ]
                )

    @classmethod
    def _connect(cls, endpoint: str, is_ipv6: bool = False):
        with cls._global_lock:
            if endpoint not in cls._socket_cache:
                sock = cls._ctx.socket(zmq.PUSH)
                if is_ipv6:
                    sock.setsockopt(zmq.IPV6, 1)
                sock.connect(endpoint)
                cls._socket_cache[endpoint] = sock
                cls._socket_locks[endpoint] = threading.Lock()
            return cls._socket_cache[endpoint], cls._socket_locks[endpoint]

    @classmethod
    def _connect_to_bootstrap_server(cls, bootstrap_info: dict):
        ip_address = bootstrap_info[&#34;rank_ip&#34;]
        port = bootstrap_info[&#34;rank_port&#34;]
        is_ipv6_address = is_valid_ipv6_address(ip_address)
        sock, lock = cls._connect(
            format_tcp_address(ip_address, port), is_ipv6=is_ipv6_address
        )
        return sock, lock

    def init(self, kv_indices: npt.NDArray[np.int32], aux_index: Optional[int] = None):
        for bootstrap_info in self.bootstrap_infos:
            sock, lock = self._connect_to_bootstrap_server(bootstrap_info)
            is_dummy = bootstrap_info[&#34;is_dummy&#34;]

            with lock:
                sock.send_multipart(
                    [
                        str(self.bootstrap_room).encode(&#34;ascii&#34;),
                        self.kv_mgr.local_ip.encode(&#34;ascii&#34;),
                        str(self.kv_mgr.rank_port).encode(&#34;ascii&#34;),
                        self.session_id.encode(&#34;ascii&#34;),
                        kv_indices.tobytes() if not is_dummy else b&#34;&#34;,
                        str(aux_index).encode(&#34;ascii&#34;) if not is_dummy else b&#34;&#34;,
                        str(self.required_dst_info_num).encode(&#34;ascii&#34;),
                    ]
                )
        self.init_time = time.time()

    def poll(self) -&gt; KVPoll:
        if self.conclude_state is None:
            status = self.kv_mgr.check_status(self.bootstrap_room)
            if status in (KVPoll.Success, KVPoll.Failed):
                self.conclude_state = status
            elif status == KVPoll.WaitingForInput:
                if self.init_time is not None:
                    now = time.time()
                    elapsed = now - self.init_time
                    if elapsed &gt;= self.kv_mgr.waiting_timeout:
                        logger.warning_once(
                            &#34;Some requests fail to receive KV Cache transfer done signal after bootstrapping. &#34;
                            &#34;If a greater mean TTFT is acceptable, you can &#39;export SGLANG_DISAGGREGATION_WAITING_TIMEOUT=600&#39; (10 minutes) to relax the timeout condition. &#34;
                        )
                        self.kv_mgr.record_failure(
                            self.bootstrap_room,
                            f&#34;Request {self.bootstrap_room} timed out after {elapsed:.1f}s in KVPoll.WaitingForInput&#34;,
                        )
                        self.conclude_state = KVPoll.Failed
                        return KVPoll.Failed

            return status

        else:
            return self.conclude_state

    def clear(self) -&gt; None:
        if self.bootstrap_room in self.kv_mgr.request_status:
            self.kv_mgr.request_status.pop(self.bootstrap_room)

        if self.bootstrap_room in self.kv_mgr.required_prefill_response_num_table:
            self.kv_mgr.required_prefill_response_num_table.pop(self.bootstrap_room)

        if self.bootstrap_room in self.kv_mgr.prefill_response_tracker:
            self.kv_mgr.prefill_response_tracker.pop(self.bootstrap_room)

    def failure_exception(self):
        # Explicitly set the status to failure since this request has failed in another rank
        if self.conclude_state is None:
            self.conclude_state = KVPoll.Failed

        self.clear()

        with self.kv_mgr.failure_lock:
            failure_reason = self.kv_mgr.failure_records.pop(
                self.bootstrap_room, &#34;Failed due to an unknown reason from another rank&#34;
            )
        raise KVTransferError(self.bootstrap_room, failure_reason)

    def abort(self):
        self.kv_mgr.record_failure(
            self.bootstrap_room,
            &#34;Aborted by AbortReq.&#34;,
        )
        # Explicitly set the status to failure since this request has been aborted
        self.conclude_state = KVPoll.Failed</code></pre>
</details>
<div class="desc"><p>Helper class that provides a standard way to create an ABC using
inheritance.</p></div>
<h3>Ancestors</h3>
<ul class="hlist">
<li><a title="sglang.srt.disaggregation.base.conn.BaseKVReceiver" href="../base/conn.html#sglang.srt.disaggregation.base.conn.BaseKVReceiver">BaseKVReceiver</a></li>
<li>abc.ABC</li>
</ul>
<h3>Subclasses</h3>
<ul class="hlist">
<li><a title="sglang.srt.disaggregation.ascend.conn.AscendKVReceiver" href="../ascend/conn.html#sglang.srt.disaggregation.ascend.conn.AscendKVReceiver">AscendKVReceiver</a></li>
</ul>
<h3>Methods</h3>
<dl>
<dt id="sglang.srt.disaggregation.mooncake.conn.MooncakeKVReceiver.abort"><code class="name flex">
<span>def <span class="ident">abort</span></span>(<span>self)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def abort(self):
    self.kv_mgr.record_failure(
        self.bootstrap_room,
        &#34;Aborted by AbortReq.&#34;,
    )
    # Explicitly set the status to failure since this request has been aborted
    self.conclude_state = KVPoll.Failed</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="sglang.srt.disaggregation.mooncake.conn.MooncakeKVReceiver.clear"><code class="name flex">
<span>def <span class="ident">clear</span></span>(<span>self) ‑> None</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def clear(self) -&gt; None:
    if self.bootstrap_room in self.kv_mgr.request_status:
        self.kv_mgr.request_status.pop(self.bootstrap_room)

    if self.bootstrap_room in self.kv_mgr.required_prefill_response_num_table:
        self.kv_mgr.required_prefill_response_num_table.pop(self.bootstrap_room)

    if self.bootstrap_room in self.kv_mgr.prefill_response_tracker:
        self.kv_mgr.prefill_response_tracker.pop(self.bootstrap_room)</code></pre>
</details>
<div class="desc"></div>
</dd>
</dl>
<h3>Inherited members</h3>
<ul class="hlist">
<li><code><b><a title="sglang.srt.disaggregation.base.conn.BaseKVReceiver" href="../base/conn.html#sglang.srt.disaggregation.base.conn.BaseKVReceiver">BaseKVReceiver</a></b></code>:
<ul class="hlist">
<li><code><a title="sglang.srt.disaggregation.base.conn.BaseKVReceiver.failure_exception" href="../base/conn.html#sglang.srt.disaggregation.base.conn.BaseKVReceiver.failure_exception">failure_exception</a></code></li>
<li><code><a title="sglang.srt.disaggregation.base.conn.BaseKVReceiver.init" href="../base/conn.html#sglang.srt.disaggregation.base.conn.BaseKVReceiver.init">init</a></code></li>
<li><code><a title="sglang.srt.disaggregation.base.conn.BaseKVReceiver.poll" href="../base/conn.html#sglang.srt.disaggregation.base.conn.BaseKVReceiver.poll">poll</a></code></li>
</ul>
</li>
</ul>
</dd>
<dt id="sglang.srt.disaggregation.mooncake.conn.MooncakeKVSender"><code class="flex name class">
<span>class <span class="ident">MooncakeKVSender</span></span>
<span>(</span><span>mgr: <a title="sglang.srt.disaggregation.mooncake.conn.MooncakeKVManager" href="#sglang.srt.disaggregation.mooncake.conn.MooncakeKVManager">MooncakeKVManager</a>,<br>bootstrap_addr: str,<br>bootstrap_room: int,<br>dest_tp_ranks: List[int],<br>pp_rank: int)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class MooncakeKVSender(BaseKVSender):

    def __init__(
        self,
        mgr: MooncakeKVManager,
        bootstrap_addr: str,
        bootstrap_room: int,
        dest_tp_ranks: List[int],
        pp_rank: int,
    ):
        self.kv_mgr = mgr
        self.bootstrap_room = bootstrap_room
        self.kv_mgr.update_status(bootstrap_room, KVPoll.Bootstrapping)
        self.aux_index = None
        self.bootstrap_server_url = bootstrap_addr
        self.conclude_state = None
        self.init_time = time.time()
        # inner state
        self.curr_idx = 0

    def init(self, num_kv_indices: int, aux_index: Optional[int] = None):
        self.num_kv_indices = num_kv_indices
        self.aux_index = aux_index

    def send(
        self,
        kv_indices: npt.NDArray[np.int32],
    ):
        index_slice = slice(self.curr_idx, self.curr_idx + len(kv_indices))
        self.curr_idx += len(kv_indices)
        is_last = self.curr_idx == self.num_kv_indices

        if not is_last:
            self.kv_mgr.add_transfer_request(
                self.bootstrap_room,
                kv_indices,
                index_slice,
                False,
            )
        else:
            self.kv_mgr.add_transfer_request(
                self.bootstrap_room,
                kv_indices,
                index_slice,
                True,
                aux_index=self.aux_index,
            )

    def poll(self) -&gt; KVPoll:
        if self.conclude_state is None:
            status = self.kv_mgr.check_status(self.bootstrap_room)
            if status in (KVPoll.Success, KVPoll.Failed):
                self.conclude_state = status
            elif status == KVPoll.Bootstrapping:
                if self.init_time is not None:
                    now = time.time()
                    elapsed = now - self.init_time
                    if elapsed &gt;= self.kv_mgr.bootstrap_timeout:
                        logger.warning_once(
                            &#34;Some requests timed out when bootstrapping, &#34;
                            &#34;which means prefill instances fail to receive the KV indices from the decode instance of this request. &#34;
                            &#34;If a greater mean TTFT is acceptable, you can &#39;export SGLANG_DISAGGREGATION_BOOTSTRAP_TIMEOUT=600&#39; (10 minutes) to relax the timeout condition. &#34;
                        )
                        self.kv_mgr.record_failure(
                            self.bootstrap_room,
                            f&#34;Request {self.bootstrap_room} timed out after {elapsed:.1f}s in KVPoll.Bootstrapping&#34;,
                        )
                        self.conclude_state = KVPoll.Failed
                        return KVPoll.Failed

            return status
        else:
            return self.conclude_state

    def clear(self) -&gt; None:
        if self.bootstrap_room in self.kv_mgr.request_status:
            self.kv_mgr.request_status.pop(self.bootstrap_room)

    def failure_exception(self):
        # Explicitly set the status to failure since this request has failed in another rank
        if self.conclude_state is None:
            self.conclude_state = KVPoll.Failed

        self.clear()

        with self.kv_mgr.failure_lock:
            failure_reason = self.kv_mgr.failure_records.pop(
                self.bootstrap_room, &#34;Failed due to an unknown reason from another rank&#34;
            )
        raise KVTransferError(self.bootstrap_room, failure_reason)

    def abort(self):
        self.kv_mgr.record_failure(
            self.bootstrap_room,
            &#34;Aborted by AbortReq.&#34;,
        )
        # Explicitly set the status to failure since this request has been aborted
        self.conclude_state = KVPoll.Failed</code></pre>
</details>
<div class="desc"><p>Helper class that provides a standard way to create an ABC using
inheritance.</p></div>
<h3>Ancestors</h3>
<ul class="hlist">
<li><a title="sglang.srt.disaggregation.base.conn.BaseKVSender" href="../base/conn.html#sglang.srt.disaggregation.base.conn.BaseKVSender">BaseKVSender</a></li>
<li>abc.ABC</li>
</ul>
<h3>Subclasses</h3>
<ul class="hlist">
<li><a title="sglang.srt.disaggregation.ascend.conn.AscendKVSender" href="../ascend/conn.html#sglang.srt.disaggregation.ascend.conn.AscendKVSender">AscendKVSender</a></li>
</ul>
<h3>Methods</h3>
<dl>
<dt id="sglang.srt.disaggregation.mooncake.conn.MooncakeKVSender.abort"><code class="name flex">
<span>def <span class="ident">abort</span></span>(<span>self)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def abort(self):
    self.kv_mgr.record_failure(
        self.bootstrap_room,
        &#34;Aborted by AbortReq.&#34;,
    )
    # Explicitly set the status to failure since this request has been aborted
    self.conclude_state = KVPoll.Failed</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="sglang.srt.disaggregation.mooncake.conn.MooncakeKVSender.clear"><code class="name flex">
<span>def <span class="ident">clear</span></span>(<span>self) ‑> None</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def clear(self) -&gt; None:
    if self.bootstrap_room in self.kv_mgr.request_status:
        self.kv_mgr.request_status.pop(self.bootstrap_room)</code></pre>
</details>
<div class="desc"></div>
</dd>
</dl>
<h3>Inherited members</h3>
<ul class="hlist">
<li><code><b><a title="sglang.srt.disaggregation.base.conn.BaseKVSender" href="../base/conn.html#sglang.srt.disaggregation.base.conn.BaseKVSender">BaseKVSender</a></b></code>:
<ul class="hlist">
<li><code><a title="sglang.srt.disaggregation.base.conn.BaseKVSender.failure_exception" href="../base/conn.html#sglang.srt.disaggregation.base.conn.BaseKVSender.failure_exception">failure_exception</a></code></li>
<li><code><a title="sglang.srt.disaggregation.base.conn.BaseKVSender.init" href="../base/conn.html#sglang.srt.disaggregation.base.conn.BaseKVSender.init">init</a></code></li>
<li><code><a title="sglang.srt.disaggregation.base.conn.BaseKVSender.poll" href="../base/conn.html#sglang.srt.disaggregation.base.conn.BaseKVSender.poll">poll</a></code></li>
<li><code><a title="sglang.srt.disaggregation.base.conn.BaseKVSender.send" href="../base/conn.html#sglang.srt.disaggregation.base.conn.BaseKVSender.send">send</a></code></li>
</ul>
</li>
</ul>
</dd>
<dt id="sglang.srt.disaggregation.mooncake.conn.TransferInfo"><code class="flex name class">
<span>class <span class="ident">TransferInfo</span></span>
<span>(</span><span>room: int,<br>endpoint: str,<br>dst_port: int,<br>mooncake_session_id: str,<br>dst_kv_indices: npt.NDArray[np.int32],<br>dst_aux_index: int,<br>required_dst_info_num: int,<br>is_dummy: bool)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@dataclasses.dataclass
class TransferInfo:
    room: int
    endpoint: str
    dst_port: int
    mooncake_session_id: str
    dst_kv_indices: npt.NDArray[np.int32]
    dst_aux_index: int
    required_dst_info_num: int
    is_dummy: bool

    @classmethod
    def from_zmq(cls, msg: List[bytes]):
        if msg[4] == b&#34;&#34; and msg[5] == b&#34;&#34;:
            is_dummy = True
            dst_kv_indices = np.array([], dtype=np.int32)
            dst_aux_index = None
        else:
            dst_kv_indices = np.frombuffer(msg[4], dtype=np.int32)
            dst_aux_index = int(msg[5].decode(&#34;ascii&#34;))
            is_dummy = False
        return cls(
            room=int(msg[0].decode(&#34;ascii&#34;)),
            endpoint=msg[1].decode(&#34;ascii&#34;),
            dst_port=int(msg[2].decode(&#34;ascii&#34;)),
            mooncake_session_id=msg[3].decode(&#34;ascii&#34;),
            dst_kv_indices=dst_kv_indices,
            dst_aux_index=dst_aux_index,
            required_dst_info_num=int(msg[6].decode(&#34;ascii&#34;)),
            is_dummy=is_dummy,
        )</code></pre>
</details>
<div class="desc"><p>TransferInfo(room: 'int', endpoint: 'str', dst_port: 'int', mooncake_session_id: 'str', dst_kv_indices: 'npt.NDArray[np.int32]', dst_aux_index: 'int', required_dst_info_num: 'int', is_dummy: 'bool')</p></div>
<h3>Static methods</h3>
<dl>
<dt id="sglang.srt.disaggregation.mooncake.conn.TransferInfo.from_zmq"><code class="name flex">
<span>def <span class="ident">from_zmq</span></span>(<span>msg: List[bytes])</span>
</code></dt>
<dd>
<div class="desc"></div>
</dd>
</dl>
<h3>Instance variables</h3>
<dl>
<dt id="sglang.srt.disaggregation.mooncake.conn.TransferInfo.dst_aux_index"><code class="name">var <span class="ident">dst_aux_index</span> : int</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="sglang.srt.disaggregation.mooncake.conn.TransferInfo.dst_kv_indices"><code class="name">var <span class="ident">dst_kv_indices</span> : numpy.ndarray[tuple[typing.Any, ...], numpy.dtype[numpy.int32]]</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="sglang.srt.disaggregation.mooncake.conn.TransferInfo.dst_port"><code class="name">var <span class="ident">dst_port</span> : int</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="sglang.srt.disaggregation.mooncake.conn.TransferInfo.endpoint"><code class="name">var <span class="ident">endpoint</span> : str</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="sglang.srt.disaggregation.mooncake.conn.TransferInfo.is_dummy"><code class="name">var <span class="ident">is_dummy</span> : bool</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="sglang.srt.disaggregation.mooncake.conn.TransferInfo.mooncake_session_id"><code class="name">var <span class="ident">mooncake_session_id</span> : str</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="sglang.srt.disaggregation.mooncake.conn.TransferInfo.required_dst_info_num"><code class="name">var <span class="ident">required_dst_info_num</span> : int</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="sglang.srt.disaggregation.mooncake.conn.TransferInfo.room"><code class="name">var <span class="ident">room</span> : int</code></dt>
<dd>
<div class="desc"></div>
</dd>
</dl>
</dd>
<dt id="sglang.srt.disaggregation.mooncake.conn.TransferKVChunk"><code class="flex name class">
<span>class <span class="ident">TransferKVChunk</span></span>
<span>(</span><span>room: int,<br>prefill_kv_indices: npt.NDArray[np.int32],<br>index_slice: slice,<br>is_last: bool,<br>prefill_aux_index: Optional[int])</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@dataclasses.dataclass
class TransferKVChunk:
    room: int
    prefill_kv_indices: npt.NDArray[np.int32]
    index_slice: slice
    is_last: bool
    prefill_aux_index: Optional[int]</code></pre>
</details>
<div class="desc"><p>TransferKVChunk(room: 'int', prefill_kv_indices: 'npt.NDArray[np.int32]', index_slice: 'slice', is_last: 'bool', prefill_aux_index: 'Optional[int]')</p></div>
<h3>Instance variables</h3>
<dl>
<dt id="sglang.srt.disaggregation.mooncake.conn.TransferKVChunk.index_slice"><code class="name">var <span class="ident">index_slice</span> : slice</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="sglang.srt.disaggregation.mooncake.conn.TransferKVChunk.is_last"><code class="name">var <span class="ident">is_last</span> : bool</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="sglang.srt.disaggregation.mooncake.conn.TransferKVChunk.prefill_aux_index"><code class="name">var <span class="ident">prefill_aux_index</span> : int | None</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="sglang.srt.disaggregation.mooncake.conn.TransferKVChunk.prefill_kv_indices"><code class="name">var <span class="ident">prefill_kv_indices</span> : numpy.ndarray[tuple[typing.Any, ...], numpy.dtype[numpy.int32]]</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="sglang.srt.disaggregation.mooncake.conn.TransferKVChunk.room"><code class="name">var <span class="ident">room</span> : int</code></dt>
<dd>
<div class="desc"></div>
</dd>
</dl>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="sglang.srt.disaggregation.mooncake" href="index.html">sglang.srt.disaggregation.mooncake</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="sglang.srt.disaggregation.mooncake.conn.AuxDataCodec" href="#sglang.srt.disaggregation.mooncake.conn.AuxDataCodec">AuxDataCodec</a></code></h4>
<ul class="">
<li><code><a title="sglang.srt.disaggregation.mooncake.conn.AuxDataCodec.deserialize_data_to_buffer" href="#sglang.srt.disaggregation.mooncake.conn.AuxDataCodec.deserialize_data_to_buffer">deserialize_data_to_buffer</a></code></li>
<li><code><a title="sglang.srt.disaggregation.mooncake.conn.AuxDataCodec.serialize_data_from_buffer" href="#sglang.srt.disaggregation.mooncake.conn.AuxDataCodec.serialize_data_from_buffer">serialize_data_from_buffer</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="sglang.srt.disaggregation.mooncake.conn.KVArgsRegisterInfo" href="#sglang.srt.disaggregation.mooncake.conn.KVArgsRegisterInfo">KVArgsRegisterInfo</a></code></h4>
<ul class="two-column">
<li><code><a title="sglang.srt.disaggregation.mooncake.conn.KVArgsRegisterInfo.dst_attn_tp_size" href="#sglang.srt.disaggregation.mooncake.conn.KVArgsRegisterInfo.dst_attn_tp_size">dst_attn_tp_size</a></code></li>
<li><code><a title="sglang.srt.disaggregation.mooncake.conn.KVArgsRegisterInfo.dst_aux_ptrs" href="#sglang.srt.disaggregation.mooncake.conn.KVArgsRegisterInfo.dst_aux_ptrs">dst_aux_ptrs</a></code></li>
<li><code><a title="sglang.srt.disaggregation.mooncake.conn.KVArgsRegisterInfo.dst_kv_item_len" href="#sglang.srt.disaggregation.mooncake.conn.KVArgsRegisterInfo.dst_kv_item_len">dst_kv_item_len</a></code></li>
<li><code><a title="sglang.srt.disaggregation.mooncake.conn.KVArgsRegisterInfo.dst_kv_ptrs" href="#sglang.srt.disaggregation.mooncake.conn.KVArgsRegisterInfo.dst_kv_ptrs">dst_kv_ptrs</a></code></li>
<li><code><a title="sglang.srt.disaggregation.mooncake.conn.KVArgsRegisterInfo.dst_port" href="#sglang.srt.disaggregation.mooncake.conn.KVArgsRegisterInfo.dst_port">dst_port</a></code></li>
<li><code><a title="sglang.srt.disaggregation.mooncake.conn.KVArgsRegisterInfo.dst_tp_rank" href="#sglang.srt.disaggregation.mooncake.conn.KVArgsRegisterInfo.dst_tp_rank">dst_tp_rank</a></code></li>
<li><code><a title="sglang.srt.disaggregation.mooncake.conn.KVArgsRegisterInfo.endpoint" href="#sglang.srt.disaggregation.mooncake.conn.KVArgsRegisterInfo.endpoint">endpoint</a></code></li>
<li><code><a title="sglang.srt.disaggregation.mooncake.conn.KVArgsRegisterInfo.from_zmq" href="#sglang.srt.disaggregation.mooncake.conn.KVArgsRegisterInfo.from_zmq">from_zmq</a></code></li>
<li><code><a title="sglang.srt.disaggregation.mooncake.conn.KVArgsRegisterInfo.mooncake_session_id" href="#sglang.srt.disaggregation.mooncake.conn.KVArgsRegisterInfo.mooncake_session_id">mooncake_session_id</a></code></li>
<li><code><a title="sglang.srt.disaggregation.mooncake.conn.KVArgsRegisterInfo.room" href="#sglang.srt.disaggregation.mooncake.conn.KVArgsRegisterInfo.room">room</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="sglang.srt.disaggregation.mooncake.conn.KVTransferError" href="#sglang.srt.disaggregation.mooncake.conn.KVTransferError">KVTransferError</a></code></h4>
</li>
<li>
<h4><code><a title="sglang.srt.disaggregation.mooncake.conn.MooncakeKVBootstrapServer" href="#sglang.srt.disaggregation.mooncake.conn.MooncakeKVBootstrapServer">MooncakeKVBootstrapServer</a></code></h4>
<ul class="">
<li><code><a title="sglang.srt.disaggregation.mooncake.conn.MooncakeKVBootstrapServer.close" href="#sglang.srt.disaggregation.mooncake.conn.MooncakeKVBootstrapServer.close">close</a></code></li>
<li><code><a title="sglang.srt.disaggregation.mooncake.conn.MooncakeKVBootstrapServer.poll" href="#sglang.srt.disaggregation.mooncake.conn.MooncakeKVBootstrapServer.poll">poll</a></code></li>
<li><code><a title="sglang.srt.disaggregation.mooncake.conn.MooncakeKVBootstrapServer.run" href="#sglang.srt.disaggregation.mooncake.conn.MooncakeKVBootstrapServer.run">run</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="sglang.srt.disaggregation.mooncake.conn.MooncakeKVManager" href="#sglang.srt.disaggregation.mooncake.conn.MooncakeKVManager">MooncakeKVManager</a></code></h4>
<ul class="">
<li><code><a title="sglang.srt.disaggregation.mooncake.conn.MooncakeKVManager.AUX_DATA_HEADER" href="#sglang.srt.disaggregation.mooncake.conn.MooncakeKVManager.AUX_DATA_HEADER">AUX_DATA_HEADER</a></code></li>
<li><code><a title="sglang.srt.disaggregation.mooncake.conn.MooncakeKVManager.add_transfer_request" href="#sglang.srt.disaggregation.mooncake.conn.MooncakeKVManager.add_transfer_request">add_transfer_request</a></code></li>
<li><code><a title="sglang.srt.disaggregation.mooncake.conn.MooncakeKVManager.check_status" href="#sglang.srt.disaggregation.mooncake.conn.MooncakeKVManager.check_status">check_status</a></code></li>
<li><code><a title="sglang.srt.disaggregation.mooncake.conn.MooncakeKVManager.get_session_id" href="#sglang.srt.disaggregation.mooncake.conn.MooncakeKVManager.get_session_id">get_session_id</a></code></li>
<li><code><a title="sglang.srt.disaggregation.mooncake.conn.MooncakeKVManager.init_engine" href="#sglang.srt.disaggregation.mooncake.conn.MooncakeKVManager.init_engine">init_engine</a></code></li>
<li><code><a title="sglang.srt.disaggregation.mooncake.conn.MooncakeKVManager.record_failure" href="#sglang.srt.disaggregation.mooncake.conn.MooncakeKVManager.record_failure">record_failure</a></code></li>
<li><code><a title="sglang.srt.disaggregation.mooncake.conn.MooncakeKVManager.register_buffer_to_engine" href="#sglang.srt.disaggregation.mooncake.conn.MooncakeKVManager.register_buffer_to_engine">register_buffer_to_engine</a></code></li>
<li><code><a title="sglang.srt.disaggregation.mooncake.conn.MooncakeKVManager.send_aux" href="#sglang.srt.disaggregation.mooncake.conn.MooncakeKVManager.send_aux">send_aux</a></code></li>
<li><code><a title="sglang.srt.disaggregation.mooncake.conn.MooncakeKVManager.send_aux_data_to_endpoint" href="#sglang.srt.disaggregation.mooncake.conn.MooncakeKVManager.send_aux_data_to_endpoint">send_aux_data_to_endpoint</a></code></li>
<li><code><a title="sglang.srt.disaggregation.mooncake.conn.MooncakeKVManager.send_aux_tcp" href="#sglang.srt.disaggregation.mooncake.conn.MooncakeKVManager.send_aux_tcp">send_aux_tcp</a></code></li>
<li><code><a title="sglang.srt.disaggregation.mooncake.conn.MooncakeKVManager.send_kvcache" href="#sglang.srt.disaggregation.mooncake.conn.MooncakeKVManager.send_kvcache">send_kvcache</a></code></li>
<li><code><a title="sglang.srt.disaggregation.mooncake.conn.MooncakeKVManager.send_kvcache_slice" href="#sglang.srt.disaggregation.mooncake.conn.MooncakeKVManager.send_kvcache_slice">send_kvcache_slice</a></code></li>
<li><code><a title="sglang.srt.disaggregation.mooncake.conn.MooncakeKVManager.start_decode_thread" href="#sglang.srt.disaggregation.mooncake.conn.MooncakeKVManager.start_decode_thread">start_decode_thread</a></code></li>
<li><code><a title="sglang.srt.disaggregation.mooncake.conn.MooncakeKVManager.start_prefill_thread" href="#sglang.srt.disaggregation.mooncake.conn.MooncakeKVManager.start_prefill_thread">start_prefill_thread</a></code></li>
<li><code><a title="sglang.srt.disaggregation.mooncake.conn.MooncakeKVManager.sync_status_to_decode_endpoint" href="#sglang.srt.disaggregation.mooncake.conn.MooncakeKVManager.sync_status_to_decode_endpoint">sync_status_to_decode_endpoint</a></code></li>
<li><code><a title="sglang.srt.disaggregation.mooncake.conn.MooncakeKVManager.transfer_worker" href="#sglang.srt.disaggregation.mooncake.conn.MooncakeKVManager.transfer_worker">transfer_worker</a></code></li>
<li><code><a title="sglang.srt.disaggregation.mooncake.conn.MooncakeKVManager.update_status" href="#sglang.srt.disaggregation.mooncake.conn.MooncakeKVManager.update_status">update_status</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="sglang.srt.disaggregation.mooncake.conn.MooncakeKVReceiver" href="#sglang.srt.disaggregation.mooncake.conn.MooncakeKVReceiver">MooncakeKVReceiver</a></code></h4>
<ul class="">
<li><code><a title="sglang.srt.disaggregation.mooncake.conn.MooncakeKVReceiver.abort" href="#sglang.srt.disaggregation.mooncake.conn.MooncakeKVReceiver.abort">abort</a></code></li>
<li><code><a title="sglang.srt.disaggregation.mooncake.conn.MooncakeKVReceiver.clear" href="#sglang.srt.disaggregation.mooncake.conn.MooncakeKVReceiver.clear">clear</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="sglang.srt.disaggregation.mooncake.conn.MooncakeKVSender" href="#sglang.srt.disaggregation.mooncake.conn.MooncakeKVSender">MooncakeKVSender</a></code></h4>
<ul class="">
<li><code><a title="sglang.srt.disaggregation.mooncake.conn.MooncakeKVSender.abort" href="#sglang.srt.disaggregation.mooncake.conn.MooncakeKVSender.abort">abort</a></code></li>
<li><code><a title="sglang.srt.disaggregation.mooncake.conn.MooncakeKVSender.clear" href="#sglang.srt.disaggregation.mooncake.conn.MooncakeKVSender.clear">clear</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="sglang.srt.disaggregation.mooncake.conn.TransferInfo" href="#sglang.srt.disaggregation.mooncake.conn.TransferInfo">TransferInfo</a></code></h4>
<ul class="">
<li><code><a title="sglang.srt.disaggregation.mooncake.conn.TransferInfo.dst_aux_index" href="#sglang.srt.disaggregation.mooncake.conn.TransferInfo.dst_aux_index">dst_aux_index</a></code></li>
<li><code><a title="sglang.srt.disaggregation.mooncake.conn.TransferInfo.dst_kv_indices" href="#sglang.srt.disaggregation.mooncake.conn.TransferInfo.dst_kv_indices">dst_kv_indices</a></code></li>
<li><code><a title="sglang.srt.disaggregation.mooncake.conn.TransferInfo.dst_port" href="#sglang.srt.disaggregation.mooncake.conn.TransferInfo.dst_port">dst_port</a></code></li>
<li><code><a title="sglang.srt.disaggregation.mooncake.conn.TransferInfo.endpoint" href="#sglang.srt.disaggregation.mooncake.conn.TransferInfo.endpoint">endpoint</a></code></li>
<li><code><a title="sglang.srt.disaggregation.mooncake.conn.TransferInfo.from_zmq" href="#sglang.srt.disaggregation.mooncake.conn.TransferInfo.from_zmq">from_zmq</a></code></li>
<li><code><a title="sglang.srt.disaggregation.mooncake.conn.TransferInfo.is_dummy" href="#sglang.srt.disaggregation.mooncake.conn.TransferInfo.is_dummy">is_dummy</a></code></li>
<li><code><a title="sglang.srt.disaggregation.mooncake.conn.TransferInfo.mooncake_session_id" href="#sglang.srt.disaggregation.mooncake.conn.TransferInfo.mooncake_session_id">mooncake_session_id</a></code></li>
<li><code><a title="sglang.srt.disaggregation.mooncake.conn.TransferInfo.required_dst_info_num" href="#sglang.srt.disaggregation.mooncake.conn.TransferInfo.required_dst_info_num">required_dst_info_num</a></code></li>
<li><code><a title="sglang.srt.disaggregation.mooncake.conn.TransferInfo.room" href="#sglang.srt.disaggregation.mooncake.conn.TransferInfo.room">room</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="sglang.srt.disaggregation.mooncake.conn.TransferKVChunk" href="#sglang.srt.disaggregation.mooncake.conn.TransferKVChunk">TransferKVChunk</a></code></h4>
<ul class="">
<li><code><a title="sglang.srt.disaggregation.mooncake.conn.TransferKVChunk.index_slice" href="#sglang.srt.disaggregation.mooncake.conn.TransferKVChunk.index_slice">index_slice</a></code></li>
<li><code><a title="sglang.srt.disaggregation.mooncake.conn.TransferKVChunk.is_last" href="#sglang.srt.disaggregation.mooncake.conn.TransferKVChunk.is_last">is_last</a></code></li>
<li><code><a title="sglang.srt.disaggregation.mooncake.conn.TransferKVChunk.prefill_aux_index" href="#sglang.srt.disaggregation.mooncake.conn.TransferKVChunk.prefill_aux_index">prefill_aux_index</a></code></li>
<li><code><a title="sglang.srt.disaggregation.mooncake.conn.TransferKVChunk.prefill_kv_indices" href="#sglang.srt.disaggregation.mooncake.conn.TransferKVChunk.prefill_kv_indices">prefill_kv_indices</a></code></li>
<li><code><a title="sglang.srt.disaggregation.mooncake.conn.TransferKVChunk.room" href="#sglang.srt.disaggregation.mooncake.conn.TransferKVChunk.room">room</a></code></li>
</ul>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc" title="pdoc: Python API documentation generator"><cite>pdoc</cite> 0.11.6</a>.</p>
</footer>
</body>
</html>
