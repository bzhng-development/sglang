<!doctype html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="generator" content="pdoc 15.0.4"/>
    <title>sglang.srt.distributed.parallel_state API documentation</title>

    <style>/*! * Bootstrap Reboot v5.0.0 (https://getbootstrap.com/) * Copyright 2011-2021 The Bootstrap Authors * Copyright 2011-2021 Twitter, Inc. * Licensed under MIT (https://github.com/twbs/bootstrap/blob/main/LICENSE) * Forked from Normalize.css, licensed MIT (https://github.com/necolas/normalize.css/blob/master/LICENSE.md) */*,::after,::before{box-sizing:border-box}@media (prefers-reduced-motion:no-preference){:root{scroll-behavior:smooth}}body{margin:0;font-family:system-ui,-apple-system,"Segoe UI",Roboto,"Helvetica Neue",Arial,"Noto Sans","Liberation Sans",sans-serif,"Apple Color Emoji","Segoe UI Emoji","Segoe UI Symbol","Noto Color Emoji";font-size:1rem;font-weight:400;line-height:1.5;color:#212529;background-color:#fff;-webkit-text-size-adjust:100%;-webkit-tap-highlight-color:transparent}hr{margin:1rem 0;color:inherit;background-color:currentColor;border:0;opacity:.25}hr:not([size]){height:1px}h1,h2,h3,h4,h5,h6{margin-top:0;margin-bottom:.5rem;font-weight:500;line-height:1.2}h1{font-size:calc(1.375rem + 1.5vw)}@media (min-width:1200px){h1{font-size:2.5rem}}h2{font-size:calc(1.325rem + .9vw)}@media (min-width:1200px){h2{font-size:2rem}}h3{font-size:calc(1.3rem + .6vw)}@media (min-width:1200px){h3{font-size:1.75rem}}h4{font-size:calc(1.275rem + .3vw)}@media (min-width:1200px){h4{font-size:1.5rem}}h5{font-size:1.25rem}h6{font-size:1rem}p{margin-top:0;margin-bottom:1rem}abbr[data-bs-original-title],abbr[title]{-webkit-text-decoration:underline dotted;text-decoration:underline dotted;cursor:help;-webkit-text-decoration-skip-ink:none;text-decoration-skip-ink:none}address{margin-bottom:1rem;font-style:normal;line-height:inherit}ol,ul{padding-left:2rem}dl,ol,ul{margin-top:0;margin-bottom:1rem}ol ol,ol ul,ul ol,ul ul{margin-bottom:0}dt{font-weight:700}dd{margin-bottom:.5rem;margin-left:0}blockquote{margin:0 0 1rem}b,strong{font-weight:bolder}small{font-size:.875em}mark{padding:.2em;background-color:#fcf8e3}sub,sup{position:relative;font-size:.75em;line-height:0;vertical-align:baseline}sub{bottom:-.25em}sup{top:-.5em}a{color:#0d6efd;text-decoration:underline}a:hover{color:#0a58ca}a:not([href]):not([class]),a:not([href]):not([class]):hover{color:inherit;text-decoration:none}code,kbd,pre,samp{font-family:SFMono-Regular,Menlo,Monaco,Consolas,"Liberation Mono","Courier New",monospace;font-size:1em;direction:ltr;unicode-bidi:bidi-override}pre{display:block;margin-top:0;margin-bottom:1rem;overflow:auto;font-size:.875em}pre code{font-size:inherit;color:inherit;word-break:normal}code{font-size:.875em;color:#d63384;word-wrap:break-word}a>code{color:inherit}kbd{padding:.2rem .4rem;font-size:.875em;color:#fff;background-color:#212529;border-radius:.2rem}kbd kbd{padding:0;font-size:1em;font-weight:700}figure{margin:0 0 1rem}img,svg{vertical-align:middle}table{caption-side:bottom;border-collapse:collapse}caption{padding-top:.5rem;padding-bottom:.5rem;color:#6c757d;text-align:left}th{text-align:inherit;text-align:-webkit-match-parent}tbody,td,tfoot,th,thead,tr{border-color:inherit;border-style:solid;border-width:0}label{display:inline-block}button{border-radius:0}button:focus:not(:focus-visible){outline:0}button,input,optgroup,select,textarea{margin:0;font-family:inherit;font-size:inherit;line-height:inherit}button,select{text-transform:none}[role=button]{cursor:pointer}select{word-wrap:normal}select:disabled{opacity:1}[list]::-webkit-calendar-picker-indicator{display:none}[type=button],[type=reset],[type=submit],button{-webkit-appearance:button}[type=button]:not(:disabled),[type=reset]:not(:disabled),[type=submit]:not(:disabled),button:not(:disabled){cursor:pointer}::-moz-focus-inner{padding:0;border-style:none}textarea{resize:vertical}fieldset{min-width:0;padding:0;margin:0;border:0}legend{float:left;width:100%;padding:0;margin-bottom:.5rem;font-size:calc(1.275rem + .3vw);line-height:inherit}@media (min-width:1200px){legend{font-size:1.5rem}}legend+*{clear:left}::-webkit-datetime-edit-day-field,::-webkit-datetime-edit-fields-wrapper,::-webkit-datetime-edit-hour-field,::-webkit-datetime-edit-minute,::-webkit-datetime-edit-month-field,::-webkit-datetime-edit-text,::-webkit-datetime-edit-year-field{padding:0}::-webkit-inner-spin-button{height:auto}[type=search]{outline-offset:-2px;-webkit-appearance:textfield}::-webkit-search-decoration{-webkit-appearance:none}::-webkit-color-swatch-wrapper{padding:0}::file-selector-button{font:inherit}::-webkit-file-upload-button{font:inherit;-webkit-appearance:button}output{display:inline-block}iframe{border:0}summary{display:list-item;cursor:pointer}progress{vertical-align:baseline}[hidden]{display:none!important}</style>
    <style>/*! syntax-highlighting.css */pre{line-height:125%;}span.linenos{color:inherit; background-color:transparent; padding-left:5px; padding-right:20px;}.pdoc-code .hll{background-color:#ffffcc}.pdoc-code{background:#f8f8f8;}.pdoc-code .c{color:#3D7B7B; font-style:italic}.pdoc-code .err{border:1px solid #FF0000}.pdoc-code .k{color:#008000; font-weight:bold}.pdoc-code .o{color:#666666}.pdoc-code .ch{color:#3D7B7B; font-style:italic}.pdoc-code .cm{color:#3D7B7B; font-style:italic}.pdoc-code .cp{color:#9C6500}.pdoc-code .cpf{color:#3D7B7B; font-style:italic}.pdoc-code .c1{color:#3D7B7B; font-style:italic}.pdoc-code .cs{color:#3D7B7B; font-style:italic}.pdoc-code .gd{color:#A00000}.pdoc-code .ge{font-style:italic}.pdoc-code .gr{color:#E40000}.pdoc-code .gh{color:#000080; font-weight:bold}.pdoc-code .gi{color:#008400}.pdoc-code .go{color:#717171}.pdoc-code .gp{color:#000080; font-weight:bold}.pdoc-code .gs{font-weight:bold}.pdoc-code .gu{color:#800080; font-weight:bold}.pdoc-code .gt{color:#0044DD}.pdoc-code .kc{color:#008000; font-weight:bold}.pdoc-code .kd{color:#008000; font-weight:bold}.pdoc-code .kn{color:#008000; font-weight:bold}.pdoc-code .kp{color:#008000}.pdoc-code .kr{color:#008000; font-weight:bold}.pdoc-code .kt{color:#B00040}.pdoc-code .m{color:#666666}.pdoc-code .s{color:#BA2121}.pdoc-code .na{color:#687822}.pdoc-code .nb{color:#008000}.pdoc-code .nc{color:#0000FF; font-weight:bold}.pdoc-code .no{color:#880000}.pdoc-code .nd{color:#AA22FF}.pdoc-code .ni{color:#717171; font-weight:bold}.pdoc-code .ne{color:#CB3F38; font-weight:bold}.pdoc-code .nf{color:#0000FF}.pdoc-code .nl{color:#767600}.pdoc-code .nn{color:#0000FF; font-weight:bold}.pdoc-code .nt{color:#008000; font-weight:bold}.pdoc-code .nv{color:#19177C}.pdoc-code .ow{color:#AA22FF; font-weight:bold}.pdoc-code .w{color:#bbbbbb}.pdoc-code .mb{color:#666666}.pdoc-code .mf{color:#666666}.pdoc-code .mh{color:#666666}.pdoc-code .mi{color:#666666}.pdoc-code .mo{color:#666666}.pdoc-code .sa{color:#BA2121}.pdoc-code .sb{color:#BA2121}.pdoc-code .sc{color:#BA2121}.pdoc-code .dl{color:#BA2121}.pdoc-code .sd{color:#BA2121; font-style:italic}.pdoc-code .s2{color:#BA2121}.pdoc-code .se{color:#AA5D1F; font-weight:bold}.pdoc-code .sh{color:#BA2121}.pdoc-code .si{color:#A45A77; font-weight:bold}.pdoc-code .sx{color:#008000}.pdoc-code .sr{color:#A45A77}.pdoc-code .s1{color:#BA2121}.pdoc-code .ss{color:#19177C}.pdoc-code .bp{color:#008000}.pdoc-code .fm{color:#0000FF}.pdoc-code .vc{color:#19177C}.pdoc-code .vg{color:#19177C}.pdoc-code .vi{color:#19177C}.pdoc-code .vm{color:#19177C}.pdoc-code .il{color:#666666}</style>
    <style>/*! theme.css */:root{--pdoc-background:#fff;}.pdoc{--text:#212529;--muted:#6c757d;--link:#3660a5;--link-hover:#1659c5;--code:#f8f8f8;--active:#fff598;--accent:#eee;--accent2:#c1c1c1;--nav-hover:rgba(255, 255, 255, 0.5);--name:#0066BB;--def:#008800;--annotation:#007020;}</style>
    <style>/*! layout.css */html, body{width:100%;height:100%;}html, main{scroll-behavior:smooth;}body{background-color:var(--pdoc-background);}@media (max-width:769px){#navtoggle{cursor:pointer;position:absolute;width:50px;height:40px;top:1rem;right:1rem;border-color:var(--text);color:var(--text);display:flex;opacity:0.8;z-index:999;}#navtoggle:hover{opacity:1;}#togglestate + div{display:none;}#togglestate:checked + div{display:inherit;}main, header{padding:2rem 3vw;}header + main{margin-top:-3rem;}.git-button{display:none !important;}nav input[type="search"]{max-width:77%;}nav input[type="search"]:first-child{margin-top:-6px;}nav input[type="search"]:valid ~ *{display:none !important;}}@media (min-width:770px){:root{--sidebar-width:clamp(12.5rem, 28vw, 22rem);}nav{position:fixed;overflow:auto;height:100vh;width:var(--sidebar-width);}main, header{padding:3rem 2rem 3rem calc(var(--sidebar-width) + 3rem);width:calc(54rem + var(--sidebar-width));max-width:100%;}header + main{margin-top:-4rem;}#navtoggle{display:none;}}#togglestate{position:absolute;height:0;opacity:0;}nav.pdoc{--pad:clamp(0.5rem, 2vw, 1.75rem);--indent:1.5rem;background-color:var(--accent);border-right:1px solid var(--accent2);box-shadow:0 0 20px rgba(50, 50, 50, .2) inset;padding:0 0 0 var(--pad);overflow-wrap:anywhere;scrollbar-width:thin; scrollbar-color:var(--accent2) transparent; z-index:1}nav.pdoc::-webkit-scrollbar{width:.4rem; }nav.pdoc::-webkit-scrollbar-thumb{background-color:var(--accent2); }nav.pdoc > div{padding:var(--pad) 0;}nav.pdoc .module-list-button{display:inline-flex;align-items:center;color:var(--text);border-color:var(--muted);margin-bottom:1rem;}nav.pdoc .module-list-button:hover{border-color:var(--text);}nav.pdoc input[type=search]{display:block;outline-offset:0;width:calc(100% - var(--pad));}nav.pdoc .logo{max-width:calc(100% - var(--pad));max-height:35vh;display:block;margin:0 auto 1rem;transform:translate(calc(-.5 * var(--pad)), 0);}nav.pdoc ul{list-style:none;padding-left:0;}nav.pdoc > div > ul{margin-left:calc(0px - var(--pad));}nav.pdoc li a{padding:.2rem 0 .2rem calc(var(--pad) + var(--indent));}nav.pdoc > div > ul > li > a{padding-left:var(--pad);}nav.pdoc li{transition:all 100ms;}nav.pdoc li:hover{background-color:var(--nav-hover);}nav.pdoc a, nav.pdoc a:hover{color:var(--text);}nav.pdoc a{display:block;}nav.pdoc > h2:first-of-type{margin-top:1.5rem;}nav.pdoc .class:before{content:"class ";color:var(--muted);}nav.pdoc .function:after{content:"()";color:var(--muted);}nav.pdoc footer:before{content:"";display:block;width:calc(100% - var(--pad));border-top:solid var(--accent2) 1px;margin-top:1.5rem;padding-top:.5rem;}nav.pdoc footer{font-size:small;}</style>
    <style>/*! content.css */.pdoc{color:var(--text);box-sizing:border-box;line-height:1.5;background:none;}.pdoc .pdoc-button{cursor:pointer;display:inline-block;border:solid black 1px;border-radius:2px;font-size:.75rem;padding:calc(0.5em - 1px) 1em;transition:100ms all;}.pdoc .alert{padding:1rem 1rem 1rem calc(1.5rem + 24px);border:1px solid transparent;border-radius:.25rem;background-repeat:no-repeat;background-position:.75rem center;margin-bottom:1rem;}.pdoc .alert > em{display:none;}.pdoc .alert > *:last-child{margin-bottom:0;}.pdoc .alert.note{color:#084298;background-color:#cfe2ff;border-color:#b6d4fe;background-image:url("data:image/svg+xml,%3Csvg%20xmlns%3D%22http%3A//www.w3.org/2000/svg%22%20width%3D%2224%22%20height%3D%2224%22%20fill%3D%22%23084298%22%20viewBox%3D%220%200%2016%2016%22%3E%3Cpath%20d%3D%22M8%2016A8%208%200%201%200%208%200a8%208%200%200%200%200%2016zm.93-9.412-1%204.705c-.07.34.029.533.304.533.194%200%20.487-.07.686-.246l-.088.416c-.287.346-.92.598-1.465.598-.703%200-1.002-.422-.808-1.319l.738-3.468c.064-.293.006-.399-.287-.47l-.451-.081.082-.381%202.29-.287zM8%205.5a1%201%200%201%201%200-2%201%201%200%200%201%200%202z%22/%3E%3C/svg%3E");}.pdoc .alert.tip{color:#0a3622;background-color:#d1e7dd;border-color:#a3cfbb;background-image:url("data:image/svg+xml,%3Csvg%20xmlns%3D%22http%3A//www.w3.org/2000/svg%22%20width%3D%2224%22%20height%3D%2224%22%20fill%3D%22%230a3622%22%20viewBox%3D%220%200%2016%2016%22%3E%3Cpath%20d%3D%22M2%206a6%206%200%201%201%2010.174%204.31c-.203.196-.359.4-.453.619l-.762%201.769A.5.5%200%200%201%2010.5%2013a.5.5%200%200%201%200%201%20.5.5%200%200%201%200%201l-.224.447a1%201%200%200%201-.894.553H6.618a1%201%200%200%201-.894-.553L5.5%2015a.5.5%200%200%201%200-1%20.5.5%200%200%201%200-1%20.5.5%200%200%201-.46-.302l-.761-1.77a2%202%200%200%200-.453-.618A5.98%205.98%200%200%201%202%206m6-5a5%205%200%200%200-3.479%208.592c.263.254.514.564.676.941L5.83%2012h4.342l.632-1.467c.162-.377.413-.687.676-.941A5%205%200%200%200%208%201%22/%3E%3C/svg%3E");}.pdoc .alert.important{color:#055160;background-color:#cff4fc;border-color:#9eeaf9;background-image:url("data:image/svg+xml,%3Csvg%20xmlns%3D%22http%3A//www.w3.org/2000/svg%22%20width%3D%2224%22%20height%3D%2224%22%20fill%3D%22%23055160%22%20viewBox%3D%220%200%2016%2016%22%3E%3Cpath%20d%3D%22M2%200a2%202%200%200%200-2%202v12a2%202%200%200%200%202%202h12a2%202%200%200%200%202-2V2a2%202%200%200%200-2-2zm6%204c.535%200%20.954.462.9.995l-.35%203.507a.552.552%200%200%201-1.1%200L7.1%204.995A.905.905%200%200%201%208%204m.002%206a1%201%200%201%201%200%202%201%201%200%200%201%200-2%22/%3E%3C/svg%3E");}.pdoc .alert.warning{color:#664d03;background-color:#fff3cd;border-color:#ffecb5;background-image:url("data:image/svg+xml,%3Csvg%20xmlns%3D%22http%3A//www.w3.org/2000/svg%22%20width%3D%2224%22%20height%3D%2224%22%20fill%3D%22%23664d03%22%20viewBox%3D%220%200%2016%2016%22%3E%3Cpath%20d%3D%22M8.982%201.566a1.13%201.13%200%200%200-1.96%200L.165%2013.233c-.457.778.091%201.767.98%201.767h13.713c.889%200%201.438-.99.98-1.767L8.982%201.566zM8%205c.535%200%20.954.462.9.995l-.35%203.507a.552.552%200%200%201-1.1%200L7.1%205.995A.905.905%200%200%201%208%205zm.002%206a1%201%200%201%201%200%202%201%201%200%200%201%200-2z%22/%3E%3C/svg%3E");}.pdoc .alert.caution{color:#842029;background-color:#f8d7da;border-color:#f5c2c7;background-image:url("data:image/svg+xml,%3Csvg%20xmlns%3D%22http%3A//www.w3.org/2000/svg%22%20width%3D%2224%22%20height%3D%2224%22%20fill%3D%22%23842029%22%20viewBox%3D%220%200%2016%2016%22%3E%3Cpath%20d%3D%22M11.46.146A.5.5%200%200%200%2011.107%200H4.893a.5.5%200%200%200-.353.146L.146%204.54A.5.5%200%200%200%200%204.893v6.214a.5.5%200%200%200%20.146.353l4.394%204.394a.5.5%200%200%200%20.353.146h6.214a.5.5%200%200%200%20.353-.146l4.394-4.394a.5.5%200%200%200%20.146-.353V4.893a.5.5%200%200%200-.146-.353zM8%204c.535%200%20.954.462.9.995l-.35%203.507a.552.552%200%200%201-1.1%200L7.1%204.995A.905.905%200%200%201%208%204m.002%206a1%201%200%201%201%200%202%201%201%200%200%201%200-2%22/%3E%3C/svg%3E");}.pdoc .alert.danger{color:#842029;background-color:#f8d7da;border-color:#f5c2c7;background-image:url("data:image/svg+xml,%3Csvg%20xmlns%3D%22http%3A//www.w3.org/2000/svg%22%20width%3D%2224%22%20height%3D%2224%22%20fill%3D%22%23842029%22%20viewBox%3D%220%200%2016%2016%22%3E%3Cpath%20d%3D%22M5.52.359A.5.5%200%200%201%206%200h4a.5.5%200%200%201%20.474.658L8.694%206H12.5a.5.5%200%200%201%20.395.807l-7%209a.5.5%200%200%201-.873-.454L6.823%209.5H3.5a.5.5%200%200%201-.48-.641l2.5-8.5z%22/%3E%3C/svg%3E");}.pdoc .visually-hidden{position:absolute !important;width:1px !important;height:1px !important;padding:0 !important;margin:-1px !important;overflow:hidden !important;clip:rect(0, 0, 0, 0) !important;white-space:nowrap !important;border:0 !important;}.pdoc h1, .pdoc h2, .pdoc h3{font-weight:300;margin:.3em 0;padding:.2em 0;}.pdoc > section:not(.module-info) h1{font-size:1.5rem;font-weight:500;}.pdoc > section:not(.module-info) h2{font-size:1.4rem;font-weight:500;}.pdoc > section:not(.module-info) h3{font-size:1.3rem;font-weight:500;}.pdoc > section:not(.module-info) h4{font-size:1.2rem;}.pdoc > section:not(.module-info) h5{font-size:1.1rem;}.pdoc a{text-decoration:none;color:var(--link);}.pdoc a:hover{color:var(--link-hover);}.pdoc blockquote{margin-left:2rem;}.pdoc pre{border-top:1px solid var(--accent2);border-bottom:1px solid var(--accent2);margin-top:0;margin-bottom:1em;padding:.5rem 0 .5rem .5rem;overflow-x:auto;background-color:var(--code);}.pdoc code{color:var(--text);padding:.2em .4em;margin:0;font-size:85%;background-color:var(--accent);border-radius:6px;}.pdoc a > code{color:inherit;}.pdoc pre > code{display:inline-block;font-size:inherit;background:none;border:none;padding:0;}.pdoc > section:not(.module-info){margin-bottom:1.5rem;}.pdoc .modulename{margin-top:0;font-weight:bold;}.pdoc .modulename a{color:var(--link);transition:100ms all;}.pdoc .git-button{float:right;border:solid var(--link) 1px;}.pdoc .git-button:hover{background-color:var(--link);color:var(--pdoc-background);}.view-source-toggle-state,.view-source-toggle-state ~ .pdoc-code{display:none;}.view-source-toggle-state:checked ~ .pdoc-code{display:block;}.view-source-button{display:inline-block;float:right;font-size:.75rem;line-height:1.5rem;color:var(--muted);padding:0 .4rem 0 1.3rem;cursor:pointer;text-indent:-2px;}.view-source-button > span{visibility:hidden;}.module-info .view-source-button{float:none;display:flex;justify-content:flex-end;margin:-1.2rem .4rem -.2rem 0;}.view-source-button::before{position:absolute;content:"View Source";display:list-item;list-style-type:disclosure-closed;}.view-source-toggle-state:checked ~ .attr .view-source-button::before,.view-source-toggle-state:checked ~ .view-source-button::before{list-style-type:disclosure-open;}.pdoc .docstring{margin-bottom:1.5rem;}.pdoc section:not(.module-info) .docstring{margin-left:clamp(0rem, 5vw - 2rem, 1rem);}.pdoc .docstring .pdoc-code{margin-left:1em;margin-right:1em;}.pdoc h1:target,.pdoc h2:target,.pdoc h3:target,.pdoc h4:target,.pdoc h5:target,.pdoc h6:target,.pdoc .pdoc-code > pre > span:target{background-color:var(--active);box-shadow:-1rem 0 0 0 var(--active);}.pdoc .pdoc-code > pre > span:target{display:block;}.pdoc div:target > .attr,.pdoc section:target > .attr,.pdoc dd:target > a{background-color:var(--active);}.pdoc *{scroll-margin:2rem;}.pdoc .pdoc-code .linenos{user-select:none;}.pdoc .attr:hover{filter:contrast(0.95);}.pdoc section, .pdoc .classattr{position:relative;}.pdoc .headerlink{--width:clamp(1rem, 3vw, 2rem);position:absolute;top:0;left:calc(0rem - var(--width));transition:all 100ms ease-in-out;opacity:0;}.pdoc .headerlink::before{content:"#";display:block;text-align:center;width:var(--width);height:2.3rem;line-height:2.3rem;font-size:1.5rem;}.pdoc .attr:hover ~ .headerlink,.pdoc *:target > .headerlink,.pdoc .headerlink:hover{opacity:1;}.pdoc .attr{display:block;margin:.5rem 0 .5rem;padding:.4rem .4rem .4rem 1rem;background-color:var(--accent);overflow-x:auto;}.pdoc .classattr{margin-left:2rem;}.pdoc .decorator-deprecated{color:#842029;}.pdoc .decorator-deprecated ~ span{filter:grayscale(1) opacity(0.8);}.pdoc .name{color:var(--name);font-weight:bold;}.pdoc .def{color:var(--def);font-weight:bold;}.pdoc .signature{background-color:transparent;}.pdoc .param, .pdoc .return-annotation{white-space:pre;}.pdoc .signature.multiline .param{display:block;}.pdoc .signature.condensed .param{display:inline-block;}.pdoc .annotation{color:var(--annotation);}.pdoc .view-value-toggle-state,.pdoc .view-value-toggle-state ~ .default_value{display:none;}.pdoc .view-value-toggle-state:checked ~ .default_value{display:inherit;}.pdoc .view-value-button{font-size:.5rem;vertical-align:middle;border-style:dashed;margin-top:-0.1rem;}.pdoc .view-value-button:hover{background:white;}.pdoc .view-value-button::before{content:"show";text-align:center;width:2.2em;display:inline-block;}.pdoc .view-value-toggle-state:checked ~ .view-value-button::before{content:"hide";}.pdoc .inherited{margin-left:2rem;}.pdoc .inherited dt{font-weight:700;}.pdoc .inherited dt, .pdoc .inherited dd{display:inline;margin-left:0;margin-bottom:.5rem;}.pdoc .inherited dd:not(:last-child):after{content:", ";}.pdoc .inherited .class:before{content:"class ";}.pdoc .inherited .function a:after{content:"()";}.pdoc .search-result .docstring{overflow:auto;max-height:25vh;}.pdoc .search-result.focused > .attr{background-color:var(--active);}.pdoc .attribution{margin-top:2rem;display:block;opacity:0.5;transition:all 200ms;filter:grayscale(100%);}.pdoc .attribution:hover{opacity:1;filter:grayscale(0%);}.pdoc .attribution img{margin-left:5px;height:35px;vertical-align:middle;width:70px;transition:all 200ms;}.pdoc table{display:block;width:max-content;max-width:100%;overflow:auto;margin-bottom:1rem;}.pdoc table th{font-weight:600;}.pdoc table th, .pdoc table td{padding:6px 13px;border:1px solid var(--accent2);}</style>
    <style>/*! custom.css */</style></head>
<body>
    <nav class="pdoc">
        <label id="navtoggle" for="togglestate" class="pdoc-button"><svg xmlns='http://www.w3.org/2000/svg' viewBox='0 0 30 30'><path stroke-linecap='round' stroke="currentColor" stroke-miterlimit='10' stroke-width='2' d='M4 7h22M4 15h22M4 23h22'/></svg></label>
        <input id="togglestate" type="checkbox" aria-hidden="true" tabindex="-1">
        <div>            <a class="pdoc-button module-list-button" href="../distributed.html">
<svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="currentColor" class="bi bi-box-arrow-in-left" viewBox="0 0 16 16">
  <path fill-rule="evenodd" d="M10 3.5a.5.5 0 0 0-.5-.5h-8a.5.5 0 0 0-.5.5v9a.5.5 0 0 0 .5.5h8a.5.5 0 0 0 .5-.5v-2a.5.5 0 0 1 1 0v2A1.5 1.5 0 0 1 9.5 14h-8A1.5 1.5 0 0 1 0 12.5v-9A1.5 1.5 0 0 1 1.5 2h8A1.5 1.5 0 0 1 11 3.5v2a.5.5 0 0 1-1 0v-2z"/>
  <path fill-rule="evenodd" d="M4.146 8.354a.5.5 0 0 1 0-.708l3-3a.5.5 0 1 1 .708.708L5.707 7.5H14.5a.5.5 0 0 1 0 1H5.707l2.147 2.146a.5.5 0 0 1-.708.708l-3-3z"/>
</svg>                &nbsp;sglang.srt.distributed</a>


            <input type="search" placeholder="Search..." role="searchbox" aria-label="search"
                   pattern=".+" required>



            <h2>API Documentation</h2>
                <ul class="memberlist">
            <li>
                    <a class="class" href="#GraphCaptureContext">GraphCaptureContext</a>
                            <ul class="memberlist">
                        <li>
                                <a class="function" href="#GraphCaptureContext.__init__">GraphCaptureContext</a>
                        </li>
                        <li>
                                <a class="variable" href="#GraphCaptureContext.stream">stream</a>
                        </li>
                </ul>

            </li>
            <li>
                    <a class="class" href="#TensorMetadata">TensorMetadata</a>
                            <ul class="memberlist">
                        <li>
                                <a class="function" href="#TensorMetadata.__init__">TensorMetadata</a>
                        </li>
                        <li>
                                <a class="variable" href="#TensorMetadata.device">device</a>
                        </li>
                        <li>
                                <a class="variable" href="#TensorMetadata.dtype">dtype</a>
                        </li>
                        <li>
                                <a class="variable" href="#TensorMetadata.size">size</a>
                        </li>
                </ul>

            </li>
            <li>
                    <a class="class" href="#GroupCoordinator">GroupCoordinator</a>
                            <ul class="memberlist">
                        <li>
                                <a class="function" href="#GroupCoordinator.__init__">GroupCoordinator</a>
                        </li>
                        <li>
                                <a class="variable" href="#GroupCoordinator.rank">rank</a>
                        </li>
                        <li>
                                <a class="variable" href="#GroupCoordinator.ranks">ranks</a>
                        </li>
                        <li>
                                <a class="variable" href="#GroupCoordinator.world_size">world_size</a>
                        </li>
                        <li>
                                <a class="variable" href="#GroupCoordinator.local_rank">local_rank</a>
                        </li>
                        <li>
                                <a class="variable" href="#GroupCoordinator.rank_in_group">rank_in_group</a>
                        </li>
                        <li>
                                <a class="variable" href="#GroupCoordinator.cpu_group">cpu_group</a>
                        </li>
                        <li>
                                <a class="variable" href="#GroupCoordinator.device_group">device_group</a>
                        </li>
                        <li>
                                <a class="variable" href="#GroupCoordinator.use_pynccl">use_pynccl</a>
                        </li>
                        <li>
                                <a class="variable" href="#GroupCoordinator.use_pymscclpp">use_pymscclpp</a>
                        </li>
                        <li>
                                <a class="variable" href="#GroupCoordinator.use_custom_allreduce">use_custom_allreduce</a>
                        </li>
                        <li>
                                <a class="variable" href="#GroupCoordinator.use_message_queue_broadcaster">use_message_queue_broadcaster</a>
                        </li>
                        <li>
                                <a class="variable" href="#GroupCoordinator.pynccl_comm">pynccl_comm</a>
                        </li>
                        <li>
                                <a class="variable" href="#GroupCoordinator.ca_comm">ca_comm</a>
                        </li>
                        <li>
                                <a class="variable" href="#GroupCoordinator.mq_broadcaster">mq_broadcaster</a>
                        </li>
                        <li>
                                <a class="variable" href="#GroupCoordinator.unique_name">unique_name</a>
                        </li>
                        <li>
                                <a class="variable" href="#GroupCoordinator.local_size">local_size</a>
                        </li>
                        <li>
                                <a class="variable" href="#GroupCoordinator.device_module">device_module</a>
                        </li>
                        <li>
                                <a class="variable" href="#GroupCoordinator.use_hpu_communicator">use_hpu_communicator</a>
                        </li>
                        <li>
                                <a class="variable" href="#GroupCoordinator.use_xpu_communicator">use_xpu_communicator</a>
                        </li>
                        <li>
                                <a class="variable" href="#GroupCoordinator.use_npu_communicator">use_npu_communicator</a>
                        </li>
                        <li>
                                <a class="variable" href="#GroupCoordinator.pymscclpp_comm">pymscclpp_comm</a>
                        </li>
                        <li>
                                <a class="variable" href="#GroupCoordinator.qr_comm">qr_comm</a>
                        </li>
                        <li>
                                <a class="variable" href="#GroupCoordinator.hpu_communicator">hpu_communicator</a>
                        </li>
                        <li>
                                <a class="variable" href="#GroupCoordinator.xpu_communicator">xpu_communicator</a>
                        </li>
                        <li>
                                <a class="variable" href="#GroupCoordinator.npu_communicator">npu_communicator</a>
                        </li>
                        <li>
                                <a class="variable" href="#GroupCoordinator.first_rank">first_rank</a>
                        </li>
                        <li>
                                <a class="variable" href="#GroupCoordinator.last_rank">last_rank</a>
                        </li>
                        <li>
                                <a class="variable" href="#GroupCoordinator.is_first_rank">is_first_rank</a>
                        </li>
                        <li>
                                <a class="variable" href="#GroupCoordinator.is_last_rank">is_last_rank</a>
                        </li>
                        <li>
                                <a class="variable" href="#GroupCoordinator.next_rank">next_rank</a>
                        </li>
                        <li>
                                <a class="variable" href="#GroupCoordinator.prev_rank">prev_rank</a>
                        </li>
                        <li>
                                <a class="function" href="#GroupCoordinator.graph_capture">graph_capture</a>
                        </li>
                        <li>
                                <a class="function" href="#GroupCoordinator.all_reduce">all_reduce</a>
                        </li>
                        <li>
                                <a class="function" href="#GroupCoordinator.reduce_scatter_tensor">reduce_scatter_tensor</a>
                        </li>
                        <li>
                                <a class="function" href="#GroupCoordinator.reduce_scatter">reduce_scatter</a>
                        </li>
                        <li>
                                <a class="function" href="#GroupCoordinator.reduce_scatterv">reduce_scatterv</a>
                        </li>
                        <li>
                                <a class="function" href="#GroupCoordinator.all_gather_into_tensor">all_gather_into_tensor</a>
                        </li>
                        <li>
                                <a class="function" href="#GroupCoordinator.all_gather">all_gather</a>
                        </li>
                        <li>
                                <a class="function" href="#GroupCoordinator.all_gatherv">all_gatherv</a>
                        </li>
                        <li>
                                <a class="function" href="#GroupCoordinator.gather">gather</a>
                        </li>
                        <li>
                                <a class="function" href="#GroupCoordinator.broadcast">broadcast</a>
                        </li>
                        <li>
                                <a class="function" href="#GroupCoordinator.broadcast_object">broadcast_object</a>
                        </li>
                        <li>
                                <a class="function" href="#GroupCoordinator.broadcast_object_list">broadcast_object_list</a>
                        </li>
                        <li>
                                <a class="function" href="#GroupCoordinator.send_object">send_object</a>
                        </li>
                        <li>
                                <a class="function" href="#GroupCoordinator.recv_object">recv_object</a>
                        </li>
                        <li>
                                <a class="function" href="#GroupCoordinator.broadcast_tensor_dict">broadcast_tensor_dict</a>
                        </li>
                        <li>
                                <a class="function" href="#GroupCoordinator.send_tensor_dict">send_tensor_dict</a>
                        </li>
                        <li>
                                <a class="function" href="#GroupCoordinator.recv_tensor_dict">recv_tensor_dict</a>
                        </li>
                        <li>
                                <a class="function" href="#GroupCoordinator.barrier">barrier</a>
                        </li>
                        <li>
                                <a class="function" href="#GroupCoordinator.send">send</a>
                        </li>
                        <li>
                                <a class="function" href="#GroupCoordinator.recv">recv</a>
                        </li>
                        <li>
                                <a class="function" href="#GroupCoordinator.destroy">destroy</a>
                        </li>
                </ul>

            </li>
            <li>
                    <a class="function" href="#get_world_group">get_world_group</a>
            </li>
            <li>
                    <a class="function" href="#init_world_group">init_world_group</a>
            </li>
            <li>
                    <a class="function" href="#init_model_parallel_group">init_model_parallel_group</a>
            </li>
            <li>
                    <a class="function" href="#set_pdmux_status">set_pdmux_status</a>
            </li>
            <li>
                    <a class="function" href="#get_tp_group">get_tp_group</a>
            </li>
            <li>
                    <a class="function" href="#get_moe_ep_group">get_moe_ep_group</a>
            </li>
            <li>
                    <a class="function" href="#get_moe_tp_group">get_moe_tp_group</a>
            </li>
            <li>
                    <a class="function" href="#get_tensor_model_parallel_group">get_tensor_model_parallel_group</a>
            </li>
            <li>
                    <a class="function" href="#get_pp_group">get_pp_group</a>
            </li>
            <li>
                    <a class="function" href="#get_pipeline_model_parallel_group">get_pipeline_model_parallel_group</a>
            </li>
            <li>
                    <a class="function" href="#graph_capture">graph_capture</a>
            </li>
            <li>
                    <a class="variable" href="#logger">logger</a>
            </li>
            <li>
                    <a class="function" href="#set_custom_all_reduce">set_custom_all_reduce</a>
            </li>
            <li>
                    <a class="function" href="#set_mscclpp_all_reduce">set_mscclpp_all_reduce</a>
            </li>
            <li>
                    <a class="function" href="#init_distributed_environment">init_distributed_environment</a>
            </li>
            <li>
                    <a class="function" href="#initialize_model_parallel">initialize_model_parallel</a>
            </li>
            <li>
                    <a class="function" href="#ensure_model_parallel_initialized">ensure_model_parallel_initialized</a>
            </li>
            <li>
                    <a class="function" href="#model_parallel_is_initialized">model_parallel_is_initialized</a>
            </li>
            <li>
                    <a class="function" href="#patch_tensor_parallel_group">patch_tensor_parallel_group</a>
            </li>
            <li>
                    <a class="function" href="#get_tensor_model_parallel_world_size">get_tensor_model_parallel_world_size</a>
            </li>
            <li>
                    <a class="function" href="#get_tensor_model_parallel_rank">get_tensor_model_parallel_rank</a>
            </li>
            <li>
                    <a class="function" href="#get_moe_expert_parallel_world_size">get_moe_expert_parallel_world_size</a>
            </li>
            <li>
                    <a class="function" href="#get_moe_expert_parallel_rank">get_moe_expert_parallel_rank</a>
            </li>
            <li>
                    <a class="function" href="#get_moe_tensor_parallel_world_size">get_moe_tensor_parallel_world_size</a>
            </li>
            <li>
                    <a class="function" href="#get_moe_tensor_parallel_rank">get_moe_tensor_parallel_rank</a>
            </li>
            <li>
                    <a class="function" href="#destroy_model_parallel">destroy_model_parallel</a>
            </li>
            <li>
                    <a class="function" href="#destroy_distributed_environment">destroy_distributed_environment</a>
            </li>
            <li>
                    <a class="function" href="#cleanup_dist_env_and_memory">cleanup_dist_env_and_memory</a>
            </li>
            <li>
                    <a class="function" href="#in_the_same_node_as">in_the_same_node_as</a>
            </li>
            <li>
                    <a class="variable" href="#vllm_get_pp_group">vllm_get_pp_group</a>
            </li>
            <li>
                    <a class="variable" href="#vllm_get_tp_group">vllm_get_tp_group</a>
            </li>
            <li>
                    <a class="variable" href="#vllm_get_world_group">vllm_get_world_group</a>
            </li>
            <li>
                    <a class="function" href="#monkey_patch_vllm_parallel_state">monkey_patch_vllm_parallel_state</a>
            </li>
            <li>
                    <a class="function" href="#inplace_all_reduce">inplace_all_reduce</a>
            </li>
            <li>
                    <a class="function" href="#inplace_all_reduce_fake">inplace_all_reduce_fake</a>
            </li>
            <li>
                    <a class="function" href="#outplace_all_reduce">outplace_all_reduce</a>
            </li>
            <li>
                    <a class="function" href="#outplace_all_reduce_fake">outplace_all_reduce_fake</a>
            </li>
            <li>
                    <a class="function" href="#reg_all_gather_into_tensor">reg_all_gather_into_tensor</a>
            </li>
            <li>
                    <a class="function" href="#reg_all_gather_into_tensor_fake">reg_all_gather_into_tensor_fake</a>
            </li>
    </ul>



        <a class="attribution" title="pdoc: Python API documentation generator" href="https://pdoc.dev" target="_blank">
            built with <span class="visually-hidden">pdoc</span><img
                alt="pdoc logo"
                src="data:image/svg+xml,%3Csvg%20xmlns%3D%22http%3A//www.w3.org/2000/svg%22%20role%3D%22img%22%20aria-label%3D%22pdoc%20logo%22%20width%3D%22300%22%20height%3D%22150%22%20viewBox%3D%22-1%200%2060%2030%22%3E%3Ctitle%3Epdoc%3C/title%3E%3Cpath%20d%3D%22M29.621%2021.293c-.011-.273-.214-.475-.511-.481a.5.5%200%200%200-.489.503l-.044%201.393c-.097.551-.695%201.215-1.566%201.704-.577.428-1.306.486-2.193.182-1.426-.617-2.467-1.654-3.304-2.487l-.173-.172a3.43%203.43%200%200%200-.365-.306.49.49%200%200%200-.286-.196c-1.718-1.06-4.931-1.47-7.353.191l-.219.15c-1.707%201.187-3.413%202.131-4.328%201.03-.02-.027-.49-.685-.141-1.763.233-.721.546-2.408.772-4.076.042-.09.067-.187.046-.288.166-1.347.277-2.625.241-3.351%201.378-1.008%202.271-2.586%202.271-4.362%200-.976-.272-1.935-.788-2.774-.057-.094-.122-.18-.184-.268.033-.167.052-.339.052-.516%200-1.477-1.202-2.679-2.679-2.679-.791%200-1.496.352-1.987.9a6.3%206.3%200%200%200-1.001.029c-.492-.564-1.207-.929-2.012-.929-1.477%200-2.679%201.202-2.679%202.679A2.65%202.65%200%200%200%20.97%206.554c-.383.747-.595%201.572-.595%202.41%200%202.311%201.507%204.29%203.635%205.107-.037.699-.147%202.27-.423%203.294l-.137.461c-.622%202.042-2.515%208.257%201.727%2010.643%201.614.908%203.06%201.248%204.317%201.248%202.665%200%204.492-1.524%205.322-2.401%201.476-1.559%202.886-1.854%206.491.82%201.877%201.393%203.514%201.753%204.861%201.068%202.223-1.713%202.811-3.867%203.399-6.374.077-.846.056-1.469.054-1.537zm-4.835%204.313c-.054.305-.156.586-.242.629-.034-.007-.131-.022-.307-.157-.145-.111-.314-.478-.456-.908.221.121.432.25.675.355.115.039.219.051.33.081zm-2.251-1.238c-.05.33-.158.648-.252.694-.022.001-.125-.018-.307-.157-.217-.166-.488-.906-.639-1.573.358.344.754.693%201.198%201.036zm-3.887-2.337c-.006-.116-.018-.231-.041-.342.635.145%201.189.368%201.599.625.097.231.166.481.174.642-.03.049-.055.101-.067.158-.046.013-.128.026-.298.004-.278-.037-.901-.57-1.367-1.087zm-1.127-.497c.116.306.176.625.12.71-.019.014-.117.045-.345.016-.206-.027-.604-.332-.986-.695.41-.051.816-.056%201.211-.031zm-4.535%201.535c.209.22.379.47.358.598-.006.041-.088.138-.351.234-.144.055-.539-.063-.979-.259a11.66%2011.66%200%200%200%20.972-.573zm.983-.664c.359-.237.738-.418%201.126-.554.25.237.479.548.457.694-.006.042-.087.138-.351.235-.174.064-.694-.105-1.232-.375zm-3.381%201.794c-.022.145-.061.29-.149.401-.133.166-.358.248-.69.251h-.002c-.133%200-.306-.26-.45-.621.417.091.854.07%201.291-.031zm-2.066-8.077a4.78%204.78%200%200%201-.775-.584c.172-.115.505-.254.88-.378l-.105.962zm-.331%202.302a10.32%2010.32%200%200%201-.828-.502c.202-.143.576-.328.984-.49l-.156.992zm-.45%202.157l-.701-.403c.214-.115.536-.249.891-.376a11.57%2011.57%200%200%201-.19.779zm-.181%201.716c.064.398.194.702.298.893-.194-.051-.435-.162-.736-.398.061-.119.224-.3.438-.495zM8.87%204.141c0%20.152-.123.276-.276.276s-.275-.124-.275-.276.123-.276.276-.276.275.124.275.276zm-.735-.389a1.15%201.15%200%200%200-.314.783%201.16%201.16%200%200%200%201.162%201.162c.457%200%20.842-.27%201.032-.653.026.117.042.238.042.362a1.68%201.68%200%200%201-1.679%201.679%201.68%201.68%200%200%201-1.679-1.679c0-.843.626-1.535%201.436-1.654zM5.059%205.406A1.68%201.68%200%200%201%203.38%207.085a1.68%201.68%200%200%201-1.679-1.679c0-.037.009-.072.011-.109.21.3.541.508.935.508a1.16%201.16%200%200%200%201.162-1.162%201.14%201.14%200%200%200-.474-.912c.015%200%20.03-.005.045-.005.926.001%201.679.754%201.679%201.68zM3.198%204.141c0%20.152-.123.276-.276.276s-.275-.124-.275-.276.123-.276.276-.276.275.124.275.276zM1.375%208.964c0-.52.103-1.035.288-1.52.466.394%201.06.64%201.717.64%201.144%200%202.116-.725%202.499-1.738.383%201.012%201.355%201.738%202.499%201.738.867%200%201.631-.421%202.121-1.062.307.605.478%201.267.478%201.942%200%202.486-2.153%204.51-4.801%204.51s-4.801-2.023-4.801-4.51zm24.342%2019.349c-.985.498-2.267.168-3.813-.979-3.073-2.281-5.453-3.199-7.813-.705-1.315%201.391-4.163%203.365-8.423.97-3.174-1.786-2.239-6.266-1.261-9.479l.146-.492c.276-1.02.395-2.457.444-3.268a6.11%206.11%200%200%200%201.18.115%206.01%206.01%200%200%200%202.536-.562l-.006.175c-.802.215-1.848.612-2.021%201.25-.079.295.021.601.274.837.219.203.415.364.598.501-.667.304-1.243.698-1.311%201.179-.02.144-.022.507.393.787.213.144.395.26.564.365-1.285.521-1.361.96-1.381%201.126-.018.142-.011.496.427.746l.854.489c-.473.389-.971.914-.999%201.429-.018.278.095.532.316.713.675.556%201.231.721%201.653.721.059%200%20.104-.014.158-.02.207.707.641%201.64%201.513%201.64h.013c.8-.008%201.236-.345%201.462-.626.173-.216.268-.457.325-.692.424.195.93.374%201.372.374.151%200%20.294-.021.423-.068.732-.27.944-.704.993-1.021.009-.061.003-.119.002-.179.266.086.538.147.789.147.15%200%20.294-.021.423-.069.542-.2.797-.489.914-.754.237.147.478.258.704.288.106.014.205.021.296.021.356%200%20.595-.101.767-.229.438.435%201.094.992%201.656%201.067.106.014.205.021.296.021a1.56%201.56%200%200%200%20.323-.035c.17.575.453%201.289.866%201.605.358.273.665.362.914.362a.99.99%200%200%200%20.421-.093%201.03%201.03%200%200%200%20.245-.164c.168.428.39.846.68%201.068.358.273.665.362.913.362a.99.99%200%200%200%20.421-.093c.317-.148.512-.448.639-.762.251.157.495.257.726.257.127%200%20.25-.024.37-.071.427-.17.706-.617.841-1.314.022-.015.047-.022.068-.038.067-.051.133-.104.196-.159-.443%201.486-1.107%202.761-2.086%203.257zM8.66%209.925a.5.5%200%201%200-1%200c0%20.653-.818%201.205-1.787%201.205s-1.787-.552-1.787-1.205a.5.5%200%201%200-1%200c0%201.216%201.25%202.205%202.787%202.205s2.787-.989%202.787-2.205zm4.4%2015.965l-.208.097c-2.661%201.258-4.708%201.436-6.086.527-1.542-1.017-1.88-3.19-1.844-4.198a.4.4%200%200%200-.385-.414c-.242-.029-.406.164-.414.385-.046%201.249.367%203.686%202.202%204.896.708.467%201.547.7%202.51.7%201.248%200%202.706-.392%204.362-1.174l.185-.086a.4.4%200%200%200%20.205-.527c-.089-.204-.326-.291-.527-.206zM9.547%202.292c.093.077.205.114.317.114a.5.5%200%200%200%20.318-.886L8.817.397a.5.5%200%200%200-.703.068.5.5%200%200%200%20.069.703l1.364%201.124zm-7.661-.065c.086%200%20.173-.022.253-.068l1.523-.893a.5.5%200%200%200-.506-.863l-1.523.892a.5.5%200%200%200-.179.685c.094.158.261.247.432.247z%22%20transform%3D%22matrix%28-1%200%200%201%2058%200%29%22%20fill%3D%22%233bb300%22/%3E%3Cpath%20d%3D%22M.3%2021.86V10.18q0-.46.02-.68.04-.22.18-.5.28-.54%201.34-.54%201.06%200%201.42.28.38.26.44.78.76-1.04%202.38-1.04%201.64%200%203.1%201.54%201.46%201.54%201.46%203.58%200%202.04-1.46%203.58-1.44%201.54-3.08%201.54-1.64%200-2.38-.92v4.04q0%20.46-.04.68-.02.22-.18.5-.14.3-.5.42-.36.12-.98.12-.62%200-1-.12-.36-.12-.52-.4-.14-.28-.18-.5-.02-.22-.02-.68zm3.96-9.42q-.46.54-.46%201.18%200%20.64.46%201.18.48.52%201.2.52.74%200%201.24-.52.52-.52.52-1.18%200-.66-.48-1.18-.48-.54-1.26-.54-.76%200-1.22.54zm14.741-8.36q.16-.3.54-.42.38-.12%201-.12.64%200%201.02.12.38.12.52.42.16.3.18.54.04.22.04.68v11.94q0%20.46-.04.7-.02.22-.18.5-.3.54-1.7.54-1.38%200-1.54-.98-.84.96-2.34.96-1.8%200-3.28-1.56-1.48-1.58-1.48-3.66%200-2.1%201.48-3.68%201.5-1.58%203.28-1.58%201.48%200%202.3%201v-4.2q0-.46.02-.68.04-.24.18-.52zm-3.24%2010.86q.52.54%201.26.54.74%200%201.22-.54.5-.54.5-1.18%200-.66-.48-1.22-.46-.56-1.26-.56-.8%200-1.28.56-.48.54-.48%201.2%200%20.66.52%201.2zm7.833-1.2q0-2.4%201.68-3.96%201.68-1.56%203.84-1.56%202.16%200%203.82%201.56%201.66%201.54%201.66%203.94%200%201.66-.86%202.96-.86%201.28-2.1%201.9-1.22.6-2.54.6-1.32%200-2.56-.64-1.24-.66-2.1-1.92-.84-1.28-.84-2.88zm4.18%201.44q.64.48%201.3.48.66%200%201.32-.5.66-.5.66-1.48%200-.98-.62-1.46-.62-.48-1.34-.48-.72%200-1.34.5-.62.5-.62%201.48%200%20.96.64%201.46zm11.412-1.44q0%20.84.56%201.32.56.46%201.18.46.64%200%201.18-.36.56-.38.9-.38.6%200%201.46%201.06.46.58.46%201.04%200%20.76-1.1%201.42-1.14.8-2.8.8-1.86%200-3.58-1.34-.82-.64-1.34-1.7-.52-1.08-.52-2.36%200-1.3.52-2.34.52-1.06%201.34-1.7%201.66-1.32%203.54-1.32.76%200%201.48.22.72.2%201.06.4l.32.2q.36.24.56.38.52.4.52.92%200%20.5-.42%201.14-.72%201.1-1.38%201.1-.38%200-1.08-.44-.36-.34-1.04-.34-.66%200-1.24.48-.58.48-.58%201.34z%22%20fill%3D%22green%22/%3E%3C/svg%3E"/>
        </a>
</div>
    </nav>
    <main class="pdoc">
            <section class="module-info">
                    <h1 class="modulename">
sglang<wbr>.<a href="./../../srt.html">srt</a><wbr>.<a href="./../distributed.html">distributed</a><wbr>.parallel_state    </h1>

                        <div class="docstring"><p>vLLM distributed state.
It takes over the control of the distributed environment from PyTorch.
The typical workflow is:</p>

<ul>
<li>call <code><a href="#init_distributed_environment">init_distributed_environment</a></code> to initialize the distributed environment.</li>
<li><p>call <code><a href="#initialize_model_parallel">initialize_model_parallel</a></code> or <code><a href="#ensure_model_parallel_initialized">ensure_model_parallel_initialized</a></code> to
initialize the model parallel groups.</p></li>
<li><p>any code dealing with the distributed stuff</p></li>
<li><p>call <code><a href="#destroy_model_parallel">destroy_model_parallel</a></code> to destroy the model parallel groups.</p></li>
<li>call <code><a href="#destroy_distributed_environment">destroy_distributed_environment</a></code> to destroy the distributed environment.</li>
</ul>

<p>If you only need to use the distributed environment without model/pipeline
 parallelism, you can skip the model parallel initialization and destruction
 steps.</p>
</div>

                        <input id="mod-parallel_state-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">

                        <label class="view-source-button" for="mod-parallel_state-view-source"><span>View Source</span></label>

                        <div class="pdoc-code codehilite"><pre><span></span><span id="L-1"><a href="#L-1"><span class="linenos">   1</span></a><span class="c1"># Adapted from https://github.com/vllm-project/vllm/blob/v0.6.4.post1/vllm/distributed/parallel_state.py</span>
</span><span id="L-2"><a href="#L-2"><span class="linenos">   2</span></a>
</span><span id="L-3"><a href="#L-3"><span class="linenos">   3</span></a><span class="c1"># Copyright 2023 The vLLM team.</span>
</span><span id="L-4"><a href="#L-4"><span class="linenos">   4</span></a><span class="c1"># Adapted from</span>
</span><span id="L-5"><a href="#L-5"><span class="linenos">   5</span></a><span class="c1"># https://github.com/NVIDIA/Megatron-LM/blob/main/megatron/core/parallel_state.py</span>
</span><span id="L-6"><a href="#L-6"><span class="linenos">   6</span></a><span class="c1"># Copyright (c) 2022, NVIDIA CORPORATION. All rights reserved.</span>
</span><span id="L-7"><a href="#L-7"><span class="linenos">   7</span></a><span class="sd">&quot;&quot;&quot;vLLM distributed state.</span>
</span><span id="L-8"><a href="#L-8"><span class="linenos">   8</span></a><span class="sd">It takes over the control of the distributed environment from PyTorch.</span>
</span><span id="L-9"><a href="#L-9"><span class="linenos">   9</span></a><span class="sd">The typical workflow is:</span>
</span><span id="L-10"><a href="#L-10"><span class="linenos">  10</span></a>
</span><span id="L-11"><a href="#L-11"><span class="linenos">  11</span></a><span class="sd">- call `init_distributed_environment` to initialize the distributed environment.</span>
</span><span id="L-12"><a href="#L-12"><span class="linenos">  12</span></a><span class="sd">- call `initialize_model_parallel` or `ensure_model_parallel_initialized` to</span>
</span><span id="L-13"><a href="#L-13"><span class="linenos">  13</span></a><span class="sd"> initialize the model parallel groups.</span>
</span><span id="L-14"><a href="#L-14"><span class="linenos">  14</span></a>
</span><span id="L-15"><a href="#L-15"><span class="linenos">  15</span></a><span class="sd">- any code dealing with the distributed stuff</span>
</span><span id="L-16"><a href="#L-16"><span class="linenos">  16</span></a>
</span><span id="L-17"><a href="#L-17"><span class="linenos">  17</span></a><span class="sd">- call `destroy_model_parallel` to destroy the model parallel groups.</span>
</span><span id="L-18"><a href="#L-18"><span class="linenos">  18</span></a><span class="sd">- call `destroy_distributed_environment` to destroy the distributed environment.</span>
</span><span id="L-19"><a href="#L-19"><span class="linenos">  19</span></a>
</span><span id="L-20"><a href="#L-20"><span class="linenos">  20</span></a><span class="sd">If you only need to use the distributed environment without model/pipeline</span>
</span><span id="L-21"><a href="#L-21"><span class="linenos">  21</span></a><span class="sd"> parallelism, you can skip the model parallel initialization and destruction</span>
</span><span id="L-22"><a href="#L-22"><span class="linenos">  22</span></a><span class="sd"> steps.</span>
</span><span id="L-23"><a href="#L-23"><span class="linenos">  23</span></a><span class="sd">&quot;&quot;&quot;</span>
</span><span id="L-24"><a href="#L-24"><span class="linenos">  24</span></a><span class="kn">import</span><span class="w"> </span><span class="nn">contextlib</span>
</span><span id="L-25"><a href="#L-25"><span class="linenos">  25</span></a><span class="kn">import</span><span class="w"> </span><span class="nn">gc</span>
</span><span id="L-26"><a href="#L-26"><span class="linenos">  26</span></a><span class="kn">import</span><span class="w"> </span><span class="nn">logging</span>
</span><span id="L-27"><a href="#L-27"><span class="linenos">  27</span></a><span class="kn">import</span><span class="w"> </span><span class="nn">os</span>
</span><span id="L-28"><a href="#L-28"><span class="linenos">  28</span></a><span class="kn">import</span><span class="w"> </span><span class="nn">pickle</span>
</span><span id="L-29"><a href="#L-29"><span class="linenos">  29</span></a><span class="kn">import</span><span class="w"> </span><span class="nn">weakref</span>
</span><span id="L-30"><a href="#L-30"><span class="linenos">  30</span></a><span class="kn">from</span><span class="w"> </span><span class="nn">collections</span><span class="w"> </span><span class="kn">import</span> <span class="n">namedtuple</span>
</span><span id="L-31"><a href="#L-31"><span class="linenos">  31</span></a><span class="kn">from</span><span class="w"> </span><span class="nn">contextlib</span><span class="w"> </span><span class="kn">import</span> <span class="n">contextmanager</span><span class="p">,</span> <span class="n">nullcontext</span>
</span><span id="L-32"><a href="#L-32"><span class="linenos">  32</span></a><span class="kn">from</span><span class="w"> </span><span class="nn">dataclasses</span><span class="w"> </span><span class="kn">import</span> <span class="n">dataclass</span>
</span><span id="L-33"><a href="#L-33"><span class="linenos">  33</span></a><span class="kn">from</span><span class="w"> </span><span class="nn">datetime</span><span class="w"> </span><span class="kn">import</span> <span class="n">timedelta</span>
</span><span id="L-34"><a href="#L-34"><span class="linenos">  34</span></a><span class="kn">from</span><span class="w"> </span><span class="nn">multiprocessing</span><span class="w"> </span><span class="kn">import</span> <span class="n">shared_memory</span>
</span><span id="L-35"><a href="#L-35"><span class="linenos">  35</span></a><span class="kn">from</span><span class="w"> </span><span class="nn">typing</span><span class="w"> </span><span class="kn">import</span> <span class="n">Any</span><span class="p">,</span> <span class="n">Callable</span><span class="p">,</span> <span class="n">Dict</span><span class="p">,</span> <span class="n">List</span><span class="p">,</span> <span class="n">Optional</span><span class="p">,</span> <span class="n">Tuple</span><span class="p">,</span> <span class="n">Union</span>
</span><span id="L-36"><a href="#L-36"><span class="linenos">  36</span></a><span class="kn">from</span><span class="w"> </span><span class="nn">unittest.mock</span><span class="w"> </span><span class="kn">import</span> <span class="n">patch</span>
</span><span id="L-37"><a href="#L-37"><span class="linenos">  37</span></a>
</span><span id="L-38"><a href="#L-38"><span class="linenos">  38</span></a><span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
</span><span id="L-39"><a href="#L-39"><span class="linenos">  39</span></a><span class="kn">import</span><span class="w"> </span><span class="nn">torch.distributed</span>
</span><span id="L-40"><a href="#L-40"><span class="linenos">  40</span></a><span class="kn">from</span><span class="w"> </span><span class="nn">torch.distributed</span><span class="w"> </span><span class="kn">import</span> <span class="n">Backend</span><span class="p">,</span> <span class="n">ProcessGroup</span>
</span><span id="L-41"><a href="#L-41"><span class="linenos">  41</span></a>
</span><span id="L-42"><a href="#L-42"><span class="linenos">  42</span></a><span class="kn">from</span><span class="w"> </span><span class="nn">sglang.srt.utils</span><span class="w"> </span><span class="kn">import</span> <span class="p">(</span>
</span><span id="L-43"><a href="#L-43"><span class="linenos">  43</span></a>    <span class="n">direct_register_custom_op</span><span class="p">,</span>
</span><span id="L-44"><a href="#L-44"><span class="linenos">  44</span></a>    <span class="n">get_bool_env_var</span><span class="p">,</span>
</span><span id="L-45"><a href="#L-45"><span class="linenos">  45</span></a>    <span class="n">get_int_env_var</span><span class="p">,</span>
</span><span id="L-46"><a href="#L-46"><span class="linenos">  46</span></a>    <span class="n">is_cuda_alike</span><span class="p">,</span>
</span><span id="L-47"><a href="#L-47"><span class="linenos">  47</span></a>    <span class="n">is_hip</span><span class="p">,</span>
</span><span id="L-48"><a href="#L-48"><span class="linenos">  48</span></a>    <span class="n">is_npu</span><span class="p">,</span>
</span><span id="L-49"><a href="#L-49"><span class="linenos">  49</span></a>    <span class="n">is_shm_available</span><span class="p">,</span>
</span><span id="L-50"><a href="#L-50"><span class="linenos">  50</span></a>    <span class="n">supports_custom_op</span><span class="p">,</span>
</span><span id="L-51"><a href="#L-51"><span class="linenos">  51</span></a><span class="p">)</span>
</span><span id="L-52"><a href="#L-52"><span class="linenos">  52</span></a>
</span><span id="L-53"><a href="#L-53"><span class="linenos">  53</span></a><span class="n">_is_npu</span> <span class="o">=</span> <span class="n">is_npu</span><span class="p">()</span>
</span><span id="L-54"><a href="#L-54"><span class="linenos">  54</span></a>
</span><span id="L-55"><a href="#L-55"><span class="linenos">  55</span></a>
</span><span id="L-56"><a href="#L-56"><span class="linenos">  56</span></a><span class="nd">@dataclass</span>
</span><span id="L-57"><a href="#L-57"><span class="linenos">  57</span></a><span class="k">class</span><span class="w"> </span><span class="nc">GraphCaptureContext</span><span class="p">:</span>
</span><span id="L-58"><a href="#L-58"><span class="linenos">  58</span></a>    <span class="n">stream</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">Stream</span> <span class="k">if</span> <span class="ow">not</span> <span class="n">_is_npu</span> <span class="k">else</span> <span class="n">torch</span><span class="o">.</span><span class="n">npu</span><span class="o">.</span><span class="n">Stream</span>
</span><span id="L-59"><a href="#L-59"><span class="linenos">  59</span></a>
</span><span id="L-60"><a href="#L-60"><span class="linenos">  60</span></a>
</span><span id="L-61"><a href="#L-61"><span class="linenos">  61</span></a><span class="n">TensorMetadata</span> <span class="o">=</span> <span class="n">namedtuple</span><span class="p">(</span><span class="s2">&quot;TensorMetadata&quot;</span><span class="p">,</span> <span class="p">[</span><span class="s2">&quot;device&quot;</span><span class="p">,</span> <span class="s2">&quot;dtype&quot;</span><span class="p">,</span> <span class="s2">&quot;size&quot;</span><span class="p">])</span>
</span><span id="L-62"><a href="#L-62"><span class="linenos">  62</span></a>
</span><span id="L-63"><a href="#L-63"><span class="linenos">  63</span></a>
</span><span id="L-64"><a href="#L-64"><span class="linenos">  64</span></a><span class="k">def</span><span class="w"> </span><span class="nf">_split_tensor_dict</span><span class="p">(</span>
</span><span id="L-65"><a href="#L-65"><span class="linenos">  65</span></a>    <span class="n">tensor_dict</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Union</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">Any</span><span class="p">]]</span>
</span><span id="L-66"><a href="#L-66"><span class="linenos">  66</span></a><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="n">Tuple</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]],</span> <span class="n">List</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]]:</span>
</span><span id="L-67"><a href="#L-67"><span class="linenos">  67</span></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;Split the tensor dictionary into two parts:</span>
</span><span id="L-68"><a href="#L-68"><span class="linenos">  68</span></a><span class="sd">    1. A list of (key, value) pairs. If the value is a tensor, it is replaced</span>
</span><span id="L-69"><a href="#L-69"><span class="linenos">  69</span></a><span class="sd">         by its metadata.</span>
</span><span id="L-70"><a href="#L-70"><span class="linenos">  70</span></a><span class="sd">    2. A list of tensors.</span>
</span><span id="L-71"><a href="#L-71"><span class="linenos">  71</span></a><span class="sd">    &quot;&quot;&quot;</span>
</span><span id="L-72"><a href="#L-72"><span class="linenos">  72</span></a>    <span class="n">metadata_list</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">Tuple</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]]</span> <span class="o">=</span> <span class="p">[]</span>
</span><span id="L-73"><a href="#L-73"><span class="linenos">  73</span></a>    <span class="n">tensor_list</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>
</span><span id="L-74"><a href="#L-74"><span class="linenos">  74</span></a>    <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">tensor_dict</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
</span><span id="L-75"><a href="#L-75"><span class="linenos">  75</span></a>        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">value</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">):</span>
</span><span id="L-76"><a href="#L-76"><span class="linenos">  76</span></a>            <span class="c1"># Note: we cannot use `value.device` here,</span>
</span><span id="L-77"><a href="#L-77"><span class="linenos">  77</span></a>            <span class="c1"># because it contains not only the device type but also the device</span>
</span><span id="L-78"><a href="#L-78"><span class="linenos">  78</span></a>            <span class="c1"># index (e.g. &quot;cuda:0&quot;). We only need the device type.</span>
</span><span id="L-79"><a href="#L-79"><span class="linenos">  79</span></a>            <span class="c1"># receiving side will set the device index.</span>
</span><span id="L-80"><a href="#L-80"><span class="linenos">  80</span></a>            <span class="n">device</span> <span class="o">=</span> <span class="n">value</span><span class="o">.</span><span class="n">device</span><span class="o">.</span><span class="n">type</span>
</span><span id="L-81"><a href="#L-81"><span class="linenos">  81</span></a>            <span class="n">metadata_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
</span><span id="L-82"><a href="#L-82"><span class="linenos">  82</span></a>                <span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="n">TensorMetadata</span><span class="p">(</span><span class="n">device</span><span class="p">,</span> <span class="n">value</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="n">value</span><span class="o">.</span><span class="n">size</span><span class="p">()))</span>
</span><span id="L-83"><a href="#L-83"><span class="linenos">  83</span></a>            <span class="p">)</span>
</span><span id="L-84"><a href="#L-84"><span class="linenos">  84</span></a>            <span class="n">tensor_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">value</span><span class="p">)</span>
</span><span id="L-85"><a href="#L-85"><span class="linenos">  85</span></a>        <span class="k">else</span><span class="p">:</span>
</span><span id="L-86"><a href="#L-86"><span class="linenos">  86</span></a>            <span class="n">metadata_list</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="n">key</span><span class="p">,</span> <span class="n">value</span><span class="p">))</span>
</span><span id="L-87"><a href="#L-87"><span class="linenos">  87</span></a>    <span class="k">return</span> <span class="n">metadata_list</span><span class="p">,</span> <span class="n">tensor_list</span>
</span><span id="L-88"><a href="#L-88"><span class="linenos">  88</span></a>
</span><span id="L-89"><a href="#L-89"><span class="linenos">  89</span></a>
</span><span id="L-90"><a href="#L-90"><span class="linenos">  90</span></a><span class="n">_group_name_counter</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="p">{}</span>
</span><span id="L-91"><a href="#L-91"><span class="linenos">  91</span></a>
</span><span id="L-92"><a href="#L-92"><span class="linenos">  92</span></a>
</span><span id="L-93"><a href="#L-93"><span class="linenos">  93</span></a><span class="k">def</span><span class="w"> </span><span class="nf">_get_unique_name</span><span class="p">(</span><span class="n">name</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
</span><span id="L-94"><a href="#L-94"><span class="linenos">  94</span></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;Get a unique name for the group.</span>
</span><span id="L-95"><a href="#L-95"><span class="linenos">  95</span></a><span class="sd">    Example:</span>
</span><span id="L-96"><a href="#L-96"><span class="linenos">  96</span></a><span class="sd">    _get_unique_name(&quot;tp&quot;) -&gt; &quot;tp:0&quot;</span>
</span><span id="L-97"><a href="#L-97"><span class="linenos">  97</span></a><span class="sd">    _get_unique_name(&quot;tp&quot;) -&gt; &quot;tp:1&quot;</span>
</span><span id="L-98"><a href="#L-98"><span class="linenos">  98</span></a><span class="sd">    &quot;&quot;&quot;</span>
</span><span id="L-99"><a href="#L-99"><span class="linenos">  99</span></a>    <span class="k">if</span> <span class="n">name</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">_group_name_counter</span><span class="p">:</span>
</span><span id="L-100"><a href="#L-100"><span class="linenos"> 100</span></a>        <span class="n">_group_name_counter</span><span class="p">[</span><span class="n">name</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>
</span><span id="L-101"><a href="#L-101"><span class="linenos"> 101</span></a>    <span class="n">newname</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">name</span><span class="si">}</span><span class="s2">:</span><span class="si">{</span><span class="n">_group_name_counter</span><span class="p">[</span><span class="n">name</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span>
</span><span id="L-102"><a href="#L-102"><span class="linenos"> 102</span></a>    <span class="n">_group_name_counter</span><span class="p">[</span><span class="n">name</span><span class="p">]</span> <span class="o">+=</span> <span class="mi">1</span>
</span><span id="L-103"><a href="#L-103"><span class="linenos"> 103</span></a>    <span class="k">return</span> <span class="n">newname</span>
</span><span id="L-104"><a href="#L-104"><span class="linenos"> 104</span></a>
</span><span id="L-105"><a href="#L-105"><span class="linenos"> 105</span></a>
</span><span id="L-106"><a href="#L-106"><span class="linenos"> 106</span></a><span class="n">_groups</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Callable</span><span class="p">[[],</span> <span class="n">Optional</span><span class="p">[</span><span class="s2">&quot;GroupCoordinator&quot;</span><span class="p">]]]</span> <span class="o">=</span> <span class="p">{}</span>
</span><span id="L-107"><a href="#L-107"><span class="linenos"> 107</span></a>
</span><span id="L-108"><a href="#L-108"><span class="linenos"> 108</span></a>
</span><span id="L-109"><a href="#L-109"><span class="linenos"> 109</span></a><span class="k">def</span><span class="w"> </span><span class="nf">_register_group</span><span class="p">(</span><span class="n">group</span><span class="p">:</span> <span class="s2">&quot;GroupCoordinator&quot;</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="L-110"><a href="#L-110"><span class="linenos"> 110</span></a>    <span class="n">_groups</span><span class="p">[</span><span class="n">group</span><span class="o">.</span><span class="n">unique_name</span><span class="p">]</span> <span class="o">=</span> <span class="n">weakref</span><span class="o">.</span><span class="n">ref</span><span class="p">(</span><span class="n">group</span><span class="p">)</span>
</span><span id="L-111"><a href="#L-111"><span class="linenos"> 111</span></a>
</span><span id="L-112"><a href="#L-112"><span class="linenos"> 112</span></a>
</span><span id="L-113"><a href="#L-113"><span class="linenos"> 113</span></a><span class="k">if</span> <span class="n">supports_custom_op</span><span class="p">():</span>
</span><span id="L-114"><a href="#L-114"><span class="linenos"> 114</span></a>
</span><span id="L-115"><a href="#L-115"><span class="linenos"> 115</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">inplace_all_reduce</span><span class="p">(</span><span class="n">tensor</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">group_name</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="L-116"><a href="#L-116"><span class="linenos"> 116</span></a>        <span class="k">assert</span> <span class="n">group_name</span> <span class="ow">in</span> <span class="n">_groups</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;Group </span><span class="si">{</span><span class="n">group_name</span><span class="si">}</span><span class="s2"> is not found.&quot;</span>
</span><span id="L-117"><a href="#L-117"><span class="linenos"> 117</span></a>        <span class="n">group</span> <span class="o">=</span> <span class="n">_groups</span><span class="p">[</span><span class="n">group_name</span><span class="p">]()</span>
</span><span id="L-118"><a href="#L-118"><span class="linenos"> 118</span></a>        <span class="k">if</span> <span class="n">group</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="L-119"><a href="#L-119"><span class="linenos"> 119</span></a>            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Group </span><span class="si">{</span><span class="n">group_name</span><span class="si">}</span><span class="s2"> is destroyed.&quot;</span><span class="p">)</span>
</span><span id="L-120"><a href="#L-120"><span class="linenos"> 120</span></a>        <span class="n">group</span><span class="o">.</span><span class="n">_all_reduce_in_place</span><span class="p">(</span><span class="n">tensor</span><span class="p">)</span>
</span><span id="L-121"><a href="#L-121"><span class="linenos"> 121</span></a>
</span><span id="L-122"><a href="#L-122"><span class="linenos"> 122</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">inplace_all_reduce_fake</span><span class="p">(</span><span class="n">tensor</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">group_name</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="L-123"><a href="#L-123"><span class="linenos"> 123</span></a>        <span class="k">return</span>
</span><span id="L-124"><a href="#L-124"><span class="linenos"> 124</span></a>
</span><span id="L-125"><a href="#L-125"><span class="linenos"> 125</span></a>    <span class="n">direct_register_custom_op</span><span class="p">(</span>
</span><span id="L-126"><a href="#L-126"><span class="linenos"> 126</span></a>        <span class="n">op_name</span><span class="o">=</span><span class="s2">&quot;inplace_all_reduce&quot;</span><span class="p">,</span>
</span><span id="L-127"><a href="#L-127"><span class="linenos"> 127</span></a>        <span class="n">op_func</span><span class="o">=</span><span class="n">inplace_all_reduce</span><span class="p">,</span>
</span><span id="L-128"><a href="#L-128"><span class="linenos"> 128</span></a>        <span class="n">mutates_args</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;tensor&quot;</span><span class="p">],</span>
</span><span id="L-129"><a href="#L-129"><span class="linenos"> 129</span></a>        <span class="n">fake_impl</span><span class="o">=</span><span class="n">inplace_all_reduce_fake</span><span class="p">,</span>
</span><span id="L-130"><a href="#L-130"><span class="linenos"> 130</span></a>    <span class="p">)</span>
</span><span id="L-131"><a href="#L-131"><span class="linenos"> 131</span></a>
</span><span id="L-132"><a href="#L-132"><span class="linenos"> 132</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">outplace_all_reduce</span><span class="p">(</span>
</span><span id="L-133"><a href="#L-133"><span class="linenos"> 133</span></a>        <span class="n">tensor</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">group_name</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">outplace_all_reduce_method</span><span class="p">:</span> <span class="nb">str</span>
</span><span id="L-134"><a href="#L-134"><span class="linenos"> 134</span></a>    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
</span><span id="L-135"><a href="#L-135"><span class="linenos"> 135</span></a>        <span class="k">assert</span> <span class="n">group_name</span> <span class="ow">in</span> <span class="n">_groups</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;Group </span><span class="si">{</span><span class="n">group_name</span><span class="si">}</span><span class="s2"> is not found.&quot;</span>
</span><span id="L-136"><a href="#L-136"><span class="linenos"> 136</span></a>        <span class="n">group</span> <span class="o">=</span> <span class="n">_groups</span><span class="p">[</span><span class="n">group_name</span><span class="p">]()</span>
</span><span id="L-137"><a href="#L-137"><span class="linenos"> 137</span></a>        <span class="k">if</span> <span class="n">group</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="L-138"><a href="#L-138"><span class="linenos"> 138</span></a>            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Group </span><span class="si">{</span><span class="n">group_name</span><span class="si">}</span><span class="s2"> is destroyed.&quot;</span><span class="p">)</span>
</span><span id="L-139"><a href="#L-139"><span class="linenos"> 139</span></a>        <span class="k">return</span> <span class="n">group</span><span class="o">.</span><span class="n">_all_reduce_out_place</span><span class="p">(</span><span class="n">tensor</span><span class="p">,</span> <span class="n">outplace_all_reduce_method</span><span class="p">)</span>
</span><span id="L-140"><a href="#L-140"><span class="linenos"> 140</span></a>
</span><span id="L-141"><a href="#L-141"><span class="linenos"> 141</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">outplace_all_reduce_fake</span><span class="p">(</span>
</span><span id="L-142"><a href="#L-142"><span class="linenos"> 142</span></a>        <span class="n">tensor</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">group_name</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">outplace_all_reduce_method</span><span class="p">:</span> <span class="nb">str</span>
</span><span id="L-143"><a href="#L-143"><span class="linenos"> 143</span></a>    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
</span><span id="L-144"><a href="#L-144"><span class="linenos"> 144</span></a>        <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">empty_like</span><span class="p">(</span><span class="n">tensor</span><span class="p">)</span>
</span><span id="L-145"><a href="#L-145"><span class="linenos"> 145</span></a>
</span><span id="L-146"><a href="#L-146"><span class="linenos"> 146</span></a>    <span class="n">direct_register_custom_op</span><span class="p">(</span>
</span><span id="L-147"><a href="#L-147"><span class="linenos"> 147</span></a>        <span class="n">op_name</span><span class="o">=</span><span class="s2">&quot;outplace_all_reduce&quot;</span><span class="p">,</span>
</span><span id="L-148"><a href="#L-148"><span class="linenos"> 148</span></a>        <span class="n">op_func</span><span class="o">=</span><span class="n">outplace_all_reduce</span><span class="p">,</span>
</span><span id="L-149"><a href="#L-149"><span class="linenos"> 149</span></a>        <span class="n">mutates_args</span><span class="o">=</span><span class="p">[],</span>
</span><span id="L-150"><a href="#L-150"><span class="linenos"> 150</span></a>        <span class="n">fake_impl</span><span class="o">=</span><span class="n">outplace_all_reduce_fake</span><span class="p">,</span>
</span><span id="L-151"><a href="#L-151"><span class="linenos"> 151</span></a>    <span class="p">)</span>
</span><span id="L-152"><a href="#L-152"><span class="linenos"> 152</span></a>
</span><span id="L-153"><a href="#L-153"><span class="linenos"> 153</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">reg_all_gather_into_tensor</span><span class="p">(</span>
</span><span id="L-154"><a href="#L-154"><span class="linenos"> 154</span></a>        <span class="n">output</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="nb">input</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">group_name</span><span class="p">:</span> <span class="nb">str</span>
</span><span id="L-155"><a href="#L-155"><span class="linenos"> 155</span></a>    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="L-156"><a href="#L-156"><span class="linenos"> 156</span></a>        <span class="k">assert</span> <span class="n">group_name</span> <span class="ow">in</span> <span class="n">_groups</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;Group </span><span class="si">{</span><span class="n">group_name</span><span class="si">}</span><span class="s2"> is not found.&quot;</span>
</span><span id="L-157"><a href="#L-157"><span class="linenos"> 157</span></a>        <span class="n">group</span> <span class="o">=</span> <span class="n">_groups</span><span class="p">[</span><span class="n">group_name</span><span class="p">]()</span>
</span><span id="L-158"><a href="#L-158"><span class="linenos"> 158</span></a>        <span class="k">if</span> <span class="n">group</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="L-159"><a href="#L-159"><span class="linenos"> 159</span></a>            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Group </span><span class="si">{</span><span class="n">group_name</span><span class="si">}</span><span class="s2"> is destroyed.&quot;</span><span class="p">)</span>
</span><span id="L-160"><a href="#L-160"><span class="linenos"> 160</span></a>        <span class="n">group</span><span class="o">.</span><span class="n">_all_gather_into_tensor</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="nb">input</span><span class="p">)</span>
</span><span id="L-161"><a href="#L-161"><span class="linenos"> 161</span></a>
</span><span id="L-162"><a href="#L-162"><span class="linenos"> 162</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">reg_all_gather_into_tensor_fake</span><span class="p">(</span>
</span><span id="L-163"><a href="#L-163"><span class="linenos"> 163</span></a>        <span class="n">output</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="nb">input</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">group_name</span><span class="p">:</span> <span class="nb">str</span>
</span><span id="L-164"><a href="#L-164"><span class="linenos"> 164</span></a>    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="L-165"><a href="#L-165"><span class="linenos"> 165</span></a>        <span class="k">pass</span>
</span><span id="L-166"><a href="#L-166"><span class="linenos"> 166</span></a>
</span><span id="L-167"><a href="#L-167"><span class="linenos"> 167</span></a>    <span class="n">direct_register_custom_op</span><span class="p">(</span>
</span><span id="L-168"><a href="#L-168"><span class="linenos"> 168</span></a>        <span class="n">op_name</span><span class="o">=</span><span class="s2">&quot;reg_all_gather_into_tensor&quot;</span><span class="p">,</span>
</span><span id="L-169"><a href="#L-169"><span class="linenos"> 169</span></a>        <span class="n">op_func</span><span class="o">=</span><span class="n">reg_all_gather_into_tensor</span><span class="p">,</span>
</span><span id="L-170"><a href="#L-170"><span class="linenos"> 170</span></a>        <span class="n">mutates_args</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;output&quot;</span><span class="p">],</span>
</span><span id="L-171"><a href="#L-171"><span class="linenos"> 171</span></a>        <span class="n">fake_impl</span><span class="o">=</span><span class="n">reg_all_gather_into_tensor_fake</span><span class="p">,</span>
</span><span id="L-172"><a href="#L-172"><span class="linenos"> 172</span></a>    <span class="p">)</span>
</span><span id="L-173"><a href="#L-173"><span class="linenos"> 173</span></a>
</span><span id="L-174"><a href="#L-174"><span class="linenos"> 174</span></a>
</span><span id="L-175"><a href="#L-175"><span class="linenos"> 175</span></a><span class="k">class</span><span class="w"> </span><span class="nc">GroupCoordinator</span><span class="p">:</span>
</span><span id="L-176"><a href="#L-176"><span class="linenos"> 176</span></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="L-177"><a href="#L-177"><span class="linenos"> 177</span></a><span class="sd">    PyTorch ProcessGroup wrapper for a group of processes.</span>
</span><span id="L-178"><a href="#L-178"><span class="linenos"> 178</span></a><span class="sd">    PyTorch ProcessGroup is bound to one specific communication backend,</span>
</span><span id="L-179"><a href="#L-179"><span class="linenos"> 179</span></a><span class="sd">        e.g. NCCL, Gloo, MPI, etc.</span>
</span><span id="L-180"><a href="#L-180"><span class="linenos"> 180</span></a><span class="sd">    GroupCoordinator takes charge of all the communication operations among</span>
</span><span id="L-181"><a href="#L-181"><span class="linenos"> 181</span></a><span class="sd">        the processes in the group. It can route the communication to</span>
</span><span id="L-182"><a href="#L-182"><span class="linenos"> 182</span></a><span class="sd">        a specific implementation (e.g. switch allreduce implementation</span>
</span><span id="L-183"><a href="#L-183"><span class="linenos"> 183</span></a><span class="sd">        based on the tensor size and cuda graph mode).</span>
</span><span id="L-184"><a href="#L-184"><span class="linenos"> 184</span></a><span class="sd">    &quot;&quot;&quot;</span>
</span><span id="L-185"><a href="#L-185"><span class="linenos"> 185</span></a>
</span><span id="L-186"><a href="#L-186"><span class="linenos"> 186</span></a>    <span class="c1"># available attributes:</span>
</span><span id="L-187"><a href="#L-187"><span class="linenos"> 187</span></a>    <span class="n">rank</span><span class="p">:</span> <span class="nb">int</span>  <span class="c1"># global rank</span>
</span><span id="L-188"><a href="#L-188"><span class="linenos"> 188</span></a>    <span class="n">ranks</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span>  <span class="c1"># global ranks in the group</span>
</span><span id="L-189"><a href="#L-189"><span class="linenos"> 189</span></a>    <span class="n">world_size</span><span class="p">:</span> <span class="nb">int</span>  <span class="c1"># size of the group</span>
</span><span id="L-190"><a href="#L-190"><span class="linenos"> 190</span></a>    <span class="c1"># difference between `local_rank` and `rank_in_group`:</span>
</span><span id="L-191"><a href="#L-191"><span class="linenos"> 191</span></a>    <span class="c1"># if we have a group of size 4 across two nodes:</span>
</span><span id="L-192"><a href="#L-192"><span class="linenos"> 192</span></a>    <span class="c1"># Process | Node | Rank | Local Rank | Rank in Group</span>
</span><span id="L-193"><a href="#L-193"><span class="linenos"> 193</span></a>    <span class="c1">#   0     |   0  |  0   |     0      |       0</span>
</span><span id="L-194"><a href="#L-194"><span class="linenos"> 194</span></a>    <span class="c1">#   1     |   0  |  1   |     1      |       1</span>
</span><span id="L-195"><a href="#L-195"><span class="linenos"> 195</span></a>    <span class="c1">#   2     |   1  |  2   |     0      |       2</span>
</span><span id="L-196"><a href="#L-196"><span class="linenos"> 196</span></a>    <span class="c1">#   3     |   1  |  3   |     1      |       3</span>
</span><span id="L-197"><a href="#L-197"><span class="linenos"> 197</span></a>    <span class="n">local_rank</span><span class="p">:</span> <span class="nb">int</span>  <span class="c1"># local rank used to assign devices</span>
</span><span id="L-198"><a href="#L-198"><span class="linenos"> 198</span></a>    <span class="n">rank_in_group</span><span class="p">:</span> <span class="nb">int</span>  <span class="c1"># rank inside the group</span>
</span><span id="L-199"><a href="#L-199"><span class="linenos"> 199</span></a>    <span class="n">cpu_group</span><span class="p">:</span> <span class="n">ProcessGroup</span>  <span class="c1"># group for CPU communication</span>
</span><span id="L-200"><a href="#L-200"><span class="linenos"> 200</span></a>    <span class="n">device_group</span><span class="p">:</span> <span class="n">ProcessGroup</span>  <span class="c1"># group for device communication</span>
</span><span id="L-201"><a href="#L-201"><span class="linenos"> 201</span></a>    <span class="n">use_pynccl</span><span class="p">:</span> <span class="nb">bool</span>  <span class="c1"># a hint of whether to use PyNccl</span>
</span><span id="L-202"><a href="#L-202"><span class="linenos"> 202</span></a>    <span class="n">use_pymscclpp</span><span class="p">:</span> <span class="nb">bool</span>  <span class="c1"># a hint of whether to use PyMsccl</span>
</span><span id="L-203"><a href="#L-203"><span class="linenos"> 203</span></a>    <span class="n">use_custom_allreduce</span><span class="p">:</span> <span class="nb">bool</span>  <span class="c1"># a hint of whether to use CustomAllreduce</span>
</span><span id="L-204"><a href="#L-204"><span class="linenos"> 204</span></a>    <span class="n">use_message_queue_broadcaster</span><span class="p">:</span> <span class="p">(</span>
</span><span id="L-205"><a href="#L-205"><span class="linenos"> 205</span></a>        <span class="nb">bool</span>  <span class="c1"># a hint of whether to use message queue broadcaster</span>
</span><span id="L-206"><a href="#L-206"><span class="linenos"> 206</span></a>    <span class="p">)</span>
</span><span id="L-207"><a href="#L-207"><span class="linenos"> 207</span></a>    <span class="c1"># communicators are only created for world size &gt; 1</span>
</span><span id="L-208"><a href="#L-208"><span class="linenos"> 208</span></a>    <span class="n">pynccl_comm</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Any</span><span class="p">]</span>  <span class="c1"># PyNccl communicator</span>
</span><span id="L-209"><a href="#L-209"><span class="linenos"> 209</span></a>    <span class="n">ca_comm</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Any</span><span class="p">]</span>  <span class="c1"># Custom allreduce communicator</span>
</span><span id="L-210"><a href="#L-210"><span class="linenos"> 210</span></a>    <span class="n">mq_broadcaster</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Any</span><span class="p">]</span>  <span class="c1"># shared memory broadcaster</span>
</span><span id="L-211"><a href="#L-211"><span class="linenos"> 211</span></a>
</span><span id="L-212"><a href="#L-212"><span class="linenos"> 212</span></a>    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
</span><span id="L-213"><a href="#L-213"><span class="linenos"> 213</span></a>        <span class="bp">self</span><span class="p">,</span>
</span><span id="L-214"><a href="#L-214"><span class="linenos"> 214</span></a>        <span class="n">group_ranks</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="nb">int</span><span class="p">]],</span>
</span><span id="L-215"><a href="#L-215"><span class="linenos"> 215</span></a>        <span class="n">local_rank</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
</span><span id="L-216"><a href="#L-216"><span class="linenos"> 216</span></a>        <span class="n">torch_distributed_backend</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Backend</span><span class="p">],</span>
</span><span id="L-217"><a href="#L-217"><span class="linenos"> 217</span></a>        <span class="n">use_pynccl</span><span class="p">:</span> <span class="nb">bool</span><span class="p">,</span>
</span><span id="L-218"><a href="#L-218"><span class="linenos"> 218</span></a>        <span class="n">use_pymscclpp</span><span class="p">:</span> <span class="nb">bool</span><span class="p">,</span>
</span><span id="L-219"><a href="#L-219"><span class="linenos"> 219</span></a>        <span class="n">use_custom_allreduce</span><span class="p">:</span> <span class="nb">bool</span><span class="p">,</span>
</span><span id="L-220"><a href="#L-220"><span class="linenos"> 220</span></a>        <span class="n">use_hpu_communicator</span><span class="p">:</span> <span class="nb">bool</span><span class="p">,</span>
</span><span id="L-221"><a href="#L-221"><span class="linenos"> 221</span></a>        <span class="n">use_xpu_communicator</span><span class="p">:</span> <span class="nb">bool</span><span class="p">,</span>
</span><span id="L-222"><a href="#L-222"><span class="linenos"> 222</span></a>        <span class="n">use_npu_communicator</span><span class="p">:</span> <span class="nb">bool</span><span class="p">,</span>
</span><span id="L-223"><a href="#L-223"><span class="linenos"> 223</span></a>        <span class="n">use_message_queue_broadcaster</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
</span><span id="L-224"><a href="#L-224"><span class="linenos"> 224</span></a>        <span class="n">group_name</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="L-225"><a href="#L-225"><span class="linenos"> 225</span></a>    <span class="p">):</span>
</span><span id="L-226"><a href="#L-226"><span class="linenos"> 226</span></a>        <span class="n">group_name</span> <span class="o">=</span> <span class="n">group_name</span> <span class="ow">or</span> <span class="s2">&quot;anonymous&quot;</span>
</span><span id="L-227"><a href="#L-227"><span class="linenos"> 227</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">unique_name</span> <span class="o">=</span> <span class="n">_get_unique_name</span><span class="p">(</span><span class="n">group_name</span><span class="p">)</span>
</span><span id="L-228"><a href="#L-228"><span class="linenos"> 228</span></a>        <span class="n">_register_group</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span>
</span><span id="L-229"><a href="#L-229"><span class="linenos"> 229</span></a>
</span><span id="L-230"><a href="#L-230"><span class="linenos"> 230</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">rank</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">distributed</span><span class="o">.</span><span class="n">get_rank</span><span class="p">()</span>
</span><span id="L-231"><a href="#L-231"><span class="linenos"> 231</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">local_rank</span> <span class="o">=</span> <span class="n">local_rank</span>
</span><span id="L-232"><a href="#L-232"><span class="linenos"> 232</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">device_group</span> <span class="o">=</span> <span class="kc">None</span>
</span><span id="L-233"><a href="#L-233"><span class="linenos"> 233</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">cpu_group</span> <span class="o">=</span> <span class="kc">None</span>
</span><span id="L-234"><a href="#L-234"><span class="linenos"> 234</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">local_size</span> <span class="o">=</span> <span class="n">get_int_env_var</span><span class="p">(</span><span class="s2">&quot;LOCAL_SIZE&quot;</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
</span><span id="L-235"><a href="#L-235"><span class="linenos"> 235</span></a>
</span><span id="L-236"><a href="#L-236"><span class="linenos"> 236</span></a>        <span class="k">for</span> <span class="n">ranks</span> <span class="ow">in</span> <span class="n">group_ranks</span><span class="p">:</span>
</span><span id="L-237"><a href="#L-237"><span class="linenos"> 237</span></a>            <span class="n">device_group</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">distributed</span><span class="o">.</span><span class="n">new_group</span><span class="p">(</span>
</span><span id="L-238"><a href="#L-238"><span class="linenos"> 238</span></a>                <span class="n">ranks</span><span class="p">,</span> <span class="n">backend</span><span class="o">=</span><span class="n">torch_distributed_backend</span>
</span><span id="L-239"><a href="#L-239"><span class="linenos"> 239</span></a>            <span class="p">)</span>
</span><span id="L-240"><a href="#L-240"><span class="linenos"> 240</span></a>            <span class="c1"># a group with `gloo` backend, to allow direct coordination between</span>
</span><span id="L-241"><a href="#L-241"><span class="linenos"> 241</span></a>            <span class="c1"># processes through the CPU.</span>
</span><span id="L-242"><a href="#L-242"><span class="linenos"> 242</span></a>            <span class="n">cpu_group</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">distributed</span><span class="o">.</span><span class="n">new_group</span><span class="p">(</span><span class="n">ranks</span><span class="p">,</span> <span class="n">backend</span><span class="o">=</span><span class="s2">&quot;gloo&quot;</span><span class="p">)</span>
</span><span id="L-243"><a href="#L-243"><span class="linenos"> 243</span></a>            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">rank</span> <span class="ow">in</span> <span class="n">ranks</span><span class="p">:</span>
</span><span id="L-244"><a href="#L-244"><span class="linenos"> 244</span></a>                <span class="bp">self</span><span class="o">.</span><span class="n">ranks</span> <span class="o">=</span> <span class="n">ranks</span>
</span><span id="L-245"><a href="#L-245"><span class="linenos"> 245</span></a>                <span class="bp">self</span><span class="o">.</span><span class="n">world_size</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">ranks</span><span class="p">)</span>
</span><span id="L-246"><a href="#L-246"><span class="linenos"> 246</span></a>                <span class="bp">self</span><span class="o">.</span><span class="n">rank_in_group</span> <span class="o">=</span> <span class="n">ranks</span><span class="o">.</span><span class="n">index</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">rank</span><span class="p">)</span>
</span><span id="L-247"><a href="#L-247"><span class="linenos"> 247</span></a>                <span class="bp">self</span><span class="o">.</span><span class="n">device_group</span> <span class="o">=</span> <span class="n">device_group</span>
</span><span id="L-248"><a href="#L-248"><span class="linenos"> 248</span></a>                <span class="bp">self</span><span class="o">.</span><span class="n">cpu_group</span> <span class="o">=</span> <span class="n">cpu_group</span>
</span><span id="L-249"><a href="#L-249"><span class="linenos"> 249</span></a>
</span><span id="L-250"><a href="#L-250"><span class="linenos"> 250</span></a>        <span class="k">assert</span> <span class="bp">self</span><span class="o">.</span><span class="n">cpu_group</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
</span><span id="L-251"><a href="#L-251"><span class="linenos"> 251</span></a>        <span class="k">assert</span> <span class="bp">self</span><span class="o">.</span><span class="n">device_group</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
</span><span id="L-252"><a href="#L-252"><span class="linenos"> 252</span></a>
</span><span id="L-253"><a href="#L-253"><span class="linenos"> 253</span></a>        <span class="k">if</span> <span class="n">is_cuda_alike</span><span class="p">():</span>
</span><span id="L-254"><a href="#L-254"><span class="linenos"> 254</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;cuda:</span><span class="si">{</span><span class="n">local_rank</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</span><span id="L-255"><a href="#L-255"><span class="linenos"> 255</span></a>        <span class="k">elif</span> <span class="n">_is_npu</span><span class="p">:</span>
</span><span id="L-256"><a href="#L-256"><span class="linenos"> 256</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;npu:</span><span class="si">{</span><span class="n">local_rank</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</span><span id="L-257"><a href="#L-257"><span class="linenos"> 257</span></a>        <span class="k">else</span><span class="p">:</span>
</span><span id="L-258"><a href="#L-258"><span class="linenos"> 258</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s2">&quot;cpu&quot;</span><span class="p">)</span>
</span><span id="L-259"><a href="#L-259"><span class="linenos"> 259</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">device_module</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">get_device_module</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
</span><span id="L-260"><a href="#L-260"><span class="linenos"> 260</span></a>
</span><span id="L-261"><a href="#L-261"><span class="linenos"> 261</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">use_pynccl</span> <span class="o">=</span> <span class="n">use_pynccl</span>
</span><span id="L-262"><a href="#L-262"><span class="linenos"> 262</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">use_pymscclpp</span> <span class="o">=</span> <span class="n">use_pymscclpp</span>
</span><span id="L-263"><a href="#L-263"><span class="linenos"> 263</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">use_custom_allreduce</span> <span class="o">=</span> <span class="n">use_custom_allreduce</span>
</span><span id="L-264"><a href="#L-264"><span class="linenos"> 264</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">use_hpu_communicator</span> <span class="o">=</span> <span class="n">use_hpu_communicator</span>
</span><span id="L-265"><a href="#L-265"><span class="linenos"> 265</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">use_xpu_communicator</span> <span class="o">=</span> <span class="n">use_xpu_communicator</span>
</span><span id="L-266"><a href="#L-266"><span class="linenos"> 266</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">use_npu_communicator</span> <span class="o">=</span> <span class="n">use_npu_communicator</span>
</span><span id="L-267"><a href="#L-267"><span class="linenos"> 267</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">use_message_queue_broadcaster</span> <span class="o">=</span> <span class="n">use_message_queue_broadcaster</span>
</span><span id="L-268"><a href="#L-268"><span class="linenos"> 268</span></a>
</span><span id="L-269"><a href="#L-269"><span class="linenos"> 269</span></a>        <span class="c1"># lazy import to avoid documentation build error</span>
</span><span id="L-270"><a href="#L-270"><span class="linenos"> 270</span></a>        <span class="kn">from</span><span class="w"> </span><span class="nn">sglang.srt.distributed.device_communicators.custom_all_reduce</span><span class="w"> </span><span class="kn">import</span> <span class="p">(</span>
</span><span id="L-271"><a href="#L-271"><span class="linenos"> 271</span></a>            <span class="n">CustomAllreduce</span><span class="p">,</span>
</span><span id="L-272"><a href="#L-272"><span class="linenos"> 272</span></a>        <span class="p">)</span>
</span><span id="L-273"><a href="#L-273"><span class="linenos"> 273</span></a>        <span class="kn">from</span><span class="w"> </span><span class="nn">sglang.srt.distributed.device_communicators.pynccl</span><span class="w"> </span><span class="kn">import</span> <span class="p">(</span>
</span><span id="L-274"><a href="#L-274"><span class="linenos"> 274</span></a>            <span class="n">PyNcclCommunicator</span><span class="p">,</span>
</span><span id="L-275"><a href="#L-275"><span class="linenos"> 275</span></a>        <span class="p">)</span>
</span><span id="L-276"><a href="#L-276"><span class="linenos"> 276</span></a>
</span><span id="L-277"><a href="#L-277"><span class="linenos"> 277</span></a>        <span class="k">if</span> <span class="n">is_hip</span><span class="p">():</span>
</span><span id="L-278"><a href="#L-278"><span class="linenos"> 278</span></a>            <span class="kn">from</span><span class="w"> </span><span class="nn">sglang.srt.distributed.device_communicators.quick_all_reduce</span><span class="w"> </span><span class="kn">import</span> <span class="p">(</span>
</span><span id="L-279"><a href="#L-279"><span class="linenos"> 279</span></a>                <span class="n">QuickAllReduce</span><span class="p">,</span>
</span><span id="L-280"><a href="#L-280"><span class="linenos"> 280</span></a>                <span class="n">qr_rocm_arch_available</span><span class="p">,</span>
</span><span id="L-281"><a href="#L-281"><span class="linenos"> 281</span></a>            <span class="p">)</span>
</span><span id="L-282"><a href="#L-282"><span class="linenos"> 282</span></a>
</span><span id="L-283"><a href="#L-283"><span class="linenos"> 283</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">pynccl_comm</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">PyNcclCommunicator</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
</span><span id="L-284"><a href="#L-284"><span class="linenos"> 284</span></a>        <span class="k">if</span> <span class="n">use_pynccl</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">world_size</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
</span><span id="L-285"><a href="#L-285"><span class="linenos"> 285</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">pynccl_comm</span> <span class="o">=</span> <span class="n">PyNcclCommunicator</span><span class="p">(</span>
</span><span id="L-286"><a href="#L-286"><span class="linenos"> 286</span></a>                <span class="n">group</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">cpu_group</span><span class="p">,</span>
</span><span id="L-287"><a href="#L-287"><span class="linenos"> 287</span></a>                <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">,</span>
</span><span id="L-288"><a href="#L-288"><span class="linenos"> 288</span></a>            <span class="p">)</span>
</span><span id="L-289"><a href="#L-289"><span class="linenos"> 289</span></a>
</span><span id="L-290"><a href="#L-290"><span class="linenos"> 290</span></a>        <span class="kn">from</span><span class="w"> </span><span class="nn">sglang.srt.distributed.device_communicators.pymscclpp</span><span class="w"> </span><span class="kn">import</span> <span class="p">(</span>
</span><span id="L-291"><a href="#L-291"><span class="linenos"> 291</span></a>            <span class="n">PyMscclppCommunicator</span><span class="p">,</span>
</span><span id="L-292"><a href="#L-292"><span class="linenos"> 292</span></a>        <span class="p">)</span>
</span><span id="L-293"><a href="#L-293"><span class="linenos"> 293</span></a>
</span><span id="L-294"><a href="#L-294"><span class="linenos"> 294</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">pymscclpp_comm</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">PyMscclppCommunicator</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
</span><span id="L-295"><a href="#L-295"><span class="linenos"> 295</span></a>        <span class="k">if</span> <span class="n">use_pymscclpp</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">world_size</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
</span><span id="L-296"><a href="#L-296"><span class="linenos"> 296</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">pymscclpp_comm</span> <span class="o">=</span> <span class="n">PyMscclppCommunicator</span><span class="p">(</span>
</span><span id="L-297"><a href="#L-297"><span class="linenos"> 297</span></a>                <span class="n">group</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">cpu_group</span><span class="p">,</span>
</span><span id="L-298"><a href="#L-298"><span class="linenos"> 298</span></a>                <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">,</span>
</span><span id="L-299"><a href="#L-299"><span class="linenos"> 299</span></a>            <span class="p">)</span>
</span><span id="L-300"><a href="#L-300"><span class="linenos"> 300</span></a>
</span><span id="L-301"><a href="#L-301"><span class="linenos"> 301</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">ca_comm</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">CustomAllreduce</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
</span><span id="L-302"><a href="#L-302"><span class="linenos"> 302</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">qr_comm</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">QuickAllReduce</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
</span><span id="L-303"><a href="#L-303"><span class="linenos"> 303</span></a>        <span class="k">if</span> <span class="n">use_custom_allreduce</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">world_size</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
</span><span id="L-304"><a href="#L-304"><span class="linenos"> 304</span></a>            <span class="c1"># Initialize a custom fast all-reduce implementation.</span>
</span><span id="L-305"><a href="#L-305"><span class="linenos"> 305</span></a>            <span class="k">try</span><span class="p">:</span>
</span><span id="L-306"><a href="#L-306"><span class="linenos"> 306</span></a>                <span class="bp">self</span><span class="o">.</span><span class="n">ca_comm</span> <span class="o">=</span> <span class="n">CustomAllreduce</span><span class="p">(</span>
</span><span id="L-307"><a href="#L-307"><span class="linenos"> 307</span></a>                    <span class="n">group</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">cpu_group</span><span class="p">,</span>
</span><span id="L-308"><a href="#L-308"><span class="linenos"> 308</span></a>                    <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">,</span>
</span><span id="L-309"><a href="#L-309"><span class="linenos"> 309</span></a>                <span class="p">)</span>
</span><span id="L-310"><a href="#L-310"><span class="linenos"> 310</span></a>            <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
</span><span id="L-311"><a href="#L-311"><span class="linenos"> 311</span></a>                <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span>
</span><span id="L-312"><a href="#L-312"><span class="linenos"> 312</span></a>                    <span class="sa">f</span><span class="s2">&quot;Setup Custom allreduce failed with </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">. To silence this &quot;</span>
</span><span id="L-313"><a href="#L-313"><span class="linenos"> 313</span></a>                    <span class="s2">&quot;warning, specify --disable-custom-all-reduce explicitly.&quot;</span>
</span><span id="L-314"><a href="#L-314"><span class="linenos"> 314</span></a>                <span class="p">)</span>
</span><span id="L-315"><a href="#L-315"><span class="linenos"> 315</span></a>            <span class="k">if</span> <span class="n">is_hip</span><span class="p">():</span>
</span><span id="L-316"><a href="#L-316"><span class="linenos"> 316</span></a>                <span class="k">try</span><span class="p">:</span>
</span><span id="L-317"><a href="#L-317"><span class="linenos"> 317</span></a>                    <span class="c1"># Initialize a custom quick all-reduce implementation for AMD</span>
</span><span id="L-318"><a href="#L-318"><span class="linenos"> 318</span></a>                    <span class="c1"># when rocm &gt;= gfx942. Quick reduce is designed as a</span>
</span><span id="L-319"><a href="#L-319"><span class="linenos"> 319</span></a>                    <span class="c1"># complement to custom allreduce.</span>
</span><span id="L-320"><a href="#L-320"><span class="linenos"> 320</span></a>                    <span class="c1"># Based on quickreduce (https://github.com/mk1-project/quickreduce).</span>
</span><span id="L-321"><a href="#L-321"><span class="linenos"> 321</span></a>                    <span class="k">if</span> <span class="n">qr_rocm_arch_available</span><span class="p">():</span>
</span><span id="L-322"><a href="#L-322"><span class="linenos"> 322</span></a>                        <span class="bp">self</span><span class="o">.</span><span class="n">qr_comm</span> <span class="o">=</span> <span class="n">QuickAllReduce</span><span class="p">(</span>
</span><span id="L-323"><a href="#L-323"><span class="linenos"> 323</span></a>                            <span class="n">group</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">cpu_group</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span>
</span><span id="L-324"><a href="#L-324"><span class="linenos"> 324</span></a>                        <span class="p">)</span>
</span><span id="L-325"><a href="#L-325"><span class="linenos"> 325</span></a>                <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
</span><span id="L-326"><a href="#L-326"><span class="linenos"> 326</span></a>                    <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Failed to initialize QuickAllReduce: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</span><span id="L-327"><a href="#L-327"><span class="linenos"> 327</span></a>
</span><span id="L-328"><a href="#L-328"><span class="linenos"> 328</span></a>        <span class="kn">from</span><span class="w"> </span><span class="nn">sglang.srt.distributed.device_communicators.hpu_communicator</span><span class="w"> </span><span class="kn">import</span> <span class="p">(</span>
</span><span id="L-329"><a href="#L-329"><span class="linenos"> 329</span></a>            <span class="n">HpuCommunicator</span><span class="p">,</span>
</span><span id="L-330"><a href="#L-330"><span class="linenos"> 330</span></a>        <span class="p">)</span>
</span><span id="L-331"><a href="#L-331"><span class="linenos"> 331</span></a>
</span><span id="L-332"><a href="#L-332"><span class="linenos"> 332</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">hpu_communicator</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">HpuCommunicator</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
</span><span id="L-333"><a href="#L-333"><span class="linenos"> 333</span></a>        <span class="k">if</span> <span class="n">use_hpu_communicator</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">world_size</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
</span><span id="L-334"><a href="#L-334"><span class="linenos"> 334</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">hpu_communicator</span> <span class="o">=</span> <span class="n">HpuCommunicator</span><span class="p">(</span><span class="n">group</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device_group</span><span class="p">)</span>
</span><span id="L-335"><a href="#L-335"><span class="linenos"> 335</span></a>
</span><span id="L-336"><a href="#L-336"><span class="linenos"> 336</span></a>        <span class="kn">from</span><span class="w"> </span><span class="nn">sglang.srt.distributed.device_communicators.xpu_communicator</span><span class="w"> </span><span class="kn">import</span> <span class="p">(</span>
</span><span id="L-337"><a href="#L-337"><span class="linenos"> 337</span></a>            <span class="n">XpuCommunicator</span><span class="p">,</span>
</span><span id="L-338"><a href="#L-338"><span class="linenos"> 338</span></a>        <span class="p">)</span>
</span><span id="L-339"><a href="#L-339"><span class="linenos"> 339</span></a>
</span><span id="L-340"><a href="#L-340"><span class="linenos"> 340</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">xpu_communicator</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">XpuCommunicator</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
</span><span id="L-341"><a href="#L-341"><span class="linenos"> 341</span></a>        <span class="k">if</span> <span class="n">use_xpu_communicator</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">world_size</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
</span><span id="L-342"><a href="#L-342"><span class="linenos"> 342</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">xpu_communicator</span> <span class="o">=</span> <span class="n">XpuCommunicator</span><span class="p">(</span><span class="n">group</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device_group</span><span class="p">)</span>
</span><span id="L-343"><a href="#L-343"><span class="linenos"> 343</span></a>
</span><span id="L-344"><a href="#L-344"><span class="linenos"> 344</span></a>        <span class="kn">from</span><span class="w"> </span><span class="nn">sglang.srt.distributed.device_communicators.npu_communicator</span><span class="w"> </span><span class="kn">import</span> <span class="p">(</span>
</span><span id="L-345"><a href="#L-345"><span class="linenos"> 345</span></a>            <span class="n">NpuCommunicator</span><span class="p">,</span>
</span><span id="L-346"><a href="#L-346"><span class="linenos"> 346</span></a>        <span class="p">)</span>
</span><span id="L-347"><a href="#L-347"><span class="linenos"> 347</span></a>
</span><span id="L-348"><a href="#L-348"><span class="linenos"> 348</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">npu_communicator</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">NpuCommunicator</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
</span><span id="L-349"><a href="#L-349"><span class="linenos"> 349</span></a>        <span class="k">if</span> <span class="n">use_npu_communicator</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">world_size</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
</span><span id="L-350"><a href="#L-350"><span class="linenos"> 350</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">npu_communicator</span> <span class="o">=</span> <span class="n">NpuCommunicator</span><span class="p">(</span><span class="n">group</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device_group</span><span class="p">)</span>
</span><span id="L-351"><a href="#L-351"><span class="linenos"> 351</span></a>
</span><span id="L-352"><a href="#L-352"><span class="linenos"> 352</span></a>        <span class="kn">from</span><span class="w"> </span><span class="nn">sglang.srt.distributed.device_communicators.shm_broadcast</span><span class="w"> </span><span class="kn">import</span> <span class="p">(</span>
</span><span id="L-353"><a href="#L-353"><span class="linenos"> 353</span></a>            <span class="n">MessageQueue</span><span class="p">,</span>
</span><span id="L-354"><a href="#L-354"><span class="linenos"> 354</span></a>        <span class="p">)</span>
</span><span id="L-355"><a href="#L-355"><span class="linenos"> 355</span></a>
</span><span id="L-356"><a href="#L-356"><span class="linenos"> 356</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">mq_broadcaster</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">MessageQueue</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
</span><span id="L-357"><a href="#L-357"><span class="linenos"> 357</span></a>        <span class="k">if</span> <span class="n">use_message_queue_broadcaster</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">world_size</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
</span><span id="L-358"><a href="#L-358"><span class="linenos"> 358</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">mq_broadcaster</span> <span class="o">=</span> <span class="n">MessageQueue</span><span class="o">.</span><span class="n">create_from_process_group</span><span class="p">(</span>
</span><span id="L-359"><a href="#L-359"><span class="linenos"> 359</span></a>                <span class="bp">self</span><span class="o">.</span><span class="n">cpu_group</span><span class="p">,</span> <span class="mi">1</span> <span class="o">&lt;&lt;</span> <span class="mi">22</span><span class="p">,</span> <span class="mi">6</span>
</span><span id="L-360"><a href="#L-360"><span class="linenos"> 360</span></a>            <span class="p">)</span>
</span><span id="L-361"><a href="#L-361"><span class="linenos"> 361</span></a>
</span><span id="L-362"><a href="#L-362"><span class="linenos"> 362</span></a>    <span class="k">def</span><span class="w"> </span><span class="fm">__repr__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
</span><span id="L-363"><a href="#L-363"><span class="linenos"> 363</span></a>        <span class="k">return</span> <span class="p">(</span>
</span><span id="L-364"><a href="#L-364"><span class="linenos"> 364</span></a>            <span class="sa">f</span><span class="s2">&quot;ranks=</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">ranks</span><span class="si">}</span><span class="s2"> rank=</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">rank</span><span class="si">}</span><span class="s2"> local_rank=</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">local_rank</span><span class="si">}</span><span class="s2"> use_pynccl=</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">use_pynccl</span><span class="si">}</span><span class="s2"> &quot;</span>
</span><span id="L-365"><a href="#L-365"><span class="linenos"> 365</span></a>            <span class="sa">f</span><span class="s2">&quot;device_group=</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">device_group</span><span class="si">}</span><span class="s2"> cpu_group=</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">cpu_group</span><span class="si">}</span><span class="s2"> unique_name=</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">unique_name</span><span class="si">}</span><span class="s2"> &quot;</span>
</span><span id="L-366"><a href="#L-366"><span class="linenos"> 366</span></a>            <span class="sa">f</span><span class="s2">&quot;world_size=</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">world_size</span><span class="si">}</span><span class="s2"> rank_in_group=</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">rank_in_group</span><span class="si">}</span><span class="s2">&quot;</span>
</span><span id="L-367"><a href="#L-367"><span class="linenos"> 367</span></a>        <span class="p">)</span>
</span><span id="L-368"><a href="#L-368"><span class="linenos"> 368</span></a>
</span><span id="L-369"><a href="#L-369"><span class="linenos"> 369</span></a>    <span class="nd">@property</span>
</span><span id="L-370"><a href="#L-370"><span class="linenos"> 370</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">first_rank</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
</span><span id="L-371"><a href="#L-371"><span class="linenos"> 371</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;Return the global rank of the first process in the group&quot;&quot;&quot;</span>
</span><span id="L-372"><a href="#L-372"><span class="linenos"> 372</span></a>        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">ranks</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
</span><span id="L-373"><a href="#L-373"><span class="linenos"> 373</span></a>
</span><span id="L-374"><a href="#L-374"><span class="linenos"> 374</span></a>    <span class="nd">@property</span>
</span><span id="L-375"><a href="#L-375"><span class="linenos"> 375</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">last_rank</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
</span><span id="L-376"><a href="#L-376"><span class="linenos"> 376</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;Return the global rank of the last process in the group&quot;&quot;&quot;</span>
</span><span id="L-377"><a href="#L-377"><span class="linenos"> 377</span></a>        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">ranks</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
</span><span id="L-378"><a href="#L-378"><span class="linenos"> 378</span></a>
</span><span id="L-379"><a href="#L-379"><span class="linenos"> 379</span></a>    <span class="nd">@property</span>
</span><span id="L-380"><a href="#L-380"><span class="linenos"> 380</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">is_first_rank</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
</span><span id="L-381"><a href="#L-381"><span class="linenos"> 381</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;Return whether the caller is the first process in the group&quot;&quot;&quot;</span>
</span><span id="L-382"><a href="#L-382"><span class="linenos"> 382</span></a>        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">rank</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">first_rank</span>
</span><span id="L-383"><a href="#L-383"><span class="linenos"> 383</span></a>
</span><span id="L-384"><a href="#L-384"><span class="linenos"> 384</span></a>    <span class="nd">@property</span>
</span><span id="L-385"><a href="#L-385"><span class="linenos"> 385</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">is_last_rank</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
</span><span id="L-386"><a href="#L-386"><span class="linenos"> 386</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;Return whether the caller is the last process in the group&quot;&quot;&quot;</span>
</span><span id="L-387"><a href="#L-387"><span class="linenos"> 387</span></a>        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">rank</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">last_rank</span>
</span><span id="L-388"><a href="#L-388"><span class="linenos"> 388</span></a>
</span><span id="L-389"><a href="#L-389"><span class="linenos"> 389</span></a>    <span class="nd">@property</span>
</span><span id="L-390"><a href="#L-390"><span class="linenos"> 390</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">next_rank</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
</span><span id="L-391"><a href="#L-391"><span class="linenos"> 391</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;Return the global rank of the process that follows the caller&quot;&quot;&quot;</span>
</span><span id="L-392"><a href="#L-392"><span class="linenos"> 392</span></a>        <span class="n">rank_in_group</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">rank_in_group</span>
</span><span id="L-393"><a href="#L-393"><span class="linenos"> 393</span></a>        <span class="n">world_size</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">world_size</span>
</span><span id="L-394"><a href="#L-394"><span class="linenos"> 394</span></a>        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">ranks</span><span class="p">[(</span><span class="n">rank_in_group</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">%</span> <span class="n">world_size</span><span class="p">]</span>
</span><span id="L-395"><a href="#L-395"><span class="linenos"> 395</span></a>
</span><span id="L-396"><a href="#L-396"><span class="linenos"> 396</span></a>    <span class="nd">@property</span>
</span><span id="L-397"><a href="#L-397"><span class="linenos"> 397</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">prev_rank</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
</span><span id="L-398"><a href="#L-398"><span class="linenos"> 398</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;Return the global rank of the process that precedes the caller&quot;&quot;&quot;</span>
</span><span id="L-399"><a href="#L-399"><span class="linenos"> 399</span></a>        <span class="n">rank_in_group</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">rank_in_group</span>
</span><span id="L-400"><a href="#L-400"><span class="linenos"> 400</span></a>        <span class="n">world_size</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">world_size</span>
</span><span id="L-401"><a href="#L-401"><span class="linenos"> 401</span></a>        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">ranks</span><span class="p">[(</span><span class="n">rank_in_group</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">%</span> <span class="n">world_size</span><span class="p">]</span>
</span><span id="L-402"><a href="#L-402"><span class="linenos"> 402</span></a>
</span><span id="L-403"><a href="#L-403"><span class="linenos"> 403</span></a>    <span class="nd">@contextmanager</span>
</span><span id="L-404"><a href="#L-404"><span class="linenos"> 404</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">graph_capture</span><span class="p">(</span>
</span><span id="L-405"><a href="#L-405"><span class="linenos"> 405</span></a>        <span class="bp">self</span><span class="p">,</span> <span class="n">graph_capture_context</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">GraphCaptureContext</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
</span><span id="L-406"><a href="#L-406"><span class="linenos"> 406</span></a>    <span class="p">):</span>
</span><span id="L-407"><a href="#L-407"><span class="linenos"> 407</span></a>        <span class="k">if</span> <span class="n">graph_capture_context</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="L-408"><a href="#L-408"><span class="linenos"> 408</span></a>            <span class="n">stream</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">device_module</span><span class="o">.</span><span class="n">Stream</span><span class="p">()</span>
</span><span id="L-409"><a href="#L-409"><span class="linenos"> 409</span></a>            <span class="n">graph_capture_context</span> <span class="o">=</span> <span class="n">GraphCaptureContext</span><span class="p">(</span><span class="n">stream</span><span class="p">)</span>
</span><span id="L-410"><a href="#L-410"><span class="linenos"> 410</span></a>        <span class="k">else</span><span class="p">:</span>
</span><span id="L-411"><a href="#L-411"><span class="linenos"> 411</span></a>            <span class="n">stream</span> <span class="o">=</span> <span class="n">graph_capture_context</span><span class="o">.</span><span class="n">stream</span>
</span><span id="L-412"><a href="#L-412"><span class="linenos"> 412</span></a>        <span class="c1"># We don&#39;t need the context of custom quick allreduce because the ipc access</span>
</span><span id="L-413"><a href="#L-413"><span class="linenos"> 413</span></a>        <span class="c1"># is already collected in init() and we can capture the quick allreduce directly.</span>
</span><span id="L-414"><a href="#L-414"><span class="linenos"> 414</span></a>        <span class="n">ca_comm</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">ca_comm</span>
</span><span id="L-415"><a href="#L-415"><span class="linenos"> 415</span></a>        <span class="n">maybe_ca_context</span> <span class="o">=</span> <span class="n">nullcontext</span><span class="p">()</span> <span class="k">if</span> <span class="n">ca_comm</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">ca_comm</span><span class="o">.</span><span class="n">capture</span><span class="p">()</span>
</span><span id="L-416"><a href="#L-416"><span class="linenos"> 416</span></a>
</span><span id="L-417"><a href="#L-417"><span class="linenos"> 417</span></a>        <span class="c1"># ensure all initialization operations complete before attempting to</span>
</span><span id="L-418"><a href="#L-418"><span class="linenos"> 418</span></a>        <span class="c1"># capture the graph on another stream</span>
</span><span id="L-419"><a href="#L-419"><span class="linenos"> 419</span></a>        <span class="n">curr_stream</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">device_module</span><span class="o">.</span><span class="n">current_stream</span><span class="p">()</span>
</span><span id="L-420"><a href="#L-420"><span class="linenos"> 420</span></a>        <span class="k">if</span> <span class="n">curr_stream</span> <span class="o">!=</span> <span class="n">stream</span><span class="p">:</span>
</span><span id="L-421"><a href="#L-421"><span class="linenos"> 421</span></a>            <span class="n">stream</span><span class="o">.</span><span class="n">wait_stream</span><span class="p">(</span><span class="n">curr_stream</span><span class="p">)</span>
</span><span id="L-422"><a href="#L-422"><span class="linenos"> 422</span></a>
</span><span id="L-423"><a href="#L-423"><span class="linenos"> 423</span></a>        <span class="k">with</span> <span class="bp">self</span><span class="o">.</span><span class="n">device_module</span><span class="o">.</span><span class="n">stream</span><span class="p">(</span><span class="n">stream</span><span class="p">),</span> <span class="n">maybe_ca_context</span><span class="p">:</span>
</span><span id="L-424"><a href="#L-424"><span class="linenos"> 424</span></a>            <span class="c1"># In graph mode, we have to be very careful about the collective</span>
</span><span id="L-425"><a href="#L-425"><span class="linenos"> 425</span></a>            <span class="c1"># operations. The current status is:</span>
</span><span id="L-426"><a href="#L-426"><span class="linenos"> 426</span></a>            <span class="c1">#     allreduce \ Mode   |  Eager  |  Graph  |</span>
</span><span id="L-427"><a href="#L-427"><span class="linenos"> 427</span></a>            <span class="c1"># --------------------------------------------</span>
</span><span id="L-428"><a href="#L-428"><span class="linenos"> 428</span></a>            <span class="c1"># quick allreduce        | enabled | enabled |</span>
</span><span id="L-429"><a href="#L-429"><span class="linenos"> 429</span></a>            <span class="c1"># custom allreduce       | enabled | enabled |</span>
</span><span id="L-430"><a href="#L-430"><span class="linenos"> 430</span></a>            <span class="c1"># PyNccl                 | disabled| enabled |</span>
</span><span id="L-431"><a href="#L-431"><span class="linenos"> 431</span></a>            <span class="c1"># PyMscclpp              | disabled| enabled |</span>
</span><span id="L-432"><a href="#L-432"><span class="linenos"> 432</span></a>            <span class="c1"># torch.distributed      | enabled | disabled|</span>
</span><span id="L-433"><a href="#L-433"><span class="linenos"> 433</span></a>            <span class="c1">#</span>
</span><span id="L-434"><a href="#L-434"><span class="linenos"> 434</span></a>            <span class="c1"># Note: When custom quick allreduce is enabled, a runtime check</span>
</span><span id="L-435"><a href="#L-435"><span class="linenos"> 435</span></a>            <span class="c1">#  will be performed. If the tensor size is too small, it will</span>
</span><span id="L-436"><a href="#L-436"><span class="linenos"> 436</span></a>            <span class="c1">#  automatically fall back to the next available option.</span>
</span><span id="L-437"><a href="#L-437"><span class="linenos"> 437</span></a>            <span class="c1"># Note that custom allreduce will have a runtime check, if the</span>
</span><span id="L-438"><a href="#L-438"><span class="linenos"> 438</span></a>            <span class="c1">#  tensor size is too large, it will fallback to the next</span>
</span><span id="L-439"><a href="#L-439"><span class="linenos"> 439</span></a>            <span class="c1">#  available option.</span>
</span><span id="L-440"><a href="#L-440"><span class="linenos"> 440</span></a>            <span class="c1"># Note that the PyMsccl needs to register the tensor in ahead,</span>
</span><span id="L-441"><a href="#L-441"><span class="linenos"> 441</span></a>            <span class="c1">#  which will introduce large overhead in the eager case,</span>
</span><span id="L-442"><a href="#L-442"><span class="linenos"> 442</span></a>            <span class="c1">#  therefore it is only supported in the graph case.</span>
</span><span id="L-443"><a href="#L-443"><span class="linenos"> 443</span></a>            <span class="c1"># In summary: We select the appropriate allreduce method for</span>
</span><span id="L-444"><a href="#L-444"><span class="linenos"> 444</span></a>            <span class="c1">#  each mode based on the algorithm order in the table and</span>
</span><span id="L-445"><a href="#L-445"><span class="linenos"> 445</span></a>            <span class="c1">#  their usage conditions.</span>
</span><span id="L-446"><a href="#L-446"><span class="linenos"> 446</span></a>            <span class="n">pynccl_comm</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">pynccl_comm</span>
</span><span id="L-447"><a href="#L-447"><span class="linenos"> 447</span></a>            <span class="n">maybe_pynccl_context</span><span class="p">:</span> <span class="n">Any</span>
</span><span id="L-448"><a href="#L-448"><span class="linenos"> 448</span></a>            <span class="k">if</span> <span class="ow">not</span> <span class="n">pynccl_comm</span><span class="p">:</span>
</span><span id="L-449"><a href="#L-449"><span class="linenos"> 449</span></a>                <span class="n">maybe_pynccl_context</span> <span class="o">=</span> <span class="n">nullcontext</span><span class="p">()</span>
</span><span id="L-450"><a href="#L-450"><span class="linenos"> 450</span></a>            <span class="k">else</span><span class="p">:</span>
</span><span id="L-451"><a href="#L-451"><span class="linenos"> 451</span></a>                <span class="n">maybe_pynccl_context</span> <span class="o">=</span> <span class="n">pynccl_comm</span><span class="o">.</span><span class="n">change_state</span><span class="p">(</span>
</span><span id="L-452"><a href="#L-452"><span class="linenos"> 452</span></a>                    <span class="n">enable</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">stream</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">current_stream</span><span class="p">()</span>
</span><span id="L-453"><a href="#L-453"><span class="linenos"> 453</span></a>                <span class="p">)</span>
</span><span id="L-454"><a href="#L-454"><span class="linenos"> 454</span></a>
</span><span id="L-455"><a href="#L-455"><span class="linenos"> 455</span></a>            <span class="n">pymscclpp_comm</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">pymscclpp_comm</span>
</span><span id="L-456"><a href="#L-456"><span class="linenos"> 456</span></a>            <span class="n">maybe_pymscclpp_context</span><span class="p">:</span> <span class="n">Any</span>
</span><span id="L-457"><a href="#L-457"><span class="linenos"> 457</span></a>            <span class="k">if</span> <span class="ow">not</span> <span class="n">pymscclpp_comm</span><span class="p">:</span>
</span><span id="L-458"><a href="#L-458"><span class="linenos"> 458</span></a>                <span class="n">maybe_pymscclpp_context</span> <span class="o">=</span> <span class="n">nullcontext</span><span class="p">()</span>
</span><span id="L-459"><a href="#L-459"><span class="linenos"> 459</span></a>            <span class="k">else</span><span class="p">:</span>
</span><span id="L-460"><a href="#L-460"><span class="linenos"> 460</span></a>                <span class="n">maybe_pymscclpp_context</span> <span class="o">=</span> <span class="n">pymscclpp_comm</span><span class="o">.</span><span class="n">change_state</span><span class="p">(</span><span class="n">enable</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</span><span id="L-461"><a href="#L-461"><span class="linenos"> 461</span></a>            <span class="k">with</span> <span class="n">maybe_pynccl_context</span><span class="p">,</span> <span class="n">maybe_pymscclpp_context</span><span class="p">:</span>
</span><span id="L-462"><a href="#L-462"><span class="linenos"> 462</span></a>                <span class="k">yield</span> <span class="n">graph_capture_context</span>
</span><span id="L-463"><a href="#L-463"><span class="linenos"> 463</span></a>
</span><span id="L-464"><a href="#L-464"><span class="linenos"> 464</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">all_reduce</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
</span><span id="L-465"><a href="#L-465"><span class="linenos"> 465</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="L-466"><a href="#L-466"><span class="linenos"> 466</span></a><span class="sd">        User-facing all-reduce function before we actually call the</span>
</span><span id="L-467"><a href="#L-467"><span class="linenos"> 467</span></a><span class="sd">        all-reduce operation.</span>
</span><span id="L-468"><a href="#L-468"><span class="linenos"> 468</span></a>
</span><span id="L-469"><a href="#L-469"><span class="linenos"> 469</span></a><span class="sd">        We need this because Dynamo does not support passing an arbitrary</span>
</span><span id="L-470"><a href="#L-470"><span class="linenos"> 470</span></a><span class="sd">        object (`self` in this case) to a custom op. We need to pass the</span>
</span><span id="L-471"><a href="#L-471"><span class="linenos"> 471</span></a><span class="sd">         group name as a string, and then look up the group coordinator from</span>
</span><span id="L-472"><a href="#L-472"><span class="linenos"> 472</span></a><span class="sd">         the group name, dispatch the all-reduce operation to the group</span>
</span><span id="L-473"><a href="#L-473"><span class="linenos"> 473</span></a><span class="sd">         coordinator.</span>
</span><span id="L-474"><a href="#L-474"><span class="linenos"> 474</span></a>
</span><span id="L-475"><a href="#L-475"><span class="linenos"> 475</span></a><span class="sd">        In addition, PyTorch custom ops do not support mutation or returning</span>
</span><span id="L-476"><a href="#L-476"><span class="linenos"> 476</span></a><span class="sd">        a new tensor in the same op. So we need to figure out if the op is</span>
</span><span id="L-477"><a href="#L-477"><span class="linenos"> 477</span></a><span class="sd">        in-place or out-of-place ahead of time.</span>
</span><span id="L-478"><a href="#L-478"><span class="linenos"> 478</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="L-479"><a href="#L-479"><span class="linenos"> 479</span></a>        <span class="c1"># Bypass the function if we are using only 1 GPU.</span>
</span><span id="L-480"><a href="#L-480"><span class="linenos"> 480</span></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">world_size</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
</span><span id="L-481"><a href="#L-481"><span class="linenos"> 481</span></a>            <span class="k">return</span> <span class="n">input_</span>
</span><span id="L-482"><a href="#L-482"><span class="linenos"> 482</span></a>
</span><span id="L-483"><a href="#L-483"><span class="linenos"> 483</span></a>        <span class="k">if</span> <span class="n">input_</span><span class="o">.</span><span class="n">is_cpu</span><span class="p">:</span>
</span><span id="L-484"><a href="#L-484"><span class="linenos"> 484</span></a>            <span class="k">if</span> <span class="n">is_shm_available</span><span class="p">(</span><span class="n">input_</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">world_size</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">local_size</span><span class="p">):</span>
</span><span id="L-485"><a href="#L-485"><span class="linenos"> 485</span></a>                <span class="n">torch</span><span class="o">.</span><span class="n">ops</span><span class="o">.</span><span class="n">sgl_kernel</span><span class="o">.</span><span class="n">shm_allreduce</span><span class="p">(</span>
</span><span id="L-486"><a href="#L-486"><span class="linenos"> 486</span></a>                    <span class="n">input_</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">distributed</span><span class="o">.</span><span class="n">ReduceOp</span><span class="o">.</span><span class="n">SUM</span>
</span><span id="L-487"><a href="#L-487"><span class="linenos"> 487</span></a>                <span class="p">)</span>
</span><span id="L-488"><a href="#L-488"><span class="linenos"> 488</span></a>            <span class="k">else</span><span class="p">:</span>
</span><span id="L-489"><a href="#L-489"><span class="linenos"> 489</span></a>                <span class="n">torch</span><span class="o">.</span><span class="n">distributed</span><span class="o">.</span><span class="n">all_reduce</span><span class="p">(</span><span class="n">input_</span><span class="p">,</span> <span class="n">group</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device_group</span><span class="p">)</span>
</span><span id="L-490"><a href="#L-490"><span class="linenos"> 490</span></a>            <span class="k">return</span> <span class="n">input_</span>
</span><span id="L-491"><a href="#L-491"><span class="linenos"> 491</span></a>
</span><span id="L-492"><a href="#L-492"><span class="linenos"> 492</span></a>        <span class="k">if</span> <span class="ow">not</span> <span class="n">supports_custom_op</span><span class="p">():</span>
</span><span id="L-493"><a href="#L-493"><span class="linenos"> 493</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">_all_reduce_in_place</span><span class="p">(</span><span class="n">input_</span><span class="p">)</span>
</span><span id="L-494"><a href="#L-494"><span class="linenos"> 494</span></a>            <span class="k">return</span> <span class="n">input_</span>
</span><span id="L-495"><a href="#L-495"><span class="linenos"> 495</span></a>
</span><span id="L-496"><a href="#L-496"><span class="linenos"> 496</span></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">hpu_communicator</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">hpu_communicator</span><span class="o">.</span><span class="n">disabled</span><span class="p">:</span>
</span><span id="L-497"><a href="#L-497"><span class="linenos"> 497</span></a>            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">hpu_communicator</span><span class="o">.</span><span class="n">all_reduce</span><span class="p">(</span><span class="n">input_</span><span class="p">)</span>
</span><span id="L-498"><a href="#L-498"><span class="linenos"> 498</span></a>
</span><span id="L-499"><a href="#L-499"><span class="linenos"> 499</span></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">xpu_communicator</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">xpu_communicator</span><span class="o">.</span><span class="n">disabled</span><span class="p">:</span>
</span><span id="L-500"><a href="#L-500"><span class="linenos"> 500</span></a>            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">xpu_communicator</span><span class="o">.</span><span class="n">all_reduce</span><span class="p">(</span><span class="n">input_</span><span class="p">)</span>
</span><span id="L-501"><a href="#L-501"><span class="linenos"> 501</span></a>
</span><span id="L-502"><a href="#L-502"><span class="linenos"> 502</span></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">npu_communicator</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">npu_communicator</span><span class="o">.</span><span class="n">disabled</span><span class="p">:</span>
</span><span id="L-503"><a href="#L-503"><span class="linenos"> 503</span></a>            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">npu_communicator</span><span class="o">.</span><span class="n">all_reduce</span><span class="p">(</span><span class="n">input_</span><span class="p">)</span>
</span><span id="L-504"><a href="#L-504"><span class="linenos"> 504</span></a>
</span><span id="L-505"><a href="#L-505"><span class="linenos"> 505</span></a>        <span class="k">if</span> <span class="p">(</span>
</span><span id="L-506"><a href="#L-506"><span class="linenos"> 506</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">pynccl_comm</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
</span><span id="L-507"><a href="#L-507"><span class="linenos"> 507</span></a>            <span class="ow">and</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">input_</span><span class="p">,</span> <span class="s2">&quot;symmetric_memory&quot;</span><span class="p">)</span>
</span><span id="L-508"><a href="#L-508"><span class="linenos"> 508</span></a>            <span class="ow">and</span> <span class="n">input_</span><span class="o">.</span><span class="n">symmetric_memory</span>
</span><span id="L-509"><a href="#L-509"><span class="linenos"> 509</span></a>        <span class="p">):</span>
</span><span id="L-510"><a href="#L-510"><span class="linenos"> 510</span></a>            <span class="k">with</span> <span class="bp">self</span><span class="o">.</span><span class="n">pynccl_comm</span><span class="o">.</span><span class="n">change_state</span><span class="p">(</span>
</span><span id="L-511"><a href="#L-511"><span class="linenos"> 511</span></a>                <span class="n">enable</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">stream</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">current_stream</span><span class="p">()</span>
</span><span id="L-512"><a href="#L-512"><span class="linenos"> 512</span></a>            <span class="p">):</span>
</span><span id="L-513"><a href="#L-513"><span class="linenos"> 513</span></a>                <span class="bp">self</span><span class="o">.</span><span class="n">pynccl_comm</span><span class="o">.</span><span class="n">all_reduce</span><span class="p">(</span><span class="n">input_</span><span class="p">)</span>
</span><span id="L-514"><a href="#L-514"><span class="linenos"> 514</span></a>                <span class="k">return</span> <span class="n">input_</span>
</span><span id="L-515"><a href="#L-515"><span class="linenos"> 515</span></a>
</span><span id="L-516"><a href="#L-516"><span class="linenos"> 516</span></a>        <span class="n">outplace_all_reduce_method</span> <span class="o">=</span> <span class="kc">None</span>
</span><span id="L-517"><a href="#L-517"><span class="linenos"> 517</span></a>        <span class="k">if</span> <span class="p">(</span>
</span><span id="L-518"><a href="#L-518"><span class="linenos"> 518</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">qr_comm</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
</span><span id="L-519"><a href="#L-519"><span class="linenos"> 519</span></a>            <span class="ow">and</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">qr_comm</span><span class="o">.</span><span class="n">disabled</span>
</span><span id="L-520"><a href="#L-520"><span class="linenos"> 520</span></a>            <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">qr_comm</span><span class="o">.</span><span class="n">should_quick_allreduce</span><span class="p">(</span><span class="n">input_</span><span class="p">)</span>
</span><span id="L-521"><a href="#L-521"><span class="linenos"> 521</span></a>        <span class="p">):</span>
</span><span id="L-522"><a href="#L-522"><span class="linenos"> 522</span></a>            <span class="n">outplace_all_reduce_method</span> <span class="o">=</span> <span class="s2">&quot;qr&quot;</span>
</span><span id="L-523"><a href="#L-523"><span class="linenos"> 523</span></a>        <span class="k">elif</span> <span class="p">(</span>
</span><span id="L-524"><a href="#L-524"><span class="linenos"> 524</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">ca_comm</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
</span><span id="L-525"><a href="#L-525"><span class="linenos"> 525</span></a>            <span class="ow">and</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">ca_comm</span><span class="o">.</span><span class="n">disabled</span>
</span><span id="L-526"><a href="#L-526"><span class="linenos"> 526</span></a>            <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">ca_comm</span><span class="o">.</span><span class="n">should_custom_ar</span><span class="p">(</span><span class="n">input_</span><span class="p">)</span>
</span><span id="L-527"><a href="#L-527"><span class="linenos"> 527</span></a>        <span class="p">):</span>
</span><span id="L-528"><a href="#L-528"><span class="linenos"> 528</span></a>            <span class="n">outplace_all_reduce_method</span> <span class="o">=</span> <span class="s2">&quot;ca&quot;</span>
</span><span id="L-529"><a href="#L-529"><span class="linenos"> 529</span></a>        <span class="k">elif</span> <span class="p">(</span>
</span><span id="L-530"><a href="#L-530"><span class="linenos"> 530</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">pymscclpp_comm</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
</span><span id="L-531"><a href="#L-531"><span class="linenos"> 531</span></a>            <span class="ow">and</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">pymscclpp_comm</span><span class="o">.</span><span class="n">disabled</span>
</span><span id="L-532"><a href="#L-532"><span class="linenos"> 532</span></a>            <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">pymscclpp_comm</span><span class="o">.</span><span class="n">should_mscclpp_allreduce</span><span class="p">(</span><span class="n">input_</span><span class="p">)</span>
</span><span id="L-533"><a href="#L-533"><span class="linenos"> 533</span></a>        <span class="p">):</span>
</span><span id="L-534"><a href="#L-534"><span class="linenos"> 534</span></a>            <span class="n">outplace_all_reduce_method</span> <span class="o">=</span> <span class="s2">&quot;pymscclpp&quot;</span>
</span><span id="L-535"><a href="#L-535"><span class="linenos"> 535</span></a>        <span class="k">if</span> <span class="n">outplace_all_reduce_method</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="L-536"><a href="#L-536"><span class="linenos"> 536</span></a>            <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">ops</span><span class="o">.</span><span class="n">sglang</span><span class="o">.</span><span class="n">outplace_all_reduce</span><span class="p">(</span>
</span><span id="L-537"><a href="#L-537"><span class="linenos"> 537</span></a>                <span class="n">input_</span><span class="p">,</span>
</span><span id="L-538"><a href="#L-538"><span class="linenos"> 538</span></a>                <span class="n">group_name</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">unique_name</span><span class="p">,</span>
</span><span id="L-539"><a href="#L-539"><span class="linenos"> 539</span></a>                <span class="n">outplace_all_reduce_method</span><span class="o">=</span><span class="n">outplace_all_reduce_method</span><span class="p">,</span>
</span><span id="L-540"><a href="#L-540"><span class="linenos"> 540</span></a>            <span class="p">)</span>
</span><span id="L-541"><a href="#L-541"><span class="linenos"> 541</span></a>        <span class="k">else</span><span class="p">:</span>
</span><span id="L-542"><a href="#L-542"><span class="linenos"> 542</span></a>            <span class="n">torch</span><span class="o">.</span><span class="n">ops</span><span class="o">.</span><span class="n">sglang</span><span class="o">.</span><span class="n">inplace_all_reduce</span><span class="p">(</span><span class="n">input_</span><span class="p">,</span> <span class="n">group_name</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">unique_name</span><span class="p">)</span>
</span><span id="L-543"><a href="#L-543"><span class="linenos"> 543</span></a>            <span class="k">return</span> <span class="n">input_</span>
</span><span id="L-544"><a href="#L-544"><span class="linenos"> 544</span></a>
</span><span id="L-545"><a href="#L-545"><span class="linenos"> 545</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">_all_reduce_out_place</span><span class="p">(</span>
</span><span id="L-546"><a href="#L-546"><span class="linenos"> 546</span></a>        <span class="bp">self</span><span class="p">,</span> <span class="n">input_</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">outplace_all_reduce_method</span><span class="p">:</span> <span class="nb">str</span>
</span><span id="L-547"><a href="#L-547"><span class="linenos"> 547</span></a>    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
</span><span id="L-548"><a href="#L-548"><span class="linenos"> 548</span></a>        <span class="n">qr_comm</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">qr_comm</span>
</span><span id="L-549"><a href="#L-549"><span class="linenos"> 549</span></a>        <span class="n">ca_comm</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">ca_comm</span>
</span><span id="L-550"><a href="#L-550"><span class="linenos"> 550</span></a>        <span class="n">pymscclpp_comm</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">pymscclpp_comm</span>
</span><span id="L-551"><a href="#L-551"><span class="linenos"> 551</span></a>        <span class="k">assert</span> <span class="nb">any</span><span class="p">([</span><span class="n">qr_comm</span><span class="p">,</span> <span class="n">ca_comm</span><span class="p">,</span> <span class="n">pymscclpp_comm</span><span class="p">])</span>
</span><span id="L-552"><a href="#L-552"><span class="linenos"> 552</span></a>        <span class="k">if</span> <span class="n">outplace_all_reduce_method</span> <span class="o">==</span> <span class="s2">&quot;qr&quot;</span><span class="p">:</span>
</span><span id="L-553"><a href="#L-553"><span class="linenos"> 553</span></a>            <span class="k">assert</span> <span class="ow">not</span> <span class="n">qr_comm</span><span class="o">.</span><span class="n">disabled</span>
</span><span id="L-554"><a href="#L-554"><span class="linenos"> 554</span></a>            <span class="n">out</span> <span class="o">=</span> <span class="n">qr_comm</span><span class="o">.</span><span class="n">quick_all_reduce</span><span class="p">(</span><span class="n">input_</span><span class="p">)</span>
</span><span id="L-555"><a href="#L-555"><span class="linenos"> 555</span></a>        <span class="k">elif</span> <span class="n">outplace_all_reduce_method</span> <span class="o">==</span> <span class="s2">&quot;ca&quot;</span><span class="p">:</span>
</span><span id="L-556"><a href="#L-556"><span class="linenos"> 556</span></a>            <span class="k">assert</span> <span class="ow">not</span> <span class="n">ca_comm</span><span class="o">.</span><span class="n">disabled</span>
</span><span id="L-557"><a href="#L-557"><span class="linenos"> 557</span></a>            <span class="n">out</span> <span class="o">=</span> <span class="n">ca_comm</span><span class="o">.</span><span class="n">custom_all_reduce</span><span class="p">(</span><span class="n">input_</span><span class="p">)</span>
</span><span id="L-558"><a href="#L-558"><span class="linenos"> 558</span></a>        <span class="k">else</span><span class="p">:</span>
</span><span id="L-559"><a href="#L-559"><span class="linenos"> 559</span></a>            <span class="k">assert</span> <span class="ow">not</span> <span class="n">pymscclpp_comm</span><span class="o">.</span><span class="n">disabled</span>
</span><span id="L-560"><a href="#L-560"><span class="linenos"> 560</span></a>            <span class="n">out</span> <span class="o">=</span> <span class="n">pymscclpp_comm</span><span class="o">.</span><span class="n">all_reduce</span><span class="p">(</span><span class="n">input_</span><span class="p">)</span>
</span><span id="L-561"><a href="#L-561"><span class="linenos"> 561</span></a>        <span class="k">assert</span> <span class="n">out</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
</span><span id="L-562"><a href="#L-562"><span class="linenos"> 562</span></a>        <span class="k">return</span> <span class="n">out</span>
</span><span id="L-563"><a href="#L-563"><span class="linenos"> 563</span></a>
</span><span id="L-564"><a href="#L-564"><span class="linenos"> 564</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">_all_reduce_in_place</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="L-565"><a href="#L-565"><span class="linenos"> 565</span></a>        <span class="n">pynccl_comm</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">pynccl_comm</span>
</span><span id="L-566"><a href="#L-566"><span class="linenos"> 566</span></a>        <span class="k">if</span> <span class="n">pynccl_comm</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">pynccl_comm</span><span class="o">.</span><span class="n">disabled</span><span class="p">:</span>
</span><span id="L-567"><a href="#L-567"><span class="linenos"> 567</span></a>            <span class="n">pynccl_comm</span><span class="o">.</span><span class="n">all_reduce</span><span class="p">(</span><span class="n">input_</span><span class="p">)</span>
</span><span id="L-568"><a href="#L-568"><span class="linenos"> 568</span></a>        <span class="k">else</span><span class="p">:</span>
</span><span id="L-569"><a href="#L-569"><span class="linenos"> 569</span></a>            <span class="n">torch</span><span class="o">.</span><span class="n">distributed</span><span class="o">.</span><span class="n">all_reduce</span><span class="p">(</span><span class="n">input_</span><span class="p">,</span> <span class="n">group</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device_group</span><span class="p">)</span>
</span><span id="L-570"><a href="#L-570"><span class="linenos"> 570</span></a>
</span><span id="L-571"><a href="#L-571"><span class="linenos"> 571</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">reduce_scatter_tensor</span><span class="p">(</span>
</span><span id="L-572"><a href="#L-572"><span class="linenos"> 572</span></a>        <span class="bp">self</span><span class="p">,</span>
</span><span id="L-573"><a href="#L-573"><span class="linenos"> 573</span></a>        <span class="n">output</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
</span><span id="L-574"><a href="#L-574"><span class="linenos"> 574</span></a>        <span class="nb">input</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
</span><span id="L-575"><a href="#L-575"><span class="linenos"> 575</span></a>    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="L-576"><a href="#L-576"><span class="linenos"> 576</span></a>        <span class="c1"># TODO(ch-wan): support other backends</span>
</span><span id="L-577"><a href="#L-577"><span class="linenos"> 577</span></a>        <span class="n">torch</span><span class="o">.</span><span class="n">distributed</span><span class="o">.</span><span class="n">reduce_scatter_tensor</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="nb">input</span><span class="p">,</span> <span class="n">group</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device_group</span><span class="p">)</span>
</span><span id="L-578"><a href="#L-578"><span class="linenos"> 578</span></a>        <span class="k">return</span> <span class="n">output</span>
</span><span id="L-579"><a href="#L-579"><span class="linenos"> 579</span></a>
</span><span id="L-580"><a href="#L-580"><span class="linenos"> 580</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">reduce_scatter</span><span class="p">(</span>
</span><span id="L-581"><a href="#L-581"><span class="linenos"> 581</span></a>        <span class="bp">self</span><span class="p">,</span>
</span><span id="L-582"><a href="#L-582"><span class="linenos"> 582</span></a>        <span class="n">output</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
</span><span id="L-583"><a href="#L-583"><span class="linenos"> 583</span></a>        <span class="n">input_list</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">],</span>
</span><span id="L-584"><a href="#L-584"><span class="linenos"> 584</span></a>    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="L-585"><a href="#L-585"><span class="linenos"> 585</span></a>        <span class="c1"># TODO(ch-wan): support other backends</span>
</span><span id="L-586"><a href="#L-586"><span class="linenos"> 586</span></a>        <span class="n">torch</span><span class="o">.</span><span class="n">distributed</span><span class="o">.</span><span class="n">reduce_scatter</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="n">input_list</span><span class="p">,</span> <span class="n">group</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device_group</span><span class="p">)</span>
</span><span id="L-587"><a href="#L-587"><span class="linenos"> 587</span></a>        <span class="k">return</span> <span class="n">output</span>
</span><span id="L-588"><a href="#L-588"><span class="linenos"> 588</span></a>
</span><span id="L-589"><a href="#L-589"><span class="linenos"> 589</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">reduce_scatterv</span><span class="p">(</span>
</span><span id="L-590"><a href="#L-590"><span class="linenos"> 590</span></a>        <span class="bp">self</span><span class="p">,</span>
</span><span id="L-591"><a href="#L-591"><span class="linenos"> 591</span></a>        <span class="n">input_</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
</span><span id="L-592"><a href="#L-592"><span class="linenos"> 592</span></a>        <span class="n">output</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="L-593"><a href="#L-593"><span class="linenos"> 593</span></a>        <span class="n">sizes</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="nb">int</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="L-594"><a href="#L-594"><span class="linenos"> 594</span></a>    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
</span><span id="L-595"><a href="#L-595"><span class="linenos"> 595</span></a>        <span class="n">world_size</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">world_size</span>
</span><span id="L-596"><a href="#L-596"><span class="linenos"> 596</span></a>        <span class="n">pynccl_comm</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">pynccl_comm</span>
</span><span id="L-597"><a href="#L-597"><span class="linenos"> 597</span></a>
</span><span id="L-598"><a href="#L-598"><span class="linenos"> 598</span></a>        <span class="k">with</span> <span class="n">pynccl_comm</span><span class="o">.</span><span class="n">change_state</span><span class="p">(</span><span class="n">enable</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">stream</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">current_stream</span><span class="p">()):</span>
</span><span id="L-599"><a href="#L-599"><span class="linenos"> 599</span></a>            <span class="k">assert</span> <span class="p">(</span>
</span><span id="L-600"><a href="#L-600"><span class="linenos"> 600</span></a>                <span class="n">pynccl_comm</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">pynccl_comm</span><span class="o">.</span><span class="n">disabled</span>
</span><span id="L-601"><a href="#L-601"><span class="linenos"> 601</span></a>            <span class="p">),</span> <span class="s2">&quot;pynccl is required for reduce_scatterv&quot;</span>
</span><span id="L-602"><a href="#L-602"><span class="linenos"> 602</span></a>
</span><span id="L-603"><a href="#L-603"><span class="linenos"> 603</span></a>            <span class="k">if</span> <span class="n">sizes</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="L-604"><a href="#L-604"><span class="linenos"> 604</span></a>                <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">sizes</span><span class="p">)</span> <span class="o">==</span> <span class="n">world_size</span>
</span><span id="L-605"><a href="#L-605"><span class="linenos"> 605</span></a>                <span class="k">assert</span> <span class="n">input_</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">==</span> <span class="nb">sum</span><span class="p">(</span><span class="n">sizes</span><span class="p">)</span>
</span><span id="L-606"><a href="#L-606"><span class="linenos"> 606</span></a>                <span class="n">chunk_size</span> <span class="o">=</span> <span class="n">sizes</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">rank_in_group</span><span class="p">]</span>
</span><span id="L-607"><a href="#L-607"><span class="linenos"> 607</span></a>            <span class="k">else</span><span class="p">:</span>
</span><span id="L-608"><a href="#L-608"><span class="linenos"> 608</span></a>                <span class="k">assert</span> <span class="n">input_</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">%</span> <span class="n">world_size</span> <span class="o">==</span> <span class="mi">0</span>
</span><span id="L-609"><a href="#L-609"><span class="linenos"> 609</span></a>                <span class="n">chunk_size</span> <span class="o">=</span> <span class="n">input_</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">//</span> <span class="n">world_size</span>
</span><span id="L-610"><a href="#L-610"><span class="linenos"> 610</span></a>            <span class="n">output_shape</span> <span class="o">=</span> <span class="p">(</span><span class="n">chunk_size</span><span class="p">,)</span> <span class="o">+</span> <span class="n">input_</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">:]</span>
</span><span id="L-611"><a href="#L-611"><span class="linenos"> 611</span></a>
</span><span id="L-612"><a href="#L-612"><span class="linenos"> 612</span></a>            <span class="k">if</span> <span class="n">output</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="L-613"><a href="#L-613"><span class="linenos"> 613</span></a>                <span class="n">output</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span>
</span><span id="L-614"><a href="#L-614"><span class="linenos"> 614</span></a>                    <span class="n">output_shape</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">input_</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">input_</span><span class="o">.</span><span class="n">device</span>
</span><span id="L-615"><a href="#L-615"><span class="linenos"> 615</span></a>                <span class="p">)</span>
</span><span id="L-616"><a href="#L-616"><span class="linenos"> 616</span></a>            <span class="k">else</span><span class="p">:</span>
</span><span id="L-617"><a href="#L-617"><span class="linenos"> 617</span></a>                <span class="k">assert</span> <span class="n">output</span><span class="o">.</span><span class="n">shape</span> <span class="o">==</span> <span class="n">output_shape</span>
</span><span id="L-618"><a href="#L-618"><span class="linenos"> 618</span></a>
</span><span id="L-619"><a href="#L-619"><span class="linenos"> 619</span></a>            <span class="n">pynccl_comm</span><span class="o">.</span><span class="n">reduce_scatter</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="n">input_</span><span class="p">,</span> <span class="n">sizes</span><span class="o">=</span><span class="n">sizes</span><span class="p">)</span>
</span><span id="L-620"><a href="#L-620"><span class="linenos"> 620</span></a>            <span class="k">return</span> <span class="n">output</span>
</span><span id="L-621"><a href="#L-621"><span class="linenos"> 621</span></a>
</span><span id="L-622"><a href="#L-622"><span class="linenos"> 622</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">_all_gather_into_tensor</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">output</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="nb">input</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">):</span>
</span><span id="L-623"><a href="#L-623"><span class="linenos"> 623</span></a>        <span class="n">pynccl_comm</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">pynccl_comm</span>
</span><span id="L-624"><a href="#L-624"><span class="linenos"> 624</span></a>        <span class="k">if</span> <span class="n">pynccl_comm</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">pynccl_comm</span><span class="o">.</span><span class="n">disabled</span><span class="p">:</span>
</span><span id="L-625"><a href="#L-625"><span class="linenos"> 625</span></a>            <span class="n">pynccl_comm</span><span class="o">.</span><span class="n">all_gather</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="nb">input</span><span class="p">)</span>
</span><span id="L-626"><a href="#L-626"><span class="linenos"> 626</span></a>        <span class="k">else</span><span class="p">:</span>
</span><span id="L-627"><a href="#L-627"><span class="linenos"> 627</span></a>            <span class="n">torch</span><span class="o">.</span><span class="n">distributed</span><span class="o">.</span><span class="n">all_gather_into_tensor</span><span class="p">(</span>
</span><span id="L-628"><a href="#L-628"><span class="linenos"> 628</span></a>                <span class="n">output</span><span class="p">,</span> <span class="nb">input</span><span class="p">,</span> <span class="n">group</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device_group</span>
</span><span id="L-629"><a href="#L-629"><span class="linenos"> 629</span></a>            <span class="p">)</span>
</span><span id="L-630"><a href="#L-630"><span class="linenos"> 630</span></a>
</span><span id="L-631"><a href="#L-631"><span class="linenos"> 631</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">all_gather_into_tensor</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">output</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="nb">input</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">):</span>
</span><span id="L-632"><a href="#L-632"><span class="linenos"> 632</span></a>        <span class="k">if</span> <span class="n">_is_npu</span> <span class="ow">or</span> <span class="ow">not</span> <span class="n">supports_custom_op</span><span class="p">():</span>
</span><span id="L-633"><a href="#L-633"><span class="linenos"> 633</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">_all_gather_into_tensor</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="nb">input</span><span class="p">)</span>
</span><span id="L-634"><a href="#L-634"><span class="linenos"> 634</span></a>        <span class="k">else</span><span class="p">:</span>
</span><span id="L-635"><a href="#L-635"><span class="linenos"> 635</span></a>            <span class="n">torch</span><span class="o">.</span><span class="n">ops</span><span class="o">.</span><span class="n">sglang</span><span class="o">.</span><span class="n">reg_all_gather_into_tensor</span><span class="p">(</span>
</span><span id="L-636"><a href="#L-636"><span class="linenos"> 636</span></a>                <span class="n">output</span><span class="p">,</span> <span class="nb">input</span><span class="p">,</span> <span class="n">group_name</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">unique_name</span>
</span><span id="L-637"><a href="#L-637"><span class="linenos"> 637</span></a>            <span class="p">)</span>
</span><span id="L-638"><a href="#L-638"><span class="linenos"> 638</span></a>
</span><span id="L-639"><a href="#L-639"><span class="linenos"> 639</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">all_gather</span><span class="p">(</span>
</span><span id="L-640"><a href="#L-640"><span class="linenos"> 640</span></a>        <span class="bp">self</span><span class="p">,</span>
</span><span id="L-641"><a href="#L-641"><span class="linenos"> 641</span></a>        <span class="n">input_</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
</span><span id="L-642"><a href="#L-642"><span class="linenos"> 642</span></a>        <span class="n">dim</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
</span><span id="L-643"><a href="#L-643"><span class="linenos"> 643</span></a>        <span class="n">output_tensor_list</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="L-644"><a href="#L-644"><span class="linenos"> 644</span></a>    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
</span><span id="L-645"><a href="#L-645"><span class="linenos"> 645</span></a>        <span class="n">world_size</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">world_size</span>
</span><span id="L-646"><a href="#L-646"><span class="linenos"> 646</span></a>        <span class="c1"># Bypass the function if we are using only 1 GPU.</span>
</span><span id="L-647"><a href="#L-647"><span class="linenos"> 647</span></a>        <span class="k">if</span> <span class="n">world_size</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
</span><span id="L-648"><a href="#L-648"><span class="linenos"> 648</span></a>            <span class="k">if</span> <span class="n">output_tensor_list</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="L-649"><a href="#L-649"><span class="linenos"> 649</span></a>                <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span>
</span><span id="L-650"><a href="#L-650"><span class="linenos"> 650</span></a>                    <span class="s2">&quot;Performing in-place all-gather with a group size of 1. &quot;</span>
</span><span id="L-651"><a href="#L-651"><span class="linenos"> 651</span></a>                    <span class="s2">&quot;This may be unnecessary; consider bypassing it for better efficiency.&quot;</span>
</span><span id="L-652"><a href="#L-652"><span class="linenos"> 652</span></a>                <span class="p">)</span>
</span><span id="L-653"><a href="#L-653"><span class="linenos"> 653</span></a>                <span class="n">output_tensor_list</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">copy_</span><span class="p">(</span><span class="n">input_</span><span class="p">)</span>
</span><span id="L-654"><a href="#L-654"><span class="linenos"> 654</span></a>                <span class="k">return</span> <span class="kc">None</span>
</span><span id="L-655"><a href="#L-655"><span class="linenos"> 655</span></a>            <span class="k">else</span><span class="p">:</span>
</span><span id="L-656"><a href="#L-656"><span class="linenos"> 656</span></a>                <span class="k">return</span> <span class="n">input_</span>
</span><span id="L-657"><a href="#L-657"><span class="linenos"> 657</span></a>
</span><span id="L-658"><a href="#L-658"><span class="linenos"> 658</span></a>        <span class="k">if</span> <span class="n">output_tensor_list</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="L-659"><a href="#L-659"><span class="linenos"> 659</span></a>            <span class="c1"># TODO(ch-wan): support other backends</span>
</span><span id="L-660"><a href="#L-660"><span class="linenos"> 660</span></a>            <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">distributed</span><span class="o">.</span><span class="n">all_gather</span><span class="p">(</span>
</span><span id="L-661"><a href="#L-661"><span class="linenos"> 661</span></a>                <span class="n">output_tensor_list</span><span class="p">,</span> <span class="n">input_</span><span class="p">,</span> <span class="n">group</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device_group</span>
</span><span id="L-662"><a href="#L-662"><span class="linenos"> 662</span></a>            <span class="p">)</span>
</span><span id="L-663"><a href="#L-663"><span class="linenos"> 663</span></a>
</span><span id="L-664"><a href="#L-664"><span class="linenos"> 664</span></a>        <span class="k">assert</span> <span class="p">(</span>
</span><span id="L-665"><a href="#L-665"><span class="linenos"> 665</span></a>            <span class="o">-</span><span class="n">input_</span><span class="o">.</span><span class="n">dim</span><span class="p">()</span> <span class="o">&lt;=</span> <span class="n">dim</span> <span class="o">&lt;</span> <span class="n">input_</span><span class="o">.</span><span class="n">dim</span><span class="p">()</span>
</span><span id="L-666"><a href="#L-666"><span class="linenos"> 666</span></a>        <span class="p">),</span> <span class="sa">f</span><span class="s2">&quot;Invalid dim (</span><span class="si">{</span><span class="n">dim</span><span class="si">}</span><span class="s2">) for input tensor with shape </span><span class="si">{</span><span class="n">input_</span><span class="o">.</span><span class="n">size</span><span class="p">()</span><span class="si">}</span><span class="s2">&quot;</span>
</span><span id="L-667"><a href="#L-667"><span class="linenos"> 667</span></a>
</span><span id="L-668"><a href="#L-668"><span class="linenos"> 668</span></a>        <span class="c1"># For HPUs, use HPU communicator.</span>
</span><span id="L-669"><a href="#L-669"><span class="linenos"> 669</span></a>        <span class="n">hpu_comm</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">hpu_communicator</span>
</span><span id="L-670"><a href="#L-670"><span class="linenos"> 670</span></a>        <span class="k">if</span> <span class="n">hpu_comm</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">hpu_comm</span><span class="o">.</span><span class="n">disabled</span><span class="p">:</span>
</span><span id="L-671"><a href="#L-671"><span class="linenos"> 671</span></a>            <span class="k">return</span> <span class="n">hpu_comm</span><span class="o">.</span><span class="n">all_gather</span><span class="p">(</span><span class="n">input_</span><span class="p">,</span> <span class="n">dim</span><span class="p">)</span>
</span><span id="L-672"><a href="#L-672"><span class="linenos"> 672</span></a>
</span><span id="L-673"><a href="#L-673"><span class="linenos"> 673</span></a>        <span class="c1"># For NPUs, use NPU communicator.</span>
</span><span id="L-674"><a href="#L-674"><span class="linenos"> 674</span></a>        <span class="n">npu_comm</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">npu_communicator</span>
</span><span id="L-675"><a href="#L-675"><span class="linenos"> 675</span></a>        <span class="k">if</span> <span class="n">npu_comm</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">npu_comm</span><span class="o">.</span><span class="n">disabled</span><span class="p">:</span>
</span><span id="L-676"><a href="#L-676"><span class="linenos"> 676</span></a>            <span class="k">return</span> <span class="n">npu_comm</span><span class="o">.</span><span class="n">all_gather</span><span class="p">(</span><span class="n">input_</span><span class="p">,</span> <span class="n">dim</span><span class="p">)</span>
</span><span id="L-677"><a href="#L-677"><span class="linenos"> 677</span></a>
</span><span id="L-678"><a href="#L-678"><span class="linenos"> 678</span></a>        <span class="k">if</span> <span class="n">dim</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">:</span>
</span><span id="L-679"><a href="#L-679"><span class="linenos"> 679</span></a>            <span class="c1"># Convert negative dim to positive.</span>
</span><span id="L-680"><a href="#L-680"><span class="linenos"> 680</span></a>            <span class="n">dim</span> <span class="o">+=</span> <span class="n">input_</span><span class="o">.</span><span class="n">dim</span><span class="p">()</span>
</span><span id="L-681"><a href="#L-681"><span class="linenos"> 681</span></a>        <span class="n">input_size</span> <span class="o">=</span> <span class="n">input_</span><span class="o">.</span><span class="n">size</span><span class="p">()</span>
</span><span id="L-682"><a href="#L-682"><span class="linenos"> 682</span></a>        <span class="c1"># NOTE: we have to use concat-style all-gather here,</span>
</span><span id="L-683"><a href="#L-683"><span class="linenos"> 683</span></a>        <span class="c1"># stack-style all-gather has compatibility issues with</span>
</span><span id="L-684"><a href="#L-684"><span class="linenos"> 684</span></a>        <span class="c1"># torch.compile . see https://github.com/pytorch/pytorch/issues/138795</span>
</span><span id="L-685"><a href="#L-685"><span class="linenos"> 685</span></a>        <span class="n">output_size</span> <span class="o">=</span> <span class="p">(</span><span class="n">input_size</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">*</span> <span class="n">world_size</span><span class="p">,)</span> <span class="o">+</span> <span class="n">input_size</span><span class="p">[</span><span class="mi">1</span><span class="p">:]</span>
</span><span id="L-686"><a href="#L-686"><span class="linenos"> 686</span></a>        <span class="c1"># Allocate output tensor.</span>
</span><span id="L-687"><a href="#L-687"><span class="linenos"> 687</span></a>        <span class="n">output_tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span>
</span><span id="L-688"><a href="#L-688"><span class="linenos"> 688</span></a>            <span class="n">output_size</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">input_</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">input_</span><span class="o">.</span><span class="n">device</span>
</span><span id="L-689"><a href="#L-689"><span class="linenos"> 689</span></a>        <span class="p">)</span>
</span><span id="L-690"><a href="#L-690"><span class="linenos"> 690</span></a>
</span><span id="L-691"><a href="#L-691"><span class="linenos"> 691</span></a>        <span class="c1"># All-gather.</span>
</span><span id="L-692"><a href="#L-692"><span class="linenos"> 692</span></a>        <span class="k">if</span> <span class="n">input_</span><span class="o">.</span><span class="n">is_cpu</span> <span class="ow">and</span> <span class="n">is_shm_available</span><span class="p">(</span>
</span><span id="L-693"><a href="#L-693"><span class="linenos"> 693</span></a>            <span class="n">input_</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">world_size</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">local_size</span>
</span><span id="L-694"><a href="#L-694"><span class="linenos"> 694</span></a>        <span class="p">):</span>
</span><span id="L-695"><a href="#L-695"><span class="linenos"> 695</span></a>            <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">ops</span><span class="o">.</span><span class="n">sgl_kernel</span><span class="o">.</span><span class="n">shm_allgather</span><span class="p">(</span><span class="n">input_</span><span class="p">,</span> <span class="n">dim</span><span class="p">)</span>
</span><span id="L-696"><a href="#L-696"><span class="linenos"> 696</span></a>
</span><span id="L-697"><a href="#L-697"><span class="linenos"> 697</span></a>        <span class="k">if</span> <span class="n">input_</span><span class="o">.</span><span class="n">is_cpu</span><span class="p">:</span>
</span><span id="L-698"><a href="#L-698"><span class="linenos"> 698</span></a>            <span class="n">torch</span><span class="o">.</span><span class="n">distributed</span><span class="o">.</span><span class="n">all_gather_into_tensor</span><span class="p">(</span>
</span><span id="L-699"><a href="#L-699"><span class="linenos"> 699</span></a>                <span class="n">output_tensor</span><span class="p">,</span> <span class="n">input_</span><span class="p">,</span> <span class="n">group</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device_group</span>
</span><span id="L-700"><a href="#L-700"><span class="linenos"> 700</span></a>            <span class="p">)</span>
</span><span id="L-701"><a href="#L-701"><span class="linenos"> 701</span></a>        <span class="k">else</span><span class="p">:</span>
</span><span id="L-702"><a href="#L-702"><span class="linenos"> 702</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">all_gather_into_tensor</span><span class="p">(</span><span class="n">output_tensor</span><span class="p">,</span> <span class="n">input_</span><span class="p">)</span>
</span><span id="L-703"><a href="#L-703"><span class="linenos"> 703</span></a>
</span><span id="L-704"><a href="#L-704"><span class="linenos"> 704</span></a>        <span class="c1"># Reshape</span>
</span><span id="L-705"><a href="#L-705"><span class="linenos"> 705</span></a>        <span class="n">output_tensor</span> <span class="o">=</span> <span class="n">output_tensor</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="n">world_size</span><span class="p">,)</span> <span class="o">+</span> <span class="n">input_size</span><span class="p">)</span>
</span><span id="L-706"><a href="#L-706"><span class="linenos"> 706</span></a>        <span class="n">output_tensor</span> <span class="o">=</span> <span class="n">output_tensor</span><span class="o">.</span><span class="n">movedim</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">dim</span><span class="p">)</span>
</span><span id="L-707"><a href="#L-707"><span class="linenos"> 707</span></a>        <span class="n">output_tensor</span> <span class="o">=</span> <span class="n">output_tensor</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span>
</span><span id="L-708"><a href="#L-708"><span class="linenos"> 708</span></a>            <span class="n">input_size</span><span class="p">[:</span><span class="n">dim</span><span class="p">]</span> <span class="o">+</span> <span class="p">(</span><span class="n">world_size</span> <span class="o">*</span> <span class="n">input_size</span><span class="p">[</span><span class="n">dim</span><span class="p">],)</span> <span class="o">+</span> <span class="n">input_size</span><span class="p">[</span><span class="n">dim</span> <span class="o">+</span> <span class="mi">1</span> <span class="p">:]</span>
</span><span id="L-709"><a href="#L-709"><span class="linenos"> 709</span></a>        <span class="p">)</span>
</span><span id="L-710"><a href="#L-710"><span class="linenos"> 710</span></a>        <span class="k">return</span> <span class="n">output_tensor</span>
</span><span id="L-711"><a href="#L-711"><span class="linenos"> 711</span></a>
</span><span id="L-712"><a href="#L-712"><span class="linenos"> 712</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">all_gatherv</span><span class="p">(</span>
</span><span id="L-713"><a href="#L-713"><span class="linenos"> 713</span></a>        <span class="bp">self</span><span class="p">,</span>
</span><span id="L-714"><a href="#L-714"><span class="linenos"> 714</span></a>        <span class="n">input_</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]],</span>
</span><span id="L-715"><a href="#L-715"><span class="linenos"> 715</span></a>        <span class="n">sizes</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="nb">int</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="L-716"><a href="#L-716"><span class="linenos"> 716</span></a>    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Union</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]]:</span>
</span><span id="L-717"><a href="#L-717"><span class="linenos"> 717</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="L-718"><a href="#L-718"><span class="linenos"> 718</span></a><span class="sd">        Supports varying sizes per rank and input tensor list.</span>
</span><span id="L-719"><a href="#L-719"><span class="linenos"> 719</span></a><span class="sd">        `sizes`: a list of len(world_size) with the number of items per rank to gather.</span>
</span><span id="L-720"><a href="#L-720"><span class="linenos"> 720</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="L-721"><a href="#L-721"><span class="linenos"> 721</span></a>        <span class="n">world_size</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">world_size</span>
</span><span id="L-722"><a href="#L-722"><span class="linenos"> 722</span></a>        <span class="n">pynccl_comm</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">pynccl_comm</span>
</span><span id="L-723"><a href="#L-723"><span class="linenos"> 723</span></a>
</span><span id="L-724"><a href="#L-724"><span class="linenos"> 724</span></a>        <span class="k">with</span> <span class="n">pynccl_comm</span><span class="o">.</span><span class="n">change_state</span><span class="p">(</span><span class="n">enable</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">stream</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">current_stream</span><span class="p">()):</span>
</span><span id="L-725"><a href="#L-725"><span class="linenos"> 725</span></a>            <span class="k">assert</span> <span class="p">(</span>
</span><span id="L-726"><a href="#L-726"><span class="linenos"> 726</span></a>                <span class="n">pynccl_comm</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">pynccl_comm</span><span class="o">.</span><span class="n">disabled</span>
</span><span id="L-727"><a href="#L-727"><span class="linenos"> 727</span></a>            <span class="p">),</span> <span class="s2">&quot;pynccl is required for all_gatherv&quot;</span>
</span><span id="L-728"><a href="#L-728"><span class="linenos"> 728</span></a>
</span><span id="L-729"><a href="#L-729"><span class="linenos"> 729</span></a>            <span class="k">def</span><span class="w"> </span><span class="nf">_all_gather_single</span><span class="p">(</span>
</span><span id="L-730"><a href="#L-730"><span class="linenos"> 730</span></a>                <span class="n">input_</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">sizes</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="nb">int</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span>
</span><span id="L-731"><a href="#L-731"><span class="linenos"> 731</span></a>            <span class="p">):</span>
</span><span id="L-732"><a href="#L-732"><span class="linenos"> 732</span></a>                <span class="n">input_size</span> <span class="o">=</span> <span class="n">input_</span><span class="o">.</span><span class="n">size</span><span class="p">()</span>
</span><span id="L-733"><a href="#L-733"><span class="linenos"> 733</span></a>                <span class="k">if</span> <span class="n">sizes</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="L-734"><a href="#L-734"><span class="linenos"> 734</span></a>                    <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">sizes</span><span class="p">)</span> <span class="o">==</span> <span class="n">world_size</span>
</span><span id="L-735"><a href="#L-735"><span class="linenos"> 735</span></a>                    <span class="k">assert</span> <span class="n">input_</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">==</span> <span class="n">sizes</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">rank_in_group</span><span class="p">]</span>
</span><span id="L-736"><a href="#L-736"><span class="linenos"> 736</span></a>                    <span class="n">output_size</span> <span class="o">=</span> <span class="p">(</span><span class="nb">sum</span><span class="p">(</span><span class="n">sizes</span><span class="p">),)</span> <span class="o">+</span> <span class="n">input_size</span><span class="p">[</span><span class="mi">1</span><span class="p">:]</span>
</span><span id="L-737"><a href="#L-737"><span class="linenos"> 737</span></a>                    <span class="c1"># &#39;sizes&#39; is not needed if all inputs in the same group have the same shape</span>
</span><span id="L-738"><a href="#L-738"><span class="linenos"> 738</span></a>                    <span class="k">if</span> <span class="nb">all</span><span class="p">(</span><span class="n">s</span> <span class="o">==</span> <span class="n">sizes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="n">sizes</span><span class="p">):</span>
</span><span id="L-739"><a href="#L-739"><span class="linenos"> 739</span></a>                        <span class="n">sizes</span> <span class="o">=</span> <span class="kc">None</span>
</span><span id="L-740"><a href="#L-740"><span class="linenos"> 740</span></a>                <span class="k">else</span><span class="p">:</span>
</span><span id="L-741"><a href="#L-741"><span class="linenos"> 741</span></a>                    <span class="n">output_size</span> <span class="o">=</span> <span class="p">(</span><span class="n">input_size</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">*</span> <span class="n">world_size</span><span class="p">,)</span> <span class="o">+</span> <span class="n">input_size</span><span class="p">[</span><span class="mi">1</span><span class="p">:]</span>
</span><span id="L-742"><a href="#L-742"><span class="linenos"> 742</span></a>                <span class="c1"># Allocate output tensor.</span>
</span><span id="L-743"><a href="#L-743"><span class="linenos"> 743</span></a>                <span class="n">output_tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span>
</span><span id="L-744"><a href="#L-744"><span class="linenos"> 744</span></a>                    <span class="n">output_size</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">input_</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">input_</span><span class="o">.</span><span class="n">device</span>
</span><span id="L-745"><a href="#L-745"><span class="linenos"> 745</span></a>                <span class="p">)</span>
</span><span id="L-746"><a href="#L-746"><span class="linenos"> 746</span></a>                <span class="n">pynccl_comm</span><span class="o">.</span><span class="n">all_gather</span><span class="p">(</span><span class="n">output_tensor</span><span class="p">,</span> <span class="n">input_</span><span class="p">,</span> <span class="n">sizes</span><span class="o">=</span><span class="n">sizes</span><span class="p">)</span>
</span><span id="L-747"><a href="#L-747"><span class="linenos"> 747</span></a>                <span class="k">return</span> <span class="n">output_tensor</span>
</span><span id="L-748"><a href="#L-748"><span class="linenos"> 748</span></a>
</span><span id="L-749"><a href="#L-749"><span class="linenos"> 749</span></a>            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">input_</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">):</span>
</span><span id="L-750"><a href="#L-750"><span class="linenos"> 750</span></a>                <span class="k">return</span> <span class="n">_all_gather_single</span><span class="p">(</span><span class="n">input_</span><span class="p">,</span> <span class="n">sizes</span><span class="p">)</span>
</span><span id="L-751"><a href="#L-751"><span class="linenos"> 751</span></a>
</span><span id="L-752"><a href="#L-752"><span class="linenos"> 752</span></a>            <span class="n">output_list</span> <span class="o">=</span> <span class="p">[]</span>
</span><span id="L-753"><a href="#L-753"><span class="linenos"> 753</span></a>            <span class="n">pynccl_comm</span><span class="o">.</span><span class="n">group_start</span><span class="p">()</span>
</span><span id="L-754"><a href="#L-754"><span class="linenos"> 754</span></a>            <span class="k">for</span> <span class="n">inp</span> <span class="ow">in</span> <span class="n">input_</span><span class="p">:</span>
</span><span id="L-755"><a href="#L-755"><span class="linenos"> 755</span></a>                <span class="n">output_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">_all_gather_single</span><span class="p">(</span><span class="n">inp</span><span class="p">,</span> <span class="n">sizes</span><span class="o">=</span><span class="n">sizes</span><span class="p">))</span>
</span><span id="L-756"><a href="#L-756"><span class="linenos"> 756</span></a>            <span class="n">pynccl_comm</span><span class="o">.</span><span class="n">group_end</span><span class="p">()</span>
</span><span id="L-757"><a href="#L-757"><span class="linenos"> 757</span></a>
</span><span id="L-758"><a href="#L-758"><span class="linenos"> 758</span></a>            <span class="k">return</span> <span class="n">output_list</span>
</span><span id="L-759"><a href="#L-759"><span class="linenos"> 759</span></a>
</span><span id="L-760"><a href="#L-760"><span class="linenos"> 760</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">gather</span><span class="p">(</span>
</span><span id="L-761"><a href="#L-761"><span class="linenos"> 761</span></a>        <span class="bp">self</span><span class="p">,</span> <span class="n">input_</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">dst</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span> <span class="n">dim</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span>
</span><span id="L-762"><a href="#L-762"><span class="linenos"> 762</span></a>    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]:</span>
</span><span id="L-763"><a href="#L-763"><span class="linenos"> 763</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="L-764"><a href="#L-764"><span class="linenos"> 764</span></a><span class="sd">        NOTE: We assume that the input tensor is on the same device across</span>
</span><span id="L-765"><a href="#L-765"><span class="linenos"> 765</span></a><span class="sd">        all the ranks.</span>
</span><span id="L-766"><a href="#L-766"><span class="linenos"> 766</span></a><span class="sd">        NOTE: `dst` is the local rank of the destination rank.</span>
</span><span id="L-767"><a href="#L-767"><span class="linenos"> 767</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="L-768"><a href="#L-768"><span class="linenos"> 768</span></a>        <span class="n">world_size</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">world_size</span>
</span><span id="L-769"><a href="#L-769"><span class="linenos"> 769</span></a>        <span class="c1"># Bypass the function if we are using only 1 GPU.</span>
</span><span id="L-770"><a href="#L-770"><span class="linenos"> 770</span></a>        <span class="k">if</span> <span class="n">world_size</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
</span><span id="L-771"><a href="#L-771"><span class="linenos"> 771</span></a>            <span class="k">return</span> <span class="n">input_</span>
</span><span id="L-772"><a href="#L-772"><span class="linenos"> 772</span></a>        <span class="k">assert</span> <span class="p">(</span>
</span><span id="L-773"><a href="#L-773"><span class="linenos"> 773</span></a>            <span class="o">-</span><span class="n">input_</span><span class="o">.</span><span class="n">dim</span><span class="p">()</span> <span class="o">&lt;=</span> <span class="n">dim</span> <span class="o">&lt;</span> <span class="n">input_</span><span class="o">.</span><span class="n">dim</span><span class="p">()</span>
</span><span id="L-774"><a href="#L-774"><span class="linenos"> 774</span></a>        <span class="p">),</span> <span class="sa">f</span><span class="s2">&quot;Invalid dim (</span><span class="si">{</span><span class="n">dim</span><span class="si">}</span><span class="s2">) for input tensor with shape </span><span class="si">{</span><span class="n">input_</span><span class="o">.</span><span class="n">size</span><span class="p">()</span><span class="si">}</span><span class="s2">&quot;</span>
</span><span id="L-775"><a href="#L-775"><span class="linenos"> 775</span></a>        <span class="k">if</span> <span class="n">dim</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">:</span>
</span><span id="L-776"><a href="#L-776"><span class="linenos"> 776</span></a>            <span class="c1"># Convert negative dim to positive.</span>
</span><span id="L-777"><a href="#L-777"><span class="linenos"> 777</span></a>            <span class="n">dim</span> <span class="o">+=</span> <span class="n">input_</span><span class="o">.</span><span class="n">dim</span><span class="p">()</span>
</span><span id="L-778"><a href="#L-778"><span class="linenos"> 778</span></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">xpu_communicator</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">xpu_communicator</span><span class="o">.</span><span class="n">disabled</span><span class="p">:</span>
</span><span id="L-779"><a href="#L-779"><span class="linenos"> 779</span></a>            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">xpu_communicator</span><span class="o">.</span><span class="n">gather</span><span class="p">(</span><span class="n">input_</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">rank_in_group</span><span class="p">,</span> <span class="n">dst</span><span class="p">,</span> <span class="n">dim</span><span class="p">)</span>
</span><span id="L-780"><a href="#L-780"><span class="linenos"> 780</span></a>        <span class="c1"># Allocate output tensor.</span>
</span><span id="L-781"><a href="#L-781"><span class="linenos"> 781</span></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">rank_in_group</span> <span class="o">==</span> <span class="n">dst</span><span class="p">:</span>
</span><span id="L-782"><a href="#L-782"><span class="linenos"> 782</span></a>            <span class="n">gather_list</span> <span class="o">=</span> <span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">empty_like</span><span class="p">(</span><span class="n">input_</span><span class="p">)</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">world_size</span><span class="p">)]</span>
</span><span id="L-783"><a href="#L-783"><span class="linenos"> 783</span></a>        <span class="k">else</span><span class="p">:</span>
</span><span id="L-784"><a href="#L-784"><span class="linenos"> 784</span></a>            <span class="n">gather_list</span> <span class="o">=</span> <span class="kc">None</span>
</span><span id="L-785"><a href="#L-785"><span class="linenos"> 785</span></a>        <span class="c1"># Gather.</span>
</span><span id="L-786"><a href="#L-786"><span class="linenos"> 786</span></a>        <span class="n">torch</span><span class="o">.</span><span class="n">distributed</span><span class="o">.</span><span class="n">gather</span><span class="p">(</span>
</span><span id="L-787"><a href="#L-787"><span class="linenos"> 787</span></a>            <span class="n">input_</span><span class="p">,</span> <span class="n">gather_list</span><span class="p">,</span> <span class="n">dst</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">ranks</span><span class="p">[</span><span class="n">dst</span><span class="p">],</span> <span class="n">group</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device_group</span>
</span><span id="L-788"><a href="#L-788"><span class="linenos"> 788</span></a>        <span class="p">)</span>
</span><span id="L-789"><a href="#L-789"><span class="linenos"> 789</span></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">rank_in_group</span> <span class="o">==</span> <span class="n">dst</span><span class="p">:</span>
</span><span id="L-790"><a href="#L-790"><span class="linenos"> 790</span></a>            <span class="n">output_tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span><span class="n">gather_list</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="n">dim</span><span class="p">)</span>
</span><span id="L-791"><a href="#L-791"><span class="linenos"> 791</span></a>        <span class="k">else</span><span class="p">:</span>
</span><span id="L-792"><a href="#L-792"><span class="linenos"> 792</span></a>            <span class="n">output_tensor</span> <span class="o">=</span> <span class="kc">None</span>
</span><span id="L-793"><a href="#L-793"><span class="linenos"> 793</span></a>        <span class="k">return</span> <span class="n">output_tensor</span>
</span><span id="L-794"><a href="#L-794"><span class="linenos"> 794</span></a>
</span><span id="L-795"><a href="#L-795"><span class="linenos"> 795</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">broadcast</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">src</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span><span class="p">):</span>
</span><span id="L-796"><a href="#L-796"><span class="linenos"> 796</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;Broadcast the input tensor.</span>
</span><span id="L-797"><a href="#L-797"><span class="linenos"> 797</span></a><span class="sd">        NOTE: `src` is the local rank of the source rank.</span>
</span><span id="L-798"><a href="#L-798"><span class="linenos"> 798</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="L-799"><a href="#L-799"><span class="linenos"> 799</span></a>        <span class="k">assert</span> <span class="n">src</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">world_size</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;Invalid src rank (</span><span class="si">{</span><span class="n">src</span><span class="si">}</span><span class="s2">)&quot;</span>
</span><span id="L-800"><a href="#L-800"><span class="linenos"> 800</span></a>
</span><span id="L-801"><a href="#L-801"><span class="linenos"> 801</span></a>        <span class="c1"># Bypass the function if we are using only 1 GPU.</span>
</span><span id="L-802"><a href="#L-802"><span class="linenos"> 802</span></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">world_size</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
</span><span id="L-803"><a href="#L-803"><span class="linenos"> 803</span></a>            <span class="k">return</span> <span class="n">input_</span>
</span><span id="L-804"><a href="#L-804"><span class="linenos"> 804</span></a>        <span class="c1"># Broadcast.</span>
</span><span id="L-805"><a href="#L-805"><span class="linenos"> 805</span></a>        <span class="n">torch</span><span class="o">.</span><span class="n">distributed</span><span class="o">.</span><span class="n">broadcast</span><span class="p">(</span>
</span><span id="L-806"><a href="#L-806"><span class="linenos"> 806</span></a>            <span class="n">input_</span><span class="p">,</span> <span class="n">src</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">ranks</span><span class="p">[</span><span class="n">src</span><span class="p">],</span> <span class="n">group</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device_group</span>
</span><span id="L-807"><a href="#L-807"><span class="linenos"> 807</span></a>        <span class="p">)</span>
</span><span id="L-808"><a href="#L-808"><span class="linenos"> 808</span></a>        <span class="k">return</span> <span class="n">input_</span>
</span><span id="L-809"><a href="#L-809"><span class="linenos"> 809</span></a>
</span><span id="L-810"><a href="#L-810"><span class="linenos"> 810</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">broadcast_object</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">obj</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Any</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="n">src</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span><span class="p">):</span>
</span><span id="L-811"><a href="#L-811"><span class="linenos"> 811</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;Broadcast the input object.</span>
</span><span id="L-812"><a href="#L-812"><span class="linenos"> 812</span></a><span class="sd">        NOTE: `src` is the local rank of the source rank.</span>
</span><span id="L-813"><a href="#L-813"><span class="linenos"> 813</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="L-814"><a href="#L-814"><span class="linenos"> 814</span></a>        <span class="k">assert</span> <span class="n">src</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">world_size</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;Invalid src rank (</span><span class="si">{</span><span class="n">src</span><span class="si">}</span><span class="s2">)&quot;</span>
</span><span id="L-815"><a href="#L-815"><span class="linenos"> 815</span></a>
</span><span id="L-816"><a href="#L-816"><span class="linenos"> 816</span></a>        <span class="c1"># Bypass the function if we are using only 1 GPU.</span>
</span><span id="L-817"><a href="#L-817"><span class="linenos"> 817</span></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">world_size</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
</span><span id="L-818"><a href="#L-818"><span class="linenos"> 818</span></a>            <span class="k">return</span> <span class="n">obj</span>
</span><span id="L-819"><a href="#L-819"><span class="linenos"> 819</span></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">mq_broadcaster</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="L-820"><a href="#L-820"><span class="linenos"> 820</span></a>            <span class="k">assert</span> <span class="n">src</span> <span class="o">==</span> <span class="mi">0</span><span class="p">,</span> <span class="s2">&quot;Message queue broadcaster only supports src=0&quot;</span>
</span><span id="L-821"><a href="#L-821"><span class="linenos"> 821</span></a>            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">mq_broadcaster</span><span class="o">.</span><span class="n">broadcast_object</span><span class="p">(</span><span class="n">obj</span><span class="p">)</span>
</span><span id="L-822"><a href="#L-822"><span class="linenos"> 822</span></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">rank_in_group</span> <span class="o">==</span> <span class="n">src</span><span class="p">:</span>
</span><span id="L-823"><a href="#L-823"><span class="linenos"> 823</span></a>            <span class="n">torch</span><span class="o">.</span><span class="n">distributed</span><span class="o">.</span><span class="n">broadcast_object_list</span><span class="p">(</span>
</span><span id="L-824"><a href="#L-824"><span class="linenos"> 824</span></a>                <span class="p">[</span><span class="n">obj</span><span class="p">],</span> <span class="n">src</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">ranks</span><span class="p">[</span><span class="n">src</span><span class="p">],</span> <span class="n">group</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">cpu_group</span>
</span><span id="L-825"><a href="#L-825"><span class="linenos"> 825</span></a>            <span class="p">)</span>
</span><span id="L-826"><a href="#L-826"><span class="linenos"> 826</span></a>            <span class="k">return</span> <span class="n">obj</span>
</span><span id="L-827"><a href="#L-827"><span class="linenos"> 827</span></a>        <span class="k">else</span><span class="p">:</span>
</span><span id="L-828"><a href="#L-828"><span class="linenos"> 828</span></a>            <span class="n">recv</span> <span class="o">=</span> <span class="p">[</span><span class="kc">None</span><span class="p">]</span>
</span><span id="L-829"><a href="#L-829"><span class="linenos"> 829</span></a>            <span class="n">torch</span><span class="o">.</span><span class="n">distributed</span><span class="o">.</span><span class="n">broadcast_object_list</span><span class="p">(</span>
</span><span id="L-830"><a href="#L-830"><span class="linenos"> 830</span></a>                <span class="n">recv</span><span class="p">,</span> <span class="n">src</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">ranks</span><span class="p">[</span><span class="n">src</span><span class="p">],</span> <span class="n">group</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">cpu_group</span>
</span><span id="L-831"><a href="#L-831"><span class="linenos"> 831</span></a>            <span class="p">)</span>
</span><span id="L-832"><a href="#L-832"><span class="linenos"> 832</span></a>            <span class="k">return</span> <span class="n">recv</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
</span><span id="L-833"><a href="#L-833"><span class="linenos"> 833</span></a>
</span><span id="L-834"><a href="#L-834"><span class="linenos"> 834</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">broadcast_object_list</span><span class="p">(</span>
</span><span id="L-835"><a href="#L-835"><span class="linenos"> 835</span></a>        <span class="bp">self</span><span class="p">,</span> <span class="n">obj_list</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">Any</span><span class="p">],</span> <span class="n">src</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span> <span class="n">group</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">ProcessGroup</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
</span><span id="L-836"><a href="#L-836"><span class="linenos"> 836</span></a>    <span class="p">):</span>
</span><span id="L-837"><a href="#L-837"><span class="linenos"> 837</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;Broadcast the input object list.</span>
</span><span id="L-838"><a href="#L-838"><span class="linenos"> 838</span></a><span class="sd">        NOTE: `src` is the local rank of the source rank.</span>
</span><span id="L-839"><a href="#L-839"><span class="linenos"> 839</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="L-840"><a href="#L-840"><span class="linenos"> 840</span></a>        <span class="k">assert</span> <span class="n">src</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">world_size</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;Invalid src rank (</span><span class="si">{</span><span class="n">src</span><span class="si">}</span><span class="s2">)&quot;</span>
</span><span id="L-841"><a href="#L-841"><span class="linenos"> 841</span></a>
</span><span id="L-842"><a href="#L-842"><span class="linenos"> 842</span></a>        <span class="c1"># Bypass the function if we are using only 1 GPU.</span>
</span><span id="L-843"><a href="#L-843"><span class="linenos"> 843</span></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">world_size</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
</span><span id="L-844"><a href="#L-844"><span class="linenos"> 844</span></a>            <span class="k">return</span> <span class="n">obj_list</span>
</span><span id="L-845"><a href="#L-845"><span class="linenos"> 845</span></a>        <span class="c1"># Broadcast.</span>
</span><span id="L-846"><a href="#L-846"><span class="linenos"> 846</span></a>        <span class="n">torch</span><span class="o">.</span><span class="n">distributed</span><span class="o">.</span><span class="n">broadcast_object_list</span><span class="p">(</span>
</span><span id="L-847"><a href="#L-847"><span class="linenos"> 847</span></a>            <span class="n">obj_list</span><span class="p">,</span> <span class="n">src</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">ranks</span><span class="p">[</span><span class="n">src</span><span class="p">],</span> <span class="n">group</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device_group</span>
</span><span id="L-848"><a href="#L-848"><span class="linenos"> 848</span></a>        <span class="p">)</span>
</span><span id="L-849"><a href="#L-849"><span class="linenos"> 849</span></a>        <span class="k">return</span> <span class="n">obj_list</span>
</span><span id="L-850"><a href="#L-850"><span class="linenos"> 850</span></a>
</span><span id="L-851"><a href="#L-851"><span class="linenos"> 851</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">send_object</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">obj</span><span class="p">:</span> <span class="n">Any</span><span class="p">,</span> <span class="n">dst</span><span class="p">:</span> <span class="nb">int</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="L-852"><a href="#L-852"><span class="linenos"> 852</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;Send the input object list to the destination rank.&quot;&quot;&quot;</span>
</span><span id="L-853"><a href="#L-853"><span class="linenos"> 853</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;NOTE: `dst` is the local rank of the destination rank.&quot;&quot;&quot;</span>
</span><span id="L-854"><a href="#L-854"><span class="linenos"> 854</span></a>
</span><span id="L-855"><a href="#L-855"><span class="linenos"> 855</span></a>        <span class="k">assert</span> <span class="n">dst</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">world_size</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;Invalid dst rank (</span><span class="si">{</span><span class="n">dst</span><span class="si">}</span><span class="s2">)&quot;</span>
</span><span id="L-856"><a href="#L-856"><span class="linenos"> 856</span></a>
</span><span id="L-857"><a href="#L-857"><span class="linenos"> 857</span></a>        <span class="k">assert</span> <span class="n">dst</span> <span class="o">!=</span> <span class="bp">self</span><span class="o">.</span><span class="n">rank_in_group</span><span class="p">,</span> <span class="p">(</span>
</span><span id="L-858"><a href="#L-858"><span class="linenos"> 858</span></a>            <span class="s2">&quot;Invalid destination rank. Destination rank is the same &quot;</span>
</span><span id="L-859"><a href="#L-859"><span class="linenos"> 859</span></a>            <span class="s2">&quot;as the current rank.&quot;</span>
</span><span id="L-860"><a href="#L-860"><span class="linenos"> 860</span></a>        <span class="p">)</span>
</span><span id="L-861"><a href="#L-861"><span class="linenos"> 861</span></a>
</span><span id="L-862"><a href="#L-862"><span class="linenos"> 862</span></a>        <span class="c1"># Serialize object to tensor and get the size as well</span>
</span><span id="L-863"><a href="#L-863"><span class="linenos"> 863</span></a>        <span class="n">object_tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">frombuffer</span><span class="p">(</span><span class="n">pickle</span><span class="o">.</span><span class="n">dumps</span><span class="p">(</span><span class="n">obj</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">uint8</span><span class="p">)</span><span class="o">.</span><span class="n">cuda</span><span class="p">(</span>
</span><span id="L-864"><a href="#L-864"><span class="linenos"> 864</span></a>            <span class="n">device</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">current_device</span><span class="p">()</span>
</span><span id="L-865"><a href="#L-865"><span class="linenos"> 865</span></a>        <span class="p">)</span>
</span><span id="L-866"><a href="#L-866"><span class="linenos"> 866</span></a>
</span><span id="L-867"><a href="#L-867"><span class="linenos"> 867</span></a>        <span class="n">size_tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span>
</span><span id="L-868"><a href="#L-868"><span class="linenos"> 868</span></a>            <span class="p">[</span><span class="n">object_tensor</span><span class="o">.</span><span class="n">numel</span><span class="p">()],</span>
</span><span id="L-869"><a href="#L-869"><span class="linenos"> 869</span></a>            <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">long</span><span class="p">,</span>
</span><span id="L-870"><a href="#L-870"><span class="linenos"> 870</span></a>            <span class="n">device</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">current_device</span><span class="p">(),</span>
</span><span id="L-871"><a href="#L-871"><span class="linenos"> 871</span></a>        <span class="p">)</span>
</span><span id="L-872"><a href="#L-872"><span class="linenos"> 872</span></a>
</span><span id="L-873"><a href="#L-873"><span class="linenos"> 873</span></a>        <span class="c1"># Send object size</span>
</span><span id="L-874"><a href="#L-874"><span class="linenos"> 874</span></a>        <span class="n">torch</span><span class="o">.</span><span class="n">distributed</span><span class="o">.</span><span class="n">send</span><span class="p">(</span>
</span><span id="L-875"><a href="#L-875"><span class="linenos"> 875</span></a>            <span class="n">size_tensor</span><span class="p">,</span> <span class="n">dst</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">ranks</span><span class="p">[</span><span class="n">dst</span><span class="p">],</span> <span class="n">group</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device_group</span>
</span><span id="L-876"><a href="#L-876"><span class="linenos"> 876</span></a>        <span class="p">)</span>
</span><span id="L-877"><a href="#L-877"><span class="linenos"> 877</span></a>
</span><span id="L-878"><a href="#L-878"><span class="linenos"> 878</span></a>        <span class="c1"># Send object</span>
</span><span id="L-879"><a href="#L-879"><span class="linenos"> 879</span></a>        <span class="n">torch</span><span class="o">.</span><span class="n">distributed</span><span class="o">.</span><span class="n">send</span><span class="p">(</span>
</span><span id="L-880"><a href="#L-880"><span class="linenos"> 880</span></a>            <span class="n">object_tensor</span><span class="p">,</span> <span class="n">dst</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">ranks</span><span class="p">[</span><span class="n">dst</span><span class="p">],</span> <span class="n">group</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device_group</span>
</span><span id="L-881"><a href="#L-881"><span class="linenos"> 881</span></a>        <span class="p">)</span>
</span><span id="L-882"><a href="#L-882"><span class="linenos"> 882</span></a>
</span><span id="L-883"><a href="#L-883"><span class="linenos"> 883</span></a>        <span class="k">return</span> <span class="kc">None</span>
</span><span id="L-884"><a href="#L-884"><span class="linenos"> 884</span></a>
</span><span id="L-885"><a href="#L-885"><span class="linenos"> 885</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">recv_object</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">src</span><span class="p">:</span> <span class="nb">int</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Any</span><span class="p">:</span>
</span><span id="L-886"><a href="#L-886"><span class="linenos"> 886</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;Receive the input object list from the source rank.&quot;&quot;&quot;</span>
</span><span id="L-887"><a href="#L-887"><span class="linenos"> 887</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;NOTE: `src` is the local rank of the source rank.&quot;&quot;&quot;</span>
</span><span id="L-888"><a href="#L-888"><span class="linenos"> 888</span></a>
</span><span id="L-889"><a href="#L-889"><span class="linenos"> 889</span></a>        <span class="k">assert</span> <span class="n">src</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">world_size</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;Invalid src rank (</span><span class="si">{</span><span class="n">src</span><span class="si">}</span><span class="s2">)&quot;</span>
</span><span id="L-890"><a href="#L-890"><span class="linenos"> 890</span></a>
</span><span id="L-891"><a href="#L-891"><span class="linenos"> 891</span></a>        <span class="k">assert</span> <span class="p">(</span>
</span><span id="L-892"><a href="#L-892"><span class="linenos"> 892</span></a>            <span class="n">src</span> <span class="o">!=</span> <span class="bp">self</span><span class="o">.</span><span class="n">rank_in_group</span>
</span><span id="L-893"><a href="#L-893"><span class="linenos"> 893</span></a>        <span class="p">),</span> <span class="s2">&quot;Invalid source rank. Source rank is the same as the current rank.&quot;</span>
</span><span id="L-894"><a href="#L-894"><span class="linenos"> 894</span></a>
</span><span id="L-895"><a href="#L-895"><span class="linenos"> 895</span></a>        <span class="n">size_tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span>
</span><span id="L-896"><a href="#L-896"><span class="linenos"> 896</span></a>            <span class="mi">1</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">long</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">current_device</span><span class="p">()</span>
</span><span id="L-897"><a href="#L-897"><span class="linenos"> 897</span></a>        <span class="p">)</span>
</span><span id="L-898"><a href="#L-898"><span class="linenos"> 898</span></a>
</span><span id="L-899"><a href="#L-899"><span class="linenos"> 899</span></a>        <span class="c1"># Receive object size</span>
</span><span id="L-900"><a href="#L-900"><span class="linenos"> 900</span></a>        <span class="n">rank_size</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">distributed</span><span class="o">.</span><span class="n">recv</span><span class="p">(</span>
</span><span id="L-901"><a href="#L-901"><span class="linenos"> 901</span></a>            <span class="n">size_tensor</span><span class="p">,</span> <span class="n">src</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">ranks</span><span class="p">[</span><span class="n">src</span><span class="p">],</span> <span class="n">group</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device_group</span>
</span><span id="L-902"><a href="#L-902"><span class="linenos"> 902</span></a>        <span class="p">)</span>
</span><span id="L-903"><a href="#L-903"><span class="linenos"> 903</span></a>
</span><span id="L-904"><a href="#L-904"><span class="linenos"> 904</span></a>        <span class="c1"># Tensor to receive serialized objects into.</span>
</span><span id="L-905"><a href="#L-905"><span class="linenos"> 905</span></a>        <span class="n">object_tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span>  <span class="c1"># type: ignore[call-overload]</span>
</span><span id="L-906"><a href="#L-906"><span class="linenos"> 906</span></a>            <span class="n">size_tensor</span><span class="o">.</span><span class="n">item</span><span class="p">(),</span>  <span class="c1"># type: ignore[arg-type]</span>
</span><span id="L-907"><a href="#L-907"><span class="linenos"> 907</span></a>            <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">uint8</span><span class="p">,</span>
</span><span id="L-908"><a href="#L-908"><span class="linenos"> 908</span></a>            <span class="n">device</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">current_device</span><span class="p">(),</span>
</span><span id="L-909"><a href="#L-909"><span class="linenos"> 909</span></a>        <span class="p">)</span>
</span><span id="L-910"><a href="#L-910"><span class="linenos"> 910</span></a>
</span><span id="L-911"><a href="#L-911"><span class="linenos"> 911</span></a>        <span class="n">rank_object</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">distributed</span><span class="o">.</span><span class="n">recv</span><span class="p">(</span>
</span><span id="L-912"><a href="#L-912"><span class="linenos"> 912</span></a>            <span class="n">object_tensor</span><span class="p">,</span> <span class="n">src</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">ranks</span><span class="p">[</span><span class="n">src</span><span class="p">],</span> <span class="n">group</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device_group</span>
</span><span id="L-913"><a href="#L-913"><span class="linenos"> 913</span></a>        <span class="p">)</span>
</span><span id="L-914"><a href="#L-914"><span class="linenos"> 914</span></a>
</span><span id="L-915"><a href="#L-915"><span class="linenos"> 915</span></a>        <span class="k">assert</span> <span class="p">(</span>
</span><span id="L-916"><a href="#L-916"><span class="linenos"> 916</span></a>            <span class="n">rank_object</span> <span class="o">==</span> <span class="n">rank_size</span>
</span><span id="L-917"><a href="#L-917"><span class="linenos"> 917</span></a>        <span class="p">),</span> <span class="s2">&quot;Received object sender rank does not match the size sender rank.&quot;</span>
</span><span id="L-918"><a href="#L-918"><span class="linenos"> 918</span></a>
</span><span id="L-919"><a href="#L-919"><span class="linenos"> 919</span></a>        <span class="n">obj</span> <span class="o">=</span> <span class="n">pickle</span><span class="o">.</span><span class="n">loads</span><span class="p">(</span><span class="n">object_tensor</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span><span class="o">.</span><span class="n">tobytes</span><span class="p">())</span>
</span><span id="L-920"><a href="#L-920"><span class="linenos"> 920</span></a>
</span><span id="L-921"><a href="#L-921"><span class="linenos"> 921</span></a>        <span class="k">return</span> <span class="n">obj</span>
</span><span id="L-922"><a href="#L-922"><span class="linenos"> 922</span></a>
</span><span id="L-923"><a href="#L-923"><span class="linenos"> 923</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">broadcast_tensor_dict</span><span class="p">(</span>
</span><span id="L-924"><a href="#L-924"><span class="linenos"> 924</span></a>        <span class="bp">self</span><span class="p">,</span>
</span><span id="L-925"><a href="#L-925"><span class="linenos"> 925</span></a>        <span class="n">tensor_dict</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Union</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">Any</span><span class="p">]]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="L-926"><a href="#L-926"><span class="linenos"> 926</span></a>        <span class="n">src</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span>
</span><span id="L-927"><a href="#L-927"><span class="linenos"> 927</span></a>        <span class="n">group</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">ProcessGroup</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="L-928"><a href="#L-928"><span class="linenos"> 928</span></a>        <span class="n">metadata_group</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">ProcessGroup</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="L-929"><a href="#L-929"><span class="linenos"> 929</span></a>    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Union</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">Any</span><span class="p">]]]:</span>
</span><span id="L-930"><a href="#L-930"><span class="linenos"> 930</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;Broadcast the input tensor dictionary.</span>
</span><span id="L-931"><a href="#L-931"><span class="linenos"> 931</span></a><span class="sd">        NOTE: `src` is the local rank of the source rank.</span>
</span><span id="L-932"><a href="#L-932"><span class="linenos"> 932</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="L-933"><a href="#L-933"><span class="linenos"> 933</span></a>        <span class="c1"># Bypass the function if we are using only 1 GPU.</span>
</span><span id="L-934"><a href="#L-934"><span class="linenos"> 934</span></a>        <span class="k">if</span> <span class="ow">not</span> <span class="n">torch</span><span class="o">.</span><span class="n">distributed</span><span class="o">.</span><span class="n">is_initialized</span><span class="p">()</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">world_size</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
</span><span id="L-935"><a href="#L-935"><span class="linenos"> 935</span></a>            <span class="k">return</span> <span class="n">tensor_dict</span>
</span><span id="L-936"><a href="#L-936"><span class="linenos"> 936</span></a>
</span><span id="L-937"><a href="#L-937"><span class="linenos"> 937</span></a>        <span class="n">group</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">device_group</span>
</span><span id="L-938"><a href="#L-938"><span class="linenos"> 938</span></a>        <span class="n">metadata_group</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">cpu_group</span>
</span><span id="L-939"><a href="#L-939"><span class="linenos"> 939</span></a>        <span class="k">assert</span> <span class="n">src</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">world_size</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;Invalid src rank (</span><span class="si">{</span><span class="n">src</span><span class="si">}</span><span class="s2">)&quot;</span>
</span><span id="L-940"><a href="#L-940"><span class="linenos"> 940</span></a>
</span><span id="L-941"><a href="#L-941"><span class="linenos"> 941</span></a>        <span class="n">rank_in_group</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">rank_in_group</span>
</span><span id="L-942"><a href="#L-942"><span class="linenos"> 942</span></a>        <span class="k">if</span> <span class="n">rank_in_group</span> <span class="o">==</span> <span class="n">src</span><span class="p">:</span>
</span><span id="L-943"><a href="#L-943"><span class="linenos"> 943</span></a>            <span class="n">metadata_list</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">Tuple</span><span class="p">[</span><span class="n">Any</span><span class="p">,</span> <span class="n">Any</span><span class="p">]]</span> <span class="o">=</span> <span class="p">[]</span>
</span><span id="L-944"><a href="#L-944"><span class="linenos"> 944</span></a>            <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span>
</span><span id="L-945"><a href="#L-945"><span class="linenos"> 945</span></a>                <span class="n">tensor_dict</span><span class="p">,</span> <span class="nb">dict</span>
</span><span id="L-946"><a href="#L-946"><span class="linenos"> 946</span></a>            <span class="p">),</span> <span class="sa">f</span><span class="s2">&quot;Expecting a dictionary, got </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">tensor_dict</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span>
</span><span id="L-947"><a href="#L-947"><span class="linenos"> 947</span></a>            <span class="n">metadata_list</span><span class="p">,</span> <span class="n">tensor_list</span> <span class="o">=</span> <span class="n">_split_tensor_dict</span><span class="p">(</span><span class="n">tensor_dict</span><span class="p">)</span>
</span><span id="L-948"><a href="#L-948"><span class="linenos"> 948</span></a>            <span class="c1"># `metadata_list` lives in CPU memory.</span>
</span><span id="L-949"><a href="#L-949"><span class="linenos"> 949</span></a>            <span class="c1"># `broadcast_object_list` has serialization &amp; deserialization,</span>
</span><span id="L-950"><a href="#L-950"><span class="linenos"> 950</span></a>            <span class="c1"># all happening on CPU. Therefore, we can use the CPU group.</span>
</span><span id="L-951"><a href="#L-951"><span class="linenos"> 951</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">broadcast_object</span><span class="p">(</span><span class="n">metadata_list</span><span class="p">,</span> <span class="n">src</span><span class="o">=</span><span class="n">src</span><span class="p">)</span>
</span><span id="L-952"><a href="#L-952"><span class="linenos"> 952</span></a>            <span class="n">async_handles</span> <span class="o">=</span> <span class="p">[]</span>
</span><span id="L-953"><a href="#L-953"><span class="linenos"> 953</span></a>            <span class="k">for</span> <span class="n">tensor</span> <span class="ow">in</span> <span class="n">tensor_list</span><span class="p">:</span>
</span><span id="L-954"><a href="#L-954"><span class="linenos"> 954</span></a>                <span class="k">if</span> <span class="n">tensor</span><span class="o">.</span><span class="n">numel</span><span class="p">()</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
</span><span id="L-955"><a href="#L-955"><span class="linenos"> 955</span></a>                    <span class="c1"># Skip broadcasting empty tensors.</span>
</span><span id="L-956"><a href="#L-956"><span class="linenos"> 956</span></a>                    <span class="k">continue</span>
</span><span id="L-957"><a href="#L-957"><span class="linenos"> 957</span></a>                <span class="k">if</span> <span class="n">tensor</span><span class="o">.</span><span class="n">is_cpu</span><span class="p">:</span>
</span><span id="L-958"><a href="#L-958"><span class="linenos"> 958</span></a>                    <span class="c1"># use metadata_group for CPU tensors</span>
</span><span id="L-959"><a href="#L-959"><span class="linenos"> 959</span></a>                    <span class="n">handle</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">distributed</span><span class="o">.</span><span class="n">broadcast</span><span class="p">(</span>
</span><span id="L-960"><a href="#L-960"><span class="linenos"> 960</span></a>                        <span class="n">tensor</span><span class="p">,</span> <span class="n">src</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">ranks</span><span class="p">[</span><span class="n">src</span><span class="p">],</span> <span class="n">group</span><span class="o">=</span><span class="n">metadata_group</span><span class="p">,</span> <span class="n">async_op</span><span class="o">=</span><span class="kc">True</span>
</span><span id="L-961"><a href="#L-961"><span class="linenos"> 961</span></a>                    <span class="p">)</span>
</span><span id="L-962"><a href="#L-962"><span class="linenos"> 962</span></a>                <span class="k">else</span><span class="p">:</span>
</span><span id="L-963"><a href="#L-963"><span class="linenos"> 963</span></a>                    <span class="c1"># use group for GPU tensors</span>
</span><span id="L-964"><a href="#L-964"><span class="linenos"> 964</span></a>                    <span class="n">handle</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">distributed</span><span class="o">.</span><span class="n">broadcast</span><span class="p">(</span>
</span><span id="L-965"><a href="#L-965"><span class="linenos"> 965</span></a>                        <span class="n">tensor</span><span class="p">,</span> <span class="n">src</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">ranks</span><span class="p">[</span><span class="n">src</span><span class="p">],</span> <span class="n">group</span><span class="o">=</span><span class="n">group</span><span class="p">,</span> <span class="n">async_op</span><span class="o">=</span><span class="kc">True</span>
</span><span id="L-966"><a href="#L-966"><span class="linenos"> 966</span></a>                    <span class="p">)</span>
</span><span id="L-967"><a href="#L-967"><span class="linenos"> 967</span></a>                <span class="n">async_handles</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">handle</span><span class="p">)</span>
</span><span id="L-968"><a href="#L-968"><span class="linenos"> 968</span></a>            <span class="k">for</span> <span class="n">async_handle</span> <span class="ow">in</span> <span class="n">async_handles</span><span class="p">:</span>
</span><span id="L-969"><a href="#L-969"><span class="linenos"> 969</span></a>                <span class="n">async_handle</span><span class="o">.</span><span class="n">wait</span><span class="p">()</span>
</span><span id="L-970"><a href="#L-970"><span class="linenos"> 970</span></a>
</span><span id="L-971"><a href="#L-971"><span class="linenos"> 971</span></a>        <span class="k">else</span><span class="p">:</span>
</span><span id="L-972"><a href="#L-972"><span class="linenos"> 972</span></a>            <span class="n">metadata_list</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">broadcast_object</span><span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="n">src</span><span class="o">=</span><span class="n">src</span><span class="p">)</span>
</span><span id="L-973"><a href="#L-973"><span class="linenos"> 973</span></a>            <span class="n">tensor_dict</span> <span class="o">=</span> <span class="p">{}</span>
</span><span id="L-974"><a href="#L-974"><span class="linenos"> 974</span></a>            <span class="n">async_handles</span> <span class="o">=</span> <span class="p">[]</span>
</span><span id="L-975"><a href="#L-975"><span class="linenos"> 975</span></a>            <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">metadata_list</span><span class="p">:</span>
</span><span id="L-976"><a href="#L-976"><span class="linenos"> 976</span></a>                <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">value</span><span class="p">,</span> <span class="n">TensorMetadata</span><span class="p">):</span>
</span><span id="L-977"><a href="#L-977"><span class="linenos"> 977</span></a>                    <span class="n">tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span>
</span><span id="L-978"><a href="#L-978"><span class="linenos"> 978</span></a>                        <span class="n">value</span><span class="o">.</span><span class="n">size</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">value</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">value</span><span class="o">.</span><span class="n">device</span>
</span><span id="L-979"><a href="#L-979"><span class="linenos"> 979</span></a>                    <span class="p">)</span>
</span><span id="L-980"><a href="#L-980"><span class="linenos"> 980</span></a>                    <span class="k">if</span> <span class="n">tensor</span><span class="o">.</span><span class="n">numel</span><span class="p">()</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
</span><span id="L-981"><a href="#L-981"><span class="linenos"> 981</span></a>                        <span class="c1"># Skip broadcasting empty tensors.</span>
</span><span id="L-982"><a href="#L-982"><span class="linenos"> 982</span></a>                        <span class="n">tensor_dict</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">=</span> <span class="n">tensor</span>
</span><span id="L-983"><a href="#L-983"><span class="linenos"> 983</span></a>                        <span class="k">continue</span>
</span><span id="L-984"><a href="#L-984"><span class="linenos"> 984</span></a>                    <span class="k">if</span> <span class="n">tensor</span><span class="o">.</span><span class="n">is_cpu</span><span class="p">:</span>
</span><span id="L-985"><a href="#L-985"><span class="linenos"> 985</span></a>                        <span class="c1"># use metadata_group for CPU tensors</span>
</span><span id="L-986"><a href="#L-986"><span class="linenos"> 986</span></a>                        <span class="n">handle</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">distributed</span><span class="o">.</span><span class="n">broadcast</span><span class="p">(</span>
</span><span id="L-987"><a href="#L-987"><span class="linenos"> 987</span></a>                            <span class="n">tensor</span><span class="p">,</span>
</span><span id="L-988"><a href="#L-988"><span class="linenos"> 988</span></a>                            <span class="n">src</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">ranks</span><span class="p">[</span><span class="n">src</span><span class="p">],</span>
</span><span id="L-989"><a href="#L-989"><span class="linenos"> 989</span></a>                            <span class="n">group</span><span class="o">=</span><span class="n">metadata_group</span><span class="p">,</span>
</span><span id="L-990"><a href="#L-990"><span class="linenos"> 990</span></a>                            <span class="n">async_op</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
</span><span id="L-991"><a href="#L-991"><span class="linenos"> 991</span></a>                        <span class="p">)</span>
</span><span id="L-992"><a href="#L-992"><span class="linenos"> 992</span></a>                    <span class="k">else</span><span class="p">:</span>
</span><span id="L-993"><a href="#L-993"><span class="linenos"> 993</span></a>                        <span class="c1"># use group for GPU tensors</span>
</span><span id="L-994"><a href="#L-994"><span class="linenos"> 994</span></a>                        <span class="n">handle</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">distributed</span><span class="o">.</span><span class="n">broadcast</span><span class="p">(</span>
</span><span id="L-995"><a href="#L-995"><span class="linenos"> 995</span></a>                            <span class="n">tensor</span><span class="p">,</span> <span class="n">src</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">ranks</span><span class="p">[</span><span class="n">src</span><span class="p">],</span> <span class="n">group</span><span class="o">=</span><span class="n">group</span><span class="p">,</span> <span class="n">async_op</span><span class="o">=</span><span class="kc">True</span>
</span><span id="L-996"><a href="#L-996"><span class="linenos"> 996</span></a>                        <span class="p">)</span>
</span><span id="L-997"><a href="#L-997"><span class="linenos"> 997</span></a>                    <span class="n">async_handles</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">handle</span><span class="p">)</span>
</span><span id="L-998"><a href="#L-998"><span class="linenos"> 998</span></a>                    <span class="n">tensor_dict</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">=</span> <span class="n">tensor</span>
</span><span id="L-999"><a href="#L-999"><span class="linenos"> 999</span></a>                <span class="k">else</span><span class="p">:</span>
</span><span id="L-1000"><a href="#L-1000"><span class="linenos">1000</span></a>                    <span class="n">tensor_dict</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">=</span> <span class="n">value</span>
</span><span id="L-1001"><a href="#L-1001"><span class="linenos">1001</span></a>            <span class="k">for</span> <span class="n">async_handle</span> <span class="ow">in</span> <span class="n">async_handles</span><span class="p">:</span>
</span><span id="L-1002"><a href="#L-1002"><span class="linenos">1002</span></a>                <span class="n">async_handle</span><span class="o">.</span><span class="n">wait</span><span class="p">()</span>
</span><span id="L-1003"><a href="#L-1003"><span class="linenos">1003</span></a>        <span class="k">return</span> <span class="n">tensor_dict</span>
</span><span id="L-1004"><a href="#L-1004"><span class="linenos">1004</span></a>
</span><span id="L-1005"><a href="#L-1005"><span class="linenos">1005</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">send_tensor_dict</span><span class="p">(</span>
</span><span id="L-1006"><a href="#L-1006"><span class="linenos">1006</span></a>        <span class="bp">self</span><span class="p">,</span>
</span><span id="L-1007"><a href="#L-1007"><span class="linenos">1007</span></a>        <span class="n">tensor_dict</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Union</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">Any</span><span class="p">]],</span>
</span><span id="L-1008"><a href="#L-1008"><span class="linenos">1008</span></a>        <span class="n">dst</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="L-1009"><a href="#L-1009"><span class="linenos">1009</span></a>        <span class="n">all_gather_group</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="s2">&quot;GroupCoordinator&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="L-1010"><a href="#L-1010"><span class="linenos">1010</span></a>    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Union</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">Any</span><span class="p">]]]:</span>
</span><span id="L-1011"><a href="#L-1011"><span class="linenos">1011</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;Send the input tensor dictionary.</span>
</span><span id="L-1012"><a href="#L-1012"><span class="linenos">1012</span></a><span class="sd">        NOTE: `dst` is the local rank of the source rank.</span>
</span><span id="L-1013"><a href="#L-1013"><span class="linenos">1013</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="L-1014"><a href="#L-1014"><span class="linenos">1014</span></a>        <span class="c1"># Bypass the function if we are using only 1 GPU.</span>
</span><span id="L-1015"><a href="#L-1015"><span class="linenos">1015</span></a>        <span class="k">if</span> <span class="ow">not</span> <span class="n">torch</span><span class="o">.</span><span class="n">distributed</span><span class="o">.</span><span class="n">is_initialized</span><span class="p">()</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">world_size</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
</span><span id="L-1016"><a href="#L-1016"><span class="linenos">1016</span></a>            <span class="k">return</span> <span class="n">tensor_dict</span>
</span><span id="L-1017"><a href="#L-1017"><span class="linenos">1017</span></a>
</span><span id="L-1018"><a href="#L-1018"><span class="linenos">1018</span></a>        <span class="n">all_gather_size</span> <span class="o">=</span> <span class="mi">1</span> <span class="k">if</span> <span class="n">all_gather_group</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">all_gather_group</span><span class="o">.</span><span class="n">world_size</span>
</span><span id="L-1019"><a href="#L-1019"><span class="linenos">1019</span></a>        <span class="n">all_gather_rank</span> <span class="o">=</span> <span class="p">(</span>
</span><span id="L-1020"><a href="#L-1020"><span class="linenos">1020</span></a>            <span class="mi">0</span> <span class="k">if</span> <span class="n">all_gather_group</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">all_gather_group</span><span class="o">.</span><span class="n">rank_in_group</span>
</span><span id="L-1021"><a href="#L-1021"><span class="linenos">1021</span></a>        <span class="p">)</span>
</span><span id="L-1022"><a href="#L-1022"><span class="linenos">1022</span></a>
</span><span id="L-1023"><a href="#L-1023"><span class="linenos">1023</span></a>        <span class="n">group</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">device_group</span>
</span><span id="L-1024"><a href="#L-1024"><span class="linenos">1024</span></a>        <span class="n">metadata_group</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">cpu_group</span>
</span><span id="L-1025"><a href="#L-1025"><span class="linenos">1025</span></a>
</span><span id="L-1026"><a href="#L-1026"><span class="linenos">1026</span></a>        <span class="k">if</span> <span class="n">dst</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="L-1027"><a href="#L-1027"><span class="linenos">1027</span></a>            <span class="n">dst</span> <span class="o">=</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">rank_in_group</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">%</span> <span class="bp">self</span><span class="o">.</span><span class="n">world_size</span>
</span><span id="L-1028"><a href="#L-1028"><span class="linenos">1028</span></a>        <span class="k">assert</span> <span class="n">dst</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">world_size</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;Invalid dst rank (</span><span class="si">{</span><span class="n">dst</span><span class="si">}</span><span class="s2">)&quot;</span>
</span><span id="L-1029"><a href="#L-1029"><span class="linenos">1029</span></a>
</span><span id="L-1030"><a href="#L-1030"><span class="linenos">1030</span></a>        <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span>
</span><span id="L-1031"><a href="#L-1031"><span class="linenos">1031</span></a>            <span class="n">tensor_dict</span><span class="p">,</span> <span class="nb">dict</span>
</span><span id="L-1032"><a href="#L-1032"><span class="linenos">1032</span></a>        <span class="p">),</span> <span class="sa">f</span><span class="s2">&quot;Expecting a dictionary, got </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">tensor_dict</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span>
</span><span id="L-1033"><a href="#L-1033"><span class="linenos">1033</span></a>        <span class="n">metadata_list</span><span class="p">,</span> <span class="n">tensor_list</span> <span class="o">=</span> <span class="n">_split_tensor_dict</span><span class="p">(</span><span class="n">tensor_dict</span><span class="p">)</span>
</span><span id="L-1034"><a href="#L-1034"><span class="linenos">1034</span></a>        <span class="c1"># Note: While switching to Device-to-Device (D2D) would introduce an extra</span>
</span><span id="L-1035"><a href="#L-1035"><span class="linenos">1035</span></a>        <span class="c1"># Device-to-Host (D2H) memory copy overhead for serialization, our benchmarks</span>
</span><span id="L-1036"><a href="#L-1036"><span class="linenos">1036</span></a>        <span class="c1"># show better overall transmission performance with D2D due to:</span>
</span><span id="L-1037"><a href="#L-1037"><span class="linenos">1037</span></a>        <span class="c1"># 1. Superior D2D transfer bandwidth</span>
</span><span id="L-1038"><a href="#L-1038"><span class="linenos">1038</span></a>        <span class="c1"># 2. Ability to overlap send and recv operations</span>
</span><span id="L-1039"><a href="#L-1039"><span class="linenos">1039</span></a>        <span class="c1"># Thus the net performance gain justifies this approach.</span>
</span><span id="L-1040"><a href="#L-1040"><span class="linenos">1040</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">send_object</span><span class="p">(</span><span class="n">metadata_list</span><span class="p">,</span> <span class="n">dst</span><span class="o">=</span><span class="n">dst</span><span class="p">)</span>
</span><span id="L-1041"><a href="#L-1041"><span class="linenos">1041</span></a>        <span class="k">for</span> <span class="n">tensor</span> <span class="ow">in</span> <span class="n">tensor_list</span><span class="p">:</span>
</span><span id="L-1042"><a href="#L-1042"><span class="linenos">1042</span></a>            <span class="k">if</span> <span class="n">tensor</span><span class="o">.</span><span class="n">numel</span><span class="p">()</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
</span><span id="L-1043"><a href="#L-1043"><span class="linenos">1043</span></a>                <span class="c1"># Skip sending empty tensors.</span>
</span><span id="L-1044"><a href="#L-1044"><span class="linenos">1044</span></a>                <span class="k">continue</span>
</span><span id="L-1045"><a href="#L-1045"><span class="linenos">1045</span></a>
</span><span id="L-1046"><a href="#L-1046"><span class="linenos">1046</span></a>            <span class="c1"># send-allgather: send only a slice, then do allgather.</span>
</span><span id="L-1047"><a href="#L-1047"><span class="linenos">1047</span></a>            <span class="k">if</span> <span class="n">all_gather_group</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">tensor</span><span class="o">.</span><span class="n">numel</span><span class="p">()</span> <span class="o">%</span> <span class="n">all_gather_size</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
</span><span id="L-1048"><a href="#L-1048"><span class="linenos">1048</span></a>                <span class="n">tensor</span> <span class="o">=</span> <span class="n">tensor</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">all_gather_size</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)[</span><span class="n">all_gather_rank</span><span class="p">]</span>
</span><span id="L-1049"><a href="#L-1049"><span class="linenos">1049</span></a>
</span><span id="L-1050"><a href="#L-1050"><span class="linenos">1050</span></a>            <span class="k">if</span> <span class="n">tensor</span><span class="o">.</span><span class="n">is_cpu</span><span class="p">:</span>
</span><span id="L-1051"><a href="#L-1051"><span class="linenos">1051</span></a>                <span class="c1"># use metadata_group for CPU tensors</span>
</span><span id="L-1052"><a href="#L-1052"><span class="linenos">1052</span></a>                <span class="n">torch</span><span class="o">.</span><span class="n">distributed</span><span class="o">.</span><span class="n">send</span><span class="p">(</span>
</span><span id="L-1053"><a href="#L-1053"><span class="linenos">1053</span></a>                    <span class="n">tensor</span><span class="p">,</span> <span class="n">dst</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">ranks</span><span class="p">[</span><span class="n">dst</span><span class="p">],</span> <span class="n">group</span><span class="o">=</span><span class="n">metadata_group</span>
</span><span id="L-1054"><a href="#L-1054"><span class="linenos">1054</span></a>                <span class="p">)</span>
</span><span id="L-1055"><a href="#L-1055"><span class="linenos">1055</span></a>            <span class="k">else</span><span class="p">:</span>
</span><span id="L-1056"><a href="#L-1056"><span class="linenos">1056</span></a>                <span class="c1"># use group for GPU tensors</span>
</span><span id="L-1057"><a href="#L-1057"><span class="linenos">1057</span></a>                <span class="n">torch</span><span class="o">.</span><span class="n">distributed</span><span class="o">.</span><span class="n">send</span><span class="p">(</span><span class="n">tensor</span><span class="p">,</span> <span class="n">dst</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">ranks</span><span class="p">[</span><span class="n">dst</span><span class="p">],</span> <span class="n">group</span><span class="o">=</span><span class="n">group</span><span class="p">)</span>
</span><span id="L-1058"><a href="#L-1058"><span class="linenos">1058</span></a>        <span class="k">return</span> <span class="kc">None</span>
</span><span id="L-1059"><a href="#L-1059"><span class="linenos">1059</span></a>
</span><span id="L-1060"><a href="#L-1060"><span class="linenos">1060</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">recv_tensor_dict</span><span class="p">(</span>
</span><span id="L-1061"><a href="#L-1061"><span class="linenos">1061</span></a>        <span class="bp">self</span><span class="p">,</span>
</span><span id="L-1062"><a href="#L-1062"><span class="linenos">1062</span></a>        <span class="n">src</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="L-1063"><a href="#L-1063"><span class="linenos">1063</span></a>        <span class="n">all_gather_group</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="s2">&quot;GroupCoordinator&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="L-1064"><a href="#L-1064"><span class="linenos">1064</span></a>    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Union</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">Any</span><span class="p">]]]:</span>
</span><span id="L-1065"><a href="#L-1065"><span class="linenos">1065</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;Recv the input tensor dictionary.</span>
</span><span id="L-1066"><a href="#L-1066"><span class="linenos">1066</span></a><span class="sd">        NOTE: `src` is the local rank of the source rank.</span>
</span><span id="L-1067"><a href="#L-1067"><span class="linenos">1067</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="L-1068"><a href="#L-1068"><span class="linenos">1068</span></a>        <span class="c1"># Bypass the function if we are using only 1 GPU.</span>
</span><span id="L-1069"><a href="#L-1069"><span class="linenos">1069</span></a>        <span class="k">if</span> <span class="ow">not</span> <span class="n">torch</span><span class="o">.</span><span class="n">distributed</span><span class="o">.</span><span class="n">is_initialized</span><span class="p">()</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">world_size</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
</span><span id="L-1070"><a href="#L-1070"><span class="linenos">1070</span></a>            <span class="k">return</span> <span class="kc">None</span>
</span><span id="L-1071"><a href="#L-1071"><span class="linenos">1071</span></a>
</span><span id="L-1072"><a href="#L-1072"><span class="linenos">1072</span></a>        <span class="n">all_gather_size</span> <span class="o">=</span> <span class="mi">1</span> <span class="k">if</span> <span class="n">all_gather_group</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">all_gather_group</span><span class="o">.</span><span class="n">world_size</span>
</span><span id="L-1073"><a href="#L-1073"><span class="linenos">1073</span></a>        <span class="n">all_gather_rank</span> <span class="o">=</span> <span class="p">(</span>
</span><span id="L-1074"><a href="#L-1074"><span class="linenos">1074</span></a>            <span class="mi">0</span> <span class="k">if</span> <span class="n">all_gather_group</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">all_gather_group</span><span class="o">.</span><span class="n">rank_in_group</span>
</span><span id="L-1075"><a href="#L-1075"><span class="linenos">1075</span></a>        <span class="p">)</span>
</span><span id="L-1076"><a href="#L-1076"><span class="linenos">1076</span></a>
</span><span id="L-1077"><a href="#L-1077"><span class="linenos">1077</span></a>        <span class="n">group</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">device_group</span>
</span><span id="L-1078"><a href="#L-1078"><span class="linenos">1078</span></a>        <span class="n">metadata_group</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">cpu_group</span>
</span><span id="L-1079"><a href="#L-1079"><span class="linenos">1079</span></a>
</span><span id="L-1080"><a href="#L-1080"><span class="linenos">1080</span></a>        <span class="k">if</span> <span class="n">src</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="L-1081"><a href="#L-1081"><span class="linenos">1081</span></a>            <span class="n">src</span> <span class="o">=</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">rank_in_group</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">%</span> <span class="bp">self</span><span class="o">.</span><span class="n">world_size</span>
</span><span id="L-1082"><a href="#L-1082"><span class="linenos">1082</span></a>        <span class="k">assert</span> <span class="n">src</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">world_size</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;Invalid src rank (</span><span class="si">{</span><span class="n">src</span><span class="si">}</span><span class="s2">)&quot;</span>
</span><span id="L-1083"><a href="#L-1083"><span class="linenos">1083</span></a>
</span><span id="L-1084"><a href="#L-1084"><span class="linenos">1084</span></a>        <span class="n">recv_metadata_list</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">recv_object</span><span class="p">(</span><span class="n">src</span><span class="o">=</span><span class="n">src</span><span class="p">)</span>
</span><span id="L-1085"><a href="#L-1085"><span class="linenos">1085</span></a>        <span class="n">tensor_dict</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]</span> <span class="o">=</span> <span class="p">{}</span>
</span><span id="L-1086"><a href="#L-1086"><span class="linenos">1086</span></a>        <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">recv_metadata_list</span><span class="p">:</span>
</span><span id="L-1087"><a href="#L-1087"><span class="linenos">1087</span></a>            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">value</span><span class="p">,</span> <span class="n">TensorMetadata</span><span class="p">):</span>
</span><span id="L-1088"><a href="#L-1088"><span class="linenos">1088</span></a>                <span class="n">tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span><span class="n">value</span><span class="o">.</span><span class="n">size</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">value</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">value</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
</span><span id="L-1089"><a href="#L-1089"><span class="linenos">1089</span></a>                <span class="k">if</span> <span class="n">tensor</span><span class="o">.</span><span class="n">numel</span><span class="p">()</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
</span><span id="L-1090"><a href="#L-1090"><span class="linenos">1090</span></a>                    <span class="c1"># Skip broadcasting empty tensors.</span>
</span><span id="L-1091"><a href="#L-1091"><span class="linenos">1091</span></a>                    <span class="n">tensor_dict</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">=</span> <span class="n">tensor</span>
</span><span id="L-1092"><a href="#L-1092"><span class="linenos">1092</span></a>                    <span class="k">continue</span>
</span><span id="L-1093"><a href="#L-1093"><span class="linenos">1093</span></a>
</span><span id="L-1094"><a href="#L-1094"><span class="linenos">1094</span></a>                <span class="c1"># send-allgather: send only a slice, then do allgather.</span>
</span><span id="L-1095"><a href="#L-1095"><span class="linenos">1095</span></a>                <span class="n">use_all_gather</span> <span class="o">=</span> <span class="p">(</span>
</span><span id="L-1096"><a href="#L-1096"><span class="linenos">1096</span></a>                    <span class="n">all_gather_group</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
</span><span id="L-1097"><a href="#L-1097"><span class="linenos">1097</span></a>                    <span class="ow">and</span> <span class="n">tensor</span><span class="o">.</span><span class="n">numel</span><span class="p">()</span> <span class="o">%</span> <span class="n">all_gather_size</span> <span class="o">==</span> <span class="mi">0</span>
</span><span id="L-1098"><a href="#L-1098"><span class="linenos">1098</span></a>                <span class="p">)</span>
</span><span id="L-1099"><a href="#L-1099"><span class="linenos">1099</span></a>
</span><span id="L-1100"><a href="#L-1100"><span class="linenos">1100</span></a>                <span class="k">if</span> <span class="n">use_all_gather</span><span class="p">:</span>
</span><span id="L-1101"><a href="#L-1101"><span class="linenos">1101</span></a>                    <span class="n">orig_shape</span> <span class="o">=</span> <span class="n">tensor</span><span class="o">.</span><span class="n">shape</span>
</span><span id="L-1102"><a href="#L-1102"><span class="linenos">1102</span></a>                    <span class="n">tensor</span> <span class="o">=</span> <span class="n">tensor</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">all_gather_size</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)[</span><span class="n">all_gather_rank</span><span class="p">]</span>
</span><span id="L-1103"><a href="#L-1103"><span class="linenos">1103</span></a>
</span><span id="L-1104"><a href="#L-1104"><span class="linenos">1104</span></a>                <span class="k">if</span> <span class="n">tensor</span><span class="o">.</span><span class="n">is_cpu</span><span class="p">:</span>
</span><span id="L-1105"><a href="#L-1105"><span class="linenos">1105</span></a>                    <span class="c1"># use metadata_group for CPU tensors</span>
</span><span id="L-1106"><a href="#L-1106"><span class="linenos">1106</span></a>                    <span class="n">torch</span><span class="o">.</span><span class="n">distributed</span><span class="o">.</span><span class="n">recv</span><span class="p">(</span>
</span><span id="L-1107"><a href="#L-1107"><span class="linenos">1107</span></a>                        <span class="n">tensor</span><span class="p">,</span> <span class="n">src</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">ranks</span><span class="p">[</span><span class="n">src</span><span class="p">],</span> <span class="n">group</span><span class="o">=</span><span class="n">metadata_group</span>
</span><span id="L-1108"><a href="#L-1108"><span class="linenos">1108</span></a>                    <span class="p">)</span>
</span><span id="L-1109"><a href="#L-1109"><span class="linenos">1109</span></a>                <span class="k">else</span><span class="p">:</span>
</span><span id="L-1110"><a href="#L-1110"><span class="linenos">1110</span></a>                    <span class="c1"># use group for GPU tensors</span>
</span><span id="L-1111"><a href="#L-1111"><span class="linenos">1111</span></a>                    <span class="n">torch</span><span class="o">.</span><span class="n">distributed</span><span class="o">.</span><span class="n">recv</span><span class="p">(</span><span class="n">tensor</span><span class="p">,</span> <span class="n">src</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">ranks</span><span class="p">[</span><span class="n">src</span><span class="p">],</span> <span class="n">group</span><span class="o">=</span><span class="n">group</span><span class="p">)</span>
</span><span id="L-1112"><a href="#L-1112"><span class="linenos">1112</span></a>                <span class="k">if</span> <span class="n">use_all_gather</span><span class="p">:</span>
</span><span id="L-1113"><a href="#L-1113"><span class="linenos">1113</span></a>                    <span class="c1"># do the allgather</span>
</span><span id="L-1114"><a href="#L-1114"><span class="linenos">1114</span></a>                    <span class="n">tensor</span> <span class="o">=</span> <span class="n">all_gather_group</span><span class="o">.</span><span class="n">all_gather</span><span class="p">(</span><span class="n">tensor</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>  <span class="c1"># type: ignore</span>
</span><span id="L-1115"><a href="#L-1115"><span class="linenos">1115</span></a>                    <span class="n">tensor</span> <span class="o">=</span> <span class="n">tensor</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">orig_shape</span><span class="p">)</span>
</span><span id="L-1116"><a href="#L-1116"><span class="linenos">1116</span></a>
</span><span id="L-1117"><a href="#L-1117"><span class="linenos">1117</span></a>                <span class="n">tensor_dict</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">=</span> <span class="n">tensor</span>
</span><span id="L-1118"><a href="#L-1118"><span class="linenos">1118</span></a>            <span class="k">else</span><span class="p">:</span>
</span><span id="L-1119"><a href="#L-1119"><span class="linenos">1119</span></a>                <span class="n">tensor_dict</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">=</span> <span class="n">value</span>
</span><span id="L-1120"><a href="#L-1120"><span class="linenos">1120</span></a>        <span class="k">return</span> <span class="n">tensor_dict</span>
</span><span id="L-1121"><a href="#L-1121"><span class="linenos">1121</span></a>
</span><span id="L-1122"><a href="#L-1122"><span class="linenos">1122</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">barrier</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
</span><span id="L-1123"><a href="#L-1123"><span class="linenos">1123</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;Barrier synchronization among the group.</span>
</span><span id="L-1124"><a href="#L-1124"><span class="linenos">1124</span></a><span class="sd">        NOTE: don&#39;t use `device_group` here! `barrier` in NCCL is</span>
</span><span id="L-1125"><a href="#L-1125"><span class="linenos">1125</span></a><span class="sd">        terrible because it is internally a broadcast operation with</span>
</span><span id="L-1126"><a href="#L-1126"><span class="linenos">1126</span></a><span class="sd">        secretly created GPU tensors. It is easy to mess up the current</span>
</span><span id="L-1127"><a href="#L-1127"><span class="linenos">1127</span></a><span class="sd">        device. Use the CPU group instead.</span>
</span><span id="L-1128"><a href="#L-1128"><span class="linenos">1128</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="L-1129"><a href="#L-1129"><span class="linenos">1129</span></a>        <span class="n">torch</span><span class="o">.</span><span class="n">distributed</span><span class="o">.</span><span class="n">barrier</span><span class="p">(</span><span class="n">group</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">cpu_group</span><span class="p">)</span>
</span><span id="L-1130"><a href="#L-1130"><span class="linenos">1130</span></a>
</span><span id="L-1131"><a href="#L-1131"><span class="linenos">1131</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">send</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">tensor</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">dst</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="L-1132"><a href="#L-1132"><span class="linenos">1132</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;Sends a tensor to the destination rank in a non-blocking way&quot;&quot;&quot;</span>
</span><span id="L-1133"><a href="#L-1133"><span class="linenos">1133</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;NOTE: `dst` is the local rank of the destination rank.&quot;&quot;&quot;</span>
</span><span id="L-1134"><a href="#L-1134"><span class="linenos">1134</span></a>        <span class="k">if</span> <span class="n">dst</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="L-1135"><a href="#L-1135"><span class="linenos">1135</span></a>            <span class="n">dst</span> <span class="o">=</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">rank_in_group</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">%</span> <span class="bp">self</span><span class="o">.</span><span class="n">world_size</span>
</span><span id="L-1136"><a href="#L-1136"><span class="linenos">1136</span></a>
</span><span id="L-1137"><a href="#L-1137"><span class="linenos">1137</span></a>        <span class="n">pynccl_comm</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">pynccl_comm</span>
</span><span id="L-1138"><a href="#L-1138"><span class="linenos">1138</span></a>        <span class="k">if</span> <span class="n">pynccl_comm</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">pynccl_comm</span><span class="o">.</span><span class="n">disabled</span><span class="p">:</span>
</span><span id="L-1139"><a href="#L-1139"><span class="linenos">1139</span></a>            <span class="n">pynccl_comm</span><span class="o">.</span><span class="n">send</span><span class="p">(</span><span class="n">tensor</span><span class="p">,</span> <span class="n">dst</span><span class="p">)</span>
</span><span id="L-1140"><a href="#L-1140"><span class="linenos">1140</span></a>        <span class="k">else</span><span class="p">:</span>
</span><span id="L-1141"><a href="#L-1141"><span class="linenos">1141</span></a>            <span class="n">torch</span><span class="o">.</span><span class="n">distributed</span><span class="o">.</span><span class="n">send</span><span class="p">(</span><span class="n">tensor</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">ranks</span><span class="p">[</span><span class="n">dst</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">device_group</span><span class="p">)</span>
</span><span id="L-1142"><a href="#L-1142"><span class="linenos">1142</span></a>
</span><span id="L-1143"><a href="#L-1143"><span class="linenos">1143</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">recv</span><span class="p">(</span>
</span><span id="L-1144"><a href="#L-1144"><span class="linenos">1144</span></a>        <span class="bp">self</span><span class="p">,</span> <span class="n">size</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">,</span> <span class="n">dtype</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="n">src</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
</span><span id="L-1145"><a href="#L-1145"><span class="linenos">1145</span></a>    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
</span><span id="L-1146"><a href="#L-1146"><span class="linenos">1146</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;Receives a tensor from the source rank.&quot;&quot;&quot;</span>
</span><span id="L-1147"><a href="#L-1147"><span class="linenos">1147</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;NOTE: `src` is the local rank of the source rank.&quot;&quot;&quot;</span>
</span><span id="L-1148"><a href="#L-1148"><span class="linenos">1148</span></a>        <span class="k">if</span> <span class="n">src</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="L-1149"><a href="#L-1149"><span class="linenos">1149</span></a>            <span class="n">src</span> <span class="o">=</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">rank_in_group</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">%</span> <span class="bp">self</span><span class="o">.</span><span class="n">world_size</span>
</span><span id="L-1150"><a href="#L-1150"><span class="linenos">1150</span></a>
</span><span id="L-1151"><a href="#L-1151"><span class="linenos">1151</span></a>        <span class="n">tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span><span class="n">size</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
</span><span id="L-1152"><a href="#L-1152"><span class="linenos">1152</span></a>        <span class="n">pynccl_comm</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">pynccl_comm</span>
</span><span id="L-1153"><a href="#L-1153"><span class="linenos">1153</span></a>        <span class="k">if</span> <span class="n">pynccl_comm</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">pynccl_comm</span><span class="o">.</span><span class="n">disabled</span><span class="p">:</span>
</span><span id="L-1154"><a href="#L-1154"><span class="linenos">1154</span></a>            <span class="n">pynccl_comm</span><span class="o">.</span><span class="n">recv</span><span class="p">(</span><span class="n">tensor</span><span class="p">,</span> <span class="n">src</span><span class="p">)</span>
</span><span id="L-1155"><a href="#L-1155"><span class="linenos">1155</span></a>        <span class="k">else</span><span class="p">:</span>
</span><span id="L-1156"><a href="#L-1156"><span class="linenos">1156</span></a>            <span class="n">torch</span><span class="o">.</span><span class="n">distributed</span><span class="o">.</span><span class="n">recv</span><span class="p">(</span><span class="n">tensor</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">ranks</span><span class="p">[</span><span class="n">src</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">device_group</span><span class="p">)</span>
</span><span id="L-1157"><a href="#L-1157"><span class="linenos">1157</span></a>        <span class="k">return</span> <span class="n">tensor</span>
</span><span id="L-1158"><a href="#L-1158"><span class="linenos">1158</span></a>
</span><span id="L-1159"><a href="#L-1159"><span class="linenos">1159</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">destroy</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
</span><span id="L-1160"><a href="#L-1160"><span class="linenos">1160</span></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">device_group</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="L-1161"><a href="#L-1161"><span class="linenos">1161</span></a>            <span class="n">torch</span><span class="o">.</span><span class="n">distributed</span><span class="o">.</span><span class="n">destroy_process_group</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device_group</span><span class="p">)</span>
</span><span id="L-1162"><a href="#L-1162"><span class="linenos">1162</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">device_group</span> <span class="o">=</span> <span class="kc">None</span>
</span><span id="L-1163"><a href="#L-1163"><span class="linenos">1163</span></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">cpu_group</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="L-1164"><a href="#L-1164"><span class="linenos">1164</span></a>            <span class="n">torch</span><span class="o">.</span><span class="n">distributed</span><span class="o">.</span><span class="n">destroy_process_group</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">cpu_group</span><span class="p">)</span>
</span><span id="L-1165"><a href="#L-1165"><span class="linenos">1165</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">cpu_group</span> <span class="o">=</span> <span class="kc">None</span>
</span><span id="L-1166"><a href="#L-1166"><span class="linenos">1166</span></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">pynccl_comm</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="L-1167"><a href="#L-1167"><span class="linenos">1167</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">pynccl_comm</span> <span class="o">=</span> <span class="kc">None</span>
</span><span id="L-1168"><a href="#L-1168"><span class="linenos">1168</span></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">ca_comm</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="L-1169"><a href="#L-1169"><span class="linenos">1169</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">ca_comm</span> <span class="o">=</span> <span class="kc">None</span>
</span><span id="L-1170"><a href="#L-1170"><span class="linenos">1170</span></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">mq_broadcaster</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="L-1171"><a href="#L-1171"><span class="linenos">1171</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">mq_broadcaster</span> <span class="o">=</span> <span class="kc">None</span>
</span><span id="L-1172"><a href="#L-1172"><span class="linenos">1172</span></a>
</span><span id="L-1173"><a href="#L-1173"><span class="linenos">1173</span></a>
</span><span id="L-1174"><a href="#L-1174"><span class="linenos">1174</span></a><span class="n">_WORLD</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">GroupCoordinator</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
</span><span id="L-1175"><a href="#L-1175"><span class="linenos">1175</span></a>
</span><span id="L-1176"><a href="#L-1176"><span class="linenos">1176</span></a>
</span><span id="L-1177"><a href="#L-1177"><span class="linenos">1177</span></a><span class="k">def</span><span class="w"> </span><span class="nf">get_world_group</span><span class="p">()</span> <span class="o">-&gt;</span> <span class="n">GroupCoordinator</span><span class="p">:</span>
</span><span id="L-1178"><a href="#L-1178"><span class="linenos">1178</span></a>    <span class="k">assert</span> <span class="n">_WORLD</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">,</span> <span class="s2">&quot;world group is not initialized&quot;</span>
</span><span id="L-1179"><a href="#L-1179"><span class="linenos">1179</span></a>    <span class="k">return</span> <span class="n">_WORLD</span>
</span><span id="L-1180"><a href="#L-1180"><span class="linenos">1180</span></a>
</span><span id="L-1181"><a href="#L-1181"><span class="linenos">1181</span></a>
</span><span id="L-1182"><a href="#L-1182"><span class="linenos">1182</span></a><span class="k">def</span><span class="w"> </span><span class="nf">init_world_group</span><span class="p">(</span>
</span><span id="L-1183"><a href="#L-1183"><span class="linenos">1183</span></a>    <span class="n">ranks</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">int</span><span class="p">],</span> <span class="n">local_rank</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">backend</span><span class="p">:</span> <span class="nb">str</span>
</span><span id="L-1184"><a href="#L-1184"><span class="linenos">1184</span></a><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">GroupCoordinator</span><span class="p">:</span>
</span><span id="L-1185"><a href="#L-1185"><span class="linenos">1185</span></a>    <span class="k">return</span> <span class="n">GroupCoordinator</span><span class="p">(</span>
</span><span id="L-1186"><a href="#L-1186"><span class="linenos">1186</span></a>        <span class="n">group_ranks</span><span class="o">=</span><span class="p">[</span><span class="n">ranks</span><span class="p">],</span>
</span><span id="L-1187"><a href="#L-1187"><span class="linenos">1187</span></a>        <span class="n">local_rank</span><span class="o">=</span><span class="n">local_rank</span><span class="p">,</span>
</span><span id="L-1188"><a href="#L-1188"><span class="linenos">1188</span></a>        <span class="n">torch_distributed_backend</span><span class="o">=</span><span class="n">backend</span><span class="p">,</span>
</span><span id="L-1189"><a href="#L-1189"><span class="linenos">1189</span></a>        <span class="n">use_pynccl</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
</span><span id="L-1190"><a href="#L-1190"><span class="linenos">1190</span></a>        <span class="n">use_pymscclpp</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
</span><span id="L-1191"><a href="#L-1191"><span class="linenos">1191</span></a>        <span class="n">use_custom_allreduce</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
</span><span id="L-1192"><a href="#L-1192"><span class="linenos">1192</span></a>        <span class="n">use_hpu_communicator</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
</span><span id="L-1193"><a href="#L-1193"><span class="linenos">1193</span></a>        <span class="n">use_xpu_communicator</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
</span><span id="L-1194"><a href="#L-1194"><span class="linenos">1194</span></a>        <span class="n">use_npu_communicator</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
</span><span id="L-1195"><a href="#L-1195"><span class="linenos">1195</span></a>        <span class="n">group_name</span><span class="o">=</span><span class="s2">&quot;world&quot;</span><span class="p">,</span>
</span><span id="L-1196"><a href="#L-1196"><span class="linenos">1196</span></a>    <span class="p">)</span>
</span><span id="L-1197"><a href="#L-1197"><span class="linenos">1197</span></a>
</span><span id="L-1198"><a href="#L-1198"><span class="linenos">1198</span></a>
</span><span id="L-1199"><a href="#L-1199"><span class="linenos">1199</span></a><span class="k">def</span><span class="w"> </span><span class="nf">init_model_parallel_group</span><span class="p">(</span>
</span><span id="L-1200"><a href="#L-1200"><span class="linenos">1200</span></a>    <span class="n">group_ranks</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="nb">int</span><span class="p">]],</span>
</span><span id="L-1201"><a href="#L-1201"><span class="linenos">1201</span></a>    <span class="n">local_rank</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
</span><span id="L-1202"><a href="#L-1202"><span class="linenos">1202</span></a>    <span class="n">backend</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
</span><span id="L-1203"><a href="#L-1203"><span class="linenos">1203</span></a>    <span class="n">use_custom_allreduce</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">bool</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="L-1204"><a href="#L-1204"><span class="linenos">1204</span></a>    <span class="n">use_message_queue_broadcaster</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
</span><span id="L-1205"><a href="#L-1205"><span class="linenos">1205</span></a>    <span class="n">group_name</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="L-1206"><a href="#L-1206"><span class="linenos">1206</span></a>    <span class="n">use_mscclpp_allreduce</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">bool</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="L-1207"><a href="#L-1207"><span class="linenos">1207</span></a><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">GroupCoordinator</span><span class="p">:</span>
</span><span id="L-1208"><a href="#L-1208"><span class="linenos">1208</span></a>    <span class="k">if</span> <span class="n">use_custom_allreduce</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="L-1209"><a href="#L-1209"><span class="linenos">1209</span></a>        <span class="n">use_custom_allreduce</span> <span class="o">=</span> <span class="n">_ENABLE_CUSTOM_ALL_REDUCE</span>
</span><span id="L-1210"><a href="#L-1210"><span class="linenos">1210</span></a>    <span class="k">if</span> <span class="n">use_mscclpp_allreduce</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="L-1211"><a href="#L-1211"><span class="linenos">1211</span></a>        <span class="n">use_mscclpp_allreduce</span> <span class="o">=</span> <span class="n">_ENABLE_MSCCLPP_ALL_REDUCE</span>
</span><span id="L-1212"><a href="#L-1212"><span class="linenos">1212</span></a>    <span class="k">return</span> <span class="n">GroupCoordinator</span><span class="p">(</span>
</span><span id="L-1213"><a href="#L-1213"><span class="linenos">1213</span></a>        <span class="n">group_ranks</span><span class="o">=</span><span class="n">group_ranks</span><span class="p">,</span>
</span><span id="L-1214"><a href="#L-1214"><span class="linenos">1214</span></a>        <span class="n">local_rank</span><span class="o">=</span><span class="n">local_rank</span><span class="p">,</span>
</span><span id="L-1215"><a href="#L-1215"><span class="linenos">1215</span></a>        <span class="n">torch_distributed_backend</span><span class="o">=</span><span class="n">backend</span><span class="p">,</span>
</span><span id="L-1216"><a href="#L-1216"><span class="linenos">1216</span></a>        <span class="n">use_pynccl</span><span class="o">=</span><span class="ow">not</span> <span class="n">_is_npu</span><span class="p">,</span>
</span><span id="L-1217"><a href="#L-1217"><span class="linenos">1217</span></a>        <span class="n">use_pymscclpp</span><span class="o">=</span><span class="n">use_mscclpp_allreduce</span><span class="p">,</span>
</span><span id="L-1218"><a href="#L-1218"><span class="linenos">1218</span></a>        <span class="n">use_custom_allreduce</span><span class="o">=</span><span class="n">use_custom_allreduce</span><span class="p">,</span>
</span><span id="L-1219"><a href="#L-1219"><span class="linenos">1219</span></a>        <span class="n">use_hpu_communicator</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
</span><span id="L-1220"><a href="#L-1220"><span class="linenos">1220</span></a>        <span class="n">use_xpu_communicator</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
</span><span id="L-1221"><a href="#L-1221"><span class="linenos">1221</span></a>        <span class="n">use_npu_communicator</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
</span><span id="L-1222"><a href="#L-1222"><span class="linenos">1222</span></a>        <span class="n">use_message_queue_broadcaster</span><span class="o">=</span><span class="n">use_message_queue_broadcaster</span><span class="p">,</span>
</span><span id="L-1223"><a href="#L-1223"><span class="linenos">1223</span></a>        <span class="n">group_name</span><span class="o">=</span><span class="n">group_name</span><span class="p">,</span>
</span><span id="L-1224"><a href="#L-1224"><span class="linenos">1224</span></a>    <span class="p">)</span>
</span><span id="L-1225"><a href="#L-1225"><span class="linenos">1225</span></a>
</span><span id="L-1226"><a href="#L-1226"><span class="linenos">1226</span></a>
</span><span id="L-1227"><a href="#L-1227"><span class="linenos">1227</span></a><span class="n">_TP</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">GroupCoordinator</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
</span><span id="L-1228"><a href="#L-1228"><span class="linenos">1228</span></a>
</span><span id="L-1229"><a href="#L-1229"><span class="linenos">1229</span></a><span class="c1"># duplicate GroupCoordinator for prefill in PD-Multiplexing</span>
</span><span id="L-1230"><a href="#L-1230"><span class="linenos">1230</span></a><span class="n">_PDMUX_PREFILL_TP_GROUP</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">GroupCoordinator</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
</span><span id="L-1231"><a href="#L-1231"><span class="linenos">1231</span></a>
</span><span id="L-1232"><a href="#L-1232"><span class="linenos">1232</span></a><span class="n">_ENABLE_PDMUX_P_TP</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span>
</span><span id="L-1233"><a href="#L-1233"><span class="linenos">1233</span></a>
</span><span id="L-1234"><a href="#L-1234"><span class="linenos">1234</span></a>
</span><span id="L-1235"><a href="#L-1235"><span class="linenos">1235</span></a><span class="k">def</span><span class="w"> </span><span class="nf">set_pdmux_status</span><span class="p">(</span><span class="n">enable_prefill_multiplexing</span><span class="p">:</span> <span class="nb">bool</span><span class="p">):</span>
</span><span id="L-1236"><a href="#L-1236"><span class="linenos">1236</span></a>    <span class="k">global</span> <span class="n">_ENABLE_PDMUX_P_TP</span>
</span><span id="L-1237"><a href="#L-1237"><span class="linenos">1237</span></a>    <span class="n">_ENABLE_PDMUX_P_TP</span> <span class="o">=</span> <span class="n">enable_prefill_multiplexing</span>
</span><span id="L-1238"><a href="#L-1238"><span class="linenos">1238</span></a>
</span><span id="L-1239"><a href="#L-1239"><span class="linenos">1239</span></a>
</span><span id="L-1240"><a href="#L-1240"><span class="linenos">1240</span></a><span class="k">def</span><span class="w"> </span><span class="nf">get_tp_group</span><span class="p">()</span> <span class="o">-&gt;</span> <span class="n">GroupCoordinator</span><span class="p">:</span>
</span><span id="L-1241"><a href="#L-1241"><span class="linenos">1241</span></a>    <span class="k">if</span> <span class="n">_ENABLE_PDMUX_P_TP</span><span class="p">:</span>
</span><span id="L-1242"><a href="#L-1242"><span class="linenos">1242</span></a>        <span class="k">assert</span> <span class="p">(</span>
</span><span id="L-1243"><a href="#L-1243"><span class="linenos">1243</span></a>            <span class="n">_PDMUX_PREFILL_TP_GROUP</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
</span><span id="L-1244"><a href="#L-1244"><span class="linenos">1244</span></a>        <span class="p">),</span> <span class="s2">&quot;tensor model parallel group for PD-Multiplexing Prefill is not initialized&quot;</span>
</span><span id="L-1245"><a href="#L-1245"><span class="linenos">1245</span></a>        <span class="k">return</span> <span class="n">_PDMUX_PREFILL_TP_GROUP</span>
</span><span id="L-1246"><a href="#L-1246"><span class="linenos">1246</span></a>    <span class="k">assert</span> <span class="n">_TP</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">,</span> <span class="s2">&quot;tensor model parallel group is not initialized&quot;</span>
</span><span id="L-1247"><a href="#L-1247"><span class="linenos">1247</span></a>    <span class="k">return</span> <span class="n">_TP</span>
</span><span id="L-1248"><a href="#L-1248"><span class="linenos">1248</span></a>
</span><span id="L-1249"><a href="#L-1249"><span class="linenos">1249</span></a>
</span><span id="L-1250"><a href="#L-1250"><span class="linenos">1250</span></a><span class="n">_MOE_EP</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">GroupCoordinator</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
</span><span id="L-1251"><a href="#L-1251"><span class="linenos">1251</span></a><span class="n">_MOE_TP</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">GroupCoordinator</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
</span><span id="L-1252"><a href="#L-1252"><span class="linenos">1252</span></a>
</span><span id="L-1253"><a href="#L-1253"><span class="linenos">1253</span></a>
</span><span id="L-1254"><a href="#L-1254"><span class="linenos">1254</span></a><span class="k">def</span><span class="w"> </span><span class="nf">get_moe_ep_group</span><span class="p">()</span> <span class="o">-&gt;</span> <span class="n">GroupCoordinator</span><span class="p">:</span>
</span><span id="L-1255"><a href="#L-1255"><span class="linenos">1255</span></a>    <span class="k">assert</span> <span class="n">_MOE_EP</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">,</span> <span class="s2">&quot;expert model parallel group is not initialized&quot;</span>
</span><span id="L-1256"><a href="#L-1256"><span class="linenos">1256</span></a>    <span class="k">return</span> <span class="n">_MOE_EP</span>
</span><span id="L-1257"><a href="#L-1257"><span class="linenos">1257</span></a>
</span><span id="L-1258"><a href="#L-1258"><span class="linenos">1258</span></a>
</span><span id="L-1259"><a href="#L-1259"><span class="linenos">1259</span></a><span class="k">def</span><span class="w"> </span><span class="nf">get_moe_tp_group</span><span class="p">()</span> <span class="o">-&gt;</span> <span class="n">GroupCoordinator</span><span class="p">:</span>
</span><span id="L-1260"><a href="#L-1260"><span class="linenos">1260</span></a>    <span class="k">assert</span> <span class="n">_MOE_TP</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">,</span> <span class="s2">&quot;expert model parallel group is not initialized&quot;</span>
</span><span id="L-1261"><a href="#L-1261"><span class="linenos">1261</span></a>    <span class="k">return</span> <span class="n">_MOE_TP</span>
</span><span id="L-1262"><a href="#L-1262"><span class="linenos">1262</span></a>
</span><span id="L-1263"><a href="#L-1263"><span class="linenos">1263</span></a>
</span><span id="L-1264"><a href="#L-1264"><span class="linenos">1264</span></a><span class="c1"># kept for backward compatibility</span>
</span><span id="L-1265"><a href="#L-1265"><span class="linenos">1265</span></a><span class="n">get_tensor_model_parallel_group</span> <span class="o">=</span> <span class="n">get_tp_group</span>
</span><span id="L-1266"><a href="#L-1266"><span class="linenos">1266</span></a>
</span><span id="L-1267"><a href="#L-1267"><span class="linenos">1267</span></a><span class="n">_PP</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">GroupCoordinator</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
</span><span id="L-1268"><a href="#L-1268"><span class="linenos">1268</span></a>
</span><span id="L-1269"><a href="#L-1269"><span class="linenos">1269</span></a>
</span><span id="L-1270"><a href="#L-1270"><span class="linenos">1270</span></a><span class="k">def</span><span class="w"> </span><span class="nf">get_pp_group</span><span class="p">()</span> <span class="o">-&gt;</span> <span class="n">GroupCoordinator</span><span class="p">:</span>
</span><span id="L-1271"><a href="#L-1271"><span class="linenos">1271</span></a>    <span class="k">assert</span> <span class="n">_PP</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">,</span> <span class="s2">&quot;pipeline model parallel group is not initialized&quot;</span>
</span><span id="L-1272"><a href="#L-1272"><span class="linenos">1272</span></a>    <span class="k">return</span> <span class="n">_PP</span>
</span><span id="L-1273"><a href="#L-1273"><span class="linenos">1273</span></a>
</span><span id="L-1274"><a href="#L-1274"><span class="linenos">1274</span></a>
</span><span id="L-1275"><a href="#L-1275"><span class="linenos">1275</span></a><span class="c1"># kept for backward compatibility</span>
</span><span id="L-1276"><a href="#L-1276"><span class="linenos">1276</span></a><span class="n">get_pipeline_model_parallel_group</span> <span class="o">=</span> <span class="n">get_pp_group</span>
</span><span id="L-1277"><a href="#L-1277"><span class="linenos">1277</span></a>
</span><span id="L-1278"><a href="#L-1278"><span class="linenos">1278</span></a>
</span><span id="L-1279"><a href="#L-1279"><span class="linenos">1279</span></a><span class="nd">@contextmanager</span>
</span><span id="L-1280"><a href="#L-1280"><span class="linenos">1280</span></a><span class="k">def</span><span class="w"> </span><span class="nf">graph_capture</span><span class="p">():</span>
</span><span id="L-1281"><a href="#L-1281"><span class="linenos">1281</span></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="L-1282"><a href="#L-1282"><span class="linenos">1282</span></a><span class="sd">    `graph_capture` is a context manager which should surround the code that</span>
</span><span id="L-1283"><a href="#L-1283"><span class="linenos">1283</span></a><span class="sd">    is capturing the CUDA graph. Its main purpose is to ensure that the</span>
</span><span id="L-1284"><a href="#L-1284"><span class="linenos">1284</span></a><span class="sd">    some operations will be run after the graph is captured, before the graph</span>
</span><span id="L-1285"><a href="#L-1285"><span class="linenos">1285</span></a><span class="sd">    is replayed. It returns a `GraphCaptureContext` object which contains the</span>
</span><span id="L-1286"><a href="#L-1286"><span class="linenos">1286</span></a><span class="sd">    necessary data for the graph capture. Currently, it only contains the</span>
</span><span id="L-1287"><a href="#L-1287"><span class="linenos">1287</span></a><span class="sd">    stream that the graph capture is running on. This stream is set to the</span>
</span><span id="L-1288"><a href="#L-1288"><span class="linenos">1288</span></a><span class="sd">    current CUDA stream when the context manager is entered and reset to the</span>
</span><span id="L-1289"><a href="#L-1289"><span class="linenos">1289</span></a><span class="sd">    default stream when the context manager is exited. This is to ensure that</span>
</span><span id="L-1290"><a href="#L-1290"><span class="linenos">1290</span></a><span class="sd">    the graph capture is running on a separate stream from the default stream,</span>
</span><span id="L-1291"><a href="#L-1291"><span class="linenos">1291</span></a><span class="sd">    in order to explicitly distinguish the kernels to capture</span>
</span><span id="L-1292"><a href="#L-1292"><span class="linenos">1292</span></a><span class="sd">    from other kernels possibly launched on background in the default stream.</span>
</span><span id="L-1293"><a href="#L-1293"><span class="linenos">1293</span></a><span class="sd">    &quot;&quot;&quot;</span>
</span><span id="L-1294"><a href="#L-1294"><span class="linenos">1294</span></a>    <span class="k">with</span> <span class="n">get_tp_group</span><span class="p">()</span><span class="o">.</span><span class="n">graph_capture</span><span class="p">()</span> <span class="k">as</span> <span class="n">context</span><span class="p">,</span> <span class="n">get_pp_group</span><span class="p">()</span><span class="o">.</span><span class="n">graph_capture</span><span class="p">(</span>
</span><span id="L-1295"><a href="#L-1295"><span class="linenos">1295</span></a>        <span class="n">context</span>
</span><span id="L-1296"><a href="#L-1296"><span class="linenos">1296</span></a>    <span class="p">):</span>
</span><span id="L-1297"><a href="#L-1297"><span class="linenos">1297</span></a>        <span class="k">yield</span> <span class="n">context</span>
</span><span id="L-1298"><a href="#L-1298"><span class="linenos">1298</span></a>
</span><span id="L-1299"><a href="#L-1299"><span class="linenos">1299</span></a>
</span><span id="L-1300"><a href="#L-1300"><span class="linenos">1300</span></a><span class="n">logger</span> <span class="o">=</span> <span class="n">logging</span><span class="o">.</span><span class="n">getLogger</span><span class="p">(</span><span class="vm">__name__</span><span class="p">)</span>
</span><span id="L-1301"><a href="#L-1301"><span class="linenos">1301</span></a>
</span><span id="L-1302"><a href="#L-1302"><span class="linenos">1302</span></a><span class="n">_ENABLE_CUSTOM_ALL_REDUCE</span> <span class="o">=</span> <span class="kc">True</span>
</span><span id="L-1303"><a href="#L-1303"><span class="linenos">1303</span></a><span class="n">_ENABLE_MSCCLPP_ALL_REDUCE</span> <span class="o">=</span> <span class="kc">False</span>
</span><span id="L-1304"><a href="#L-1304"><span class="linenos">1304</span></a>
</span><span id="L-1305"><a href="#L-1305"><span class="linenos">1305</span></a>
</span><span id="L-1306"><a href="#L-1306"><span class="linenos">1306</span></a><span class="k">def</span><span class="w"> </span><span class="nf">set_custom_all_reduce</span><span class="p">(</span><span class="n">enable</span><span class="p">:</span> <span class="nb">bool</span><span class="p">):</span>
</span><span id="L-1307"><a href="#L-1307"><span class="linenos">1307</span></a>    <span class="k">global</span> <span class="n">_ENABLE_CUSTOM_ALL_REDUCE</span>
</span><span id="L-1308"><a href="#L-1308"><span class="linenos">1308</span></a>    <span class="n">_ENABLE_CUSTOM_ALL_REDUCE</span> <span class="o">=</span> <span class="n">enable</span>
</span><span id="L-1309"><a href="#L-1309"><span class="linenos">1309</span></a>
</span><span id="L-1310"><a href="#L-1310"><span class="linenos">1310</span></a>
</span><span id="L-1311"><a href="#L-1311"><span class="linenos">1311</span></a><span class="k">def</span><span class="w"> </span><span class="nf">set_mscclpp_all_reduce</span><span class="p">(</span><span class="n">enable</span><span class="p">:</span> <span class="nb">bool</span><span class="p">):</span>
</span><span id="L-1312"><a href="#L-1312"><span class="linenos">1312</span></a>    <span class="k">global</span> <span class="n">_ENABLE_MSCCLPP_ALL_REDUCE</span>
</span><span id="L-1313"><a href="#L-1313"><span class="linenos">1313</span></a>    <span class="n">_ENABLE_MSCCLPP_ALL_REDUCE</span> <span class="o">=</span> <span class="n">enable</span>
</span><span id="L-1314"><a href="#L-1314"><span class="linenos">1314</span></a>
</span><span id="L-1315"><a href="#L-1315"><span class="linenos">1315</span></a>
</span><span id="L-1316"><a href="#L-1316"><span class="linenos">1316</span></a><span class="k">def</span><span class="w"> </span><span class="nf">init_distributed_environment</span><span class="p">(</span>
</span><span id="L-1317"><a href="#L-1317"><span class="linenos">1317</span></a>    <span class="n">world_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
</span><span id="L-1318"><a href="#L-1318"><span class="linenos">1318</span></a>    <span class="n">rank</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
</span><span id="L-1319"><a href="#L-1319"><span class="linenos">1319</span></a>    <span class="n">distributed_init_method</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;env://&quot;</span><span class="p">,</span>
</span><span id="L-1320"><a href="#L-1320"><span class="linenos">1320</span></a>    <span class="n">local_rank</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
</span><span id="L-1321"><a href="#L-1321"><span class="linenos">1321</span></a>    <span class="n">backend</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;nccl&quot;</span><span class="p">,</span>
</span><span id="L-1322"><a href="#L-1322"><span class="linenos">1322</span></a>    <span class="n">timeout</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="L-1323"><a href="#L-1323"><span class="linenos">1323</span></a><span class="p">):</span>
</span><span id="L-1324"><a href="#L-1324"><span class="linenos">1324</span></a>    <span class="n">logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span>
</span><span id="L-1325"><a href="#L-1325"><span class="linenos">1325</span></a>        <span class="s2">&quot;world_size=</span><span class="si">%d</span><span class="s2"> rank=</span><span class="si">%d</span><span class="s2"> local_rank=</span><span class="si">%d</span><span class="s2"> &quot;</span> <span class="s2">&quot;distributed_init_method=</span><span class="si">%s</span><span class="s2"> backend=</span><span class="si">%s</span><span class="s2">&quot;</span><span class="p">,</span>
</span><span id="L-1326"><a href="#L-1326"><span class="linenos">1326</span></a>        <span class="n">world_size</span><span class="p">,</span>
</span><span id="L-1327"><a href="#L-1327"><span class="linenos">1327</span></a>        <span class="n">rank</span><span class="p">,</span>
</span><span id="L-1328"><a href="#L-1328"><span class="linenos">1328</span></a>        <span class="n">local_rank</span><span class="p">,</span>
</span><span id="L-1329"><a href="#L-1329"><span class="linenos">1329</span></a>        <span class="n">distributed_init_method</span><span class="p">,</span>
</span><span id="L-1330"><a href="#L-1330"><span class="linenos">1330</span></a>        <span class="n">backend</span><span class="p">,</span>
</span><span id="L-1331"><a href="#L-1331"><span class="linenos">1331</span></a>    <span class="p">)</span>
</span><span id="L-1332"><a href="#L-1332"><span class="linenos">1332</span></a>    <span class="k">if</span> <span class="ow">not</span> <span class="n">torch</span><span class="o">.</span><span class="n">distributed</span><span class="o">.</span><span class="n">is_initialized</span><span class="p">():</span>
</span><span id="L-1333"><a href="#L-1333"><span class="linenos">1333</span></a>        <span class="k">assert</span> <span class="n">distributed_init_method</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">,</span> <span class="p">(</span>
</span><span id="L-1334"><a href="#L-1334"><span class="linenos">1334</span></a>            <span class="s2">&quot;distributed_init_method must be provided when initializing &quot;</span>
</span><span id="L-1335"><a href="#L-1335"><span class="linenos">1335</span></a>            <span class="s2">&quot;distributed environment&quot;</span>
</span><span id="L-1336"><a href="#L-1336"><span class="linenos">1336</span></a>        <span class="p">)</span>
</span><span id="L-1337"><a href="#L-1337"><span class="linenos">1337</span></a>        <span class="k">if</span> <span class="n">timeout</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="L-1338"><a href="#L-1338"><span class="linenos">1338</span></a>            <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">timeout</span><span class="p">,</span> <span class="p">(</span><span class="nb">int</span><span class="p">)),</span> <span class="s2">&quot;timeout must be a number&quot;</span>
</span><span id="L-1339"><a href="#L-1339"><span class="linenos">1339</span></a>            <span class="k">assert</span> <span class="n">timeout</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">,</span> <span class="s2">&quot;timeout must be positive&quot;</span>
</span><span id="L-1340"><a href="#L-1340"><span class="linenos">1340</span></a>            <span class="n">timeout</span> <span class="o">=</span> <span class="n">timedelta</span><span class="p">(</span><span class="n">seconds</span><span class="o">=</span><span class="n">timeout</span><span class="p">)</span>
</span><span id="L-1341"><a href="#L-1341"><span class="linenos">1341</span></a>
</span><span id="L-1342"><a href="#L-1342"><span class="linenos">1342</span></a>        <span class="c1"># this backend is used for WORLD</span>
</span><span id="L-1343"><a href="#L-1343"><span class="linenos">1343</span></a>        <span class="n">torch</span><span class="o">.</span><span class="n">distributed</span><span class="o">.</span><span class="n">init_process_group</span><span class="p">(</span>
</span><span id="L-1344"><a href="#L-1344"><span class="linenos">1344</span></a>            <span class="n">backend</span><span class="o">=</span><span class="n">backend</span><span class="p">,</span>
</span><span id="L-1345"><a href="#L-1345"><span class="linenos">1345</span></a>            <span class="n">init_method</span><span class="o">=</span><span class="n">distributed_init_method</span><span class="p">,</span>
</span><span id="L-1346"><a href="#L-1346"><span class="linenos">1346</span></a>            <span class="n">world_size</span><span class="o">=</span><span class="n">world_size</span><span class="p">,</span>
</span><span id="L-1347"><a href="#L-1347"><span class="linenos">1347</span></a>            <span class="n">rank</span><span class="o">=</span><span class="n">rank</span><span class="p">,</span>
</span><span id="L-1348"><a href="#L-1348"><span class="linenos">1348</span></a>            <span class="n">timeout</span><span class="o">=</span><span class="n">timeout</span><span class="p">,</span>
</span><span id="L-1349"><a href="#L-1349"><span class="linenos">1349</span></a>        <span class="p">)</span>
</span><span id="L-1350"><a href="#L-1350"><span class="linenos">1350</span></a>
</span><span id="L-1351"><a href="#L-1351"><span class="linenos">1351</span></a>    <span class="c1"># set the local rank</span>
</span><span id="L-1352"><a href="#L-1352"><span class="linenos">1352</span></a>    <span class="c1"># local_rank is not available in torch ProcessGroup,</span>
</span><span id="L-1353"><a href="#L-1353"><span class="linenos">1353</span></a>    <span class="c1"># see https://github.com/pytorch/pytorch/issues/122816</span>
</span><span id="L-1354"><a href="#L-1354"><span class="linenos">1354</span></a>    <span class="k">if</span> <span class="n">local_rank</span> <span class="o">==</span> <span class="o">-</span><span class="mi">1</span><span class="p">:</span>
</span><span id="L-1355"><a href="#L-1355"><span class="linenos">1355</span></a>        <span class="c1"># local rank not set, this usually happens in single-node</span>
</span><span id="L-1356"><a href="#L-1356"><span class="linenos">1356</span></a>        <span class="c1"># setting, where we can use rank as local rank</span>
</span><span id="L-1357"><a href="#L-1357"><span class="linenos">1357</span></a>        <span class="k">if</span> <span class="n">distributed_init_method</span> <span class="o">==</span> <span class="s2">&quot;env://&quot;</span><span class="p">:</span>
</span><span id="L-1358"><a href="#L-1358"><span class="linenos">1358</span></a>            <span class="n">local_rank</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;LOCAL_RANK&quot;</span><span class="p">,</span> <span class="s2">&quot;0&quot;</span><span class="p">))</span>
</span><span id="L-1359"><a href="#L-1359"><span class="linenos">1359</span></a>        <span class="k">else</span><span class="p">:</span>
</span><span id="L-1360"><a href="#L-1360"><span class="linenos">1360</span></a>            <span class="n">local_rank</span> <span class="o">=</span> <span class="n">rank</span>
</span><span id="L-1361"><a href="#L-1361"><span class="linenos">1361</span></a>    <span class="k">global</span> <span class="n">_WORLD</span>
</span><span id="L-1362"><a href="#L-1362"><span class="linenos">1362</span></a>    <span class="k">if</span> <span class="n">_WORLD</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="L-1363"><a href="#L-1363"><span class="linenos">1363</span></a>        <span class="n">ranks</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">distributed</span><span class="o">.</span><span class="n">get_world_size</span><span class="p">()))</span>
</span><span id="L-1364"><a href="#L-1364"><span class="linenos">1364</span></a>        <span class="n">_WORLD</span> <span class="o">=</span> <span class="n">init_world_group</span><span class="p">(</span><span class="n">ranks</span><span class="p">,</span> <span class="n">local_rank</span><span class="p">,</span> <span class="n">backend</span><span class="p">)</span>
</span><span id="L-1365"><a href="#L-1365"><span class="linenos">1365</span></a>    <span class="k">else</span><span class="p">:</span>
</span><span id="L-1366"><a href="#L-1366"><span class="linenos">1366</span></a>        <span class="k">assert</span> <span class="p">(</span>
</span><span id="L-1367"><a href="#L-1367"><span class="linenos">1367</span></a>            <span class="n">_WORLD</span><span class="o">.</span><span class="n">world_size</span> <span class="o">==</span> <span class="n">torch</span><span class="o">.</span><span class="n">distributed</span><span class="o">.</span><span class="n">get_world_size</span><span class="p">()</span>
</span><span id="L-1368"><a href="#L-1368"><span class="linenos">1368</span></a>        <span class="p">),</span> <span class="s2">&quot;world group already initialized with a different world size&quot;</span>
</span><span id="L-1369"><a href="#L-1369"><span class="linenos">1369</span></a>
</span><span id="L-1370"><a href="#L-1370"><span class="linenos">1370</span></a>
</span><span id="L-1371"><a href="#L-1371"><span class="linenos">1371</span></a><span class="k">def</span><span class="w"> </span><span class="nf">initialize_model_parallel</span><span class="p">(</span>
</span><span id="L-1372"><a href="#L-1372"><span class="linenos">1372</span></a>    <span class="n">tensor_model_parallel_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
</span><span id="L-1373"><a href="#L-1373"><span class="linenos">1373</span></a>    <span class="n">expert_model_parallel_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
</span><span id="L-1374"><a href="#L-1374"><span class="linenos">1374</span></a>    <span class="n">pipeline_model_parallel_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
</span><span id="L-1375"><a href="#L-1375"><span class="linenos">1375</span></a>    <span class="n">backend</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="L-1376"><a href="#L-1376"><span class="linenos">1376</span></a>    <span class="n">duplicate_tp_group</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
</span><span id="L-1377"><a href="#L-1377"><span class="linenos">1377</span></a><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="L-1378"><a href="#L-1378"><span class="linenos">1378</span></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="L-1379"><a href="#L-1379"><span class="linenos">1379</span></a><span class="sd">    Initialize model parallel groups.</span>
</span><span id="L-1380"><a href="#L-1380"><span class="linenos">1380</span></a>
</span><span id="L-1381"><a href="#L-1381"><span class="linenos">1381</span></a><span class="sd">    Arguments:</span>
</span><span id="L-1382"><a href="#L-1382"><span class="linenos">1382</span></a><span class="sd">        tensor_model_parallel_size: number of GPUs used for tensor model</span>
</span><span id="L-1383"><a href="#L-1383"><span class="linenos">1383</span></a><span class="sd">            parallelism.</span>
</span><span id="L-1384"><a href="#L-1384"><span class="linenos">1384</span></a><span class="sd">        pipeline_model_parallel_size: number of GPUs used for pipeline model</span>
</span><span id="L-1385"><a href="#L-1385"><span class="linenos">1385</span></a><span class="sd">            parallelism.</span>
</span><span id="L-1386"><a href="#L-1386"><span class="linenos">1386</span></a>
</span><span id="L-1387"><a href="#L-1387"><span class="linenos">1387</span></a><span class="sd">    Let&#39;s say we have a total of 8 GPUs denoted by g0 ... g7 and we</span>
</span><span id="L-1388"><a href="#L-1388"><span class="linenos">1388</span></a><span class="sd">    use 2 GPUs to parallelize the model tensor, and 4 GPUs to parallelize</span>
</span><span id="L-1389"><a href="#L-1389"><span class="linenos">1389</span></a><span class="sd">    the model pipeline. The present function will</span>
</span><span id="L-1390"><a href="#L-1390"><span class="linenos">1390</span></a><span class="sd">    create 4 tensor model-parallel groups and 2 pipeline model-parallel groups:</span>
</span><span id="L-1391"><a href="#L-1391"><span class="linenos">1391</span></a><span class="sd">        4 tensor model-parallel groups:</span>
</span><span id="L-1392"><a href="#L-1392"><span class="linenos">1392</span></a><span class="sd">            [g0, g1], [g2, g3], [g4, g5], [g6, g7]</span>
</span><span id="L-1393"><a href="#L-1393"><span class="linenos">1393</span></a><span class="sd">        2 pipeline model-parallel groups:</span>
</span><span id="L-1394"><a href="#L-1394"><span class="linenos">1394</span></a><span class="sd">            [g0, g2, g4, g6], [g1, g3, g5, g7]</span>
</span><span id="L-1395"><a href="#L-1395"><span class="linenos">1395</span></a><span class="sd">    Note that for efficiency, the caller should make sure adjacent ranks</span>
</span><span id="L-1396"><a href="#L-1396"><span class="linenos">1396</span></a><span class="sd">    are on the same DGX box. For example if we are using 2 DGX-1 boxes</span>
</span><span id="L-1397"><a href="#L-1397"><span class="linenos">1397</span></a><span class="sd">    with a total of 16 GPUs, rank 0 to 7 belong to the first box and</span>
</span><span id="L-1398"><a href="#L-1398"><span class="linenos">1398</span></a><span class="sd">    ranks 8 to 15 belong to the second box.</span>
</span><span id="L-1399"><a href="#L-1399"><span class="linenos">1399</span></a><span class="sd">    &quot;&quot;&quot;</span>
</span><span id="L-1400"><a href="#L-1400"><span class="linenos">1400</span></a>    <span class="c1"># Get world size and rank. Ensure some consistencies.</span>
</span><span id="L-1401"><a href="#L-1401"><span class="linenos">1401</span></a>    <span class="k">assert</span> <span class="n">torch</span><span class="o">.</span><span class="n">distributed</span><span class="o">.</span><span class="n">is_initialized</span><span class="p">()</span>
</span><span id="L-1402"><a href="#L-1402"><span class="linenos">1402</span></a>    <span class="n">world_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">distributed</span><span class="o">.</span><span class="n">get_world_size</span><span class="p">()</span>
</span><span id="L-1403"><a href="#L-1403"><span class="linenos">1403</span></a>    <span class="n">backend</span> <span class="o">=</span> <span class="n">backend</span> <span class="ow">or</span> <span class="n">torch</span><span class="o">.</span><span class="n">distributed</span><span class="o">.</span><span class="n">get_backend</span><span class="p">(</span><span class="n">get_world_group</span><span class="p">()</span><span class="o">.</span><span class="n">device_group</span><span class="p">)</span>
</span><span id="L-1404"><a href="#L-1404"><span class="linenos">1404</span></a>
</span><span id="L-1405"><a href="#L-1405"><span class="linenos">1405</span></a>    <span class="k">if</span> <span class="n">world_size</span> <span class="o">!=</span> <span class="n">tensor_model_parallel_size</span> <span class="o">*</span> <span class="n">pipeline_model_parallel_size</span><span class="p">:</span>
</span><span id="L-1406"><a href="#L-1406"><span class="linenos">1406</span></a>        <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span>
</span><span id="L-1407"><a href="#L-1407"><span class="linenos">1407</span></a>            <span class="sa">f</span><span class="s2">&quot;world_size (</span><span class="si">{</span><span class="n">world_size</span><span class="si">}</span><span class="s2">) is not equal to &quot;</span>
</span><span id="L-1408"><a href="#L-1408"><span class="linenos">1408</span></a>            <span class="sa">f</span><span class="s2">&quot;tensor_model_parallel_size (</span><span class="si">{</span><span class="n">tensor_model_parallel_size</span><span class="si">}</span><span class="s2">) x &quot;</span>
</span><span id="L-1409"><a href="#L-1409"><span class="linenos">1409</span></a>            <span class="sa">f</span><span class="s2">&quot;pipeline_model_parallel_size (</span><span class="si">{</span><span class="n">pipeline_model_parallel_size</span><span class="si">}</span><span class="s2">)&quot;</span>
</span><span id="L-1410"><a href="#L-1410"><span class="linenos">1410</span></a>        <span class="p">)</span>
</span><span id="L-1411"><a href="#L-1411"><span class="linenos">1411</span></a>
</span><span id="L-1412"><a href="#L-1412"><span class="linenos">1412</span></a>    <span class="c1"># Build the tensor model-parallel groups.</span>
</span><span id="L-1413"><a href="#L-1413"><span class="linenos">1413</span></a>    <span class="n">num_tensor_model_parallel_groups</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="n">world_size</span> <span class="o">//</span> <span class="n">tensor_model_parallel_size</span>
</span><span id="L-1414"><a href="#L-1414"><span class="linenos">1414</span></a>    <span class="k">global</span> <span class="n">_TP</span>
</span><span id="L-1415"><a href="#L-1415"><span class="linenos">1415</span></a>    <span class="k">assert</span> <span class="n">_TP</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">,</span> <span class="s2">&quot;tensor model parallel group is already initialized&quot;</span>
</span><span id="L-1416"><a href="#L-1416"><span class="linenos">1416</span></a>    <span class="n">group_ranks</span> <span class="o">=</span> <span class="p">[]</span>
</span><span id="L-1417"><a href="#L-1417"><span class="linenos">1417</span></a>    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_tensor_model_parallel_groups</span><span class="p">):</span>
</span><span id="L-1418"><a href="#L-1418"><span class="linenos">1418</span></a>        <span class="n">ranks</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span>
</span><span id="L-1419"><a href="#L-1419"><span class="linenos">1419</span></a>            <span class="nb">range</span><span class="p">(</span><span class="n">i</span> <span class="o">*</span> <span class="n">tensor_model_parallel_size</span><span class="p">,</span> <span class="p">(</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="n">tensor_model_parallel_size</span><span class="p">)</span>
</span><span id="L-1420"><a href="#L-1420"><span class="linenos">1420</span></a>        <span class="p">)</span>
</span><span id="L-1421"><a href="#L-1421"><span class="linenos">1421</span></a>        <span class="n">group_ranks</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">ranks</span><span class="p">)</span>
</span><span id="L-1422"><a href="#L-1422"><span class="linenos">1422</span></a>
</span><span id="L-1423"><a href="#L-1423"><span class="linenos">1423</span></a>    <span class="c1"># message queue broadcaster is only used in tensor model parallel group</span>
</span><span id="L-1424"><a href="#L-1424"><span class="linenos">1424</span></a>    <span class="n">_TP</span> <span class="o">=</span> <span class="n">init_model_parallel_group</span><span class="p">(</span>
</span><span id="L-1425"><a href="#L-1425"><span class="linenos">1425</span></a>        <span class="n">group_ranks</span><span class="p">,</span>
</span><span id="L-1426"><a href="#L-1426"><span class="linenos">1426</span></a>        <span class="n">get_world_group</span><span class="p">()</span><span class="o">.</span><span class="n">local_rank</span><span class="p">,</span>
</span><span id="L-1427"><a href="#L-1427"><span class="linenos">1427</span></a>        <span class="n">backend</span><span class="p">,</span>
</span><span id="L-1428"><a href="#L-1428"><span class="linenos">1428</span></a>        <span class="n">use_message_queue_broadcaster</span><span class="o">=</span><span class="n">get_bool_env_var</span><span class="p">(</span>
</span><span id="L-1429"><a href="#L-1429"><span class="linenos">1429</span></a>            <span class="s2">&quot;SGLANG_USE_MESSAGE_QUEUE_BROADCASTER&quot;</span><span class="p">,</span> <span class="s2">&quot;true&quot;</span>
</span><span id="L-1430"><a href="#L-1430"><span class="linenos">1430</span></a>        <span class="p">),</span>
</span><span id="L-1431"><a href="#L-1431"><span class="linenos">1431</span></a>        <span class="n">group_name</span><span class="o">=</span><span class="s2">&quot;tp&quot;</span><span class="p">,</span>
</span><span id="L-1432"><a href="#L-1432"><span class="linenos">1432</span></a>    <span class="p">)</span>
</span><span id="L-1433"><a href="#L-1433"><span class="linenos">1433</span></a>
</span><span id="L-1434"><a href="#L-1434"><span class="linenos">1434</span></a>    <span class="k">if</span> <span class="n">duplicate_tp_group</span><span class="p">:</span>
</span><span id="L-1435"><a href="#L-1435"><span class="linenos">1435</span></a>        <span class="k">global</span> <span class="n">_PDMUX_PREFILL_TP_GROUP</span>
</span><span id="L-1436"><a href="#L-1436"><span class="linenos">1436</span></a>        <span class="k">assert</span> <span class="p">(</span>
</span><span id="L-1437"><a href="#L-1437"><span class="linenos">1437</span></a>            <span class="n">_PDMUX_PREFILL_TP_GROUP</span> <span class="ow">is</span> <span class="kc">None</span>
</span><span id="L-1438"><a href="#L-1438"><span class="linenos">1438</span></a>        <span class="p">),</span> <span class="s2">&quot;tensor model parallel group for PD-Multiplexing Prefill is already initialized&quot;</span>
</span><span id="L-1439"><a href="#L-1439"><span class="linenos">1439</span></a>        <span class="n">_PDMUX_PREFILL_TP_GROUP</span> <span class="o">=</span> <span class="n">init_model_parallel_group</span><span class="p">(</span>
</span><span id="L-1440"><a href="#L-1440"><span class="linenos">1440</span></a>            <span class="n">group_ranks</span><span class="p">,</span>
</span><span id="L-1441"><a href="#L-1441"><span class="linenos">1441</span></a>            <span class="n">get_world_group</span><span class="p">()</span><span class="o">.</span><span class="n">local_rank</span><span class="p">,</span>
</span><span id="L-1442"><a href="#L-1442"><span class="linenos">1442</span></a>            <span class="n">backend</span><span class="p">,</span>
</span><span id="L-1443"><a href="#L-1443"><span class="linenos">1443</span></a>            <span class="n">use_message_queue_broadcaster</span><span class="o">=</span><span class="n">get_bool_env_var</span><span class="p">(</span>
</span><span id="L-1444"><a href="#L-1444"><span class="linenos">1444</span></a>                <span class="s2">&quot;SGLANG_USE_MESSAGE_QUEUE_BROADCASTER&quot;</span><span class="p">,</span> <span class="s2">&quot;true&quot;</span>
</span><span id="L-1445"><a href="#L-1445"><span class="linenos">1445</span></a>            <span class="p">),</span>
</span><span id="L-1446"><a href="#L-1446"><span class="linenos">1446</span></a>            <span class="n">group_name</span><span class="o">=</span><span class="s2">&quot;pdmux_prefill_tp&quot;</span><span class="p">,</span>
</span><span id="L-1447"><a href="#L-1447"><span class="linenos">1447</span></a>        <span class="p">)</span>
</span><span id="L-1448"><a href="#L-1448"><span class="linenos">1448</span></a>        <span class="n">_TP</span><span class="o">.</span><span class="n">pynccl_comm</span><span class="o">.</span><span class="n">disabled</span> <span class="o">=</span> <span class="kc">False</span>
</span><span id="L-1449"><a href="#L-1449"><span class="linenos">1449</span></a>        <span class="n">_PDMUX_PREFILL_TP_GROUP</span><span class="o">.</span><span class="n">pynccl_comm</span><span class="o">.</span><span class="n">disabled</span> <span class="o">=</span> <span class="kc">False</span>
</span><span id="L-1450"><a href="#L-1450"><span class="linenos">1450</span></a>
</span><span id="L-1451"><a href="#L-1451"><span class="linenos">1451</span></a>    <span class="n">moe_ep_size</span> <span class="o">=</span> <span class="n">expert_model_parallel_size</span>
</span><span id="L-1452"><a href="#L-1452"><span class="linenos">1452</span></a>
</span><span id="L-1453"><a href="#L-1453"><span class="linenos">1453</span></a>    <span class="n">moe_tp_size</span> <span class="o">=</span> <span class="n">tensor_model_parallel_size</span> <span class="o">//</span> <span class="n">moe_ep_size</span>
</span><span id="L-1454"><a href="#L-1454"><span class="linenos">1454</span></a>    <span class="k">global</span> <span class="n">_MOE_EP</span>
</span><span id="L-1455"><a href="#L-1455"><span class="linenos">1455</span></a>    <span class="k">assert</span> <span class="n">_MOE_EP</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">,</span> <span class="s2">&quot;expert model parallel group is already initialized&quot;</span>
</span><span id="L-1456"><a href="#L-1456"><span class="linenos">1456</span></a>    <span class="n">group_ranks</span> <span class="o">=</span> <span class="p">[]</span>
</span><span id="L-1457"><a href="#L-1457"><span class="linenos">1457</span></a>    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_tensor_model_parallel_groups</span><span class="p">):</span>
</span><span id="L-1458"><a href="#L-1458"><span class="linenos">1458</span></a>        <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">moe_tp_size</span><span class="p">):</span>
</span><span id="L-1459"><a href="#L-1459"><span class="linenos">1459</span></a>            <span class="n">st</span> <span class="o">=</span> <span class="n">i</span> <span class="o">*</span> <span class="n">tensor_model_parallel_size</span> <span class="o">+</span> <span class="n">j</span>
</span><span id="L-1460"><a href="#L-1460"><span class="linenos">1460</span></a>            <span class="n">en</span> <span class="o">=</span> <span class="p">(</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="n">tensor_model_parallel_size</span> <span class="o">+</span> <span class="n">j</span>
</span><span id="L-1461"><a href="#L-1461"><span class="linenos">1461</span></a>            <span class="n">ranks</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">st</span><span class="p">,</span> <span class="n">en</span><span class="p">,</span> <span class="n">moe_tp_size</span><span class="p">))</span>
</span><span id="L-1462"><a href="#L-1462"><span class="linenos">1462</span></a>            <span class="n">group_ranks</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">ranks</span><span class="p">)</span>
</span><span id="L-1463"><a href="#L-1463"><span class="linenos">1463</span></a>
</span><span id="L-1464"><a href="#L-1464"><span class="linenos">1464</span></a>    <span class="n">_MOE_EP</span> <span class="o">=</span> <span class="n">init_model_parallel_group</span><span class="p">(</span>
</span><span id="L-1465"><a href="#L-1465"><span class="linenos">1465</span></a>        <span class="n">group_ranks</span><span class="p">,</span>
</span><span id="L-1466"><a href="#L-1466"><span class="linenos">1466</span></a>        <span class="n">get_world_group</span><span class="p">()</span><span class="o">.</span><span class="n">local_rank</span><span class="p">,</span>
</span><span id="L-1467"><a href="#L-1467"><span class="linenos">1467</span></a>        <span class="n">backend</span><span class="p">,</span>
</span><span id="L-1468"><a href="#L-1468"><span class="linenos">1468</span></a>        <span class="n">use_custom_allreduce</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
</span><span id="L-1469"><a href="#L-1469"><span class="linenos">1469</span></a>        <span class="n">group_name</span><span class="o">=</span><span class="s2">&quot;moe_ep&quot;</span><span class="p">,</span>
</span><span id="L-1470"><a href="#L-1470"><span class="linenos">1470</span></a>    <span class="p">)</span>
</span><span id="L-1471"><a href="#L-1471"><span class="linenos">1471</span></a>
</span><span id="L-1472"><a href="#L-1472"><span class="linenos">1472</span></a>    <span class="k">global</span> <span class="n">_MOE_TP</span>
</span><span id="L-1473"><a href="#L-1473"><span class="linenos">1473</span></a>    <span class="k">assert</span> <span class="n">_MOE_TP</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">,</span> <span class="s2">&quot;expert model parallel group is already initialized&quot;</span>
</span><span id="L-1474"><a href="#L-1474"><span class="linenos">1474</span></a>    <span class="n">group_ranks</span> <span class="o">=</span> <span class="p">[]</span>
</span><span id="L-1475"><a href="#L-1475"><span class="linenos">1475</span></a>    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_tensor_model_parallel_groups</span><span class="p">):</span>
</span><span id="L-1476"><a href="#L-1476"><span class="linenos">1476</span></a>        <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">moe_ep_size</span><span class="p">):</span>
</span><span id="L-1477"><a href="#L-1477"><span class="linenos">1477</span></a>            <span class="n">st</span> <span class="o">=</span> <span class="n">i</span> <span class="o">*</span> <span class="n">tensor_model_parallel_size</span> <span class="o">+</span> <span class="n">j</span> <span class="o">*</span> <span class="n">moe_tp_size</span>
</span><span id="L-1478"><a href="#L-1478"><span class="linenos">1478</span></a>            <span class="n">en</span> <span class="o">=</span> <span class="n">i</span> <span class="o">*</span> <span class="n">tensor_model_parallel_size</span> <span class="o">+</span> <span class="p">(</span><span class="n">j</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="n">moe_tp_size</span>
</span><span id="L-1479"><a href="#L-1479"><span class="linenos">1479</span></a>            <span class="n">ranks</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">st</span><span class="p">,</span> <span class="n">en</span><span class="p">))</span>
</span><span id="L-1480"><a href="#L-1480"><span class="linenos">1480</span></a>            <span class="n">group_ranks</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">ranks</span><span class="p">)</span>
</span><span id="L-1481"><a href="#L-1481"><span class="linenos">1481</span></a>
</span><span id="L-1482"><a href="#L-1482"><span class="linenos">1482</span></a>    <span class="n">_MOE_TP</span> <span class="o">=</span> <span class="n">init_model_parallel_group</span><span class="p">(</span>
</span><span id="L-1483"><a href="#L-1483"><span class="linenos">1483</span></a>        <span class="n">group_ranks</span><span class="p">,</span>
</span><span id="L-1484"><a href="#L-1484"><span class="linenos">1484</span></a>        <span class="n">get_world_group</span><span class="p">()</span><span class="o">.</span><span class="n">local_rank</span><span class="p">,</span>
</span><span id="L-1485"><a href="#L-1485"><span class="linenos">1485</span></a>        <span class="n">backend</span><span class="p">,</span>
</span><span id="L-1486"><a href="#L-1486"><span class="linenos">1486</span></a>        <span class="n">use_custom_allreduce</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
</span><span id="L-1487"><a href="#L-1487"><span class="linenos">1487</span></a>        <span class="n">group_name</span><span class="o">=</span><span class="s2">&quot;moe_tp&quot;</span><span class="p">,</span>
</span><span id="L-1488"><a href="#L-1488"><span class="linenos">1488</span></a>    <span class="p">)</span>
</span><span id="L-1489"><a href="#L-1489"><span class="linenos">1489</span></a>
</span><span id="L-1490"><a href="#L-1490"><span class="linenos">1490</span></a>    <span class="c1"># Build the pipeline model-parallel groups.</span>
</span><span id="L-1491"><a href="#L-1491"><span class="linenos">1491</span></a>    <span class="n">num_pipeline_model_parallel_groups</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="n">world_size</span> <span class="o">//</span> <span class="n">pipeline_model_parallel_size</span>
</span><span id="L-1492"><a href="#L-1492"><span class="linenos">1492</span></a>    <span class="k">global</span> <span class="n">_PP</span>
</span><span id="L-1493"><a href="#L-1493"><span class="linenos">1493</span></a>    <span class="k">assert</span> <span class="n">_PP</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">,</span> <span class="s2">&quot;pipeline model parallel group is already initialized&quot;</span>
</span><span id="L-1494"><a href="#L-1494"><span class="linenos">1494</span></a>    <span class="n">group_ranks</span> <span class="o">=</span> <span class="p">[]</span>
</span><span id="L-1495"><a href="#L-1495"><span class="linenos">1495</span></a>    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_pipeline_model_parallel_groups</span><span class="p">):</span>
</span><span id="L-1496"><a href="#L-1496"><span class="linenos">1496</span></a>        <span class="n">ranks</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">world_size</span><span class="p">,</span> <span class="n">num_pipeline_model_parallel_groups</span><span class="p">))</span>
</span><span id="L-1497"><a href="#L-1497"><span class="linenos">1497</span></a>        <span class="n">group_ranks</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">ranks</span><span class="p">)</span>
</span><span id="L-1498"><a href="#L-1498"><span class="linenos">1498</span></a>    <span class="c1"># pipeline parallel does not need custom allreduce</span>
</span><span id="L-1499"><a href="#L-1499"><span class="linenos">1499</span></a>    <span class="n">_PP</span> <span class="o">=</span> <span class="n">init_model_parallel_group</span><span class="p">(</span>
</span><span id="L-1500"><a href="#L-1500"><span class="linenos">1500</span></a>        <span class="n">group_ranks</span><span class="p">,</span>
</span><span id="L-1501"><a href="#L-1501"><span class="linenos">1501</span></a>        <span class="n">get_world_group</span><span class="p">()</span><span class="o">.</span><span class="n">local_rank</span><span class="p">,</span>
</span><span id="L-1502"><a href="#L-1502"><span class="linenos">1502</span></a>        <span class="n">backend</span><span class="p">,</span>
</span><span id="L-1503"><a href="#L-1503"><span class="linenos">1503</span></a>        <span class="n">use_custom_allreduce</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
</span><span id="L-1504"><a href="#L-1504"><span class="linenos">1504</span></a>        <span class="n">group_name</span><span class="o">=</span><span class="s2">&quot;pp&quot;</span><span class="p">,</span>
</span><span id="L-1505"><a href="#L-1505"><span class="linenos">1505</span></a>    <span class="p">)</span>
</span><span id="L-1506"><a href="#L-1506"><span class="linenos">1506</span></a>
</span><span id="L-1507"><a href="#L-1507"><span class="linenos">1507</span></a>
</span><span id="L-1508"><a href="#L-1508"><span class="linenos">1508</span></a><span class="k">def</span><span class="w"> </span><span class="nf">ensure_model_parallel_initialized</span><span class="p">(</span>
</span><span id="L-1509"><a href="#L-1509"><span class="linenos">1509</span></a>    <span class="n">tensor_model_parallel_size</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
</span><span id="L-1510"><a href="#L-1510"><span class="linenos">1510</span></a>    <span class="n">expert_model_parallel_size</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
</span><span id="L-1511"><a href="#L-1511"><span class="linenos">1511</span></a>    <span class="n">pipeline_model_parallel_size</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
</span><span id="L-1512"><a href="#L-1512"><span class="linenos">1512</span></a>    <span class="n">backend</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="L-1513"><a href="#L-1513"><span class="linenos">1513</span></a><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="L-1514"><a href="#L-1514"><span class="linenos">1514</span></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;Helper to initialize model parallel groups if they are not initialized,</span>
</span><span id="L-1515"><a href="#L-1515"><span class="linenos">1515</span></a><span class="sd">    or ensure tensor-parallel and pipeline-parallel sizes are equal to expected</span>
</span><span id="L-1516"><a href="#L-1516"><span class="linenos">1516</span></a><span class="sd">    values if the model parallel groups are initialized.</span>
</span><span id="L-1517"><a href="#L-1517"><span class="linenos">1517</span></a><span class="sd">    &quot;&quot;&quot;</span>
</span><span id="L-1518"><a href="#L-1518"><span class="linenos">1518</span></a>    <span class="n">backend</span> <span class="o">=</span> <span class="n">backend</span> <span class="ow">or</span> <span class="n">torch</span><span class="o">.</span><span class="n">distributed</span><span class="o">.</span><span class="n">get_backend</span><span class="p">(</span><span class="n">get_world_group</span><span class="p">()</span><span class="o">.</span><span class="n">device_group</span><span class="p">)</span>
</span><span id="L-1519"><a href="#L-1519"><span class="linenos">1519</span></a>    <span class="k">if</span> <span class="ow">not</span> <span class="n">model_parallel_is_initialized</span><span class="p">():</span>
</span><span id="L-1520"><a href="#L-1520"><span class="linenos">1520</span></a>        <span class="n">initialize_model_parallel</span><span class="p">(</span>
</span><span id="L-1521"><a href="#L-1521"><span class="linenos">1521</span></a>            <span class="n">tensor_model_parallel_size</span><span class="p">,</span>
</span><span id="L-1522"><a href="#L-1522"><span class="linenos">1522</span></a>            <span class="n">expert_model_parallel_size</span><span class="p">,</span>
</span><span id="L-1523"><a href="#L-1523"><span class="linenos">1523</span></a>            <span class="n">pipeline_model_parallel_size</span><span class="p">,</span>
</span><span id="L-1524"><a href="#L-1524"><span class="linenos">1524</span></a>            <span class="n">backend</span><span class="p">,</span>
</span><span id="L-1525"><a href="#L-1525"><span class="linenos">1525</span></a>        <span class="p">)</span>
</span><span id="L-1526"><a href="#L-1526"><span class="linenos">1526</span></a>        <span class="k">return</span>
</span><span id="L-1527"><a href="#L-1527"><span class="linenos">1527</span></a>
</span><span id="L-1528"><a href="#L-1528"><span class="linenos">1528</span></a>    <span class="k">assert</span> <span class="n">get_tensor_model_parallel_world_size</span><span class="p">()</span> <span class="o">==</span> <span class="n">tensor_model_parallel_size</span><span class="p">,</span> <span class="p">(</span>
</span><span id="L-1529"><a href="#L-1529"><span class="linenos">1529</span></a>        <span class="s2">&quot;tensor parallel group already initialized, but of unexpected size: &quot;</span>
</span><span id="L-1530"><a href="#L-1530"><span class="linenos">1530</span></a>        <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">get_tensor_model_parallel_world_size</span><span class="p">()</span><span class="si">=}</span><span class="s2"> vs. &quot;</span>
</span><span id="L-1531"><a href="#L-1531"><span class="linenos">1531</span></a>        <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">tensor_model_parallel_size</span><span class="si">=}</span><span class="s2">&quot;</span>
</span><span id="L-1532"><a href="#L-1532"><span class="linenos">1532</span></a>    <span class="p">)</span>
</span><span id="L-1533"><a href="#L-1533"><span class="linenos">1533</span></a>    <span class="n">pp_world_size</span> <span class="o">=</span> <span class="n">get_pp_group</span><span class="p">()</span><span class="o">.</span><span class="n">world_size</span>
</span><span id="L-1534"><a href="#L-1534"><span class="linenos">1534</span></a>    <span class="k">assert</span> <span class="n">pp_world_size</span> <span class="o">==</span> <span class="n">pipeline_model_parallel_size</span><span class="p">,</span> <span class="p">(</span>
</span><span id="L-1535"><a href="#L-1535"><span class="linenos">1535</span></a>        <span class="s2">&quot;pipeline parallel group already initialized, but of unexpected size: &quot;</span>
</span><span id="L-1536"><a href="#L-1536"><span class="linenos">1536</span></a>        <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">pp_world_size</span><span class="si">=}</span><span class="s2"> vs. &quot;</span>
</span><span id="L-1537"><a href="#L-1537"><span class="linenos">1537</span></a>        <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">pipeline_model_parallel_size</span><span class="si">=}</span><span class="s2">&quot;</span>
</span><span id="L-1538"><a href="#L-1538"><span class="linenos">1538</span></a>    <span class="p">)</span>
</span><span id="L-1539"><a href="#L-1539"><span class="linenos">1539</span></a>
</span><span id="L-1540"><a href="#L-1540"><span class="linenos">1540</span></a>
</span><span id="L-1541"><a href="#L-1541"><span class="linenos">1541</span></a><span class="k">def</span><span class="w"> </span><span class="nf">model_parallel_is_initialized</span><span class="p">():</span>
</span><span id="L-1542"><a href="#L-1542"><span class="linenos">1542</span></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;Check if tensor and pipeline parallel groups are initialized.&quot;&quot;&quot;</span>
</span><span id="L-1543"><a href="#L-1543"><span class="linenos">1543</span></a>    <span class="k">return</span> <span class="n">_TP</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">_PP</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
</span><span id="L-1544"><a href="#L-1544"><span class="linenos">1544</span></a>
</span><span id="L-1545"><a href="#L-1545"><span class="linenos">1545</span></a>
</span><span id="L-1546"><a href="#L-1546"><span class="linenos">1546</span></a><span class="n">_TP_STATE_PATCHED</span> <span class="o">=</span> <span class="kc">False</span>
</span><span id="L-1547"><a href="#L-1547"><span class="linenos">1547</span></a>
</span><span id="L-1548"><a href="#L-1548"><span class="linenos">1548</span></a>
</span><span id="L-1549"><a href="#L-1549"><span class="linenos">1549</span></a><span class="nd">@contextmanager</span>
</span><span id="L-1550"><a href="#L-1550"><span class="linenos">1550</span></a><span class="k">def</span><span class="w"> </span><span class="nf">patch_tensor_parallel_group</span><span class="p">(</span><span class="n">tp_group</span><span class="p">:</span> <span class="n">GroupCoordinator</span><span class="p">):</span>
</span><span id="L-1551"><a href="#L-1551"><span class="linenos">1551</span></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;Patch the tp group temporarily until this function ends.</span>
</span><span id="L-1552"><a href="#L-1552"><span class="linenos">1552</span></a>
</span><span id="L-1553"><a href="#L-1553"><span class="linenos">1553</span></a><span class="sd">    This method is for draft workers of speculative decoding to run draft model</span>
</span><span id="L-1554"><a href="#L-1554"><span class="linenos">1554</span></a><span class="sd">    with different tp degree from that of target model workers.</span>
</span><span id="L-1555"><a href="#L-1555"><span class="linenos">1555</span></a>
</span><span id="L-1556"><a href="#L-1556"><span class="linenos">1556</span></a><span class="sd">    Args:</span>
</span><span id="L-1557"><a href="#L-1557"><span class="linenos">1557</span></a><span class="sd">        tp_group (GroupCoordinator): the tp group coordinator</span>
</span><span id="L-1558"><a href="#L-1558"><span class="linenos">1558</span></a><span class="sd">    &quot;&quot;&quot;</span>
</span><span id="L-1559"><a href="#L-1559"><span class="linenos">1559</span></a>    <span class="k">global</span> <span class="n">_TP_STATE_PATCHED</span>
</span><span id="L-1560"><a href="#L-1560"><span class="linenos">1560</span></a>    <span class="k">assert</span> <span class="ow">not</span> <span class="n">_TP_STATE_PATCHED</span><span class="p">,</span> <span class="s2">&quot;Should not call when it&#39;s already patched&quot;</span>
</span><span id="L-1561"><a href="#L-1561"><span class="linenos">1561</span></a>
</span><span id="L-1562"><a href="#L-1562"><span class="linenos">1562</span></a>    <span class="n">_TP_STATE_PATCHED</span> <span class="o">=</span> <span class="kc">True</span>
</span><span id="L-1563"><a href="#L-1563"><span class="linenos">1563</span></a>    <span class="n">old_tp_group</span> <span class="o">=</span> <span class="n">get_tp_group</span><span class="p">()</span>
</span><span id="L-1564"><a href="#L-1564"><span class="linenos">1564</span></a>    <span class="k">global</span> <span class="n">_TP</span>
</span><span id="L-1565"><a href="#L-1565"><span class="linenos">1565</span></a>    <span class="n">_TP</span> <span class="o">=</span> <span class="n">tp_group</span>
</span><span id="L-1566"><a href="#L-1566"><span class="linenos">1566</span></a>    <span class="k">try</span><span class="p">:</span>
</span><span id="L-1567"><a href="#L-1567"><span class="linenos">1567</span></a>        <span class="k">yield</span>
</span><span id="L-1568"><a href="#L-1568"><span class="linenos">1568</span></a>    <span class="k">finally</span><span class="p">:</span>
</span><span id="L-1569"><a href="#L-1569"><span class="linenos">1569</span></a>        <span class="c1"># restore the original state</span>
</span><span id="L-1570"><a href="#L-1570"><span class="linenos">1570</span></a>        <span class="n">_TP_STATE_PATCHED</span> <span class="o">=</span> <span class="kc">False</span>
</span><span id="L-1571"><a href="#L-1571"><span class="linenos">1571</span></a>        <span class="n">_TP</span> <span class="o">=</span> <span class="n">old_tp_group</span>
</span><span id="L-1572"><a href="#L-1572"><span class="linenos">1572</span></a>
</span><span id="L-1573"><a href="#L-1573"><span class="linenos">1573</span></a>
</span><span id="L-1574"><a href="#L-1574"><span class="linenos">1574</span></a><span class="k">def</span><span class="w"> </span><span class="nf">get_tensor_model_parallel_world_size</span><span class="p">():</span>
</span><span id="L-1575"><a href="#L-1575"><span class="linenos">1575</span></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;Return world size for the tensor model parallel group.&quot;&quot;&quot;</span>
</span><span id="L-1576"><a href="#L-1576"><span class="linenos">1576</span></a>    <span class="k">return</span> <span class="n">get_tp_group</span><span class="p">()</span><span class="o">.</span><span class="n">world_size</span>
</span><span id="L-1577"><a href="#L-1577"><span class="linenos">1577</span></a>
</span><span id="L-1578"><a href="#L-1578"><span class="linenos">1578</span></a>
</span><span id="L-1579"><a href="#L-1579"><span class="linenos">1579</span></a><span class="k">def</span><span class="w"> </span><span class="nf">get_tensor_model_parallel_rank</span><span class="p">():</span>
</span><span id="L-1580"><a href="#L-1580"><span class="linenos">1580</span></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;Return my rank for the tensor model parallel group.&quot;&quot;&quot;</span>
</span><span id="L-1581"><a href="#L-1581"><span class="linenos">1581</span></a>    <span class="k">return</span> <span class="n">get_tp_group</span><span class="p">()</span><span class="o">.</span><span class="n">rank_in_group</span>
</span><span id="L-1582"><a href="#L-1582"><span class="linenos">1582</span></a>
</span><span id="L-1583"><a href="#L-1583"><span class="linenos">1583</span></a>
</span><span id="L-1584"><a href="#L-1584"><span class="linenos">1584</span></a><span class="k">def</span><span class="w"> </span><span class="nf">get_moe_expert_parallel_world_size</span><span class="p">():</span>
</span><span id="L-1585"><a href="#L-1585"><span class="linenos">1585</span></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;Return world size for the moe expert parallel group.&quot;&quot;&quot;</span>
</span><span id="L-1586"><a href="#L-1586"><span class="linenos">1586</span></a>    <span class="k">return</span> <span class="n">get_moe_ep_group</span><span class="p">()</span><span class="o">.</span><span class="n">world_size</span>
</span><span id="L-1587"><a href="#L-1587"><span class="linenos">1587</span></a>
</span><span id="L-1588"><a href="#L-1588"><span class="linenos">1588</span></a>
</span><span id="L-1589"><a href="#L-1589"><span class="linenos">1589</span></a><span class="k">def</span><span class="w"> </span><span class="nf">get_moe_expert_parallel_rank</span><span class="p">():</span>
</span><span id="L-1590"><a href="#L-1590"><span class="linenos">1590</span></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;Return my rank for the moe expert parallel group.&quot;&quot;&quot;</span>
</span><span id="L-1591"><a href="#L-1591"><span class="linenos">1591</span></a>    <span class="k">return</span> <span class="n">get_moe_ep_group</span><span class="p">()</span><span class="o">.</span><span class="n">rank_in_group</span>
</span><span id="L-1592"><a href="#L-1592"><span class="linenos">1592</span></a>
</span><span id="L-1593"><a href="#L-1593"><span class="linenos">1593</span></a>
</span><span id="L-1594"><a href="#L-1594"><span class="linenos">1594</span></a><span class="k">def</span><span class="w"> </span><span class="nf">get_moe_tensor_parallel_world_size</span><span class="p">():</span>
</span><span id="L-1595"><a href="#L-1595"><span class="linenos">1595</span></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;Return world size for the moe tensor parallel group.&quot;&quot;&quot;</span>
</span><span id="L-1596"><a href="#L-1596"><span class="linenos">1596</span></a>    <span class="k">return</span> <span class="n">get_moe_tp_group</span><span class="p">()</span><span class="o">.</span><span class="n">world_size</span>
</span><span id="L-1597"><a href="#L-1597"><span class="linenos">1597</span></a>
</span><span id="L-1598"><a href="#L-1598"><span class="linenos">1598</span></a>
</span><span id="L-1599"><a href="#L-1599"><span class="linenos">1599</span></a><span class="k">def</span><span class="w"> </span><span class="nf">get_moe_tensor_parallel_rank</span><span class="p">():</span>
</span><span id="L-1600"><a href="#L-1600"><span class="linenos">1600</span></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;Return my rank for the moe tensor parallel group.&quot;&quot;&quot;</span>
</span><span id="L-1601"><a href="#L-1601"><span class="linenos">1601</span></a>    <span class="k">return</span> <span class="n">get_moe_tp_group</span><span class="p">()</span><span class="o">.</span><span class="n">rank_in_group</span>
</span><span id="L-1602"><a href="#L-1602"><span class="linenos">1602</span></a>
</span><span id="L-1603"><a href="#L-1603"><span class="linenos">1603</span></a>
</span><span id="L-1604"><a href="#L-1604"><span class="linenos">1604</span></a><span class="k">def</span><span class="w"> </span><span class="nf">destroy_model_parallel</span><span class="p">():</span>
</span><span id="L-1605"><a href="#L-1605"><span class="linenos">1605</span></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;Set the groups to none and destroy them.&quot;&quot;&quot;</span>
</span><span id="L-1606"><a href="#L-1606"><span class="linenos">1606</span></a>    <span class="k">global</span> <span class="n">_TP</span>
</span><span id="L-1607"><a href="#L-1607"><span class="linenos">1607</span></a>    <span class="k">if</span> <span class="n">_TP</span><span class="p">:</span>
</span><span id="L-1608"><a href="#L-1608"><span class="linenos">1608</span></a>        <span class="n">_TP</span><span class="o">.</span><span class="n">destroy</span><span class="p">()</span>
</span><span id="L-1609"><a href="#L-1609"><span class="linenos">1609</span></a>    <span class="n">_TP</span> <span class="o">=</span> <span class="kc">None</span>
</span><span id="L-1610"><a href="#L-1610"><span class="linenos">1610</span></a>
</span><span id="L-1611"><a href="#L-1611"><span class="linenos">1611</span></a>    <span class="k">global</span> <span class="n">_PP</span>
</span><span id="L-1612"><a href="#L-1612"><span class="linenos">1612</span></a>    <span class="k">if</span> <span class="n">_PP</span><span class="p">:</span>
</span><span id="L-1613"><a href="#L-1613"><span class="linenos">1613</span></a>        <span class="n">_PP</span><span class="o">.</span><span class="n">destroy</span><span class="p">()</span>
</span><span id="L-1614"><a href="#L-1614"><span class="linenos">1614</span></a>    <span class="n">_PP</span> <span class="o">=</span> <span class="kc">None</span>
</span><span id="L-1615"><a href="#L-1615"><span class="linenos">1615</span></a>
</span><span id="L-1616"><a href="#L-1616"><span class="linenos">1616</span></a>
</span><span id="L-1617"><a href="#L-1617"><span class="linenos">1617</span></a><span class="k">def</span><span class="w"> </span><span class="nf">destroy_distributed_environment</span><span class="p">():</span>
</span><span id="L-1618"><a href="#L-1618"><span class="linenos">1618</span></a>    <span class="k">global</span> <span class="n">_WORLD</span>
</span><span id="L-1619"><a href="#L-1619"><span class="linenos">1619</span></a>    <span class="k">if</span> <span class="n">_WORLD</span><span class="p">:</span>
</span><span id="L-1620"><a href="#L-1620"><span class="linenos">1620</span></a>        <span class="n">_WORLD</span><span class="o">.</span><span class="n">destroy</span><span class="p">()</span>
</span><span id="L-1621"><a href="#L-1621"><span class="linenos">1621</span></a>    <span class="n">_WORLD</span> <span class="o">=</span> <span class="kc">None</span>
</span><span id="L-1622"><a href="#L-1622"><span class="linenos">1622</span></a>    <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">distributed</span><span class="o">.</span><span class="n">is_initialized</span><span class="p">():</span>
</span><span id="L-1623"><a href="#L-1623"><span class="linenos">1623</span></a>        <span class="n">torch</span><span class="o">.</span><span class="n">distributed</span><span class="o">.</span><span class="n">destroy_process_group</span><span class="p">()</span>
</span><span id="L-1624"><a href="#L-1624"><span class="linenos">1624</span></a>
</span><span id="L-1625"><a href="#L-1625"><span class="linenos">1625</span></a>
</span><span id="L-1626"><a href="#L-1626"><span class="linenos">1626</span></a><span class="k">def</span><span class="w"> </span><span class="nf">cleanup_dist_env_and_memory</span><span class="p">(</span><span class="n">shutdown_ray</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">):</span>
</span><span id="L-1627"><a href="#L-1627"><span class="linenos">1627</span></a>    <span class="n">destroy_model_parallel</span><span class="p">()</span>
</span><span id="L-1628"><a href="#L-1628"><span class="linenos">1628</span></a>    <span class="n">destroy_distributed_environment</span><span class="p">()</span>
</span><span id="L-1629"><a href="#L-1629"><span class="linenos">1629</span></a>    <span class="k">with</span> <span class="n">contextlib</span><span class="o">.</span><span class="n">suppress</span><span class="p">(</span><span class="ne">AssertionError</span><span class="p">):</span>
</span><span id="L-1630"><a href="#L-1630"><span class="linenos">1630</span></a>        <span class="n">torch</span><span class="o">.</span><span class="n">distributed</span><span class="o">.</span><span class="n">destroy_process_group</span><span class="p">()</span>
</span><span id="L-1631"><a href="#L-1631"><span class="linenos">1631</span></a>    <span class="k">if</span> <span class="n">shutdown_ray</span><span class="p">:</span>
</span><span id="L-1632"><a href="#L-1632"><span class="linenos">1632</span></a>        <span class="kn">import</span><span class="w"> </span><span class="nn">ray</span>  <span class="c1"># Lazy import Ray</span>
</span><span id="L-1633"><a href="#L-1633"><span class="linenos">1633</span></a>
</span><span id="L-1634"><a href="#L-1634"><span class="linenos">1634</span></a>        <span class="n">ray</span><span class="o">.</span><span class="n">shutdown</span><span class="p">()</span>
</span><span id="L-1635"><a href="#L-1635"><span class="linenos">1635</span></a>    <span class="n">gc</span><span class="o">.</span><span class="n">collect</span><span class="p">()</span>
</span><span id="L-1636"><a href="#L-1636"><span class="linenos">1636</span></a>    <span class="k">if</span> <span class="ow">not</span> <span class="n">current_platform</span><span class="o">.</span><span class="n">is_cpu</span><span class="p">():</span>
</span><span id="L-1637"><a href="#L-1637"><span class="linenos">1637</span></a>        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">torch</span><span class="p">,</span> <span class="s2">&quot;cuda&quot;</span><span class="p">)</span> <span class="ow">and</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">():</span>
</span><span id="L-1638"><a href="#L-1638"><span class="linenos">1638</span></a>            <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">empty_cache</span><span class="p">()</span>
</span><span id="L-1639"><a href="#L-1639"><span class="linenos">1639</span></a>            <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">_C</span><span class="p">,</span> <span class="s2">&quot;_host_emptyCache&quot;</span><span class="p">):</span>
</span><span id="L-1640"><a href="#L-1640"><span class="linenos">1640</span></a>                <span class="n">torch</span><span class="o">.</span><span class="n">_C</span><span class="o">.</span><span class="n">_host_emptyCache</span><span class="p">()</span>
</span><span id="L-1641"><a href="#L-1641"><span class="linenos">1641</span></a>            <span class="k">else</span><span class="p">:</span>
</span><span id="L-1642"><a href="#L-1642"><span class="linenos">1642</span></a>                <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span>
</span><span id="L-1643"><a href="#L-1643"><span class="linenos">1643</span></a>                    <span class="s2">&quot;torch._C._host_emptyCache() only available in Pytorch &gt;=2.5&quot;</span>
</span><span id="L-1644"><a href="#L-1644"><span class="linenos">1644</span></a>                <span class="p">)</span>
</span><span id="L-1645"><a href="#L-1645"><span class="linenos">1645</span></a>        <span class="k">elif</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">torch</span><span class="p">,</span> <span class="s2">&quot;xpu&quot;</span><span class="p">)</span> <span class="ow">and</span> <span class="n">torch</span><span class="o">.</span><span class="n">xpu</span><span class="o">.</span><span class="n">is_available</span><span class="p">():</span>
</span><span id="L-1646"><a href="#L-1646"><span class="linenos">1646</span></a>            <span class="n">torch</span><span class="o">.</span><span class="n">xpu</span><span class="o">.</span><span class="n">empty_cache</span><span class="p">()</span>
</span><span id="L-1647"><a href="#L-1647"><span class="linenos">1647</span></a>        <span class="k">elif</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">torch</span><span class="p">,</span> <span class="s2">&quot;npu&quot;</span><span class="p">)</span> <span class="ow">and</span> <span class="n">torch</span><span class="o">.</span><span class="n">npu</span><span class="o">.</span><span class="n">is_available</span><span class="p">():</span>
</span><span id="L-1648"><a href="#L-1648"><span class="linenos">1648</span></a>            <span class="n">torch</span><span class="o">.</span><span class="n">npu</span><span class="o">.</span><span class="n">empty_cache</span><span class="p">()</span>
</span><span id="L-1649"><a href="#L-1649"><span class="linenos">1649</span></a>
</span><span id="L-1650"><a href="#L-1650"><span class="linenos">1650</span></a>
</span><span id="L-1651"><a href="#L-1651"><span class="linenos">1651</span></a><span class="k">def</span><span class="w"> </span><span class="nf">in_the_same_node_as</span><span class="p">(</span><span class="n">pg</span><span class="p">:</span> <span class="n">ProcessGroup</span><span class="p">,</span> <span class="n">source_rank</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="nb">bool</span><span class="p">]:</span>
</span><span id="L-1652"><a href="#L-1652"><span class="linenos">1652</span></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="L-1653"><a href="#L-1653"><span class="linenos">1653</span></a><span class="sd">    This is a collective operation that returns if each rank is in the same node</span>
</span><span id="L-1654"><a href="#L-1654"><span class="linenos">1654</span></a><span class="sd">    as the source rank. It tests if processes are attached to the same</span>
</span><span id="L-1655"><a href="#L-1655"><span class="linenos">1655</span></a><span class="sd">    memory system (shared access to shared memory).</span>
</span><span id="L-1656"><a href="#L-1656"><span class="linenos">1656</span></a><span class="sd">    &quot;&quot;&quot;</span>
</span><span id="L-1657"><a href="#L-1657"><span class="linenos">1657</span></a>    <span class="k">assert</span> <span class="p">(</span>
</span><span id="L-1658"><a href="#L-1658"><span class="linenos">1658</span></a>        <span class="n">torch</span><span class="o">.</span><span class="n">distributed</span><span class="o">.</span><span class="n">get_backend</span><span class="p">(</span><span class="n">pg</span><span class="p">)</span> <span class="o">!=</span> <span class="n">torch</span><span class="o">.</span><span class="n">distributed</span><span class="o">.</span><span class="n">Backend</span><span class="o">.</span><span class="n">NCCL</span>
</span><span id="L-1659"><a href="#L-1659"><span class="linenos">1659</span></a>    <span class="p">),</span> <span class="s2">&quot;in_the_same_node_as should be tested with a non-NCCL group.&quot;</span>
</span><span id="L-1660"><a href="#L-1660"><span class="linenos">1660</span></a>    <span class="c1"># local rank inside the group</span>
</span><span id="L-1661"><a href="#L-1661"><span class="linenos">1661</span></a>    <span class="n">rank</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">distributed</span><span class="o">.</span><span class="n">get_rank</span><span class="p">(</span><span class="n">group</span><span class="o">=</span><span class="n">pg</span><span class="p">)</span>
</span><span id="L-1662"><a href="#L-1662"><span class="linenos">1662</span></a>    <span class="n">world_size</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">distributed</span><span class="o">.</span><span class="n">get_world_size</span><span class="p">(</span><span class="n">group</span><span class="o">=</span><span class="n">pg</span><span class="p">)</span>
</span><span id="L-1663"><a href="#L-1663"><span class="linenos">1663</span></a>
</span><span id="L-1664"><a href="#L-1664"><span class="linenos">1664</span></a>    <span class="c1"># local tensor in each process to store the result</span>
</span><span id="L-1665"><a href="#L-1665"><span class="linenos">1665</span></a>    <span class="n">is_in_the_same_node</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mi">0</span><span class="p">]</span> <span class="o">*</span> <span class="n">world_size</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
</span><span id="L-1666"><a href="#L-1666"><span class="linenos">1666</span></a>
</span><span id="L-1667"><a href="#L-1667"><span class="linenos">1667</span></a>    <span class="c1"># global ranks of the processes in the group</span>
</span><span id="L-1668"><a href="#L-1668"><span class="linenos">1668</span></a>    <span class="n">ranks</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">distributed</span><span class="o">.</span><span class="n">get_process_group_ranks</span><span class="p">(</span><span class="n">pg</span><span class="p">)</span>
</span><span id="L-1669"><a href="#L-1669"><span class="linenos">1669</span></a>
</span><span id="L-1670"><a href="#L-1670"><span class="linenos">1670</span></a>    <span class="n">magic_message</span> <span class="o">=</span> <span class="sa">b</span><span class="s2">&quot;magic_message&quot;</span>
</span><span id="L-1671"><a href="#L-1671"><span class="linenos">1671</span></a>    <span class="n">shm</span> <span class="o">=</span> <span class="kc">None</span>
</span><span id="L-1672"><a href="#L-1672"><span class="linenos">1672</span></a>
</span><span id="L-1673"><a href="#L-1673"><span class="linenos">1673</span></a>    <span class="k">try</span><span class="p">:</span>
</span><span id="L-1674"><a href="#L-1674"><span class="linenos">1674</span></a>        <span class="k">with</span> <span class="n">contextlib</span><span class="o">.</span><span class="n">suppress</span><span class="p">(</span><span class="ne">OSError</span><span class="p">):</span>
</span><span id="L-1675"><a href="#L-1675"><span class="linenos">1675</span></a>            <span class="k">if</span> <span class="n">rank</span> <span class="o">==</span> <span class="n">source_rank</span><span class="p">:</span>
</span><span id="L-1676"><a href="#L-1676"><span class="linenos">1676</span></a>                <span class="c1"># create a shared memory segment</span>
</span><span id="L-1677"><a href="#L-1677"><span class="linenos">1677</span></a>                <span class="n">shm</span> <span class="o">=</span> <span class="n">shared_memory</span><span class="o">.</span><span class="n">SharedMemory</span><span class="p">(</span><span class="n">create</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="mi">128</span><span class="p">)</span>
</span><span id="L-1678"><a href="#L-1678"><span class="linenos">1678</span></a>                <span class="n">shm</span><span class="o">.</span><span class="n">buf</span><span class="p">[:</span> <span class="nb">len</span><span class="p">(</span><span class="n">magic_message</span><span class="p">)]</span> <span class="o">=</span> <span class="n">magic_message</span>
</span><span id="L-1679"><a href="#L-1679"><span class="linenos">1679</span></a>                <span class="n">torch</span><span class="o">.</span><span class="n">distributed</span><span class="o">.</span><span class="n">broadcast_object_list</span><span class="p">(</span>
</span><span id="L-1680"><a href="#L-1680"><span class="linenos">1680</span></a>                    <span class="p">[</span><span class="n">shm</span><span class="o">.</span><span class="n">name</span><span class="p">],</span> <span class="n">src</span><span class="o">=</span><span class="n">ranks</span><span class="p">[</span><span class="n">source_rank</span><span class="p">],</span> <span class="n">group</span><span class="o">=</span><span class="n">pg</span>
</span><span id="L-1681"><a href="#L-1681"><span class="linenos">1681</span></a>                <span class="p">)</span>
</span><span id="L-1682"><a href="#L-1682"><span class="linenos">1682</span></a>                <span class="n">is_in_the_same_node</span><span class="p">[</span><span class="n">rank</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>
</span><span id="L-1683"><a href="#L-1683"><span class="linenos">1683</span></a>            <span class="k">else</span><span class="p">:</span>
</span><span id="L-1684"><a href="#L-1684"><span class="linenos">1684</span></a>                <span class="c1"># try to open the shared memory segment</span>
</span><span id="L-1685"><a href="#L-1685"><span class="linenos">1685</span></a>                <span class="n">recv</span> <span class="o">=</span> <span class="p">[</span><span class="kc">None</span><span class="p">]</span>
</span><span id="L-1686"><a href="#L-1686"><span class="linenos">1686</span></a>                <span class="n">torch</span><span class="o">.</span><span class="n">distributed</span><span class="o">.</span><span class="n">broadcast_object_list</span><span class="p">(</span>
</span><span id="L-1687"><a href="#L-1687"><span class="linenos">1687</span></a>                    <span class="n">recv</span><span class="p">,</span> <span class="n">src</span><span class="o">=</span><span class="n">ranks</span><span class="p">[</span><span class="n">source_rank</span><span class="p">],</span> <span class="n">group</span><span class="o">=</span><span class="n">pg</span>
</span><span id="L-1688"><a href="#L-1688"><span class="linenos">1688</span></a>                <span class="p">)</span>
</span><span id="L-1689"><a href="#L-1689"><span class="linenos">1689</span></a>                <span class="n">name</span> <span class="o">=</span> <span class="n">recv</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
</span><span id="L-1690"><a href="#L-1690"><span class="linenos">1690</span></a>                <span class="c1"># fix to https://stackoverflow.com/q/62748654/9191338</span>
</span><span id="L-1691"><a href="#L-1691"><span class="linenos">1691</span></a>                <span class="c1"># Python incorrectly tracks shared memory even if it is not</span>
</span><span id="L-1692"><a href="#L-1692"><span class="linenos">1692</span></a>                <span class="c1"># created by the process. The following patch is a workaround.</span>
</span><span id="L-1693"><a href="#L-1693"><span class="linenos">1693</span></a>                <span class="k">with</span> <span class="n">patch</span><span class="p">(</span>
</span><span id="L-1694"><a href="#L-1694"><span class="linenos">1694</span></a>                    <span class="s2">&quot;multiprocessing.resource_tracker.register&quot;</span><span class="p">,</span>
</span><span id="L-1695"><a href="#L-1695"><span class="linenos">1695</span></a>                    <span class="k">lambda</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">:</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="L-1696"><a href="#L-1696"><span class="linenos">1696</span></a>                <span class="p">):</span>
</span><span id="L-1697"><a href="#L-1697"><span class="linenos">1697</span></a>                    <span class="n">shm</span> <span class="o">=</span> <span class="n">shared_memory</span><span class="o">.</span><span class="n">SharedMemory</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
</span><span id="L-1698"><a href="#L-1698"><span class="linenos">1698</span></a>                <span class="k">if</span> <span class="n">shm</span><span class="o">.</span><span class="n">buf</span><span class="p">[:</span> <span class="nb">len</span><span class="p">(</span><span class="n">magic_message</span><span class="p">)]</span> <span class="o">==</span> <span class="n">magic_message</span><span class="p">:</span>
</span><span id="L-1699"><a href="#L-1699"><span class="linenos">1699</span></a>                    <span class="n">is_in_the_same_node</span><span class="p">[</span><span class="n">rank</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>
</span><span id="L-1700"><a href="#L-1700"><span class="linenos">1700</span></a>    <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
</span><span id="L-1701"><a href="#L-1701"><span class="linenos">1701</span></a>        <span class="n">logger</span><span class="o">.</span><span class="n">error</span><span class="p">(</span><span class="s2">&quot;Error ignored in is_in_the_same_node: </span><span class="si">%s</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">e</span><span class="p">)</span>
</span><span id="L-1702"><a href="#L-1702"><span class="linenos">1702</span></a>    <span class="k">finally</span><span class="p">:</span>
</span><span id="L-1703"><a href="#L-1703"><span class="linenos">1703</span></a>        <span class="k">if</span> <span class="n">shm</span><span class="p">:</span>
</span><span id="L-1704"><a href="#L-1704"><span class="linenos">1704</span></a>            <span class="n">shm</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
</span><span id="L-1705"><a href="#L-1705"><span class="linenos">1705</span></a>
</span><span id="L-1706"><a href="#L-1706"><span class="linenos">1706</span></a>    <span class="n">torch</span><span class="o">.</span><span class="n">distributed</span><span class="o">.</span><span class="n">barrier</span><span class="p">(</span><span class="n">group</span><span class="o">=</span><span class="n">pg</span><span class="p">)</span>
</span><span id="L-1707"><a href="#L-1707"><span class="linenos">1707</span></a>
</span><span id="L-1708"><a href="#L-1708"><span class="linenos">1708</span></a>    <span class="c1"># clean up the shared memory segment</span>
</span><span id="L-1709"><a href="#L-1709"><span class="linenos">1709</span></a>    <span class="k">with</span> <span class="n">contextlib</span><span class="o">.</span><span class="n">suppress</span><span class="p">(</span><span class="ne">OSError</span><span class="p">):</span>
</span><span id="L-1710"><a href="#L-1710"><span class="linenos">1710</span></a>        <span class="k">if</span> <span class="n">rank</span> <span class="o">==</span> <span class="n">source_rank</span> <span class="ow">and</span> <span class="n">shm</span><span class="p">:</span>
</span><span id="L-1711"><a href="#L-1711"><span class="linenos">1711</span></a>            <span class="n">shm</span><span class="o">.</span><span class="n">unlink</span><span class="p">()</span>
</span><span id="L-1712"><a href="#L-1712"><span class="linenos">1712</span></a>    <span class="n">torch</span><span class="o">.</span><span class="n">distributed</span><span class="o">.</span><span class="n">all_reduce</span><span class="p">(</span><span class="n">is_in_the_same_node</span><span class="p">,</span> <span class="n">group</span><span class="o">=</span><span class="n">pg</span><span class="p">)</span>
</span><span id="L-1713"><a href="#L-1713"><span class="linenos">1713</span></a>
</span><span id="L-1714"><a href="#L-1714"><span class="linenos">1714</span></a>    <span class="k">return</span> <span class="p">[</span><span class="n">x</span> <span class="o">==</span> <span class="mi">1</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">is_in_the_same_node</span><span class="o">.</span><span class="n">tolist</span><span class="p">()]</span>
</span><span id="L-1715"><a href="#L-1715"><span class="linenos">1715</span></a>
</span><span id="L-1716"><a href="#L-1716"><span class="linenos">1716</span></a>
</span><span id="L-1717"><a href="#L-1717"><span class="linenos">1717</span></a><span class="n">vllm_get_pp_group</span> <span class="o">=</span> <span class="kc">None</span>
</span><span id="L-1718"><a href="#L-1718"><span class="linenos">1718</span></a><span class="n">vllm_get_tp_group</span> <span class="o">=</span> <span class="kc">None</span>
</span><span id="L-1719"><a href="#L-1719"><span class="linenos">1719</span></a><span class="n">vllm_get_world_group</span> <span class="o">=</span> <span class="kc">None</span>
</span><span id="L-1720"><a href="#L-1720"><span class="linenos">1720</span></a>
</span><span id="L-1721"><a href="#L-1721"><span class="linenos">1721</span></a>
</span><span id="L-1722"><a href="#L-1722"><span class="linenos">1722</span></a><span class="k">def</span><span class="w"> </span><span class="nf">monkey_patch_vllm_parallel_state</span><span class="p">(</span><span class="n">reverse</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">):</span>
</span><span id="L-1723"><a href="#L-1723"><span class="linenos">1723</span></a>    <span class="k">try</span><span class="p">:</span>
</span><span id="L-1724"><a href="#L-1724"><span class="linenos">1724</span></a>        <span class="kn">import</span><span class="w"> </span><span class="nn">vllm.distributed.parallel_state</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">vllm_parrlel_state</span>
</span><span id="L-1725"><a href="#L-1725"><span class="linenos">1725</span></a>    <span class="k">except</span> <span class="ne">ImportError</span><span class="p">:</span>
</span><span id="L-1726"><a href="#L-1726"><span class="linenos">1726</span></a>        <span class="k">return</span>
</span><span id="L-1727"><a href="#L-1727"><span class="linenos">1727</span></a>
</span><span id="L-1728"><a href="#L-1728"><span class="linenos">1728</span></a>    <span class="k">global</span> <span class="n">vllm_get_pp_group</span><span class="p">,</span> <span class="n">vllm_get_tp_group</span><span class="p">,</span> <span class="n">vllm_get_world_group</span>
</span><span id="L-1729"><a href="#L-1729"><span class="linenos">1729</span></a>    <span class="k">if</span> <span class="n">vllm_get_pp_group</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="L-1730"><a href="#L-1730"><span class="linenos">1730</span></a>        <span class="n">vllm_get_pp_group</span> <span class="o">=</span> <span class="n">vllm_parrlel_state</span><span class="o">.</span><span class="n">get_pp_group</span>
</span><span id="L-1731"><a href="#L-1731"><span class="linenos">1731</span></a>        <span class="n">vllm_get_tp_group</span> <span class="o">=</span> <span class="n">vllm_parrlel_state</span><span class="o">.</span><span class="n">get_tp_group</span>
</span><span id="L-1732"><a href="#L-1732"><span class="linenos">1732</span></a>        <span class="n">vllm_get_world_group</span> <span class="o">=</span> <span class="n">vllm_parrlel_state</span><span class="o">.</span><span class="n">get_world_group</span>
</span><span id="L-1733"><a href="#L-1733"><span class="linenos">1733</span></a>    <span class="k">if</span> <span class="n">reverse</span><span class="p">:</span>
</span><span id="L-1734"><a href="#L-1734"><span class="linenos">1734</span></a>        <span class="nb">setattr</span><span class="p">(</span><span class="n">vllm_parrlel_state</span><span class="p">,</span> <span class="s2">&quot;get_pp_group&quot;</span><span class="p">,</span> <span class="n">vllm_get_pp_group</span><span class="p">)</span>
</span><span id="L-1735"><a href="#L-1735"><span class="linenos">1735</span></a>        <span class="nb">setattr</span><span class="p">(</span><span class="n">vllm_parrlel_state</span><span class="p">,</span> <span class="s2">&quot;get_tp_group&quot;</span><span class="p">,</span> <span class="n">vllm_get_tp_group</span><span class="p">)</span>
</span><span id="L-1736"><a href="#L-1736"><span class="linenos">1736</span></a>        <span class="nb">setattr</span><span class="p">(</span><span class="n">vllm_parrlel_state</span><span class="p">,</span> <span class="s2">&quot;get_world_group&quot;</span><span class="p">,</span> <span class="n">vllm_get_world_group</span><span class="p">)</span>
</span><span id="L-1737"><a href="#L-1737"><span class="linenos">1737</span></a>    <span class="k">else</span><span class="p">:</span>
</span><span id="L-1738"><a href="#L-1738"><span class="linenos">1738</span></a>        <span class="nb">setattr</span><span class="p">(</span><span class="n">vllm_parrlel_state</span><span class="p">,</span> <span class="s2">&quot;get_pp_group&quot;</span><span class="p">,</span> <span class="n">get_pp_group</span><span class="p">)</span>
</span><span id="L-1739"><a href="#L-1739"><span class="linenos">1739</span></a>        <span class="nb">setattr</span><span class="p">(</span><span class="n">vllm_parrlel_state</span><span class="p">,</span> <span class="s2">&quot;get_tp_group&quot;</span><span class="p">,</span> <span class="n">get_tp_group</span><span class="p">)</span>
</span><span id="L-1740"><a href="#L-1740"><span class="linenos">1740</span></a>        <span class="nb">setattr</span><span class="p">(</span><span class="n">vllm_parrlel_state</span><span class="p">,</span> <span class="s2">&quot;get_world_group&quot;</span><span class="p">,</span> <span class="n">get_world_group</span><span class="p">)</span>
</span></pre></div>


            </section>
                <section id="GraphCaptureContext">
                            <input id="GraphCaptureContext-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr class">
                    <div class="decorator decorator-dataclass">@dataclass</div>

    <span class="def">class</span>
    <span class="name">GraphCaptureContext</span>:

                <label class="view-source-button" for="GraphCaptureContext-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#GraphCaptureContext"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="GraphCaptureContext-57"><a href="#GraphCaptureContext-57"><span class="linenos">57</span></a><span class="nd">@dataclass</span>
</span><span id="GraphCaptureContext-58"><a href="#GraphCaptureContext-58"><span class="linenos">58</span></a><span class="k">class</span><span class="w"> </span><span class="nc">GraphCaptureContext</span><span class="p">:</span>
</span><span id="GraphCaptureContext-59"><a href="#GraphCaptureContext-59"><span class="linenos">59</span></a>    <span class="n">stream</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">Stream</span> <span class="k">if</span> <span class="ow">not</span> <span class="n">_is_npu</span> <span class="k">else</span> <span class="n">torch</span><span class="o">.</span><span class="n">npu</span><span class="o">.</span><span class="n">Stream</span>
</span></pre></div>


    

                            <div id="GraphCaptureContext.__init__" class="classattr">
                                <div class="attr function">
            
        <span class="name">GraphCaptureContext</span><span class="signature pdoc-code condensed">(<span class="param"><span class="n">stream</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">streams</span><span class="o">.</span><span class="n">Stream</span></span>)</span>

        
    </div>
    <a class="headerlink" href="#GraphCaptureContext.__init__"></a>
    
    

                            </div>
                            <div id="GraphCaptureContext.stream" class="classattr">
                                <div class="attr variable">
            <span class="name">stream</span><span class="annotation">: torch.cuda.streams.Stream</span>

        
    </div>
    <a class="headerlink" href="#GraphCaptureContext.stream"></a>
    
    

                            </div>
                </section>
                <section id="TensorMetadata">
                    <div class="attr class">
            
    <span class="def">class</span>
    <span class="name">TensorMetadata</span><wbr>(<span class="base">builtins.tuple</span>):

        
    </div>
    <a class="headerlink" href="#TensorMetadata"></a>
    
            <div class="docstring"><p>TensorMetadata(device, dtype, size)</p>
</div>


                            <div id="TensorMetadata.__init__" class="classattr">
                                <div class="attr function">
            
        <span class="name">TensorMetadata</span><span class="signature pdoc-code condensed">(<span class="param"><span class="n">device</span>, </span><span class="param"><span class="n">dtype</span>, </span><span class="param"><span class="n">size</span></span>)</span>

        
    </div>
    <a class="headerlink" href="#TensorMetadata.__init__"></a>
    
            <div class="docstring"><p>Create new instance of TensorMetadata(device, dtype, size)</p>
</div>


                            </div>
                            <div id="TensorMetadata.device" class="classattr">
                                <div class="attr variable">
            <span class="name">device</span>

        
    </div>
    <a class="headerlink" href="#TensorMetadata.device"></a>
    
            <div class="docstring"><p>Alias for field number 0</p>
</div>


                            </div>
                            <div id="TensorMetadata.dtype" class="classattr">
                                <div class="attr variable">
            <span class="name">dtype</span>

        
    </div>
    <a class="headerlink" href="#TensorMetadata.dtype"></a>
    
            <div class="docstring"><p>Alias for field number 1</p>
</div>


                            </div>
                            <div id="TensorMetadata.size" class="classattr">
                                <div class="attr variable">
            <span class="name">size</span>

        
    </div>
    <a class="headerlink" href="#TensorMetadata.size"></a>
    
            <div class="docstring"><p>Alias for field number 2</p>
</div>


                            </div>
                </section>
                <section id="GroupCoordinator">
                            <input id="GroupCoordinator-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr class">
            
    <span class="def">class</span>
    <span class="name">GroupCoordinator</span>:

                <label class="view-source-button" for="GroupCoordinator-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#GroupCoordinator"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="GroupCoordinator-176"><a href="#GroupCoordinator-176"><span class="linenos"> 176</span></a><span class="k">class</span><span class="w"> </span><span class="nc">GroupCoordinator</span><span class="p">:</span>
</span><span id="GroupCoordinator-177"><a href="#GroupCoordinator-177"><span class="linenos"> 177</span></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="GroupCoordinator-178"><a href="#GroupCoordinator-178"><span class="linenos"> 178</span></a><span class="sd">    PyTorch ProcessGroup wrapper for a group of processes.</span>
</span><span id="GroupCoordinator-179"><a href="#GroupCoordinator-179"><span class="linenos"> 179</span></a><span class="sd">    PyTorch ProcessGroup is bound to one specific communication backend,</span>
</span><span id="GroupCoordinator-180"><a href="#GroupCoordinator-180"><span class="linenos"> 180</span></a><span class="sd">        e.g. NCCL, Gloo, MPI, etc.</span>
</span><span id="GroupCoordinator-181"><a href="#GroupCoordinator-181"><span class="linenos"> 181</span></a><span class="sd">    GroupCoordinator takes charge of all the communication operations among</span>
</span><span id="GroupCoordinator-182"><a href="#GroupCoordinator-182"><span class="linenos"> 182</span></a><span class="sd">        the processes in the group. It can route the communication to</span>
</span><span id="GroupCoordinator-183"><a href="#GroupCoordinator-183"><span class="linenos"> 183</span></a><span class="sd">        a specific implementation (e.g. switch allreduce implementation</span>
</span><span id="GroupCoordinator-184"><a href="#GroupCoordinator-184"><span class="linenos"> 184</span></a><span class="sd">        based on the tensor size and cuda graph mode).</span>
</span><span id="GroupCoordinator-185"><a href="#GroupCoordinator-185"><span class="linenos"> 185</span></a><span class="sd">    &quot;&quot;&quot;</span>
</span><span id="GroupCoordinator-186"><a href="#GroupCoordinator-186"><span class="linenos"> 186</span></a>
</span><span id="GroupCoordinator-187"><a href="#GroupCoordinator-187"><span class="linenos"> 187</span></a>    <span class="c1"># available attributes:</span>
</span><span id="GroupCoordinator-188"><a href="#GroupCoordinator-188"><span class="linenos"> 188</span></a>    <span class="n">rank</span><span class="p">:</span> <span class="nb">int</span>  <span class="c1"># global rank</span>
</span><span id="GroupCoordinator-189"><a href="#GroupCoordinator-189"><span class="linenos"> 189</span></a>    <span class="n">ranks</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span>  <span class="c1"># global ranks in the group</span>
</span><span id="GroupCoordinator-190"><a href="#GroupCoordinator-190"><span class="linenos"> 190</span></a>    <span class="n">world_size</span><span class="p">:</span> <span class="nb">int</span>  <span class="c1"># size of the group</span>
</span><span id="GroupCoordinator-191"><a href="#GroupCoordinator-191"><span class="linenos"> 191</span></a>    <span class="c1"># difference between `local_rank` and `rank_in_group`:</span>
</span><span id="GroupCoordinator-192"><a href="#GroupCoordinator-192"><span class="linenos"> 192</span></a>    <span class="c1"># if we have a group of size 4 across two nodes:</span>
</span><span id="GroupCoordinator-193"><a href="#GroupCoordinator-193"><span class="linenos"> 193</span></a>    <span class="c1"># Process | Node | Rank | Local Rank | Rank in Group</span>
</span><span id="GroupCoordinator-194"><a href="#GroupCoordinator-194"><span class="linenos"> 194</span></a>    <span class="c1">#   0     |   0  |  0   |     0      |       0</span>
</span><span id="GroupCoordinator-195"><a href="#GroupCoordinator-195"><span class="linenos"> 195</span></a>    <span class="c1">#   1     |   0  |  1   |     1      |       1</span>
</span><span id="GroupCoordinator-196"><a href="#GroupCoordinator-196"><span class="linenos"> 196</span></a>    <span class="c1">#   2     |   1  |  2   |     0      |       2</span>
</span><span id="GroupCoordinator-197"><a href="#GroupCoordinator-197"><span class="linenos"> 197</span></a>    <span class="c1">#   3     |   1  |  3   |     1      |       3</span>
</span><span id="GroupCoordinator-198"><a href="#GroupCoordinator-198"><span class="linenos"> 198</span></a>    <span class="n">local_rank</span><span class="p">:</span> <span class="nb">int</span>  <span class="c1"># local rank used to assign devices</span>
</span><span id="GroupCoordinator-199"><a href="#GroupCoordinator-199"><span class="linenos"> 199</span></a>    <span class="n">rank_in_group</span><span class="p">:</span> <span class="nb">int</span>  <span class="c1"># rank inside the group</span>
</span><span id="GroupCoordinator-200"><a href="#GroupCoordinator-200"><span class="linenos"> 200</span></a>    <span class="n">cpu_group</span><span class="p">:</span> <span class="n">ProcessGroup</span>  <span class="c1"># group for CPU communication</span>
</span><span id="GroupCoordinator-201"><a href="#GroupCoordinator-201"><span class="linenos"> 201</span></a>    <span class="n">device_group</span><span class="p">:</span> <span class="n">ProcessGroup</span>  <span class="c1"># group for device communication</span>
</span><span id="GroupCoordinator-202"><a href="#GroupCoordinator-202"><span class="linenos"> 202</span></a>    <span class="n">use_pynccl</span><span class="p">:</span> <span class="nb">bool</span>  <span class="c1"># a hint of whether to use PyNccl</span>
</span><span id="GroupCoordinator-203"><a href="#GroupCoordinator-203"><span class="linenos"> 203</span></a>    <span class="n">use_pymscclpp</span><span class="p">:</span> <span class="nb">bool</span>  <span class="c1"># a hint of whether to use PyMsccl</span>
</span><span id="GroupCoordinator-204"><a href="#GroupCoordinator-204"><span class="linenos"> 204</span></a>    <span class="n">use_custom_allreduce</span><span class="p">:</span> <span class="nb">bool</span>  <span class="c1"># a hint of whether to use CustomAllreduce</span>
</span><span id="GroupCoordinator-205"><a href="#GroupCoordinator-205"><span class="linenos"> 205</span></a>    <span class="n">use_message_queue_broadcaster</span><span class="p">:</span> <span class="p">(</span>
</span><span id="GroupCoordinator-206"><a href="#GroupCoordinator-206"><span class="linenos"> 206</span></a>        <span class="nb">bool</span>  <span class="c1"># a hint of whether to use message queue broadcaster</span>
</span><span id="GroupCoordinator-207"><a href="#GroupCoordinator-207"><span class="linenos"> 207</span></a>    <span class="p">)</span>
</span><span id="GroupCoordinator-208"><a href="#GroupCoordinator-208"><span class="linenos"> 208</span></a>    <span class="c1"># communicators are only created for world size &gt; 1</span>
</span><span id="GroupCoordinator-209"><a href="#GroupCoordinator-209"><span class="linenos"> 209</span></a>    <span class="n">pynccl_comm</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Any</span><span class="p">]</span>  <span class="c1"># PyNccl communicator</span>
</span><span id="GroupCoordinator-210"><a href="#GroupCoordinator-210"><span class="linenos"> 210</span></a>    <span class="n">ca_comm</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Any</span><span class="p">]</span>  <span class="c1"># Custom allreduce communicator</span>
</span><span id="GroupCoordinator-211"><a href="#GroupCoordinator-211"><span class="linenos"> 211</span></a>    <span class="n">mq_broadcaster</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Any</span><span class="p">]</span>  <span class="c1"># shared memory broadcaster</span>
</span><span id="GroupCoordinator-212"><a href="#GroupCoordinator-212"><span class="linenos"> 212</span></a>
</span><span id="GroupCoordinator-213"><a href="#GroupCoordinator-213"><span class="linenos"> 213</span></a>    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
</span><span id="GroupCoordinator-214"><a href="#GroupCoordinator-214"><span class="linenos"> 214</span></a>        <span class="bp">self</span><span class="p">,</span>
</span><span id="GroupCoordinator-215"><a href="#GroupCoordinator-215"><span class="linenos"> 215</span></a>        <span class="n">group_ranks</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="nb">int</span><span class="p">]],</span>
</span><span id="GroupCoordinator-216"><a href="#GroupCoordinator-216"><span class="linenos"> 216</span></a>        <span class="n">local_rank</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
</span><span id="GroupCoordinator-217"><a href="#GroupCoordinator-217"><span class="linenos"> 217</span></a>        <span class="n">torch_distributed_backend</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Backend</span><span class="p">],</span>
</span><span id="GroupCoordinator-218"><a href="#GroupCoordinator-218"><span class="linenos"> 218</span></a>        <span class="n">use_pynccl</span><span class="p">:</span> <span class="nb">bool</span><span class="p">,</span>
</span><span id="GroupCoordinator-219"><a href="#GroupCoordinator-219"><span class="linenos"> 219</span></a>        <span class="n">use_pymscclpp</span><span class="p">:</span> <span class="nb">bool</span><span class="p">,</span>
</span><span id="GroupCoordinator-220"><a href="#GroupCoordinator-220"><span class="linenos"> 220</span></a>        <span class="n">use_custom_allreduce</span><span class="p">:</span> <span class="nb">bool</span><span class="p">,</span>
</span><span id="GroupCoordinator-221"><a href="#GroupCoordinator-221"><span class="linenos"> 221</span></a>        <span class="n">use_hpu_communicator</span><span class="p">:</span> <span class="nb">bool</span><span class="p">,</span>
</span><span id="GroupCoordinator-222"><a href="#GroupCoordinator-222"><span class="linenos"> 222</span></a>        <span class="n">use_xpu_communicator</span><span class="p">:</span> <span class="nb">bool</span><span class="p">,</span>
</span><span id="GroupCoordinator-223"><a href="#GroupCoordinator-223"><span class="linenos"> 223</span></a>        <span class="n">use_npu_communicator</span><span class="p">:</span> <span class="nb">bool</span><span class="p">,</span>
</span><span id="GroupCoordinator-224"><a href="#GroupCoordinator-224"><span class="linenos"> 224</span></a>        <span class="n">use_message_queue_broadcaster</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
</span><span id="GroupCoordinator-225"><a href="#GroupCoordinator-225"><span class="linenos"> 225</span></a>        <span class="n">group_name</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="GroupCoordinator-226"><a href="#GroupCoordinator-226"><span class="linenos"> 226</span></a>    <span class="p">):</span>
</span><span id="GroupCoordinator-227"><a href="#GroupCoordinator-227"><span class="linenos"> 227</span></a>        <span class="n">group_name</span> <span class="o">=</span> <span class="n">group_name</span> <span class="ow">or</span> <span class="s2">&quot;anonymous&quot;</span>
</span><span id="GroupCoordinator-228"><a href="#GroupCoordinator-228"><span class="linenos"> 228</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">unique_name</span> <span class="o">=</span> <span class="n">_get_unique_name</span><span class="p">(</span><span class="n">group_name</span><span class="p">)</span>
</span><span id="GroupCoordinator-229"><a href="#GroupCoordinator-229"><span class="linenos"> 229</span></a>        <span class="n">_register_group</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span>
</span><span id="GroupCoordinator-230"><a href="#GroupCoordinator-230"><span class="linenos"> 230</span></a>
</span><span id="GroupCoordinator-231"><a href="#GroupCoordinator-231"><span class="linenos"> 231</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">rank</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">distributed</span><span class="o">.</span><span class="n">get_rank</span><span class="p">()</span>
</span><span id="GroupCoordinator-232"><a href="#GroupCoordinator-232"><span class="linenos"> 232</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">local_rank</span> <span class="o">=</span> <span class="n">local_rank</span>
</span><span id="GroupCoordinator-233"><a href="#GroupCoordinator-233"><span class="linenos"> 233</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">device_group</span> <span class="o">=</span> <span class="kc">None</span>
</span><span id="GroupCoordinator-234"><a href="#GroupCoordinator-234"><span class="linenos"> 234</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">cpu_group</span> <span class="o">=</span> <span class="kc">None</span>
</span><span id="GroupCoordinator-235"><a href="#GroupCoordinator-235"><span class="linenos"> 235</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">local_size</span> <span class="o">=</span> <span class="n">get_int_env_var</span><span class="p">(</span><span class="s2">&quot;LOCAL_SIZE&quot;</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
</span><span id="GroupCoordinator-236"><a href="#GroupCoordinator-236"><span class="linenos"> 236</span></a>
</span><span id="GroupCoordinator-237"><a href="#GroupCoordinator-237"><span class="linenos"> 237</span></a>        <span class="k">for</span> <span class="n">ranks</span> <span class="ow">in</span> <span class="n">group_ranks</span><span class="p">:</span>
</span><span id="GroupCoordinator-238"><a href="#GroupCoordinator-238"><span class="linenos"> 238</span></a>            <span class="n">device_group</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">distributed</span><span class="o">.</span><span class="n">new_group</span><span class="p">(</span>
</span><span id="GroupCoordinator-239"><a href="#GroupCoordinator-239"><span class="linenos"> 239</span></a>                <span class="n">ranks</span><span class="p">,</span> <span class="n">backend</span><span class="o">=</span><span class="n">torch_distributed_backend</span>
</span><span id="GroupCoordinator-240"><a href="#GroupCoordinator-240"><span class="linenos"> 240</span></a>            <span class="p">)</span>
</span><span id="GroupCoordinator-241"><a href="#GroupCoordinator-241"><span class="linenos"> 241</span></a>            <span class="c1"># a group with `gloo` backend, to allow direct coordination between</span>
</span><span id="GroupCoordinator-242"><a href="#GroupCoordinator-242"><span class="linenos"> 242</span></a>            <span class="c1"># processes through the CPU.</span>
</span><span id="GroupCoordinator-243"><a href="#GroupCoordinator-243"><span class="linenos"> 243</span></a>            <span class="n">cpu_group</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">distributed</span><span class="o">.</span><span class="n">new_group</span><span class="p">(</span><span class="n">ranks</span><span class="p">,</span> <span class="n">backend</span><span class="o">=</span><span class="s2">&quot;gloo&quot;</span><span class="p">)</span>
</span><span id="GroupCoordinator-244"><a href="#GroupCoordinator-244"><span class="linenos"> 244</span></a>            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">rank</span> <span class="ow">in</span> <span class="n">ranks</span><span class="p">:</span>
</span><span id="GroupCoordinator-245"><a href="#GroupCoordinator-245"><span class="linenos"> 245</span></a>                <span class="bp">self</span><span class="o">.</span><span class="n">ranks</span> <span class="o">=</span> <span class="n">ranks</span>
</span><span id="GroupCoordinator-246"><a href="#GroupCoordinator-246"><span class="linenos"> 246</span></a>                <span class="bp">self</span><span class="o">.</span><span class="n">world_size</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">ranks</span><span class="p">)</span>
</span><span id="GroupCoordinator-247"><a href="#GroupCoordinator-247"><span class="linenos"> 247</span></a>                <span class="bp">self</span><span class="o">.</span><span class="n">rank_in_group</span> <span class="o">=</span> <span class="n">ranks</span><span class="o">.</span><span class="n">index</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">rank</span><span class="p">)</span>
</span><span id="GroupCoordinator-248"><a href="#GroupCoordinator-248"><span class="linenos"> 248</span></a>                <span class="bp">self</span><span class="o">.</span><span class="n">device_group</span> <span class="o">=</span> <span class="n">device_group</span>
</span><span id="GroupCoordinator-249"><a href="#GroupCoordinator-249"><span class="linenos"> 249</span></a>                <span class="bp">self</span><span class="o">.</span><span class="n">cpu_group</span> <span class="o">=</span> <span class="n">cpu_group</span>
</span><span id="GroupCoordinator-250"><a href="#GroupCoordinator-250"><span class="linenos"> 250</span></a>
</span><span id="GroupCoordinator-251"><a href="#GroupCoordinator-251"><span class="linenos"> 251</span></a>        <span class="k">assert</span> <span class="bp">self</span><span class="o">.</span><span class="n">cpu_group</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
</span><span id="GroupCoordinator-252"><a href="#GroupCoordinator-252"><span class="linenos"> 252</span></a>        <span class="k">assert</span> <span class="bp">self</span><span class="o">.</span><span class="n">device_group</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
</span><span id="GroupCoordinator-253"><a href="#GroupCoordinator-253"><span class="linenos"> 253</span></a>
</span><span id="GroupCoordinator-254"><a href="#GroupCoordinator-254"><span class="linenos"> 254</span></a>        <span class="k">if</span> <span class="n">is_cuda_alike</span><span class="p">():</span>
</span><span id="GroupCoordinator-255"><a href="#GroupCoordinator-255"><span class="linenos"> 255</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;cuda:</span><span class="si">{</span><span class="n">local_rank</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</span><span id="GroupCoordinator-256"><a href="#GroupCoordinator-256"><span class="linenos"> 256</span></a>        <span class="k">elif</span> <span class="n">_is_npu</span><span class="p">:</span>
</span><span id="GroupCoordinator-257"><a href="#GroupCoordinator-257"><span class="linenos"> 257</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;npu:</span><span class="si">{</span><span class="n">local_rank</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</span><span id="GroupCoordinator-258"><a href="#GroupCoordinator-258"><span class="linenos"> 258</span></a>        <span class="k">else</span><span class="p">:</span>
</span><span id="GroupCoordinator-259"><a href="#GroupCoordinator-259"><span class="linenos"> 259</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s2">&quot;cpu&quot;</span><span class="p">)</span>
</span><span id="GroupCoordinator-260"><a href="#GroupCoordinator-260"><span class="linenos"> 260</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">device_module</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">get_device_module</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
</span><span id="GroupCoordinator-261"><a href="#GroupCoordinator-261"><span class="linenos"> 261</span></a>
</span><span id="GroupCoordinator-262"><a href="#GroupCoordinator-262"><span class="linenos"> 262</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">use_pynccl</span> <span class="o">=</span> <span class="n">use_pynccl</span>
</span><span id="GroupCoordinator-263"><a href="#GroupCoordinator-263"><span class="linenos"> 263</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">use_pymscclpp</span> <span class="o">=</span> <span class="n">use_pymscclpp</span>
</span><span id="GroupCoordinator-264"><a href="#GroupCoordinator-264"><span class="linenos"> 264</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">use_custom_allreduce</span> <span class="o">=</span> <span class="n">use_custom_allreduce</span>
</span><span id="GroupCoordinator-265"><a href="#GroupCoordinator-265"><span class="linenos"> 265</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">use_hpu_communicator</span> <span class="o">=</span> <span class="n">use_hpu_communicator</span>
</span><span id="GroupCoordinator-266"><a href="#GroupCoordinator-266"><span class="linenos"> 266</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">use_xpu_communicator</span> <span class="o">=</span> <span class="n">use_xpu_communicator</span>
</span><span id="GroupCoordinator-267"><a href="#GroupCoordinator-267"><span class="linenos"> 267</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">use_npu_communicator</span> <span class="o">=</span> <span class="n">use_npu_communicator</span>
</span><span id="GroupCoordinator-268"><a href="#GroupCoordinator-268"><span class="linenos"> 268</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">use_message_queue_broadcaster</span> <span class="o">=</span> <span class="n">use_message_queue_broadcaster</span>
</span><span id="GroupCoordinator-269"><a href="#GroupCoordinator-269"><span class="linenos"> 269</span></a>
</span><span id="GroupCoordinator-270"><a href="#GroupCoordinator-270"><span class="linenos"> 270</span></a>        <span class="c1"># lazy import to avoid documentation build error</span>
</span><span id="GroupCoordinator-271"><a href="#GroupCoordinator-271"><span class="linenos"> 271</span></a>        <span class="kn">from</span><span class="w"> </span><span class="nn">sglang.srt.distributed.device_communicators.custom_all_reduce</span><span class="w"> </span><span class="kn">import</span> <span class="p">(</span>
</span><span id="GroupCoordinator-272"><a href="#GroupCoordinator-272"><span class="linenos"> 272</span></a>            <span class="n">CustomAllreduce</span><span class="p">,</span>
</span><span id="GroupCoordinator-273"><a href="#GroupCoordinator-273"><span class="linenos"> 273</span></a>        <span class="p">)</span>
</span><span id="GroupCoordinator-274"><a href="#GroupCoordinator-274"><span class="linenos"> 274</span></a>        <span class="kn">from</span><span class="w"> </span><span class="nn">sglang.srt.distributed.device_communicators.pynccl</span><span class="w"> </span><span class="kn">import</span> <span class="p">(</span>
</span><span id="GroupCoordinator-275"><a href="#GroupCoordinator-275"><span class="linenos"> 275</span></a>            <span class="n">PyNcclCommunicator</span><span class="p">,</span>
</span><span id="GroupCoordinator-276"><a href="#GroupCoordinator-276"><span class="linenos"> 276</span></a>        <span class="p">)</span>
</span><span id="GroupCoordinator-277"><a href="#GroupCoordinator-277"><span class="linenos"> 277</span></a>
</span><span id="GroupCoordinator-278"><a href="#GroupCoordinator-278"><span class="linenos"> 278</span></a>        <span class="k">if</span> <span class="n">is_hip</span><span class="p">():</span>
</span><span id="GroupCoordinator-279"><a href="#GroupCoordinator-279"><span class="linenos"> 279</span></a>            <span class="kn">from</span><span class="w"> </span><span class="nn">sglang.srt.distributed.device_communicators.quick_all_reduce</span><span class="w"> </span><span class="kn">import</span> <span class="p">(</span>
</span><span id="GroupCoordinator-280"><a href="#GroupCoordinator-280"><span class="linenos"> 280</span></a>                <span class="n">QuickAllReduce</span><span class="p">,</span>
</span><span id="GroupCoordinator-281"><a href="#GroupCoordinator-281"><span class="linenos"> 281</span></a>                <span class="n">qr_rocm_arch_available</span><span class="p">,</span>
</span><span id="GroupCoordinator-282"><a href="#GroupCoordinator-282"><span class="linenos"> 282</span></a>            <span class="p">)</span>
</span><span id="GroupCoordinator-283"><a href="#GroupCoordinator-283"><span class="linenos"> 283</span></a>
</span><span id="GroupCoordinator-284"><a href="#GroupCoordinator-284"><span class="linenos"> 284</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">pynccl_comm</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">PyNcclCommunicator</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
</span><span id="GroupCoordinator-285"><a href="#GroupCoordinator-285"><span class="linenos"> 285</span></a>        <span class="k">if</span> <span class="n">use_pynccl</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">world_size</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
</span><span id="GroupCoordinator-286"><a href="#GroupCoordinator-286"><span class="linenos"> 286</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">pynccl_comm</span> <span class="o">=</span> <span class="n">PyNcclCommunicator</span><span class="p">(</span>
</span><span id="GroupCoordinator-287"><a href="#GroupCoordinator-287"><span class="linenos"> 287</span></a>                <span class="n">group</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">cpu_group</span><span class="p">,</span>
</span><span id="GroupCoordinator-288"><a href="#GroupCoordinator-288"><span class="linenos"> 288</span></a>                <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">,</span>
</span><span id="GroupCoordinator-289"><a href="#GroupCoordinator-289"><span class="linenos"> 289</span></a>            <span class="p">)</span>
</span><span id="GroupCoordinator-290"><a href="#GroupCoordinator-290"><span class="linenos"> 290</span></a>
</span><span id="GroupCoordinator-291"><a href="#GroupCoordinator-291"><span class="linenos"> 291</span></a>        <span class="kn">from</span><span class="w"> </span><span class="nn">sglang.srt.distributed.device_communicators.pymscclpp</span><span class="w"> </span><span class="kn">import</span> <span class="p">(</span>
</span><span id="GroupCoordinator-292"><a href="#GroupCoordinator-292"><span class="linenos"> 292</span></a>            <span class="n">PyMscclppCommunicator</span><span class="p">,</span>
</span><span id="GroupCoordinator-293"><a href="#GroupCoordinator-293"><span class="linenos"> 293</span></a>        <span class="p">)</span>
</span><span id="GroupCoordinator-294"><a href="#GroupCoordinator-294"><span class="linenos"> 294</span></a>
</span><span id="GroupCoordinator-295"><a href="#GroupCoordinator-295"><span class="linenos"> 295</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">pymscclpp_comm</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">PyMscclppCommunicator</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
</span><span id="GroupCoordinator-296"><a href="#GroupCoordinator-296"><span class="linenos"> 296</span></a>        <span class="k">if</span> <span class="n">use_pymscclpp</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">world_size</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
</span><span id="GroupCoordinator-297"><a href="#GroupCoordinator-297"><span class="linenos"> 297</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">pymscclpp_comm</span> <span class="o">=</span> <span class="n">PyMscclppCommunicator</span><span class="p">(</span>
</span><span id="GroupCoordinator-298"><a href="#GroupCoordinator-298"><span class="linenos"> 298</span></a>                <span class="n">group</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">cpu_group</span><span class="p">,</span>
</span><span id="GroupCoordinator-299"><a href="#GroupCoordinator-299"><span class="linenos"> 299</span></a>                <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">,</span>
</span><span id="GroupCoordinator-300"><a href="#GroupCoordinator-300"><span class="linenos"> 300</span></a>            <span class="p">)</span>
</span><span id="GroupCoordinator-301"><a href="#GroupCoordinator-301"><span class="linenos"> 301</span></a>
</span><span id="GroupCoordinator-302"><a href="#GroupCoordinator-302"><span class="linenos"> 302</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">ca_comm</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">CustomAllreduce</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
</span><span id="GroupCoordinator-303"><a href="#GroupCoordinator-303"><span class="linenos"> 303</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">qr_comm</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">QuickAllReduce</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
</span><span id="GroupCoordinator-304"><a href="#GroupCoordinator-304"><span class="linenos"> 304</span></a>        <span class="k">if</span> <span class="n">use_custom_allreduce</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">world_size</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
</span><span id="GroupCoordinator-305"><a href="#GroupCoordinator-305"><span class="linenos"> 305</span></a>            <span class="c1"># Initialize a custom fast all-reduce implementation.</span>
</span><span id="GroupCoordinator-306"><a href="#GroupCoordinator-306"><span class="linenos"> 306</span></a>            <span class="k">try</span><span class="p">:</span>
</span><span id="GroupCoordinator-307"><a href="#GroupCoordinator-307"><span class="linenos"> 307</span></a>                <span class="bp">self</span><span class="o">.</span><span class="n">ca_comm</span> <span class="o">=</span> <span class="n">CustomAllreduce</span><span class="p">(</span>
</span><span id="GroupCoordinator-308"><a href="#GroupCoordinator-308"><span class="linenos"> 308</span></a>                    <span class="n">group</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">cpu_group</span><span class="p">,</span>
</span><span id="GroupCoordinator-309"><a href="#GroupCoordinator-309"><span class="linenos"> 309</span></a>                    <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">,</span>
</span><span id="GroupCoordinator-310"><a href="#GroupCoordinator-310"><span class="linenos"> 310</span></a>                <span class="p">)</span>
</span><span id="GroupCoordinator-311"><a href="#GroupCoordinator-311"><span class="linenos"> 311</span></a>            <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
</span><span id="GroupCoordinator-312"><a href="#GroupCoordinator-312"><span class="linenos"> 312</span></a>                <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span>
</span><span id="GroupCoordinator-313"><a href="#GroupCoordinator-313"><span class="linenos"> 313</span></a>                    <span class="sa">f</span><span class="s2">&quot;Setup Custom allreduce failed with </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">. To silence this &quot;</span>
</span><span id="GroupCoordinator-314"><a href="#GroupCoordinator-314"><span class="linenos"> 314</span></a>                    <span class="s2">&quot;warning, specify --disable-custom-all-reduce explicitly.&quot;</span>
</span><span id="GroupCoordinator-315"><a href="#GroupCoordinator-315"><span class="linenos"> 315</span></a>                <span class="p">)</span>
</span><span id="GroupCoordinator-316"><a href="#GroupCoordinator-316"><span class="linenos"> 316</span></a>            <span class="k">if</span> <span class="n">is_hip</span><span class="p">():</span>
</span><span id="GroupCoordinator-317"><a href="#GroupCoordinator-317"><span class="linenos"> 317</span></a>                <span class="k">try</span><span class="p">:</span>
</span><span id="GroupCoordinator-318"><a href="#GroupCoordinator-318"><span class="linenos"> 318</span></a>                    <span class="c1"># Initialize a custom quick all-reduce implementation for AMD</span>
</span><span id="GroupCoordinator-319"><a href="#GroupCoordinator-319"><span class="linenos"> 319</span></a>                    <span class="c1"># when rocm &gt;= gfx942. Quick reduce is designed as a</span>
</span><span id="GroupCoordinator-320"><a href="#GroupCoordinator-320"><span class="linenos"> 320</span></a>                    <span class="c1"># complement to custom allreduce.</span>
</span><span id="GroupCoordinator-321"><a href="#GroupCoordinator-321"><span class="linenos"> 321</span></a>                    <span class="c1"># Based on quickreduce (https://github.com/mk1-project/quickreduce).</span>
</span><span id="GroupCoordinator-322"><a href="#GroupCoordinator-322"><span class="linenos"> 322</span></a>                    <span class="k">if</span> <span class="n">qr_rocm_arch_available</span><span class="p">():</span>
</span><span id="GroupCoordinator-323"><a href="#GroupCoordinator-323"><span class="linenos"> 323</span></a>                        <span class="bp">self</span><span class="o">.</span><span class="n">qr_comm</span> <span class="o">=</span> <span class="n">QuickAllReduce</span><span class="p">(</span>
</span><span id="GroupCoordinator-324"><a href="#GroupCoordinator-324"><span class="linenos"> 324</span></a>                            <span class="n">group</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">cpu_group</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span>
</span><span id="GroupCoordinator-325"><a href="#GroupCoordinator-325"><span class="linenos"> 325</span></a>                        <span class="p">)</span>
</span><span id="GroupCoordinator-326"><a href="#GroupCoordinator-326"><span class="linenos"> 326</span></a>                <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
</span><span id="GroupCoordinator-327"><a href="#GroupCoordinator-327"><span class="linenos"> 327</span></a>                    <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Failed to initialize QuickAllReduce: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</span><span id="GroupCoordinator-328"><a href="#GroupCoordinator-328"><span class="linenos"> 328</span></a>
</span><span id="GroupCoordinator-329"><a href="#GroupCoordinator-329"><span class="linenos"> 329</span></a>        <span class="kn">from</span><span class="w"> </span><span class="nn">sglang.srt.distributed.device_communicators.hpu_communicator</span><span class="w"> </span><span class="kn">import</span> <span class="p">(</span>
</span><span id="GroupCoordinator-330"><a href="#GroupCoordinator-330"><span class="linenos"> 330</span></a>            <span class="n">HpuCommunicator</span><span class="p">,</span>
</span><span id="GroupCoordinator-331"><a href="#GroupCoordinator-331"><span class="linenos"> 331</span></a>        <span class="p">)</span>
</span><span id="GroupCoordinator-332"><a href="#GroupCoordinator-332"><span class="linenos"> 332</span></a>
</span><span id="GroupCoordinator-333"><a href="#GroupCoordinator-333"><span class="linenos"> 333</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">hpu_communicator</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">HpuCommunicator</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
</span><span id="GroupCoordinator-334"><a href="#GroupCoordinator-334"><span class="linenos"> 334</span></a>        <span class="k">if</span> <span class="n">use_hpu_communicator</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">world_size</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
</span><span id="GroupCoordinator-335"><a href="#GroupCoordinator-335"><span class="linenos"> 335</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">hpu_communicator</span> <span class="o">=</span> <span class="n">HpuCommunicator</span><span class="p">(</span><span class="n">group</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device_group</span><span class="p">)</span>
</span><span id="GroupCoordinator-336"><a href="#GroupCoordinator-336"><span class="linenos"> 336</span></a>
</span><span id="GroupCoordinator-337"><a href="#GroupCoordinator-337"><span class="linenos"> 337</span></a>        <span class="kn">from</span><span class="w"> </span><span class="nn">sglang.srt.distributed.device_communicators.xpu_communicator</span><span class="w"> </span><span class="kn">import</span> <span class="p">(</span>
</span><span id="GroupCoordinator-338"><a href="#GroupCoordinator-338"><span class="linenos"> 338</span></a>            <span class="n">XpuCommunicator</span><span class="p">,</span>
</span><span id="GroupCoordinator-339"><a href="#GroupCoordinator-339"><span class="linenos"> 339</span></a>        <span class="p">)</span>
</span><span id="GroupCoordinator-340"><a href="#GroupCoordinator-340"><span class="linenos"> 340</span></a>
</span><span id="GroupCoordinator-341"><a href="#GroupCoordinator-341"><span class="linenos"> 341</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">xpu_communicator</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">XpuCommunicator</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
</span><span id="GroupCoordinator-342"><a href="#GroupCoordinator-342"><span class="linenos"> 342</span></a>        <span class="k">if</span> <span class="n">use_xpu_communicator</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">world_size</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
</span><span id="GroupCoordinator-343"><a href="#GroupCoordinator-343"><span class="linenos"> 343</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">xpu_communicator</span> <span class="o">=</span> <span class="n">XpuCommunicator</span><span class="p">(</span><span class="n">group</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device_group</span><span class="p">)</span>
</span><span id="GroupCoordinator-344"><a href="#GroupCoordinator-344"><span class="linenos"> 344</span></a>
</span><span id="GroupCoordinator-345"><a href="#GroupCoordinator-345"><span class="linenos"> 345</span></a>        <span class="kn">from</span><span class="w"> </span><span class="nn">sglang.srt.distributed.device_communicators.npu_communicator</span><span class="w"> </span><span class="kn">import</span> <span class="p">(</span>
</span><span id="GroupCoordinator-346"><a href="#GroupCoordinator-346"><span class="linenos"> 346</span></a>            <span class="n">NpuCommunicator</span><span class="p">,</span>
</span><span id="GroupCoordinator-347"><a href="#GroupCoordinator-347"><span class="linenos"> 347</span></a>        <span class="p">)</span>
</span><span id="GroupCoordinator-348"><a href="#GroupCoordinator-348"><span class="linenos"> 348</span></a>
</span><span id="GroupCoordinator-349"><a href="#GroupCoordinator-349"><span class="linenos"> 349</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">npu_communicator</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">NpuCommunicator</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
</span><span id="GroupCoordinator-350"><a href="#GroupCoordinator-350"><span class="linenos"> 350</span></a>        <span class="k">if</span> <span class="n">use_npu_communicator</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">world_size</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
</span><span id="GroupCoordinator-351"><a href="#GroupCoordinator-351"><span class="linenos"> 351</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">npu_communicator</span> <span class="o">=</span> <span class="n">NpuCommunicator</span><span class="p">(</span><span class="n">group</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device_group</span><span class="p">)</span>
</span><span id="GroupCoordinator-352"><a href="#GroupCoordinator-352"><span class="linenos"> 352</span></a>
</span><span id="GroupCoordinator-353"><a href="#GroupCoordinator-353"><span class="linenos"> 353</span></a>        <span class="kn">from</span><span class="w"> </span><span class="nn">sglang.srt.distributed.device_communicators.shm_broadcast</span><span class="w"> </span><span class="kn">import</span> <span class="p">(</span>
</span><span id="GroupCoordinator-354"><a href="#GroupCoordinator-354"><span class="linenos"> 354</span></a>            <span class="n">MessageQueue</span><span class="p">,</span>
</span><span id="GroupCoordinator-355"><a href="#GroupCoordinator-355"><span class="linenos"> 355</span></a>        <span class="p">)</span>
</span><span id="GroupCoordinator-356"><a href="#GroupCoordinator-356"><span class="linenos"> 356</span></a>
</span><span id="GroupCoordinator-357"><a href="#GroupCoordinator-357"><span class="linenos"> 357</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">mq_broadcaster</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">MessageQueue</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
</span><span id="GroupCoordinator-358"><a href="#GroupCoordinator-358"><span class="linenos"> 358</span></a>        <span class="k">if</span> <span class="n">use_message_queue_broadcaster</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">world_size</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
</span><span id="GroupCoordinator-359"><a href="#GroupCoordinator-359"><span class="linenos"> 359</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">mq_broadcaster</span> <span class="o">=</span> <span class="n">MessageQueue</span><span class="o">.</span><span class="n">create_from_process_group</span><span class="p">(</span>
</span><span id="GroupCoordinator-360"><a href="#GroupCoordinator-360"><span class="linenos"> 360</span></a>                <span class="bp">self</span><span class="o">.</span><span class="n">cpu_group</span><span class="p">,</span> <span class="mi">1</span> <span class="o">&lt;&lt;</span> <span class="mi">22</span><span class="p">,</span> <span class="mi">6</span>
</span><span id="GroupCoordinator-361"><a href="#GroupCoordinator-361"><span class="linenos"> 361</span></a>            <span class="p">)</span>
</span><span id="GroupCoordinator-362"><a href="#GroupCoordinator-362"><span class="linenos"> 362</span></a>
</span><span id="GroupCoordinator-363"><a href="#GroupCoordinator-363"><span class="linenos"> 363</span></a>    <span class="k">def</span><span class="w"> </span><span class="fm">__repr__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
</span><span id="GroupCoordinator-364"><a href="#GroupCoordinator-364"><span class="linenos"> 364</span></a>        <span class="k">return</span> <span class="p">(</span>
</span><span id="GroupCoordinator-365"><a href="#GroupCoordinator-365"><span class="linenos"> 365</span></a>            <span class="sa">f</span><span class="s2">&quot;ranks=</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">ranks</span><span class="si">}</span><span class="s2"> rank=</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">rank</span><span class="si">}</span><span class="s2"> local_rank=</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">local_rank</span><span class="si">}</span><span class="s2"> use_pynccl=</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">use_pynccl</span><span class="si">}</span><span class="s2"> &quot;</span>
</span><span id="GroupCoordinator-366"><a href="#GroupCoordinator-366"><span class="linenos"> 366</span></a>            <span class="sa">f</span><span class="s2">&quot;device_group=</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">device_group</span><span class="si">}</span><span class="s2"> cpu_group=</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">cpu_group</span><span class="si">}</span><span class="s2"> unique_name=</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">unique_name</span><span class="si">}</span><span class="s2"> &quot;</span>
</span><span id="GroupCoordinator-367"><a href="#GroupCoordinator-367"><span class="linenos"> 367</span></a>            <span class="sa">f</span><span class="s2">&quot;world_size=</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">world_size</span><span class="si">}</span><span class="s2"> rank_in_group=</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">rank_in_group</span><span class="si">}</span><span class="s2">&quot;</span>
</span><span id="GroupCoordinator-368"><a href="#GroupCoordinator-368"><span class="linenos"> 368</span></a>        <span class="p">)</span>
</span><span id="GroupCoordinator-369"><a href="#GroupCoordinator-369"><span class="linenos"> 369</span></a>
</span><span id="GroupCoordinator-370"><a href="#GroupCoordinator-370"><span class="linenos"> 370</span></a>    <span class="nd">@property</span>
</span><span id="GroupCoordinator-371"><a href="#GroupCoordinator-371"><span class="linenos"> 371</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">first_rank</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
</span><span id="GroupCoordinator-372"><a href="#GroupCoordinator-372"><span class="linenos"> 372</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;Return the global rank of the first process in the group&quot;&quot;&quot;</span>
</span><span id="GroupCoordinator-373"><a href="#GroupCoordinator-373"><span class="linenos"> 373</span></a>        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">ranks</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
</span><span id="GroupCoordinator-374"><a href="#GroupCoordinator-374"><span class="linenos"> 374</span></a>
</span><span id="GroupCoordinator-375"><a href="#GroupCoordinator-375"><span class="linenos"> 375</span></a>    <span class="nd">@property</span>
</span><span id="GroupCoordinator-376"><a href="#GroupCoordinator-376"><span class="linenos"> 376</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">last_rank</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
</span><span id="GroupCoordinator-377"><a href="#GroupCoordinator-377"><span class="linenos"> 377</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;Return the global rank of the last process in the group&quot;&quot;&quot;</span>
</span><span id="GroupCoordinator-378"><a href="#GroupCoordinator-378"><span class="linenos"> 378</span></a>        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">ranks</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
</span><span id="GroupCoordinator-379"><a href="#GroupCoordinator-379"><span class="linenos"> 379</span></a>
</span><span id="GroupCoordinator-380"><a href="#GroupCoordinator-380"><span class="linenos"> 380</span></a>    <span class="nd">@property</span>
</span><span id="GroupCoordinator-381"><a href="#GroupCoordinator-381"><span class="linenos"> 381</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">is_first_rank</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
</span><span id="GroupCoordinator-382"><a href="#GroupCoordinator-382"><span class="linenos"> 382</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;Return whether the caller is the first process in the group&quot;&quot;&quot;</span>
</span><span id="GroupCoordinator-383"><a href="#GroupCoordinator-383"><span class="linenos"> 383</span></a>        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">rank</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">first_rank</span>
</span><span id="GroupCoordinator-384"><a href="#GroupCoordinator-384"><span class="linenos"> 384</span></a>
</span><span id="GroupCoordinator-385"><a href="#GroupCoordinator-385"><span class="linenos"> 385</span></a>    <span class="nd">@property</span>
</span><span id="GroupCoordinator-386"><a href="#GroupCoordinator-386"><span class="linenos"> 386</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">is_last_rank</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
</span><span id="GroupCoordinator-387"><a href="#GroupCoordinator-387"><span class="linenos"> 387</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;Return whether the caller is the last process in the group&quot;&quot;&quot;</span>
</span><span id="GroupCoordinator-388"><a href="#GroupCoordinator-388"><span class="linenos"> 388</span></a>        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">rank</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">last_rank</span>
</span><span id="GroupCoordinator-389"><a href="#GroupCoordinator-389"><span class="linenos"> 389</span></a>
</span><span id="GroupCoordinator-390"><a href="#GroupCoordinator-390"><span class="linenos"> 390</span></a>    <span class="nd">@property</span>
</span><span id="GroupCoordinator-391"><a href="#GroupCoordinator-391"><span class="linenos"> 391</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">next_rank</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
</span><span id="GroupCoordinator-392"><a href="#GroupCoordinator-392"><span class="linenos"> 392</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;Return the global rank of the process that follows the caller&quot;&quot;&quot;</span>
</span><span id="GroupCoordinator-393"><a href="#GroupCoordinator-393"><span class="linenos"> 393</span></a>        <span class="n">rank_in_group</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">rank_in_group</span>
</span><span id="GroupCoordinator-394"><a href="#GroupCoordinator-394"><span class="linenos"> 394</span></a>        <span class="n">world_size</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">world_size</span>
</span><span id="GroupCoordinator-395"><a href="#GroupCoordinator-395"><span class="linenos"> 395</span></a>        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">ranks</span><span class="p">[(</span><span class="n">rank_in_group</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">%</span> <span class="n">world_size</span><span class="p">]</span>
</span><span id="GroupCoordinator-396"><a href="#GroupCoordinator-396"><span class="linenos"> 396</span></a>
</span><span id="GroupCoordinator-397"><a href="#GroupCoordinator-397"><span class="linenos"> 397</span></a>    <span class="nd">@property</span>
</span><span id="GroupCoordinator-398"><a href="#GroupCoordinator-398"><span class="linenos"> 398</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">prev_rank</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
</span><span id="GroupCoordinator-399"><a href="#GroupCoordinator-399"><span class="linenos"> 399</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;Return the global rank of the process that precedes the caller&quot;&quot;&quot;</span>
</span><span id="GroupCoordinator-400"><a href="#GroupCoordinator-400"><span class="linenos"> 400</span></a>        <span class="n">rank_in_group</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">rank_in_group</span>
</span><span id="GroupCoordinator-401"><a href="#GroupCoordinator-401"><span class="linenos"> 401</span></a>        <span class="n">world_size</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">world_size</span>
</span><span id="GroupCoordinator-402"><a href="#GroupCoordinator-402"><span class="linenos"> 402</span></a>        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">ranks</span><span class="p">[(</span><span class="n">rank_in_group</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">%</span> <span class="n">world_size</span><span class="p">]</span>
</span><span id="GroupCoordinator-403"><a href="#GroupCoordinator-403"><span class="linenos"> 403</span></a>
</span><span id="GroupCoordinator-404"><a href="#GroupCoordinator-404"><span class="linenos"> 404</span></a>    <span class="nd">@contextmanager</span>
</span><span id="GroupCoordinator-405"><a href="#GroupCoordinator-405"><span class="linenos"> 405</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">graph_capture</span><span class="p">(</span>
</span><span id="GroupCoordinator-406"><a href="#GroupCoordinator-406"><span class="linenos"> 406</span></a>        <span class="bp">self</span><span class="p">,</span> <span class="n">graph_capture_context</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">GraphCaptureContext</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
</span><span id="GroupCoordinator-407"><a href="#GroupCoordinator-407"><span class="linenos"> 407</span></a>    <span class="p">):</span>
</span><span id="GroupCoordinator-408"><a href="#GroupCoordinator-408"><span class="linenos"> 408</span></a>        <span class="k">if</span> <span class="n">graph_capture_context</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="GroupCoordinator-409"><a href="#GroupCoordinator-409"><span class="linenos"> 409</span></a>            <span class="n">stream</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">device_module</span><span class="o">.</span><span class="n">Stream</span><span class="p">()</span>
</span><span id="GroupCoordinator-410"><a href="#GroupCoordinator-410"><span class="linenos"> 410</span></a>            <span class="n">graph_capture_context</span> <span class="o">=</span> <span class="n">GraphCaptureContext</span><span class="p">(</span><span class="n">stream</span><span class="p">)</span>
</span><span id="GroupCoordinator-411"><a href="#GroupCoordinator-411"><span class="linenos"> 411</span></a>        <span class="k">else</span><span class="p">:</span>
</span><span id="GroupCoordinator-412"><a href="#GroupCoordinator-412"><span class="linenos"> 412</span></a>            <span class="n">stream</span> <span class="o">=</span> <span class="n">graph_capture_context</span><span class="o">.</span><span class="n">stream</span>
</span><span id="GroupCoordinator-413"><a href="#GroupCoordinator-413"><span class="linenos"> 413</span></a>        <span class="c1"># We don&#39;t need the context of custom quick allreduce because the ipc access</span>
</span><span id="GroupCoordinator-414"><a href="#GroupCoordinator-414"><span class="linenos"> 414</span></a>        <span class="c1"># is already collected in init() and we can capture the quick allreduce directly.</span>
</span><span id="GroupCoordinator-415"><a href="#GroupCoordinator-415"><span class="linenos"> 415</span></a>        <span class="n">ca_comm</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">ca_comm</span>
</span><span id="GroupCoordinator-416"><a href="#GroupCoordinator-416"><span class="linenos"> 416</span></a>        <span class="n">maybe_ca_context</span> <span class="o">=</span> <span class="n">nullcontext</span><span class="p">()</span> <span class="k">if</span> <span class="n">ca_comm</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">ca_comm</span><span class="o">.</span><span class="n">capture</span><span class="p">()</span>
</span><span id="GroupCoordinator-417"><a href="#GroupCoordinator-417"><span class="linenos"> 417</span></a>
</span><span id="GroupCoordinator-418"><a href="#GroupCoordinator-418"><span class="linenos"> 418</span></a>        <span class="c1"># ensure all initialization operations complete before attempting to</span>
</span><span id="GroupCoordinator-419"><a href="#GroupCoordinator-419"><span class="linenos"> 419</span></a>        <span class="c1"># capture the graph on another stream</span>
</span><span id="GroupCoordinator-420"><a href="#GroupCoordinator-420"><span class="linenos"> 420</span></a>        <span class="n">curr_stream</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">device_module</span><span class="o">.</span><span class="n">current_stream</span><span class="p">()</span>
</span><span id="GroupCoordinator-421"><a href="#GroupCoordinator-421"><span class="linenos"> 421</span></a>        <span class="k">if</span> <span class="n">curr_stream</span> <span class="o">!=</span> <span class="n">stream</span><span class="p">:</span>
</span><span id="GroupCoordinator-422"><a href="#GroupCoordinator-422"><span class="linenos"> 422</span></a>            <span class="n">stream</span><span class="o">.</span><span class="n">wait_stream</span><span class="p">(</span><span class="n">curr_stream</span><span class="p">)</span>
</span><span id="GroupCoordinator-423"><a href="#GroupCoordinator-423"><span class="linenos"> 423</span></a>
</span><span id="GroupCoordinator-424"><a href="#GroupCoordinator-424"><span class="linenos"> 424</span></a>        <span class="k">with</span> <span class="bp">self</span><span class="o">.</span><span class="n">device_module</span><span class="o">.</span><span class="n">stream</span><span class="p">(</span><span class="n">stream</span><span class="p">),</span> <span class="n">maybe_ca_context</span><span class="p">:</span>
</span><span id="GroupCoordinator-425"><a href="#GroupCoordinator-425"><span class="linenos"> 425</span></a>            <span class="c1"># In graph mode, we have to be very careful about the collective</span>
</span><span id="GroupCoordinator-426"><a href="#GroupCoordinator-426"><span class="linenos"> 426</span></a>            <span class="c1"># operations. The current status is:</span>
</span><span id="GroupCoordinator-427"><a href="#GroupCoordinator-427"><span class="linenos"> 427</span></a>            <span class="c1">#     allreduce \ Mode   |  Eager  |  Graph  |</span>
</span><span id="GroupCoordinator-428"><a href="#GroupCoordinator-428"><span class="linenos"> 428</span></a>            <span class="c1"># --------------------------------------------</span>
</span><span id="GroupCoordinator-429"><a href="#GroupCoordinator-429"><span class="linenos"> 429</span></a>            <span class="c1"># quick allreduce        | enabled | enabled |</span>
</span><span id="GroupCoordinator-430"><a href="#GroupCoordinator-430"><span class="linenos"> 430</span></a>            <span class="c1"># custom allreduce       | enabled | enabled |</span>
</span><span id="GroupCoordinator-431"><a href="#GroupCoordinator-431"><span class="linenos"> 431</span></a>            <span class="c1"># PyNccl                 | disabled| enabled |</span>
</span><span id="GroupCoordinator-432"><a href="#GroupCoordinator-432"><span class="linenos"> 432</span></a>            <span class="c1"># PyMscclpp              | disabled| enabled |</span>
</span><span id="GroupCoordinator-433"><a href="#GroupCoordinator-433"><span class="linenos"> 433</span></a>            <span class="c1"># torch.distributed      | enabled | disabled|</span>
</span><span id="GroupCoordinator-434"><a href="#GroupCoordinator-434"><span class="linenos"> 434</span></a>            <span class="c1">#</span>
</span><span id="GroupCoordinator-435"><a href="#GroupCoordinator-435"><span class="linenos"> 435</span></a>            <span class="c1"># Note: When custom quick allreduce is enabled, a runtime check</span>
</span><span id="GroupCoordinator-436"><a href="#GroupCoordinator-436"><span class="linenos"> 436</span></a>            <span class="c1">#  will be performed. If the tensor size is too small, it will</span>
</span><span id="GroupCoordinator-437"><a href="#GroupCoordinator-437"><span class="linenos"> 437</span></a>            <span class="c1">#  automatically fall back to the next available option.</span>
</span><span id="GroupCoordinator-438"><a href="#GroupCoordinator-438"><span class="linenos"> 438</span></a>            <span class="c1"># Note that custom allreduce will have a runtime check, if the</span>
</span><span id="GroupCoordinator-439"><a href="#GroupCoordinator-439"><span class="linenos"> 439</span></a>            <span class="c1">#  tensor size is too large, it will fallback to the next</span>
</span><span id="GroupCoordinator-440"><a href="#GroupCoordinator-440"><span class="linenos"> 440</span></a>            <span class="c1">#  available option.</span>
</span><span id="GroupCoordinator-441"><a href="#GroupCoordinator-441"><span class="linenos"> 441</span></a>            <span class="c1"># Note that the PyMsccl needs to register the tensor in ahead,</span>
</span><span id="GroupCoordinator-442"><a href="#GroupCoordinator-442"><span class="linenos"> 442</span></a>            <span class="c1">#  which will introduce large overhead in the eager case,</span>
</span><span id="GroupCoordinator-443"><a href="#GroupCoordinator-443"><span class="linenos"> 443</span></a>            <span class="c1">#  therefore it is only supported in the graph case.</span>
</span><span id="GroupCoordinator-444"><a href="#GroupCoordinator-444"><span class="linenos"> 444</span></a>            <span class="c1"># In summary: We select the appropriate allreduce method for</span>
</span><span id="GroupCoordinator-445"><a href="#GroupCoordinator-445"><span class="linenos"> 445</span></a>            <span class="c1">#  each mode based on the algorithm order in the table and</span>
</span><span id="GroupCoordinator-446"><a href="#GroupCoordinator-446"><span class="linenos"> 446</span></a>            <span class="c1">#  their usage conditions.</span>
</span><span id="GroupCoordinator-447"><a href="#GroupCoordinator-447"><span class="linenos"> 447</span></a>            <span class="n">pynccl_comm</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">pynccl_comm</span>
</span><span id="GroupCoordinator-448"><a href="#GroupCoordinator-448"><span class="linenos"> 448</span></a>            <span class="n">maybe_pynccl_context</span><span class="p">:</span> <span class="n">Any</span>
</span><span id="GroupCoordinator-449"><a href="#GroupCoordinator-449"><span class="linenos"> 449</span></a>            <span class="k">if</span> <span class="ow">not</span> <span class="n">pynccl_comm</span><span class="p">:</span>
</span><span id="GroupCoordinator-450"><a href="#GroupCoordinator-450"><span class="linenos"> 450</span></a>                <span class="n">maybe_pynccl_context</span> <span class="o">=</span> <span class="n">nullcontext</span><span class="p">()</span>
</span><span id="GroupCoordinator-451"><a href="#GroupCoordinator-451"><span class="linenos"> 451</span></a>            <span class="k">else</span><span class="p">:</span>
</span><span id="GroupCoordinator-452"><a href="#GroupCoordinator-452"><span class="linenos"> 452</span></a>                <span class="n">maybe_pynccl_context</span> <span class="o">=</span> <span class="n">pynccl_comm</span><span class="o">.</span><span class="n">change_state</span><span class="p">(</span>
</span><span id="GroupCoordinator-453"><a href="#GroupCoordinator-453"><span class="linenos"> 453</span></a>                    <span class="n">enable</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">stream</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">current_stream</span><span class="p">()</span>
</span><span id="GroupCoordinator-454"><a href="#GroupCoordinator-454"><span class="linenos"> 454</span></a>                <span class="p">)</span>
</span><span id="GroupCoordinator-455"><a href="#GroupCoordinator-455"><span class="linenos"> 455</span></a>
</span><span id="GroupCoordinator-456"><a href="#GroupCoordinator-456"><span class="linenos"> 456</span></a>            <span class="n">pymscclpp_comm</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">pymscclpp_comm</span>
</span><span id="GroupCoordinator-457"><a href="#GroupCoordinator-457"><span class="linenos"> 457</span></a>            <span class="n">maybe_pymscclpp_context</span><span class="p">:</span> <span class="n">Any</span>
</span><span id="GroupCoordinator-458"><a href="#GroupCoordinator-458"><span class="linenos"> 458</span></a>            <span class="k">if</span> <span class="ow">not</span> <span class="n">pymscclpp_comm</span><span class="p">:</span>
</span><span id="GroupCoordinator-459"><a href="#GroupCoordinator-459"><span class="linenos"> 459</span></a>                <span class="n">maybe_pymscclpp_context</span> <span class="o">=</span> <span class="n">nullcontext</span><span class="p">()</span>
</span><span id="GroupCoordinator-460"><a href="#GroupCoordinator-460"><span class="linenos"> 460</span></a>            <span class="k">else</span><span class="p">:</span>
</span><span id="GroupCoordinator-461"><a href="#GroupCoordinator-461"><span class="linenos"> 461</span></a>                <span class="n">maybe_pymscclpp_context</span> <span class="o">=</span> <span class="n">pymscclpp_comm</span><span class="o">.</span><span class="n">change_state</span><span class="p">(</span><span class="n">enable</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</span><span id="GroupCoordinator-462"><a href="#GroupCoordinator-462"><span class="linenos"> 462</span></a>            <span class="k">with</span> <span class="n">maybe_pynccl_context</span><span class="p">,</span> <span class="n">maybe_pymscclpp_context</span><span class="p">:</span>
</span><span id="GroupCoordinator-463"><a href="#GroupCoordinator-463"><span class="linenos"> 463</span></a>                <span class="k">yield</span> <span class="n">graph_capture_context</span>
</span><span id="GroupCoordinator-464"><a href="#GroupCoordinator-464"><span class="linenos"> 464</span></a>
</span><span id="GroupCoordinator-465"><a href="#GroupCoordinator-465"><span class="linenos"> 465</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">all_reduce</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
</span><span id="GroupCoordinator-466"><a href="#GroupCoordinator-466"><span class="linenos"> 466</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="GroupCoordinator-467"><a href="#GroupCoordinator-467"><span class="linenos"> 467</span></a><span class="sd">        User-facing all-reduce function before we actually call the</span>
</span><span id="GroupCoordinator-468"><a href="#GroupCoordinator-468"><span class="linenos"> 468</span></a><span class="sd">        all-reduce operation.</span>
</span><span id="GroupCoordinator-469"><a href="#GroupCoordinator-469"><span class="linenos"> 469</span></a>
</span><span id="GroupCoordinator-470"><a href="#GroupCoordinator-470"><span class="linenos"> 470</span></a><span class="sd">        We need this because Dynamo does not support passing an arbitrary</span>
</span><span id="GroupCoordinator-471"><a href="#GroupCoordinator-471"><span class="linenos"> 471</span></a><span class="sd">        object (`self` in this case) to a custom op. We need to pass the</span>
</span><span id="GroupCoordinator-472"><a href="#GroupCoordinator-472"><span class="linenos"> 472</span></a><span class="sd">         group name as a string, and then look up the group coordinator from</span>
</span><span id="GroupCoordinator-473"><a href="#GroupCoordinator-473"><span class="linenos"> 473</span></a><span class="sd">         the group name, dispatch the all-reduce operation to the group</span>
</span><span id="GroupCoordinator-474"><a href="#GroupCoordinator-474"><span class="linenos"> 474</span></a><span class="sd">         coordinator.</span>
</span><span id="GroupCoordinator-475"><a href="#GroupCoordinator-475"><span class="linenos"> 475</span></a>
</span><span id="GroupCoordinator-476"><a href="#GroupCoordinator-476"><span class="linenos"> 476</span></a><span class="sd">        In addition, PyTorch custom ops do not support mutation or returning</span>
</span><span id="GroupCoordinator-477"><a href="#GroupCoordinator-477"><span class="linenos"> 477</span></a><span class="sd">        a new tensor in the same op. So we need to figure out if the op is</span>
</span><span id="GroupCoordinator-478"><a href="#GroupCoordinator-478"><span class="linenos"> 478</span></a><span class="sd">        in-place or out-of-place ahead of time.</span>
</span><span id="GroupCoordinator-479"><a href="#GroupCoordinator-479"><span class="linenos"> 479</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="GroupCoordinator-480"><a href="#GroupCoordinator-480"><span class="linenos"> 480</span></a>        <span class="c1"># Bypass the function if we are using only 1 GPU.</span>
</span><span id="GroupCoordinator-481"><a href="#GroupCoordinator-481"><span class="linenos"> 481</span></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">world_size</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
</span><span id="GroupCoordinator-482"><a href="#GroupCoordinator-482"><span class="linenos"> 482</span></a>            <span class="k">return</span> <span class="n">input_</span>
</span><span id="GroupCoordinator-483"><a href="#GroupCoordinator-483"><span class="linenos"> 483</span></a>
</span><span id="GroupCoordinator-484"><a href="#GroupCoordinator-484"><span class="linenos"> 484</span></a>        <span class="k">if</span> <span class="n">input_</span><span class="o">.</span><span class="n">is_cpu</span><span class="p">:</span>
</span><span id="GroupCoordinator-485"><a href="#GroupCoordinator-485"><span class="linenos"> 485</span></a>            <span class="k">if</span> <span class="n">is_shm_available</span><span class="p">(</span><span class="n">input_</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">world_size</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">local_size</span><span class="p">):</span>
</span><span id="GroupCoordinator-486"><a href="#GroupCoordinator-486"><span class="linenos"> 486</span></a>                <span class="n">torch</span><span class="o">.</span><span class="n">ops</span><span class="o">.</span><span class="n">sgl_kernel</span><span class="o">.</span><span class="n">shm_allreduce</span><span class="p">(</span>
</span><span id="GroupCoordinator-487"><a href="#GroupCoordinator-487"><span class="linenos"> 487</span></a>                    <span class="n">input_</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">distributed</span><span class="o">.</span><span class="n">ReduceOp</span><span class="o">.</span><span class="n">SUM</span>
</span><span id="GroupCoordinator-488"><a href="#GroupCoordinator-488"><span class="linenos"> 488</span></a>                <span class="p">)</span>
</span><span id="GroupCoordinator-489"><a href="#GroupCoordinator-489"><span class="linenos"> 489</span></a>            <span class="k">else</span><span class="p">:</span>
</span><span id="GroupCoordinator-490"><a href="#GroupCoordinator-490"><span class="linenos"> 490</span></a>                <span class="n">torch</span><span class="o">.</span><span class="n">distributed</span><span class="o">.</span><span class="n">all_reduce</span><span class="p">(</span><span class="n">input_</span><span class="p">,</span> <span class="n">group</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device_group</span><span class="p">)</span>
</span><span id="GroupCoordinator-491"><a href="#GroupCoordinator-491"><span class="linenos"> 491</span></a>            <span class="k">return</span> <span class="n">input_</span>
</span><span id="GroupCoordinator-492"><a href="#GroupCoordinator-492"><span class="linenos"> 492</span></a>
</span><span id="GroupCoordinator-493"><a href="#GroupCoordinator-493"><span class="linenos"> 493</span></a>        <span class="k">if</span> <span class="ow">not</span> <span class="n">supports_custom_op</span><span class="p">():</span>
</span><span id="GroupCoordinator-494"><a href="#GroupCoordinator-494"><span class="linenos"> 494</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">_all_reduce_in_place</span><span class="p">(</span><span class="n">input_</span><span class="p">)</span>
</span><span id="GroupCoordinator-495"><a href="#GroupCoordinator-495"><span class="linenos"> 495</span></a>            <span class="k">return</span> <span class="n">input_</span>
</span><span id="GroupCoordinator-496"><a href="#GroupCoordinator-496"><span class="linenos"> 496</span></a>
</span><span id="GroupCoordinator-497"><a href="#GroupCoordinator-497"><span class="linenos"> 497</span></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">hpu_communicator</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">hpu_communicator</span><span class="o">.</span><span class="n">disabled</span><span class="p">:</span>
</span><span id="GroupCoordinator-498"><a href="#GroupCoordinator-498"><span class="linenos"> 498</span></a>            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">hpu_communicator</span><span class="o">.</span><span class="n">all_reduce</span><span class="p">(</span><span class="n">input_</span><span class="p">)</span>
</span><span id="GroupCoordinator-499"><a href="#GroupCoordinator-499"><span class="linenos"> 499</span></a>
</span><span id="GroupCoordinator-500"><a href="#GroupCoordinator-500"><span class="linenos"> 500</span></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">xpu_communicator</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">xpu_communicator</span><span class="o">.</span><span class="n">disabled</span><span class="p">:</span>
</span><span id="GroupCoordinator-501"><a href="#GroupCoordinator-501"><span class="linenos"> 501</span></a>            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">xpu_communicator</span><span class="o">.</span><span class="n">all_reduce</span><span class="p">(</span><span class="n">input_</span><span class="p">)</span>
</span><span id="GroupCoordinator-502"><a href="#GroupCoordinator-502"><span class="linenos"> 502</span></a>
</span><span id="GroupCoordinator-503"><a href="#GroupCoordinator-503"><span class="linenos"> 503</span></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">npu_communicator</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">npu_communicator</span><span class="o">.</span><span class="n">disabled</span><span class="p">:</span>
</span><span id="GroupCoordinator-504"><a href="#GroupCoordinator-504"><span class="linenos"> 504</span></a>            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">npu_communicator</span><span class="o">.</span><span class="n">all_reduce</span><span class="p">(</span><span class="n">input_</span><span class="p">)</span>
</span><span id="GroupCoordinator-505"><a href="#GroupCoordinator-505"><span class="linenos"> 505</span></a>
</span><span id="GroupCoordinator-506"><a href="#GroupCoordinator-506"><span class="linenos"> 506</span></a>        <span class="k">if</span> <span class="p">(</span>
</span><span id="GroupCoordinator-507"><a href="#GroupCoordinator-507"><span class="linenos"> 507</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">pynccl_comm</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
</span><span id="GroupCoordinator-508"><a href="#GroupCoordinator-508"><span class="linenos"> 508</span></a>            <span class="ow">and</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">input_</span><span class="p">,</span> <span class="s2">&quot;symmetric_memory&quot;</span><span class="p">)</span>
</span><span id="GroupCoordinator-509"><a href="#GroupCoordinator-509"><span class="linenos"> 509</span></a>            <span class="ow">and</span> <span class="n">input_</span><span class="o">.</span><span class="n">symmetric_memory</span>
</span><span id="GroupCoordinator-510"><a href="#GroupCoordinator-510"><span class="linenos"> 510</span></a>        <span class="p">):</span>
</span><span id="GroupCoordinator-511"><a href="#GroupCoordinator-511"><span class="linenos"> 511</span></a>            <span class="k">with</span> <span class="bp">self</span><span class="o">.</span><span class="n">pynccl_comm</span><span class="o">.</span><span class="n">change_state</span><span class="p">(</span>
</span><span id="GroupCoordinator-512"><a href="#GroupCoordinator-512"><span class="linenos"> 512</span></a>                <span class="n">enable</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">stream</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">current_stream</span><span class="p">()</span>
</span><span id="GroupCoordinator-513"><a href="#GroupCoordinator-513"><span class="linenos"> 513</span></a>            <span class="p">):</span>
</span><span id="GroupCoordinator-514"><a href="#GroupCoordinator-514"><span class="linenos"> 514</span></a>                <span class="bp">self</span><span class="o">.</span><span class="n">pynccl_comm</span><span class="o">.</span><span class="n">all_reduce</span><span class="p">(</span><span class="n">input_</span><span class="p">)</span>
</span><span id="GroupCoordinator-515"><a href="#GroupCoordinator-515"><span class="linenos"> 515</span></a>                <span class="k">return</span> <span class="n">input_</span>
</span><span id="GroupCoordinator-516"><a href="#GroupCoordinator-516"><span class="linenos"> 516</span></a>
</span><span id="GroupCoordinator-517"><a href="#GroupCoordinator-517"><span class="linenos"> 517</span></a>        <span class="n">outplace_all_reduce_method</span> <span class="o">=</span> <span class="kc">None</span>
</span><span id="GroupCoordinator-518"><a href="#GroupCoordinator-518"><span class="linenos"> 518</span></a>        <span class="k">if</span> <span class="p">(</span>
</span><span id="GroupCoordinator-519"><a href="#GroupCoordinator-519"><span class="linenos"> 519</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">qr_comm</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
</span><span id="GroupCoordinator-520"><a href="#GroupCoordinator-520"><span class="linenos"> 520</span></a>            <span class="ow">and</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">qr_comm</span><span class="o">.</span><span class="n">disabled</span>
</span><span id="GroupCoordinator-521"><a href="#GroupCoordinator-521"><span class="linenos"> 521</span></a>            <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">qr_comm</span><span class="o">.</span><span class="n">should_quick_allreduce</span><span class="p">(</span><span class="n">input_</span><span class="p">)</span>
</span><span id="GroupCoordinator-522"><a href="#GroupCoordinator-522"><span class="linenos"> 522</span></a>        <span class="p">):</span>
</span><span id="GroupCoordinator-523"><a href="#GroupCoordinator-523"><span class="linenos"> 523</span></a>            <span class="n">outplace_all_reduce_method</span> <span class="o">=</span> <span class="s2">&quot;qr&quot;</span>
</span><span id="GroupCoordinator-524"><a href="#GroupCoordinator-524"><span class="linenos"> 524</span></a>        <span class="k">elif</span> <span class="p">(</span>
</span><span id="GroupCoordinator-525"><a href="#GroupCoordinator-525"><span class="linenos"> 525</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">ca_comm</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
</span><span id="GroupCoordinator-526"><a href="#GroupCoordinator-526"><span class="linenos"> 526</span></a>            <span class="ow">and</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">ca_comm</span><span class="o">.</span><span class="n">disabled</span>
</span><span id="GroupCoordinator-527"><a href="#GroupCoordinator-527"><span class="linenos"> 527</span></a>            <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">ca_comm</span><span class="o">.</span><span class="n">should_custom_ar</span><span class="p">(</span><span class="n">input_</span><span class="p">)</span>
</span><span id="GroupCoordinator-528"><a href="#GroupCoordinator-528"><span class="linenos"> 528</span></a>        <span class="p">):</span>
</span><span id="GroupCoordinator-529"><a href="#GroupCoordinator-529"><span class="linenos"> 529</span></a>            <span class="n">outplace_all_reduce_method</span> <span class="o">=</span> <span class="s2">&quot;ca&quot;</span>
</span><span id="GroupCoordinator-530"><a href="#GroupCoordinator-530"><span class="linenos"> 530</span></a>        <span class="k">elif</span> <span class="p">(</span>
</span><span id="GroupCoordinator-531"><a href="#GroupCoordinator-531"><span class="linenos"> 531</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">pymscclpp_comm</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
</span><span id="GroupCoordinator-532"><a href="#GroupCoordinator-532"><span class="linenos"> 532</span></a>            <span class="ow">and</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">pymscclpp_comm</span><span class="o">.</span><span class="n">disabled</span>
</span><span id="GroupCoordinator-533"><a href="#GroupCoordinator-533"><span class="linenos"> 533</span></a>            <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">pymscclpp_comm</span><span class="o">.</span><span class="n">should_mscclpp_allreduce</span><span class="p">(</span><span class="n">input_</span><span class="p">)</span>
</span><span id="GroupCoordinator-534"><a href="#GroupCoordinator-534"><span class="linenos"> 534</span></a>        <span class="p">):</span>
</span><span id="GroupCoordinator-535"><a href="#GroupCoordinator-535"><span class="linenos"> 535</span></a>            <span class="n">outplace_all_reduce_method</span> <span class="o">=</span> <span class="s2">&quot;pymscclpp&quot;</span>
</span><span id="GroupCoordinator-536"><a href="#GroupCoordinator-536"><span class="linenos"> 536</span></a>        <span class="k">if</span> <span class="n">outplace_all_reduce_method</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="GroupCoordinator-537"><a href="#GroupCoordinator-537"><span class="linenos"> 537</span></a>            <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">ops</span><span class="o">.</span><span class="n">sglang</span><span class="o">.</span><span class="n">outplace_all_reduce</span><span class="p">(</span>
</span><span id="GroupCoordinator-538"><a href="#GroupCoordinator-538"><span class="linenos"> 538</span></a>                <span class="n">input_</span><span class="p">,</span>
</span><span id="GroupCoordinator-539"><a href="#GroupCoordinator-539"><span class="linenos"> 539</span></a>                <span class="n">group_name</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">unique_name</span><span class="p">,</span>
</span><span id="GroupCoordinator-540"><a href="#GroupCoordinator-540"><span class="linenos"> 540</span></a>                <span class="n">outplace_all_reduce_method</span><span class="o">=</span><span class="n">outplace_all_reduce_method</span><span class="p">,</span>
</span><span id="GroupCoordinator-541"><a href="#GroupCoordinator-541"><span class="linenos"> 541</span></a>            <span class="p">)</span>
</span><span id="GroupCoordinator-542"><a href="#GroupCoordinator-542"><span class="linenos"> 542</span></a>        <span class="k">else</span><span class="p">:</span>
</span><span id="GroupCoordinator-543"><a href="#GroupCoordinator-543"><span class="linenos"> 543</span></a>            <span class="n">torch</span><span class="o">.</span><span class="n">ops</span><span class="o">.</span><span class="n">sglang</span><span class="o">.</span><span class="n">inplace_all_reduce</span><span class="p">(</span><span class="n">input_</span><span class="p">,</span> <span class="n">group_name</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">unique_name</span><span class="p">)</span>
</span><span id="GroupCoordinator-544"><a href="#GroupCoordinator-544"><span class="linenos"> 544</span></a>            <span class="k">return</span> <span class="n">input_</span>
</span><span id="GroupCoordinator-545"><a href="#GroupCoordinator-545"><span class="linenos"> 545</span></a>
</span><span id="GroupCoordinator-546"><a href="#GroupCoordinator-546"><span class="linenos"> 546</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">_all_reduce_out_place</span><span class="p">(</span>
</span><span id="GroupCoordinator-547"><a href="#GroupCoordinator-547"><span class="linenos"> 547</span></a>        <span class="bp">self</span><span class="p">,</span> <span class="n">input_</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">outplace_all_reduce_method</span><span class="p">:</span> <span class="nb">str</span>
</span><span id="GroupCoordinator-548"><a href="#GroupCoordinator-548"><span class="linenos"> 548</span></a>    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
</span><span id="GroupCoordinator-549"><a href="#GroupCoordinator-549"><span class="linenos"> 549</span></a>        <span class="n">qr_comm</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">qr_comm</span>
</span><span id="GroupCoordinator-550"><a href="#GroupCoordinator-550"><span class="linenos"> 550</span></a>        <span class="n">ca_comm</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">ca_comm</span>
</span><span id="GroupCoordinator-551"><a href="#GroupCoordinator-551"><span class="linenos"> 551</span></a>        <span class="n">pymscclpp_comm</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">pymscclpp_comm</span>
</span><span id="GroupCoordinator-552"><a href="#GroupCoordinator-552"><span class="linenos"> 552</span></a>        <span class="k">assert</span> <span class="nb">any</span><span class="p">([</span><span class="n">qr_comm</span><span class="p">,</span> <span class="n">ca_comm</span><span class="p">,</span> <span class="n">pymscclpp_comm</span><span class="p">])</span>
</span><span id="GroupCoordinator-553"><a href="#GroupCoordinator-553"><span class="linenos"> 553</span></a>        <span class="k">if</span> <span class="n">outplace_all_reduce_method</span> <span class="o">==</span> <span class="s2">&quot;qr&quot;</span><span class="p">:</span>
</span><span id="GroupCoordinator-554"><a href="#GroupCoordinator-554"><span class="linenos"> 554</span></a>            <span class="k">assert</span> <span class="ow">not</span> <span class="n">qr_comm</span><span class="o">.</span><span class="n">disabled</span>
</span><span id="GroupCoordinator-555"><a href="#GroupCoordinator-555"><span class="linenos"> 555</span></a>            <span class="n">out</span> <span class="o">=</span> <span class="n">qr_comm</span><span class="o">.</span><span class="n">quick_all_reduce</span><span class="p">(</span><span class="n">input_</span><span class="p">)</span>
</span><span id="GroupCoordinator-556"><a href="#GroupCoordinator-556"><span class="linenos"> 556</span></a>        <span class="k">elif</span> <span class="n">outplace_all_reduce_method</span> <span class="o">==</span> <span class="s2">&quot;ca&quot;</span><span class="p">:</span>
</span><span id="GroupCoordinator-557"><a href="#GroupCoordinator-557"><span class="linenos"> 557</span></a>            <span class="k">assert</span> <span class="ow">not</span> <span class="n">ca_comm</span><span class="o">.</span><span class="n">disabled</span>
</span><span id="GroupCoordinator-558"><a href="#GroupCoordinator-558"><span class="linenos"> 558</span></a>            <span class="n">out</span> <span class="o">=</span> <span class="n">ca_comm</span><span class="o">.</span><span class="n">custom_all_reduce</span><span class="p">(</span><span class="n">input_</span><span class="p">)</span>
</span><span id="GroupCoordinator-559"><a href="#GroupCoordinator-559"><span class="linenos"> 559</span></a>        <span class="k">else</span><span class="p">:</span>
</span><span id="GroupCoordinator-560"><a href="#GroupCoordinator-560"><span class="linenos"> 560</span></a>            <span class="k">assert</span> <span class="ow">not</span> <span class="n">pymscclpp_comm</span><span class="o">.</span><span class="n">disabled</span>
</span><span id="GroupCoordinator-561"><a href="#GroupCoordinator-561"><span class="linenos"> 561</span></a>            <span class="n">out</span> <span class="o">=</span> <span class="n">pymscclpp_comm</span><span class="o">.</span><span class="n">all_reduce</span><span class="p">(</span><span class="n">input_</span><span class="p">)</span>
</span><span id="GroupCoordinator-562"><a href="#GroupCoordinator-562"><span class="linenos"> 562</span></a>        <span class="k">assert</span> <span class="n">out</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
</span><span id="GroupCoordinator-563"><a href="#GroupCoordinator-563"><span class="linenos"> 563</span></a>        <span class="k">return</span> <span class="n">out</span>
</span><span id="GroupCoordinator-564"><a href="#GroupCoordinator-564"><span class="linenos"> 564</span></a>
</span><span id="GroupCoordinator-565"><a href="#GroupCoordinator-565"><span class="linenos"> 565</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">_all_reduce_in_place</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="GroupCoordinator-566"><a href="#GroupCoordinator-566"><span class="linenos"> 566</span></a>        <span class="n">pynccl_comm</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">pynccl_comm</span>
</span><span id="GroupCoordinator-567"><a href="#GroupCoordinator-567"><span class="linenos"> 567</span></a>        <span class="k">if</span> <span class="n">pynccl_comm</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">pynccl_comm</span><span class="o">.</span><span class="n">disabled</span><span class="p">:</span>
</span><span id="GroupCoordinator-568"><a href="#GroupCoordinator-568"><span class="linenos"> 568</span></a>            <span class="n">pynccl_comm</span><span class="o">.</span><span class="n">all_reduce</span><span class="p">(</span><span class="n">input_</span><span class="p">)</span>
</span><span id="GroupCoordinator-569"><a href="#GroupCoordinator-569"><span class="linenos"> 569</span></a>        <span class="k">else</span><span class="p">:</span>
</span><span id="GroupCoordinator-570"><a href="#GroupCoordinator-570"><span class="linenos"> 570</span></a>            <span class="n">torch</span><span class="o">.</span><span class="n">distributed</span><span class="o">.</span><span class="n">all_reduce</span><span class="p">(</span><span class="n">input_</span><span class="p">,</span> <span class="n">group</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device_group</span><span class="p">)</span>
</span><span id="GroupCoordinator-571"><a href="#GroupCoordinator-571"><span class="linenos"> 571</span></a>
</span><span id="GroupCoordinator-572"><a href="#GroupCoordinator-572"><span class="linenos"> 572</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">reduce_scatter_tensor</span><span class="p">(</span>
</span><span id="GroupCoordinator-573"><a href="#GroupCoordinator-573"><span class="linenos"> 573</span></a>        <span class="bp">self</span><span class="p">,</span>
</span><span id="GroupCoordinator-574"><a href="#GroupCoordinator-574"><span class="linenos"> 574</span></a>        <span class="n">output</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
</span><span id="GroupCoordinator-575"><a href="#GroupCoordinator-575"><span class="linenos"> 575</span></a>        <span class="nb">input</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
</span><span id="GroupCoordinator-576"><a href="#GroupCoordinator-576"><span class="linenos"> 576</span></a>    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="GroupCoordinator-577"><a href="#GroupCoordinator-577"><span class="linenos"> 577</span></a>        <span class="c1"># TODO(ch-wan): support other backends</span>
</span><span id="GroupCoordinator-578"><a href="#GroupCoordinator-578"><span class="linenos"> 578</span></a>        <span class="n">torch</span><span class="o">.</span><span class="n">distributed</span><span class="o">.</span><span class="n">reduce_scatter_tensor</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="nb">input</span><span class="p">,</span> <span class="n">group</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device_group</span><span class="p">)</span>
</span><span id="GroupCoordinator-579"><a href="#GroupCoordinator-579"><span class="linenos"> 579</span></a>        <span class="k">return</span> <span class="n">output</span>
</span><span id="GroupCoordinator-580"><a href="#GroupCoordinator-580"><span class="linenos"> 580</span></a>
</span><span id="GroupCoordinator-581"><a href="#GroupCoordinator-581"><span class="linenos"> 581</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">reduce_scatter</span><span class="p">(</span>
</span><span id="GroupCoordinator-582"><a href="#GroupCoordinator-582"><span class="linenos"> 582</span></a>        <span class="bp">self</span><span class="p">,</span>
</span><span id="GroupCoordinator-583"><a href="#GroupCoordinator-583"><span class="linenos"> 583</span></a>        <span class="n">output</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
</span><span id="GroupCoordinator-584"><a href="#GroupCoordinator-584"><span class="linenos"> 584</span></a>        <span class="n">input_list</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">],</span>
</span><span id="GroupCoordinator-585"><a href="#GroupCoordinator-585"><span class="linenos"> 585</span></a>    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="GroupCoordinator-586"><a href="#GroupCoordinator-586"><span class="linenos"> 586</span></a>        <span class="c1"># TODO(ch-wan): support other backends</span>
</span><span id="GroupCoordinator-587"><a href="#GroupCoordinator-587"><span class="linenos"> 587</span></a>        <span class="n">torch</span><span class="o">.</span><span class="n">distributed</span><span class="o">.</span><span class="n">reduce_scatter</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="n">input_list</span><span class="p">,</span> <span class="n">group</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device_group</span><span class="p">)</span>
</span><span id="GroupCoordinator-588"><a href="#GroupCoordinator-588"><span class="linenos"> 588</span></a>        <span class="k">return</span> <span class="n">output</span>
</span><span id="GroupCoordinator-589"><a href="#GroupCoordinator-589"><span class="linenos"> 589</span></a>
</span><span id="GroupCoordinator-590"><a href="#GroupCoordinator-590"><span class="linenos"> 590</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">reduce_scatterv</span><span class="p">(</span>
</span><span id="GroupCoordinator-591"><a href="#GroupCoordinator-591"><span class="linenos"> 591</span></a>        <span class="bp">self</span><span class="p">,</span>
</span><span id="GroupCoordinator-592"><a href="#GroupCoordinator-592"><span class="linenos"> 592</span></a>        <span class="n">input_</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
</span><span id="GroupCoordinator-593"><a href="#GroupCoordinator-593"><span class="linenos"> 593</span></a>        <span class="n">output</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="GroupCoordinator-594"><a href="#GroupCoordinator-594"><span class="linenos"> 594</span></a>        <span class="n">sizes</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="nb">int</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="GroupCoordinator-595"><a href="#GroupCoordinator-595"><span class="linenos"> 595</span></a>    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
</span><span id="GroupCoordinator-596"><a href="#GroupCoordinator-596"><span class="linenos"> 596</span></a>        <span class="n">world_size</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">world_size</span>
</span><span id="GroupCoordinator-597"><a href="#GroupCoordinator-597"><span class="linenos"> 597</span></a>        <span class="n">pynccl_comm</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">pynccl_comm</span>
</span><span id="GroupCoordinator-598"><a href="#GroupCoordinator-598"><span class="linenos"> 598</span></a>
</span><span id="GroupCoordinator-599"><a href="#GroupCoordinator-599"><span class="linenos"> 599</span></a>        <span class="k">with</span> <span class="n">pynccl_comm</span><span class="o">.</span><span class="n">change_state</span><span class="p">(</span><span class="n">enable</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">stream</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">current_stream</span><span class="p">()):</span>
</span><span id="GroupCoordinator-600"><a href="#GroupCoordinator-600"><span class="linenos"> 600</span></a>            <span class="k">assert</span> <span class="p">(</span>
</span><span id="GroupCoordinator-601"><a href="#GroupCoordinator-601"><span class="linenos"> 601</span></a>                <span class="n">pynccl_comm</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">pynccl_comm</span><span class="o">.</span><span class="n">disabled</span>
</span><span id="GroupCoordinator-602"><a href="#GroupCoordinator-602"><span class="linenos"> 602</span></a>            <span class="p">),</span> <span class="s2">&quot;pynccl is required for reduce_scatterv&quot;</span>
</span><span id="GroupCoordinator-603"><a href="#GroupCoordinator-603"><span class="linenos"> 603</span></a>
</span><span id="GroupCoordinator-604"><a href="#GroupCoordinator-604"><span class="linenos"> 604</span></a>            <span class="k">if</span> <span class="n">sizes</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="GroupCoordinator-605"><a href="#GroupCoordinator-605"><span class="linenos"> 605</span></a>                <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">sizes</span><span class="p">)</span> <span class="o">==</span> <span class="n">world_size</span>
</span><span id="GroupCoordinator-606"><a href="#GroupCoordinator-606"><span class="linenos"> 606</span></a>                <span class="k">assert</span> <span class="n">input_</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">==</span> <span class="nb">sum</span><span class="p">(</span><span class="n">sizes</span><span class="p">)</span>
</span><span id="GroupCoordinator-607"><a href="#GroupCoordinator-607"><span class="linenos"> 607</span></a>                <span class="n">chunk_size</span> <span class="o">=</span> <span class="n">sizes</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">rank_in_group</span><span class="p">]</span>
</span><span id="GroupCoordinator-608"><a href="#GroupCoordinator-608"><span class="linenos"> 608</span></a>            <span class="k">else</span><span class="p">:</span>
</span><span id="GroupCoordinator-609"><a href="#GroupCoordinator-609"><span class="linenos"> 609</span></a>                <span class="k">assert</span> <span class="n">input_</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">%</span> <span class="n">world_size</span> <span class="o">==</span> <span class="mi">0</span>
</span><span id="GroupCoordinator-610"><a href="#GroupCoordinator-610"><span class="linenos"> 610</span></a>                <span class="n">chunk_size</span> <span class="o">=</span> <span class="n">input_</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">//</span> <span class="n">world_size</span>
</span><span id="GroupCoordinator-611"><a href="#GroupCoordinator-611"><span class="linenos"> 611</span></a>            <span class="n">output_shape</span> <span class="o">=</span> <span class="p">(</span><span class="n">chunk_size</span><span class="p">,)</span> <span class="o">+</span> <span class="n">input_</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">:]</span>
</span><span id="GroupCoordinator-612"><a href="#GroupCoordinator-612"><span class="linenos"> 612</span></a>
</span><span id="GroupCoordinator-613"><a href="#GroupCoordinator-613"><span class="linenos"> 613</span></a>            <span class="k">if</span> <span class="n">output</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="GroupCoordinator-614"><a href="#GroupCoordinator-614"><span class="linenos"> 614</span></a>                <span class="n">output</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span>
</span><span id="GroupCoordinator-615"><a href="#GroupCoordinator-615"><span class="linenos"> 615</span></a>                    <span class="n">output_shape</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">input_</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">input_</span><span class="o">.</span><span class="n">device</span>
</span><span id="GroupCoordinator-616"><a href="#GroupCoordinator-616"><span class="linenos"> 616</span></a>                <span class="p">)</span>
</span><span id="GroupCoordinator-617"><a href="#GroupCoordinator-617"><span class="linenos"> 617</span></a>            <span class="k">else</span><span class="p">:</span>
</span><span id="GroupCoordinator-618"><a href="#GroupCoordinator-618"><span class="linenos"> 618</span></a>                <span class="k">assert</span> <span class="n">output</span><span class="o">.</span><span class="n">shape</span> <span class="o">==</span> <span class="n">output_shape</span>
</span><span id="GroupCoordinator-619"><a href="#GroupCoordinator-619"><span class="linenos"> 619</span></a>
</span><span id="GroupCoordinator-620"><a href="#GroupCoordinator-620"><span class="linenos"> 620</span></a>            <span class="n">pynccl_comm</span><span class="o">.</span><span class="n">reduce_scatter</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="n">input_</span><span class="p">,</span> <span class="n">sizes</span><span class="o">=</span><span class="n">sizes</span><span class="p">)</span>
</span><span id="GroupCoordinator-621"><a href="#GroupCoordinator-621"><span class="linenos"> 621</span></a>            <span class="k">return</span> <span class="n">output</span>
</span><span id="GroupCoordinator-622"><a href="#GroupCoordinator-622"><span class="linenos"> 622</span></a>
</span><span id="GroupCoordinator-623"><a href="#GroupCoordinator-623"><span class="linenos"> 623</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">_all_gather_into_tensor</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">output</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="nb">input</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">):</span>
</span><span id="GroupCoordinator-624"><a href="#GroupCoordinator-624"><span class="linenos"> 624</span></a>        <span class="n">pynccl_comm</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">pynccl_comm</span>
</span><span id="GroupCoordinator-625"><a href="#GroupCoordinator-625"><span class="linenos"> 625</span></a>        <span class="k">if</span> <span class="n">pynccl_comm</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">pynccl_comm</span><span class="o">.</span><span class="n">disabled</span><span class="p">:</span>
</span><span id="GroupCoordinator-626"><a href="#GroupCoordinator-626"><span class="linenos"> 626</span></a>            <span class="n">pynccl_comm</span><span class="o">.</span><span class="n">all_gather</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="nb">input</span><span class="p">)</span>
</span><span id="GroupCoordinator-627"><a href="#GroupCoordinator-627"><span class="linenos"> 627</span></a>        <span class="k">else</span><span class="p">:</span>
</span><span id="GroupCoordinator-628"><a href="#GroupCoordinator-628"><span class="linenos"> 628</span></a>            <span class="n">torch</span><span class="o">.</span><span class="n">distributed</span><span class="o">.</span><span class="n">all_gather_into_tensor</span><span class="p">(</span>
</span><span id="GroupCoordinator-629"><a href="#GroupCoordinator-629"><span class="linenos"> 629</span></a>                <span class="n">output</span><span class="p">,</span> <span class="nb">input</span><span class="p">,</span> <span class="n">group</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device_group</span>
</span><span id="GroupCoordinator-630"><a href="#GroupCoordinator-630"><span class="linenos"> 630</span></a>            <span class="p">)</span>
</span><span id="GroupCoordinator-631"><a href="#GroupCoordinator-631"><span class="linenos"> 631</span></a>
</span><span id="GroupCoordinator-632"><a href="#GroupCoordinator-632"><span class="linenos"> 632</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">all_gather_into_tensor</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">output</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="nb">input</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">):</span>
</span><span id="GroupCoordinator-633"><a href="#GroupCoordinator-633"><span class="linenos"> 633</span></a>        <span class="k">if</span> <span class="n">_is_npu</span> <span class="ow">or</span> <span class="ow">not</span> <span class="n">supports_custom_op</span><span class="p">():</span>
</span><span id="GroupCoordinator-634"><a href="#GroupCoordinator-634"><span class="linenos"> 634</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">_all_gather_into_tensor</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="nb">input</span><span class="p">)</span>
</span><span id="GroupCoordinator-635"><a href="#GroupCoordinator-635"><span class="linenos"> 635</span></a>        <span class="k">else</span><span class="p">:</span>
</span><span id="GroupCoordinator-636"><a href="#GroupCoordinator-636"><span class="linenos"> 636</span></a>            <span class="n">torch</span><span class="o">.</span><span class="n">ops</span><span class="o">.</span><span class="n">sglang</span><span class="o">.</span><span class="n">reg_all_gather_into_tensor</span><span class="p">(</span>
</span><span id="GroupCoordinator-637"><a href="#GroupCoordinator-637"><span class="linenos"> 637</span></a>                <span class="n">output</span><span class="p">,</span> <span class="nb">input</span><span class="p">,</span> <span class="n">group_name</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">unique_name</span>
</span><span id="GroupCoordinator-638"><a href="#GroupCoordinator-638"><span class="linenos"> 638</span></a>            <span class="p">)</span>
</span><span id="GroupCoordinator-639"><a href="#GroupCoordinator-639"><span class="linenos"> 639</span></a>
</span><span id="GroupCoordinator-640"><a href="#GroupCoordinator-640"><span class="linenos"> 640</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">all_gather</span><span class="p">(</span>
</span><span id="GroupCoordinator-641"><a href="#GroupCoordinator-641"><span class="linenos"> 641</span></a>        <span class="bp">self</span><span class="p">,</span>
</span><span id="GroupCoordinator-642"><a href="#GroupCoordinator-642"><span class="linenos"> 642</span></a>        <span class="n">input_</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
</span><span id="GroupCoordinator-643"><a href="#GroupCoordinator-643"><span class="linenos"> 643</span></a>        <span class="n">dim</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
</span><span id="GroupCoordinator-644"><a href="#GroupCoordinator-644"><span class="linenos"> 644</span></a>        <span class="n">output_tensor_list</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="GroupCoordinator-645"><a href="#GroupCoordinator-645"><span class="linenos"> 645</span></a>    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
</span><span id="GroupCoordinator-646"><a href="#GroupCoordinator-646"><span class="linenos"> 646</span></a>        <span class="n">world_size</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">world_size</span>
</span><span id="GroupCoordinator-647"><a href="#GroupCoordinator-647"><span class="linenos"> 647</span></a>        <span class="c1"># Bypass the function if we are using only 1 GPU.</span>
</span><span id="GroupCoordinator-648"><a href="#GroupCoordinator-648"><span class="linenos"> 648</span></a>        <span class="k">if</span> <span class="n">world_size</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
</span><span id="GroupCoordinator-649"><a href="#GroupCoordinator-649"><span class="linenos"> 649</span></a>            <span class="k">if</span> <span class="n">output_tensor_list</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="GroupCoordinator-650"><a href="#GroupCoordinator-650"><span class="linenos"> 650</span></a>                <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span>
</span><span id="GroupCoordinator-651"><a href="#GroupCoordinator-651"><span class="linenos"> 651</span></a>                    <span class="s2">&quot;Performing in-place all-gather with a group size of 1. &quot;</span>
</span><span id="GroupCoordinator-652"><a href="#GroupCoordinator-652"><span class="linenos"> 652</span></a>                    <span class="s2">&quot;This may be unnecessary; consider bypassing it for better efficiency.&quot;</span>
</span><span id="GroupCoordinator-653"><a href="#GroupCoordinator-653"><span class="linenos"> 653</span></a>                <span class="p">)</span>
</span><span id="GroupCoordinator-654"><a href="#GroupCoordinator-654"><span class="linenos"> 654</span></a>                <span class="n">output_tensor_list</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">copy_</span><span class="p">(</span><span class="n">input_</span><span class="p">)</span>
</span><span id="GroupCoordinator-655"><a href="#GroupCoordinator-655"><span class="linenos"> 655</span></a>                <span class="k">return</span> <span class="kc">None</span>
</span><span id="GroupCoordinator-656"><a href="#GroupCoordinator-656"><span class="linenos"> 656</span></a>            <span class="k">else</span><span class="p">:</span>
</span><span id="GroupCoordinator-657"><a href="#GroupCoordinator-657"><span class="linenos"> 657</span></a>                <span class="k">return</span> <span class="n">input_</span>
</span><span id="GroupCoordinator-658"><a href="#GroupCoordinator-658"><span class="linenos"> 658</span></a>
</span><span id="GroupCoordinator-659"><a href="#GroupCoordinator-659"><span class="linenos"> 659</span></a>        <span class="k">if</span> <span class="n">output_tensor_list</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="GroupCoordinator-660"><a href="#GroupCoordinator-660"><span class="linenos"> 660</span></a>            <span class="c1"># TODO(ch-wan): support other backends</span>
</span><span id="GroupCoordinator-661"><a href="#GroupCoordinator-661"><span class="linenos"> 661</span></a>            <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">distributed</span><span class="o">.</span><span class="n">all_gather</span><span class="p">(</span>
</span><span id="GroupCoordinator-662"><a href="#GroupCoordinator-662"><span class="linenos"> 662</span></a>                <span class="n">output_tensor_list</span><span class="p">,</span> <span class="n">input_</span><span class="p">,</span> <span class="n">group</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device_group</span>
</span><span id="GroupCoordinator-663"><a href="#GroupCoordinator-663"><span class="linenos"> 663</span></a>            <span class="p">)</span>
</span><span id="GroupCoordinator-664"><a href="#GroupCoordinator-664"><span class="linenos"> 664</span></a>
</span><span id="GroupCoordinator-665"><a href="#GroupCoordinator-665"><span class="linenos"> 665</span></a>        <span class="k">assert</span> <span class="p">(</span>
</span><span id="GroupCoordinator-666"><a href="#GroupCoordinator-666"><span class="linenos"> 666</span></a>            <span class="o">-</span><span class="n">input_</span><span class="o">.</span><span class="n">dim</span><span class="p">()</span> <span class="o">&lt;=</span> <span class="n">dim</span> <span class="o">&lt;</span> <span class="n">input_</span><span class="o">.</span><span class="n">dim</span><span class="p">()</span>
</span><span id="GroupCoordinator-667"><a href="#GroupCoordinator-667"><span class="linenos"> 667</span></a>        <span class="p">),</span> <span class="sa">f</span><span class="s2">&quot;Invalid dim (</span><span class="si">{</span><span class="n">dim</span><span class="si">}</span><span class="s2">) for input tensor with shape </span><span class="si">{</span><span class="n">input_</span><span class="o">.</span><span class="n">size</span><span class="p">()</span><span class="si">}</span><span class="s2">&quot;</span>
</span><span id="GroupCoordinator-668"><a href="#GroupCoordinator-668"><span class="linenos"> 668</span></a>
</span><span id="GroupCoordinator-669"><a href="#GroupCoordinator-669"><span class="linenos"> 669</span></a>        <span class="c1"># For HPUs, use HPU communicator.</span>
</span><span id="GroupCoordinator-670"><a href="#GroupCoordinator-670"><span class="linenos"> 670</span></a>        <span class="n">hpu_comm</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">hpu_communicator</span>
</span><span id="GroupCoordinator-671"><a href="#GroupCoordinator-671"><span class="linenos"> 671</span></a>        <span class="k">if</span> <span class="n">hpu_comm</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">hpu_comm</span><span class="o">.</span><span class="n">disabled</span><span class="p">:</span>
</span><span id="GroupCoordinator-672"><a href="#GroupCoordinator-672"><span class="linenos"> 672</span></a>            <span class="k">return</span> <span class="n">hpu_comm</span><span class="o">.</span><span class="n">all_gather</span><span class="p">(</span><span class="n">input_</span><span class="p">,</span> <span class="n">dim</span><span class="p">)</span>
</span><span id="GroupCoordinator-673"><a href="#GroupCoordinator-673"><span class="linenos"> 673</span></a>
</span><span id="GroupCoordinator-674"><a href="#GroupCoordinator-674"><span class="linenos"> 674</span></a>        <span class="c1"># For NPUs, use NPU communicator.</span>
</span><span id="GroupCoordinator-675"><a href="#GroupCoordinator-675"><span class="linenos"> 675</span></a>        <span class="n">npu_comm</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">npu_communicator</span>
</span><span id="GroupCoordinator-676"><a href="#GroupCoordinator-676"><span class="linenos"> 676</span></a>        <span class="k">if</span> <span class="n">npu_comm</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">npu_comm</span><span class="o">.</span><span class="n">disabled</span><span class="p">:</span>
</span><span id="GroupCoordinator-677"><a href="#GroupCoordinator-677"><span class="linenos"> 677</span></a>            <span class="k">return</span> <span class="n">npu_comm</span><span class="o">.</span><span class="n">all_gather</span><span class="p">(</span><span class="n">input_</span><span class="p">,</span> <span class="n">dim</span><span class="p">)</span>
</span><span id="GroupCoordinator-678"><a href="#GroupCoordinator-678"><span class="linenos"> 678</span></a>
</span><span id="GroupCoordinator-679"><a href="#GroupCoordinator-679"><span class="linenos"> 679</span></a>        <span class="k">if</span> <span class="n">dim</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">:</span>
</span><span id="GroupCoordinator-680"><a href="#GroupCoordinator-680"><span class="linenos"> 680</span></a>            <span class="c1"># Convert negative dim to positive.</span>
</span><span id="GroupCoordinator-681"><a href="#GroupCoordinator-681"><span class="linenos"> 681</span></a>            <span class="n">dim</span> <span class="o">+=</span> <span class="n">input_</span><span class="o">.</span><span class="n">dim</span><span class="p">()</span>
</span><span id="GroupCoordinator-682"><a href="#GroupCoordinator-682"><span class="linenos"> 682</span></a>        <span class="n">input_size</span> <span class="o">=</span> <span class="n">input_</span><span class="o">.</span><span class="n">size</span><span class="p">()</span>
</span><span id="GroupCoordinator-683"><a href="#GroupCoordinator-683"><span class="linenos"> 683</span></a>        <span class="c1"># NOTE: we have to use concat-style all-gather here,</span>
</span><span id="GroupCoordinator-684"><a href="#GroupCoordinator-684"><span class="linenos"> 684</span></a>        <span class="c1"># stack-style all-gather has compatibility issues with</span>
</span><span id="GroupCoordinator-685"><a href="#GroupCoordinator-685"><span class="linenos"> 685</span></a>        <span class="c1"># torch.compile . see https://github.com/pytorch/pytorch/issues/138795</span>
</span><span id="GroupCoordinator-686"><a href="#GroupCoordinator-686"><span class="linenos"> 686</span></a>        <span class="n">output_size</span> <span class="o">=</span> <span class="p">(</span><span class="n">input_size</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">*</span> <span class="n">world_size</span><span class="p">,)</span> <span class="o">+</span> <span class="n">input_size</span><span class="p">[</span><span class="mi">1</span><span class="p">:]</span>
</span><span id="GroupCoordinator-687"><a href="#GroupCoordinator-687"><span class="linenos"> 687</span></a>        <span class="c1"># Allocate output tensor.</span>
</span><span id="GroupCoordinator-688"><a href="#GroupCoordinator-688"><span class="linenos"> 688</span></a>        <span class="n">output_tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span>
</span><span id="GroupCoordinator-689"><a href="#GroupCoordinator-689"><span class="linenos"> 689</span></a>            <span class="n">output_size</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">input_</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">input_</span><span class="o">.</span><span class="n">device</span>
</span><span id="GroupCoordinator-690"><a href="#GroupCoordinator-690"><span class="linenos"> 690</span></a>        <span class="p">)</span>
</span><span id="GroupCoordinator-691"><a href="#GroupCoordinator-691"><span class="linenos"> 691</span></a>
</span><span id="GroupCoordinator-692"><a href="#GroupCoordinator-692"><span class="linenos"> 692</span></a>        <span class="c1"># All-gather.</span>
</span><span id="GroupCoordinator-693"><a href="#GroupCoordinator-693"><span class="linenos"> 693</span></a>        <span class="k">if</span> <span class="n">input_</span><span class="o">.</span><span class="n">is_cpu</span> <span class="ow">and</span> <span class="n">is_shm_available</span><span class="p">(</span>
</span><span id="GroupCoordinator-694"><a href="#GroupCoordinator-694"><span class="linenos"> 694</span></a>            <span class="n">input_</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">world_size</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">local_size</span>
</span><span id="GroupCoordinator-695"><a href="#GroupCoordinator-695"><span class="linenos"> 695</span></a>        <span class="p">):</span>
</span><span id="GroupCoordinator-696"><a href="#GroupCoordinator-696"><span class="linenos"> 696</span></a>            <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">ops</span><span class="o">.</span><span class="n">sgl_kernel</span><span class="o">.</span><span class="n">shm_allgather</span><span class="p">(</span><span class="n">input_</span><span class="p">,</span> <span class="n">dim</span><span class="p">)</span>
</span><span id="GroupCoordinator-697"><a href="#GroupCoordinator-697"><span class="linenos"> 697</span></a>
</span><span id="GroupCoordinator-698"><a href="#GroupCoordinator-698"><span class="linenos"> 698</span></a>        <span class="k">if</span> <span class="n">input_</span><span class="o">.</span><span class="n">is_cpu</span><span class="p">:</span>
</span><span id="GroupCoordinator-699"><a href="#GroupCoordinator-699"><span class="linenos"> 699</span></a>            <span class="n">torch</span><span class="o">.</span><span class="n">distributed</span><span class="o">.</span><span class="n">all_gather_into_tensor</span><span class="p">(</span>
</span><span id="GroupCoordinator-700"><a href="#GroupCoordinator-700"><span class="linenos"> 700</span></a>                <span class="n">output_tensor</span><span class="p">,</span> <span class="n">input_</span><span class="p">,</span> <span class="n">group</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device_group</span>
</span><span id="GroupCoordinator-701"><a href="#GroupCoordinator-701"><span class="linenos"> 701</span></a>            <span class="p">)</span>
</span><span id="GroupCoordinator-702"><a href="#GroupCoordinator-702"><span class="linenos"> 702</span></a>        <span class="k">else</span><span class="p">:</span>
</span><span id="GroupCoordinator-703"><a href="#GroupCoordinator-703"><span class="linenos"> 703</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">all_gather_into_tensor</span><span class="p">(</span><span class="n">output_tensor</span><span class="p">,</span> <span class="n">input_</span><span class="p">)</span>
</span><span id="GroupCoordinator-704"><a href="#GroupCoordinator-704"><span class="linenos"> 704</span></a>
</span><span id="GroupCoordinator-705"><a href="#GroupCoordinator-705"><span class="linenos"> 705</span></a>        <span class="c1"># Reshape</span>
</span><span id="GroupCoordinator-706"><a href="#GroupCoordinator-706"><span class="linenos"> 706</span></a>        <span class="n">output_tensor</span> <span class="o">=</span> <span class="n">output_tensor</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="n">world_size</span><span class="p">,)</span> <span class="o">+</span> <span class="n">input_size</span><span class="p">)</span>
</span><span id="GroupCoordinator-707"><a href="#GroupCoordinator-707"><span class="linenos"> 707</span></a>        <span class="n">output_tensor</span> <span class="o">=</span> <span class="n">output_tensor</span><span class="o">.</span><span class="n">movedim</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">dim</span><span class="p">)</span>
</span><span id="GroupCoordinator-708"><a href="#GroupCoordinator-708"><span class="linenos"> 708</span></a>        <span class="n">output_tensor</span> <span class="o">=</span> <span class="n">output_tensor</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span>
</span><span id="GroupCoordinator-709"><a href="#GroupCoordinator-709"><span class="linenos"> 709</span></a>            <span class="n">input_size</span><span class="p">[:</span><span class="n">dim</span><span class="p">]</span> <span class="o">+</span> <span class="p">(</span><span class="n">world_size</span> <span class="o">*</span> <span class="n">input_size</span><span class="p">[</span><span class="n">dim</span><span class="p">],)</span> <span class="o">+</span> <span class="n">input_size</span><span class="p">[</span><span class="n">dim</span> <span class="o">+</span> <span class="mi">1</span> <span class="p">:]</span>
</span><span id="GroupCoordinator-710"><a href="#GroupCoordinator-710"><span class="linenos"> 710</span></a>        <span class="p">)</span>
</span><span id="GroupCoordinator-711"><a href="#GroupCoordinator-711"><span class="linenos"> 711</span></a>        <span class="k">return</span> <span class="n">output_tensor</span>
</span><span id="GroupCoordinator-712"><a href="#GroupCoordinator-712"><span class="linenos"> 712</span></a>
</span><span id="GroupCoordinator-713"><a href="#GroupCoordinator-713"><span class="linenos"> 713</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">all_gatherv</span><span class="p">(</span>
</span><span id="GroupCoordinator-714"><a href="#GroupCoordinator-714"><span class="linenos"> 714</span></a>        <span class="bp">self</span><span class="p">,</span>
</span><span id="GroupCoordinator-715"><a href="#GroupCoordinator-715"><span class="linenos"> 715</span></a>        <span class="n">input_</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]],</span>
</span><span id="GroupCoordinator-716"><a href="#GroupCoordinator-716"><span class="linenos"> 716</span></a>        <span class="n">sizes</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="nb">int</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="GroupCoordinator-717"><a href="#GroupCoordinator-717"><span class="linenos"> 717</span></a>    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Union</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]]:</span>
</span><span id="GroupCoordinator-718"><a href="#GroupCoordinator-718"><span class="linenos"> 718</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="GroupCoordinator-719"><a href="#GroupCoordinator-719"><span class="linenos"> 719</span></a><span class="sd">        Supports varying sizes per rank and input tensor list.</span>
</span><span id="GroupCoordinator-720"><a href="#GroupCoordinator-720"><span class="linenos"> 720</span></a><span class="sd">        `sizes`: a list of len(world_size) with the number of items per rank to gather.</span>
</span><span id="GroupCoordinator-721"><a href="#GroupCoordinator-721"><span class="linenos"> 721</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="GroupCoordinator-722"><a href="#GroupCoordinator-722"><span class="linenos"> 722</span></a>        <span class="n">world_size</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">world_size</span>
</span><span id="GroupCoordinator-723"><a href="#GroupCoordinator-723"><span class="linenos"> 723</span></a>        <span class="n">pynccl_comm</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">pynccl_comm</span>
</span><span id="GroupCoordinator-724"><a href="#GroupCoordinator-724"><span class="linenos"> 724</span></a>
</span><span id="GroupCoordinator-725"><a href="#GroupCoordinator-725"><span class="linenos"> 725</span></a>        <span class="k">with</span> <span class="n">pynccl_comm</span><span class="o">.</span><span class="n">change_state</span><span class="p">(</span><span class="n">enable</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">stream</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">current_stream</span><span class="p">()):</span>
</span><span id="GroupCoordinator-726"><a href="#GroupCoordinator-726"><span class="linenos"> 726</span></a>            <span class="k">assert</span> <span class="p">(</span>
</span><span id="GroupCoordinator-727"><a href="#GroupCoordinator-727"><span class="linenos"> 727</span></a>                <span class="n">pynccl_comm</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">pynccl_comm</span><span class="o">.</span><span class="n">disabled</span>
</span><span id="GroupCoordinator-728"><a href="#GroupCoordinator-728"><span class="linenos"> 728</span></a>            <span class="p">),</span> <span class="s2">&quot;pynccl is required for all_gatherv&quot;</span>
</span><span id="GroupCoordinator-729"><a href="#GroupCoordinator-729"><span class="linenos"> 729</span></a>
</span><span id="GroupCoordinator-730"><a href="#GroupCoordinator-730"><span class="linenos"> 730</span></a>            <span class="k">def</span><span class="w"> </span><span class="nf">_all_gather_single</span><span class="p">(</span>
</span><span id="GroupCoordinator-731"><a href="#GroupCoordinator-731"><span class="linenos"> 731</span></a>                <span class="n">input_</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">sizes</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="nb">int</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span>
</span><span id="GroupCoordinator-732"><a href="#GroupCoordinator-732"><span class="linenos"> 732</span></a>            <span class="p">):</span>
</span><span id="GroupCoordinator-733"><a href="#GroupCoordinator-733"><span class="linenos"> 733</span></a>                <span class="n">input_size</span> <span class="o">=</span> <span class="n">input_</span><span class="o">.</span><span class="n">size</span><span class="p">()</span>
</span><span id="GroupCoordinator-734"><a href="#GroupCoordinator-734"><span class="linenos"> 734</span></a>                <span class="k">if</span> <span class="n">sizes</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="GroupCoordinator-735"><a href="#GroupCoordinator-735"><span class="linenos"> 735</span></a>                    <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">sizes</span><span class="p">)</span> <span class="o">==</span> <span class="n">world_size</span>
</span><span id="GroupCoordinator-736"><a href="#GroupCoordinator-736"><span class="linenos"> 736</span></a>                    <span class="k">assert</span> <span class="n">input_</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">==</span> <span class="n">sizes</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">rank_in_group</span><span class="p">]</span>
</span><span id="GroupCoordinator-737"><a href="#GroupCoordinator-737"><span class="linenos"> 737</span></a>                    <span class="n">output_size</span> <span class="o">=</span> <span class="p">(</span><span class="nb">sum</span><span class="p">(</span><span class="n">sizes</span><span class="p">),)</span> <span class="o">+</span> <span class="n">input_size</span><span class="p">[</span><span class="mi">1</span><span class="p">:]</span>
</span><span id="GroupCoordinator-738"><a href="#GroupCoordinator-738"><span class="linenos"> 738</span></a>                    <span class="c1"># &#39;sizes&#39; is not needed if all inputs in the same group have the same shape</span>
</span><span id="GroupCoordinator-739"><a href="#GroupCoordinator-739"><span class="linenos"> 739</span></a>                    <span class="k">if</span> <span class="nb">all</span><span class="p">(</span><span class="n">s</span> <span class="o">==</span> <span class="n">sizes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="n">sizes</span><span class="p">):</span>
</span><span id="GroupCoordinator-740"><a href="#GroupCoordinator-740"><span class="linenos"> 740</span></a>                        <span class="n">sizes</span> <span class="o">=</span> <span class="kc">None</span>
</span><span id="GroupCoordinator-741"><a href="#GroupCoordinator-741"><span class="linenos"> 741</span></a>                <span class="k">else</span><span class="p">:</span>
</span><span id="GroupCoordinator-742"><a href="#GroupCoordinator-742"><span class="linenos"> 742</span></a>                    <span class="n">output_size</span> <span class="o">=</span> <span class="p">(</span><span class="n">input_size</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">*</span> <span class="n">world_size</span><span class="p">,)</span> <span class="o">+</span> <span class="n">input_size</span><span class="p">[</span><span class="mi">1</span><span class="p">:]</span>
</span><span id="GroupCoordinator-743"><a href="#GroupCoordinator-743"><span class="linenos"> 743</span></a>                <span class="c1"># Allocate output tensor.</span>
</span><span id="GroupCoordinator-744"><a href="#GroupCoordinator-744"><span class="linenos"> 744</span></a>                <span class="n">output_tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span>
</span><span id="GroupCoordinator-745"><a href="#GroupCoordinator-745"><span class="linenos"> 745</span></a>                    <span class="n">output_size</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">input_</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">input_</span><span class="o">.</span><span class="n">device</span>
</span><span id="GroupCoordinator-746"><a href="#GroupCoordinator-746"><span class="linenos"> 746</span></a>                <span class="p">)</span>
</span><span id="GroupCoordinator-747"><a href="#GroupCoordinator-747"><span class="linenos"> 747</span></a>                <span class="n">pynccl_comm</span><span class="o">.</span><span class="n">all_gather</span><span class="p">(</span><span class="n">output_tensor</span><span class="p">,</span> <span class="n">input_</span><span class="p">,</span> <span class="n">sizes</span><span class="o">=</span><span class="n">sizes</span><span class="p">)</span>
</span><span id="GroupCoordinator-748"><a href="#GroupCoordinator-748"><span class="linenos"> 748</span></a>                <span class="k">return</span> <span class="n">output_tensor</span>
</span><span id="GroupCoordinator-749"><a href="#GroupCoordinator-749"><span class="linenos"> 749</span></a>
</span><span id="GroupCoordinator-750"><a href="#GroupCoordinator-750"><span class="linenos"> 750</span></a>            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">input_</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">):</span>
</span><span id="GroupCoordinator-751"><a href="#GroupCoordinator-751"><span class="linenos"> 751</span></a>                <span class="k">return</span> <span class="n">_all_gather_single</span><span class="p">(</span><span class="n">input_</span><span class="p">,</span> <span class="n">sizes</span><span class="p">)</span>
</span><span id="GroupCoordinator-752"><a href="#GroupCoordinator-752"><span class="linenos"> 752</span></a>
</span><span id="GroupCoordinator-753"><a href="#GroupCoordinator-753"><span class="linenos"> 753</span></a>            <span class="n">output_list</span> <span class="o">=</span> <span class="p">[]</span>
</span><span id="GroupCoordinator-754"><a href="#GroupCoordinator-754"><span class="linenos"> 754</span></a>            <span class="n">pynccl_comm</span><span class="o">.</span><span class="n">group_start</span><span class="p">()</span>
</span><span id="GroupCoordinator-755"><a href="#GroupCoordinator-755"><span class="linenos"> 755</span></a>            <span class="k">for</span> <span class="n">inp</span> <span class="ow">in</span> <span class="n">input_</span><span class="p">:</span>
</span><span id="GroupCoordinator-756"><a href="#GroupCoordinator-756"><span class="linenos"> 756</span></a>                <span class="n">output_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">_all_gather_single</span><span class="p">(</span><span class="n">inp</span><span class="p">,</span> <span class="n">sizes</span><span class="o">=</span><span class="n">sizes</span><span class="p">))</span>
</span><span id="GroupCoordinator-757"><a href="#GroupCoordinator-757"><span class="linenos"> 757</span></a>            <span class="n">pynccl_comm</span><span class="o">.</span><span class="n">group_end</span><span class="p">()</span>
</span><span id="GroupCoordinator-758"><a href="#GroupCoordinator-758"><span class="linenos"> 758</span></a>
</span><span id="GroupCoordinator-759"><a href="#GroupCoordinator-759"><span class="linenos"> 759</span></a>            <span class="k">return</span> <span class="n">output_list</span>
</span><span id="GroupCoordinator-760"><a href="#GroupCoordinator-760"><span class="linenos"> 760</span></a>
</span><span id="GroupCoordinator-761"><a href="#GroupCoordinator-761"><span class="linenos"> 761</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">gather</span><span class="p">(</span>
</span><span id="GroupCoordinator-762"><a href="#GroupCoordinator-762"><span class="linenos"> 762</span></a>        <span class="bp">self</span><span class="p">,</span> <span class="n">input_</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">dst</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span> <span class="n">dim</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span>
</span><span id="GroupCoordinator-763"><a href="#GroupCoordinator-763"><span class="linenos"> 763</span></a>    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]:</span>
</span><span id="GroupCoordinator-764"><a href="#GroupCoordinator-764"><span class="linenos"> 764</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="GroupCoordinator-765"><a href="#GroupCoordinator-765"><span class="linenos"> 765</span></a><span class="sd">        NOTE: We assume that the input tensor is on the same device across</span>
</span><span id="GroupCoordinator-766"><a href="#GroupCoordinator-766"><span class="linenos"> 766</span></a><span class="sd">        all the ranks.</span>
</span><span id="GroupCoordinator-767"><a href="#GroupCoordinator-767"><span class="linenos"> 767</span></a><span class="sd">        NOTE: `dst` is the local rank of the destination rank.</span>
</span><span id="GroupCoordinator-768"><a href="#GroupCoordinator-768"><span class="linenos"> 768</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="GroupCoordinator-769"><a href="#GroupCoordinator-769"><span class="linenos"> 769</span></a>        <span class="n">world_size</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">world_size</span>
</span><span id="GroupCoordinator-770"><a href="#GroupCoordinator-770"><span class="linenos"> 770</span></a>        <span class="c1"># Bypass the function if we are using only 1 GPU.</span>
</span><span id="GroupCoordinator-771"><a href="#GroupCoordinator-771"><span class="linenos"> 771</span></a>        <span class="k">if</span> <span class="n">world_size</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
</span><span id="GroupCoordinator-772"><a href="#GroupCoordinator-772"><span class="linenos"> 772</span></a>            <span class="k">return</span> <span class="n">input_</span>
</span><span id="GroupCoordinator-773"><a href="#GroupCoordinator-773"><span class="linenos"> 773</span></a>        <span class="k">assert</span> <span class="p">(</span>
</span><span id="GroupCoordinator-774"><a href="#GroupCoordinator-774"><span class="linenos"> 774</span></a>            <span class="o">-</span><span class="n">input_</span><span class="o">.</span><span class="n">dim</span><span class="p">()</span> <span class="o">&lt;=</span> <span class="n">dim</span> <span class="o">&lt;</span> <span class="n">input_</span><span class="o">.</span><span class="n">dim</span><span class="p">()</span>
</span><span id="GroupCoordinator-775"><a href="#GroupCoordinator-775"><span class="linenos"> 775</span></a>        <span class="p">),</span> <span class="sa">f</span><span class="s2">&quot;Invalid dim (</span><span class="si">{</span><span class="n">dim</span><span class="si">}</span><span class="s2">) for input tensor with shape </span><span class="si">{</span><span class="n">input_</span><span class="o">.</span><span class="n">size</span><span class="p">()</span><span class="si">}</span><span class="s2">&quot;</span>
</span><span id="GroupCoordinator-776"><a href="#GroupCoordinator-776"><span class="linenos"> 776</span></a>        <span class="k">if</span> <span class="n">dim</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">:</span>
</span><span id="GroupCoordinator-777"><a href="#GroupCoordinator-777"><span class="linenos"> 777</span></a>            <span class="c1"># Convert negative dim to positive.</span>
</span><span id="GroupCoordinator-778"><a href="#GroupCoordinator-778"><span class="linenos"> 778</span></a>            <span class="n">dim</span> <span class="o">+=</span> <span class="n">input_</span><span class="o">.</span><span class="n">dim</span><span class="p">()</span>
</span><span id="GroupCoordinator-779"><a href="#GroupCoordinator-779"><span class="linenos"> 779</span></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">xpu_communicator</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">xpu_communicator</span><span class="o">.</span><span class="n">disabled</span><span class="p">:</span>
</span><span id="GroupCoordinator-780"><a href="#GroupCoordinator-780"><span class="linenos"> 780</span></a>            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">xpu_communicator</span><span class="o">.</span><span class="n">gather</span><span class="p">(</span><span class="n">input_</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">rank_in_group</span><span class="p">,</span> <span class="n">dst</span><span class="p">,</span> <span class="n">dim</span><span class="p">)</span>
</span><span id="GroupCoordinator-781"><a href="#GroupCoordinator-781"><span class="linenos"> 781</span></a>        <span class="c1"># Allocate output tensor.</span>
</span><span id="GroupCoordinator-782"><a href="#GroupCoordinator-782"><span class="linenos"> 782</span></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">rank_in_group</span> <span class="o">==</span> <span class="n">dst</span><span class="p">:</span>
</span><span id="GroupCoordinator-783"><a href="#GroupCoordinator-783"><span class="linenos"> 783</span></a>            <span class="n">gather_list</span> <span class="o">=</span> <span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">empty_like</span><span class="p">(</span><span class="n">input_</span><span class="p">)</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">world_size</span><span class="p">)]</span>
</span><span id="GroupCoordinator-784"><a href="#GroupCoordinator-784"><span class="linenos"> 784</span></a>        <span class="k">else</span><span class="p">:</span>
</span><span id="GroupCoordinator-785"><a href="#GroupCoordinator-785"><span class="linenos"> 785</span></a>            <span class="n">gather_list</span> <span class="o">=</span> <span class="kc">None</span>
</span><span id="GroupCoordinator-786"><a href="#GroupCoordinator-786"><span class="linenos"> 786</span></a>        <span class="c1"># Gather.</span>
</span><span id="GroupCoordinator-787"><a href="#GroupCoordinator-787"><span class="linenos"> 787</span></a>        <span class="n">torch</span><span class="o">.</span><span class="n">distributed</span><span class="o">.</span><span class="n">gather</span><span class="p">(</span>
</span><span id="GroupCoordinator-788"><a href="#GroupCoordinator-788"><span class="linenos"> 788</span></a>            <span class="n">input_</span><span class="p">,</span> <span class="n">gather_list</span><span class="p">,</span> <span class="n">dst</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">ranks</span><span class="p">[</span><span class="n">dst</span><span class="p">],</span> <span class="n">group</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device_group</span>
</span><span id="GroupCoordinator-789"><a href="#GroupCoordinator-789"><span class="linenos"> 789</span></a>        <span class="p">)</span>
</span><span id="GroupCoordinator-790"><a href="#GroupCoordinator-790"><span class="linenos"> 790</span></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">rank_in_group</span> <span class="o">==</span> <span class="n">dst</span><span class="p">:</span>
</span><span id="GroupCoordinator-791"><a href="#GroupCoordinator-791"><span class="linenos"> 791</span></a>            <span class="n">output_tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span><span class="n">gather_list</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="n">dim</span><span class="p">)</span>
</span><span id="GroupCoordinator-792"><a href="#GroupCoordinator-792"><span class="linenos"> 792</span></a>        <span class="k">else</span><span class="p">:</span>
</span><span id="GroupCoordinator-793"><a href="#GroupCoordinator-793"><span class="linenos"> 793</span></a>            <span class="n">output_tensor</span> <span class="o">=</span> <span class="kc">None</span>
</span><span id="GroupCoordinator-794"><a href="#GroupCoordinator-794"><span class="linenos"> 794</span></a>        <span class="k">return</span> <span class="n">output_tensor</span>
</span><span id="GroupCoordinator-795"><a href="#GroupCoordinator-795"><span class="linenos"> 795</span></a>
</span><span id="GroupCoordinator-796"><a href="#GroupCoordinator-796"><span class="linenos"> 796</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">broadcast</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">src</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span><span class="p">):</span>
</span><span id="GroupCoordinator-797"><a href="#GroupCoordinator-797"><span class="linenos"> 797</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;Broadcast the input tensor.</span>
</span><span id="GroupCoordinator-798"><a href="#GroupCoordinator-798"><span class="linenos"> 798</span></a><span class="sd">        NOTE: `src` is the local rank of the source rank.</span>
</span><span id="GroupCoordinator-799"><a href="#GroupCoordinator-799"><span class="linenos"> 799</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="GroupCoordinator-800"><a href="#GroupCoordinator-800"><span class="linenos"> 800</span></a>        <span class="k">assert</span> <span class="n">src</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">world_size</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;Invalid src rank (</span><span class="si">{</span><span class="n">src</span><span class="si">}</span><span class="s2">)&quot;</span>
</span><span id="GroupCoordinator-801"><a href="#GroupCoordinator-801"><span class="linenos"> 801</span></a>
</span><span id="GroupCoordinator-802"><a href="#GroupCoordinator-802"><span class="linenos"> 802</span></a>        <span class="c1"># Bypass the function if we are using only 1 GPU.</span>
</span><span id="GroupCoordinator-803"><a href="#GroupCoordinator-803"><span class="linenos"> 803</span></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">world_size</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
</span><span id="GroupCoordinator-804"><a href="#GroupCoordinator-804"><span class="linenos"> 804</span></a>            <span class="k">return</span> <span class="n">input_</span>
</span><span id="GroupCoordinator-805"><a href="#GroupCoordinator-805"><span class="linenos"> 805</span></a>        <span class="c1"># Broadcast.</span>
</span><span id="GroupCoordinator-806"><a href="#GroupCoordinator-806"><span class="linenos"> 806</span></a>        <span class="n">torch</span><span class="o">.</span><span class="n">distributed</span><span class="o">.</span><span class="n">broadcast</span><span class="p">(</span>
</span><span id="GroupCoordinator-807"><a href="#GroupCoordinator-807"><span class="linenos"> 807</span></a>            <span class="n">input_</span><span class="p">,</span> <span class="n">src</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">ranks</span><span class="p">[</span><span class="n">src</span><span class="p">],</span> <span class="n">group</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device_group</span>
</span><span id="GroupCoordinator-808"><a href="#GroupCoordinator-808"><span class="linenos"> 808</span></a>        <span class="p">)</span>
</span><span id="GroupCoordinator-809"><a href="#GroupCoordinator-809"><span class="linenos"> 809</span></a>        <span class="k">return</span> <span class="n">input_</span>
</span><span id="GroupCoordinator-810"><a href="#GroupCoordinator-810"><span class="linenos"> 810</span></a>
</span><span id="GroupCoordinator-811"><a href="#GroupCoordinator-811"><span class="linenos"> 811</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">broadcast_object</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">obj</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Any</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="n">src</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span><span class="p">):</span>
</span><span id="GroupCoordinator-812"><a href="#GroupCoordinator-812"><span class="linenos"> 812</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;Broadcast the input object.</span>
</span><span id="GroupCoordinator-813"><a href="#GroupCoordinator-813"><span class="linenos"> 813</span></a><span class="sd">        NOTE: `src` is the local rank of the source rank.</span>
</span><span id="GroupCoordinator-814"><a href="#GroupCoordinator-814"><span class="linenos"> 814</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="GroupCoordinator-815"><a href="#GroupCoordinator-815"><span class="linenos"> 815</span></a>        <span class="k">assert</span> <span class="n">src</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">world_size</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;Invalid src rank (</span><span class="si">{</span><span class="n">src</span><span class="si">}</span><span class="s2">)&quot;</span>
</span><span id="GroupCoordinator-816"><a href="#GroupCoordinator-816"><span class="linenos"> 816</span></a>
</span><span id="GroupCoordinator-817"><a href="#GroupCoordinator-817"><span class="linenos"> 817</span></a>        <span class="c1"># Bypass the function if we are using only 1 GPU.</span>
</span><span id="GroupCoordinator-818"><a href="#GroupCoordinator-818"><span class="linenos"> 818</span></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">world_size</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
</span><span id="GroupCoordinator-819"><a href="#GroupCoordinator-819"><span class="linenos"> 819</span></a>            <span class="k">return</span> <span class="n">obj</span>
</span><span id="GroupCoordinator-820"><a href="#GroupCoordinator-820"><span class="linenos"> 820</span></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">mq_broadcaster</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="GroupCoordinator-821"><a href="#GroupCoordinator-821"><span class="linenos"> 821</span></a>            <span class="k">assert</span> <span class="n">src</span> <span class="o">==</span> <span class="mi">0</span><span class="p">,</span> <span class="s2">&quot;Message queue broadcaster only supports src=0&quot;</span>
</span><span id="GroupCoordinator-822"><a href="#GroupCoordinator-822"><span class="linenos"> 822</span></a>            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">mq_broadcaster</span><span class="o">.</span><span class="n">broadcast_object</span><span class="p">(</span><span class="n">obj</span><span class="p">)</span>
</span><span id="GroupCoordinator-823"><a href="#GroupCoordinator-823"><span class="linenos"> 823</span></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">rank_in_group</span> <span class="o">==</span> <span class="n">src</span><span class="p">:</span>
</span><span id="GroupCoordinator-824"><a href="#GroupCoordinator-824"><span class="linenos"> 824</span></a>            <span class="n">torch</span><span class="o">.</span><span class="n">distributed</span><span class="o">.</span><span class="n">broadcast_object_list</span><span class="p">(</span>
</span><span id="GroupCoordinator-825"><a href="#GroupCoordinator-825"><span class="linenos"> 825</span></a>                <span class="p">[</span><span class="n">obj</span><span class="p">],</span> <span class="n">src</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">ranks</span><span class="p">[</span><span class="n">src</span><span class="p">],</span> <span class="n">group</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">cpu_group</span>
</span><span id="GroupCoordinator-826"><a href="#GroupCoordinator-826"><span class="linenos"> 826</span></a>            <span class="p">)</span>
</span><span id="GroupCoordinator-827"><a href="#GroupCoordinator-827"><span class="linenos"> 827</span></a>            <span class="k">return</span> <span class="n">obj</span>
</span><span id="GroupCoordinator-828"><a href="#GroupCoordinator-828"><span class="linenos"> 828</span></a>        <span class="k">else</span><span class="p">:</span>
</span><span id="GroupCoordinator-829"><a href="#GroupCoordinator-829"><span class="linenos"> 829</span></a>            <span class="n">recv</span> <span class="o">=</span> <span class="p">[</span><span class="kc">None</span><span class="p">]</span>
</span><span id="GroupCoordinator-830"><a href="#GroupCoordinator-830"><span class="linenos"> 830</span></a>            <span class="n">torch</span><span class="o">.</span><span class="n">distributed</span><span class="o">.</span><span class="n">broadcast_object_list</span><span class="p">(</span>
</span><span id="GroupCoordinator-831"><a href="#GroupCoordinator-831"><span class="linenos"> 831</span></a>                <span class="n">recv</span><span class="p">,</span> <span class="n">src</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">ranks</span><span class="p">[</span><span class="n">src</span><span class="p">],</span> <span class="n">group</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">cpu_group</span>
</span><span id="GroupCoordinator-832"><a href="#GroupCoordinator-832"><span class="linenos"> 832</span></a>            <span class="p">)</span>
</span><span id="GroupCoordinator-833"><a href="#GroupCoordinator-833"><span class="linenos"> 833</span></a>            <span class="k">return</span> <span class="n">recv</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
</span><span id="GroupCoordinator-834"><a href="#GroupCoordinator-834"><span class="linenos"> 834</span></a>
</span><span id="GroupCoordinator-835"><a href="#GroupCoordinator-835"><span class="linenos"> 835</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">broadcast_object_list</span><span class="p">(</span>
</span><span id="GroupCoordinator-836"><a href="#GroupCoordinator-836"><span class="linenos"> 836</span></a>        <span class="bp">self</span><span class="p">,</span> <span class="n">obj_list</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">Any</span><span class="p">],</span> <span class="n">src</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span> <span class="n">group</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">ProcessGroup</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
</span><span id="GroupCoordinator-837"><a href="#GroupCoordinator-837"><span class="linenos"> 837</span></a>    <span class="p">):</span>
</span><span id="GroupCoordinator-838"><a href="#GroupCoordinator-838"><span class="linenos"> 838</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;Broadcast the input object list.</span>
</span><span id="GroupCoordinator-839"><a href="#GroupCoordinator-839"><span class="linenos"> 839</span></a><span class="sd">        NOTE: `src` is the local rank of the source rank.</span>
</span><span id="GroupCoordinator-840"><a href="#GroupCoordinator-840"><span class="linenos"> 840</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="GroupCoordinator-841"><a href="#GroupCoordinator-841"><span class="linenos"> 841</span></a>        <span class="k">assert</span> <span class="n">src</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">world_size</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;Invalid src rank (</span><span class="si">{</span><span class="n">src</span><span class="si">}</span><span class="s2">)&quot;</span>
</span><span id="GroupCoordinator-842"><a href="#GroupCoordinator-842"><span class="linenos"> 842</span></a>
</span><span id="GroupCoordinator-843"><a href="#GroupCoordinator-843"><span class="linenos"> 843</span></a>        <span class="c1"># Bypass the function if we are using only 1 GPU.</span>
</span><span id="GroupCoordinator-844"><a href="#GroupCoordinator-844"><span class="linenos"> 844</span></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">world_size</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
</span><span id="GroupCoordinator-845"><a href="#GroupCoordinator-845"><span class="linenos"> 845</span></a>            <span class="k">return</span> <span class="n">obj_list</span>
</span><span id="GroupCoordinator-846"><a href="#GroupCoordinator-846"><span class="linenos"> 846</span></a>        <span class="c1"># Broadcast.</span>
</span><span id="GroupCoordinator-847"><a href="#GroupCoordinator-847"><span class="linenos"> 847</span></a>        <span class="n">torch</span><span class="o">.</span><span class="n">distributed</span><span class="o">.</span><span class="n">broadcast_object_list</span><span class="p">(</span>
</span><span id="GroupCoordinator-848"><a href="#GroupCoordinator-848"><span class="linenos"> 848</span></a>            <span class="n">obj_list</span><span class="p">,</span> <span class="n">src</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">ranks</span><span class="p">[</span><span class="n">src</span><span class="p">],</span> <span class="n">group</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device_group</span>
</span><span id="GroupCoordinator-849"><a href="#GroupCoordinator-849"><span class="linenos"> 849</span></a>        <span class="p">)</span>
</span><span id="GroupCoordinator-850"><a href="#GroupCoordinator-850"><span class="linenos"> 850</span></a>        <span class="k">return</span> <span class="n">obj_list</span>
</span><span id="GroupCoordinator-851"><a href="#GroupCoordinator-851"><span class="linenos"> 851</span></a>
</span><span id="GroupCoordinator-852"><a href="#GroupCoordinator-852"><span class="linenos"> 852</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">send_object</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">obj</span><span class="p">:</span> <span class="n">Any</span><span class="p">,</span> <span class="n">dst</span><span class="p">:</span> <span class="nb">int</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="GroupCoordinator-853"><a href="#GroupCoordinator-853"><span class="linenos"> 853</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;Send the input object list to the destination rank.&quot;&quot;&quot;</span>
</span><span id="GroupCoordinator-854"><a href="#GroupCoordinator-854"><span class="linenos"> 854</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;NOTE: `dst` is the local rank of the destination rank.&quot;&quot;&quot;</span>
</span><span id="GroupCoordinator-855"><a href="#GroupCoordinator-855"><span class="linenos"> 855</span></a>
</span><span id="GroupCoordinator-856"><a href="#GroupCoordinator-856"><span class="linenos"> 856</span></a>        <span class="k">assert</span> <span class="n">dst</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">world_size</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;Invalid dst rank (</span><span class="si">{</span><span class="n">dst</span><span class="si">}</span><span class="s2">)&quot;</span>
</span><span id="GroupCoordinator-857"><a href="#GroupCoordinator-857"><span class="linenos"> 857</span></a>
</span><span id="GroupCoordinator-858"><a href="#GroupCoordinator-858"><span class="linenos"> 858</span></a>        <span class="k">assert</span> <span class="n">dst</span> <span class="o">!=</span> <span class="bp">self</span><span class="o">.</span><span class="n">rank_in_group</span><span class="p">,</span> <span class="p">(</span>
</span><span id="GroupCoordinator-859"><a href="#GroupCoordinator-859"><span class="linenos"> 859</span></a>            <span class="s2">&quot;Invalid destination rank. Destination rank is the same &quot;</span>
</span><span id="GroupCoordinator-860"><a href="#GroupCoordinator-860"><span class="linenos"> 860</span></a>            <span class="s2">&quot;as the current rank.&quot;</span>
</span><span id="GroupCoordinator-861"><a href="#GroupCoordinator-861"><span class="linenos"> 861</span></a>        <span class="p">)</span>
</span><span id="GroupCoordinator-862"><a href="#GroupCoordinator-862"><span class="linenos"> 862</span></a>
</span><span id="GroupCoordinator-863"><a href="#GroupCoordinator-863"><span class="linenos"> 863</span></a>        <span class="c1"># Serialize object to tensor and get the size as well</span>
</span><span id="GroupCoordinator-864"><a href="#GroupCoordinator-864"><span class="linenos"> 864</span></a>        <span class="n">object_tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">frombuffer</span><span class="p">(</span><span class="n">pickle</span><span class="o">.</span><span class="n">dumps</span><span class="p">(</span><span class="n">obj</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">uint8</span><span class="p">)</span><span class="o">.</span><span class="n">cuda</span><span class="p">(</span>
</span><span id="GroupCoordinator-865"><a href="#GroupCoordinator-865"><span class="linenos"> 865</span></a>            <span class="n">device</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">current_device</span><span class="p">()</span>
</span><span id="GroupCoordinator-866"><a href="#GroupCoordinator-866"><span class="linenos"> 866</span></a>        <span class="p">)</span>
</span><span id="GroupCoordinator-867"><a href="#GroupCoordinator-867"><span class="linenos"> 867</span></a>
</span><span id="GroupCoordinator-868"><a href="#GroupCoordinator-868"><span class="linenos"> 868</span></a>        <span class="n">size_tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span>
</span><span id="GroupCoordinator-869"><a href="#GroupCoordinator-869"><span class="linenos"> 869</span></a>            <span class="p">[</span><span class="n">object_tensor</span><span class="o">.</span><span class="n">numel</span><span class="p">()],</span>
</span><span id="GroupCoordinator-870"><a href="#GroupCoordinator-870"><span class="linenos"> 870</span></a>            <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">long</span><span class="p">,</span>
</span><span id="GroupCoordinator-871"><a href="#GroupCoordinator-871"><span class="linenos"> 871</span></a>            <span class="n">device</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">current_device</span><span class="p">(),</span>
</span><span id="GroupCoordinator-872"><a href="#GroupCoordinator-872"><span class="linenos"> 872</span></a>        <span class="p">)</span>
</span><span id="GroupCoordinator-873"><a href="#GroupCoordinator-873"><span class="linenos"> 873</span></a>
</span><span id="GroupCoordinator-874"><a href="#GroupCoordinator-874"><span class="linenos"> 874</span></a>        <span class="c1"># Send object size</span>
</span><span id="GroupCoordinator-875"><a href="#GroupCoordinator-875"><span class="linenos"> 875</span></a>        <span class="n">torch</span><span class="o">.</span><span class="n">distributed</span><span class="o">.</span><span class="n">send</span><span class="p">(</span>
</span><span id="GroupCoordinator-876"><a href="#GroupCoordinator-876"><span class="linenos"> 876</span></a>            <span class="n">size_tensor</span><span class="p">,</span> <span class="n">dst</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">ranks</span><span class="p">[</span><span class="n">dst</span><span class="p">],</span> <span class="n">group</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device_group</span>
</span><span id="GroupCoordinator-877"><a href="#GroupCoordinator-877"><span class="linenos"> 877</span></a>        <span class="p">)</span>
</span><span id="GroupCoordinator-878"><a href="#GroupCoordinator-878"><span class="linenos"> 878</span></a>
</span><span id="GroupCoordinator-879"><a href="#GroupCoordinator-879"><span class="linenos"> 879</span></a>        <span class="c1"># Send object</span>
</span><span id="GroupCoordinator-880"><a href="#GroupCoordinator-880"><span class="linenos"> 880</span></a>        <span class="n">torch</span><span class="o">.</span><span class="n">distributed</span><span class="o">.</span><span class="n">send</span><span class="p">(</span>
</span><span id="GroupCoordinator-881"><a href="#GroupCoordinator-881"><span class="linenos"> 881</span></a>            <span class="n">object_tensor</span><span class="p">,</span> <span class="n">dst</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">ranks</span><span class="p">[</span><span class="n">dst</span><span class="p">],</span> <span class="n">group</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device_group</span>
</span><span id="GroupCoordinator-882"><a href="#GroupCoordinator-882"><span class="linenos"> 882</span></a>        <span class="p">)</span>
</span><span id="GroupCoordinator-883"><a href="#GroupCoordinator-883"><span class="linenos"> 883</span></a>
</span><span id="GroupCoordinator-884"><a href="#GroupCoordinator-884"><span class="linenos"> 884</span></a>        <span class="k">return</span> <span class="kc">None</span>
</span><span id="GroupCoordinator-885"><a href="#GroupCoordinator-885"><span class="linenos"> 885</span></a>
</span><span id="GroupCoordinator-886"><a href="#GroupCoordinator-886"><span class="linenos"> 886</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">recv_object</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">src</span><span class="p">:</span> <span class="nb">int</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Any</span><span class="p">:</span>
</span><span id="GroupCoordinator-887"><a href="#GroupCoordinator-887"><span class="linenos"> 887</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;Receive the input object list from the source rank.&quot;&quot;&quot;</span>
</span><span id="GroupCoordinator-888"><a href="#GroupCoordinator-888"><span class="linenos"> 888</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;NOTE: `src` is the local rank of the source rank.&quot;&quot;&quot;</span>
</span><span id="GroupCoordinator-889"><a href="#GroupCoordinator-889"><span class="linenos"> 889</span></a>
</span><span id="GroupCoordinator-890"><a href="#GroupCoordinator-890"><span class="linenos"> 890</span></a>        <span class="k">assert</span> <span class="n">src</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">world_size</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;Invalid src rank (</span><span class="si">{</span><span class="n">src</span><span class="si">}</span><span class="s2">)&quot;</span>
</span><span id="GroupCoordinator-891"><a href="#GroupCoordinator-891"><span class="linenos"> 891</span></a>
</span><span id="GroupCoordinator-892"><a href="#GroupCoordinator-892"><span class="linenos"> 892</span></a>        <span class="k">assert</span> <span class="p">(</span>
</span><span id="GroupCoordinator-893"><a href="#GroupCoordinator-893"><span class="linenos"> 893</span></a>            <span class="n">src</span> <span class="o">!=</span> <span class="bp">self</span><span class="o">.</span><span class="n">rank_in_group</span>
</span><span id="GroupCoordinator-894"><a href="#GroupCoordinator-894"><span class="linenos"> 894</span></a>        <span class="p">),</span> <span class="s2">&quot;Invalid source rank. Source rank is the same as the current rank.&quot;</span>
</span><span id="GroupCoordinator-895"><a href="#GroupCoordinator-895"><span class="linenos"> 895</span></a>
</span><span id="GroupCoordinator-896"><a href="#GroupCoordinator-896"><span class="linenos"> 896</span></a>        <span class="n">size_tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span>
</span><span id="GroupCoordinator-897"><a href="#GroupCoordinator-897"><span class="linenos"> 897</span></a>            <span class="mi">1</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">long</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">current_device</span><span class="p">()</span>
</span><span id="GroupCoordinator-898"><a href="#GroupCoordinator-898"><span class="linenos"> 898</span></a>        <span class="p">)</span>
</span><span id="GroupCoordinator-899"><a href="#GroupCoordinator-899"><span class="linenos"> 899</span></a>
</span><span id="GroupCoordinator-900"><a href="#GroupCoordinator-900"><span class="linenos"> 900</span></a>        <span class="c1"># Receive object size</span>
</span><span id="GroupCoordinator-901"><a href="#GroupCoordinator-901"><span class="linenos"> 901</span></a>        <span class="n">rank_size</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">distributed</span><span class="o">.</span><span class="n">recv</span><span class="p">(</span>
</span><span id="GroupCoordinator-902"><a href="#GroupCoordinator-902"><span class="linenos"> 902</span></a>            <span class="n">size_tensor</span><span class="p">,</span> <span class="n">src</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">ranks</span><span class="p">[</span><span class="n">src</span><span class="p">],</span> <span class="n">group</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device_group</span>
</span><span id="GroupCoordinator-903"><a href="#GroupCoordinator-903"><span class="linenos"> 903</span></a>        <span class="p">)</span>
</span><span id="GroupCoordinator-904"><a href="#GroupCoordinator-904"><span class="linenos"> 904</span></a>
</span><span id="GroupCoordinator-905"><a href="#GroupCoordinator-905"><span class="linenos"> 905</span></a>        <span class="c1"># Tensor to receive serialized objects into.</span>
</span><span id="GroupCoordinator-906"><a href="#GroupCoordinator-906"><span class="linenos"> 906</span></a>        <span class="n">object_tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span>  <span class="c1"># type: ignore[call-overload]</span>
</span><span id="GroupCoordinator-907"><a href="#GroupCoordinator-907"><span class="linenos"> 907</span></a>            <span class="n">size_tensor</span><span class="o">.</span><span class="n">item</span><span class="p">(),</span>  <span class="c1"># type: ignore[arg-type]</span>
</span><span id="GroupCoordinator-908"><a href="#GroupCoordinator-908"><span class="linenos"> 908</span></a>            <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">uint8</span><span class="p">,</span>
</span><span id="GroupCoordinator-909"><a href="#GroupCoordinator-909"><span class="linenos"> 909</span></a>            <span class="n">device</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">current_device</span><span class="p">(),</span>
</span><span id="GroupCoordinator-910"><a href="#GroupCoordinator-910"><span class="linenos"> 910</span></a>        <span class="p">)</span>
</span><span id="GroupCoordinator-911"><a href="#GroupCoordinator-911"><span class="linenos"> 911</span></a>
</span><span id="GroupCoordinator-912"><a href="#GroupCoordinator-912"><span class="linenos"> 912</span></a>        <span class="n">rank_object</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">distributed</span><span class="o">.</span><span class="n">recv</span><span class="p">(</span>
</span><span id="GroupCoordinator-913"><a href="#GroupCoordinator-913"><span class="linenos"> 913</span></a>            <span class="n">object_tensor</span><span class="p">,</span> <span class="n">src</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">ranks</span><span class="p">[</span><span class="n">src</span><span class="p">],</span> <span class="n">group</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device_group</span>
</span><span id="GroupCoordinator-914"><a href="#GroupCoordinator-914"><span class="linenos"> 914</span></a>        <span class="p">)</span>
</span><span id="GroupCoordinator-915"><a href="#GroupCoordinator-915"><span class="linenos"> 915</span></a>
</span><span id="GroupCoordinator-916"><a href="#GroupCoordinator-916"><span class="linenos"> 916</span></a>        <span class="k">assert</span> <span class="p">(</span>
</span><span id="GroupCoordinator-917"><a href="#GroupCoordinator-917"><span class="linenos"> 917</span></a>            <span class="n">rank_object</span> <span class="o">==</span> <span class="n">rank_size</span>
</span><span id="GroupCoordinator-918"><a href="#GroupCoordinator-918"><span class="linenos"> 918</span></a>        <span class="p">),</span> <span class="s2">&quot;Received object sender rank does not match the size sender rank.&quot;</span>
</span><span id="GroupCoordinator-919"><a href="#GroupCoordinator-919"><span class="linenos"> 919</span></a>
</span><span id="GroupCoordinator-920"><a href="#GroupCoordinator-920"><span class="linenos"> 920</span></a>        <span class="n">obj</span> <span class="o">=</span> <span class="n">pickle</span><span class="o">.</span><span class="n">loads</span><span class="p">(</span><span class="n">object_tensor</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span><span class="o">.</span><span class="n">tobytes</span><span class="p">())</span>
</span><span id="GroupCoordinator-921"><a href="#GroupCoordinator-921"><span class="linenos"> 921</span></a>
</span><span id="GroupCoordinator-922"><a href="#GroupCoordinator-922"><span class="linenos"> 922</span></a>        <span class="k">return</span> <span class="n">obj</span>
</span><span id="GroupCoordinator-923"><a href="#GroupCoordinator-923"><span class="linenos"> 923</span></a>
</span><span id="GroupCoordinator-924"><a href="#GroupCoordinator-924"><span class="linenos"> 924</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">broadcast_tensor_dict</span><span class="p">(</span>
</span><span id="GroupCoordinator-925"><a href="#GroupCoordinator-925"><span class="linenos"> 925</span></a>        <span class="bp">self</span><span class="p">,</span>
</span><span id="GroupCoordinator-926"><a href="#GroupCoordinator-926"><span class="linenos"> 926</span></a>        <span class="n">tensor_dict</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Union</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">Any</span><span class="p">]]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="GroupCoordinator-927"><a href="#GroupCoordinator-927"><span class="linenos"> 927</span></a>        <span class="n">src</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span>
</span><span id="GroupCoordinator-928"><a href="#GroupCoordinator-928"><span class="linenos"> 928</span></a>        <span class="n">group</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">ProcessGroup</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="GroupCoordinator-929"><a href="#GroupCoordinator-929"><span class="linenos"> 929</span></a>        <span class="n">metadata_group</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">ProcessGroup</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="GroupCoordinator-930"><a href="#GroupCoordinator-930"><span class="linenos"> 930</span></a>    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Union</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">Any</span><span class="p">]]]:</span>
</span><span id="GroupCoordinator-931"><a href="#GroupCoordinator-931"><span class="linenos"> 931</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;Broadcast the input tensor dictionary.</span>
</span><span id="GroupCoordinator-932"><a href="#GroupCoordinator-932"><span class="linenos"> 932</span></a><span class="sd">        NOTE: `src` is the local rank of the source rank.</span>
</span><span id="GroupCoordinator-933"><a href="#GroupCoordinator-933"><span class="linenos"> 933</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="GroupCoordinator-934"><a href="#GroupCoordinator-934"><span class="linenos"> 934</span></a>        <span class="c1"># Bypass the function if we are using only 1 GPU.</span>
</span><span id="GroupCoordinator-935"><a href="#GroupCoordinator-935"><span class="linenos"> 935</span></a>        <span class="k">if</span> <span class="ow">not</span> <span class="n">torch</span><span class="o">.</span><span class="n">distributed</span><span class="o">.</span><span class="n">is_initialized</span><span class="p">()</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">world_size</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
</span><span id="GroupCoordinator-936"><a href="#GroupCoordinator-936"><span class="linenos"> 936</span></a>            <span class="k">return</span> <span class="n">tensor_dict</span>
</span><span id="GroupCoordinator-937"><a href="#GroupCoordinator-937"><span class="linenos"> 937</span></a>
</span><span id="GroupCoordinator-938"><a href="#GroupCoordinator-938"><span class="linenos"> 938</span></a>        <span class="n">group</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">device_group</span>
</span><span id="GroupCoordinator-939"><a href="#GroupCoordinator-939"><span class="linenos"> 939</span></a>        <span class="n">metadata_group</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">cpu_group</span>
</span><span id="GroupCoordinator-940"><a href="#GroupCoordinator-940"><span class="linenos"> 940</span></a>        <span class="k">assert</span> <span class="n">src</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">world_size</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;Invalid src rank (</span><span class="si">{</span><span class="n">src</span><span class="si">}</span><span class="s2">)&quot;</span>
</span><span id="GroupCoordinator-941"><a href="#GroupCoordinator-941"><span class="linenos"> 941</span></a>
</span><span id="GroupCoordinator-942"><a href="#GroupCoordinator-942"><span class="linenos"> 942</span></a>        <span class="n">rank_in_group</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">rank_in_group</span>
</span><span id="GroupCoordinator-943"><a href="#GroupCoordinator-943"><span class="linenos"> 943</span></a>        <span class="k">if</span> <span class="n">rank_in_group</span> <span class="o">==</span> <span class="n">src</span><span class="p">:</span>
</span><span id="GroupCoordinator-944"><a href="#GroupCoordinator-944"><span class="linenos"> 944</span></a>            <span class="n">metadata_list</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">Tuple</span><span class="p">[</span><span class="n">Any</span><span class="p">,</span> <span class="n">Any</span><span class="p">]]</span> <span class="o">=</span> <span class="p">[]</span>
</span><span id="GroupCoordinator-945"><a href="#GroupCoordinator-945"><span class="linenos"> 945</span></a>            <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span>
</span><span id="GroupCoordinator-946"><a href="#GroupCoordinator-946"><span class="linenos"> 946</span></a>                <span class="n">tensor_dict</span><span class="p">,</span> <span class="nb">dict</span>
</span><span id="GroupCoordinator-947"><a href="#GroupCoordinator-947"><span class="linenos"> 947</span></a>            <span class="p">),</span> <span class="sa">f</span><span class="s2">&quot;Expecting a dictionary, got </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">tensor_dict</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span>
</span><span id="GroupCoordinator-948"><a href="#GroupCoordinator-948"><span class="linenos"> 948</span></a>            <span class="n">metadata_list</span><span class="p">,</span> <span class="n">tensor_list</span> <span class="o">=</span> <span class="n">_split_tensor_dict</span><span class="p">(</span><span class="n">tensor_dict</span><span class="p">)</span>
</span><span id="GroupCoordinator-949"><a href="#GroupCoordinator-949"><span class="linenos"> 949</span></a>            <span class="c1"># `metadata_list` lives in CPU memory.</span>
</span><span id="GroupCoordinator-950"><a href="#GroupCoordinator-950"><span class="linenos"> 950</span></a>            <span class="c1"># `broadcast_object_list` has serialization &amp; deserialization,</span>
</span><span id="GroupCoordinator-951"><a href="#GroupCoordinator-951"><span class="linenos"> 951</span></a>            <span class="c1"># all happening on CPU. Therefore, we can use the CPU group.</span>
</span><span id="GroupCoordinator-952"><a href="#GroupCoordinator-952"><span class="linenos"> 952</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">broadcast_object</span><span class="p">(</span><span class="n">metadata_list</span><span class="p">,</span> <span class="n">src</span><span class="o">=</span><span class="n">src</span><span class="p">)</span>
</span><span id="GroupCoordinator-953"><a href="#GroupCoordinator-953"><span class="linenos"> 953</span></a>            <span class="n">async_handles</span> <span class="o">=</span> <span class="p">[]</span>
</span><span id="GroupCoordinator-954"><a href="#GroupCoordinator-954"><span class="linenos"> 954</span></a>            <span class="k">for</span> <span class="n">tensor</span> <span class="ow">in</span> <span class="n">tensor_list</span><span class="p">:</span>
</span><span id="GroupCoordinator-955"><a href="#GroupCoordinator-955"><span class="linenos"> 955</span></a>                <span class="k">if</span> <span class="n">tensor</span><span class="o">.</span><span class="n">numel</span><span class="p">()</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
</span><span id="GroupCoordinator-956"><a href="#GroupCoordinator-956"><span class="linenos"> 956</span></a>                    <span class="c1"># Skip broadcasting empty tensors.</span>
</span><span id="GroupCoordinator-957"><a href="#GroupCoordinator-957"><span class="linenos"> 957</span></a>                    <span class="k">continue</span>
</span><span id="GroupCoordinator-958"><a href="#GroupCoordinator-958"><span class="linenos"> 958</span></a>                <span class="k">if</span> <span class="n">tensor</span><span class="o">.</span><span class="n">is_cpu</span><span class="p">:</span>
</span><span id="GroupCoordinator-959"><a href="#GroupCoordinator-959"><span class="linenos"> 959</span></a>                    <span class="c1"># use metadata_group for CPU tensors</span>
</span><span id="GroupCoordinator-960"><a href="#GroupCoordinator-960"><span class="linenos"> 960</span></a>                    <span class="n">handle</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">distributed</span><span class="o">.</span><span class="n">broadcast</span><span class="p">(</span>
</span><span id="GroupCoordinator-961"><a href="#GroupCoordinator-961"><span class="linenos"> 961</span></a>                        <span class="n">tensor</span><span class="p">,</span> <span class="n">src</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">ranks</span><span class="p">[</span><span class="n">src</span><span class="p">],</span> <span class="n">group</span><span class="o">=</span><span class="n">metadata_group</span><span class="p">,</span> <span class="n">async_op</span><span class="o">=</span><span class="kc">True</span>
</span><span id="GroupCoordinator-962"><a href="#GroupCoordinator-962"><span class="linenos"> 962</span></a>                    <span class="p">)</span>
</span><span id="GroupCoordinator-963"><a href="#GroupCoordinator-963"><span class="linenos"> 963</span></a>                <span class="k">else</span><span class="p">:</span>
</span><span id="GroupCoordinator-964"><a href="#GroupCoordinator-964"><span class="linenos"> 964</span></a>                    <span class="c1"># use group for GPU tensors</span>
</span><span id="GroupCoordinator-965"><a href="#GroupCoordinator-965"><span class="linenos"> 965</span></a>                    <span class="n">handle</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">distributed</span><span class="o">.</span><span class="n">broadcast</span><span class="p">(</span>
</span><span id="GroupCoordinator-966"><a href="#GroupCoordinator-966"><span class="linenos"> 966</span></a>                        <span class="n">tensor</span><span class="p">,</span> <span class="n">src</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">ranks</span><span class="p">[</span><span class="n">src</span><span class="p">],</span> <span class="n">group</span><span class="o">=</span><span class="n">group</span><span class="p">,</span> <span class="n">async_op</span><span class="o">=</span><span class="kc">True</span>
</span><span id="GroupCoordinator-967"><a href="#GroupCoordinator-967"><span class="linenos"> 967</span></a>                    <span class="p">)</span>
</span><span id="GroupCoordinator-968"><a href="#GroupCoordinator-968"><span class="linenos"> 968</span></a>                <span class="n">async_handles</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">handle</span><span class="p">)</span>
</span><span id="GroupCoordinator-969"><a href="#GroupCoordinator-969"><span class="linenos"> 969</span></a>            <span class="k">for</span> <span class="n">async_handle</span> <span class="ow">in</span> <span class="n">async_handles</span><span class="p">:</span>
</span><span id="GroupCoordinator-970"><a href="#GroupCoordinator-970"><span class="linenos"> 970</span></a>                <span class="n">async_handle</span><span class="o">.</span><span class="n">wait</span><span class="p">()</span>
</span><span id="GroupCoordinator-971"><a href="#GroupCoordinator-971"><span class="linenos"> 971</span></a>
</span><span id="GroupCoordinator-972"><a href="#GroupCoordinator-972"><span class="linenos"> 972</span></a>        <span class="k">else</span><span class="p">:</span>
</span><span id="GroupCoordinator-973"><a href="#GroupCoordinator-973"><span class="linenos"> 973</span></a>            <span class="n">metadata_list</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">broadcast_object</span><span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="n">src</span><span class="o">=</span><span class="n">src</span><span class="p">)</span>
</span><span id="GroupCoordinator-974"><a href="#GroupCoordinator-974"><span class="linenos"> 974</span></a>            <span class="n">tensor_dict</span> <span class="o">=</span> <span class="p">{}</span>
</span><span id="GroupCoordinator-975"><a href="#GroupCoordinator-975"><span class="linenos"> 975</span></a>            <span class="n">async_handles</span> <span class="o">=</span> <span class="p">[]</span>
</span><span id="GroupCoordinator-976"><a href="#GroupCoordinator-976"><span class="linenos"> 976</span></a>            <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">metadata_list</span><span class="p">:</span>
</span><span id="GroupCoordinator-977"><a href="#GroupCoordinator-977"><span class="linenos"> 977</span></a>                <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">value</span><span class="p">,</span> <span class="n">TensorMetadata</span><span class="p">):</span>
</span><span id="GroupCoordinator-978"><a href="#GroupCoordinator-978"><span class="linenos"> 978</span></a>                    <span class="n">tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span>
</span><span id="GroupCoordinator-979"><a href="#GroupCoordinator-979"><span class="linenos"> 979</span></a>                        <span class="n">value</span><span class="o">.</span><span class="n">size</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">value</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">value</span><span class="o">.</span><span class="n">device</span>
</span><span id="GroupCoordinator-980"><a href="#GroupCoordinator-980"><span class="linenos"> 980</span></a>                    <span class="p">)</span>
</span><span id="GroupCoordinator-981"><a href="#GroupCoordinator-981"><span class="linenos"> 981</span></a>                    <span class="k">if</span> <span class="n">tensor</span><span class="o">.</span><span class="n">numel</span><span class="p">()</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
</span><span id="GroupCoordinator-982"><a href="#GroupCoordinator-982"><span class="linenos"> 982</span></a>                        <span class="c1"># Skip broadcasting empty tensors.</span>
</span><span id="GroupCoordinator-983"><a href="#GroupCoordinator-983"><span class="linenos"> 983</span></a>                        <span class="n">tensor_dict</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">=</span> <span class="n">tensor</span>
</span><span id="GroupCoordinator-984"><a href="#GroupCoordinator-984"><span class="linenos"> 984</span></a>                        <span class="k">continue</span>
</span><span id="GroupCoordinator-985"><a href="#GroupCoordinator-985"><span class="linenos"> 985</span></a>                    <span class="k">if</span> <span class="n">tensor</span><span class="o">.</span><span class="n">is_cpu</span><span class="p">:</span>
</span><span id="GroupCoordinator-986"><a href="#GroupCoordinator-986"><span class="linenos"> 986</span></a>                        <span class="c1"># use metadata_group for CPU tensors</span>
</span><span id="GroupCoordinator-987"><a href="#GroupCoordinator-987"><span class="linenos"> 987</span></a>                        <span class="n">handle</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">distributed</span><span class="o">.</span><span class="n">broadcast</span><span class="p">(</span>
</span><span id="GroupCoordinator-988"><a href="#GroupCoordinator-988"><span class="linenos"> 988</span></a>                            <span class="n">tensor</span><span class="p">,</span>
</span><span id="GroupCoordinator-989"><a href="#GroupCoordinator-989"><span class="linenos"> 989</span></a>                            <span class="n">src</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">ranks</span><span class="p">[</span><span class="n">src</span><span class="p">],</span>
</span><span id="GroupCoordinator-990"><a href="#GroupCoordinator-990"><span class="linenos"> 990</span></a>                            <span class="n">group</span><span class="o">=</span><span class="n">metadata_group</span><span class="p">,</span>
</span><span id="GroupCoordinator-991"><a href="#GroupCoordinator-991"><span class="linenos"> 991</span></a>                            <span class="n">async_op</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
</span><span id="GroupCoordinator-992"><a href="#GroupCoordinator-992"><span class="linenos"> 992</span></a>                        <span class="p">)</span>
</span><span id="GroupCoordinator-993"><a href="#GroupCoordinator-993"><span class="linenos"> 993</span></a>                    <span class="k">else</span><span class="p">:</span>
</span><span id="GroupCoordinator-994"><a href="#GroupCoordinator-994"><span class="linenos"> 994</span></a>                        <span class="c1"># use group for GPU tensors</span>
</span><span id="GroupCoordinator-995"><a href="#GroupCoordinator-995"><span class="linenos"> 995</span></a>                        <span class="n">handle</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">distributed</span><span class="o">.</span><span class="n">broadcast</span><span class="p">(</span>
</span><span id="GroupCoordinator-996"><a href="#GroupCoordinator-996"><span class="linenos"> 996</span></a>                            <span class="n">tensor</span><span class="p">,</span> <span class="n">src</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">ranks</span><span class="p">[</span><span class="n">src</span><span class="p">],</span> <span class="n">group</span><span class="o">=</span><span class="n">group</span><span class="p">,</span> <span class="n">async_op</span><span class="o">=</span><span class="kc">True</span>
</span><span id="GroupCoordinator-997"><a href="#GroupCoordinator-997"><span class="linenos"> 997</span></a>                        <span class="p">)</span>
</span><span id="GroupCoordinator-998"><a href="#GroupCoordinator-998"><span class="linenos"> 998</span></a>                    <span class="n">async_handles</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">handle</span><span class="p">)</span>
</span><span id="GroupCoordinator-999"><a href="#GroupCoordinator-999"><span class="linenos"> 999</span></a>                    <span class="n">tensor_dict</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">=</span> <span class="n">tensor</span>
</span><span id="GroupCoordinator-1000"><a href="#GroupCoordinator-1000"><span class="linenos">1000</span></a>                <span class="k">else</span><span class="p">:</span>
</span><span id="GroupCoordinator-1001"><a href="#GroupCoordinator-1001"><span class="linenos">1001</span></a>                    <span class="n">tensor_dict</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">=</span> <span class="n">value</span>
</span><span id="GroupCoordinator-1002"><a href="#GroupCoordinator-1002"><span class="linenos">1002</span></a>            <span class="k">for</span> <span class="n">async_handle</span> <span class="ow">in</span> <span class="n">async_handles</span><span class="p">:</span>
</span><span id="GroupCoordinator-1003"><a href="#GroupCoordinator-1003"><span class="linenos">1003</span></a>                <span class="n">async_handle</span><span class="o">.</span><span class="n">wait</span><span class="p">()</span>
</span><span id="GroupCoordinator-1004"><a href="#GroupCoordinator-1004"><span class="linenos">1004</span></a>        <span class="k">return</span> <span class="n">tensor_dict</span>
</span><span id="GroupCoordinator-1005"><a href="#GroupCoordinator-1005"><span class="linenos">1005</span></a>
</span><span id="GroupCoordinator-1006"><a href="#GroupCoordinator-1006"><span class="linenos">1006</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">send_tensor_dict</span><span class="p">(</span>
</span><span id="GroupCoordinator-1007"><a href="#GroupCoordinator-1007"><span class="linenos">1007</span></a>        <span class="bp">self</span><span class="p">,</span>
</span><span id="GroupCoordinator-1008"><a href="#GroupCoordinator-1008"><span class="linenos">1008</span></a>        <span class="n">tensor_dict</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Union</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">Any</span><span class="p">]],</span>
</span><span id="GroupCoordinator-1009"><a href="#GroupCoordinator-1009"><span class="linenos">1009</span></a>        <span class="n">dst</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="GroupCoordinator-1010"><a href="#GroupCoordinator-1010"><span class="linenos">1010</span></a>        <span class="n">all_gather_group</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="s2">&quot;GroupCoordinator&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="GroupCoordinator-1011"><a href="#GroupCoordinator-1011"><span class="linenos">1011</span></a>    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Union</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">Any</span><span class="p">]]]:</span>
</span><span id="GroupCoordinator-1012"><a href="#GroupCoordinator-1012"><span class="linenos">1012</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;Send the input tensor dictionary.</span>
</span><span id="GroupCoordinator-1013"><a href="#GroupCoordinator-1013"><span class="linenos">1013</span></a><span class="sd">        NOTE: `dst` is the local rank of the source rank.</span>
</span><span id="GroupCoordinator-1014"><a href="#GroupCoordinator-1014"><span class="linenos">1014</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="GroupCoordinator-1015"><a href="#GroupCoordinator-1015"><span class="linenos">1015</span></a>        <span class="c1"># Bypass the function if we are using only 1 GPU.</span>
</span><span id="GroupCoordinator-1016"><a href="#GroupCoordinator-1016"><span class="linenos">1016</span></a>        <span class="k">if</span> <span class="ow">not</span> <span class="n">torch</span><span class="o">.</span><span class="n">distributed</span><span class="o">.</span><span class="n">is_initialized</span><span class="p">()</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">world_size</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
</span><span id="GroupCoordinator-1017"><a href="#GroupCoordinator-1017"><span class="linenos">1017</span></a>            <span class="k">return</span> <span class="n">tensor_dict</span>
</span><span id="GroupCoordinator-1018"><a href="#GroupCoordinator-1018"><span class="linenos">1018</span></a>
</span><span id="GroupCoordinator-1019"><a href="#GroupCoordinator-1019"><span class="linenos">1019</span></a>        <span class="n">all_gather_size</span> <span class="o">=</span> <span class="mi">1</span> <span class="k">if</span> <span class="n">all_gather_group</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">all_gather_group</span><span class="o">.</span><span class="n">world_size</span>
</span><span id="GroupCoordinator-1020"><a href="#GroupCoordinator-1020"><span class="linenos">1020</span></a>        <span class="n">all_gather_rank</span> <span class="o">=</span> <span class="p">(</span>
</span><span id="GroupCoordinator-1021"><a href="#GroupCoordinator-1021"><span class="linenos">1021</span></a>            <span class="mi">0</span> <span class="k">if</span> <span class="n">all_gather_group</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">all_gather_group</span><span class="o">.</span><span class="n">rank_in_group</span>
</span><span id="GroupCoordinator-1022"><a href="#GroupCoordinator-1022"><span class="linenos">1022</span></a>        <span class="p">)</span>
</span><span id="GroupCoordinator-1023"><a href="#GroupCoordinator-1023"><span class="linenos">1023</span></a>
</span><span id="GroupCoordinator-1024"><a href="#GroupCoordinator-1024"><span class="linenos">1024</span></a>        <span class="n">group</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">device_group</span>
</span><span id="GroupCoordinator-1025"><a href="#GroupCoordinator-1025"><span class="linenos">1025</span></a>        <span class="n">metadata_group</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">cpu_group</span>
</span><span id="GroupCoordinator-1026"><a href="#GroupCoordinator-1026"><span class="linenos">1026</span></a>
</span><span id="GroupCoordinator-1027"><a href="#GroupCoordinator-1027"><span class="linenos">1027</span></a>        <span class="k">if</span> <span class="n">dst</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="GroupCoordinator-1028"><a href="#GroupCoordinator-1028"><span class="linenos">1028</span></a>            <span class="n">dst</span> <span class="o">=</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">rank_in_group</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">%</span> <span class="bp">self</span><span class="o">.</span><span class="n">world_size</span>
</span><span id="GroupCoordinator-1029"><a href="#GroupCoordinator-1029"><span class="linenos">1029</span></a>        <span class="k">assert</span> <span class="n">dst</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">world_size</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;Invalid dst rank (</span><span class="si">{</span><span class="n">dst</span><span class="si">}</span><span class="s2">)&quot;</span>
</span><span id="GroupCoordinator-1030"><a href="#GroupCoordinator-1030"><span class="linenos">1030</span></a>
</span><span id="GroupCoordinator-1031"><a href="#GroupCoordinator-1031"><span class="linenos">1031</span></a>        <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span>
</span><span id="GroupCoordinator-1032"><a href="#GroupCoordinator-1032"><span class="linenos">1032</span></a>            <span class="n">tensor_dict</span><span class="p">,</span> <span class="nb">dict</span>
</span><span id="GroupCoordinator-1033"><a href="#GroupCoordinator-1033"><span class="linenos">1033</span></a>        <span class="p">),</span> <span class="sa">f</span><span class="s2">&quot;Expecting a dictionary, got </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">tensor_dict</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span>
</span><span id="GroupCoordinator-1034"><a href="#GroupCoordinator-1034"><span class="linenos">1034</span></a>        <span class="n">metadata_list</span><span class="p">,</span> <span class="n">tensor_list</span> <span class="o">=</span> <span class="n">_split_tensor_dict</span><span class="p">(</span><span class="n">tensor_dict</span><span class="p">)</span>
</span><span id="GroupCoordinator-1035"><a href="#GroupCoordinator-1035"><span class="linenos">1035</span></a>        <span class="c1"># Note: While switching to Device-to-Device (D2D) would introduce an extra</span>
</span><span id="GroupCoordinator-1036"><a href="#GroupCoordinator-1036"><span class="linenos">1036</span></a>        <span class="c1"># Device-to-Host (D2H) memory copy overhead for serialization, our benchmarks</span>
</span><span id="GroupCoordinator-1037"><a href="#GroupCoordinator-1037"><span class="linenos">1037</span></a>        <span class="c1"># show better overall transmission performance with D2D due to:</span>
</span><span id="GroupCoordinator-1038"><a href="#GroupCoordinator-1038"><span class="linenos">1038</span></a>        <span class="c1"># 1. Superior D2D transfer bandwidth</span>
</span><span id="GroupCoordinator-1039"><a href="#GroupCoordinator-1039"><span class="linenos">1039</span></a>        <span class="c1"># 2. Ability to overlap send and recv operations</span>
</span><span id="GroupCoordinator-1040"><a href="#GroupCoordinator-1040"><span class="linenos">1040</span></a>        <span class="c1"># Thus the net performance gain justifies this approach.</span>
</span><span id="GroupCoordinator-1041"><a href="#GroupCoordinator-1041"><span class="linenos">1041</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">send_object</span><span class="p">(</span><span class="n">metadata_list</span><span class="p">,</span> <span class="n">dst</span><span class="o">=</span><span class="n">dst</span><span class="p">)</span>
</span><span id="GroupCoordinator-1042"><a href="#GroupCoordinator-1042"><span class="linenos">1042</span></a>        <span class="k">for</span> <span class="n">tensor</span> <span class="ow">in</span> <span class="n">tensor_list</span><span class="p">:</span>
</span><span id="GroupCoordinator-1043"><a href="#GroupCoordinator-1043"><span class="linenos">1043</span></a>            <span class="k">if</span> <span class="n">tensor</span><span class="o">.</span><span class="n">numel</span><span class="p">()</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
</span><span id="GroupCoordinator-1044"><a href="#GroupCoordinator-1044"><span class="linenos">1044</span></a>                <span class="c1"># Skip sending empty tensors.</span>
</span><span id="GroupCoordinator-1045"><a href="#GroupCoordinator-1045"><span class="linenos">1045</span></a>                <span class="k">continue</span>
</span><span id="GroupCoordinator-1046"><a href="#GroupCoordinator-1046"><span class="linenos">1046</span></a>
</span><span id="GroupCoordinator-1047"><a href="#GroupCoordinator-1047"><span class="linenos">1047</span></a>            <span class="c1"># send-allgather: send only a slice, then do allgather.</span>
</span><span id="GroupCoordinator-1048"><a href="#GroupCoordinator-1048"><span class="linenos">1048</span></a>            <span class="k">if</span> <span class="n">all_gather_group</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">tensor</span><span class="o">.</span><span class="n">numel</span><span class="p">()</span> <span class="o">%</span> <span class="n">all_gather_size</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
</span><span id="GroupCoordinator-1049"><a href="#GroupCoordinator-1049"><span class="linenos">1049</span></a>                <span class="n">tensor</span> <span class="o">=</span> <span class="n">tensor</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">all_gather_size</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)[</span><span class="n">all_gather_rank</span><span class="p">]</span>
</span><span id="GroupCoordinator-1050"><a href="#GroupCoordinator-1050"><span class="linenos">1050</span></a>
</span><span id="GroupCoordinator-1051"><a href="#GroupCoordinator-1051"><span class="linenos">1051</span></a>            <span class="k">if</span> <span class="n">tensor</span><span class="o">.</span><span class="n">is_cpu</span><span class="p">:</span>
</span><span id="GroupCoordinator-1052"><a href="#GroupCoordinator-1052"><span class="linenos">1052</span></a>                <span class="c1"># use metadata_group for CPU tensors</span>
</span><span id="GroupCoordinator-1053"><a href="#GroupCoordinator-1053"><span class="linenos">1053</span></a>                <span class="n">torch</span><span class="o">.</span><span class="n">distributed</span><span class="o">.</span><span class="n">send</span><span class="p">(</span>
</span><span id="GroupCoordinator-1054"><a href="#GroupCoordinator-1054"><span class="linenos">1054</span></a>                    <span class="n">tensor</span><span class="p">,</span> <span class="n">dst</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">ranks</span><span class="p">[</span><span class="n">dst</span><span class="p">],</span> <span class="n">group</span><span class="o">=</span><span class="n">metadata_group</span>
</span><span id="GroupCoordinator-1055"><a href="#GroupCoordinator-1055"><span class="linenos">1055</span></a>                <span class="p">)</span>
</span><span id="GroupCoordinator-1056"><a href="#GroupCoordinator-1056"><span class="linenos">1056</span></a>            <span class="k">else</span><span class="p">:</span>
</span><span id="GroupCoordinator-1057"><a href="#GroupCoordinator-1057"><span class="linenos">1057</span></a>                <span class="c1"># use group for GPU tensors</span>
</span><span id="GroupCoordinator-1058"><a href="#GroupCoordinator-1058"><span class="linenos">1058</span></a>                <span class="n">torch</span><span class="o">.</span><span class="n">distributed</span><span class="o">.</span><span class="n">send</span><span class="p">(</span><span class="n">tensor</span><span class="p">,</span> <span class="n">dst</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">ranks</span><span class="p">[</span><span class="n">dst</span><span class="p">],</span> <span class="n">group</span><span class="o">=</span><span class="n">group</span><span class="p">)</span>
</span><span id="GroupCoordinator-1059"><a href="#GroupCoordinator-1059"><span class="linenos">1059</span></a>        <span class="k">return</span> <span class="kc">None</span>
</span><span id="GroupCoordinator-1060"><a href="#GroupCoordinator-1060"><span class="linenos">1060</span></a>
</span><span id="GroupCoordinator-1061"><a href="#GroupCoordinator-1061"><span class="linenos">1061</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">recv_tensor_dict</span><span class="p">(</span>
</span><span id="GroupCoordinator-1062"><a href="#GroupCoordinator-1062"><span class="linenos">1062</span></a>        <span class="bp">self</span><span class="p">,</span>
</span><span id="GroupCoordinator-1063"><a href="#GroupCoordinator-1063"><span class="linenos">1063</span></a>        <span class="n">src</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="GroupCoordinator-1064"><a href="#GroupCoordinator-1064"><span class="linenos">1064</span></a>        <span class="n">all_gather_group</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="s2">&quot;GroupCoordinator&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="GroupCoordinator-1065"><a href="#GroupCoordinator-1065"><span class="linenos">1065</span></a>    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Union</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">Any</span><span class="p">]]]:</span>
</span><span id="GroupCoordinator-1066"><a href="#GroupCoordinator-1066"><span class="linenos">1066</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;Recv the input tensor dictionary.</span>
</span><span id="GroupCoordinator-1067"><a href="#GroupCoordinator-1067"><span class="linenos">1067</span></a><span class="sd">        NOTE: `src` is the local rank of the source rank.</span>
</span><span id="GroupCoordinator-1068"><a href="#GroupCoordinator-1068"><span class="linenos">1068</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="GroupCoordinator-1069"><a href="#GroupCoordinator-1069"><span class="linenos">1069</span></a>        <span class="c1"># Bypass the function if we are using only 1 GPU.</span>
</span><span id="GroupCoordinator-1070"><a href="#GroupCoordinator-1070"><span class="linenos">1070</span></a>        <span class="k">if</span> <span class="ow">not</span> <span class="n">torch</span><span class="o">.</span><span class="n">distributed</span><span class="o">.</span><span class="n">is_initialized</span><span class="p">()</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">world_size</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
</span><span id="GroupCoordinator-1071"><a href="#GroupCoordinator-1071"><span class="linenos">1071</span></a>            <span class="k">return</span> <span class="kc">None</span>
</span><span id="GroupCoordinator-1072"><a href="#GroupCoordinator-1072"><span class="linenos">1072</span></a>
</span><span id="GroupCoordinator-1073"><a href="#GroupCoordinator-1073"><span class="linenos">1073</span></a>        <span class="n">all_gather_size</span> <span class="o">=</span> <span class="mi">1</span> <span class="k">if</span> <span class="n">all_gather_group</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">all_gather_group</span><span class="o">.</span><span class="n">world_size</span>
</span><span id="GroupCoordinator-1074"><a href="#GroupCoordinator-1074"><span class="linenos">1074</span></a>        <span class="n">all_gather_rank</span> <span class="o">=</span> <span class="p">(</span>
</span><span id="GroupCoordinator-1075"><a href="#GroupCoordinator-1075"><span class="linenos">1075</span></a>            <span class="mi">0</span> <span class="k">if</span> <span class="n">all_gather_group</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">all_gather_group</span><span class="o">.</span><span class="n">rank_in_group</span>
</span><span id="GroupCoordinator-1076"><a href="#GroupCoordinator-1076"><span class="linenos">1076</span></a>        <span class="p">)</span>
</span><span id="GroupCoordinator-1077"><a href="#GroupCoordinator-1077"><span class="linenos">1077</span></a>
</span><span id="GroupCoordinator-1078"><a href="#GroupCoordinator-1078"><span class="linenos">1078</span></a>        <span class="n">group</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">device_group</span>
</span><span id="GroupCoordinator-1079"><a href="#GroupCoordinator-1079"><span class="linenos">1079</span></a>        <span class="n">metadata_group</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">cpu_group</span>
</span><span id="GroupCoordinator-1080"><a href="#GroupCoordinator-1080"><span class="linenos">1080</span></a>
</span><span id="GroupCoordinator-1081"><a href="#GroupCoordinator-1081"><span class="linenos">1081</span></a>        <span class="k">if</span> <span class="n">src</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="GroupCoordinator-1082"><a href="#GroupCoordinator-1082"><span class="linenos">1082</span></a>            <span class="n">src</span> <span class="o">=</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">rank_in_group</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">%</span> <span class="bp">self</span><span class="o">.</span><span class="n">world_size</span>
</span><span id="GroupCoordinator-1083"><a href="#GroupCoordinator-1083"><span class="linenos">1083</span></a>        <span class="k">assert</span> <span class="n">src</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">world_size</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;Invalid src rank (</span><span class="si">{</span><span class="n">src</span><span class="si">}</span><span class="s2">)&quot;</span>
</span><span id="GroupCoordinator-1084"><a href="#GroupCoordinator-1084"><span class="linenos">1084</span></a>
</span><span id="GroupCoordinator-1085"><a href="#GroupCoordinator-1085"><span class="linenos">1085</span></a>        <span class="n">recv_metadata_list</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">recv_object</span><span class="p">(</span><span class="n">src</span><span class="o">=</span><span class="n">src</span><span class="p">)</span>
</span><span id="GroupCoordinator-1086"><a href="#GroupCoordinator-1086"><span class="linenos">1086</span></a>        <span class="n">tensor_dict</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]</span> <span class="o">=</span> <span class="p">{}</span>
</span><span id="GroupCoordinator-1087"><a href="#GroupCoordinator-1087"><span class="linenos">1087</span></a>        <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">recv_metadata_list</span><span class="p">:</span>
</span><span id="GroupCoordinator-1088"><a href="#GroupCoordinator-1088"><span class="linenos">1088</span></a>            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">value</span><span class="p">,</span> <span class="n">TensorMetadata</span><span class="p">):</span>
</span><span id="GroupCoordinator-1089"><a href="#GroupCoordinator-1089"><span class="linenos">1089</span></a>                <span class="n">tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span><span class="n">value</span><span class="o">.</span><span class="n">size</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">value</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">value</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
</span><span id="GroupCoordinator-1090"><a href="#GroupCoordinator-1090"><span class="linenos">1090</span></a>                <span class="k">if</span> <span class="n">tensor</span><span class="o">.</span><span class="n">numel</span><span class="p">()</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
</span><span id="GroupCoordinator-1091"><a href="#GroupCoordinator-1091"><span class="linenos">1091</span></a>                    <span class="c1"># Skip broadcasting empty tensors.</span>
</span><span id="GroupCoordinator-1092"><a href="#GroupCoordinator-1092"><span class="linenos">1092</span></a>                    <span class="n">tensor_dict</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">=</span> <span class="n">tensor</span>
</span><span id="GroupCoordinator-1093"><a href="#GroupCoordinator-1093"><span class="linenos">1093</span></a>                    <span class="k">continue</span>
</span><span id="GroupCoordinator-1094"><a href="#GroupCoordinator-1094"><span class="linenos">1094</span></a>
</span><span id="GroupCoordinator-1095"><a href="#GroupCoordinator-1095"><span class="linenos">1095</span></a>                <span class="c1"># send-allgather: send only a slice, then do allgather.</span>
</span><span id="GroupCoordinator-1096"><a href="#GroupCoordinator-1096"><span class="linenos">1096</span></a>                <span class="n">use_all_gather</span> <span class="o">=</span> <span class="p">(</span>
</span><span id="GroupCoordinator-1097"><a href="#GroupCoordinator-1097"><span class="linenos">1097</span></a>                    <span class="n">all_gather_group</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
</span><span id="GroupCoordinator-1098"><a href="#GroupCoordinator-1098"><span class="linenos">1098</span></a>                    <span class="ow">and</span> <span class="n">tensor</span><span class="o">.</span><span class="n">numel</span><span class="p">()</span> <span class="o">%</span> <span class="n">all_gather_size</span> <span class="o">==</span> <span class="mi">0</span>
</span><span id="GroupCoordinator-1099"><a href="#GroupCoordinator-1099"><span class="linenos">1099</span></a>                <span class="p">)</span>
</span><span id="GroupCoordinator-1100"><a href="#GroupCoordinator-1100"><span class="linenos">1100</span></a>
</span><span id="GroupCoordinator-1101"><a href="#GroupCoordinator-1101"><span class="linenos">1101</span></a>                <span class="k">if</span> <span class="n">use_all_gather</span><span class="p">:</span>
</span><span id="GroupCoordinator-1102"><a href="#GroupCoordinator-1102"><span class="linenos">1102</span></a>                    <span class="n">orig_shape</span> <span class="o">=</span> <span class="n">tensor</span><span class="o">.</span><span class="n">shape</span>
</span><span id="GroupCoordinator-1103"><a href="#GroupCoordinator-1103"><span class="linenos">1103</span></a>                    <span class="n">tensor</span> <span class="o">=</span> <span class="n">tensor</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">all_gather_size</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)[</span><span class="n">all_gather_rank</span><span class="p">]</span>
</span><span id="GroupCoordinator-1104"><a href="#GroupCoordinator-1104"><span class="linenos">1104</span></a>
</span><span id="GroupCoordinator-1105"><a href="#GroupCoordinator-1105"><span class="linenos">1105</span></a>                <span class="k">if</span> <span class="n">tensor</span><span class="o">.</span><span class="n">is_cpu</span><span class="p">:</span>
</span><span id="GroupCoordinator-1106"><a href="#GroupCoordinator-1106"><span class="linenos">1106</span></a>                    <span class="c1"># use metadata_group for CPU tensors</span>
</span><span id="GroupCoordinator-1107"><a href="#GroupCoordinator-1107"><span class="linenos">1107</span></a>                    <span class="n">torch</span><span class="o">.</span><span class="n">distributed</span><span class="o">.</span><span class="n">recv</span><span class="p">(</span>
</span><span id="GroupCoordinator-1108"><a href="#GroupCoordinator-1108"><span class="linenos">1108</span></a>                        <span class="n">tensor</span><span class="p">,</span> <span class="n">src</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">ranks</span><span class="p">[</span><span class="n">src</span><span class="p">],</span> <span class="n">group</span><span class="o">=</span><span class="n">metadata_group</span>
</span><span id="GroupCoordinator-1109"><a href="#GroupCoordinator-1109"><span class="linenos">1109</span></a>                    <span class="p">)</span>
</span><span id="GroupCoordinator-1110"><a href="#GroupCoordinator-1110"><span class="linenos">1110</span></a>                <span class="k">else</span><span class="p">:</span>
</span><span id="GroupCoordinator-1111"><a href="#GroupCoordinator-1111"><span class="linenos">1111</span></a>                    <span class="c1"># use group for GPU tensors</span>
</span><span id="GroupCoordinator-1112"><a href="#GroupCoordinator-1112"><span class="linenos">1112</span></a>                    <span class="n">torch</span><span class="o">.</span><span class="n">distributed</span><span class="o">.</span><span class="n">recv</span><span class="p">(</span><span class="n">tensor</span><span class="p">,</span> <span class="n">src</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">ranks</span><span class="p">[</span><span class="n">src</span><span class="p">],</span> <span class="n">group</span><span class="o">=</span><span class="n">group</span><span class="p">)</span>
</span><span id="GroupCoordinator-1113"><a href="#GroupCoordinator-1113"><span class="linenos">1113</span></a>                <span class="k">if</span> <span class="n">use_all_gather</span><span class="p">:</span>
</span><span id="GroupCoordinator-1114"><a href="#GroupCoordinator-1114"><span class="linenos">1114</span></a>                    <span class="c1"># do the allgather</span>
</span><span id="GroupCoordinator-1115"><a href="#GroupCoordinator-1115"><span class="linenos">1115</span></a>                    <span class="n">tensor</span> <span class="o">=</span> <span class="n">all_gather_group</span><span class="o">.</span><span class="n">all_gather</span><span class="p">(</span><span class="n">tensor</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>  <span class="c1"># type: ignore</span>
</span><span id="GroupCoordinator-1116"><a href="#GroupCoordinator-1116"><span class="linenos">1116</span></a>                    <span class="n">tensor</span> <span class="o">=</span> <span class="n">tensor</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">orig_shape</span><span class="p">)</span>
</span><span id="GroupCoordinator-1117"><a href="#GroupCoordinator-1117"><span class="linenos">1117</span></a>
</span><span id="GroupCoordinator-1118"><a href="#GroupCoordinator-1118"><span class="linenos">1118</span></a>                <span class="n">tensor_dict</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">=</span> <span class="n">tensor</span>
</span><span id="GroupCoordinator-1119"><a href="#GroupCoordinator-1119"><span class="linenos">1119</span></a>            <span class="k">else</span><span class="p">:</span>
</span><span id="GroupCoordinator-1120"><a href="#GroupCoordinator-1120"><span class="linenos">1120</span></a>                <span class="n">tensor_dict</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">=</span> <span class="n">value</span>
</span><span id="GroupCoordinator-1121"><a href="#GroupCoordinator-1121"><span class="linenos">1121</span></a>        <span class="k">return</span> <span class="n">tensor_dict</span>
</span><span id="GroupCoordinator-1122"><a href="#GroupCoordinator-1122"><span class="linenos">1122</span></a>
</span><span id="GroupCoordinator-1123"><a href="#GroupCoordinator-1123"><span class="linenos">1123</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">barrier</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
</span><span id="GroupCoordinator-1124"><a href="#GroupCoordinator-1124"><span class="linenos">1124</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;Barrier synchronization among the group.</span>
</span><span id="GroupCoordinator-1125"><a href="#GroupCoordinator-1125"><span class="linenos">1125</span></a><span class="sd">        NOTE: don&#39;t use `device_group` here! `barrier` in NCCL is</span>
</span><span id="GroupCoordinator-1126"><a href="#GroupCoordinator-1126"><span class="linenos">1126</span></a><span class="sd">        terrible because it is internally a broadcast operation with</span>
</span><span id="GroupCoordinator-1127"><a href="#GroupCoordinator-1127"><span class="linenos">1127</span></a><span class="sd">        secretly created GPU tensors. It is easy to mess up the current</span>
</span><span id="GroupCoordinator-1128"><a href="#GroupCoordinator-1128"><span class="linenos">1128</span></a><span class="sd">        device. Use the CPU group instead.</span>
</span><span id="GroupCoordinator-1129"><a href="#GroupCoordinator-1129"><span class="linenos">1129</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="GroupCoordinator-1130"><a href="#GroupCoordinator-1130"><span class="linenos">1130</span></a>        <span class="n">torch</span><span class="o">.</span><span class="n">distributed</span><span class="o">.</span><span class="n">barrier</span><span class="p">(</span><span class="n">group</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">cpu_group</span><span class="p">)</span>
</span><span id="GroupCoordinator-1131"><a href="#GroupCoordinator-1131"><span class="linenos">1131</span></a>
</span><span id="GroupCoordinator-1132"><a href="#GroupCoordinator-1132"><span class="linenos">1132</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">send</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">tensor</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">dst</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="GroupCoordinator-1133"><a href="#GroupCoordinator-1133"><span class="linenos">1133</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;Sends a tensor to the destination rank in a non-blocking way&quot;&quot;&quot;</span>
</span><span id="GroupCoordinator-1134"><a href="#GroupCoordinator-1134"><span class="linenos">1134</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;NOTE: `dst` is the local rank of the destination rank.&quot;&quot;&quot;</span>
</span><span id="GroupCoordinator-1135"><a href="#GroupCoordinator-1135"><span class="linenos">1135</span></a>        <span class="k">if</span> <span class="n">dst</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="GroupCoordinator-1136"><a href="#GroupCoordinator-1136"><span class="linenos">1136</span></a>            <span class="n">dst</span> <span class="o">=</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">rank_in_group</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">%</span> <span class="bp">self</span><span class="o">.</span><span class="n">world_size</span>
</span><span id="GroupCoordinator-1137"><a href="#GroupCoordinator-1137"><span class="linenos">1137</span></a>
</span><span id="GroupCoordinator-1138"><a href="#GroupCoordinator-1138"><span class="linenos">1138</span></a>        <span class="n">pynccl_comm</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">pynccl_comm</span>
</span><span id="GroupCoordinator-1139"><a href="#GroupCoordinator-1139"><span class="linenos">1139</span></a>        <span class="k">if</span> <span class="n">pynccl_comm</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">pynccl_comm</span><span class="o">.</span><span class="n">disabled</span><span class="p">:</span>
</span><span id="GroupCoordinator-1140"><a href="#GroupCoordinator-1140"><span class="linenos">1140</span></a>            <span class="n">pynccl_comm</span><span class="o">.</span><span class="n">send</span><span class="p">(</span><span class="n">tensor</span><span class="p">,</span> <span class="n">dst</span><span class="p">)</span>
</span><span id="GroupCoordinator-1141"><a href="#GroupCoordinator-1141"><span class="linenos">1141</span></a>        <span class="k">else</span><span class="p">:</span>
</span><span id="GroupCoordinator-1142"><a href="#GroupCoordinator-1142"><span class="linenos">1142</span></a>            <span class="n">torch</span><span class="o">.</span><span class="n">distributed</span><span class="o">.</span><span class="n">send</span><span class="p">(</span><span class="n">tensor</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">ranks</span><span class="p">[</span><span class="n">dst</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">device_group</span><span class="p">)</span>
</span><span id="GroupCoordinator-1143"><a href="#GroupCoordinator-1143"><span class="linenos">1143</span></a>
</span><span id="GroupCoordinator-1144"><a href="#GroupCoordinator-1144"><span class="linenos">1144</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">recv</span><span class="p">(</span>
</span><span id="GroupCoordinator-1145"><a href="#GroupCoordinator-1145"><span class="linenos">1145</span></a>        <span class="bp">self</span><span class="p">,</span> <span class="n">size</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">,</span> <span class="n">dtype</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="n">src</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
</span><span id="GroupCoordinator-1146"><a href="#GroupCoordinator-1146"><span class="linenos">1146</span></a>    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
</span><span id="GroupCoordinator-1147"><a href="#GroupCoordinator-1147"><span class="linenos">1147</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;Receives a tensor from the source rank.&quot;&quot;&quot;</span>
</span><span id="GroupCoordinator-1148"><a href="#GroupCoordinator-1148"><span class="linenos">1148</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;NOTE: `src` is the local rank of the source rank.&quot;&quot;&quot;</span>
</span><span id="GroupCoordinator-1149"><a href="#GroupCoordinator-1149"><span class="linenos">1149</span></a>        <span class="k">if</span> <span class="n">src</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="GroupCoordinator-1150"><a href="#GroupCoordinator-1150"><span class="linenos">1150</span></a>            <span class="n">src</span> <span class="o">=</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">rank_in_group</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">%</span> <span class="bp">self</span><span class="o">.</span><span class="n">world_size</span>
</span><span id="GroupCoordinator-1151"><a href="#GroupCoordinator-1151"><span class="linenos">1151</span></a>
</span><span id="GroupCoordinator-1152"><a href="#GroupCoordinator-1152"><span class="linenos">1152</span></a>        <span class="n">tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span><span class="n">size</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
</span><span id="GroupCoordinator-1153"><a href="#GroupCoordinator-1153"><span class="linenos">1153</span></a>        <span class="n">pynccl_comm</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">pynccl_comm</span>
</span><span id="GroupCoordinator-1154"><a href="#GroupCoordinator-1154"><span class="linenos">1154</span></a>        <span class="k">if</span> <span class="n">pynccl_comm</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">pynccl_comm</span><span class="o">.</span><span class="n">disabled</span><span class="p">:</span>
</span><span id="GroupCoordinator-1155"><a href="#GroupCoordinator-1155"><span class="linenos">1155</span></a>            <span class="n">pynccl_comm</span><span class="o">.</span><span class="n">recv</span><span class="p">(</span><span class="n">tensor</span><span class="p">,</span> <span class="n">src</span><span class="p">)</span>
</span><span id="GroupCoordinator-1156"><a href="#GroupCoordinator-1156"><span class="linenos">1156</span></a>        <span class="k">else</span><span class="p">:</span>
</span><span id="GroupCoordinator-1157"><a href="#GroupCoordinator-1157"><span class="linenos">1157</span></a>            <span class="n">torch</span><span class="o">.</span><span class="n">distributed</span><span class="o">.</span><span class="n">recv</span><span class="p">(</span><span class="n">tensor</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">ranks</span><span class="p">[</span><span class="n">src</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">device_group</span><span class="p">)</span>
</span><span id="GroupCoordinator-1158"><a href="#GroupCoordinator-1158"><span class="linenos">1158</span></a>        <span class="k">return</span> <span class="n">tensor</span>
</span><span id="GroupCoordinator-1159"><a href="#GroupCoordinator-1159"><span class="linenos">1159</span></a>
</span><span id="GroupCoordinator-1160"><a href="#GroupCoordinator-1160"><span class="linenos">1160</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">destroy</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
</span><span id="GroupCoordinator-1161"><a href="#GroupCoordinator-1161"><span class="linenos">1161</span></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">device_group</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="GroupCoordinator-1162"><a href="#GroupCoordinator-1162"><span class="linenos">1162</span></a>            <span class="n">torch</span><span class="o">.</span><span class="n">distributed</span><span class="o">.</span><span class="n">destroy_process_group</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device_group</span><span class="p">)</span>
</span><span id="GroupCoordinator-1163"><a href="#GroupCoordinator-1163"><span class="linenos">1163</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">device_group</span> <span class="o">=</span> <span class="kc">None</span>
</span><span id="GroupCoordinator-1164"><a href="#GroupCoordinator-1164"><span class="linenos">1164</span></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">cpu_group</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="GroupCoordinator-1165"><a href="#GroupCoordinator-1165"><span class="linenos">1165</span></a>            <span class="n">torch</span><span class="o">.</span><span class="n">distributed</span><span class="o">.</span><span class="n">destroy_process_group</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">cpu_group</span><span class="p">)</span>
</span><span id="GroupCoordinator-1166"><a href="#GroupCoordinator-1166"><span class="linenos">1166</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">cpu_group</span> <span class="o">=</span> <span class="kc">None</span>
</span><span id="GroupCoordinator-1167"><a href="#GroupCoordinator-1167"><span class="linenos">1167</span></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">pynccl_comm</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="GroupCoordinator-1168"><a href="#GroupCoordinator-1168"><span class="linenos">1168</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">pynccl_comm</span> <span class="o">=</span> <span class="kc">None</span>
</span><span id="GroupCoordinator-1169"><a href="#GroupCoordinator-1169"><span class="linenos">1169</span></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">ca_comm</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="GroupCoordinator-1170"><a href="#GroupCoordinator-1170"><span class="linenos">1170</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">ca_comm</span> <span class="o">=</span> <span class="kc">None</span>
</span><span id="GroupCoordinator-1171"><a href="#GroupCoordinator-1171"><span class="linenos">1171</span></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">mq_broadcaster</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="GroupCoordinator-1172"><a href="#GroupCoordinator-1172"><span class="linenos">1172</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">mq_broadcaster</span> <span class="o">=</span> <span class="kc">None</span>
</span></pre></div>


            <div class="docstring"><p>PyTorch ProcessGroup wrapper for a group of processes.
PyTorch ProcessGroup is bound to one specific communication backend,
    e.g. NCCL, Gloo, MPI, etc.
GroupCoordinator takes charge of all the communication operations among
    the processes in the group. It can route the communication to
    a specific implementation (e.g. switch allreduce implementation
    based on the tensor size and cuda graph mode).</p>
</div>


                            <div id="GroupCoordinator.__init__" class="classattr">
                                        <input id="GroupCoordinator.__init__-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="name">GroupCoordinator</span><span class="signature pdoc-code multiline">(<span class="param">	<span class="n">group_ranks</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="nb">int</span><span class="p">]]</span>,</span><span class="param">	<span class="n">local_rank</span><span class="p">:</span> <span class="nb">int</span>,</span><span class="param">	<span class="n">torch_distributed_backend</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">distributed</span><span class="o">.</span><span class="n">distributed_c10d</span><span class="o">.</span><span class="n">Backend</span><span class="p">]</span>,</span><span class="param">	<span class="n">use_pynccl</span><span class="p">:</span> <span class="nb">bool</span>,</span><span class="param">	<span class="n">use_pymscclpp</span><span class="p">:</span> <span class="nb">bool</span>,</span><span class="param">	<span class="n">use_custom_allreduce</span><span class="p">:</span> <span class="nb">bool</span>,</span><span class="param">	<span class="n">use_hpu_communicator</span><span class="p">:</span> <span class="nb">bool</span>,</span><span class="param">	<span class="n">use_xpu_communicator</span><span class="p">:</span> <span class="nb">bool</span>,</span><span class="param">	<span class="n">use_npu_communicator</span><span class="p">:</span> <span class="nb">bool</span>,</span><span class="param">	<span class="n">use_message_queue_broadcaster</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span>,</span><span class="param">	<span class="n">group_name</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span></span>)</span>

                <label class="view-source-button" for="GroupCoordinator.__init__-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#GroupCoordinator.__init__"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="GroupCoordinator.__init__-213"><a href="#GroupCoordinator.__init__-213"><span class="linenos">213</span></a>    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
</span><span id="GroupCoordinator.__init__-214"><a href="#GroupCoordinator.__init__-214"><span class="linenos">214</span></a>        <span class="bp">self</span><span class="p">,</span>
</span><span id="GroupCoordinator.__init__-215"><a href="#GroupCoordinator.__init__-215"><span class="linenos">215</span></a>        <span class="n">group_ranks</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="nb">int</span><span class="p">]],</span>
</span><span id="GroupCoordinator.__init__-216"><a href="#GroupCoordinator.__init__-216"><span class="linenos">216</span></a>        <span class="n">local_rank</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
</span><span id="GroupCoordinator.__init__-217"><a href="#GroupCoordinator.__init__-217"><span class="linenos">217</span></a>        <span class="n">torch_distributed_backend</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Backend</span><span class="p">],</span>
</span><span id="GroupCoordinator.__init__-218"><a href="#GroupCoordinator.__init__-218"><span class="linenos">218</span></a>        <span class="n">use_pynccl</span><span class="p">:</span> <span class="nb">bool</span><span class="p">,</span>
</span><span id="GroupCoordinator.__init__-219"><a href="#GroupCoordinator.__init__-219"><span class="linenos">219</span></a>        <span class="n">use_pymscclpp</span><span class="p">:</span> <span class="nb">bool</span><span class="p">,</span>
</span><span id="GroupCoordinator.__init__-220"><a href="#GroupCoordinator.__init__-220"><span class="linenos">220</span></a>        <span class="n">use_custom_allreduce</span><span class="p">:</span> <span class="nb">bool</span><span class="p">,</span>
</span><span id="GroupCoordinator.__init__-221"><a href="#GroupCoordinator.__init__-221"><span class="linenos">221</span></a>        <span class="n">use_hpu_communicator</span><span class="p">:</span> <span class="nb">bool</span><span class="p">,</span>
</span><span id="GroupCoordinator.__init__-222"><a href="#GroupCoordinator.__init__-222"><span class="linenos">222</span></a>        <span class="n">use_xpu_communicator</span><span class="p">:</span> <span class="nb">bool</span><span class="p">,</span>
</span><span id="GroupCoordinator.__init__-223"><a href="#GroupCoordinator.__init__-223"><span class="linenos">223</span></a>        <span class="n">use_npu_communicator</span><span class="p">:</span> <span class="nb">bool</span><span class="p">,</span>
</span><span id="GroupCoordinator.__init__-224"><a href="#GroupCoordinator.__init__-224"><span class="linenos">224</span></a>        <span class="n">use_message_queue_broadcaster</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
</span><span id="GroupCoordinator.__init__-225"><a href="#GroupCoordinator.__init__-225"><span class="linenos">225</span></a>        <span class="n">group_name</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="GroupCoordinator.__init__-226"><a href="#GroupCoordinator.__init__-226"><span class="linenos">226</span></a>    <span class="p">):</span>
</span><span id="GroupCoordinator.__init__-227"><a href="#GroupCoordinator.__init__-227"><span class="linenos">227</span></a>        <span class="n">group_name</span> <span class="o">=</span> <span class="n">group_name</span> <span class="ow">or</span> <span class="s2">&quot;anonymous&quot;</span>
</span><span id="GroupCoordinator.__init__-228"><a href="#GroupCoordinator.__init__-228"><span class="linenos">228</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">unique_name</span> <span class="o">=</span> <span class="n">_get_unique_name</span><span class="p">(</span><span class="n">group_name</span><span class="p">)</span>
</span><span id="GroupCoordinator.__init__-229"><a href="#GroupCoordinator.__init__-229"><span class="linenos">229</span></a>        <span class="n">_register_group</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span>
</span><span id="GroupCoordinator.__init__-230"><a href="#GroupCoordinator.__init__-230"><span class="linenos">230</span></a>
</span><span id="GroupCoordinator.__init__-231"><a href="#GroupCoordinator.__init__-231"><span class="linenos">231</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">rank</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">distributed</span><span class="o">.</span><span class="n">get_rank</span><span class="p">()</span>
</span><span id="GroupCoordinator.__init__-232"><a href="#GroupCoordinator.__init__-232"><span class="linenos">232</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">local_rank</span> <span class="o">=</span> <span class="n">local_rank</span>
</span><span id="GroupCoordinator.__init__-233"><a href="#GroupCoordinator.__init__-233"><span class="linenos">233</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">device_group</span> <span class="o">=</span> <span class="kc">None</span>
</span><span id="GroupCoordinator.__init__-234"><a href="#GroupCoordinator.__init__-234"><span class="linenos">234</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">cpu_group</span> <span class="o">=</span> <span class="kc">None</span>
</span><span id="GroupCoordinator.__init__-235"><a href="#GroupCoordinator.__init__-235"><span class="linenos">235</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">local_size</span> <span class="o">=</span> <span class="n">get_int_env_var</span><span class="p">(</span><span class="s2">&quot;LOCAL_SIZE&quot;</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
</span><span id="GroupCoordinator.__init__-236"><a href="#GroupCoordinator.__init__-236"><span class="linenos">236</span></a>
</span><span id="GroupCoordinator.__init__-237"><a href="#GroupCoordinator.__init__-237"><span class="linenos">237</span></a>        <span class="k">for</span> <span class="n">ranks</span> <span class="ow">in</span> <span class="n">group_ranks</span><span class="p">:</span>
</span><span id="GroupCoordinator.__init__-238"><a href="#GroupCoordinator.__init__-238"><span class="linenos">238</span></a>            <span class="n">device_group</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">distributed</span><span class="o">.</span><span class="n">new_group</span><span class="p">(</span>
</span><span id="GroupCoordinator.__init__-239"><a href="#GroupCoordinator.__init__-239"><span class="linenos">239</span></a>                <span class="n">ranks</span><span class="p">,</span> <span class="n">backend</span><span class="o">=</span><span class="n">torch_distributed_backend</span>
</span><span id="GroupCoordinator.__init__-240"><a href="#GroupCoordinator.__init__-240"><span class="linenos">240</span></a>            <span class="p">)</span>
</span><span id="GroupCoordinator.__init__-241"><a href="#GroupCoordinator.__init__-241"><span class="linenos">241</span></a>            <span class="c1"># a group with `gloo` backend, to allow direct coordination between</span>
</span><span id="GroupCoordinator.__init__-242"><a href="#GroupCoordinator.__init__-242"><span class="linenos">242</span></a>            <span class="c1"># processes through the CPU.</span>
</span><span id="GroupCoordinator.__init__-243"><a href="#GroupCoordinator.__init__-243"><span class="linenos">243</span></a>            <span class="n">cpu_group</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">distributed</span><span class="o">.</span><span class="n">new_group</span><span class="p">(</span><span class="n">ranks</span><span class="p">,</span> <span class="n">backend</span><span class="o">=</span><span class="s2">&quot;gloo&quot;</span><span class="p">)</span>
</span><span id="GroupCoordinator.__init__-244"><a href="#GroupCoordinator.__init__-244"><span class="linenos">244</span></a>            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">rank</span> <span class="ow">in</span> <span class="n">ranks</span><span class="p">:</span>
</span><span id="GroupCoordinator.__init__-245"><a href="#GroupCoordinator.__init__-245"><span class="linenos">245</span></a>                <span class="bp">self</span><span class="o">.</span><span class="n">ranks</span> <span class="o">=</span> <span class="n">ranks</span>
</span><span id="GroupCoordinator.__init__-246"><a href="#GroupCoordinator.__init__-246"><span class="linenos">246</span></a>                <span class="bp">self</span><span class="o">.</span><span class="n">world_size</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">ranks</span><span class="p">)</span>
</span><span id="GroupCoordinator.__init__-247"><a href="#GroupCoordinator.__init__-247"><span class="linenos">247</span></a>                <span class="bp">self</span><span class="o">.</span><span class="n">rank_in_group</span> <span class="o">=</span> <span class="n">ranks</span><span class="o">.</span><span class="n">index</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">rank</span><span class="p">)</span>
</span><span id="GroupCoordinator.__init__-248"><a href="#GroupCoordinator.__init__-248"><span class="linenos">248</span></a>                <span class="bp">self</span><span class="o">.</span><span class="n">device_group</span> <span class="o">=</span> <span class="n">device_group</span>
</span><span id="GroupCoordinator.__init__-249"><a href="#GroupCoordinator.__init__-249"><span class="linenos">249</span></a>                <span class="bp">self</span><span class="o">.</span><span class="n">cpu_group</span> <span class="o">=</span> <span class="n">cpu_group</span>
</span><span id="GroupCoordinator.__init__-250"><a href="#GroupCoordinator.__init__-250"><span class="linenos">250</span></a>
</span><span id="GroupCoordinator.__init__-251"><a href="#GroupCoordinator.__init__-251"><span class="linenos">251</span></a>        <span class="k">assert</span> <span class="bp">self</span><span class="o">.</span><span class="n">cpu_group</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
</span><span id="GroupCoordinator.__init__-252"><a href="#GroupCoordinator.__init__-252"><span class="linenos">252</span></a>        <span class="k">assert</span> <span class="bp">self</span><span class="o">.</span><span class="n">device_group</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
</span><span id="GroupCoordinator.__init__-253"><a href="#GroupCoordinator.__init__-253"><span class="linenos">253</span></a>
</span><span id="GroupCoordinator.__init__-254"><a href="#GroupCoordinator.__init__-254"><span class="linenos">254</span></a>        <span class="k">if</span> <span class="n">is_cuda_alike</span><span class="p">():</span>
</span><span id="GroupCoordinator.__init__-255"><a href="#GroupCoordinator.__init__-255"><span class="linenos">255</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;cuda:</span><span class="si">{</span><span class="n">local_rank</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</span><span id="GroupCoordinator.__init__-256"><a href="#GroupCoordinator.__init__-256"><span class="linenos">256</span></a>        <span class="k">elif</span> <span class="n">_is_npu</span><span class="p">:</span>
</span><span id="GroupCoordinator.__init__-257"><a href="#GroupCoordinator.__init__-257"><span class="linenos">257</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;npu:</span><span class="si">{</span><span class="n">local_rank</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</span><span id="GroupCoordinator.__init__-258"><a href="#GroupCoordinator.__init__-258"><span class="linenos">258</span></a>        <span class="k">else</span><span class="p">:</span>
</span><span id="GroupCoordinator.__init__-259"><a href="#GroupCoordinator.__init__-259"><span class="linenos">259</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s2">&quot;cpu&quot;</span><span class="p">)</span>
</span><span id="GroupCoordinator.__init__-260"><a href="#GroupCoordinator.__init__-260"><span class="linenos">260</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">device_module</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">get_device_module</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
</span><span id="GroupCoordinator.__init__-261"><a href="#GroupCoordinator.__init__-261"><span class="linenos">261</span></a>
</span><span id="GroupCoordinator.__init__-262"><a href="#GroupCoordinator.__init__-262"><span class="linenos">262</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">use_pynccl</span> <span class="o">=</span> <span class="n">use_pynccl</span>
</span><span id="GroupCoordinator.__init__-263"><a href="#GroupCoordinator.__init__-263"><span class="linenos">263</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">use_pymscclpp</span> <span class="o">=</span> <span class="n">use_pymscclpp</span>
</span><span id="GroupCoordinator.__init__-264"><a href="#GroupCoordinator.__init__-264"><span class="linenos">264</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">use_custom_allreduce</span> <span class="o">=</span> <span class="n">use_custom_allreduce</span>
</span><span id="GroupCoordinator.__init__-265"><a href="#GroupCoordinator.__init__-265"><span class="linenos">265</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">use_hpu_communicator</span> <span class="o">=</span> <span class="n">use_hpu_communicator</span>
</span><span id="GroupCoordinator.__init__-266"><a href="#GroupCoordinator.__init__-266"><span class="linenos">266</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">use_xpu_communicator</span> <span class="o">=</span> <span class="n">use_xpu_communicator</span>
</span><span id="GroupCoordinator.__init__-267"><a href="#GroupCoordinator.__init__-267"><span class="linenos">267</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">use_npu_communicator</span> <span class="o">=</span> <span class="n">use_npu_communicator</span>
</span><span id="GroupCoordinator.__init__-268"><a href="#GroupCoordinator.__init__-268"><span class="linenos">268</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">use_message_queue_broadcaster</span> <span class="o">=</span> <span class="n">use_message_queue_broadcaster</span>
</span><span id="GroupCoordinator.__init__-269"><a href="#GroupCoordinator.__init__-269"><span class="linenos">269</span></a>
</span><span id="GroupCoordinator.__init__-270"><a href="#GroupCoordinator.__init__-270"><span class="linenos">270</span></a>        <span class="c1"># lazy import to avoid documentation build error</span>
</span><span id="GroupCoordinator.__init__-271"><a href="#GroupCoordinator.__init__-271"><span class="linenos">271</span></a>        <span class="kn">from</span><span class="w"> </span><span class="nn">sglang.srt.distributed.device_communicators.custom_all_reduce</span><span class="w"> </span><span class="kn">import</span> <span class="p">(</span>
</span><span id="GroupCoordinator.__init__-272"><a href="#GroupCoordinator.__init__-272"><span class="linenos">272</span></a>            <span class="n">CustomAllreduce</span><span class="p">,</span>
</span><span id="GroupCoordinator.__init__-273"><a href="#GroupCoordinator.__init__-273"><span class="linenos">273</span></a>        <span class="p">)</span>
</span><span id="GroupCoordinator.__init__-274"><a href="#GroupCoordinator.__init__-274"><span class="linenos">274</span></a>        <span class="kn">from</span><span class="w"> </span><span class="nn">sglang.srt.distributed.device_communicators.pynccl</span><span class="w"> </span><span class="kn">import</span> <span class="p">(</span>
</span><span id="GroupCoordinator.__init__-275"><a href="#GroupCoordinator.__init__-275"><span class="linenos">275</span></a>            <span class="n">PyNcclCommunicator</span><span class="p">,</span>
</span><span id="GroupCoordinator.__init__-276"><a href="#GroupCoordinator.__init__-276"><span class="linenos">276</span></a>        <span class="p">)</span>
</span><span id="GroupCoordinator.__init__-277"><a href="#GroupCoordinator.__init__-277"><span class="linenos">277</span></a>
</span><span id="GroupCoordinator.__init__-278"><a href="#GroupCoordinator.__init__-278"><span class="linenos">278</span></a>        <span class="k">if</span> <span class="n">is_hip</span><span class="p">():</span>
</span><span id="GroupCoordinator.__init__-279"><a href="#GroupCoordinator.__init__-279"><span class="linenos">279</span></a>            <span class="kn">from</span><span class="w"> </span><span class="nn">sglang.srt.distributed.device_communicators.quick_all_reduce</span><span class="w"> </span><span class="kn">import</span> <span class="p">(</span>
</span><span id="GroupCoordinator.__init__-280"><a href="#GroupCoordinator.__init__-280"><span class="linenos">280</span></a>                <span class="n">QuickAllReduce</span><span class="p">,</span>
</span><span id="GroupCoordinator.__init__-281"><a href="#GroupCoordinator.__init__-281"><span class="linenos">281</span></a>                <span class="n">qr_rocm_arch_available</span><span class="p">,</span>
</span><span id="GroupCoordinator.__init__-282"><a href="#GroupCoordinator.__init__-282"><span class="linenos">282</span></a>            <span class="p">)</span>
</span><span id="GroupCoordinator.__init__-283"><a href="#GroupCoordinator.__init__-283"><span class="linenos">283</span></a>
</span><span id="GroupCoordinator.__init__-284"><a href="#GroupCoordinator.__init__-284"><span class="linenos">284</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">pynccl_comm</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">PyNcclCommunicator</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
</span><span id="GroupCoordinator.__init__-285"><a href="#GroupCoordinator.__init__-285"><span class="linenos">285</span></a>        <span class="k">if</span> <span class="n">use_pynccl</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">world_size</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
</span><span id="GroupCoordinator.__init__-286"><a href="#GroupCoordinator.__init__-286"><span class="linenos">286</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">pynccl_comm</span> <span class="o">=</span> <span class="n">PyNcclCommunicator</span><span class="p">(</span>
</span><span id="GroupCoordinator.__init__-287"><a href="#GroupCoordinator.__init__-287"><span class="linenos">287</span></a>                <span class="n">group</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">cpu_group</span><span class="p">,</span>
</span><span id="GroupCoordinator.__init__-288"><a href="#GroupCoordinator.__init__-288"><span class="linenos">288</span></a>                <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">,</span>
</span><span id="GroupCoordinator.__init__-289"><a href="#GroupCoordinator.__init__-289"><span class="linenos">289</span></a>            <span class="p">)</span>
</span><span id="GroupCoordinator.__init__-290"><a href="#GroupCoordinator.__init__-290"><span class="linenos">290</span></a>
</span><span id="GroupCoordinator.__init__-291"><a href="#GroupCoordinator.__init__-291"><span class="linenos">291</span></a>        <span class="kn">from</span><span class="w"> </span><span class="nn">sglang.srt.distributed.device_communicators.pymscclpp</span><span class="w"> </span><span class="kn">import</span> <span class="p">(</span>
</span><span id="GroupCoordinator.__init__-292"><a href="#GroupCoordinator.__init__-292"><span class="linenos">292</span></a>            <span class="n">PyMscclppCommunicator</span><span class="p">,</span>
</span><span id="GroupCoordinator.__init__-293"><a href="#GroupCoordinator.__init__-293"><span class="linenos">293</span></a>        <span class="p">)</span>
</span><span id="GroupCoordinator.__init__-294"><a href="#GroupCoordinator.__init__-294"><span class="linenos">294</span></a>
</span><span id="GroupCoordinator.__init__-295"><a href="#GroupCoordinator.__init__-295"><span class="linenos">295</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">pymscclpp_comm</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">PyMscclppCommunicator</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
</span><span id="GroupCoordinator.__init__-296"><a href="#GroupCoordinator.__init__-296"><span class="linenos">296</span></a>        <span class="k">if</span> <span class="n">use_pymscclpp</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">world_size</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
</span><span id="GroupCoordinator.__init__-297"><a href="#GroupCoordinator.__init__-297"><span class="linenos">297</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">pymscclpp_comm</span> <span class="o">=</span> <span class="n">PyMscclppCommunicator</span><span class="p">(</span>
</span><span id="GroupCoordinator.__init__-298"><a href="#GroupCoordinator.__init__-298"><span class="linenos">298</span></a>                <span class="n">group</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">cpu_group</span><span class="p">,</span>
</span><span id="GroupCoordinator.__init__-299"><a href="#GroupCoordinator.__init__-299"><span class="linenos">299</span></a>                <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">,</span>
</span><span id="GroupCoordinator.__init__-300"><a href="#GroupCoordinator.__init__-300"><span class="linenos">300</span></a>            <span class="p">)</span>
</span><span id="GroupCoordinator.__init__-301"><a href="#GroupCoordinator.__init__-301"><span class="linenos">301</span></a>
</span><span id="GroupCoordinator.__init__-302"><a href="#GroupCoordinator.__init__-302"><span class="linenos">302</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">ca_comm</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">CustomAllreduce</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
</span><span id="GroupCoordinator.__init__-303"><a href="#GroupCoordinator.__init__-303"><span class="linenos">303</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">qr_comm</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">QuickAllReduce</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
</span><span id="GroupCoordinator.__init__-304"><a href="#GroupCoordinator.__init__-304"><span class="linenos">304</span></a>        <span class="k">if</span> <span class="n">use_custom_allreduce</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">world_size</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
</span><span id="GroupCoordinator.__init__-305"><a href="#GroupCoordinator.__init__-305"><span class="linenos">305</span></a>            <span class="c1"># Initialize a custom fast all-reduce implementation.</span>
</span><span id="GroupCoordinator.__init__-306"><a href="#GroupCoordinator.__init__-306"><span class="linenos">306</span></a>            <span class="k">try</span><span class="p">:</span>
</span><span id="GroupCoordinator.__init__-307"><a href="#GroupCoordinator.__init__-307"><span class="linenos">307</span></a>                <span class="bp">self</span><span class="o">.</span><span class="n">ca_comm</span> <span class="o">=</span> <span class="n">CustomAllreduce</span><span class="p">(</span>
</span><span id="GroupCoordinator.__init__-308"><a href="#GroupCoordinator.__init__-308"><span class="linenos">308</span></a>                    <span class="n">group</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">cpu_group</span><span class="p">,</span>
</span><span id="GroupCoordinator.__init__-309"><a href="#GroupCoordinator.__init__-309"><span class="linenos">309</span></a>                    <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">,</span>
</span><span id="GroupCoordinator.__init__-310"><a href="#GroupCoordinator.__init__-310"><span class="linenos">310</span></a>                <span class="p">)</span>
</span><span id="GroupCoordinator.__init__-311"><a href="#GroupCoordinator.__init__-311"><span class="linenos">311</span></a>            <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
</span><span id="GroupCoordinator.__init__-312"><a href="#GroupCoordinator.__init__-312"><span class="linenos">312</span></a>                <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span>
</span><span id="GroupCoordinator.__init__-313"><a href="#GroupCoordinator.__init__-313"><span class="linenos">313</span></a>                    <span class="sa">f</span><span class="s2">&quot;Setup Custom allreduce failed with </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">. To silence this &quot;</span>
</span><span id="GroupCoordinator.__init__-314"><a href="#GroupCoordinator.__init__-314"><span class="linenos">314</span></a>                    <span class="s2">&quot;warning, specify --disable-custom-all-reduce explicitly.&quot;</span>
</span><span id="GroupCoordinator.__init__-315"><a href="#GroupCoordinator.__init__-315"><span class="linenos">315</span></a>                <span class="p">)</span>
</span><span id="GroupCoordinator.__init__-316"><a href="#GroupCoordinator.__init__-316"><span class="linenos">316</span></a>            <span class="k">if</span> <span class="n">is_hip</span><span class="p">():</span>
</span><span id="GroupCoordinator.__init__-317"><a href="#GroupCoordinator.__init__-317"><span class="linenos">317</span></a>                <span class="k">try</span><span class="p">:</span>
</span><span id="GroupCoordinator.__init__-318"><a href="#GroupCoordinator.__init__-318"><span class="linenos">318</span></a>                    <span class="c1"># Initialize a custom quick all-reduce implementation for AMD</span>
</span><span id="GroupCoordinator.__init__-319"><a href="#GroupCoordinator.__init__-319"><span class="linenos">319</span></a>                    <span class="c1"># when rocm &gt;= gfx942. Quick reduce is designed as a</span>
</span><span id="GroupCoordinator.__init__-320"><a href="#GroupCoordinator.__init__-320"><span class="linenos">320</span></a>                    <span class="c1"># complement to custom allreduce.</span>
</span><span id="GroupCoordinator.__init__-321"><a href="#GroupCoordinator.__init__-321"><span class="linenos">321</span></a>                    <span class="c1"># Based on quickreduce (https://github.com/mk1-project/quickreduce).</span>
</span><span id="GroupCoordinator.__init__-322"><a href="#GroupCoordinator.__init__-322"><span class="linenos">322</span></a>                    <span class="k">if</span> <span class="n">qr_rocm_arch_available</span><span class="p">():</span>
</span><span id="GroupCoordinator.__init__-323"><a href="#GroupCoordinator.__init__-323"><span class="linenos">323</span></a>                        <span class="bp">self</span><span class="o">.</span><span class="n">qr_comm</span> <span class="o">=</span> <span class="n">QuickAllReduce</span><span class="p">(</span>
</span><span id="GroupCoordinator.__init__-324"><a href="#GroupCoordinator.__init__-324"><span class="linenos">324</span></a>                            <span class="n">group</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">cpu_group</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span>
</span><span id="GroupCoordinator.__init__-325"><a href="#GroupCoordinator.__init__-325"><span class="linenos">325</span></a>                        <span class="p">)</span>
</span><span id="GroupCoordinator.__init__-326"><a href="#GroupCoordinator.__init__-326"><span class="linenos">326</span></a>                <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
</span><span id="GroupCoordinator.__init__-327"><a href="#GroupCoordinator.__init__-327"><span class="linenos">327</span></a>                    <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Failed to initialize QuickAllReduce: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</span><span id="GroupCoordinator.__init__-328"><a href="#GroupCoordinator.__init__-328"><span class="linenos">328</span></a>
</span><span id="GroupCoordinator.__init__-329"><a href="#GroupCoordinator.__init__-329"><span class="linenos">329</span></a>        <span class="kn">from</span><span class="w"> </span><span class="nn">sglang.srt.distributed.device_communicators.hpu_communicator</span><span class="w"> </span><span class="kn">import</span> <span class="p">(</span>
</span><span id="GroupCoordinator.__init__-330"><a href="#GroupCoordinator.__init__-330"><span class="linenos">330</span></a>            <span class="n">HpuCommunicator</span><span class="p">,</span>
</span><span id="GroupCoordinator.__init__-331"><a href="#GroupCoordinator.__init__-331"><span class="linenos">331</span></a>        <span class="p">)</span>
</span><span id="GroupCoordinator.__init__-332"><a href="#GroupCoordinator.__init__-332"><span class="linenos">332</span></a>
</span><span id="GroupCoordinator.__init__-333"><a href="#GroupCoordinator.__init__-333"><span class="linenos">333</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">hpu_communicator</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">HpuCommunicator</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
</span><span id="GroupCoordinator.__init__-334"><a href="#GroupCoordinator.__init__-334"><span class="linenos">334</span></a>        <span class="k">if</span> <span class="n">use_hpu_communicator</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">world_size</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
</span><span id="GroupCoordinator.__init__-335"><a href="#GroupCoordinator.__init__-335"><span class="linenos">335</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">hpu_communicator</span> <span class="o">=</span> <span class="n">HpuCommunicator</span><span class="p">(</span><span class="n">group</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device_group</span><span class="p">)</span>
</span><span id="GroupCoordinator.__init__-336"><a href="#GroupCoordinator.__init__-336"><span class="linenos">336</span></a>
</span><span id="GroupCoordinator.__init__-337"><a href="#GroupCoordinator.__init__-337"><span class="linenos">337</span></a>        <span class="kn">from</span><span class="w"> </span><span class="nn">sglang.srt.distributed.device_communicators.xpu_communicator</span><span class="w"> </span><span class="kn">import</span> <span class="p">(</span>
</span><span id="GroupCoordinator.__init__-338"><a href="#GroupCoordinator.__init__-338"><span class="linenos">338</span></a>            <span class="n">XpuCommunicator</span><span class="p">,</span>
</span><span id="GroupCoordinator.__init__-339"><a href="#GroupCoordinator.__init__-339"><span class="linenos">339</span></a>        <span class="p">)</span>
</span><span id="GroupCoordinator.__init__-340"><a href="#GroupCoordinator.__init__-340"><span class="linenos">340</span></a>
</span><span id="GroupCoordinator.__init__-341"><a href="#GroupCoordinator.__init__-341"><span class="linenos">341</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">xpu_communicator</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">XpuCommunicator</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
</span><span id="GroupCoordinator.__init__-342"><a href="#GroupCoordinator.__init__-342"><span class="linenos">342</span></a>        <span class="k">if</span> <span class="n">use_xpu_communicator</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">world_size</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
</span><span id="GroupCoordinator.__init__-343"><a href="#GroupCoordinator.__init__-343"><span class="linenos">343</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">xpu_communicator</span> <span class="o">=</span> <span class="n">XpuCommunicator</span><span class="p">(</span><span class="n">group</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device_group</span><span class="p">)</span>
</span><span id="GroupCoordinator.__init__-344"><a href="#GroupCoordinator.__init__-344"><span class="linenos">344</span></a>
</span><span id="GroupCoordinator.__init__-345"><a href="#GroupCoordinator.__init__-345"><span class="linenos">345</span></a>        <span class="kn">from</span><span class="w"> </span><span class="nn">sglang.srt.distributed.device_communicators.npu_communicator</span><span class="w"> </span><span class="kn">import</span> <span class="p">(</span>
</span><span id="GroupCoordinator.__init__-346"><a href="#GroupCoordinator.__init__-346"><span class="linenos">346</span></a>            <span class="n">NpuCommunicator</span><span class="p">,</span>
</span><span id="GroupCoordinator.__init__-347"><a href="#GroupCoordinator.__init__-347"><span class="linenos">347</span></a>        <span class="p">)</span>
</span><span id="GroupCoordinator.__init__-348"><a href="#GroupCoordinator.__init__-348"><span class="linenos">348</span></a>
</span><span id="GroupCoordinator.__init__-349"><a href="#GroupCoordinator.__init__-349"><span class="linenos">349</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">npu_communicator</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">NpuCommunicator</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
</span><span id="GroupCoordinator.__init__-350"><a href="#GroupCoordinator.__init__-350"><span class="linenos">350</span></a>        <span class="k">if</span> <span class="n">use_npu_communicator</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">world_size</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
</span><span id="GroupCoordinator.__init__-351"><a href="#GroupCoordinator.__init__-351"><span class="linenos">351</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">npu_communicator</span> <span class="o">=</span> <span class="n">NpuCommunicator</span><span class="p">(</span><span class="n">group</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device_group</span><span class="p">)</span>
</span><span id="GroupCoordinator.__init__-352"><a href="#GroupCoordinator.__init__-352"><span class="linenos">352</span></a>
</span><span id="GroupCoordinator.__init__-353"><a href="#GroupCoordinator.__init__-353"><span class="linenos">353</span></a>        <span class="kn">from</span><span class="w"> </span><span class="nn">sglang.srt.distributed.device_communicators.shm_broadcast</span><span class="w"> </span><span class="kn">import</span> <span class="p">(</span>
</span><span id="GroupCoordinator.__init__-354"><a href="#GroupCoordinator.__init__-354"><span class="linenos">354</span></a>            <span class="n">MessageQueue</span><span class="p">,</span>
</span><span id="GroupCoordinator.__init__-355"><a href="#GroupCoordinator.__init__-355"><span class="linenos">355</span></a>        <span class="p">)</span>
</span><span id="GroupCoordinator.__init__-356"><a href="#GroupCoordinator.__init__-356"><span class="linenos">356</span></a>
</span><span id="GroupCoordinator.__init__-357"><a href="#GroupCoordinator.__init__-357"><span class="linenos">357</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">mq_broadcaster</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">MessageQueue</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
</span><span id="GroupCoordinator.__init__-358"><a href="#GroupCoordinator.__init__-358"><span class="linenos">358</span></a>        <span class="k">if</span> <span class="n">use_message_queue_broadcaster</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">world_size</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
</span><span id="GroupCoordinator.__init__-359"><a href="#GroupCoordinator.__init__-359"><span class="linenos">359</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">mq_broadcaster</span> <span class="o">=</span> <span class="n">MessageQueue</span><span class="o">.</span><span class="n">create_from_process_group</span><span class="p">(</span>
</span><span id="GroupCoordinator.__init__-360"><a href="#GroupCoordinator.__init__-360"><span class="linenos">360</span></a>                <span class="bp">self</span><span class="o">.</span><span class="n">cpu_group</span><span class="p">,</span> <span class="mi">1</span> <span class="o">&lt;&lt;</span> <span class="mi">22</span><span class="p">,</span> <span class="mi">6</span>
</span><span id="GroupCoordinator.__init__-361"><a href="#GroupCoordinator.__init__-361"><span class="linenos">361</span></a>            <span class="p">)</span>
</span></pre></div>


    

                            </div>
                            <div id="GroupCoordinator.rank" class="classattr">
                                <div class="attr variable">
            <span class="name">rank</span><span class="annotation">: int</span>

        
    </div>
    <a class="headerlink" href="#GroupCoordinator.rank"></a>
    
    

                            </div>
                            <div id="GroupCoordinator.ranks" class="classattr">
                                <div class="attr variable">
            <span class="name">ranks</span><span class="annotation">: List[int]</span>

        
    </div>
    <a class="headerlink" href="#GroupCoordinator.ranks"></a>
    
    

                            </div>
                            <div id="GroupCoordinator.world_size" class="classattr">
                                <div class="attr variable">
            <span class="name">world_size</span><span class="annotation">: int</span>

        
    </div>
    <a class="headerlink" href="#GroupCoordinator.world_size"></a>
    
    

                            </div>
                            <div id="GroupCoordinator.local_rank" class="classattr">
                                <div class="attr variable">
            <span class="name">local_rank</span><span class="annotation">: int</span>

        
    </div>
    <a class="headerlink" href="#GroupCoordinator.local_rank"></a>
    
    

                            </div>
                            <div id="GroupCoordinator.rank_in_group" class="classattr">
                                <div class="attr variable">
            <span class="name">rank_in_group</span><span class="annotation">: int</span>

        
    </div>
    <a class="headerlink" href="#GroupCoordinator.rank_in_group"></a>
    
    

                            </div>
                            <div id="GroupCoordinator.cpu_group" class="classattr">
                                <div class="attr variable">
            <span class="name">cpu_group</span><span class="annotation">: torch.distributed.distributed_c10d.ProcessGroup</span>

        
    </div>
    <a class="headerlink" href="#GroupCoordinator.cpu_group"></a>
    
    

                            </div>
                            <div id="GroupCoordinator.device_group" class="classattr">
                                <div class="attr variable">
            <span class="name">device_group</span><span class="annotation">: torch.distributed.distributed_c10d.ProcessGroup</span>

        
    </div>
    <a class="headerlink" href="#GroupCoordinator.device_group"></a>
    
    

                            </div>
                            <div id="GroupCoordinator.use_pynccl" class="classattr">
                                <div class="attr variable">
            <span class="name">use_pynccl</span><span class="annotation">: bool</span>

        
    </div>
    <a class="headerlink" href="#GroupCoordinator.use_pynccl"></a>
    
    

                            </div>
                            <div id="GroupCoordinator.use_pymscclpp" class="classattr">
                                <div class="attr variable">
            <span class="name">use_pymscclpp</span><span class="annotation">: bool</span>

        
    </div>
    <a class="headerlink" href="#GroupCoordinator.use_pymscclpp"></a>
    
    

                            </div>
                            <div id="GroupCoordinator.use_custom_allreduce" class="classattr">
                                <div class="attr variable">
            <span class="name">use_custom_allreduce</span><span class="annotation">: bool</span>

        
    </div>
    <a class="headerlink" href="#GroupCoordinator.use_custom_allreduce"></a>
    
    

                            </div>
                            <div id="GroupCoordinator.use_message_queue_broadcaster" class="classattr">
                                <div class="attr variable">
            <span class="name">use_message_queue_broadcaster</span><span class="annotation">: bool</span>

        
    </div>
    <a class="headerlink" href="#GroupCoordinator.use_message_queue_broadcaster"></a>
    
    

                            </div>
                            <div id="GroupCoordinator.pynccl_comm" class="classattr">
                                <div class="attr variable">
            <span class="name">pynccl_comm</span><span class="annotation">: Optional[Any]</span>

        
    </div>
    <a class="headerlink" href="#GroupCoordinator.pynccl_comm"></a>
    
    

                            </div>
                            <div id="GroupCoordinator.ca_comm" class="classattr">
                                <div class="attr variable">
            <span class="name">ca_comm</span><span class="annotation">: Optional[Any]</span>

        
    </div>
    <a class="headerlink" href="#GroupCoordinator.ca_comm"></a>
    
    

                            </div>
                            <div id="GroupCoordinator.mq_broadcaster" class="classattr">
                                <div class="attr variable">
            <span class="name">mq_broadcaster</span><span class="annotation">: Optional[Any]</span>

        
    </div>
    <a class="headerlink" href="#GroupCoordinator.mq_broadcaster"></a>
    
    

                            </div>
                            <div id="GroupCoordinator.unique_name" class="classattr">
                                <div class="attr variable">
            <span class="name">unique_name</span>

        
    </div>
    <a class="headerlink" href="#GroupCoordinator.unique_name"></a>
    
    

                            </div>
                            <div id="GroupCoordinator.local_size" class="classattr">
                                <div class="attr variable">
            <span class="name">local_size</span>

        
    </div>
    <a class="headerlink" href="#GroupCoordinator.local_size"></a>
    
    

                            </div>
                            <div id="GroupCoordinator.device_module" class="classattr">
                                <div class="attr variable">
            <span class="name">device_module</span>

        
    </div>
    <a class="headerlink" href="#GroupCoordinator.device_module"></a>
    
    

                            </div>
                            <div id="GroupCoordinator.use_hpu_communicator" class="classattr">
                                <div class="attr variable">
            <span class="name">use_hpu_communicator</span>

        
    </div>
    <a class="headerlink" href="#GroupCoordinator.use_hpu_communicator"></a>
    
    

                            </div>
                            <div id="GroupCoordinator.use_xpu_communicator" class="classattr">
                                <div class="attr variable">
            <span class="name">use_xpu_communicator</span>

        
    </div>
    <a class="headerlink" href="#GroupCoordinator.use_xpu_communicator"></a>
    
    

                            </div>
                            <div id="GroupCoordinator.use_npu_communicator" class="classattr">
                                <div class="attr variable">
            <span class="name">use_npu_communicator</span>

        
    </div>
    <a class="headerlink" href="#GroupCoordinator.use_npu_communicator"></a>
    
    

                            </div>
                            <div id="GroupCoordinator.pymscclpp_comm" class="classattr">
                                <div class="attr variable">
            <span class="name">pymscclpp_comm</span><span class="annotation">: &#39;Optional[PyMscclppCommunicator]&#39;</span>

        
    </div>
    <a class="headerlink" href="#GroupCoordinator.pymscclpp_comm"></a>
    
    

                            </div>
                            <div id="GroupCoordinator.qr_comm" class="classattr">
                                <div class="attr variable">
            <span class="name">qr_comm</span><span class="annotation">: &#39;Optional[QuickAllReduce]&#39;</span>

        
    </div>
    <a class="headerlink" href="#GroupCoordinator.qr_comm"></a>
    
    

                            </div>
                            <div id="GroupCoordinator.hpu_communicator" class="classattr">
                                <div class="attr variable">
            <span class="name">hpu_communicator</span><span class="annotation">: &#39;Optional[HpuCommunicator]&#39;</span>

        
    </div>
    <a class="headerlink" href="#GroupCoordinator.hpu_communicator"></a>
    
    

                            </div>
                            <div id="GroupCoordinator.xpu_communicator" class="classattr">
                                <div class="attr variable">
            <span class="name">xpu_communicator</span><span class="annotation">: &#39;Optional[XpuCommunicator]&#39;</span>

        
    </div>
    <a class="headerlink" href="#GroupCoordinator.xpu_communicator"></a>
    
    

                            </div>
                            <div id="GroupCoordinator.npu_communicator" class="classattr">
                                <div class="attr variable">
            <span class="name">npu_communicator</span><span class="annotation">: &#39;Optional[NpuCommunicator]&#39;</span>

        
    </div>
    <a class="headerlink" href="#GroupCoordinator.npu_communicator"></a>
    
    

                            </div>
                            <div id="GroupCoordinator.first_rank" class="classattr">
                                        <input id="GroupCoordinator.first_rank-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr variable">
            <span class="name">first_rank</span>

                <label class="view-source-button" for="GroupCoordinator.first_rank-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#GroupCoordinator.first_rank"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="GroupCoordinator.first_rank-370"><a href="#GroupCoordinator.first_rank-370"><span class="linenos">370</span></a>    <span class="nd">@property</span>
</span><span id="GroupCoordinator.first_rank-371"><a href="#GroupCoordinator.first_rank-371"><span class="linenos">371</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">first_rank</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
</span><span id="GroupCoordinator.first_rank-372"><a href="#GroupCoordinator.first_rank-372"><span class="linenos">372</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;Return the global rank of the first process in the group&quot;&quot;&quot;</span>
</span><span id="GroupCoordinator.first_rank-373"><a href="#GroupCoordinator.first_rank-373"><span class="linenos">373</span></a>        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">ranks</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
</span></pre></div>


            <div class="docstring"><p>Return the global rank of the first process in the group</p>
</div>


                            </div>
                            <div id="GroupCoordinator.last_rank" class="classattr">
                                        <input id="GroupCoordinator.last_rank-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr variable">
            <span class="name">last_rank</span>

                <label class="view-source-button" for="GroupCoordinator.last_rank-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#GroupCoordinator.last_rank"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="GroupCoordinator.last_rank-375"><a href="#GroupCoordinator.last_rank-375"><span class="linenos">375</span></a>    <span class="nd">@property</span>
</span><span id="GroupCoordinator.last_rank-376"><a href="#GroupCoordinator.last_rank-376"><span class="linenos">376</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">last_rank</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
</span><span id="GroupCoordinator.last_rank-377"><a href="#GroupCoordinator.last_rank-377"><span class="linenos">377</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;Return the global rank of the last process in the group&quot;&quot;&quot;</span>
</span><span id="GroupCoordinator.last_rank-378"><a href="#GroupCoordinator.last_rank-378"><span class="linenos">378</span></a>        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">ranks</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
</span></pre></div>


            <div class="docstring"><p>Return the global rank of the last process in the group</p>
</div>


                            </div>
                            <div id="GroupCoordinator.is_first_rank" class="classattr">
                                        <input id="GroupCoordinator.is_first_rank-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr variable">
            <span class="name">is_first_rank</span>

                <label class="view-source-button" for="GroupCoordinator.is_first_rank-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#GroupCoordinator.is_first_rank"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="GroupCoordinator.is_first_rank-380"><a href="#GroupCoordinator.is_first_rank-380"><span class="linenos">380</span></a>    <span class="nd">@property</span>
</span><span id="GroupCoordinator.is_first_rank-381"><a href="#GroupCoordinator.is_first_rank-381"><span class="linenos">381</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">is_first_rank</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
</span><span id="GroupCoordinator.is_first_rank-382"><a href="#GroupCoordinator.is_first_rank-382"><span class="linenos">382</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;Return whether the caller is the first process in the group&quot;&quot;&quot;</span>
</span><span id="GroupCoordinator.is_first_rank-383"><a href="#GroupCoordinator.is_first_rank-383"><span class="linenos">383</span></a>        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">rank</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">first_rank</span>
</span></pre></div>


            <div class="docstring"><p>Return whether the caller is the first process in the group</p>
</div>


                            </div>
                            <div id="GroupCoordinator.is_last_rank" class="classattr">
                                        <input id="GroupCoordinator.is_last_rank-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr variable">
            <span class="name">is_last_rank</span>

                <label class="view-source-button" for="GroupCoordinator.is_last_rank-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#GroupCoordinator.is_last_rank"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="GroupCoordinator.is_last_rank-385"><a href="#GroupCoordinator.is_last_rank-385"><span class="linenos">385</span></a>    <span class="nd">@property</span>
</span><span id="GroupCoordinator.is_last_rank-386"><a href="#GroupCoordinator.is_last_rank-386"><span class="linenos">386</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">is_last_rank</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
</span><span id="GroupCoordinator.is_last_rank-387"><a href="#GroupCoordinator.is_last_rank-387"><span class="linenos">387</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;Return whether the caller is the last process in the group&quot;&quot;&quot;</span>
</span><span id="GroupCoordinator.is_last_rank-388"><a href="#GroupCoordinator.is_last_rank-388"><span class="linenos">388</span></a>        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">rank</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">last_rank</span>
</span></pre></div>


            <div class="docstring"><p>Return whether the caller is the last process in the group</p>
</div>


                            </div>
                            <div id="GroupCoordinator.next_rank" class="classattr">
                                        <input id="GroupCoordinator.next_rank-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr variable">
            <span class="name">next_rank</span>

                <label class="view-source-button" for="GroupCoordinator.next_rank-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#GroupCoordinator.next_rank"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="GroupCoordinator.next_rank-390"><a href="#GroupCoordinator.next_rank-390"><span class="linenos">390</span></a>    <span class="nd">@property</span>
</span><span id="GroupCoordinator.next_rank-391"><a href="#GroupCoordinator.next_rank-391"><span class="linenos">391</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">next_rank</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
</span><span id="GroupCoordinator.next_rank-392"><a href="#GroupCoordinator.next_rank-392"><span class="linenos">392</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;Return the global rank of the process that follows the caller&quot;&quot;&quot;</span>
</span><span id="GroupCoordinator.next_rank-393"><a href="#GroupCoordinator.next_rank-393"><span class="linenos">393</span></a>        <span class="n">rank_in_group</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">rank_in_group</span>
</span><span id="GroupCoordinator.next_rank-394"><a href="#GroupCoordinator.next_rank-394"><span class="linenos">394</span></a>        <span class="n">world_size</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">world_size</span>
</span><span id="GroupCoordinator.next_rank-395"><a href="#GroupCoordinator.next_rank-395"><span class="linenos">395</span></a>        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">ranks</span><span class="p">[(</span><span class="n">rank_in_group</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">%</span> <span class="n">world_size</span><span class="p">]</span>
</span></pre></div>


            <div class="docstring"><p>Return the global rank of the process that follows the caller</p>
</div>


                            </div>
                            <div id="GroupCoordinator.prev_rank" class="classattr">
                                        <input id="GroupCoordinator.prev_rank-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr variable">
            <span class="name">prev_rank</span>

                <label class="view-source-button" for="GroupCoordinator.prev_rank-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#GroupCoordinator.prev_rank"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="GroupCoordinator.prev_rank-397"><a href="#GroupCoordinator.prev_rank-397"><span class="linenos">397</span></a>    <span class="nd">@property</span>
</span><span id="GroupCoordinator.prev_rank-398"><a href="#GroupCoordinator.prev_rank-398"><span class="linenos">398</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">prev_rank</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
</span><span id="GroupCoordinator.prev_rank-399"><a href="#GroupCoordinator.prev_rank-399"><span class="linenos">399</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;Return the global rank of the process that precedes the caller&quot;&quot;&quot;</span>
</span><span id="GroupCoordinator.prev_rank-400"><a href="#GroupCoordinator.prev_rank-400"><span class="linenos">400</span></a>        <span class="n">rank_in_group</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">rank_in_group</span>
</span><span id="GroupCoordinator.prev_rank-401"><a href="#GroupCoordinator.prev_rank-401"><span class="linenos">401</span></a>        <span class="n">world_size</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">world_size</span>
</span><span id="GroupCoordinator.prev_rank-402"><a href="#GroupCoordinator.prev_rank-402"><span class="linenos">402</span></a>        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">ranks</span><span class="p">[(</span><span class="n">rank_in_group</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">%</span> <span class="n">world_size</span><span class="p">]</span>
</span></pre></div>


            <div class="docstring"><p>Return the global rank of the process that precedes the caller</p>
</div>


                            </div>
                            <div id="GroupCoordinator.graph_capture" class="classattr">
                                        <input id="GroupCoordinator.graph_capture-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
                    <div class="decorator decorator-contextmanager">@contextmanager</div>

        <span class="def">def</span>
        <span class="name">graph_capture</span><span class="signature pdoc-code multiline">(<span class="param">	<span class="bp">self</span>,</span><span class="param">	<span class="n">graph_capture_context</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n"><a href="#GraphCaptureContext">GraphCaptureContext</a></span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span></span><span class="return-annotation">):</span></span>

                <label class="view-source-button" for="GroupCoordinator.graph_capture-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#GroupCoordinator.graph_capture"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="GroupCoordinator.graph_capture-404"><a href="#GroupCoordinator.graph_capture-404"><span class="linenos">404</span></a>    <span class="nd">@contextmanager</span>
</span><span id="GroupCoordinator.graph_capture-405"><a href="#GroupCoordinator.graph_capture-405"><span class="linenos">405</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">graph_capture</span><span class="p">(</span>
</span><span id="GroupCoordinator.graph_capture-406"><a href="#GroupCoordinator.graph_capture-406"><span class="linenos">406</span></a>        <span class="bp">self</span><span class="p">,</span> <span class="n">graph_capture_context</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">GraphCaptureContext</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
</span><span id="GroupCoordinator.graph_capture-407"><a href="#GroupCoordinator.graph_capture-407"><span class="linenos">407</span></a>    <span class="p">):</span>
</span><span id="GroupCoordinator.graph_capture-408"><a href="#GroupCoordinator.graph_capture-408"><span class="linenos">408</span></a>        <span class="k">if</span> <span class="n">graph_capture_context</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="GroupCoordinator.graph_capture-409"><a href="#GroupCoordinator.graph_capture-409"><span class="linenos">409</span></a>            <span class="n">stream</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">device_module</span><span class="o">.</span><span class="n">Stream</span><span class="p">()</span>
</span><span id="GroupCoordinator.graph_capture-410"><a href="#GroupCoordinator.graph_capture-410"><span class="linenos">410</span></a>            <span class="n">graph_capture_context</span> <span class="o">=</span> <span class="n">GraphCaptureContext</span><span class="p">(</span><span class="n">stream</span><span class="p">)</span>
</span><span id="GroupCoordinator.graph_capture-411"><a href="#GroupCoordinator.graph_capture-411"><span class="linenos">411</span></a>        <span class="k">else</span><span class="p">:</span>
</span><span id="GroupCoordinator.graph_capture-412"><a href="#GroupCoordinator.graph_capture-412"><span class="linenos">412</span></a>            <span class="n">stream</span> <span class="o">=</span> <span class="n">graph_capture_context</span><span class="o">.</span><span class="n">stream</span>
</span><span id="GroupCoordinator.graph_capture-413"><a href="#GroupCoordinator.graph_capture-413"><span class="linenos">413</span></a>        <span class="c1"># We don&#39;t need the context of custom quick allreduce because the ipc access</span>
</span><span id="GroupCoordinator.graph_capture-414"><a href="#GroupCoordinator.graph_capture-414"><span class="linenos">414</span></a>        <span class="c1"># is already collected in init() and we can capture the quick allreduce directly.</span>
</span><span id="GroupCoordinator.graph_capture-415"><a href="#GroupCoordinator.graph_capture-415"><span class="linenos">415</span></a>        <span class="n">ca_comm</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">ca_comm</span>
</span><span id="GroupCoordinator.graph_capture-416"><a href="#GroupCoordinator.graph_capture-416"><span class="linenos">416</span></a>        <span class="n">maybe_ca_context</span> <span class="o">=</span> <span class="n">nullcontext</span><span class="p">()</span> <span class="k">if</span> <span class="n">ca_comm</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">ca_comm</span><span class="o">.</span><span class="n">capture</span><span class="p">()</span>
</span><span id="GroupCoordinator.graph_capture-417"><a href="#GroupCoordinator.graph_capture-417"><span class="linenos">417</span></a>
</span><span id="GroupCoordinator.graph_capture-418"><a href="#GroupCoordinator.graph_capture-418"><span class="linenos">418</span></a>        <span class="c1"># ensure all initialization operations complete before attempting to</span>
</span><span id="GroupCoordinator.graph_capture-419"><a href="#GroupCoordinator.graph_capture-419"><span class="linenos">419</span></a>        <span class="c1"># capture the graph on another stream</span>
</span><span id="GroupCoordinator.graph_capture-420"><a href="#GroupCoordinator.graph_capture-420"><span class="linenos">420</span></a>        <span class="n">curr_stream</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">device_module</span><span class="o">.</span><span class="n">current_stream</span><span class="p">()</span>
</span><span id="GroupCoordinator.graph_capture-421"><a href="#GroupCoordinator.graph_capture-421"><span class="linenos">421</span></a>        <span class="k">if</span> <span class="n">curr_stream</span> <span class="o">!=</span> <span class="n">stream</span><span class="p">:</span>
</span><span id="GroupCoordinator.graph_capture-422"><a href="#GroupCoordinator.graph_capture-422"><span class="linenos">422</span></a>            <span class="n">stream</span><span class="o">.</span><span class="n">wait_stream</span><span class="p">(</span><span class="n">curr_stream</span><span class="p">)</span>
</span><span id="GroupCoordinator.graph_capture-423"><a href="#GroupCoordinator.graph_capture-423"><span class="linenos">423</span></a>
</span><span id="GroupCoordinator.graph_capture-424"><a href="#GroupCoordinator.graph_capture-424"><span class="linenos">424</span></a>        <span class="k">with</span> <span class="bp">self</span><span class="o">.</span><span class="n">device_module</span><span class="o">.</span><span class="n">stream</span><span class="p">(</span><span class="n">stream</span><span class="p">),</span> <span class="n">maybe_ca_context</span><span class="p">:</span>
</span><span id="GroupCoordinator.graph_capture-425"><a href="#GroupCoordinator.graph_capture-425"><span class="linenos">425</span></a>            <span class="c1"># In graph mode, we have to be very careful about the collective</span>
</span><span id="GroupCoordinator.graph_capture-426"><a href="#GroupCoordinator.graph_capture-426"><span class="linenos">426</span></a>            <span class="c1"># operations. The current status is:</span>
</span><span id="GroupCoordinator.graph_capture-427"><a href="#GroupCoordinator.graph_capture-427"><span class="linenos">427</span></a>            <span class="c1">#     allreduce \ Mode   |  Eager  |  Graph  |</span>
</span><span id="GroupCoordinator.graph_capture-428"><a href="#GroupCoordinator.graph_capture-428"><span class="linenos">428</span></a>            <span class="c1"># --------------------------------------------</span>
</span><span id="GroupCoordinator.graph_capture-429"><a href="#GroupCoordinator.graph_capture-429"><span class="linenos">429</span></a>            <span class="c1"># quick allreduce        | enabled | enabled |</span>
</span><span id="GroupCoordinator.graph_capture-430"><a href="#GroupCoordinator.graph_capture-430"><span class="linenos">430</span></a>            <span class="c1"># custom allreduce       | enabled | enabled |</span>
</span><span id="GroupCoordinator.graph_capture-431"><a href="#GroupCoordinator.graph_capture-431"><span class="linenos">431</span></a>            <span class="c1"># PyNccl                 | disabled| enabled |</span>
</span><span id="GroupCoordinator.graph_capture-432"><a href="#GroupCoordinator.graph_capture-432"><span class="linenos">432</span></a>            <span class="c1"># PyMscclpp              | disabled| enabled |</span>
</span><span id="GroupCoordinator.graph_capture-433"><a href="#GroupCoordinator.graph_capture-433"><span class="linenos">433</span></a>            <span class="c1"># torch.distributed      | enabled | disabled|</span>
</span><span id="GroupCoordinator.graph_capture-434"><a href="#GroupCoordinator.graph_capture-434"><span class="linenos">434</span></a>            <span class="c1">#</span>
</span><span id="GroupCoordinator.graph_capture-435"><a href="#GroupCoordinator.graph_capture-435"><span class="linenos">435</span></a>            <span class="c1"># Note: When custom quick allreduce is enabled, a runtime check</span>
</span><span id="GroupCoordinator.graph_capture-436"><a href="#GroupCoordinator.graph_capture-436"><span class="linenos">436</span></a>            <span class="c1">#  will be performed. If the tensor size is too small, it will</span>
</span><span id="GroupCoordinator.graph_capture-437"><a href="#GroupCoordinator.graph_capture-437"><span class="linenos">437</span></a>            <span class="c1">#  automatically fall back to the next available option.</span>
</span><span id="GroupCoordinator.graph_capture-438"><a href="#GroupCoordinator.graph_capture-438"><span class="linenos">438</span></a>            <span class="c1"># Note that custom allreduce will have a runtime check, if the</span>
</span><span id="GroupCoordinator.graph_capture-439"><a href="#GroupCoordinator.graph_capture-439"><span class="linenos">439</span></a>            <span class="c1">#  tensor size is too large, it will fallback to the next</span>
</span><span id="GroupCoordinator.graph_capture-440"><a href="#GroupCoordinator.graph_capture-440"><span class="linenos">440</span></a>            <span class="c1">#  available option.</span>
</span><span id="GroupCoordinator.graph_capture-441"><a href="#GroupCoordinator.graph_capture-441"><span class="linenos">441</span></a>            <span class="c1"># Note that the PyMsccl needs to register the tensor in ahead,</span>
</span><span id="GroupCoordinator.graph_capture-442"><a href="#GroupCoordinator.graph_capture-442"><span class="linenos">442</span></a>            <span class="c1">#  which will introduce large overhead in the eager case,</span>
</span><span id="GroupCoordinator.graph_capture-443"><a href="#GroupCoordinator.graph_capture-443"><span class="linenos">443</span></a>            <span class="c1">#  therefore it is only supported in the graph case.</span>
</span><span id="GroupCoordinator.graph_capture-444"><a href="#GroupCoordinator.graph_capture-444"><span class="linenos">444</span></a>            <span class="c1"># In summary: We select the appropriate allreduce method for</span>
</span><span id="GroupCoordinator.graph_capture-445"><a href="#GroupCoordinator.graph_capture-445"><span class="linenos">445</span></a>            <span class="c1">#  each mode based on the algorithm order in the table and</span>
</span><span id="GroupCoordinator.graph_capture-446"><a href="#GroupCoordinator.graph_capture-446"><span class="linenos">446</span></a>            <span class="c1">#  their usage conditions.</span>
</span><span id="GroupCoordinator.graph_capture-447"><a href="#GroupCoordinator.graph_capture-447"><span class="linenos">447</span></a>            <span class="n">pynccl_comm</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">pynccl_comm</span>
</span><span id="GroupCoordinator.graph_capture-448"><a href="#GroupCoordinator.graph_capture-448"><span class="linenos">448</span></a>            <span class="n">maybe_pynccl_context</span><span class="p">:</span> <span class="n">Any</span>
</span><span id="GroupCoordinator.graph_capture-449"><a href="#GroupCoordinator.graph_capture-449"><span class="linenos">449</span></a>            <span class="k">if</span> <span class="ow">not</span> <span class="n">pynccl_comm</span><span class="p">:</span>
</span><span id="GroupCoordinator.graph_capture-450"><a href="#GroupCoordinator.graph_capture-450"><span class="linenos">450</span></a>                <span class="n">maybe_pynccl_context</span> <span class="o">=</span> <span class="n">nullcontext</span><span class="p">()</span>
</span><span id="GroupCoordinator.graph_capture-451"><a href="#GroupCoordinator.graph_capture-451"><span class="linenos">451</span></a>            <span class="k">else</span><span class="p">:</span>
</span><span id="GroupCoordinator.graph_capture-452"><a href="#GroupCoordinator.graph_capture-452"><span class="linenos">452</span></a>                <span class="n">maybe_pynccl_context</span> <span class="o">=</span> <span class="n">pynccl_comm</span><span class="o">.</span><span class="n">change_state</span><span class="p">(</span>
</span><span id="GroupCoordinator.graph_capture-453"><a href="#GroupCoordinator.graph_capture-453"><span class="linenos">453</span></a>                    <span class="n">enable</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">stream</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">current_stream</span><span class="p">()</span>
</span><span id="GroupCoordinator.graph_capture-454"><a href="#GroupCoordinator.graph_capture-454"><span class="linenos">454</span></a>                <span class="p">)</span>
</span><span id="GroupCoordinator.graph_capture-455"><a href="#GroupCoordinator.graph_capture-455"><span class="linenos">455</span></a>
</span><span id="GroupCoordinator.graph_capture-456"><a href="#GroupCoordinator.graph_capture-456"><span class="linenos">456</span></a>            <span class="n">pymscclpp_comm</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">pymscclpp_comm</span>
</span><span id="GroupCoordinator.graph_capture-457"><a href="#GroupCoordinator.graph_capture-457"><span class="linenos">457</span></a>            <span class="n">maybe_pymscclpp_context</span><span class="p">:</span> <span class="n">Any</span>
</span><span id="GroupCoordinator.graph_capture-458"><a href="#GroupCoordinator.graph_capture-458"><span class="linenos">458</span></a>            <span class="k">if</span> <span class="ow">not</span> <span class="n">pymscclpp_comm</span><span class="p">:</span>
</span><span id="GroupCoordinator.graph_capture-459"><a href="#GroupCoordinator.graph_capture-459"><span class="linenos">459</span></a>                <span class="n">maybe_pymscclpp_context</span> <span class="o">=</span> <span class="n">nullcontext</span><span class="p">()</span>
</span><span id="GroupCoordinator.graph_capture-460"><a href="#GroupCoordinator.graph_capture-460"><span class="linenos">460</span></a>            <span class="k">else</span><span class="p">:</span>
</span><span id="GroupCoordinator.graph_capture-461"><a href="#GroupCoordinator.graph_capture-461"><span class="linenos">461</span></a>                <span class="n">maybe_pymscclpp_context</span> <span class="o">=</span> <span class="n">pymscclpp_comm</span><span class="o">.</span><span class="n">change_state</span><span class="p">(</span><span class="n">enable</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</span><span id="GroupCoordinator.graph_capture-462"><a href="#GroupCoordinator.graph_capture-462"><span class="linenos">462</span></a>            <span class="k">with</span> <span class="n">maybe_pynccl_context</span><span class="p">,</span> <span class="n">maybe_pymscclpp_context</span><span class="p">:</span>
</span><span id="GroupCoordinator.graph_capture-463"><a href="#GroupCoordinator.graph_capture-463"><span class="linenos">463</span></a>                <span class="k">yield</span> <span class="n">graph_capture_context</span>
</span></pre></div>


    

                            </div>
                            <div id="GroupCoordinator.all_reduce" class="classattr">
                                        <input id="GroupCoordinator.all_reduce-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="def">def</span>
        <span class="name">all_reduce</span><span class="signature pdoc-code condensed">(<span class="param"><span class="bp">self</span>, </span><span class="param"><span class="n">input_</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span></span><span class="return-annotation">) -> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span>:</span></span>

                <label class="view-source-button" for="GroupCoordinator.all_reduce-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#GroupCoordinator.all_reduce"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="GroupCoordinator.all_reduce-465"><a href="#GroupCoordinator.all_reduce-465"><span class="linenos">465</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">all_reduce</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
</span><span id="GroupCoordinator.all_reduce-466"><a href="#GroupCoordinator.all_reduce-466"><span class="linenos">466</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="GroupCoordinator.all_reduce-467"><a href="#GroupCoordinator.all_reduce-467"><span class="linenos">467</span></a><span class="sd">        User-facing all-reduce function before we actually call the</span>
</span><span id="GroupCoordinator.all_reduce-468"><a href="#GroupCoordinator.all_reduce-468"><span class="linenos">468</span></a><span class="sd">        all-reduce operation.</span>
</span><span id="GroupCoordinator.all_reduce-469"><a href="#GroupCoordinator.all_reduce-469"><span class="linenos">469</span></a>
</span><span id="GroupCoordinator.all_reduce-470"><a href="#GroupCoordinator.all_reduce-470"><span class="linenos">470</span></a><span class="sd">        We need this because Dynamo does not support passing an arbitrary</span>
</span><span id="GroupCoordinator.all_reduce-471"><a href="#GroupCoordinator.all_reduce-471"><span class="linenos">471</span></a><span class="sd">        object (`self` in this case) to a custom op. We need to pass the</span>
</span><span id="GroupCoordinator.all_reduce-472"><a href="#GroupCoordinator.all_reduce-472"><span class="linenos">472</span></a><span class="sd">         group name as a string, and then look up the group coordinator from</span>
</span><span id="GroupCoordinator.all_reduce-473"><a href="#GroupCoordinator.all_reduce-473"><span class="linenos">473</span></a><span class="sd">         the group name, dispatch the all-reduce operation to the group</span>
</span><span id="GroupCoordinator.all_reduce-474"><a href="#GroupCoordinator.all_reduce-474"><span class="linenos">474</span></a><span class="sd">         coordinator.</span>
</span><span id="GroupCoordinator.all_reduce-475"><a href="#GroupCoordinator.all_reduce-475"><span class="linenos">475</span></a>
</span><span id="GroupCoordinator.all_reduce-476"><a href="#GroupCoordinator.all_reduce-476"><span class="linenos">476</span></a><span class="sd">        In addition, PyTorch custom ops do not support mutation or returning</span>
</span><span id="GroupCoordinator.all_reduce-477"><a href="#GroupCoordinator.all_reduce-477"><span class="linenos">477</span></a><span class="sd">        a new tensor in the same op. So we need to figure out if the op is</span>
</span><span id="GroupCoordinator.all_reduce-478"><a href="#GroupCoordinator.all_reduce-478"><span class="linenos">478</span></a><span class="sd">        in-place or out-of-place ahead of time.</span>
</span><span id="GroupCoordinator.all_reduce-479"><a href="#GroupCoordinator.all_reduce-479"><span class="linenos">479</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="GroupCoordinator.all_reduce-480"><a href="#GroupCoordinator.all_reduce-480"><span class="linenos">480</span></a>        <span class="c1"># Bypass the function if we are using only 1 GPU.</span>
</span><span id="GroupCoordinator.all_reduce-481"><a href="#GroupCoordinator.all_reduce-481"><span class="linenos">481</span></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">world_size</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
</span><span id="GroupCoordinator.all_reduce-482"><a href="#GroupCoordinator.all_reduce-482"><span class="linenos">482</span></a>            <span class="k">return</span> <span class="n">input_</span>
</span><span id="GroupCoordinator.all_reduce-483"><a href="#GroupCoordinator.all_reduce-483"><span class="linenos">483</span></a>
</span><span id="GroupCoordinator.all_reduce-484"><a href="#GroupCoordinator.all_reduce-484"><span class="linenos">484</span></a>        <span class="k">if</span> <span class="n">input_</span><span class="o">.</span><span class="n">is_cpu</span><span class="p">:</span>
</span><span id="GroupCoordinator.all_reduce-485"><a href="#GroupCoordinator.all_reduce-485"><span class="linenos">485</span></a>            <span class="k">if</span> <span class="n">is_shm_available</span><span class="p">(</span><span class="n">input_</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">world_size</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">local_size</span><span class="p">):</span>
</span><span id="GroupCoordinator.all_reduce-486"><a href="#GroupCoordinator.all_reduce-486"><span class="linenos">486</span></a>                <span class="n">torch</span><span class="o">.</span><span class="n">ops</span><span class="o">.</span><span class="n">sgl_kernel</span><span class="o">.</span><span class="n">shm_allreduce</span><span class="p">(</span>
</span><span id="GroupCoordinator.all_reduce-487"><a href="#GroupCoordinator.all_reduce-487"><span class="linenos">487</span></a>                    <span class="n">input_</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">distributed</span><span class="o">.</span><span class="n">ReduceOp</span><span class="o">.</span><span class="n">SUM</span>
</span><span id="GroupCoordinator.all_reduce-488"><a href="#GroupCoordinator.all_reduce-488"><span class="linenos">488</span></a>                <span class="p">)</span>
</span><span id="GroupCoordinator.all_reduce-489"><a href="#GroupCoordinator.all_reduce-489"><span class="linenos">489</span></a>            <span class="k">else</span><span class="p">:</span>
</span><span id="GroupCoordinator.all_reduce-490"><a href="#GroupCoordinator.all_reduce-490"><span class="linenos">490</span></a>                <span class="n">torch</span><span class="o">.</span><span class="n">distributed</span><span class="o">.</span><span class="n">all_reduce</span><span class="p">(</span><span class="n">input_</span><span class="p">,</span> <span class="n">group</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device_group</span><span class="p">)</span>
</span><span id="GroupCoordinator.all_reduce-491"><a href="#GroupCoordinator.all_reduce-491"><span class="linenos">491</span></a>            <span class="k">return</span> <span class="n">input_</span>
</span><span id="GroupCoordinator.all_reduce-492"><a href="#GroupCoordinator.all_reduce-492"><span class="linenos">492</span></a>
</span><span id="GroupCoordinator.all_reduce-493"><a href="#GroupCoordinator.all_reduce-493"><span class="linenos">493</span></a>        <span class="k">if</span> <span class="ow">not</span> <span class="n">supports_custom_op</span><span class="p">():</span>
</span><span id="GroupCoordinator.all_reduce-494"><a href="#GroupCoordinator.all_reduce-494"><span class="linenos">494</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">_all_reduce_in_place</span><span class="p">(</span><span class="n">input_</span><span class="p">)</span>
</span><span id="GroupCoordinator.all_reduce-495"><a href="#GroupCoordinator.all_reduce-495"><span class="linenos">495</span></a>            <span class="k">return</span> <span class="n">input_</span>
</span><span id="GroupCoordinator.all_reduce-496"><a href="#GroupCoordinator.all_reduce-496"><span class="linenos">496</span></a>
</span><span id="GroupCoordinator.all_reduce-497"><a href="#GroupCoordinator.all_reduce-497"><span class="linenos">497</span></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">hpu_communicator</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">hpu_communicator</span><span class="o">.</span><span class="n">disabled</span><span class="p">:</span>
</span><span id="GroupCoordinator.all_reduce-498"><a href="#GroupCoordinator.all_reduce-498"><span class="linenos">498</span></a>            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">hpu_communicator</span><span class="o">.</span><span class="n">all_reduce</span><span class="p">(</span><span class="n">input_</span><span class="p">)</span>
</span><span id="GroupCoordinator.all_reduce-499"><a href="#GroupCoordinator.all_reduce-499"><span class="linenos">499</span></a>
</span><span id="GroupCoordinator.all_reduce-500"><a href="#GroupCoordinator.all_reduce-500"><span class="linenos">500</span></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">xpu_communicator</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">xpu_communicator</span><span class="o">.</span><span class="n">disabled</span><span class="p">:</span>
</span><span id="GroupCoordinator.all_reduce-501"><a href="#GroupCoordinator.all_reduce-501"><span class="linenos">501</span></a>            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">xpu_communicator</span><span class="o">.</span><span class="n">all_reduce</span><span class="p">(</span><span class="n">input_</span><span class="p">)</span>
</span><span id="GroupCoordinator.all_reduce-502"><a href="#GroupCoordinator.all_reduce-502"><span class="linenos">502</span></a>
</span><span id="GroupCoordinator.all_reduce-503"><a href="#GroupCoordinator.all_reduce-503"><span class="linenos">503</span></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">npu_communicator</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">npu_communicator</span><span class="o">.</span><span class="n">disabled</span><span class="p">:</span>
</span><span id="GroupCoordinator.all_reduce-504"><a href="#GroupCoordinator.all_reduce-504"><span class="linenos">504</span></a>            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">npu_communicator</span><span class="o">.</span><span class="n">all_reduce</span><span class="p">(</span><span class="n">input_</span><span class="p">)</span>
</span><span id="GroupCoordinator.all_reduce-505"><a href="#GroupCoordinator.all_reduce-505"><span class="linenos">505</span></a>
</span><span id="GroupCoordinator.all_reduce-506"><a href="#GroupCoordinator.all_reduce-506"><span class="linenos">506</span></a>        <span class="k">if</span> <span class="p">(</span>
</span><span id="GroupCoordinator.all_reduce-507"><a href="#GroupCoordinator.all_reduce-507"><span class="linenos">507</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">pynccl_comm</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
</span><span id="GroupCoordinator.all_reduce-508"><a href="#GroupCoordinator.all_reduce-508"><span class="linenos">508</span></a>            <span class="ow">and</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">input_</span><span class="p">,</span> <span class="s2">&quot;symmetric_memory&quot;</span><span class="p">)</span>
</span><span id="GroupCoordinator.all_reduce-509"><a href="#GroupCoordinator.all_reduce-509"><span class="linenos">509</span></a>            <span class="ow">and</span> <span class="n">input_</span><span class="o">.</span><span class="n">symmetric_memory</span>
</span><span id="GroupCoordinator.all_reduce-510"><a href="#GroupCoordinator.all_reduce-510"><span class="linenos">510</span></a>        <span class="p">):</span>
</span><span id="GroupCoordinator.all_reduce-511"><a href="#GroupCoordinator.all_reduce-511"><span class="linenos">511</span></a>            <span class="k">with</span> <span class="bp">self</span><span class="o">.</span><span class="n">pynccl_comm</span><span class="o">.</span><span class="n">change_state</span><span class="p">(</span>
</span><span id="GroupCoordinator.all_reduce-512"><a href="#GroupCoordinator.all_reduce-512"><span class="linenos">512</span></a>                <span class="n">enable</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">stream</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">current_stream</span><span class="p">()</span>
</span><span id="GroupCoordinator.all_reduce-513"><a href="#GroupCoordinator.all_reduce-513"><span class="linenos">513</span></a>            <span class="p">):</span>
</span><span id="GroupCoordinator.all_reduce-514"><a href="#GroupCoordinator.all_reduce-514"><span class="linenos">514</span></a>                <span class="bp">self</span><span class="o">.</span><span class="n">pynccl_comm</span><span class="o">.</span><span class="n">all_reduce</span><span class="p">(</span><span class="n">input_</span><span class="p">)</span>
</span><span id="GroupCoordinator.all_reduce-515"><a href="#GroupCoordinator.all_reduce-515"><span class="linenos">515</span></a>                <span class="k">return</span> <span class="n">input_</span>
</span><span id="GroupCoordinator.all_reduce-516"><a href="#GroupCoordinator.all_reduce-516"><span class="linenos">516</span></a>
</span><span id="GroupCoordinator.all_reduce-517"><a href="#GroupCoordinator.all_reduce-517"><span class="linenos">517</span></a>        <span class="n">outplace_all_reduce_method</span> <span class="o">=</span> <span class="kc">None</span>
</span><span id="GroupCoordinator.all_reduce-518"><a href="#GroupCoordinator.all_reduce-518"><span class="linenos">518</span></a>        <span class="k">if</span> <span class="p">(</span>
</span><span id="GroupCoordinator.all_reduce-519"><a href="#GroupCoordinator.all_reduce-519"><span class="linenos">519</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">qr_comm</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
</span><span id="GroupCoordinator.all_reduce-520"><a href="#GroupCoordinator.all_reduce-520"><span class="linenos">520</span></a>            <span class="ow">and</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">qr_comm</span><span class="o">.</span><span class="n">disabled</span>
</span><span id="GroupCoordinator.all_reduce-521"><a href="#GroupCoordinator.all_reduce-521"><span class="linenos">521</span></a>            <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">qr_comm</span><span class="o">.</span><span class="n">should_quick_allreduce</span><span class="p">(</span><span class="n">input_</span><span class="p">)</span>
</span><span id="GroupCoordinator.all_reduce-522"><a href="#GroupCoordinator.all_reduce-522"><span class="linenos">522</span></a>        <span class="p">):</span>
</span><span id="GroupCoordinator.all_reduce-523"><a href="#GroupCoordinator.all_reduce-523"><span class="linenos">523</span></a>            <span class="n">outplace_all_reduce_method</span> <span class="o">=</span> <span class="s2">&quot;qr&quot;</span>
</span><span id="GroupCoordinator.all_reduce-524"><a href="#GroupCoordinator.all_reduce-524"><span class="linenos">524</span></a>        <span class="k">elif</span> <span class="p">(</span>
</span><span id="GroupCoordinator.all_reduce-525"><a href="#GroupCoordinator.all_reduce-525"><span class="linenos">525</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">ca_comm</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
</span><span id="GroupCoordinator.all_reduce-526"><a href="#GroupCoordinator.all_reduce-526"><span class="linenos">526</span></a>            <span class="ow">and</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">ca_comm</span><span class="o">.</span><span class="n">disabled</span>
</span><span id="GroupCoordinator.all_reduce-527"><a href="#GroupCoordinator.all_reduce-527"><span class="linenos">527</span></a>            <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">ca_comm</span><span class="o">.</span><span class="n">should_custom_ar</span><span class="p">(</span><span class="n">input_</span><span class="p">)</span>
</span><span id="GroupCoordinator.all_reduce-528"><a href="#GroupCoordinator.all_reduce-528"><span class="linenos">528</span></a>        <span class="p">):</span>
</span><span id="GroupCoordinator.all_reduce-529"><a href="#GroupCoordinator.all_reduce-529"><span class="linenos">529</span></a>            <span class="n">outplace_all_reduce_method</span> <span class="o">=</span> <span class="s2">&quot;ca&quot;</span>
</span><span id="GroupCoordinator.all_reduce-530"><a href="#GroupCoordinator.all_reduce-530"><span class="linenos">530</span></a>        <span class="k">elif</span> <span class="p">(</span>
</span><span id="GroupCoordinator.all_reduce-531"><a href="#GroupCoordinator.all_reduce-531"><span class="linenos">531</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">pymscclpp_comm</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
</span><span id="GroupCoordinator.all_reduce-532"><a href="#GroupCoordinator.all_reduce-532"><span class="linenos">532</span></a>            <span class="ow">and</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">pymscclpp_comm</span><span class="o">.</span><span class="n">disabled</span>
</span><span id="GroupCoordinator.all_reduce-533"><a href="#GroupCoordinator.all_reduce-533"><span class="linenos">533</span></a>            <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">pymscclpp_comm</span><span class="o">.</span><span class="n">should_mscclpp_allreduce</span><span class="p">(</span><span class="n">input_</span><span class="p">)</span>
</span><span id="GroupCoordinator.all_reduce-534"><a href="#GroupCoordinator.all_reduce-534"><span class="linenos">534</span></a>        <span class="p">):</span>
</span><span id="GroupCoordinator.all_reduce-535"><a href="#GroupCoordinator.all_reduce-535"><span class="linenos">535</span></a>            <span class="n">outplace_all_reduce_method</span> <span class="o">=</span> <span class="s2">&quot;pymscclpp&quot;</span>
</span><span id="GroupCoordinator.all_reduce-536"><a href="#GroupCoordinator.all_reduce-536"><span class="linenos">536</span></a>        <span class="k">if</span> <span class="n">outplace_all_reduce_method</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="GroupCoordinator.all_reduce-537"><a href="#GroupCoordinator.all_reduce-537"><span class="linenos">537</span></a>            <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">ops</span><span class="o">.</span><span class="n">sglang</span><span class="o">.</span><span class="n">outplace_all_reduce</span><span class="p">(</span>
</span><span id="GroupCoordinator.all_reduce-538"><a href="#GroupCoordinator.all_reduce-538"><span class="linenos">538</span></a>                <span class="n">input_</span><span class="p">,</span>
</span><span id="GroupCoordinator.all_reduce-539"><a href="#GroupCoordinator.all_reduce-539"><span class="linenos">539</span></a>                <span class="n">group_name</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">unique_name</span><span class="p">,</span>
</span><span id="GroupCoordinator.all_reduce-540"><a href="#GroupCoordinator.all_reduce-540"><span class="linenos">540</span></a>                <span class="n">outplace_all_reduce_method</span><span class="o">=</span><span class="n">outplace_all_reduce_method</span><span class="p">,</span>
</span><span id="GroupCoordinator.all_reduce-541"><a href="#GroupCoordinator.all_reduce-541"><span class="linenos">541</span></a>            <span class="p">)</span>
</span><span id="GroupCoordinator.all_reduce-542"><a href="#GroupCoordinator.all_reduce-542"><span class="linenos">542</span></a>        <span class="k">else</span><span class="p">:</span>
</span><span id="GroupCoordinator.all_reduce-543"><a href="#GroupCoordinator.all_reduce-543"><span class="linenos">543</span></a>            <span class="n">torch</span><span class="o">.</span><span class="n">ops</span><span class="o">.</span><span class="n">sglang</span><span class="o">.</span><span class="n">inplace_all_reduce</span><span class="p">(</span><span class="n">input_</span><span class="p">,</span> <span class="n">group_name</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">unique_name</span><span class="p">)</span>
</span><span id="GroupCoordinator.all_reduce-544"><a href="#GroupCoordinator.all_reduce-544"><span class="linenos">544</span></a>            <span class="k">return</span> <span class="n">input_</span>
</span></pre></div>


            <div class="docstring"><p>User-facing all-reduce function before we actually call the
all-reduce operation.</p>

<p>We need this because Dynamo does not support passing an arbitrary
object (<code>self</code> in this case) to a custom op. We need to pass the
 group name as a string, and then look up the group coordinator from
 the group name, dispatch the all-reduce operation to the group
 coordinator.</p>

<p>In addition, PyTorch custom ops do not support mutation or returning
a new tensor in the same op. So we need to figure out if the op is
in-place or out-of-place ahead of time.</p>
</div>


                            </div>
                            <div id="GroupCoordinator.reduce_scatter_tensor" class="classattr">
                                        <input id="GroupCoordinator.reduce_scatter_tensor-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="def">def</span>
        <span class="name">reduce_scatter_tensor</span><span class="signature pdoc-code condensed">(<span class="param"><span class="bp">self</span>, </span><span class="param"><span class="n">output</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span>, </span><span class="param"><span class="nb">input</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span></span><span class="return-annotation">) -> <span class="kc">None</span>:</span></span>

                <label class="view-source-button" for="GroupCoordinator.reduce_scatter_tensor-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#GroupCoordinator.reduce_scatter_tensor"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="GroupCoordinator.reduce_scatter_tensor-572"><a href="#GroupCoordinator.reduce_scatter_tensor-572"><span class="linenos">572</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">reduce_scatter_tensor</span><span class="p">(</span>
</span><span id="GroupCoordinator.reduce_scatter_tensor-573"><a href="#GroupCoordinator.reduce_scatter_tensor-573"><span class="linenos">573</span></a>        <span class="bp">self</span><span class="p">,</span>
</span><span id="GroupCoordinator.reduce_scatter_tensor-574"><a href="#GroupCoordinator.reduce_scatter_tensor-574"><span class="linenos">574</span></a>        <span class="n">output</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
</span><span id="GroupCoordinator.reduce_scatter_tensor-575"><a href="#GroupCoordinator.reduce_scatter_tensor-575"><span class="linenos">575</span></a>        <span class="nb">input</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
</span><span id="GroupCoordinator.reduce_scatter_tensor-576"><a href="#GroupCoordinator.reduce_scatter_tensor-576"><span class="linenos">576</span></a>    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="GroupCoordinator.reduce_scatter_tensor-577"><a href="#GroupCoordinator.reduce_scatter_tensor-577"><span class="linenos">577</span></a>        <span class="c1"># TODO(ch-wan): support other backends</span>
</span><span id="GroupCoordinator.reduce_scatter_tensor-578"><a href="#GroupCoordinator.reduce_scatter_tensor-578"><span class="linenos">578</span></a>        <span class="n">torch</span><span class="o">.</span><span class="n">distributed</span><span class="o">.</span><span class="n">reduce_scatter_tensor</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="nb">input</span><span class="p">,</span> <span class="n">group</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device_group</span><span class="p">)</span>
</span><span id="GroupCoordinator.reduce_scatter_tensor-579"><a href="#GroupCoordinator.reduce_scatter_tensor-579"><span class="linenos">579</span></a>        <span class="k">return</span> <span class="n">output</span>
</span></pre></div>


    

                            </div>
                            <div id="GroupCoordinator.reduce_scatter" class="classattr">
                                        <input id="GroupCoordinator.reduce_scatter-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="def">def</span>
        <span class="name">reduce_scatter</span><span class="signature pdoc-code condensed">(<span class="param"><span class="bp">self</span>, </span><span class="param"><span class="n">output</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span>, </span><span class="param"><span class="n">input_list</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span></span><span class="return-annotation">) -> <span class="kc">None</span>:</span></span>

                <label class="view-source-button" for="GroupCoordinator.reduce_scatter-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#GroupCoordinator.reduce_scatter"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="GroupCoordinator.reduce_scatter-581"><a href="#GroupCoordinator.reduce_scatter-581"><span class="linenos">581</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">reduce_scatter</span><span class="p">(</span>
</span><span id="GroupCoordinator.reduce_scatter-582"><a href="#GroupCoordinator.reduce_scatter-582"><span class="linenos">582</span></a>        <span class="bp">self</span><span class="p">,</span>
</span><span id="GroupCoordinator.reduce_scatter-583"><a href="#GroupCoordinator.reduce_scatter-583"><span class="linenos">583</span></a>        <span class="n">output</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
</span><span id="GroupCoordinator.reduce_scatter-584"><a href="#GroupCoordinator.reduce_scatter-584"><span class="linenos">584</span></a>        <span class="n">input_list</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">],</span>
</span><span id="GroupCoordinator.reduce_scatter-585"><a href="#GroupCoordinator.reduce_scatter-585"><span class="linenos">585</span></a>    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="GroupCoordinator.reduce_scatter-586"><a href="#GroupCoordinator.reduce_scatter-586"><span class="linenos">586</span></a>        <span class="c1"># TODO(ch-wan): support other backends</span>
</span><span id="GroupCoordinator.reduce_scatter-587"><a href="#GroupCoordinator.reduce_scatter-587"><span class="linenos">587</span></a>        <span class="n">torch</span><span class="o">.</span><span class="n">distributed</span><span class="o">.</span><span class="n">reduce_scatter</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="n">input_list</span><span class="p">,</span> <span class="n">group</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device_group</span><span class="p">)</span>
</span><span id="GroupCoordinator.reduce_scatter-588"><a href="#GroupCoordinator.reduce_scatter-588"><span class="linenos">588</span></a>        <span class="k">return</span> <span class="n">output</span>
</span></pre></div>


    

                            </div>
                            <div id="GroupCoordinator.reduce_scatterv" class="classattr">
                                        <input id="GroupCoordinator.reduce_scatterv-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="def">def</span>
        <span class="name">reduce_scatterv</span><span class="signature pdoc-code multiline">(<span class="param">	<span class="bp">self</span>,</span><span class="param">	<span class="n">input_</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span>,</span><span class="param">	<span class="n">output</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>,</span><span class="param">	<span class="n">sizes</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="nb">int</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span></span><span class="return-annotation">) -> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span>:</span></span>

                <label class="view-source-button" for="GroupCoordinator.reduce_scatterv-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#GroupCoordinator.reduce_scatterv"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="GroupCoordinator.reduce_scatterv-590"><a href="#GroupCoordinator.reduce_scatterv-590"><span class="linenos">590</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">reduce_scatterv</span><span class="p">(</span>
</span><span id="GroupCoordinator.reduce_scatterv-591"><a href="#GroupCoordinator.reduce_scatterv-591"><span class="linenos">591</span></a>        <span class="bp">self</span><span class="p">,</span>
</span><span id="GroupCoordinator.reduce_scatterv-592"><a href="#GroupCoordinator.reduce_scatterv-592"><span class="linenos">592</span></a>        <span class="n">input_</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
</span><span id="GroupCoordinator.reduce_scatterv-593"><a href="#GroupCoordinator.reduce_scatterv-593"><span class="linenos">593</span></a>        <span class="n">output</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="GroupCoordinator.reduce_scatterv-594"><a href="#GroupCoordinator.reduce_scatterv-594"><span class="linenos">594</span></a>        <span class="n">sizes</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="nb">int</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="GroupCoordinator.reduce_scatterv-595"><a href="#GroupCoordinator.reduce_scatterv-595"><span class="linenos">595</span></a>    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
</span><span id="GroupCoordinator.reduce_scatterv-596"><a href="#GroupCoordinator.reduce_scatterv-596"><span class="linenos">596</span></a>        <span class="n">world_size</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">world_size</span>
</span><span id="GroupCoordinator.reduce_scatterv-597"><a href="#GroupCoordinator.reduce_scatterv-597"><span class="linenos">597</span></a>        <span class="n">pynccl_comm</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">pynccl_comm</span>
</span><span id="GroupCoordinator.reduce_scatterv-598"><a href="#GroupCoordinator.reduce_scatterv-598"><span class="linenos">598</span></a>
</span><span id="GroupCoordinator.reduce_scatterv-599"><a href="#GroupCoordinator.reduce_scatterv-599"><span class="linenos">599</span></a>        <span class="k">with</span> <span class="n">pynccl_comm</span><span class="o">.</span><span class="n">change_state</span><span class="p">(</span><span class="n">enable</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">stream</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">current_stream</span><span class="p">()):</span>
</span><span id="GroupCoordinator.reduce_scatterv-600"><a href="#GroupCoordinator.reduce_scatterv-600"><span class="linenos">600</span></a>            <span class="k">assert</span> <span class="p">(</span>
</span><span id="GroupCoordinator.reduce_scatterv-601"><a href="#GroupCoordinator.reduce_scatterv-601"><span class="linenos">601</span></a>                <span class="n">pynccl_comm</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">pynccl_comm</span><span class="o">.</span><span class="n">disabled</span>
</span><span id="GroupCoordinator.reduce_scatterv-602"><a href="#GroupCoordinator.reduce_scatterv-602"><span class="linenos">602</span></a>            <span class="p">),</span> <span class="s2">&quot;pynccl is required for reduce_scatterv&quot;</span>
</span><span id="GroupCoordinator.reduce_scatterv-603"><a href="#GroupCoordinator.reduce_scatterv-603"><span class="linenos">603</span></a>
</span><span id="GroupCoordinator.reduce_scatterv-604"><a href="#GroupCoordinator.reduce_scatterv-604"><span class="linenos">604</span></a>            <span class="k">if</span> <span class="n">sizes</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="GroupCoordinator.reduce_scatterv-605"><a href="#GroupCoordinator.reduce_scatterv-605"><span class="linenos">605</span></a>                <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">sizes</span><span class="p">)</span> <span class="o">==</span> <span class="n">world_size</span>
</span><span id="GroupCoordinator.reduce_scatterv-606"><a href="#GroupCoordinator.reduce_scatterv-606"><span class="linenos">606</span></a>                <span class="k">assert</span> <span class="n">input_</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">==</span> <span class="nb">sum</span><span class="p">(</span><span class="n">sizes</span><span class="p">)</span>
</span><span id="GroupCoordinator.reduce_scatterv-607"><a href="#GroupCoordinator.reduce_scatterv-607"><span class="linenos">607</span></a>                <span class="n">chunk_size</span> <span class="o">=</span> <span class="n">sizes</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">rank_in_group</span><span class="p">]</span>
</span><span id="GroupCoordinator.reduce_scatterv-608"><a href="#GroupCoordinator.reduce_scatterv-608"><span class="linenos">608</span></a>            <span class="k">else</span><span class="p">:</span>
</span><span id="GroupCoordinator.reduce_scatterv-609"><a href="#GroupCoordinator.reduce_scatterv-609"><span class="linenos">609</span></a>                <span class="k">assert</span> <span class="n">input_</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">%</span> <span class="n">world_size</span> <span class="o">==</span> <span class="mi">0</span>
</span><span id="GroupCoordinator.reduce_scatterv-610"><a href="#GroupCoordinator.reduce_scatterv-610"><span class="linenos">610</span></a>                <span class="n">chunk_size</span> <span class="o">=</span> <span class="n">input_</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">//</span> <span class="n">world_size</span>
</span><span id="GroupCoordinator.reduce_scatterv-611"><a href="#GroupCoordinator.reduce_scatterv-611"><span class="linenos">611</span></a>            <span class="n">output_shape</span> <span class="o">=</span> <span class="p">(</span><span class="n">chunk_size</span><span class="p">,)</span> <span class="o">+</span> <span class="n">input_</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">:]</span>
</span><span id="GroupCoordinator.reduce_scatterv-612"><a href="#GroupCoordinator.reduce_scatterv-612"><span class="linenos">612</span></a>
</span><span id="GroupCoordinator.reduce_scatterv-613"><a href="#GroupCoordinator.reduce_scatterv-613"><span class="linenos">613</span></a>            <span class="k">if</span> <span class="n">output</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="GroupCoordinator.reduce_scatterv-614"><a href="#GroupCoordinator.reduce_scatterv-614"><span class="linenos">614</span></a>                <span class="n">output</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span>
</span><span id="GroupCoordinator.reduce_scatterv-615"><a href="#GroupCoordinator.reduce_scatterv-615"><span class="linenos">615</span></a>                    <span class="n">output_shape</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">input_</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">input_</span><span class="o">.</span><span class="n">device</span>
</span><span id="GroupCoordinator.reduce_scatterv-616"><a href="#GroupCoordinator.reduce_scatterv-616"><span class="linenos">616</span></a>                <span class="p">)</span>
</span><span id="GroupCoordinator.reduce_scatterv-617"><a href="#GroupCoordinator.reduce_scatterv-617"><span class="linenos">617</span></a>            <span class="k">else</span><span class="p">:</span>
</span><span id="GroupCoordinator.reduce_scatterv-618"><a href="#GroupCoordinator.reduce_scatterv-618"><span class="linenos">618</span></a>                <span class="k">assert</span> <span class="n">output</span><span class="o">.</span><span class="n">shape</span> <span class="o">==</span> <span class="n">output_shape</span>
</span><span id="GroupCoordinator.reduce_scatterv-619"><a href="#GroupCoordinator.reduce_scatterv-619"><span class="linenos">619</span></a>
</span><span id="GroupCoordinator.reduce_scatterv-620"><a href="#GroupCoordinator.reduce_scatterv-620"><span class="linenos">620</span></a>            <span class="n">pynccl_comm</span><span class="o">.</span><span class="n">reduce_scatter</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="n">input_</span><span class="p">,</span> <span class="n">sizes</span><span class="o">=</span><span class="n">sizes</span><span class="p">)</span>
</span><span id="GroupCoordinator.reduce_scatterv-621"><a href="#GroupCoordinator.reduce_scatterv-621"><span class="linenos">621</span></a>            <span class="k">return</span> <span class="n">output</span>
</span></pre></div>


    

                            </div>
                            <div id="GroupCoordinator.all_gather_into_tensor" class="classattr">
                                        <input id="GroupCoordinator.all_gather_into_tensor-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="def">def</span>
        <span class="name">all_gather_into_tensor</span><span class="signature pdoc-code condensed">(<span class="param"><span class="bp">self</span>, </span><span class="param"><span class="n">output</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span>, </span><span class="param"><span class="nb">input</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span></span><span class="return-annotation">):</span></span>

                <label class="view-source-button" for="GroupCoordinator.all_gather_into_tensor-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#GroupCoordinator.all_gather_into_tensor"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="GroupCoordinator.all_gather_into_tensor-632"><a href="#GroupCoordinator.all_gather_into_tensor-632"><span class="linenos">632</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">all_gather_into_tensor</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">output</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="nb">input</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">):</span>
</span><span id="GroupCoordinator.all_gather_into_tensor-633"><a href="#GroupCoordinator.all_gather_into_tensor-633"><span class="linenos">633</span></a>        <span class="k">if</span> <span class="n">_is_npu</span> <span class="ow">or</span> <span class="ow">not</span> <span class="n">supports_custom_op</span><span class="p">():</span>
</span><span id="GroupCoordinator.all_gather_into_tensor-634"><a href="#GroupCoordinator.all_gather_into_tensor-634"><span class="linenos">634</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">_all_gather_into_tensor</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="nb">input</span><span class="p">)</span>
</span><span id="GroupCoordinator.all_gather_into_tensor-635"><a href="#GroupCoordinator.all_gather_into_tensor-635"><span class="linenos">635</span></a>        <span class="k">else</span><span class="p">:</span>
</span><span id="GroupCoordinator.all_gather_into_tensor-636"><a href="#GroupCoordinator.all_gather_into_tensor-636"><span class="linenos">636</span></a>            <span class="n">torch</span><span class="o">.</span><span class="n">ops</span><span class="o">.</span><span class="n">sglang</span><span class="o">.</span><span class="n">reg_all_gather_into_tensor</span><span class="p">(</span>
</span><span id="GroupCoordinator.all_gather_into_tensor-637"><a href="#GroupCoordinator.all_gather_into_tensor-637"><span class="linenos">637</span></a>                <span class="n">output</span><span class="p">,</span> <span class="nb">input</span><span class="p">,</span> <span class="n">group_name</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">unique_name</span>
</span><span id="GroupCoordinator.all_gather_into_tensor-638"><a href="#GroupCoordinator.all_gather_into_tensor-638"><span class="linenos">638</span></a>            <span class="p">)</span>
</span></pre></div>


    

                            </div>
                            <div id="GroupCoordinator.all_gather" class="classattr">
                                        <input id="GroupCoordinator.all_gather-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="def">def</span>
        <span class="name">all_gather</span><span class="signature pdoc-code multiline">(<span class="param">	<span class="bp">self</span>,</span><span class="param">	<span class="n">input_</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span>,</span><span class="param">	<span class="n">dim</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span>,</span><span class="param">	<span class="n">output_tensor_list</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span></span><span class="return-annotation">) -> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span>:</span></span>

                <label class="view-source-button" for="GroupCoordinator.all_gather-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#GroupCoordinator.all_gather"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="GroupCoordinator.all_gather-640"><a href="#GroupCoordinator.all_gather-640"><span class="linenos">640</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">all_gather</span><span class="p">(</span>
</span><span id="GroupCoordinator.all_gather-641"><a href="#GroupCoordinator.all_gather-641"><span class="linenos">641</span></a>        <span class="bp">self</span><span class="p">,</span>
</span><span id="GroupCoordinator.all_gather-642"><a href="#GroupCoordinator.all_gather-642"><span class="linenos">642</span></a>        <span class="n">input_</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
</span><span id="GroupCoordinator.all_gather-643"><a href="#GroupCoordinator.all_gather-643"><span class="linenos">643</span></a>        <span class="n">dim</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
</span><span id="GroupCoordinator.all_gather-644"><a href="#GroupCoordinator.all_gather-644"><span class="linenos">644</span></a>        <span class="n">output_tensor_list</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="GroupCoordinator.all_gather-645"><a href="#GroupCoordinator.all_gather-645"><span class="linenos">645</span></a>    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
</span><span id="GroupCoordinator.all_gather-646"><a href="#GroupCoordinator.all_gather-646"><span class="linenos">646</span></a>        <span class="n">world_size</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">world_size</span>
</span><span id="GroupCoordinator.all_gather-647"><a href="#GroupCoordinator.all_gather-647"><span class="linenos">647</span></a>        <span class="c1"># Bypass the function if we are using only 1 GPU.</span>
</span><span id="GroupCoordinator.all_gather-648"><a href="#GroupCoordinator.all_gather-648"><span class="linenos">648</span></a>        <span class="k">if</span> <span class="n">world_size</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
</span><span id="GroupCoordinator.all_gather-649"><a href="#GroupCoordinator.all_gather-649"><span class="linenos">649</span></a>            <span class="k">if</span> <span class="n">output_tensor_list</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="GroupCoordinator.all_gather-650"><a href="#GroupCoordinator.all_gather-650"><span class="linenos">650</span></a>                <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span>
</span><span id="GroupCoordinator.all_gather-651"><a href="#GroupCoordinator.all_gather-651"><span class="linenos">651</span></a>                    <span class="s2">&quot;Performing in-place all-gather with a group size of 1. &quot;</span>
</span><span id="GroupCoordinator.all_gather-652"><a href="#GroupCoordinator.all_gather-652"><span class="linenos">652</span></a>                    <span class="s2">&quot;This may be unnecessary; consider bypassing it for better efficiency.&quot;</span>
</span><span id="GroupCoordinator.all_gather-653"><a href="#GroupCoordinator.all_gather-653"><span class="linenos">653</span></a>                <span class="p">)</span>
</span><span id="GroupCoordinator.all_gather-654"><a href="#GroupCoordinator.all_gather-654"><span class="linenos">654</span></a>                <span class="n">output_tensor_list</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">copy_</span><span class="p">(</span><span class="n">input_</span><span class="p">)</span>
</span><span id="GroupCoordinator.all_gather-655"><a href="#GroupCoordinator.all_gather-655"><span class="linenos">655</span></a>                <span class="k">return</span> <span class="kc">None</span>
</span><span id="GroupCoordinator.all_gather-656"><a href="#GroupCoordinator.all_gather-656"><span class="linenos">656</span></a>            <span class="k">else</span><span class="p">:</span>
</span><span id="GroupCoordinator.all_gather-657"><a href="#GroupCoordinator.all_gather-657"><span class="linenos">657</span></a>                <span class="k">return</span> <span class="n">input_</span>
</span><span id="GroupCoordinator.all_gather-658"><a href="#GroupCoordinator.all_gather-658"><span class="linenos">658</span></a>
</span><span id="GroupCoordinator.all_gather-659"><a href="#GroupCoordinator.all_gather-659"><span class="linenos">659</span></a>        <span class="k">if</span> <span class="n">output_tensor_list</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="GroupCoordinator.all_gather-660"><a href="#GroupCoordinator.all_gather-660"><span class="linenos">660</span></a>            <span class="c1"># TODO(ch-wan): support other backends</span>
</span><span id="GroupCoordinator.all_gather-661"><a href="#GroupCoordinator.all_gather-661"><span class="linenos">661</span></a>            <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">distributed</span><span class="o">.</span><span class="n">all_gather</span><span class="p">(</span>
</span><span id="GroupCoordinator.all_gather-662"><a href="#GroupCoordinator.all_gather-662"><span class="linenos">662</span></a>                <span class="n">output_tensor_list</span><span class="p">,</span> <span class="n">input_</span><span class="p">,</span> <span class="n">group</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device_group</span>
</span><span id="GroupCoordinator.all_gather-663"><a href="#GroupCoordinator.all_gather-663"><span class="linenos">663</span></a>            <span class="p">)</span>
</span><span id="GroupCoordinator.all_gather-664"><a href="#GroupCoordinator.all_gather-664"><span class="linenos">664</span></a>
</span><span id="GroupCoordinator.all_gather-665"><a href="#GroupCoordinator.all_gather-665"><span class="linenos">665</span></a>        <span class="k">assert</span> <span class="p">(</span>
</span><span id="GroupCoordinator.all_gather-666"><a href="#GroupCoordinator.all_gather-666"><span class="linenos">666</span></a>            <span class="o">-</span><span class="n">input_</span><span class="o">.</span><span class="n">dim</span><span class="p">()</span> <span class="o">&lt;=</span> <span class="n">dim</span> <span class="o">&lt;</span> <span class="n">input_</span><span class="o">.</span><span class="n">dim</span><span class="p">()</span>
</span><span id="GroupCoordinator.all_gather-667"><a href="#GroupCoordinator.all_gather-667"><span class="linenos">667</span></a>        <span class="p">),</span> <span class="sa">f</span><span class="s2">&quot;Invalid dim (</span><span class="si">{</span><span class="n">dim</span><span class="si">}</span><span class="s2">) for input tensor with shape </span><span class="si">{</span><span class="n">input_</span><span class="o">.</span><span class="n">size</span><span class="p">()</span><span class="si">}</span><span class="s2">&quot;</span>
</span><span id="GroupCoordinator.all_gather-668"><a href="#GroupCoordinator.all_gather-668"><span class="linenos">668</span></a>
</span><span id="GroupCoordinator.all_gather-669"><a href="#GroupCoordinator.all_gather-669"><span class="linenos">669</span></a>        <span class="c1"># For HPUs, use HPU communicator.</span>
</span><span id="GroupCoordinator.all_gather-670"><a href="#GroupCoordinator.all_gather-670"><span class="linenos">670</span></a>        <span class="n">hpu_comm</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">hpu_communicator</span>
</span><span id="GroupCoordinator.all_gather-671"><a href="#GroupCoordinator.all_gather-671"><span class="linenos">671</span></a>        <span class="k">if</span> <span class="n">hpu_comm</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">hpu_comm</span><span class="o">.</span><span class="n">disabled</span><span class="p">:</span>
</span><span id="GroupCoordinator.all_gather-672"><a href="#GroupCoordinator.all_gather-672"><span class="linenos">672</span></a>            <span class="k">return</span> <span class="n">hpu_comm</span><span class="o">.</span><span class="n">all_gather</span><span class="p">(</span><span class="n">input_</span><span class="p">,</span> <span class="n">dim</span><span class="p">)</span>
</span><span id="GroupCoordinator.all_gather-673"><a href="#GroupCoordinator.all_gather-673"><span class="linenos">673</span></a>
</span><span id="GroupCoordinator.all_gather-674"><a href="#GroupCoordinator.all_gather-674"><span class="linenos">674</span></a>        <span class="c1"># For NPUs, use NPU communicator.</span>
</span><span id="GroupCoordinator.all_gather-675"><a href="#GroupCoordinator.all_gather-675"><span class="linenos">675</span></a>        <span class="n">npu_comm</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">npu_communicator</span>
</span><span id="GroupCoordinator.all_gather-676"><a href="#GroupCoordinator.all_gather-676"><span class="linenos">676</span></a>        <span class="k">if</span> <span class="n">npu_comm</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">npu_comm</span><span class="o">.</span><span class="n">disabled</span><span class="p">:</span>
</span><span id="GroupCoordinator.all_gather-677"><a href="#GroupCoordinator.all_gather-677"><span class="linenos">677</span></a>            <span class="k">return</span> <span class="n">npu_comm</span><span class="o">.</span><span class="n">all_gather</span><span class="p">(</span><span class="n">input_</span><span class="p">,</span> <span class="n">dim</span><span class="p">)</span>
</span><span id="GroupCoordinator.all_gather-678"><a href="#GroupCoordinator.all_gather-678"><span class="linenos">678</span></a>
</span><span id="GroupCoordinator.all_gather-679"><a href="#GroupCoordinator.all_gather-679"><span class="linenos">679</span></a>        <span class="k">if</span> <span class="n">dim</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">:</span>
</span><span id="GroupCoordinator.all_gather-680"><a href="#GroupCoordinator.all_gather-680"><span class="linenos">680</span></a>            <span class="c1"># Convert negative dim to positive.</span>
</span><span id="GroupCoordinator.all_gather-681"><a href="#GroupCoordinator.all_gather-681"><span class="linenos">681</span></a>            <span class="n">dim</span> <span class="o">+=</span> <span class="n">input_</span><span class="o">.</span><span class="n">dim</span><span class="p">()</span>
</span><span id="GroupCoordinator.all_gather-682"><a href="#GroupCoordinator.all_gather-682"><span class="linenos">682</span></a>        <span class="n">input_size</span> <span class="o">=</span> <span class="n">input_</span><span class="o">.</span><span class="n">size</span><span class="p">()</span>
</span><span id="GroupCoordinator.all_gather-683"><a href="#GroupCoordinator.all_gather-683"><span class="linenos">683</span></a>        <span class="c1"># NOTE: we have to use concat-style all-gather here,</span>
</span><span id="GroupCoordinator.all_gather-684"><a href="#GroupCoordinator.all_gather-684"><span class="linenos">684</span></a>        <span class="c1"># stack-style all-gather has compatibility issues with</span>
</span><span id="GroupCoordinator.all_gather-685"><a href="#GroupCoordinator.all_gather-685"><span class="linenos">685</span></a>        <span class="c1"># torch.compile . see https://github.com/pytorch/pytorch/issues/138795</span>
</span><span id="GroupCoordinator.all_gather-686"><a href="#GroupCoordinator.all_gather-686"><span class="linenos">686</span></a>        <span class="n">output_size</span> <span class="o">=</span> <span class="p">(</span><span class="n">input_size</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">*</span> <span class="n">world_size</span><span class="p">,)</span> <span class="o">+</span> <span class="n">input_size</span><span class="p">[</span><span class="mi">1</span><span class="p">:]</span>
</span><span id="GroupCoordinator.all_gather-687"><a href="#GroupCoordinator.all_gather-687"><span class="linenos">687</span></a>        <span class="c1"># Allocate output tensor.</span>
</span><span id="GroupCoordinator.all_gather-688"><a href="#GroupCoordinator.all_gather-688"><span class="linenos">688</span></a>        <span class="n">output_tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span>
</span><span id="GroupCoordinator.all_gather-689"><a href="#GroupCoordinator.all_gather-689"><span class="linenos">689</span></a>            <span class="n">output_size</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">input_</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">input_</span><span class="o">.</span><span class="n">device</span>
</span><span id="GroupCoordinator.all_gather-690"><a href="#GroupCoordinator.all_gather-690"><span class="linenos">690</span></a>        <span class="p">)</span>
</span><span id="GroupCoordinator.all_gather-691"><a href="#GroupCoordinator.all_gather-691"><span class="linenos">691</span></a>
</span><span id="GroupCoordinator.all_gather-692"><a href="#GroupCoordinator.all_gather-692"><span class="linenos">692</span></a>        <span class="c1"># All-gather.</span>
</span><span id="GroupCoordinator.all_gather-693"><a href="#GroupCoordinator.all_gather-693"><span class="linenos">693</span></a>        <span class="k">if</span> <span class="n">input_</span><span class="o">.</span><span class="n">is_cpu</span> <span class="ow">and</span> <span class="n">is_shm_available</span><span class="p">(</span>
</span><span id="GroupCoordinator.all_gather-694"><a href="#GroupCoordinator.all_gather-694"><span class="linenos">694</span></a>            <span class="n">input_</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">world_size</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">local_size</span>
</span><span id="GroupCoordinator.all_gather-695"><a href="#GroupCoordinator.all_gather-695"><span class="linenos">695</span></a>        <span class="p">):</span>
</span><span id="GroupCoordinator.all_gather-696"><a href="#GroupCoordinator.all_gather-696"><span class="linenos">696</span></a>            <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">ops</span><span class="o">.</span><span class="n">sgl_kernel</span><span class="o">.</span><span class="n">shm_allgather</span><span class="p">(</span><span class="n">input_</span><span class="p">,</span> <span class="n">dim</span><span class="p">)</span>
</span><span id="GroupCoordinator.all_gather-697"><a href="#GroupCoordinator.all_gather-697"><span class="linenos">697</span></a>
</span><span id="GroupCoordinator.all_gather-698"><a href="#GroupCoordinator.all_gather-698"><span class="linenos">698</span></a>        <span class="k">if</span> <span class="n">input_</span><span class="o">.</span><span class="n">is_cpu</span><span class="p">:</span>
</span><span id="GroupCoordinator.all_gather-699"><a href="#GroupCoordinator.all_gather-699"><span class="linenos">699</span></a>            <span class="n">torch</span><span class="o">.</span><span class="n">distributed</span><span class="o">.</span><span class="n">all_gather_into_tensor</span><span class="p">(</span>
</span><span id="GroupCoordinator.all_gather-700"><a href="#GroupCoordinator.all_gather-700"><span class="linenos">700</span></a>                <span class="n">output_tensor</span><span class="p">,</span> <span class="n">input_</span><span class="p">,</span> <span class="n">group</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device_group</span>
</span><span id="GroupCoordinator.all_gather-701"><a href="#GroupCoordinator.all_gather-701"><span class="linenos">701</span></a>            <span class="p">)</span>
</span><span id="GroupCoordinator.all_gather-702"><a href="#GroupCoordinator.all_gather-702"><span class="linenos">702</span></a>        <span class="k">else</span><span class="p">:</span>
</span><span id="GroupCoordinator.all_gather-703"><a href="#GroupCoordinator.all_gather-703"><span class="linenos">703</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">all_gather_into_tensor</span><span class="p">(</span><span class="n">output_tensor</span><span class="p">,</span> <span class="n">input_</span><span class="p">)</span>
</span><span id="GroupCoordinator.all_gather-704"><a href="#GroupCoordinator.all_gather-704"><span class="linenos">704</span></a>
</span><span id="GroupCoordinator.all_gather-705"><a href="#GroupCoordinator.all_gather-705"><span class="linenos">705</span></a>        <span class="c1"># Reshape</span>
</span><span id="GroupCoordinator.all_gather-706"><a href="#GroupCoordinator.all_gather-706"><span class="linenos">706</span></a>        <span class="n">output_tensor</span> <span class="o">=</span> <span class="n">output_tensor</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="n">world_size</span><span class="p">,)</span> <span class="o">+</span> <span class="n">input_size</span><span class="p">)</span>
</span><span id="GroupCoordinator.all_gather-707"><a href="#GroupCoordinator.all_gather-707"><span class="linenos">707</span></a>        <span class="n">output_tensor</span> <span class="o">=</span> <span class="n">output_tensor</span><span class="o">.</span><span class="n">movedim</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">dim</span><span class="p">)</span>
</span><span id="GroupCoordinator.all_gather-708"><a href="#GroupCoordinator.all_gather-708"><span class="linenos">708</span></a>        <span class="n">output_tensor</span> <span class="o">=</span> <span class="n">output_tensor</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span>
</span><span id="GroupCoordinator.all_gather-709"><a href="#GroupCoordinator.all_gather-709"><span class="linenos">709</span></a>            <span class="n">input_size</span><span class="p">[:</span><span class="n">dim</span><span class="p">]</span> <span class="o">+</span> <span class="p">(</span><span class="n">world_size</span> <span class="o">*</span> <span class="n">input_size</span><span class="p">[</span><span class="n">dim</span><span class="p">],)</span> <span class="o">+</span> <span class="n">input_size</span><span class="p">[</span><span class="n">dim</span> <span class="o">+</span> <span class="mi">1</span> <span class="p">:]</span>
</span><span id="GroupCoordinator.all_gather-710"><a href="#GroupCoordinator.all_gather-710"><span class="linenos">710</span></a>        <span class="p">)</span>
</span><span id="GroupCoordinator.all_gather-711"><a href="#GroupCoordinator.all_gather-711"><span class="linenos">711</span></a>        <span class="k">return</span> <span class="n">output_tensor</span>
</span></pre></div>


    

                            </div>
                            <div id="GroupCoordinator.all_gatherv" class="classattr">
                                        <input id="GroupCoordinator.all_gatherv-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="def">def</span>
        <span class="name">all_gatherv</span><span class="signature pdoc-code multiline">(<span class="param">	<span class="bp">self</span>,</span><span class="param">	<span class="n">input_</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]]</span>,</span><span class="param">	<span class="n">sizes</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="nb">int</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span></span><span class="return-annotation">) -> <span class="n">Union</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]]</span>:</span></span>

                <label class="view-source-button" for="GroupCoordinator.all_gatherv-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#GroupCoordinator.all_gatherv"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="GroupCoordinator.all_gatherv-713"><a href="#GroupCoordinator.all_gatherv-713"><span class="linenos">713</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">all_gatherv</span><span class="p">(</span>
</span><span id="GroupCoordinator.all_gatherv-714"><a href="#GroupCoordinator.all_gatherv-714"><span class="linenos">714</span></a>        <span class="bp">self</span><span class="p">,</span>
</span><span id="GroupCoordinator.all_gatherv-715"><a href="#GroupCoordinator.all_gatherv-715"><span class="linenos">715</span></a>        <span class="n">input_</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]],</span>
</span><span id="GroupCoordinator.all_gatherv-716"><a href="#GroupCoordinator.all_gatherv-716"><span class="linenos">716</span></a>        <span class="n">sizes</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="nb">int</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="GroupCoordinator.all_gatherv-717"><a href="#GroupCoordinator.all_gatherv-717"><span class="linenos">717</span></a>    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Union</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]]:</span>
</span><span id="GroupCoordinator.all_gatherv-718"><a href="#GroupCoordinator.all_gatherv-718"><span class="linenos">718</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="GroupCoordinator.all_gatherv-719"><a href="#GroupCoordinator.all_gatherv-719"><span class="linenos">719</span></a><span class="sd">        Supports varying sizes per rank and input tensor list.</span>
</span><span id="GroupCoordinator.all_gatherv-720"><a href="#GroupCoordinator.all_gatherv-720"><span class="linenos">720</span></a><span class="sd">        `sizes`: a list of len(world_size) with the number of items per rank to gather.</span>
</span><span id="GroupCoordinator.all_gatherv-721"><a href="#GroupCoordinator.all_gatherv-721"><span class="linenos">721</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="GroupCoordinator.all_gatherv-722"><a href="#GroupCoordinator.all_gatherv-722"><span class="linenos">722</span></a>        <span class="n">world_size</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">world_size</span>
</span><span id="GroupCoordinator.all_gatherv-723"><a href="#GroupCoordinator.all_gatherv-723"><span class="linenos">723</span></a>        <span class="n">pynccl_comm</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">pynccl_comm</span>
</span><span id="GroupCoordinator.all_gatherv-724"><a href="#GroupCoordinator.all_gatherv-724"><span class="linenos">724</span></a>
</span><span id="GroupCoordinator.all_gatherv-725"><a href="#GroupCoordinator.all_gatherv-725"><span class="linenos">725</span></a>        <span class="k">with</span> <span class="n">pynccl_comm</span><span class="o">.</span><span class="n">change_state</span><span class="p">(</span><span class="n">enable</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">stream</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">current_stream</span><span class="p">()):</span>
</span><span id="GroupCoordinator.all_gatherv-726"><a href="#GroupCoordinator.all_gatherv-726"><span class="linenos">726</span></a>            <span class="k">assert</span> <span class="p">(</span>
</span><span id="GroupCoordinator.all_gatherv-727"><a href="#GroupCoordinator.all_gatherv-727"><span class="linenos">727</span></a>                <span class="n">pynccl_comm</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">pynccl_comm</span><span class="o">.</span><span class="n">disabled</span>
</span><span id="GroupCoordinator.all_gatherv-728"><a href="#GroupCoordinator.all_gatherv-728"><span class="linenos">728</span></a>            <span class="p">),</span> <span class="s2">&quot;pynccl is required for all_gatherv&quot;</span>
</span><span id="GroupCoordinator.all_gatherv-729"><a href="#GroupCoordinator.all_gatherv-729"><span class="linenos">729</span></a>
</span><span id="GroupCoordinator.all_gatherv-730"><a href="#GroupCoordinator.all_gatherv-730"><span class="linenos">730</span></a>            <span class="k">def</span><span class="w"> </span><span class="nf">_all_gather_single</span><span class="p">(</span>
</span><span id="GroupCoordinator.all_gatherv-731"><a href="#GroupCoordinator.all_gatherv-731"><span class="linenos">731</span></a>                <span class="n">input_</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">sizes</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="nb">int</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span>
</span><span id="GroupCoordinator.all_gatherv-732"><a href="#GroupCoordinator.all_gatherv-732"><span class="linenos">732</span></a>            <span class="p">):</span>
</span><span id="GroupCoordinator.all_gatherv-733"><a href="#GroupCoordinator.all_gatherv-733"><span class="linenos">733</span></a>                <span class="n">input_size</span> <span class="o">=</span> <span class="n">input_</span><span class="o">.</span><span class="n">size</span><span class="p">()</span>
</span><span id="GroupCoordinator.all_gatherv-734"><a href="#GroupCoordinator.all_gatherv-734"><span class="linenos">734</span></a>                <span class="k">if</span> <span class="n">sizes</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="GroupCoordinator.all_gatherv-735"><a href="#GroupCoordinator.all_gatherv-735"><span class="linenos">735</span></a>                    <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">sizes</span><span class="p">)</span> <span class="o">==</span> <span class="n">world_size</span>
</span><span id="GroupCoordinator.all_gatherv-736"><a href="#GroupCoordinator.all_gatherv-736"><span class="linenos">736</span></a>                    <span class="k">assert</span> <span class="n">input_</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">==</span> <span class="n">sizes</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">rank_in_group</span><span class="p">]</span>
</span><span id="GroupCoordinator.all_gatherv-737"><a href="#GroupCoordinator.all_gatherv-737"><span class="linenos">737</span></a>                    <span class="n">output_size</span> <span class="o">=</span> <span class="p">(</span><span class="nb">sum</span><span class="p">(</span><span class="n">sizes</span><span class="p">),)</span> <span class="o">+</span> <span class="n">input_size</span><span class="p">[</span><span class="mi">1</span><span class="p">:]</span>
</span><span id="GroupCoordinator.all_gatherv-738"><a href="#GroupCoordinator.all_gatherv-738"><span class="linenos">738</span></a>                    <span class="c1"># &#39;sizes&#39; is not needed if all inputs in the same group have the same shape</span>
</span><span id="GroupCoordinator.all_gatherv-739"><a href="#GroupCoordinator.all_gatherv-739"><span class="linenos">739</span></a>                    <span class="k">if</span> <span class="nb">all</span><span class="p">(</span><span class="n">s</span> <span class="o">==</span> <span class="n">sizes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="n">sizes</span><span class="p">):</span>
</span><span id="GroupCoordinator.all_gatherv-740"><a href="#GroupCoordinator.all_gatherv-740"><span class="linenos">740</span></a>                        <span class="n">sizes</span> <span class="o">=</span> <span class="kc">None</span>
</span><span id="GroupCoordinator.all_gatherv-741"><a href="#GroupCoordinator.all_gatherv-741"><span class="linenos">741</span></a>                <span class="k">else</span><span class="p">:</span>
</span><span id="GroupCoordinator.all_gatherv-742"><a href="#GroupCoordinator.all_gatherv-742"><span class="linenos">742</span></a>                    <span class="n">output_size</span> <span class="o">=</span> <span class="p">(</span><span class="n">input_size</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">*</span> <span class="n">world_size</span><span class="p">,)</span> <span class="o">+</span> <span class="n">input_size</span><span class="p">[</span><span class="mi">1</span><span class="p">:]</span>
</span><span id="GroupCoordinator.all_gatherv-743"><a href="#GroupCoordinator.all_gatherv-743"><span class="linenos">743</span></a>                <span class="c1"># Allocate output tensor.</span>
</span><span id="GroupCoordinator.all_gatherv-744"><a href="#GroupCoordinator.all_gatherv-744"><span class="linenos">744</span></a>                <span class="n">output_tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span>
</span><span id="GroupCoordinator.all_gatherv-745"><a href="#GroupCoordinator.all_gatherv-745"><span class="linenos">745</span></a>                    <span class="n">output_size</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">input_</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">input_</span><span class="o">.</span><span class="n">device</span>
</span><span id="GroupCoordinator.all_gatherv-746"><a href="#GroupCoordinator.all_gatherv-746"><span class="linenos">746</span></a>                <span class="p">)</span>
</span><span id="GroupCoordinator.all_gatherv-747"><a href="#GroupCoordinator.all_gatherv-747"><span class="linenos">747</span></a>                <span class="n">pynccl_comm</span><span class="o">.</span><span class="n">all_gather</span><span class="p">(</span><span class="n">output_tensor</span><span class="p">,</span> <span class="n">input_</span><span class="p">,</span> <span class="n">sizes</span><span class="o">=</span><span class="n">sizes</span><span class="p">)</span>
</span><span id="GroupCoordinator.all_gatherv-748"><a href="#GroupCoordinator.all_gatherv-748"><span class="linenos">748</span></a>                <span class="k">return</span> <span class="n">output_tensor</span>
</span><span id="GroupCoordinator.all_gatherv-749"><a href="#GroupCoordinator.all_gatherv-749"><span class="linenos">749</span></a>
</span><span id="GroupCoordinator.all_gatherv-750"><a href="#GroupCoordinator.all_gatherv-750"><span class="linenos">750</span></a>            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">input_</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">):</span>
</span><span id="GroupCoordinator.all_gatherv-751"><a href="#GroupCoordinator.all_gatherv-751"><span class="linenos">751</span></a>                <span class="k">return</span> <span class="n">_all_gather_single</span><span class="p">(</span><span class="n">input_</span><span class="p">,</span> <span class="n">sizes</span><span class="p">)</span>
</span><span id="GroupCoordinator.all_gatherv-752"><a href="#GroupCoordinator.all_gatherv-752"><span class="linenos">752</span></a>
</span><span id="GroupCoordinator.all_gatherv-753"><a href="#GroupCoordinator.all_gatherv-753"><span class="linenos">753</span></a>            <span class="n">output_list</span> <span class="o">=</span> <span class="p">[]</span>
</span><span id="GroupCoordinator.all_gatherv-754"><a href="#GroupCoordinator.all_gatherv-754"><span class="linenos">754</span></a>            <span class="n">pynccl_comm</span><span class="o">.</span><span class="n">group_start</span><span class="p">()</span>
</span><span id="GroupCoordinator.all_gatherv-755"><a href="#GroupCoordinator.all_gatherv-755"><span class="linenos">755</span></a>            <span class="k">for</span> <span class="n">inp</span> <span class="ow">in</span> <span class="n">input_</span><span class="p">:</span>
</span><span id="GroupCoordinator.all_gatherv-756"><a href="#GroupCoordinator.all_gatherv-756"><span class="linenos">756</span></a>                <span class="n">output_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">_all_gather_single</span><span class="p">(</span><span class="n">inp</span><span class="p">,</span> <span class="n">sizes</span><span class="o">=</span><span class="n">sizes</span><span class="p">))</span>
</span><span id="GroupCoordinator.all_gatherv-757"><a href="#GroupCoordinator.all_gatherv-757"><span class="linenos">757</span></a>            <span class="n">pynccl_comm</span><span class="o">.</span><span class="n">group_end</span><span class="p">()</span>
</span><span id="GroupCoordinator.all_gatherv-758"><a href="#GroupCoordinator.all_gatherv-758"><span class="linenos">758</span></a>
</span><span id="GroupCoordinator.all_gatherv-759"><a href="#GroupCoordinator.all_gatherv-759"><span class="linenos">759</span></a>            <span class="k">return</span> <span class="n">output_list</span>
</span></pre></div>


            <div class="docstring"><p>Supports varying sizes per rank and input tensor list.
<code>sizes</code>: a list of len(world_size) with the number of items per rank to gather.</p>
</div>


                            </div>
                            <div id="GroupCoordinator.gather" class="classattr">
                                        <input id="GroupCoordinator.gather-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="def">def</span>
        <span class="name">gather</span><span class="signature pdoc-code multiline">(<span class="param">	<span class="bp">self</span>,</span><span class="param">	<span class="n">input_</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span>,</span><span class="param">	<span class="n">dst</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span>,</span><span class="param">	<span class="n">dim</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span></span><span class="return-annotation">) -> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span>:</span></span>

                <label class="view-source-button" for="GroupCoordinator.gather-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#GroupCoordinator.gather"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="GroupCoordinator.gather-761"><a href="#GroupCoordinator.gather-761"><span class="linenos">761</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">gather</span><span class="p">(</span>
</span><span id="GroupCoordinator.gather-762"><a href="#GroupCoordinator.gather-762"><span class="linenos">762</span></a>        <span class="bp">self</span><span class="p">,</span> <span class="n">input_</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">dst</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span> <span class="n">dim</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span>
</span><span id="GroupCoordinator.gather-763"><a href="#GroupCoordinator.gather-763"><span class="linenos">763</span></a>    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]:</span>
</span><span id="GroupCoordinator.gather-764"><a href="#GroupCoordinator.gather-764"><span class="linenos">764</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="GroupCoordinator.gather-765"><a href="#GroupCoordinator.gather-765"><span class="linenos">765</span></a><span class="sd">        NOTE: We assume that the input tensor is on the same device across</span>
</span><span id="GroupCoordinator.gather-766"><a href="#GroupCoordinator.gather-766"><span class="linenos">766</span></a><span class="sd">        all the ranks.</span>
</span><span id="GroupCoordinator.gather-767"><a href="#GroupCoordinator.gather-767"><span class="linenos">767</span></a><span class="sd">        NOTE: `dst` is the local rank of the destination rank.</span>
</span><span id="GroupCoordinator.gather-768"><a href="#GroupCoordinator.gather-768"><span class="linenos">768</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="GroupCoordinator.gather-769"><a href="#GroupCoordinator.gather-769"><span class="linenos">769</span></a>        <span class="n">world_size</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">world_size</span>
</span><span id="GroupCoordinator.gather-770"><a href="#GroupCoordinator.gather-770"><span class="linenos">770</span></a>        <span class="c1"># Bypass the function if we are using only 1 GPU.</span>
</span><span id="GroupCoordinator.gather-771"><a href="#GroupCoordinator.gather-771"><span class="linenos">771</span></a>        <span class="k">if</span> <span class="n">world_size</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
</span><span id="GroupCoordinator.gather-772"><a href="#GroupCoordinator.gather-772"><span class="linenos">772</span></a>            <span class="k">return</span> <span class="n">input_</span>
</span><span id="GroupCoordinator.gather-773"><a href="#GroupCoordinator.gather-773"><span class="linenos">773</span></a>        <span class="k">assert</span> <span class="p">(</span>
</span><span id="GroupCoordinator.gather-774"><a href="#GroupCoordinator.gather-774"><span class="linenos">774</span></a>            <span class="o">-</span><span class="n">input_</span><span class="o">.</span><span class="n">dim</span><span class="p">()</span> <span class="o">&lt;=</span> <span class="n">dim</span> <span class="o">&lt;</span> <span class="n">input_</span><span class="o">.</span><span class="n">dim</span><span class="p">()</span>
</span><span id="GroupCoordinator.gather-775"><a href="#GroupCoordinator.gather-775"><span class="linenos">775</span></a>        <span class="p">),</span> <span class="sa">f</span><span class="s2">&quot;Invalid dim (</span><span class="si">{</span><span class="n">dim</span><span class="si">}</span><span class="s2">) for input tensor with shape </span><span class="si">{</span><span class="n">input_</span><span class="o">.</span><span class="n">size</span><span class="p">()</span><span class="si">}</span><span class="s2">&quot;</span>
</span><span id="GroupCoordinator.gather-776"><a href="#GroupCoordinator.gather-776"><span class="linenos">776</span></a>        <span class="k">if</span> <span class="n">dim</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">:</span>
</span><span id="GroupCoordinator.gather-777"><a href="#GroupCoordinator.gather-777"><span class="linenos">777</span></a>            <span class="c1"># Convert negative dim to positive.</span>
</span><span id="GroupCoordinator.gather-778"><a href="#GroupCoordinator.gather-778"><span class="linenos">778</span></a>            <span class="n">dim</span> <span class="o">+=</span> <span class="n">input_</span><span class="o">.</span><span class="n">dim</span><span class="p">()</span>
</span><span id="GroupCoordinator.gather-779"><a href="#GroupCoordinator.gather-779"><span class="linenos">779</span></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">xpu_communicator</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">xpu_communicator</span><span class="o">.</span><span class="n">disabled</span><span class="p">:</span>
</span><span id="GroupCoordinator.gather-780"><a href="#GroupCoordinator.gather-780"><span class="linenos">780</span></a>            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">xpu_communicator</span><span class="o">.</span><span class="n">gather</span><span class="p">(</span><span class="n">input_</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">rank_in_group</span><span class="p">,</span> <span class="n">dst</span><span class="p">,</span> <span class="n">dim</span><span class="p">)</span>
</span><span id="GroupCoordinator.gather-781"><a href="#GroupCoordinator.gather-781"><span class="linenos">781</span></a>        <span class="c1"># Allocate output tensor.</span>
</span><span id="GroupCoordinator.gather-782"><a href="#GroupCoordinator.gather-782"><span class="linenos">782</span></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">rank_in_group</span> <span class="o">==</span> <span class="n">dst</span><span class="p">:</span>
</span><span id="GroupCoordinator.gather-783"><a href="#GroupCoordinator.gather-783"><span class="linenos">783</span></a>            <span class="n">gather_list</span> <span class="o">=</span> <span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">empty_like</span><span class="p">(</span><span class="n">input_</span><span class="p">)</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">world_size</span><span class="p">)]</span>
</span><span id="GroupCoordinator.gather-784"><a href="#GroupCoordinator.gather-784"><span class="linenos">784</span></a>        <span class="k">else</span><span class="p">:</span>
</span><span id="GroupCoordinator.gather-785"><a href="#GroupCoordinator.gather-785"><span class="linenos">785</span></a>            <span class="n">gather_list</span> <span class="o">=</span> <span class="kc">None</span>
</span><span id="GroupCoordinator.gather-786"><a href="#GroupCoordinator.gather-786"><span class="linenos">786</span></a>        <span class="c1"># Gather.</span>
</span><span id="GroupCoordinator.gather-787"><a href="#GroupCoordinator.gather-787"><span class="linenos">787</span></a>        <span class="n">torch</span><span class="o">.</span><span class="n">distributed</span><span class="o">.</span><span class="n">gather</span><span class="p">(</span>
</span><span id="GroupCoordinator.gather-788"><a href="#GroupCoordinator.gather-788"><span class="linenos">788</span></a>            <span class="n">input_</span><span class="p">,</span> <span class="n">gather_list</span><span class="p">,</span> <span class="n">dst</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">ranks</span><span class="p">[</span><span class="n">dst</span><span class="p">],</span> <span class="n">group</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device_group</span>
</span><span id="GroupCoordinator.gather-789"><a href="#GroupCoordinator.gather-789"><span class="linenos">789</span></a>        <span class="p">)</span>
</span><span id="GroupCoordinator.gather-790"><a href="#GroupCoordinator.gather-790"><span class="linenos">790</span></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">rank_in_group</span> <span class="o">==</span> <span class="n">dst</span><span class="p">:</span>
</span><span id="GroupCoordinator.gather-791"><a href="#GroupCoordinator.gather-791"><span class="linenos">791</span></a>            <span class="n">output_tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span><span class="n">gather_list</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="n">dim</span><span class="p">)</span>
</span><span id="GroupCoordinator.gather-792"><a href="#GroupCoordinator.gather-792"><span class="linenos">792</span></a>        <span class="k">else</span><span class="p">:</span>
</span><span id="GroupCoordinator.gather-793"><a href="#GroupCoordinator.gather-793"><span class="linenos">793</span></a>            <span class="n">output_tensor</span> <span class="o">=</span> <span class="kc">None</span>
</span><span id="GroupCoordinator.gather-794"><a href="#GroupCoordinator.gather-794"><span class="linenos">794</span></a>        <span class="k">return</span> <span class="n">output_tensor</span>
</span></pre></div>


            <div class="docstring"><p>NOTE: We assume that the input tensor is on the same device across
all the ranks.
NOTE: <code>dst</code> is the local rank of the destination rank.</p>
</div>


                            </div>
                            <div id="GroupCoordinator.broadcast" class="classattr">
                                        <input id="GroupCoordinator.broadcast-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="def">def</span>
        <span class="name">broadcast</span><span class="signature pdoc-code condensed">(<span class="param"><span class="bp">self</span>, </span><span class="param"><span class="n">input_</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span>, </span><span class="param"><span class="n">src</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span></span><span class="return-annotation">):</span></span>

                <label class="view-source-button" for="GroupCoordinator.broadcast-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#GroupCoordinator.broadcast"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="GroupCoordinator.broadcast-796"><a href="#GroupCoordinator.broadcast-796"><span class="linenos">796</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">broadcast</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">src</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span><span class="p">):</span>
</span><span id="GroupCoordinator.broadcast-797"><a href="#GroupCoordinator.broadcast-797"><span class="linenos">797</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;Broadcast the input tensor.</span>
</span><span id="GroupCoordinator.broadcast-798"><a href="#GroupCoordinator.broadcast-798"><span class="linenos">798</span></a><span class="sd">        NOTE: `src` is the local rank of the source rank.</span>
</span><span id="GroupCoordinator.broadcast-799"><a href="#GroupCoordinator.broadcast-799"><span class="linenos">799</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="GroupCoordinator.broadcast-800"><a href="#GroupCoordinator.broadcast-800"><span class="linenos">800</span></a>        <span class="k">assert</span> <span class="n">src</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">world_size</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;Invalid src rank (</span><span class="si">{</span><span class="n">src</span><span class="si">}</span><span class="s2">)&quot;</span>
</span><span id="GroupCoordinator.broadcast-801"><a href="#GroupCoordinator.broadcast-801"><span class="linenos">801</span></a>
</span><span id="GroupCoordinator.broadcast-802"><a href="#GroupCoordinator.broadcast-802"><span class="linenos">802</span></a>        <span class="c1"># Bypass the function if we are using only 1 GPU.</span>
</span><span id="GroupCoordinator.broadcast-803"><a href="#GroupCoordinator.broadcast-803"><span class="linenos">803</span></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">world_size</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
</span><span id="GroupCoordinator.broadcast-804"><a href="#GroupCoordinator.broadcast-804"><span class="linenos">804</span></a>            <span class="k">return</span> <span class="n">input_</span>
</span><span id="GroupCoordinator.broadcast-805"><a href="#GroupCoordinator.broadcast-805"><span class="linenos">805</span></a>        <span class="c1"># Broadcast.</span>
</span><span id="GroupCoordinator.broadcast-806"><a href="#GroupCoordinator.broadcast-806"><span class="linenos">806</span></a>        <span class="n">torch</span><span class="o">.</span><span class="n">distributed</span><span class="o">.</span><span class="n">broadcast</span><span class="p">(</span>
</span><span id="GroupCoordinator.broadcast-807"><a href="#GroupCoordinator.broadcast-807"><span class="linenos">807</span></a>            <span class="n">input_</span><span class="p">,</span> <span class="n">src</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">ranks</span><span class="p">[</span><span class="n">src</span><span class="p">],</span> <span class="n">group</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device_group</span>
</span><span id="GroupCoordinator.broadcast-808"><a href="#GroupCoordinator.broadcast-808"><span class="linenos">808</span></a>        <span class="p">)</span>
</span><span id="GroupCoordinator.broadcast-809"><a href="#GroupCoordinator.broadcast-809"><span class="linenos">809</span></a>        <span class="k">return</span> <span class="n">input_</span>
</span></pre></div>


            <div class="docstring"><p>Broadcast the input tensor.
NOTE: <code>src</code> is the local rank of the source rank.</p>
</div>


                            </div>
                            <div id="GroupCoordinator.broadcast_object" class="classattr">
                                        <input id="GroupCoordinator.broadcast_object-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="def">def</span>
        <span class="name">broadcast_object</span><span class="signature pdoc-code condensed">(<span class="param"><span class="bp">self</span>, </span><span class="param"><span class="n">obj</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Any</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>, </span><span class="param"><span class="n">src</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span></span><span class="return-annotation">):</span></span>

                <label class="view-source-button" for="GroupCoordinator.broadcast_object-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#GroupCoordinator.broadcast_object"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="GroupCoordinator.broadcast_object-811"><a href="#GroupCoordinator.broadcast_object-811"><span class="linenos">811</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">broadcast_object</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">obj</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Any</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="n">src</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span><span class="p">):</span>
</span><span id="GroupCoordinator.broadcast_object-812"><a href="#GroupCoordinator.broadcast_object-812"><span class="linenos">812</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;Broadcast the input object.</span>
</span><span id="GroupCoordinator.broadcast_object-813"><a href="#GroupCoordinator.broadcast_object-813"><span class="linenos">813</span></a><span class="sd">        NOTE: `src` is the local rank of the source rank.</span>
</span><span id="GroupCoordinator.broadcast_object-814"><a href="#GroupCoordinator.broadcast_object-814"><span class="linenos">814</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="GroupCoordinator.broadcast_object-815"><a href="#GroupCoordinator.broadcast_object-815"><span class="linenos">815</span></a>        <span class="k">assert</span> <span class="n">src</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">world_size</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;Invalid src rank (</span><span class="si">{</span><span class="n">src</span><span class="si">}</span><span class="s2">)&quot;</span>
</span><span id="GroupCoordinator.broadcast_object-816"><a href="#GroupCoordinator.broadcast_object-816"><span class="linenos">816</span></a>
</span><span id="GroupCoordinator.broadcast_object-817"><a href="#GroupCoordinator.broadcast_object-817"><span class="linenos">817</span></a>        <span class="c1"># Bypass the function if we are using only 1 GPU.</span>
</span><span id="GroupCoordinator.broadcast_object-818"><a href="#GroupCoordinator.broadcast_object-818"><span class="linenos">818</span></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">world_size</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
</span><span id="GroupCoordinator.broadcast_object-819"><a href="#GroupCoordinator.broadcast_object-819"><span class="linenos">819</span></a>            <span class="k">return</span> <span class="n">obj</span>
</span><span id="GroupCoordinator.broadcast_object-820"><a href="#GroupCoordinator.broadcast_object-820"><span class="linenos">820</span></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">mq_broadcaster</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="GroupCoordinator.broadcast_object-821"><a href="#GroupCoordinator.broadcast_object-821"><span class="linenos">821</span></a>            <span class="k">assert</span> <span class="n">src</span> <span class="o">==</span> <span class="mi">0</span><span class="p">,</span> <span class="s2">&quot;Message queue broadcaster only supports src=0&quot;</span>
</span><span id="GroupCoordinator.broadcast_object-822"><a href="#GroupCoordinator.broadcast_object-822"><span class="linenos">822</span></a>            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">mq_broadcaster</span><span class="o">.</span><span class="n">broadcast_object</span><span class="p">(</span><span class="n">obj</span><span class="p">)</span>
</span><span id="GroupCoordinator.broadcast_object-823"><a href="#GroupCoordinator.broadcast_object-823"><span class="linenos">823</span></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">rank_in_group</span> <span class="o">==</span> <span class="n">src</span><span class="p">:</span>
</span><span id="GroupCoordinator.broadcast_object-824"><a href="#GroupCoordinator.broadcast_object-824"><span class="linenos">824</span></a>            <span class="n">torch</span><span class="o">.</span><span class="n">distributed</span><span class="o">.</span><span class="n">broadcast_object_list</span><span class="p">(</span>
</span><span id="GroupCoordinator.broadcast_object-825"><a href="#GroupCoordinator.broadcast_object-825"><span class="linenos">825</span></a>                <span class="p">[</span><span class="n">obj</span><span class="p">],</span> <span class="n">src</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">ranks</span><span class="p">[</span><span class="n">src</span><span class="p">],</span> <span class="n">group</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">cpu_group</span>
</span><span id="GroupCoordinator.broadcast_object-826"><a href="#GroupCoordinator.broadcast_object-826"><span class="linenos">826</span></a>            <span class="p">)</span>
</span><span id="GroupCoordinator.broadcast_object-827"><a href="#GroupCoordinator.broadcast_object-827"><span class="linenos">827</span></a>            <span class="k">return</span> <span class="n">obj</span>
</span><span id="GroupCoordinator.broadcast_object-828"><a href="#GroupCoordinator.broadcast_object-828"><span class="linenos">828</span></a>        <span class="k">else</span><span class="p">:</span>
</span><span id="GroupCoordinator.broadcast_object-829"><a href="#GroupCoordinator.broadcast_object-829"><span class="linenos">829</span></a>            <span class="n">recv</span> <span class="o">=</span> <span class="p">[</span><span class="kc">None</span><span class="p">]</span>
</span><span id="GroupCoordinator.broadcast_object-830"><a href="#GroupCoordinator.broadcast_object-830"><span class="linenos">830</span></a>            <span class="n">torch</span><span class="o">.</span><span class="n">distributed</span><span class="o">.</span><span class="n">broadcast_object_list</span><span class="p">(</span>
</span><span id="GroupCoordinator.broadcast_object-831"><a href="#GroupCoordinator.broadcast_object-831"><span class="linenos">831</span></a>                <span class="n">recv</span><span class="p">,</span> <span class="n">src</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">ranks</span><span class="p">[</span><span class="n">src</span><span class="p">],</span> <span class="n">group</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">cpu_group</span>
</span><span id="GroupCoordinator.broadcast_object-832"><a href="#GroupCoordinator.broadcast_object-832"><span class="linenos">832</span></a>            <span class="p">)</span>
</span><span id="GroupCoordinator.broadcast_object-833"><a href="#GroupCoordinator.broadcast_object-833"><span class="linenos">833</span></a>            <span class="k">return</span> <span class="n">recv</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
</span></pre></div>


            <div class="docstring"><p>Broadcast the input object.
NOTE: <code>src</code> is the local rank of the source rank.</p>
</div>


                            </div>
                            <div id="GroupCoordinator.broadcast_object_list" class="classattr">
                                        <input id="GroupCoordinator.broadcast_object_list-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="def">def</span>
        <span class="name">broadcast_object_list</span><span class="signature pdoc-code multiline">(<span class="param">	<span class="bp">self</span>,</span><span class="param">	<span class="n">obj_list</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">Any</span><span class="p">]</span>,</span><span class="param">	<span class="n">src</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span>,</span><span class="param">	<span class="n">group</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">distributed</span><span class="o">.</span><span class="n">distributed_c10d</span><span class="o">.</span><span class="n">ProcessGroup</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span></span><span class="return-annotation">):</span></span>

                <label class="view-source-button" for="GroupCoordinator.broadcast_object_list-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#GroupCoordinator.broadcast_object_list"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="GroupCoordinator.broadcast_object_list-835"><a href="#GroupCoordinator.broadcast_object_list-835"><span class="linenos">835</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">broadcast_object_list</span><span class="p">(</span>
</span><span id="GroupCoordinator.broadcast_object_list-836"><a href="#GroupCoordinator.broadcast_object_list-836"><span class="linenos">836</span></a>        <span class="bp">self</span><span class="p">,</span> <span class="n">obj_list</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">Any</span><span class="p">],</span> <span class="n">src</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span> <span class="n">group</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">ProcessGroup</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
</span><span id="GroupCoordinator.broadcast_object_list-837"><a href="#GroupCoordinator.broadcast_object_list-837"><span class="linenos">837</span></a>    <span class="p">):</span>
</span><span id="GroupCoordinator.broadcast_object_list-838"><a href="#GroupCoordinator.broadcast_object_list-838"><span class="linenos">838</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;Broadcast the input object list.</span>
</span><span id="GroupCoordinator.broadcast_object_list-839"><a href="#GroupCoordinator.broadcast_object_list-839"><span class="linenos">839</span></a><span class="sd">        NOTE: `src` is the local rank of the source rank.</span>
</span><span id="GroupCoordinator.broadcast_object_list-840"><a href="#GroupCoordinator.broadcast_object_list-840"><span class="linenos">840</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="GroupCoordinator.broadcast_object_list-841"><a href="#GroupCoordinator.broadcast_object_list-841"><span class="linenos">841</span></a>        <span class="k">assert</span> <span class="n">src</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">world_size</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;Invalid src rank (</span><span class="si">{</span><span class="n">src</span><span class="si">}</span><span class="s2">)&quot;</span>
</span><span id="GroupCoordinator.broadcast_object_list-842"><a href="#GroupCoordinator.broadcast_object_list-842"><span class="linenos">842</span></a>
</span><span id="GroupCoordinator.broadcast_object_list-843"><a href="#GroupCoordinator.broadcast_object_list-843"><span class="linenos">843</span></a>        <span class="c1"># Bypass the function if we are using only 1 GPU.</span>
</span><span id="GroupCoordinator.broadcast_object_list-844"><a href="#GroupCoordinator.broadcast_object_list-844"><span class="linenos">844</span></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">world_size</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
</span><span id="GroupCoordinator.broadcast_object_list-845"><a href="#GroupCoordinator.broadcast_object_list-845"><span class="linenos">845</span></a>            <span class="k">return</span> <span class="n">obj_list</span>
</span><span id="GroupCoordinator.broadcast_object_list-846"><a href="#GroupCoordinator.broadcast_object_list-846"><span class="linenos">846</span></a>        <span class="c1"># Broadcast.</span>
</span><span id="GroupCoordinator.broadcast_object_list-847"><a href="#GroupCoordinator.broadcast_object_list-847"><span class="linenos">847</span></a>        <span class="n">torch</span><span class="o">.</span><span class="n">distributed</span><span class="o">.</span><span class="n">broadcast_object_list</span><span class="p">(</span>
</span><span id="GroupCoordinator.broadcast_object_list-848"><a href="#GroupCoordinator.broadcast_object_list-848"><span class="linenos">848</span></a>            <span class="n">obj_list</span><span class="p">,</span> <span class="n">src</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">ranks</span><span class="p">[</span><span class="n">src</span><span class="p">],</span> <span class="n">group</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device_group</span>
</span><span id="GroupCoordinator.broadcast_object_list-849"><a href="#GroupCoordinator.broadcast_object_list-849"><span class="linenos">849</span></a>        <span class="p">)</span>
</span><span id="GroupCoordinator.broadcast_object_list-850"><a href="#GroupCoordinator.broadcast_object_list-850"><span class="linenos">850</span></a>        <span class="k">return</span> <span class="n">obj_list</span>
</span></pre></div>


            <div class="docstring"><p>Broadcast the input object list.
NOTE: <code>src</code> is the local rank of the source rank.</p>
</div>


                            </div>
                            <div id="GroupCoordinator.send_object" class="classattr">
                                        <input id="GroupCoordinator.send_object-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="def">def</span>
        <span class="name">send_object</span><span class="signature pdoc-code condensed">(<span class="param"><span class="bp">self</span>, </span><span class="param"><span class="n">obj</span><span class="p">:</span> <span class="n">Any</span>, </span><span class="param"><span class="n">dst</span><span class="p">:</span> <span class="nb">int</span></span><span class="return-annotation">) -> <span class="kc">None</span>:</span></span>

                <label class="view-source-button" for="GroupCoordinator.send_object-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#GroupCoordinator.send_object"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="GroupCoordinator.send_object-852"><a href="#GroupCoordinator.send_object-852"><span class="linenos">852</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">send_object</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">obj</span><span class="p">:</span> <span class="n">Any</span><span class="p">,</span> <span class="n">dst</span><span class="p">:</span> <span class="nb">int</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="GroupCoordinator.send_object-853"><a href="#GroupCoordinator.send_object-853"><span class="linenos">853</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;Send the input object list to the destination rank.&quot;&quot;&quot;</span>
</span><span id="GroupCoordinator.send_object-854"><a href="#GroupCoordinator.send_object-854"><span class="linenos">854</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;NOTE: `dst` is the local rank of the destination rank.&quot;&quot;&quot;</span>
</span><span id="GroupCoordinator.send_object-855"><a href="#GroupCoordinator.send_object-855"><span class="linenos">855</span></a>
</span><span id="GroupCoordinator.send_object-856"><a href="#GroupCoordinator.send_object-856"><span class="linenos">856</span></a>        <span class="k">assert</span> <span class="n">dst</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">world_size</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;Invalid dst rank (</span><span class="si">{</span><span class="n">dst</span><span class="si">}</span><span class="s2">)&quot;</span>
</span><span id="GroupCoordinator.send_object-857"><a href="#GroupCoordinator.send_object-857"><span class="linenos">857</span></a>
</span><span id="GroupCoordinator.send_object-858"><a href="#GroupCoordinator.send_object-858"><span class="linenos">858</span></a>        <span class="k">assert</span> <span class="n">dst</span> <span class="o">!=</span> <span class="bp">self</span><span class="o">.</span><span class="n">rank_in_group</span><span class="p">,</span> <span class="p">(</span>
</span><span id="GroupCoordinator.send_object-859"><a href="#GroupCoordinator.send_object-859"><span class="linenos">859</span></a>            <span class="s2">&quot;Invalid destination rank. Destination rank is the same &quot;</span>
</span><span id="GroupCoordinator.send_object-860"><a href="#GroupCoordinator.send_object-860"><span class="linenos">860</span></a>            <span class="s2">&quot;as the current rank.&quot;</span>
</span><span id="GroupCoordinator.send_object-861"><a href="#GroupCoordinator.send_object-861"><span class="linenos">861</span></a>        <span class="p">)</span>
</span><span id="GroupCoordinator.send_object-862"><a href="#GroupCoordinator.send_object-862"><span class="linenos">862</span></a>
</span><span id="GroupCoordinator.send_object-863"><a href="#GroupCoordinator.send_object-863"><span class="linenos">863</span></a>        <span class="c1"># Serialize object to tensor and get the size as well</span>
</span><span id="GroupCoordinator.send_object-864"><a href="#GroupCoordinator.send_object-864"><span class="linenos">864</span></a>        <span class="n">object_tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">frombuffer</span><span class="p">(</span><span class="n">pickle</span><span class="o">.</span><span class="n">dumps</span><span class="p">(</span><span class="n">obj</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">uint8</span><span class="p">)</span><span class="o">.</span><span class="n">cuda</span><span class="p">(</span>
</span><span id="GroupCoordinator.send_object-865"><a href="#GroupCoordinator.send_object-865"><span class="linenos">865</span></a>            <span class="n">device</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">current_device</span><span class="p">()</span>
</span><span id="GroupCoordinator.send_object-866"><a href="#GroupCoordinator.send_object-866"><span class="linenos">866</span></a>        <span class="p">)</span>
</span><span id="GroupCoordinator.send_object-867"><a href="#GroupCoordinator.send_object-867"><span class="linenos">867</span></a>
</span><span id="GroupCoordinator.send_object-868"><a href="#GroupCoordinator.send_object-868"><span class="linenos">868</span></a>        <span class="n">size_tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span>
</span><span id="GroupCoordinator.send_object-869"><a href="#GroupCoordinator.send_object-869"><span class="linenos">869</span></a>            <span class="p">[</span><span class="n">object_tensor</span><span class="o">.</span><span class="n">numel</span><span class="p">()],</span>
</span><span id="GroupCoordinator.send_object-870"><a href="#GroupCoordinator.send_object-870"><span class="linenos">870</span></a>            <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">long</span><span class="p">,</span>
</span><span id="GroupCoordinator.send_object-871"><a href="#GroupCoordinator.send_object-871"><span class="linenos">871</span></a>            <span class="n">device</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">current_device</span><span class="p">(),</span>
</span><span id="GroupCoordinator.send_object-872"><a href="#GroupCoordinator.send_object-872"><span class="linenos">872</span></a>        <span class="p">)</span>
</span><span id="GroupCoordinator.send_object-873"><a href="#GroupCoordinator.send_object-873"><span class="linenos">873</span></a>
</span><span id="GroupCoordinator.send_object-874"><a href="#GroupCoordinator.send_object-874"><span class="linenos">874</span></a>        <span class="c1"># Send object size</span>
</span><span id="GroupCoordinator.send_object-875"><a href="#GroupCoordinator.send_object-875"><span class="linenos">875</span></a>        <span class="n">torch</span><span class="o">.</span><span class="n">distributed</span><span class="o">.</span><span class="n">send</span><span class="p">(</span>
</span><span id="GroupCoordinator.send_object-876"><a href="#GroupCoordinator.send_object-876"><span class="linenos">876</span></a>            <span class="n">size_tensor</span><span class="p">,</span> <span class="n">dst</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">ranks</span><span class="p">[</span><span class="n">dst</span><span class="p">],</span> <span class="n">group</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device_group</span>
</span><span id="GroupCoordinator.send_object-877"><a href="#GroupCoordinator.send_object-877"><span class="linenos">877</span></a>        <span class="p">)</span>
</span><span id="GroupCoordinator.send_object-878"><a href="#GroupCoordinator.send_object-878"><span class="linenos">878</span></a>
</span><span id="GroupCoordinator.send_object-879"><a href="#GroupCoordinator.send_object-879"><span class="linenos">879</span></a>        <span class="c1"># Send object</span>
</span><span id="GroupCoordinator.send_object-880"><a href="#GroupCoordinator.send_object-880"><span class="linenos">880</span></a>        <span class="n">torch</span><span class="o">.</span><span class="n">distributed</span><span class="o">.</span><span class="n">send</span><span class="p">(</span>
</span><span id="GroupCoordinator.send_object-881"><a href="#GroupCoordinator.send_object-881"><span class="linenos">881</span></a>            <span class="n">object_tensor</span><span class="p">,</span> <span class="n">dst</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">ranks</span><span class="p">[</span><span class="n">dst</span><span class="p">],</span> <span class="n">group</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device_group</span>
</span><span id="GroupCoordinator.send_object-882"><a href="#GroupCoordinator.send_object-882"><span class="linenos">882</span></a>        <span class="p">)</span>
</span><span id="GroupCoordinator.send_object-883"><a href="#GroupCoordinator.send_object-883"><span class="linenos">883</span></a>
</span><span id="GroupCoordinator.send_object-884"><a href="#GroupCoordinator.send_object-884"><span class="linenos">884</span></a>        <span class="k">return</span> <span class="kc">None</span>
</span></pre></div>


            <div class="docstring"><p>Send the input object list to the destination rank.</p>
</div>


                            </div>
                            <div id="GroupCoordinator.recv_object" class="classattr">
                                        <input id="GroupCoordinator.recv_object-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="def">def</span>
        <span class="name">recv_object</span><span class="signature pdoc-code condensed">(<span class="param"><span class="bp">self</span>, </span><span class="param"><span class="n">src</span><span class="p">:</span> <span class="nb">int</span></span><span class="return-annotation">) -> <span class="n">Any</span>:</span></span>

                <label class="view-source-button" for="GroupCoordinator.recv_object-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#GroupCoordinator.recv_object"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="GroupCoordinator.recv_object-886"><a href="#GroupCoordinator.recv_object-886"><span class="linenos">886</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">recv_object</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">src</span><span class="p">:</span> <span class="nb">int</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Any</span><span class="p">:</span>
</span><span id="GroupCoordinator.recv_object-887"><a href="#GroupCoordinator.recv_object-887"><span class="linenos">887</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;Receive the input object list from the source rank.&quot;&quot;&quot;</span>
</span><span id="GroupCoordinator.recv_object-888"><a href="#GroupCoordinator.recv_object-888"><span class="linenos">888</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;NOTE: `src` is the local rank of the source rank.&quot;&quot;&quot;</span>
</span><span id="GroupCoordinator.recv_object-889"><a href="#GroupCoordinator.recv_object-889"><span class="linenos">889</span></a>
</span><span id="GroupCoordinator.recv_object-890"><a href="#GroupCoordinator.recv_object-890"><span class="linenos">890</span></a>        <span class="k">assert</span> <span class="n">src</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">world_size</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;Invalid src rank (</span><span class="si">{</span><span class="n">src</span><span class="si">}</span><span class="s2">)&quot;</span>
</span><span id="GroupCoordinator.recv_object-891"><a href="#GroupCoordinator.recv_object-891"><span class="linenos">891</span></a>
</span><span id="GroupCoordinator.recv_object-892"><a href="#GroupCoordinator.recv_object-892"><span class="linenos">892</span></a>        <span class="k">assert</span> <span class="p">(</span>
</span><span id="GroupCoordinator.recv_object-893"><a href="#GroupCoordinator.recv_object-893"><span class="linenos">893</span></a>            <span class="n">src</span> <span class="o">!=</span> <span class="bp">self</span><span class="o">.</span><span class="n">rank_in_group</span>
</span><span id="GroupCoordinator.recv_object-894"><a href="#GroupCoordinator.recv_object-894"><span class="linenos">894</span></a>        <span class="p">),</span> <span class="s2">&quot;Invalid source rank. Source rank is the same as the current rank.&quot;</span>
</span><span id="GroupCoordinator.recv_object-895"><a href="#GroupCoordinator.recv_object-895"><span class="linenos">895</span></a>
</span><span id="GroupCoordinator.recv_object-896"><a href="#GroupCoordinator.recv_object-896"><span class="linenos">896</span></a>        <span class="n">size_tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span>
</span><span id="GroupCoordinator.recv_object-897"><a href="#GroupCoordinator.recv_object-897"><span class="linenos">897</span></a>            <span class="mi">1</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">long</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">current_device</span><span class="p">()</span>
</span><span id="GroupCoordinator.recv_object-898"><a href="#GroupCoordinator.recv_object-898"><span class="linenos">898</span></a>        <span class="p">)</span>
</span><span id="GroupCoordinator.recv_object-899"><a href="#GroupCoordinator.recv_object-899"><span class="linenos">899</span></a>
</span><span id="GroupCoordinator.recv_object-900"><a href="#GroupCoordinator.recv_object-900"><span class="linenos">900</span></a>        <span class="c1"># Receive object size</span>
</span><span id="GroupCoordinator.recv_object-901"><a href="#GroupCoordinator.recv_object-901"><span class="linenos">901</span></a>        <span class="n">rank_size</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">distributed</span><span class="o">.</span><span class="n">recv</span><span class="p">(</span>
</span><span id="GroupCoordinator.recv_object-902"><a href="#GroupCoordinator.recv_object-902"><span class="linenos">902</span></a>            <span class="n">size_tensor</span><span class="p">,</span> <span class="n">src</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">ranks</span><span class="p">[</span><span class="n">src</span><span class="p">],</span> <span class="n">group</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device_group</span>
</span><span id="GroupCoordinator.recv_object-903"><a href="#GroupCoordinator.recv_object-903"><span class="linenos">903</span></a>        <span class="p">)</span>
</span><span id="GroupCoordinator.recv_object-904"><a href="#GroupCoordinator.recv_object-904"><span class="linenos">904</span></a>
</span><span id="GroupCoordinator.recv_object-905"><a href="#GroupCoordinator.recv_object-905"><span class="linenos">905</span></a>        <span class="c1"># Tensor to receive serialized objects into.</span>
</span><span id="GroupCoordinator.recv_object-906"><a href="#GroupCoordinator.recv_object-906"><span class="linenos">906</span></a>        <span class="n">object_tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span>  <span class="c1"># type: ignore[call-overload]</span>
</span><span id="GroupCoordinator.recv_object-907"><a href="#GroupCoordinator.recv_object-907"><span class="linenos">907</span></a>            <span class="n">size_tensor</span><span class="o">.</span><span class="n">item</span><span class="p">(),</span>  <span class="c1"># type: ignore[arg-type]</span>
</span><span id="GroupCoordinator.recv_object-908"><a href="#GroupCoordinator.recv_object-908"><span class="linenos">908</span></a>            <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">uint8</span><span class="p">,</span>
</span><span id="GroupCoordinator.recv_object-909"><a href="#GroupCoordinator.recv_object-909"><span class="linenos">909</span></a>            <span class="n">device</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">current_device</span><span class="p">(),</span>
</span><span id="GroupCoordinator.recv_object-910"><a href="#GroupCoordinator.recv_object-910"><span class="linenos">910</span></a>        <span class="p">)</span>
</span><span id="GroupCoordinator.recv_object-911"><a href="#GroupCoordinator.recv_object-911"><span class="linenos">911</span></a>
</span><span id="GroupCoordinator.recv_object-912"><a href="#GroupCoordinator.recv_object-912"><span class="linenos">912</span></a>        <span class="n">rank_object</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">distributed</span><span class="o">.</span><span class="n">recv</span><span class="p">(</span>
</span><span id="GroupCoordinator.recv_object-913"><a href="#GroupCoordinator.recv_object-913"><span class="linenos">913</span></a>            <span class="n">object_tensor</span><span class="p">,</span> <span class="n">src</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">ranks</span><span class="p">[</span><span class="n">src</span><span class="p">],</span> <span class="n">group</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device_group</span>
</span><span id="GroupCoordinator.recv_object-914"><a href="#GroupCoordinator.recv_object-914"><span class="linenos">914</span></a>        <span class="p">)</span>
</span><span id="GroupCoordinator.recv_object-915"><a href="#GroupCoordinator.recv_object-915"><span class="linenos">915</span></a>
</span><span id="GroupCoordinator.recv_object-916"><a href="#GroupCoordinator.recv_object-916"><span class="linenos">916</span></a>        <span class="k">assert</span> <span class="p">(</span>
</span><span id="GroupCoordinator.recv_object-917"><a href="#GroupCoordinator.recv_object-917"><span class="linenos">917</span></a>            <span class="n">rank_object</span> <span class="o">==</span> <span class="n">rank_size</span>
</span><span id="GroupCoordinator.recv_object-918"><a href="#GroupCoordinator.recv_object-918"><span class="linenos">918</span></a>        <span class="p">),</span> <span class="s2">&quot;Received object sender rank does not match the size sender rank.&quot;</span>
</span><span id="GroupCoordinator.recv_object-919"><a href="#GroupCoordinator.recv_object-919"><span class="linenos">919</span></a>
</span><span id="GroupCoordinator.recv_object-920"><a href="#GroupCoordinator.recv_object-920"><span class="linenos">920</span></a>        <span class="n">obj</span> <span class="o">=</span> <span class="n">pickle</span><span class="o">.</span><span class="n">loads</span><span class="p">(</span><span class="n">object_tensor</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span><span class="o">.</span><span class="n">tobytes</span><span class="p">())</span>
</span><span id="GroupCoordinator.recv_object-921"><a href="#GroupCoordinator.recv_object-921"><span class="linenos">921</span></a>
</span><span id="GroupCoordinator.recv_object-922"><a href="#GroupCoordinator.recv_object-922"><span class="linenos">922</span></a>        <span class="k">return</span> <span class="n">obj</span>
</span></pre></div>


            <div class="docstring"><p>Receive the input object list from the source rank.</p>
</div>


                            </div>
                            <div id="GroupCoordinator.broadcast_tensor_dict" class="classattr">
                                        <input id="GroupCoordinator.broadcast_tensor_dict-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="def">def</span>
        <span class="name">broadcast_tensor_dict</span><span class="signature pdoc-code multiline">(<span class="param">	<span class="bp">self</span>,</span><span class="param">	<span class="n">tensor_dict</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Union</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">Any</span><span class="p">]]]</span> <span class="o">=</span> <span class="kc">None</span>,</span><span class="param">	<span class="n">src</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span>,</span><span class="param">	<span class="n">group</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">distributed</span><span class="o">.</span><span class="n">distributed_c10d</span><span class="o">.</span><span class="n">ProcessGroup</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>,</span><span class="param">	<span class="n">metadata_group</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">distributed</span><span class="o">.</span><span class="n">distributed_c10d</span><span class="o">.</span><span class="n">ProcessGroup</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span></span><span class="return-annotation">) -> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Union</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">Any</span><span class="p">]]]</span>:</span></span>

                <label class="view-source-button" for="GroupCoordinator.broadcast_tensor_dict-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#GroupCoordinator.broadcast_tensor_dict"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="GroupCoordinator.broadcast_tensor_dict-924"><a href="#GroupCoordinator.broadcast_tensor_dict-924"><span class="linenos"> 924</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">broadcast_tensor_dict</span><span class="p">(</span>
</span><span id="GroupCoordinator.broadcast_tensor_dict-925"><a href="#GroupCoordinator.broadcast_tensor_dict-925"><span class="linenos"> 925</span></a>        <span class="bp">self</span><span class="p">,</span>
</span><span id="GroupCoordinator.broadcast_tensor_dict-926"><a href="#GroupCoordinator.broadcast_tensor_dict-926"><span class="linenos"> 926</span></a>        <span class="n">tensor_dict</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Union</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">Any</span><span class="p">]]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="GroupCoordinator.broadcast_tensor_dict-927"><a href="#GroupCoordinator.broadcast_tensor_dict-927"><span class="linenos"> 927</span></a>        <span class="n">src</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span>
</span><span id="GroupCoordinator.broadcast_tensor_dict-928"><a href="#GroupCoordinator.broadcast_tensor_dict-928"><span class="linenos"> 928</span></a>        <span class="n">group</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">ProcessGroup</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="GroupCoordinator.broadcast_tensor_dict-929"><a href="#GroupCoordinator.broadcast_tensor_dict-929"><span class="linenos"> 929</span></a>        <span class="n">metadata_group</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">ProcessGroup</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="GroupCoordinator.broadcast_tensor_dict-930"><a href="#GroupCoordinator.broadcast_tensor_dict-930"><span class="linenos"> 930</span></a>    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Union</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">Any</span><span class="p">]]]:</span>
</span><span id="GroupCoordinator.broadcast_tensor_dict-931"><a href="#GroupCoordinator.broadcast_tensor_dict-931"><span class="linenos"> 931</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;Broadcast the input tensor dictionary.</span>
</span><span id="GroupCoordinator.broadcast_tensor_dict-932"><a href="#GroupCoordinator.broadcast_tensor_dict-932"><span class="linenos"> 932</span></a><span class="sd">        NOTE: `src` is the local rank of the source rank.</span>
</span><span id="GroupCoordinator.broadcast_tensor_dict-933"><a href="#GroupCoordinator.broadcast_tensor_dict-933"><span class="linenos"> 933</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="GroupCoordinator.broadcast_tensor_dict-934"><a href="#GroupCoordinator.broadcast_tensor_dict-934"><span class="linenos"> 934</span></a>        <span class="c1"># Bypass the function if we are using only 1 GPU.</span>
</span><span id="GroupCoordinator.broadcast_tensor_dict-935"><a href="#GroupCoordinator.broadcast_tensor_dict-935"><span class="linenos"> 935</span></a>        <span class="k">if</span> <span class="ow">not</span> <span class="n">torch</span><span class="o">.</span><span class="n">distributed</span><span class="o">.</span><span class="n">is_initialized</span><span class="p">()</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">world_size</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
</span><span id="GroupCoordinator.broadcast_tensor_dict-936"><a href="#GroupCoordinator.broadcast_tensor_dict-936"><span class="linenos"> 936</span></a>            <span class="k">return</span> <span class="n">tensor_dict</span>
</span><span id="GroupCoordinator.broadcast_tensor_dict-937"><a href="#GroupCoordinator.broadcast_tensor_dict-937"><span class="linenos"> 937</span></a>
</span><span id="GroupCoordinator.broadcast_tensor_dict-938"><a href="#GroupCoordinator.broadcast_tensor_dict-938"><span class="linenos"> 938</span></a>        <span class="n">group</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">device_group</span>
</span><span id="GroupCoordinator.broadcast_tensor_dict-939"><a href="#GroupCoordinator.broadcast_tensor_dict-939"><span class="linenos"> 939</span></a>        <span class="n">metadata_group</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">cpu_group</span>
</span><span id="GroupCoordinator.broadcast_tensor_dict-940"><a href="#GroupCoordinator.broadcast_tensor_dict-940"><span class="linenos"> 940</span></a>        <span class="k">assert</span> <span class="n">src</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">world_size</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;Invalid src rank (</span><span class="si">{</span><span class="n">src</span><span class="si">}</span><span class="s2">)&quot;</span>
</span><span id="GroupCoordinator.broadcast_tensor_dict-941"><a href="#GroupCoordinator.broadcast_tensor_dict-941"><span class="linenos"> 941</span></a>
</span><span id="GroupCoordinator.broadcast_tensor_dict-942"><a href="#GroupCoordinator.broadcast_tensor_dict-942"><span class="linenos"> 942</span></a>        <span class="n">rank_in_group</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">rank_in_group</span>
</span><span id="GroupCoordinator.broadcast_tensor_dict-943"><a href="#GroupCoordinator.broadcast_tensor_dict-943"><span class="linenos"> 943</span></a>        <span class="k">if</span> <span class="n">rank_in_group</span> <span class="o">==</span> <span class="n">src</span><span class="p">:</span>
</span><span id="GroupCoordinator.broadcast_tensor_dict-944"><a href="#GroupCoordinator.broadcast_tensor_dict-944"><span class="linenos"> 944</span></a>            <span class="n">metadata_list</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">Tuple</span><span class="p">[</span><span class="n">Any</span><span class="p">,</span> <span class="n">Any</span><span class="p">]]</span> <span class="o">=</span> <span class="p">[]</span>
</span><span id="GroupCoordinator.broadcast_tensor_dict-945"><a href="#GroupCoordinator.broadcast_tensor_dict-945"><span class="linenos"> 945</span></a>            <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span>
</span><span id="GroupCoordinator.broadcast_tensor_dict-946"><a href="#GroupCoordinator.broadcast_tensor_dict-946"><span class="linenos"> 946</span></a>                <span class="n">tensor_dict</span><span class="p">,</span> <span class="nb">dict</span>
</span><span id="GroupCoordinator.broadcast_tensor_dict-947"><a href="#GroupCoordinator.broadcast_tensor_dict-947"><span class="linenos"> 947</span></a>            <span class="p">),</span> <span class="sa">f</span><span class="s2">&quot;Expecting a dictionary, got </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">tensor_dict</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span>
</span><span id="GroupCoordinator.broadcast_tensor_dict-948"><a href="#GroupCoordinator.broadcast_tensor_dict-948"><span class="linenos"> 948</span></a>            <span class="n">metadata_list</span><span class="p">,</span> <span class="n">tensor_list</span> <span class="o">=</span> <span class="n">_split_tensor_dict</span><span class="p">(</span><span class="n">tensor_dict</span><span class="p">)</span>
</span><span id="GroupCoordinator.broadcast_tensor_dict-949"><a href="#GroupCoordinator.broadcast_tensor_dict-949"><span class="linenos"> 949</span></a>            <span class="c1"># `metadata_list` lives in CPU memory.</span>
</span><span id="GroupCoordinator.broadcast_tensor_dict-950"><a href="#GroupCoordinator.broadcast_tensor_dict-950"><span class="linenos"> 950</span></a>            <span class="c1"># `broadcast_object_list` has serialization &amp; deserialization,</span>
</span><span id="GroupCoordinator.broadcast_tensor_dict-951"><a href="#GroupCoordinator.broadcast_tensor_dict-951"><span class="linenos"> 951</span></a>            <span class="c1"># all happening on CPU. Therefore, we can use the CPU group.</span>
</span><span id="GroupCoordinator.broadcast_tensor_dict-952"><a href="#GroupCoordinator.broadcast_tensor_dict-952"><span class="linenos"> 952</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">broadcast_object</span><span class="p">(</span><span class="n">metadata_list</span><span class="p">,</span> <span class="n">src</span><span class="o">=</span><span class="n">src</span><span class="p">)</span>
</span><span id="GroupCoordinator.broadcast_tensor_dict-953"><a href="#GroupCoordinator.broadcast_tensor_dict-953"><span class="linenos"> 953</span></a>            <span class="n">async_handles</span> <span class="o">=</span> <span class="p">[]</span>
</span><span id="GroupCoordinator.broadcast_tensor_dict-954"><a href="#GroupCoordinator.broadcast_tensor_dict-954"><span class="linenos"> 954</span></a>            <span class="k">for</span> <span class="n">tensor</span> <span class="ow">in</span> <span class="n">tensor_list</span><span class="p">:</span>
</span><span id="GroupCoordinator.broadcast_tensor_dict-955"><a href="#GroupCoordinator.broadcast_tensor_dict-955"><span class="linenos"> 955</span></a>                <span class="k">if</span> <span class="n">tensor</span><span class="o">.</span><span class="n">numel</span><span class="p">()</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
</span><span id="GroupCoordinator.broadcast_tensor_dict-956"><a href="#GroupCoordinator.broadcast_tensor_dict-956"><span class="linenos"> 956</span></a>                    <span class="c1"># Skip broadcasting empty tensors.</span>
</span><span id="GroupCoordinator.broadcast_tensor_dict-957"><a href="#GroupCoordinator.broadcast_tensor_dict-957"><span class="linenos"> 957</span></a>                    <span class="k">continue</span>
</span><span id="GroupCoordinator.broadcast_tensor_dict-958"><a href="#GroupCoordinator.broadcast_tensor_dict-958"><span class="linenos"> 958</span></a>                <span class="k">if</span> <span class="n">tensor</span><span class="o">.</span><span class="n">is_cpu</span><span class="p">:</span>
</span><span id="GroupCoordinator.broadcast_tensor_dict-959"><a href="#GroupCoordinator.broadcast_tensor_dict-959"><span class="linenos"> 959</span></a>                    <span class="c1"># use metadata_group for CPU tensors</span>
</span><span id="GroupCoordinator.broadcast_tensor_dict-960"><a href="#GroupCoordinator.broadcast_tensor_dict-960"><span class="linenos"> 960</span></a>                    <span class="n">handle</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">distributed</span><span class="o">.</span><span class="n">broadcast</span><span class="p">(</span>
</span><span id="GroupCoordinator.broadcast_tensor_dict-961"><a href="#GroupCoordinator.broadcast_tensor_dict-961"><span class="linenos"> 961</span></a>                        <span class="n">tensor</span><span class="p">,</span> <span class="n">src</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">ranks</span><span class="p">[</span><span class="n">src</span><span class="p">],</span> <span class="n">group</span><span class="o">=</span><span class="n">metadata_group</span><span class="p">,</span> <span class="n">async_op</span><span class="o">=</span><span class="kc">True</span>
</span><span id="GroupCoordinator.broadcast_tensor_dict-962"><a href="#GroupCoordinator.broadcast_tensor_dict-962"><span class="linenos"> 962</span></a>                    <span class="p">)</span>
</span><span id="GroupCoordinator.broadcast_tensor_dict-963"><a href="#GroupCoordinator.broadcast_tensor_dict-963"><span class="linenos"> 963</span></a>                <span class="k">else</span><span class="p">:</span>
</span><span id="GroupCoordinator.broadcast_tensor_dict-964"><a href="#GroupCoordinator.broadcast_tensor_dict-964"><span class="linenos"> 964</span></a>                    <span class="c1"># use group for GPU tensors</span>
</span><span id="GroupCoordinator.broadcast_tensor_dict-965"><a href="#GroupCoordinator.broadcast_tensor_dict-965"><span class="linenos"> 965</span></a>                    <span class="n">handle</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">distributed</span><span class="o">.</span><span class="n">broadcast</span><span class="p">(</span>
</span><span id="GroupCoordinator.broadcast_tensor_dict-966"><a href="#GroupCoordinator.broadcast_tensor_dict-966"><span class="linenos"> 966</span></a>                        <span class="n">tensor</span><span class="p">,</span> <span class="n">src</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">ranks</span><span class="p">[</span><span class="n">src</span><span class="p">],</span> <span class="n">group</span><span class="o">=</span><span class="n">group</span><span class="p">,</span> <span class="n">async_op</span><span class="o">=</span><span class="kc">True</span>
</span><span id="GroupCoordinator.broadcast_tensor_dict-967"><a href="#GroupCoordinator.broadcast_tensor_dict-967"><span class="linenos"> 967</span></a>                    <span class="p">)</span>
</span><span id="GroupCoordinator.broadcast_tensor_dict-968"><a href="#GroupCoordinator.broadcast_tensor_dict-968"><span class="linenos"> 968</span></a>                <span class="n">async_handles</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">handle</span><span class="p">)</span>
</span><span id="GroupCoordinator.broadcast_tensor_dict-969"><a href="#GroupCoordinator.broadcast_tensor_dict-969"><span class="linenos"> 969</span></a>            <span class="k">for</span> <span class="n">async_handle</span> <span class="ow">in</span> <span class="n">async_handles</span><span class="p">:</span>
</span><span id="GroupCoordinator.broadcast_tensor_dict-970"><a href="#GroupCoordinator.broadcast_tensor_dict-970"><span class="linenos"> 970</span></a>                <span class="n">async_handle</span><span class="o">.</span><span class="n">wait</span><span class="p">()</span>
</span><span id="GroupCoordinator.broadcast_tensor_dict-971"><a href="#GroupCoordinator.broadcast_tensor_dict-971"><span class="linenos"> 971</span></a>
</span><span id="GroupCoordinator.broadcast_tensor_dict-972"><a href="#GroupCoordinator.broadcast_tensor_dict-972"><span class="linenos"> 972</span></a>        <span class="k">else</span><span class="p">:</span>
</span><span id="GroupCoordinator.broadcast_tensor_dict-973"><a href="#GroupCoordinator.broadcast_tensor_dict-973"><span class="linenos"> 973</span></a>            <span class="n">metadata_list</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">broadcast_object</span><span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="n">src</span><span class="o">=</span><span class="n">src</span><span class="p">)</span>
</span><span id="GroupCoordinator.broadcast_tensor_dict-974"><a href="#GroupCoordinator.broadcast_tensor_dict-974"><span class="linenos"> 974</span></a>            <span class="n">tensor_dict</span> <span class="o">=</span> <span class="p">{}</span>
</span><span id="GroupCoordinator.broadcast_tensor_dict-975"><a href="#GroupCoordinator.broadcast_tensor_dict-975"><span class="linenos"> 975</span></a>            <span class="n">async_handles</span> <span class="o">=</span> <span class="p">[]</span>
</span><span id="GroupCoordinator.broadcast_tensor_dict-976"><a href="#GroupCoordinator.broadcast_tensor_dict-976"><span class="linenos"> 976</span></a>            <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">metadata_list</span><span class="p">:</span>
</span><span id="GroupCoordinator.broadcast_tensor_dict-977"><a href="#GroupCoordinator.broadcast_tensor_dict-977"><span class="linenos"> 977</span></a>                <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">value</span><span class="p">,</span> <span class="n">TensorMetadata</span><span class="p">):</span>
</span><span id="GroupCoordinator.broadcast_tensor_dict-978"><a href="#GroupCoordinator.broadcast_tensor_dict-978"><span class="linenos"> 978</span></a>                    <span class="n">tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span>
</span><span id="GroupCoordinator.broadcast_tensor_dict-979"><a href="#GroupCoordinator.broadcast_tensor_dict-979"><span class="linenos"> 979</span></a>                        <span class="n">value</span><span class="o">.</span><span class="n">size</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">value</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">value</span><span class="o">.</span><span class="n">device</span>
</span><span id="GroupCoordinator.broadcast_tensor_dict-980"><a href="#GroupCoordinator.broadcast_tensor_dict-980"><span class="linenos"> 980</span></a>                    <span class="p">)</span>
</span><span id="GroupCoordinator.broadcast_tensor_dict-981"><a href="#GroupCoordinator.broadcast_tensor_dict-981"><span class="linenos"> 981</span></a>                    <span class="k">if</span> <span class="n">tensor</span><span class="o">.</span><span class="n">numel</span><span class="p">()</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
</span><span id="GroupCoordinator.broadcast_tensor_dict-982"><a href="#GroupCoordinator.broadcast_tensor_dict-982"><span class="linenos"> 982</span></a>                        <span class="c1"># Skip broadcasting empty tensors.</span>
</span><span id="GroupCoordinator.broadcast_tensor_dict-983"><a href="#GroupCoordinator.broadcast_tensor_dict-983"><span class="linenos"> 983</span></a>                        <span class="n">tensor_dict</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">=</span> <span class="n">tensor</span>
</span><span id="GroupCoordinator.broadcast_tensor_dict-984"><a href="#GroupCoordinator.broadcast_tensor_dict-984"><span class="linenos"> 984</span></a>                        <span class="k">continue</span>
</span><span id="GroupCoordinator.broadcast_tensor_dict-985"><a href="#GroupCoordinator.broadcast_tensor_dict-985"><span class="linenos"> 985</span></a>                    <span class="k">if</span> <span class="n">tensor</span><span class="o">.</span><span class="n">is_cpu</span><span class="p">:</span>
</span><span id="GroupCoordinator.broadcast_tensor_dict-986"><a href="#GroupCoordinator.broadcast_tensor_dict-986"><span class="linenos"> 986</span></a>                        <span class="c1"># use metadata_group for CPU tensors</span>
</span><span id="GroupCoordinator.broadcast_tensor_dict-987"><a href="#GroupCoordinator.broadcast_tensor_dict-987"><span class="linenos"> 987</span></a>                        <span class="n">handle</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">distributed</span><span class="o">.</span><span class="n">broadcast</span><span class="p">(</span>
</span><span id="GroupCoordinator.broadcast_tensor_dict-988"><a href="#GroupCoordinator.broadcast_tensor_dict-988"><span class="linenos"> 988</span></a>                            <span class="n">tensor</span><span class="p">,</span>
</span><span id="GroupCoordinator.broadcast_tensor_dict-989"><a href="#GroupCoordinator.broadcast_tensor_dict-989"><span class="linenos"> 989</span></a>                            <span class="n">src</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">ranks</span><span class="p">[</span><span class="n">src</span><span class="p">],</span>
</span><span id="GroupCoordinator.broadcast_tensor_dict-990"><a href="#GroupCoordinator.broadcast_tensor_dict-990"><span class="linenos"> 990</span></a>                            <span class="n">group</span><span class="o">=</span><span class="n">metadata_group</span><span class="p">,</span>
</span><span id="GroupCoordinator.broadcast_tensor_dict-991"><a href="#GroupCoordinator.broadcast_tensor_dict-991"><span class="linenos"> 991</span></a>                            <span class="n">async_op</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
</span><span id="GroupCoordinator.broadcast_tensor_dict-992"><a href="#GroupCoordinator.broadcast_tensor_dict-992"><span class="linenos"> 992</span></a>                        <span class="p">)</span>
</span><span id="GroupCoordinator.broadcast_tensor_dict-993"><a href="#GroupCoordinator.broadcast_tensor_dict-993"><span class="linenos"> 993</span></a>                    <span class="k">else</span><span class="p">:</span>
</span><span id="GroupCoordinator.broadcast_tensor_dict-994"><a href="#GroupCoordinator.broadcast_tensor_dict-994"><span class="linenos"> 994</span></a>                        <span class="c1"># use group for GPU tensors</span>
</span><span id="GroupCoordinator.broadcast_tensor_dict-995"><a href="#GroupCoordinator.broadcast_tensor_dict-995"><span class="linenos"> 995</span></a>                        <span class="n">handle</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">distributed</span><span class="o">.</span><span class="n">broadcast</span><span class="p">(</span>
</span><span id="GroupCoordinator.broadcast_tensor_dict-996"><a href="#GroupCoordinator.broadcast_tensor_dict-996"><span class="linenos"> 996</span></a>                            <span class="n">tensor</span><span class="p">,</span> <span class="n">src</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">ranks</span><span class="p">[</span><span class="n">src</span><span class="p">],</span> <span class="n">group</span><span class="o">=</span><span class="n">group</span><span class="p">,</span> <span class="n">async_op</span><span class="o">=</span><span class="kc">True</span>
</span><span id="GroupCoordinator.broadcast_tensor_dict-997"><a href="#GroupCoordinator.broadcast_tensor_dict-997"><span class="linenos"> 997</span></a>                        <span class="p">)</span>
</span><span id="GroupCoordinator.broadcast_tensor_dict-998"><a href="#GroupCoordinator.broadcast_tensor_dict-998"><span class="linenos"> 998</span></a>                    <span class="n">async_handles</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">handle</span><span class="p">)</span>
</span><span id="GroupCoordinator.broadcast_tensor_dict-999"><a href="#GroupCoordinator.broadcast_tensor_dict-999"><span class="linenos"> 999</span></a>                    <span class="n">tensor_dict</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">=</span> <span class="n">tensor</span>
</span><span id="GroupCoordinator.broadcast_tensor_dict-1000"><a href="#GroupCoordinator.broadcast_tensor_dict-1000"><span class="linenos">1000</span></a>                <span class="k">else</span><span class="p">:</span>
</span><span id="GroupCoordinator.broadcast_tensor_dict-1001"><a href="#GroupCoordinator.broadcast_tensor_dict-1001"><span class="linenos">1001</span></a>                    <span class="n">tensor_dict</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">=</span> <span class="n">value</span>
</span><span id="GroupCoordinator.broadcast_tensor_dict-1002"><a href="#GroupCoordinator.broadcast_tensor_dict-1002"><span class="linenos">1002</span></a>            <span class="k">for</span> <span class="n">async_handle</span> <span class="ow">in</span> <span class="n">async_handles</span><span class="p">:</span>
</span><span id="GroupCoordinator.broadcast_tensor_dict-1003"><a href="#GroupCoordinator.broadcast_tensor_dict-1003"><span class="linenos">1003</span></a>                <span class="n">async_handle</span><span class="o">.</span><span class="n">wait</span><span class="p">()</span>
</span><span id="GroupCoordinator.broadcast_tensor_dict-1004"><a href="#GroupCoordinator.broadcast_tensor_dict-1004"><span class="linenos">1004</span></a>        <span class="k">return</span> <span class="n">tensor_dict</span>
</span></pre></div>


            <div class="docstring"><p>Broadcast the input tensor dictionary.
NOTE: <code>src</code> is the local rank of the source rank.</p>
</div>


                            </div>
                            <div id="GroupCoordinator.send_tensor_dict" class="classattr">
                                        <input id="GroupCoordinator.send_tensor_dict-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="def">def</span>
        <span class="name">send_tensor_dict</span><span class="signature pdoc-code multiline">(<span class="param">	<span class="bp">self</span>,</span><span class="param">	<span class="n">tensor_dict</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Union</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">Any</span><span class="p">]]</span>,</span><span class="param">	<span class="n">dst</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>,</span><span class="param">	<span class="n">all_gather_group</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n"><a href="#GroupCoordinator">GroupCoordinator</a></span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span></span><span class="return-annotation">) -> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Union</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">Any</span><span class="p">]]]</span>:</span></span>

                <label class="view-source-button" for="GroupCoordinator.send_tensor_dict-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#GroupCoordinator.send_tensor_dict"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="GroupCoordinator.send_tensor_dict-1006"><a href="#GroupCoordinator.send_tensor_dict-1006"><span class="linenos">1006</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">send_tensor_dict</span><span class="p">(</span>
</span><span id="GroupCoordinator.send_tensor_dict-1007"><a href="#GroupCoordinator.send_tensor_dict-1007"><span class="linenos">1007</span></a>        <span class="bp">self</span><span class="p">,</span>
</span><span id="GroupCoordinator.send_tensor_dict-1008"><a href="#GroupCoordinator.send_tensor_dict-1008"><span class="linenos">1008</span></a>        <span class="n">tensor_dict</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Union</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">Any</span><span class="p">]],</span>
</span><span id="GroupCoordinator.send_tensor_dict-1009"><a href="#GroupCoordinator.send_tensor_dict-1009"><span class="linenos">1009</span></a>        <span class="n">dst</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="GroupCoordinator.send_tensor_dict-1010"><a href="#GroupCoordinator.send_tensor_dict-1010"><span class="linenos">1010</span></a>        <span class="n">all_gather_group</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="s2">&quot;GroupCoordinator&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="GroupCoordinator.send_tensor_dict-1011"><a href="#GroupCoordinator.send_tensor_dict-1011"><span class="linenos">1011</span></a>    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Union</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">Any</span><span class="p">]]]:</span>
</span><span id="GroupCoordinator.send_tensor_dict-1012"><a href="#GroupCoordinator.send_tensor_dict-1012"><span class="linenos">1012</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;Send the input tensor dictionary.</span>
</span><span id="GroupCoordinator.send_tensor_dict-1013"><a href="#GroupCoordinator.send_tensor_dict-1013"><span class="linenos">1013</span></a><span class="sd">        NOTE: `dst` is the local rank of the source rank.</span>
</span><span id="GroupCoordinator.send_tensor_dict-1014"><a href="#GroupCoordinator.send_tensor_dict-1014"><span class="linenos">1014</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="GroupCoordinator.send_tensor_dict-1015"><a href="#GroupCoordinator.send_tensor_dict-1015"><span class="linenos">1015</span></a>        <span class="c1"># Bypass the function if we are using only 1 GPU.</span>
</span><span id="GroupCoordinator.send_tensor_dict-1016"><a href="#GroupCoordinator.send_tensor_dict-1016"><span class="linenos">1016</span></a>        <span class="k">if</span> <span class="ow">not</span> <span class="n">torch</span><span class="o">.</span><span class="n">distributed</span><span class="o">.</span><span class="n">is_initialized</span><span class="p">()</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">world_size</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
</span><span id="GroupCoordinator.send_tensor_dict-1017"><a href="#GroupCoordinator.send_tensor_dict-1017"><span class="linenos">1017</span></a>            <span class="k">return</span> <span class="n">tensor_dict</span>
</span><span id="GroupCoordinator.send_tensor_dict-1018"><a href="#GroupCoordinator.send_tensor_dict-1018"><span class="linenos">1018</span></a>
</span><span id="GroupCoordinator.send_tensor_dict-1019"><a href="#GroupCoordinator.send_tensor_dict-1019"><span class="linenos">1019</span></a>        <span class="n">all_gather_size</span> <span class="o">=</span> <span class="mi">1</span> <span class="k">if</span> <span class="n">all_gather_group</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">all_gather_group</span><span class="o">.</span><span class="n">world_size</span>
</span><span id="GroupCoordinator.send_tensor_dict-1020"><a href="#GroupCoordinator.send_tensor_dict-1020"><span class="linenos">1020</span></a>        <span class="n">all_gather_rank</span> <span class="o">=</span> <span class="p">(</span>
</span><span id="GroupCoordinator.send_tensor_dict-1021"><a href="#GroupCoordinator.send_tensor_dict-1021"><span class="linenos">1021</span></a>            <span class="mi">0</span> <span class="k">if</span> <span class="n">all_gather_group</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">all_gather_group</span><span class="o">.</span><span class="n">rank_in_group</span>
</span><span id="GroupCoordinator.send_tensor_dict-1022"><a href="#GroupCoordinator.send_tensor_dict-1022"><span class="linenos">1022</span></a>        <span class="p">)</span>
</span><span id="GroupCoordinator.send_tensor_dict-1023"><a href="#GroupCoordinator.send_tensor_dict-1023"><span class="linenos">1023</span></a>
</span><span id="GroupCoordinator.send_tensor_dict-1024"><a href="#GroupCoordinator.send_tensor_dict-1024"><span class="linenos">1024</span></a>        <span class="n">group</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">device_group</span>
</span><span id="GroupCoordinator.send_tensor_dict-1025"><a href="#GroupCoordinator.send_tensor_dict-1025"><span class="linenos">1025</span></a>        <span class="n">metadata_group</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">cpu_group</span>
</span><span id="GroupCoordinator.send_tensor_dict-1026"><a href="#GroupCoordinator.send_tensor_dict-1026"><span class="linenos">1026</span></a>
</span><span id="GroupCoordinator.send_tensor_dict-1027"><a href="#GroupCoordinator.send_tensor_dict-1027"><span class="linenos">1027</span></a>        <span class="k">if</span> <span class="n">dst</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="GroupCoordinator.send_tensor_dict-1028"><a href="#GroupCoordinator.send_tensor_dict-1028"><span class="linenos">1028</span></a>            <span class="n">dst</span> <span class="o">=</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">rank_in_group</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">%</span> <span class="bp">self</span><span class="o">.</span><span class="n">world_size</span>
</span><span id="GroupCoordinator.send_tensor_dict-1029"><a href="#GroupCoordinator.send_tensor_dict-1029"><span class="linenos">1029</span></a>        <span class="k">assert</span> <span class="n">dst</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">world_size</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;Invalid dst rank (</span><span class="si">{</span><span class="n">dst</span><span class="si">}</span><span class="s2">)&quot;</span>
</span><span id="GroupCoordinator.send_tensor_dict-1030"><a href="#GroupCoordinator.send_tensor_dict-1030"><span class="linenos">1030</span></a>
</span><span id="GroupCoordinator.send_tensor_dict-1031"><a href="#GroupCoordinator.send_tensor_dict-1031"><span class="linenos">1031</span></a>        <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span>
</span><span id="GroupCoordinator.send_tensor_dict-1032"><a href="#GroupCoordinator.send_tensor_dict-1032"><span class="linenos">1032</span></a>            <span class="n">tensor_dict</span><span class="p">,</span> <span class="nb">dict</span>
</span><span id="GroupCoordinator.send_tensor_dict-1033"><a href="#GroupCoordinator.send_tensor_dict-1033"><span class="linenos">1033</span></a>        <span class="p">),</span> <span class="sa">f</span><span class="s2">&quot;Expecting a dictionary, got </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">tensor_dict</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span>
</span><span id="GroupCoordinator.send_tensor_dict-1034"><a href="#GroupCoordinator.send_tensor_dict-1034"><span class="linenos">1034</span></a>        <span class="n">metadata_list</span><span class="p">,</span> <span class="n">tensor_list</span> <span class="o">=</span> <span class="n">_split_tensor_dict</span><span class="p">(</span><span class="n">tensor_dict</span><span class="p">)</span>
</span><span id="GroupCoordinator.send_tensor_dict-1035"><a href="#GroupCoordinator.send_tensor_dict-1035"><span class="linenos">1035</span></a>        <span class="c1"># Note: While switching to Device-to-Device (D2D) would introduce an extra</span>
</span><span id="GroupCoordinator.send_tensor_dict-1036"><a href="#GroupCoordinator.send_tensor_dict-1036"><span class="linenos">1036</span></a>        <span class="c1"># Device-to-Host (D2H) memory copy overhead for serialization, our benchmarks</span>
</span><span id="GroupCoordinator.send_tensor_dict-1037"><a href="#GroupCoordinator.send_tensor_dict-1037"><span class="linenos">1037</span></a>        <span class="c1"># show better overall transmission performance with D2D due to:</span>
</span><span id="GroupCoordinator.send_tensor_dict-1038"><a href="#GroupCoordinator.send_tensor_dict-1038"><span class="linenos">1038</span></a>        <span class="c1"># 1. Superior D2D transfer bandwidth</span>
</span><span id="GroupCoordinator.send_tensor_dict-1039"><a href="#GroupCoordinator.send_tensor_dict-1039"><span class="linenos">1039</span></a>        <span class="c1"># 2. Ability to overlap send and recv operations</span>
</span><span id="GroupCoordinator.send_tensor_dict-1040"><a href="#GroupCoordinator.send_tensor_dict-1040"><span class="linenos">1040</span></a>        <span class="c1"># Thus the net performance gain justifies this approach.</span>
</span><span id="GroupCoordinator.send_tensor_dict-1041"><a href="#GroupCoordinator.send_tensor_dict-1041"><span class="linenos">1041</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">send_object</span><span class="p">(</span><span class="n">metadata_list</span><span class="p">,</span> <span class="n">dst</span><span class="o">=</span><span class="n">dst</span><span class="p">)</span>
</span><span id="GroupCoordinator.send_tensor_dict-1042"><a href="#GroupCoordinator.send_tensor_dict-1042"><span class="linenos">1042</span></a>        <span class="k">for</span> <span class="n">tensor</span> <span class="ow">in</span> <span class="n">tensor_list</span><span class="p">:</span>
</span><span id="GroupCoordinator.send_tensor_dict-1043"><a href="#GroupCoordinator.send_tensor_dict-1043"><span class="linenos">1043</span></a>            <span class="k">if</span> <span class="n">tensor</span><span class="o">.</span><span class="n">numel</span><span class="p">()</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
</span><span id="GroupCoordinator.send_tensor_dict-1044"><a href="#GroupCoordinator.send_tensor_dict-1044"><span class="linenos">1044</span></a>                <span class="c1"># Skip sending empty tensors.</span>
</span><span id="GroupCoordinator.send_tensor_dict-1045"><a href="#GroupCoordinator.send_tensor_dict-1045"><span class="linenos">1045</span></a>                <span class="k">continue</span>
</span><span id="GroupCoordinator.send_tensor_dict-1046"><a href="#GroupCoordinator.send_tensor_dict-1046"><span class="linenos">1046</span></a>
</span><span id="GroupCoordinator.send_tensor_dict-1047"><a href="#GroupCoordinator.send_tensor_dict-1047"><span class="linenos">1047</span></a>            <span class="c1"># send-allgather: send only a slice, then do allgather.</span>
</span><span id="GroupCoordinator.send_tensor_dict-1048"><a href="#GroupCoordinator.send_tensor_dict-1048"><span class="linenos">1048</span></a>            <span class="k">if</span> <span class="n">all_gather_group</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">tensor</span><span class="o">.</span><span class="n">numel</span><span class="p">()</span> <span class="o">%</span> <span class="n">all_gather_size</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
</span><span id="GroupCoordinator.send_tensor_dict-1049"><a href="#GroupCoordinator.send_tensor_dict-1049"><span class="linenos">1049</span></a>                <span class="n">tensor</span> <span class="o">=</span> <span class="n">tensor</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">all_gather_size</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)[</span><span class="n">all_gather_rank</span><span class="p">]</span>
</span><span id="GroupCoordinator.send_tensor_dict-1050"><a href="#GroupCoordinator.send_tensor_dict-1050"><span class="linenos">1050</span></a>
</span><span id="GroupCoordinator.send_tensor_dict-1051"><a href="#GroupCoordinator.send_tensor_dict-1051"><span class="linenos">1051</span></a>            <span class="k">if</span> <span class="n">tensor</span><span class="o">.</span><span class="n">is_cpu</span><span class="p">:</span>
</span><span id="GroupCoordinator.send_tensor_dict-1052"><a href="#GroupCoordinator.send_tensor_dict-1052"><span class="linenos">1052</span></a>                <span class="c1"># use metadata_group for CPU tensors</span>
</span><span id="GroupCoordinator.send_tensor_dict-1053"><a href="#GroupCoordinator.send_tensor_dict-1053"><span class="linenos">1053</span></a>                <span class="n">torch</span><span class="o">.</span><span class="n">distributed</span><span class="o">.</span><span class="n">send</span><span class="p">(</span>
</span><span id="GroupCoordinator.send_tensor_dict-1054"><a href="#GroupCoordinator.send_tensor_dict-1054"><span class="linenos">1054</span></a>                    <span class="n">tensor</span><span class="p">,</span> <span class="n">dst</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">ranks</span><span class="p">[</span><span class="n">dst</span><span class="p">],</span> <span class="n">group</span><span class="o">=</span><span class="n">metadata_group</span>
</span><span id="GroupCoordinator.send_tensor_dict-1055"><a href="#GroupCoordinator.send_tensor_dict-1055"><span class="linenos">1055</span></a>                <span class="p">)</span>
</span><span id="GroupCoordinator.send_tensor_dict-1056"><a href="#GroupCoordinator.send_tensor_dict-1056"><span class="linenos">1056</span></a>            <span class="k">else</span><span class="p">:</span>
</span><span id="GroupCoordinator.send_tensor_dict-1057"><a href="#GroupCoordinator.send_tensor_dict-1057"><span class="linenos">1057</span></a>                <span class="c1"># use group for GPU tensors</span>
</span><span id="GroupCoordinator.send_tensor_dict-1058"><a href="#GroupCoordinator.send_tensor_dict-1058"><span class="linenos">1058</span></a>                <span class="n">torch</span><span class="o">.</span><span class="n">distributed</span><span class="o">.</span><span class="n">send</span><span class="p">(</span><span class="n">tensor</span><span class="p">,</span> <span class="n">dst</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">ranks</span><span class="p">[</span><span class="n">dst</span><span class="p">],</span> <span class="n">group</span><span class="o">=</span><span class="n">group</span><span class="p">)</span>
</span><span id="GroupCoordinator.send_tensor_dict-1059"><a href="#GroupCoordinator.send_tensor_dict-1059"><span class="linenos">1059</span></a>        <span class="k">return</span> <span class="kc">None</span>
</span></pre></div>


            <div class="docstring"><p>Send the input tensor dictionary.
NOTE: <code>dst</code> is the local rank of the source rank.</p>
</div>


                            </div>
                            <div id="GroupCoordinator.recv_tensor_dict" class="classattr">
                                        <input id="GroupCoordinator.recv_tensor_dict-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="def">def</span>
        <span class="name">recv_tensor_dict</span><span class="signature pdoc-code multiline">(<span class="param">	<span class="bp">self</span>,</span><span class="param">	<span class="n">src</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>,</span><span class="param">	<span class="n">all_gather_group</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n"><a href="#GroupCoordinator">GroupCoordinator</a></span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span></span><span class="return-annotation">) -> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Union</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">Any</span><span class="p">]]]</span>:</span></span>

                <label class="view-source-button" for="GroupCoordinator.recv_tensor_dict-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#GroupCoordinator.recv_tensor_dict"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="GroupCoordinator.recv_tensor_dict-1061"><a href="#GroupCoordinator.recv_tensor_dict-1061"><span class="linenos">1061</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">recv_tensor_dict</span><span class="p">(</span>
</span><span id="GroupCoordinator.recv_tensor_dict-1062"><a href="#GroupCoordinator.recv_tensor_dict-1062"><span class="linenos">1062</span></a>        <span class="bp">self</span><span class="p">,</span>
</span><span id="GroupCoordinator.recv_tensor_dict-1063"><a href="#GroupCoordinator.recv_tensor_dict-1063"><span class="linenos">1063</span></a>        <span class="n">src</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="GroupCoordinator.recv_tensor_dict-1064"><a href="#GroupCoordinator.recv_tensor_dict-1064"><span class="linenos">1064</span></a>        <span class="n">all_gather_group</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="s2">&quot;GroupCoordinator&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="GroupCoordinator.recv_tensor_dict-1065"><a href="#GroupCoordinator.recv_tensor_dict-1065"><span class="linenos">1065</span></a>    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Union</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">Any</span><span class="p">]]]:</span>
</span><span id="GroupCoordinator.recv_tensor_dict-1066"><a href="#GroupCoordinator.recv_tensor_dict-1066"><span class="linenos">1066</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;Recv the input tensor dictionary.</span>
</span><span id="GroupCoordinator.recv_tensor_dict-1067"><a href="#GroupCoordinator.recv_tensor_dict-1067"><span class="linenos">1067</span></a><span class="sd">        NOTE: `src` is the local rank of the source rank.</span>
</span><span id="GroupCoordinator.recv_tensor_dict-1068"><a href="#GroupCoordinator.recv_tensor_dict-1068"><span class="linenos">1068</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="GroupCoordinator.recv_tensor_dict-1069"><a href="#GroupCoordinator.recv_tensor_dict-1069"><span class="linenos">1069</span></a>        <span class="c1"># Bypass the function if we are using only 1 GPU.</span>
</span><span id="GroupCoordinator.recv_tensor_dict-1070"><a href="#GroupCoordinator.recv_tensor_dict-1070"><span class="linenos">1070</span></a>        <span class="k">if</span> <span class="ow">not</span> <span class="n">torch</span><span class="o">.</span><span class="n">distributed</span><span class="o">.</span><span class="n">is_initialized</span><span class="p">()</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">world_size</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
</span><span id="GroupCoordinator.recv_tensor_dict-1071"><a href="#GroupCoordinator.recv_tensor_dict-1071"><span class="linenos">1071</span></a>            <span class="k">return</span> <span class="kc">None</span>
</span><span id="GroupCoordinator.recv_tensor_dict-1072"><a href="#GroupCoordinator.recv_tensor_dict-1072"><span class="linenos">1072</span></a>
</span><span id="GroupCoordinator.recv_tensor_dict-1073"><a href="#GroupCoordinator.recv_tensor_dict-1073"><span class="linenos">1073</span></a>        <span class="n">all_gather_size</span> <span class="o">=</span> <span class="mi">1</span> <span class="k">if</span> <span class="n">all_gather_group</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">all_gather_group</span><span class="o">.</span><span class="n">world_size</span>
</span><span id="GroupCoordinator.recv_tensor_dict-1074"><a href="#GroupCoordinator.recv_tensor_dict-1074"><span class="linenos">1074</span></a>        <span class="n">all_gather_rank</span> <span class="o">=</span> <span class="p">(</span>
</span><span id="GroupCoordinator.recv_tensor_dict-1075"><a href="#GroupCoordinator.recv_tensor_dict-1075"><span class="linenos">1075</span></a>            <span class="mi">0</span> <span class="k">if</span> <span class="n">all_gather_group</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">all_gather_group</span><span class="o">.</span><span class="n">rank_in_group</span>
</span><span id="GroupCoordinator.recv_tensor_dict-1076"><a href="#GroupCoordinator.recv_tensor_dict-1076"><span class="linenos">1076</span></a>        <span class="p">)</span>
</span><span id="GroupCoordinator.recv_tensor_dict-1077"><a href="#GroupCoordinator.recv_tensor_dict-1077"><span class="linenos">1077</span></a>
</span><span id="GroupCoordinator.recv_tensor_dict-1078"><a href="#GroupCoordinator.recv_tensor_dict-1078"><span class="linenos">1078</span></a>        <span class="n">group</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">device_group</span>
</span><span id="GroupCoordinator.recv_tensor_dict-1079"><a href="#GroupCoordinator.recv_tensor_dict-1079"><span class="linenos">1079</span></a>        <span class="n">metadata_group</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">cpu_group</span>
</span><span id="GroupCoordinator.recv_tensor_dict-1080"><a href="#GroupCoordinator.recv_tensor_dict-1080"><span class="linenos">1080</span></a>
</span><span id="GroupCoordinator.recv_tensor_dict-1081"><a href="#GroupCoordinator.recv_tensor_dict-1081"><span class="linenos">1081</span></a>        <span class="k">if</span> <span class="n">src</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="GroupCoordinator.recv_tensor_dict-1082"><a href="#GroupCoordinator.recv_tensor_dict-1082"><span class="linenos">1082</span></a>            <span class="n">src</span> <span class="o">=</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">rank_in_group</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">%</span> <span class="bp">self</span><span class="o">.</span><span class="n">world_size</span>
</span><span id="GroupCoordinator.recv_tensor_dict-1083"><a href="#GroupCoordinator.recv_tensor_dict-1083"><span class="linenos">1083</span></a>        <span class="k">assert</span> <span class="n">src</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">world_size</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;Invalid src rank (</span><span class="si">{</span><span class="n">src</span><span class="si">}</span><span class="s2">)&quot;</span>
</span><span id="GroupCoordinator.recv_tensor_dict-1084"><a href="#GroupCoordinator.recv_tensor_dict-1084"><span class="linenos">1084</span></a>
</span><span id="GroupCoordinator.recv_tensor_dict-1085"><a href="#GroupCoordinator.recv_tensor_dict-1085"><span class="linenos">1085</span></a>        <span class="n">recv_metadata_list</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">recv_object</span><span class="p">(</span><span class="n">src</span><span class="o">=</span><span class="n">src</span><span class="p">)</span>
</span><span id="GroupCoordinator.recv_tensor_dict-1086"><a href="#GroupCoordinator.recv_tensor_dict-1086"><span class="linenos">1086</span></a>        <span class="n">tensor_dict</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]</span> <span class="o">=</span> <span class="p">{}</span>
</span><span id="GroupCoordinator.recv_tensor_dict-1087"><a href="#GroupCoordinator.recv_tensor_dict-1087"><span class="linenos">1087</span></a>        <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">recv_metadata_list</span><span class="p">:</span>
</span><span id="GroupCoordinator.recv_tensor_dict-1088"><a href="#GroupCoordinator.recv_tensor_dict-1088"><span class="linenos">1088</span></a>            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">value</span><span class="p">,</span> <span class="n">TensorMetadata</span><span class="p">):</span>
</span><span id="GroupCoordinator.recv_tensor_dict-1089"><a href="#GroupCoordinator.recv_tensor_dict-1089"><span class="linenos">1089</span></a>                <span class="n">tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span><span class="n">value</span><span class="o">.</span><span class="n">size</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">value</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">value</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
</span><span id="GroupCoordinator.recv_tensor_dict-1090"><a href="#GroupCoordinator.recv_tensor_dict-1090"><span class="linenos">1090</span></a>                <span class="k">if</span> <span class="n">tensor</span><span class="o">.</span><span class="n">numel</span><span class="p">()</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
</span><span id="GroupCoordinator.recv_tensor_dict-1091"><a href="#GroupCoordinator.recv_tensor_dict-1091"><span class="linenos">1091</span></a>                    <span class="c1"># Skip broadcasting empty tensors.</span>
</span><span id="GroupCoordinator.recv_tensor_dict-1092"><a href="#GroupCoordinator.recv_tensor_dict-1092"><span class="linenos">1092</span></a>                    <span class="n">tensor_dict</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">=</span> <span class="n">tensor</span>
</span><span id="GroupCoordinator.recv_tensor_dict-1093"><a href="#GroupCoordinator.recv_tensor_dict-1093"><span class="linenos">1093</span></a>                    <span class="k">continue</span>
</span><span id="GroupCoordinator.recv_tensor_dict-1094"><a href="#GroupCoordinator.recv_tensor_dict-1094"><span class="linenos">1094</span></a>
</span><span id="GroupCoordinator.recv_tensor_dict-1095"><a href="#GroupCoordinator.recv_tensor_dict-1095"><span class="linenos">1095</span></a>                <span class="c1"># send-allgather: send only a slice, then do allgather.</span>
</span><span id="GroupCoordinator.recv_tensor_dict-1096"><a href="#GroupCoordinator.recv_tensor_dict-1096"><span class="linenos">1096</span></a>                <span class="n">use_all_gather</span> <span class="o">=</span> <span class="p">(</span>
</span><span id="GroupCoordinator.recv_tensor_dict-1097"><a href="#GroupCoordinator.recv_tensor_dict-1097"><span class="linenos">1097</span></a>                    <span class="n">all_gather_group</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
</span><span id="GroupCoordinator.recv_tensor_dict-1098"><a href="#GroupCoordinator.recv_tensor_dict-1098"><span class="linenos">1098</span></a>                    <span class="ow">and</span> <span class="n">tensor</span><span class="o">.</span><span class="n">numel</span><span class="p">()</span> <span class="o">%</span> <span class="n">all_gather_size</span> <span class="o">==</span> <span class="mi">0</span>
</span><span id="GroupCoordinator.recv_tensor_dict-1099"><a href="#GroupCoordinator.recv_tensor_dict-1099"><span class="linenos">1099</span></a>                <span class="p">)</span>
</span><span id="GroupCoordinator.recv_tensor_dict-1100"><a href="#GroupCoordinator.recv_tensor_dict-1100"><span class="linenos">1100</span></a>
</span><span id="GroupCoordinator.recv_tensor_dict-1101"><a href="#GroupCoordinator.recv_tensor_dict-1101"><span class="linenos">1101</span></a>                <span class="k">if</span> <span class="n">use_all_gather</span><span class="p">:</span>
</span><span id="GroupCoordinator.recv_tensor_dict-1102"><a href="#GroupCoordinator.recv_tensor_dict-1102"><span class="linenos">1102</span></a>                    <span class="n">orig_shape</span> <span class="o">=</span> <span class="n">tensor</span><span class="o">.</span><span class="n">shape</span>
</span><span id="GroupCoordinator.recv_tensor_dict-1103"><a href="#GroupCoordinator.recv_tensor_dict-1103"><span class="linenos">1103</span></a>                    <span class="n">tensor</span> <span class="o">=</span> <span class="n">tensor</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">all_gather_size</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)[</span><span class="n">all_gather_rank</span><span class="p">]</span>
</span><span id="GroupCoordinator.recv_tensor_dict-1104"><a href="#GroupCoordinator.recv_tensor_dict-1104"><span class="linenos">1104</span></a>
</span><span id="GroupCoordinator.recv_tensor_dict-1105"><a href="#GroupCoordinator.recv_tensor_dict-1105"><span class="linenos">1105</span></a>                <span class="k">if</span> <span class="n">tensor</span><span class="o">.</span><span class="n">is_cpu</span><span class="p">:</span>
</span><span id="GroupCoordinator.recv_tensor_dict-1106"><a href="#GroupCoordinator.recv_tensor_dict-1106"><span class="linenos">1106</span></a>                    <span class="c1"># use metadata_group for CPU tensors</span>
</span><span id="GroupCoordinator.recv_tensor_dict-1107"><a href="#GroupCoordinator.recv_tensor_dict-1107"><span class="linenos">1107</span></a>                    <span class="n">torch</span><span class="o">.</span><span class="n">distributed</span><span class="o">.</span><span class="n">recv</span><span class="p">(</span>
</span><span id="GroupCoordinator.recv_tensor_dict-1108"><a href="#GroupCoordinator.recv_tensor_dict-1108"><span class="linenos">1108</span></a>                        <span class="n">tensor</span><span class="p">,</span> <span class="n">src</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">ranks</span><span class="p">[</span><span class="n">src</span><span class="p">],</span> <span class="n">group</span><span class="o">=</span><span class="n">metadata_group</span>
</span><span id="GroupCoordinator.recv_tensor_dict-1109"><a href="#GroupCoordinator.recv_tensor_dict-1109"><span class="linenos">1109</span></a>                    <span class="p">)</span>
</span><span id="GroupCoordinator.recv_tensor_dict-1110"><a href="#GroupCoordinator.recv_tensor_dict-1110"><span class="linenos">1110</span></a>                <span class="k">else</span><span class="p">:</span>
</span><span id="GroupCoordinator.recv_tensor_dict-1111"><a href="#GroupCoordinator.recv_tensor_dict-1111"><span class="linenos">1111</span></a>                    <span class="c1"># use group for GPU tensors</span>
</span><span id="GroupCoordinator.recv_tensor_dict-1112"><a href="#GroupCoordinator.recv_tensor_dict-1112"><span class="linenos">1112</span></a>                    <span class="n">torch</span><span class="o">.</span><span class="n">distributed</span><span class="o">.</span><span class="n">recv</span><span class="p">(</span><span class="n">tensor</span><span class="p">,</span> <span class="n">src</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">ranks</span><span class="p">[</span><span class="n">src</span><span class="p">],</span> <span class="n">group</span><span class="o">=</span><span class="n">group</span><span class="p">)</span>
</span><span id="GroupCoordinator.recv_tensor_dict-1113"><a href="#GroupCoordinator.recv_tensor_dict-1113"><span class="linenos">1113</span></a>                <span class="k">if</span> <span class="n">use_all_gather</span><span class="p">:</span>
</span><span id="GroupCoordinator.recv_tensor_dict-1114"><a href="#GroupCoordinator.recv_tensor_dict-1114"><span class="linenos">1114</span></a>                    <span class="c1"># do the allgather</span>
</span><span id="GroupCoordinator.recv_tensor_dict-1115"><a href="#GroupCoordinator.recv_tensor_dict-1115"><span class="linenos">1115</span></a>                    <span class="n">tensor</span> <span class="o">=</span> <span class="n">all_gather_group</span><span class="o">.</span><span class="n">all_gather</span><span class="p">(</span><span class="n">tensor</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>  <span class="c1"># type: ignore</span>
</span><span id="GroupCoordinator.recv_tensor_dict-1116"><a href="#GroupCoordinator.recv_tensor_dict-1116"><span class="linenos">1116</span></a>                    <span class="n">tensor</span> <span class="o">=</span> <span class="n">tensor</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">orig_shape</span><span class="p">)</span>
</span><span id="GroupCoordinator.recv_tensor_dict-1117"><a href="#GroupCoordinator.recv_tensor_dict-1117"><span class="linenos">1117</span></a>
</span><span id="GroupCoordinator.recv_tensor_dict-1118"><a href="#GroupCoordinator.recv_tensor_dict-1118"><span class="linenos">1118</span></a>                <span class="n">tensor_dict</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">=</span> <span class="n">tensor</span>
</span><span id="GroupCoordinator.recv_tensor_dict-1119"><a href="#GroupCoordinator.recv_tensor_dict-1119"><span class="linenos">1119</span></a>            <span class="k">else</span><span class="p">:</span>
</span><span id="GroupCoordinator.recv_tensor_dict-1120"><a href="#GroupCoordinator.recv_tensor_dict-1120"><span class="linenos">1120</span></a>                <span class="n">tensor_dict</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">=</span> <span class="n">value</span>
</span><span id="GroupCoordinator.recv_tensor_dict-1121"><a href="#GroupCoordinator.recv_tensor_dict-1121"><span class="linenos">1121</span></a>        <span class="k">return</span> <span class="n">tensor_dict</span>
</span></pre></div>


            <div class="docstring"><p>Recv the input tensor dictionary.
NOTE: <code>src</code> is the local rank of the source rank.</p>
</div>


                            </div>
                            <div id="GroupCoordinator.barrier" class="classattr">
                                        <input id="GroupCoordinator.barrier-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="def">def</span>
        <span class="name">barrier</span><span class="signature pdoc-code condensed">(<span class="param"><span class="bp">self</span></span><span class="return-annotation">):</span></span>

                <label class="view-source-button" for="GroupCoordinator.barrier-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#GroupCoordinator.barrier"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="GroupCoordinator.barrier-1123"><a href="#GroupCoordinator.barrier-1123"><span class="linenos">1123</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">barrier</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
</span><span id="GroupCoordinator.barrier-1124"><a href="#GroupCoordinator.barrier-1124"><span class="linenos">1124</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;Barrier synchronization among the group.</span>
</span><span id="GroupCoordinator.barrier-1125"><a href="#GroupCoordinator.barrier-1125"><span class="linenos">1125</span></a><span class="sd">        NOTE: don&#39;t use `device_group` here! `barrier` in NCCL is</span>
</span><span id="GroupCoordinator.barrier-1126"><a href="#GroupCoordinator.barrier-1126"><span class="linenos">1126</span></a><span class="sd">        terrible because it is internally a broadcast operation with</span>
</span><span id="GroupCoordinator.barrier-1127"><a href="#GroupCoordinator.barrier-1127"><span class="linenos">1127</span></a><span class="sd">        secretly created GPU tensors. It is easy to mess up the current</span>
</span><span id="GroupCoordinator.barrier-1128"><a href="#GroupCoordinator.barrier-1128"><span class="linenos">1128</span></a><span class="sd">        device. Use the CPU group instead.</span>
</span><span id="GroupCoordinator.barrier-1129"><a href="#GroupCoordinator.barrier-1129"><span class="linenos">1129</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="GroupCoordinator.barrier-1130"><a href="#GroupCoordinator.barrier-1130"><span class="linenos">1130</span></a>        <span class="n">torch</span><span class="o">.</span><span class="n">distributed</span><span class="o">.</span><span class="n">barrier</span><span class="p">(</span><span class="n">group</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">cpu_group</span><span class="p">)</span>
</span></pre></div>


            <div class="docstring"><p>Barrier synchronization among the group.
NOTE: don't use <code><a href="#GroupCoordinator.device_group">device_group</a></code> here! <code><a href="#GroupCoordinator.barrier">barrier</a></code> in NCCL is
terrible because it is internally a broadcast operation with
secretly created GPU tensors. It is easy to mess up the current
device. Use the CPU group instead.</p>
</div>


                            </div>
                            <div id="GroupCoordinator.send" class="classattr">
                                        <input id="GroupCoordinator.send-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="def">def</span>
        <span class="name">send</span><span class="signature pdoc-code condensed">(<span class="param"><span class="bp">self</span>, </span><span class="param"><span class="n">tensor</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span>, </span><span class="param"><span class="n">dst</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span></span><span class="return-annotation">) -> <span class="kc">None</span>:</span></span>

                <label class="view-source-button" for="GroupCoordinator.send-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#GroupCoordinator.send"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="GroupCoordinator.send-1132"><a href="#GroupCoordinator.send-1132"><span class="linenos">1132</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">send</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">tensor</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">dst</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="GroupCoordinator.send-1133"><a href="#GroupCoordinator.send-1133"><span class="linenos">1133</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;Sends a tensor to the destination rank in a non-blocking way&quot;&quot;&quot;</span>
</span><span id="GroupCoordinator.send-1134"><a href="#GroupCoordinator.send-1134"><span class="linenos">1134</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;NOTE: `dst` is the local rank of the destination rank.&quot;&quot;&quot;</span>
</span><span id="GroupCoordinator.send-1135"><a href="#GroupCoordinator.send-1135"><span class="linenos">1135</span></a>        <span class="k">if</span> <span class="n">dst</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="GroupCoordinator.send-1136"><a href="#GroupCoordinator.send-1136"><span class="linenos">1136</span></a>            <span class="n">dst</span> <span class="o">=</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">rank_in_group</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">%</span> <span class="bp">self</span><span class="o">.</span><span class="n">world_size</span>
</span><span id="GroupCoordinator.send-1137"><a href="#GroupCoordinator.send-1137"><span class="linenos">1137</span></a>
</span><span id="GroupCoordinator.send-1138"><a href="#GroupCoordinator.send-1138"><span class="linenos">1138</span></a>        <span class="n">pynccl_comm</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">pynccl_comm</span>
</span><span id="GroupCoordinator.send-1139"><a href="#GroupCoordinator.send-1139"><span class="linenos">1139</span></a>        <span class="k">if</span> <span class="n">pynccl_comm</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">pynccl_comm</span><span class="o">.</span><span class="n">disabled</span><span class="p">:</span>
</span><span id="GroupCoordinator.send-1140"><a href="#GroupCoordinator.send-1140"><span class="linenos">1140</span></a>            <span class="n">pynccl_comm</span><span class="o">.</span><span class="n">send</span><span class="p">(</span><span class="n">tensor</span><span class="p">,</span> <span class="n">dst</span><span class="p">)</span>
</span><span id="GroupCoordinator.send-1141"><a href="#GroupCoordinator.send-1141"><span class="linenos">1141</span></a>        <span class="k">else</span><span class="p">:</span>
</span><span id="GroupCoordinator.send-1142"><a href="#GroupCoordinator.send-1142"><span class="linenos">1142</span></a>            <span class="n">torch</span><span class="o">.</span><span class="n">distributed</span><span class="o">.</span><span class="n">send</span><span class="p">(</span><span class="n">tensor</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">ranks</span><span class="p">[</span><span class="n">dst</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">device_group</span><span class="p">)</span>
</span></pre></div>


            <div class="docstring"><p>Sends a tensor to the destination rank in a non-blocking way</p>
</div>


                            </div>
                            <div id="GroupCoordinator.recv" class="classattr">
                                        <input id="GroupCoordinator.recv-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="def">def</span>
        <span class="name">recv</span><span class="signature pdoc-code multiline">(<span class="param">	<span class="bp">self</span>,</span><span class="param">	<span class="n">size</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Size</span>,</span><span class="param">	<span class="n">dtype</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">dtype</span>,</span><span class="param">	<span class="n">src</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span></span><span class="return-annotation">) -> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span>:</span></span>

                <label class="view-source-button" for="GroupCoordinator.recv-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#GroupCoordinator.recv"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="GroupCoordinator.recv-1144"><a href="#GroupCoordinator.recv-1144"><span class="linenos">1144</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">recv</span><span class="p">(</span>
</span><span id="GroupCoordinator.recv-1145"><a href="#GroupCoordinator.recv-1145"><span class="linenos">1145</span></a>        <span class="bp">self</span><span class="p">,</span> <span class="n">size</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">,</span> <span class="n">dtype</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="n">src</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
</span><span id="GroupCoordinator.recv-1146"><a href="#GroupCoordinator.recv-1146"><span class="linenos">1146</span></a>    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
</span><span id="GroupCoordinator.recv-1147"><a href="#GroupCoordinator.recv-1147"><span class="linenos">1147</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;Receives a tensor from the source rank.&quot;&quot;&quot;</span>
</span><span id="GroupCoordinator.recv-1148"><a href="#GroupCoordinator.recv-1148"><span class="linenos">1148</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;NOTE: `src` is the local rank of the source rank.&quot;&quot;&quot;</span>
</span><span id="GroupCoordinator.recv-1149"><a href="#GroupCoordinator.recv-1149"><span class="linenos">1149</span></a>        <span class="k">if</span> <span class="n">src</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="GroupCoordinator.recv-1150"><a href="#GroupCoordinator.recv-1150"><span class="linenos">1150</span></a>            <span class="n">src</span> <span class="o">=</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">rank_in_group</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">%</span> <span class="bp">self</span><span class="o">.</span><span class="n">world_size</span>
</span><span id="GroupCoordinator.recv-1151"><a href="#GroupCoordinator.recv-1151"><span class="linenos">1151</span></a>
</span><span id="GroupCoordinator.recv-1152"><a href="#GroupCoordinator.recv-1152"><span class="linenos">1152</span></a>        <span class="n">tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span><span class="n">size</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
</span><span id="GroupCoordinator.recv-1153"><a href="#GroupCoordinator.recv-1153"><span class="linenos">1153</span></a>        <span class="n">pynccl_comm</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">pynccl_comm</span>
</span><span id="GroupCoordinator.recv-1154"><a href="#GroupCoordinator.recv-1154"><span class="linenos">1154</span></a>        <span class="k">if</span> <span class="n">pynccl_comm</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">pynccl_comm</span><span class="o">.</span><span class="n">disabled</span><span class="p">:</span>
</span><span id="GroupCoordinator.recv-1155"><a href="#GroupCoordinator.recv-1155"><span class="linenos">1155</span></a>            <span class="n">pynccl_comm</span><span class="o">.</span><span class="n">recv</span><span class="p">(</span><span class="n">tensor</span><span class="p">,</span> <span class="n">src</span><span class="p">)</span>
</span><span id="GroupCoordinator.recv-1156"><a href="#GroupCoordinator.recv-1156"><span class="linenos">1156</span></a>        <span class="k">else</span><span class="p">:</span>
</span><span id="GroupCoordinator.recv-1157"><a href="#GroupCoordinator.recv-1157"><span class="linenos">1157</span></a>            <span class="n">torch</span><span class="o">.</span><span class="n">distributed</span><span class="o">.</span><span class="n">recv</span><span class="p">(</span><span class="n">tensor</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">ranks</span><span class="p">[</span><span class="n">src</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">device_group</span><span class="p">)</span>
</span><span id="GroupCoordinator.recv-1158"><a href="#GroupCoordinator.recv-1158"><span class="linenos">1158</span></a>        <span class="k">return</span> <span class="n">tensor</span>
</span></pre></div>


            <div class="docstring"><p>Receives a tensor from the source rank.</p>
</div>


                            </div>
                            <div id="GroupCoordinator.destroy" class="classattr">
                                        <input id="GroupCoordinator.destroy-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="def">def</span>
        <span class="name">destroy</span><span class="signature pdoc-code condensed">(<span class="param"><span class="bp">self</span></span><span class="return-annotation">):</span></span>

                <label class="view-source-button" for="GroupCoordinator.destroy-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#GroupCoordinator.destroy"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="GroupCoordinator.destroy-1160"><a href="#GroupCoordinator.destroy-1160"><span class="linenos">1160</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">destroy</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
</span><span id="GroupCoordinator.destroy-1161"><a href="#GroupCoordinator.destroy-1161"><span class="linenos">1161</span></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">device_group</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="GroupCoordinator.destroy-1162"><a href="#GroupCoordinator.destroy-1162"><span class="linenos">1162</span></a>            <span class="n">torch</span><span class="o">.</span><span class="n">distributed</span><span class="o">.</span><span class="n">destroy_process_group</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device_group</span><span class="p">)</span>
</span><span id="GroupCoordinator.destroy-1163"><a href="#GroupCoordinator.destroy-1163"><span class="linenos">1163</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">device_group</span> <span class="o">=</span> <span class="kc">None</span>
</span><span id="GroupCoordinator.destroy-1164"><a href="#GroupCoordinator.destroy-1164"><span class="linenos">1164</span></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">cpu_group</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="GroupCoordinator.destroy-1165"><a href="#GroupCoordinator.destroy-1165"><span class="linenos">1165</span></a>            <span class="n">torch</span><span class="o">.</span><span class="n">distributed</span><span class="o">.</span><span class="n">destroy_process_group</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">cpu_group</span><span class="p">)</span>
</span><span id="GroupCoordinator.destroy-1166"><a href="#GroupCoordinator.destroy-1166"><span class="linenos">1166</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">cpu_group</span> <span class="o">=</span> <span class="kc">None</span>
</span><span id="GroupCoordinator.destroy-1167"><a href="#GroupCoordinator.destroy-1167"><span class="linenos">1167</span></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">pynccl_comm</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="GroupCoordinator.destroy-1168"><a href="#GroupCoordinator.destroy-1168"><span class="linenos">1168</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">pynccl_comm</span> <span class="o">=</span> <span class="kc">None</span>
</span><span id="GroupCoordinator.destroy-1169"><a href="#GroupCoordinator.destroy-1169"><span class="linenos">1169</span></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">ca_comm</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="GroupCoordinator.destroy-1170"><a href="#GroupCoordinator.destroy-1170"><span class="linenos">1170</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">ca_comm</span> <span class="o">=</span> <span class="kc">None</span>
</span><span id="GroupCoordinator.destroy-1171"><a href="#GroupCoordinator.destroy-1171"><span class="linenos">1171</span></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">mq_broadcaster</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="GroupCoordinator.destroy-1172"><a href="#GroupCoordinator.destroy-1172"><span class="linenos">1172</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">mq_broadcaster</span> <span class="o">=</span> <span class="kc">None</span>
</span></pre></div>


    

                            </div>
                </section>
                <section id="get_world_group">
                            <input id="get_world_group-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="def">def</span>
        <span class="name">get_world_group</span><span class="signature pdoc-code condensed">(<span class="return-annotation">) -> <span class="n"><a href="#GroupCoordinator">GroupCoordinator</a></span>:</span></span>

                <label class="view-source-button" for="get_world_group-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#get_world_group"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="get_world_group-1178"><a href="#get_world_group-1178"><span class="linenos">1178</span></a><span class="k">def</span><span class="w"> </span><span class="nf">get_world_group</span><span class="p">()</span> <span class="o">-&gt;</span> <span class="n">GroupCoordinator</span><span class="p">:</span>
</span><span id="get_world_group-1179"><a href="#get_world_group-1179"><span class="linenos">1179</span></a>    <span class="k">assert</span> <span class="n">_WORLD</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">,</span> <span class="s2">&quot;world group is not initialized&quot;</span>
</span><span id="get_world_group-1180"><a href="#get_world_group-1180"><span class="linenos">1180</span></a>    <span class="k">return</span> <span class="n">_WORLD</span>
</span></pre></div>


    

                </section>
                <section id="init_world_group">
                            <input id="init_world_group-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="def">def</span>
        <span class="name">init_world_group</span><span class="signature pdoc-code multiline">(<span class="param">	<span class="n">ranks</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span>,</span><span class="param">	<span class="n">local_rank</span><span class="p">:</span> <span class="nb">int</span>,</span><span class="param">	<span class="n">backend</span><span class="p">:</span> <span class="nb">str</span></span><span class="return-annotation">) -> <span class="n"><a href="#GroupCoordinator">GroupCoordinator</a></span>:</span></span>

                <label class="view-source-button" for="init_world_group-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#init_world_group"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="init_world_group-1183"><a href="#init_world_group-1183"><span class="linenos">1183</span></a><span class="k">def</span><span class="w"> </span><span class="nf">init_world_group</span><span class="p">(</span>
</span><span id="init_world_group-1184"><a href="#init_world_group-1184"><span class="linenos">1184</span></a>    <span class="n">ranks</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">int</span><span class="p">],</span> <span class="n">local_rank</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">backend</span><span class="p">:</span> <span class="nb">str</span>
</span><span id="init_world_group-1185"><a href="#init_world_group-1185"><span class="linenos">1185</span></a><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">GroupCoordinator</span><span class="p">:</span>
</span><span id="init_world_group-1186"><a href="#init_world_group-1186"><span class="linenos">1186</span></a>    <span class="k">return</span> <span class="n">GroupCoordinator</span><span class="p">(</span>
</span><span id="init_world_group-1187"><a href="#init_world_group-1187"><span class="linenos">1187</span></a>        <span class="n">group_ranks</span><span class="o">=</span><span class="p">[</span><span class="n">ranks</span><span class="p">],</span>
</span><span id="init_world_group-1188"><a href="#init_world_group-1188"><span class="linenos">1188</span></a>        <span class="n">local_rank</span><span class="o">=</span><span class="n">local_rank</span><span class="p">,</span>
</span><span id="init_world_group-1189"><a href="#init_world_group-1189"><span class="linenos">1189</span></a>        <span class="n">torch_distributed_backend</span><span class="o">=</span><span class="n">backend</span><span class="p">,</span>
</span><span id="init_world_group-1190"><a href="#init_world_group-1190"><span class="linenos">1190</span></a>        <span class="n">use_pynccl</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
</span><span id="init_world_group-1191"><a href="#init_world_group-1191"><span class="linenos">1191</span></a>        <span class="n">use_pymscclpp</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
</span><span id="init_world_group-1192"><a href="#init_world_group-1192"><span class="linenos">1192</span></a>        <span class="n">use_custom_allreduce</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
</span><span id="init_world_group-1193"><a href="#init_world_group-1193"><span class="linenos">1193</span></a>        <span class="n">use_hpu_communicator</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
</span><span id="init_world_group-1194"><a href="#init_world_group-1194"><span class="linenos">1194</span></a>        <span class="n">use_xpu_communicator</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
</span><span id="init_world_group-1195"><a href="#init_world_group-1195"><span class="linenos">1195</span></a>        <span class="n">use_npu_communicator</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
</span><span id="init_world_group-1196"><a href="#init_world_group-1196"><span class="linenos">1196</span></a>        <span class="n">group_name</span><span class="o">=</span><span class="s2">&quot;world&quot;</span><span class="p">,</span>
</span><span id="init_world_group-1197"><a href="#init_world_group-1197"><span class="linenos">1197</span></a>    <span class="p">)</span>
</span></pre></div>


    

                </section>
                <section id="init_model_parallel_group">
                            <input id="init_model_parallel_group-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="def">def</span>
        <span class="name">init_model_parallel_group</span><span class="signature pdoc-code multiline">(<span class="param">	<span class="n">group_ranks</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="nb">int</span><span class="p">]]</span>,</span><span class="param">	<span class="n">local_rank</span><span class="p">:</span> <span class="nb">int</span>,</span><span class="param">	<span class="n">backend</span><span class="p">:</span> <span class="nb">str</span>,</span><span class="param">	<span class="n">use_custom_allreduce</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">bool</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>,</span><span class="param">	<span class="n">use_message_queue_broadcaster</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span>,</span><span class="param">	<span class="n">group_name</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>,</span><span class="param">	<span class="n">use_mscclpp_allreduce</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">bool</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span></span><span class="return-annotation">) -> <span class="n"><a href="#GroupCoordinator">GroupCoordinator</a></span>:</span></span>

                <label class="view-source-button" for="init_model_parallel_group-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#init_model_parallel_group"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="init_model_parallel_group-1200"><a href="#init_model_parallel_group-1200"><span class="linenos">1200</span></a><span class="k">def</span><span class="w"> </span><span class="nf">init_model_parallel_group</span><span class="p">(</span>
</span><span id="init_model_parallel_group-1201"><a href="#init_model_parallel_group-1201"><span class="linenos">1201</span></a>    <span class="n">group_ranks</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="nb">int</span><span class="p">]],</span>
</span><span id="init_model_parallel_group-1202"><a href="#init_model_parallel_group-1202"><span class="linenos">1202</span></a>    <span class="n">local_rank</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
</span><span id="init_model_parallel_group-1203"><a href="#init_model_parallel_group-1203"><span class="linenos">1203</span></a>    <span class="n">backend</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
</span><span id="init_model_parallel_group-1204"><a href="#init_model_parallel_group-1204"><span class="linenos">1204</span></a>    <span class="n">use_custom_allreduce</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">bool</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="init_model_parallel_group-1205"><a href="#init_model_parallel_group-1205"><span class="linenos">1205</span></a>    <span class="n">use_message_queue_broadcaster</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
</span><span id="init_model_parallel_group-1206"><a href="#init_model_parallel_group-1206"><span class="linenos">1206</span></a>    <span class="n">group_name</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="init_model_parallel_group-1207"><a href="#init_model_parallel_group-1207"><span class="linenos">1207</span></a>    <span class="n">use_mscclpp_allreduce</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">bool</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="init_model_parallel_group-1208"><a href="#init_model_parallel_group-1208"><span class="linenos">1208</span></a><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">GroupCoordinator</span><span class="p">:</span>
</span><span id="init_model_parallel_group-1209"><a href="#init_model_parallel_group-1209"><span class="linenos">1209</span></a>    <span class="k">if</span> <span class="n">use_custom_allreduce</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="init_model_parallel_group-1210"><a href="#init_model_parallel_group-1210"><span class="linenos">1210</span></a>        <span class="n">use_custom_allreduce</span> <span class="o">=</span> <span class="n">_ENABLE_CUSTOM_ALL_REDUCE</span>
</span><span id="init_model_parallel_group-1211"><a href="#init_model_parallel_group-1211"><span class="linenos">1211</span></a>    <span class="k">if</span> <span class="n">use_mscclpp_allreduce</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="init_model_parallel_group-1212"><a href="#init_model_parallel_group-1212"><span class="linenos">1212</span></a>        <span class="n">use_mscclpp_allreduce</span> <span class="o">=</span> <span class="n">_ENABLE_MSCCLPP_ALL_REDUCE</span>
</span><span id="init_model_parallel_group-1213"><a href="#init_model_parallel_group-1213"><span class="linenos">1213</span></a>    <span class="k">return</span> <span class="n">GroupCoordinator</span><span class="p">(</span>
</span><span id="init_model_parallel_group-1214"><a href="#init_model_parallel_group-1214"><span class="linenos">1214</span></a>        <span class="n">group_ranks</span><span class="o">=</span><span class="n">group_ranks</span><span class="p">,</span>
</span><span id="init_model_parallel_group-1215"><a href="#init_model_parallel_group-1215"><span class="linenos">1215</span></a>        <span class="n">local_rank</span><span class="o">=</span><span class="n">local_rank</span><span class="p">,</span>
</span><span id="init_model_parallel_group-1216"><a href="#init_model_parallel_group-1216"><span class="linenos">1216</span></a>        <span class="n">torch_distributed_backend</span><span class="o">=</span><span class="n">backend</span><span class="p">,</span>
</span><span id="init_model_parallel_group-1217"><a href="#init_model_parallel_group-1217"><span class="linenos">1217</span></a>        <span class="n">use_pynccl</span><span class="o">=</span><span class="ow">not</span> <span class="n">_is_npu</span><span class="p">,</span>
</span><span id="init_model_parallel_group-1218"><a href="#init_model_parallel_group-1218"><span class="linenos">1218</span></a>        <span class="n">use_pymscclpp</span><span class="o">=</span><span class="n">use_mscclpp_allreduce</span><span class="p">,</span>
</span><span id="init_model_parallel_group-1219"><a href="#init_model_parallel_group-1219"><span class="linenos">1219</span></a>        <span class="n">use_custom_allreduce</span><span class="o">=</span><span class="n">use_custom_allreduce</span><span class="p">,</span>
</span><span id="init_model_parallel_group-1220"><a href="#init_model_parallel_group-1220"><span class="linenos">1220</span></a>        <span class="n">use_hpu_communicator</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
</span><span id="init_model_parallel_group-1221"><a href="#init_model_parallel_group-1221"><span class="linenos">1221</span></a>        <span class="n">use_xpu_communicator</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
</span><span id="init_model_parallel_group-1222"><a href="#init_model_parallel_group-1222"><span class="linenos">1222</span></a>        <span class="n">use_npu_communicator</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
</span><span id="init_model_parallel_group-1223"><a href="#init_model_parallel_group-1223"><span class="linenos">1223</span></a>        <span class="n">use_message_queue_broadcaster</span><span class="o">=</span><span class="n">use_message_queue_broadcaster</span><span class="p">,</span>
</span><span id="init_model_parallel_group-1224"><a href="#init_model_parallel_group-1224"><span class="linenos">1224</span></a>        <span class="n">group_name</span><span class="o">=</span><span class="n">group_name</span><span class="p">,</span>
</span><span id="init_model_parallel_group-1225"><a href="#init_model_parallel_group-1225"><span class="linenos">1225</span></a>    <span class="p">)</span>
</span></pre></div>


    

                </section>
                <section id="set_pdmux_status">
                            <input id="set_pdmux_status-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="def">def</span>
        <span class="name">set_pdmux_status</span><span class="signature pdoc-code condensed">(<span class="param"><span class="n">enable_prefill_multiplexing</span><span class="p">:</span> <span class="nb">bool</span></span><span class="return-annotation">):</span></span>

                <label class="view-source-button" for="set_pdmux_status-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#set_pdmux_status"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="set_pdmux_status-1236"><a href="#set_pdmux_status-1236"><span class="linenos">1236</span></a><span class="k">def</span><span class="w"> </span><span class="nf">set_pdmux_status</span><span class="p">(</span><span class="n">enable_prefill_multiplexing</span><span class="p">:</span> <span class="nb">bool</span><span class="p">):</span>
</span><span id="set_pdmux_status-1237"><a href="#set_pdmux_status-1237"><span class="linenos">1237</span></a>    <span class="k">global</span> <span class="n">_ENABLE_PDMUX_P_TP</span>
</span><span id="set_pdmux_status-1238"><a href="#set_pdmux_status-1238"><span class="linenos">1238</span></a>    <span class="n">_ENABLE_PDMUX_P_TP</span> <span class="o">=</span> <span class="n">enable_prefill_multiplexing</span>
</span></pre></div>


    

                </section>
                <section id="get_tp_group">
                            <input id="get_tp_group-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="def">def</span>
        <span class="name">get_tp_group</span><span class="signature pdoc-code condensed">(<span class="return-annotation">) -> <span class="n"><a href="#GroupCoordinator">GroupCoordinator</a></span>:</span></span>

                <label class="view-source-button" for="get_tp_group-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#get_tp_group"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="get_tp_group-1241"><a href="#get_tp_group-1241"><span class="linenos">1241</span></a><span class="k">def</span><span class="w"> </span><span class="nf">get_tp_group</span><span class="p">()</span> <span class="o">-&gt;</span> <span class="n">GroupCoordinator</span><span class="p">:</span>
</span><span id="get_tp_group-1242"><a href="#get_tp_group-1242"><span class="linenos">1242</span></a>    <span class="k">if</span> <span class="n">_ENABLE_PDMUX_P_TP</span><span class="p">:</span>
</span><span id="get_tp_group-1243"><a href="#get_tp_group-1243"><span class="linenos">1243</span></a>        <span class="k">assert</span> <span class="p">(</span>
</span><span id="get_tp_group-1244"><a href="#get_tp_group-1244"><span class="linenos">1244</span></a>            <span class="n">_PDMUX_PREFILL_TP_GROUP</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
</span><span id="get_tp_group-1245"><a href="#get_tp_group-1245"><span class="linenos">1245</span></a>        <span class="p">),</span> <span class="s2">&quot;tensor model parallel group for PD-Multiplexing Prefill is not initialized&quot;</span>
</span><span id="get_tp_group-1246"><a href="#get_tp_group-1246"><span class="linenos">1246</span></a>        <span class="k">return</span> <span class="n">_PDMUX_PREFILL_TP_GROUP</span>
</span><span id="get_tp_group-1247"><a href="#get_tp_group-1247"><span class="linenos">1247</span></a>    <span class="k">assert</span> <span class="n">_TP</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">,</span> <span class="s2">&quot;tensor model parallel group is not initialized&quot;</span>
</span><span id="get_tp_group-1248"><a href="#get_tp_group-1248"><span class="linenos">1248</span></a>    <span class="k">return</span> <span class="n">_TP</span>
</span></pre></div>


    

                </section>
                <section id="get_moe_ep_group">
                            <input id="get_moe_ep_group-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="def">def</span>
        <span class="name">get_moe_ep_group</span><span class="signature pdoc-code condensed">(<span class="return-annotation">) -> <span class="n"><a href="#GroupCoordinator">GroupCoordinator</a></span>:</span></span>

                <label class="view-source-button" for="get_moe_ep_group-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#get_moe_ep_group"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="get_moe_ep_group-1255"><a href="#get_moe_ep_group-1255"><span class="linenos">1255</span></a><span class="k">def</span><span class="w"> </span><span class="nf">get_moe_ep_group</span><span class="p">()</span> <span class="o">-&gt;</span> <span class="n">GroupCoordinator</span><span class="p">:</span>
</span><span id="get_moe_ep_group-1256"><a href="#get_moe_ep_group-1256"><span class="linenos">1256</span></a>    <span class="k">assert</span> <span class="n">_MOE_EP</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">,</span> <span class="s2">&quot;expert model parallel group is not initialized&quot;</span>
</span><span id="get_moe_ep_group-1257"><a href="#get_moe_ep_group-1257"><span class="linenos">1257</span></a>    <span class="k">return</span> <span class="n">_MOE_EP</span>
</span></pre></div>


    

                </section>
                <section id="get_moe_tp_group">
                            <input id="get_moe_tp_group-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="def">def</span>
        <span class="name">get_moe_tp_group</span><span class="signature pdoc-code condensed">(<span class="return-annotation">) -> <span class="n"><a href="#GroupCoordinator">GroupCoordinator</a></span>:</span></span>

                <label class="view-source-button" for="get_moe_tp_group-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#get_moe_tp_group"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="get_moe_tp_group-1260"><a href="#get_moe_tp_group-1260"><span class="linenos">1260</span></a><span class="k">def</span><span class="w"> </span><span class="nf">get_moe_tp_group</span><span class="p">()</span> <span class="o">-&gt;</span> <span class="n">GroupCoordinator</span><span class="p">:</span>
</span><span id="get_moe_tp_group-1261"><a href="#get_moe_tp_group-1261"><span class="linenos">1261</span></a>    <span class="k">assert</span> <span class="n">_MOE_TP</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">,</span> <span class="s2">&quot;expert model parallel group is not initialized&quot;</span>
</span><span id="get_moe_tp_group-1262"><a href="#get_moe_tp_group-1262"><span class="linenos">1262</span></a>    <span class="k">return</span> <span class="n">_MOE_TP</span>
</span></pre></div>


    

                </section>
                <section id="get_tensor_model_parallel_group">
                            <input id="get_tensor_model_parallel_group-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="def">def</span>
        <span class="name">get_tensor_model_parallel_group</span><span class="signature pdoc-code condensed">(<span class="return-annotation">) -> <span class="n"><a href="#GroupCoordinator">GroupCoordinator</a></span>:</span></span>

                <label class="view-source-button" for="get_tensor_model_parallel_group-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#get_tensor_model_parallel_group"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="get_tensor_model_parallel_group-1241"><a href="#get_tensor_model_parallel_group-1241"><span class="linenos">1241</span></a><span class="k">def</span><span class="w"> </span><span class="nf">get_tp_group</span><span class="p">()</span> <span class="o">-&gt;</span> <span class="n">GroupCoordinator</span><span class="p">:</span>
</span><span id="get_tensor_model_parallel_group-1242"><a href="#get_tensor_model_parallel_group-1242"><span class="linenos">1242</span></a>    <span class="k">if</span> <span class="n">_ENABLE_PDMUX_P_TP</span><span class="p">:</span>
</span><span id="get_tensor_model_parallel_group-1243"><a href="#get_tensor_model_parallel_group-1243"><span class="linenos">1243</span></a>        <span class="k">assert</span> <span class="p">(</span>
</span><span id="get_tensor_model_parallel_group-1244"><a href="#get_tensor_model_parallel_group-1244"><span class="linenos">1244</span></a>            <span class="n">_PDMUX_PREFILL_TP_GROUP</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
</span><span id="get_tensor_model_parallel_group-1245"><a href="#get_tensor_model_parallel_group-1245"><span class="linenos">1245</span></a>        <span class="p">),</span> <span class="s2">&quot;tensor model parallel group for PD-Multiplexing Prefill is not initialized&quot;</span>
</span><span id="get_tensor_model_parallel_group-1246"><a href="#get_tensor_model_parallel_group-1246"><span class="linenos">1246</span></a>        <span class="k">return</span> <span class="n">_PDMUX_PREFILL_TP_GROUP</span>
</span><span id="get_tensor_model_parallel_group-1247"><a href="#get_tensor_model_parallel_group-1247"><span class="linenos">1247</span></a>    <span class="k">assert</span> <span class="n">_TP</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">,</span> <span class="s2">&quot;tensor model parallel group is not initialized&quot;</span>
</span><span id="get_tensor_model_parallel_group-1248"><a href="#get_tensor_model_parallel_group-1248"><span class="linenos">1248</span></a>    <span class="k">return</span> <span class="n">_TP</span>
</span></pre></div>


    

                </section>
                <section id="get_pp_group">
                            <input id="get_pp_group-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="def">def</span>
        <span class="name">get_pp_group</span><span class="signature pdoc-code condensed">(<span class="return-annotation">) -> <span class="n"><a href="#GroupCoordinator">GroupCoordinator</a></span>:</span></span>

                <label class="view-source-button" for="get_pp_group-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#get_pp_group"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="get_pp_group-1271"><a href="#get_pp_group-1271"><span class="linenos">1271</span></a><span class="k">def</span><span class="w"> </span><span class="nf">get_pp_group</span><span class="p">()</span> <span class="o">-&gt;</span> <span class="n">GroupCoordinator</span><span class="p">:</span>
</span><span id="get_pp_group-1272"><a href="#get_pp_group-1272"><span class="linenos">1272</span></a>    <span class="k">assert</span> <span class="n">_PP</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">,</span> <span class="s2">&quot;pipeline model parallel group is not initialized&quot;</span>
</span><span id="get_pp_group-1273"><a href="#get_pp_group-1273"><span class="linenos">1273</span></a>    <span class="k">return</span> <span class="n">_PP</span>
</span></pre></div>


    

                </section>
                <section id="get_pipeline_model_parallel_group">
                            <input id="get_pipeline_model_parallel_group-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="def">def</span>
        <span class="name">get_pipeline_model_parallel_group</span><span class="signature pdoc-code condensed">(<span class="return-annotation">) -> <span class="n"><a href="#GroupCoordinator">GroupCoordinator</a></span>:</span></span>

                <label class="view-source-button" for="get_pipeline_model_parallel_group-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#get_pipeline_model_parallel_group"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="get_pipeline_model_parallel_group-1271"><a href="#get_pipeline_model_parallel_group-1271"><span class="linenos">1271</span></a><span class="k">def</span><span class="w"> </span><span class="nf">get_pp_group</span><span class="p">()</span> <span class="o">-&gt;</span> <span class="n">GroupCoordinator</span><span class="p">:</span>
</span><span id="get_pipeline_model_parallel_group-1272"><a href="#get_pipeline_model_parallel_group-1272"><span class="linenos">1272</span></a>    <span class="k">assert</span> <span class="n">_PP</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">,</span> <span class="s2">&quot;pipeline model parallel group is not initialized&quot;</span>
</span><span id="get_pipeline_model_parallel_group-1273"><a href="#get_pipeline_model_parallel_group-1273"><span class="linenos">1273</span></a>    <span class="k">return</span> <span class="n">_PP</span>
</span></pre></div>


    

                </section>
                <section id="graph_capture">
                            <input id="graph_capture-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
                    <div class="decorator decorator-contextmanager">@contextmanager</div>

        <span class="def">def</span>
        <span class="name">graph_capture</span><span class="signature pdoc-code condensed">(<span class="return-annotation">):</span></span>

                <label class="view-source-button" for="graph_capture-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#graph_capture"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="graph_capture-1280"><a href="#graph_capture-1280"><span class="linenos">1280</span></a><span class="nd">@contextmanager</span>
</span><span id="graph_capture-1281"><a href="#graph_capture-1281"><span class="linenos">1281</span></a><span class="k">def</span><span class="w"> </span><span class="nf">graph_capture</span><span class="p">():</span>
</span><span id="graph_capture-1282"><a href="#graph_capture-1282"><span class="linenos">1282</span></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="graph_capture-1283"><a href="#graph_capture-1283"><span class="linenos">1283</span></a><span class="sd">    `graph_capture` is a context manager which should surround the code that</span>
</span><span id="graph_capture-1284"><a href="#graph_capture-1284"><span class="linenos">1284</span></a><span class="sd">    is capturing the CUDA graph. Its main purpose is to ensure that the</span>
</span><span id="graph_capture-1285"><a href="#graph_capture-1285"><span class="linenos">1285</span></a><span class="sd">    some operations will be run after the graph is captured, before the graph</span>
</span><span id="graph_capture-1286"><a href="#graph_capture-1286"><span class="linenos">1286</span></a><span class="sd">    is replayed. It returns a `GraphCaptureContext` object which contains the</span>
</span><span id="graph_capture-1287"><a href="#graph_capture-1287"><span class="linenos">1287</span></a><span class="sd">    necessary data for the graph capture. Currently, it only contains the</span>
</span><span id="graph_capture-1288"><a href="#graph_capture-1288"><span class="linenos">1288</span></a><span class="sd">    stream that the graph capture is running on. This stream is set to the</span>
</span><span id="graph_capture-1289"><a href="#graph_capture-1289"><span class="linenos">1289</span></a><span class="sd">    current CUDA stream when the context manager is entered and reset to the</span>
</span><span id="graph_capture-1290"><a href="#graph_capture-1290"><span class="linenos">1290</span></a><span class="sd">    default stream when the context manager is exited. This is to ensure that</span>
</span><span id="graph_capture-1291"><a href="#graph_capture-1291"><span class="linenos">1291</span></a><span class="sd">    the graph capture is running on a separate stream from the default stream,</span>
</span><span id="graph_capture-1292"><a href="#graph_capture-1292"><span class="linenos">1292</span></a><span class="sd">    in order to explicitly distinguish the kernels to capture</span>
</span><span id="graph_capture-1293"><a href="#graph_capture-1293"><span class="linenos">1293</span></a><span class="sd">    from other kernels possibly launched on background in the default stream.</span>
</span><span id="graph_capture-1294"><a href="#graph_capture-1294"><span class="linenos">1294</span></a><span class="sd">    &quot;&quot;&quot;</span>
</span><span id="graph_capture-1295"><a href="#graph_capture-1295"><span class="linenos">1295</span></a>    <span class="k">with</span> <span class="n">get_tp_group</span><span class="p">()</span><span class="o">.</span><span class="n">graph_capture</span><span class="p">()</span> <span class="k">as</span> <span class="n">context</span><span class="p">,</span> <span class="n">get_pp_group</span><span class="p">()</span><span class="o">.</span><span class="n">graph_capture</span><span class="p">(</span>
</span><span id="graph_capture-1296"><a href="#graph_capture-1296"><span class="linenos">1296</span></a>        <span class="n">context</span>
</span><span id="graph_capture-1297"><a href="#graph_capture-1297"><span class="linenos">1297</span></a>    <span class="p">):</span>
</span><span id="graph_capture-1298"><a href="#graph_capture-1298"><span class="linenos">1298</span></a>        <span class="k">yield</span> <span class="n">context</span>
</span></pre></div>


            <div class="docstring"><p><code><a href="#graph_capture">graph_capture</a></code> is a context manager which should surround the code that
is capturing the CUDA graph. Its main purpose is to ensure that the
some operations will be run after the graph is captured, before the graph
is replayed. It returns a <code><a href="#GraphCaptureContext">GraphCaptureContext</a></code> object which contains the
necessary data for the graph capture. Currently, it only contains the
stream that the graph capture is running on. This stream is set to the
current CUDA stream when the context manager is entered and reset to the
default stream when the context manager is exited. This is to ensure that
the graph capture is running on a separate stream from the default stream,
in order to explicitly distinguish the kernels to capture
from other kernels possibly launched on background in the default stream.</p>
</div>


                </section>
                <section id="logger">
                    <div class="attr variable">
            <span class="name">logger</span>        =
<span class="default_value">&lt;Logger <a href="">sglang.srt.distributed.parallel_state</a> (WARNING)&gt;</span>

        
    </div>
    <a class="headerlink" href="#logger"></a>
    
    

                </section>
                <section id="set_custom_all_reduce">
                            <input id="set_custom_all_reduce-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="def">def</span>
        <span class="name">set_custom_all_reduce</span><span class="signature pdoc-code condensed">(<span class="param"><span class="n">enable</span><span class="p">:</span> <span class="nb">bool</span></span><span class="return-annotation">):</span></span>

                <label class="view-source-button" for="set_custom_all_reduce-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#set_custom_all_reduce"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="set_custom_all_reduce-1307"><a href="#set_custom_all_reduce-1307"><span class="linenos">1307</span></a><span class="k">def</span><span class="w"> </span><span class="nf">set_custom_all_reduce</span><span class="p">(</span><span class="n">enable</span><span class="p">:</span> <span class="nb">bool</span><span class="p">):</span>
</span><span id="set_custom_all_reduce-1308"><a href="#set_custom_all_reduce-1308"><span class="linenos">1308</span></a>    <span class="k">global</span> <span class="n">_ENABLE_CUSTOM_ALL_REDUCE</span>
</span><span id="set_custom_all_reduce-1309"><a href="#set_custom_all_reduce-1309"><span class="linenos">1309</span></a>    <span class="n">_ENABLE_CUSTOM_ALL_REDUCE</span> <span class="o">=</span> <span class="n">enable</span>
</span></pre></div>


    

                </section>
                <section id="set_mscclpp_all_reduce">
                            <input id="set_mscclpp_all_reduce-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="def">def</span>
        <span class="name">set_mscclpp_all_reduce</span><span class="signature pdoc-code condensed">(<span class="param"><span class="n">enable</span><span class="p">:</span> <span class="nb">bool</span></span><span class="return-annotation">):</span></span>

                <label class="view-source-button" for="set_mscclpp_all_reduce-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#set_mscclpp_all_reduce"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="set_mscclpp_all_reduce-1312"><a href="#set_mscclpp_all_reduce-1312"><span class="linenos">1312</span></a><span class="k">def</span><span class="w"> </span><span class="nf">set_mscclpp_all_reduce</span><span class="p">(</span><span class="n">enable</span><span class="p">:</span> <span class="nb">bool</span><span class="p">):</span>
</span><span id="set_mscclpp_all_reduce-1313"><a href="#set_mscclpp_all_reduce-1313"><span class="linenos">1313</span></a>    <span class="k">global</span> <span class="n">_ENABLE_MSCCLPP_ALL_REDUCE</span>
</span><span id="set_mscclpp_all_reduce-1314"><a href="#set_mscclpp_all_reduce-1314"><span class="linenos">1314</span></a>    <span class="n">_ENABLE_MSCCLPP_ALL_REDUCE</span> <span class="o">=</span> <span class="n">enable</span>
</span></pre></div>


    

                </section>
                <section id="init_distributed_environment">
                            <input id="init_distributed_environment-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="def">def</span>
        <span class="name">init_distributed_environment</span><span class="signature pdoc-code multiline">(<span class="param">	<span class="n">world_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span>,</span><span class="param">	<span class="n">rank</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span>,</span><span class="param">	<span class="n">distributed_init_method</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s1">&#39;env://&#39;</span>,</span><span class="param">	<span class="n">local_rank</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span>,</span><span class="param">	<span class="n">backend</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s1">&#39;nccl&#39;</span>,</span><span class="param">	<span class="n">timeout</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span></span><span class="return-annotation">):</span></span>

                <label class="view-source-button" for="init_distributed_environment-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#init_distributed_environment"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="init_distributed_environment-1317"><a href="#init_distributed_environment-1317"><span class="linenos">1317</span></a><span class="k">def</span><span class="w"> </span><span class="nf">init_distributed_environment</span><span class="p">(</span>
</span><span id="init_distributed_environment-1318"><a href="#init_distributed_environment-1318"><span class="linenos">1318</span></a>    <span class="n">world_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
</span><span id="init_distributed_environment-1319"><a href="#init_distributed_environment-1319"><span class="linenos">1319</span></a>    <span class="n">rank</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
</span><span id="init_distributed_environment-1320"><a href="#init_distributed_environment-1320"><span class="linenos">1320</span></a>    <span class="n">distributed_init_method</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;env://&quot;</span><span class="p">,</span>
</span><span id="init_distributed_environment-1321"><a href="#init_distributed_environment-1321"><span class="linenos">1321</span></a>    <span class="n">local_rank</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
</span><span id="init_distributed_environment-1322"><a href="#init_distributed_environment-1322"><span class="linenos">1322</span></a>    <span class="n">backend</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;nccl&quot;</span><span class="p">,</span>
</span><span id="init_distributed_environment-1323"><a href="#init_distributed_environment-1323"><span class="linenos">1323</span></a>    <span class="n">timeout</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="init_distributed_environment-1324"><a href="#init_distributed_environment-1324"><span class="linenos">1324</span></a><span class="p">):</span>
</span><span id="init_distributed_environment-1325"><a href="#init_distributed_environment-1325"><span class="linenos">1325</span></a>    <span class="n">logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span>
</span><span id="init_distributed_environment-1326"><a href="#init_distributed_environment-1326"><span class="linenos">1326</span></a>        <span class="s2">&quot;world_size=</span><span class="si">%d</span><span class="s2"> rank=</span><span class="si">%d</span><span class="s2"> local_rank=</span><span class="si">%d</span><span class="s2"> &quot;</span> <span class="s2">&quot;distributed_init_method=</span><span class="si">%s</span><span class="s2"> backend=</span><span class="si">%s</span><span class="s2">&quot;</span><span class="p">,</span>
</span><span id="init_distributed_environment-1327"><a href="#init_distributed_environment-1327"><span class="linenos">1327</span></a>        <span class="n">world_size</span><span class="p">,</span>
</span><span id="init_distributed_environment-1328"><a href="#init_distributed_environment-1328"><span class="linenos">1328</span></a>        <span class="n">rank</span><span class="p">,</span>
</span><span id="init_distributed_environment-1329"><a href="#init_distributed_environment-1329"><span class="linenos">1329</span></a>        <span class="n">local_rank</span><span class="p">,</span>
</span><span id="init_distributed_environment-1330"><a href="#init_distributed_environment-1330"><span class="linenos">1330</span></a>        <span class="n">distributed_init_method</span><span class="p">,</span>
</span><span id="init_distributed_environment-1331"><a href="#init_distributed_environment-1331"><span class="linenos">1331</span></a>        <span class="n">backend</span><span class="p">,</span>
</span><span id="init_distributed_environment-1332"><a href="#init_distributed_environment-1332"><span class="linenos">1332</span></a>    <span class="p">)</span>
</span><span id="init_distributed_environment-1333"><a href="#init_distributed_environment-1333"><span class="linenos">1333</span></a>    <span class="k">if</span> <span class="ow">not</span> <span class="n">torch</span><span class="o">.</span><span class="n">distributed</span><span class="o">.</span><span class="n">is_initialized</span><span class="p">():</span>
</span><span id="init_distributed_environment-1334"><a href="#init_distributed_environment-1334"><span class="linenos">1334</span></a>        <span class="k">assert</span> <span class="n">distributed_init_method</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">,</span> <span class="p">(</span>
</span><span id="init_distributed_environment-1335"><a href="#init_distributed_environment-1335"><span class="linenos">1335</span></a>            <span class="s2">&quot;distributed_init_method must be provided when initializing &quot;</span>
</span><span id="init_distributed_environment-1336"><a href="#init_distributed_environment-1336"><span class="linenos">1336</span></a>            <span class="s2">&quot;distributed environment&quot;</span>
</span><span id="init_distributed_environment-1337"><a href="#init_distributed_environment-1337"><span class="linenos">1337</span></a>        <span class="p">)</span>
</span><span id="init_distributed_environment-1338"><a href="#init_distributed_environment-1338"><span class="linenos">1338</span></a>        <span class="k">if</span> <span class="n">timeout</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="init_distributed_environment-1339"><a href="#init_distributed_environment-1339"><span class="linenos">1339</span></a>            <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">timeout</span><span class="p">,</span> <span class="p">(</span><span class="nb">int</span><span class="p">)),</span> <span class="s2">&quot;timeout must be a number&quot;</span>
</span><span id="init_distributed_environment-1340"><a href="#init_distributed_environment-1340"><span class="linenos">1340</span></a>            <span class="k">assert</span> <span class="n">timeout</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">,</span> <span class="s2">&quot;timeout must be positive&quot;</span>
</span><span id="init_distributed_environment-1341"><a href="#init_distributed_environment-1341"><span class="linenos">1341</span></a>            <span class="n">timeout</span> <span class="o">=</span> <span class="n">timedelta</span><span class="p">(</span><span class="n">seconds</span><span class="o">=</span><span class="n">timeout</span><span class="p">)</span>
</span><span id="init_distributed_environment-1342"><a href="#init_distributed_environment-1342"><span class="linenos">1342</span></a>
</span><span id="init_distributed_environment-1343"><a href="#init_distributed_environment-1343"><span class="linenos">1343</span></a>        <span class="c1"># this backend is used for WORLD</span>
</span><span id="init_distributed_environment-1344"><a href="#init_distributed_environment-1344"><span class="linenos">1344</span></a>        <span class="n">torch</span><span class="o">.</span><span class="n">distributed</span><span class="o">.</span><span class="n">init_process_group</span><span class="p">(</span>
</span><span id="init_distributed_environment-1345"><a href="#init_distributed_environment-1345"><span class="linenos">1345</span></a>            <span class="n">backend</span><span class="o">=</span><span class="n">backend</span><span class="p">,</span>
</span><span id="init_distributed_environment-1346"><a href="#init_distributed_environment-1346"><span class="linenos">1346</span></a>            <span class="n">init_method</span><span class="o">=</span><span class="n">distributed_init_method</span><span class="p">,</span>
</span><span id="init_distributed_environment-1347"><a href="#init_distributed_environment-1347"><span class="linenos">1347</span></a>            <span class="n">world_size</span><span class="o">=</span><span class="n">world_size</span><span class="p">,</span>
</span><span id="init_distributed_environment-1348"><a href="#init_distributed_environment-1348"><span class="linenos">1348</span></a>            <span class="n">rank</span><span class="o">=</span><span class="n">rank</span><span class="p">,</span>
</span><span id="init_distributed_environment-1349"><a href="#init_distributed_environment-1349"><span class="linenos">1349</span></a>            <span class="n">timeout</span><span class="o">=</span><span class="n">timeout</span><span class="p">,</span>
</span><span id="init_distributed_environment-1350"><a href="#init_distributed_environment-1350"><span class="linenos">1350</span></a>        <span class="p">)</span>
</span><span id="init_distributed_environment-1351"><a href="#init_distributed_environment-1351"><span class="linenos">1351</span></a>
</span><span id="init_distributed_environment-1352"><a href="#init_distributed_environment-1352"><span class="linenos">1352</span></a>    <span class="c1"># set the local rank</span>
</span><span id="init_distributed_environment-1353"><a href="#init_distributed_environment-1353"><span class="linenos">1353</span></a>    <span class="c1"># local_rank is not available in torch ProcessGroup,</span>
</span><span id="init_distributed_environment-1354"><a href="#init_distributed_environment-1354"><span class="linenos">1354</span></a>    <span class="c1"># see https://github.com/pytorch/pytorch/issues/122816</span>
</span><span id="init_distributed_environment-1355"><a href="#init_distributed_environment-1355"><span class="linenos">1355</span></a>    <span class="k">if</span> <span class="n">local_rank</span> <span class="o">==</span> <span class="o">-</span><span class="mi">1</span><span class="p">:</span>
</span><span id="init_distributed_environment-1356"><a href="#init_distributed_environment-1356"><span class="linenos">1356</span></a>        <span class="c1"># local rank not set, this usually happens in single-node</span>
</span><span id="init_distributed_environment-1357"><a href="#init_distributed_environment-1357"><span class="linenos">1357</span></a>        <span class="c1"># setting, where we can use rank as local rank</span>
</span><span id="init_distributed_environment-1358"><a href="#init_distributed_environment-1358"><span class="linenos">1358</span></a>        <span class="k">if</span> <span class="n">distributed_init_method</span> <span class="o">==</span> <span class="s2">&quot;env://&quot;</span><span class="p">:</span>
</span><span id="init_distributed_environment-1359"><a href="#init_distributed_environment-1359"><span class="linenos">1359</span></a>            <span class="n">local_rank</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;LOCAL_RANK&quot;</span><span class="p">,</span> <span class="s2">&quot;0&quot;</span><span class="p">))</span>
</span><span id="init_distributed_environment-1360"><a href="#init_distributed_environment-1360"><span class="linenos">1360</span></a>        <span class="k">else</span><span class="p">:</span>
</span><span id="init_distributed_environment-1361"><a href="#init_distributed_environment-1361"><span class="linenos">1361</span></a>            <span class="n">local_rank</span> <span class="o">=</span> <span class="n">rank</span>
</span><span id="init_distributed_environment-1362"><a href="#init_distributed_environment-1362"><span class="linenos">1362</span></a>    <span class="k">global</span> <span class="n">_WORLD</span>
</span><span id="init_distributed_environment-1363"><a href="#init_distributed_environment-1363"><span class="linenos">1363</span></a>    <span class="k">if</span> <span class="n">_WORLD</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="init_distributed_environment-1364"><a href="#init_distributed_environment-1364"><span class="linenos">1364</span></a>        <span class="n">ranks</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">distributed</span><span class="o">.</span><span class="n">get_world_size</span><span class="p">()))</span>
</span><span id="init_distributed_environment-1365"><a href="#init_distributed_environment-1365"><span class="linenos">1365</span></a>        <span class="n">_WORLD</span> <span class="o">=</span> <span class="n">init_world_group</span><span class="p">(</span><span class="n">ranks</span><span class="p">,</span> <span class="n">local_rank</span><span class="p">,</span> <span class="n">backend</span><span class="p">)</span>
</span><span id="init_distributed_environment-1366"><a href="#init_distributed_environment-1366"><span class="linenos">1366</span></a>    <span class="k">else</span><span class="p">:</span>
</span><span id="init_distributed_environment-1367"><a href="#init_distributed_environment-1367"><span class="linenos">1367</span></a>        <span class="k">assert</span> <span class="p">(</span>
</span><span id="init_distributed_environment-1368"><a href="#init_distributed_environment-1368"><span class="linenos">1368</span></a>            <span class="n">_WORLD</span><span class="o">.</span><span class="n">world_size</span> <span class="o">==</span> <span class="n">torch</span><span class="o">.</span><span class="n">distributed</span><span class="o">.</span><span class="n">get_world_size</span><span class="p">()</span>
</span><span id="init_distributed_environment-1369"><a href="#init_distributed_environment-1369"><span class="linenos">1369</span></a>        <span class="p">),</span> <span class="s2">&quot;world group already initialized with a different world size&quot;</span>
</span></pre></div>


    

                </section>
                <section id="initialize_model_parallel">
                            <input id="initialize_model_parallel-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="def">def</span>
        <span class="name">initialize_model_parallel</span><span class="signature pdoc-code multiline">(<span class="param">	<span class="n">tensor_model_parallel_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span>,</span><span class="param">	<span class="n">expert_model_parallel_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span>,</span><span class="param">	<span class="n">pipeline_model_parallel_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span>,</span><span class="param">	<span class="n">backend</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>,</span><span class="param">	<span class="n">duplicate_tp_group</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span></span><span class="return-annotation">) -> <span class="kc">None</span>:</span></span>

                <label class="view-source-button" for="initialize_model_parallel-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#initialize_model_parallel"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="initialize_model_parallel-1372"><a href="#initialize_model_parallel-1372"><span class="linenos">1372</span></a><span class="k">def</span><span class="w"> </span><span class="nf">initialize_model_parallel</span><span class="p">(</span>
</span><span id="initialize_model_parallel-1373"><a href="#initialize_model_parallel-1373"><span class="linenos">1373</span></a>    <span class="n">tensor_model_parallel_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
</span><span id="initialize_model_parallel-1374"><a href="#initialize_model_parallel-1374"><span class="linenos">1374</span></a>    <span class="n">expert_model_parallel_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
</span><span id="initialize_model_parallel-1375"><a href="#initialize_model_parallel-1375"><span class="linenos">1375</span></a>    <span class="n">pipeline_model_parallel_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
</span><span id="initialize_model_parallel-1376"><a href="#initialize_model_parallel-1376"><span class="linenos">1376</span></a>    <span class="n">backend</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="initialize_model_parallel-1377"><a href="#initialize_model_parallel-1377"><span class="linenos">1377</span></a>    <span class="n">duplicate_tp_group</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
</span><span id="initialize_model_parallel-1378"><a href="#initialize_model_parallel-1378"><span class="linenos">1378</span></a><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="initialize_model_parallel-1379"><a href="#initialize_model_parallel-1379"><span class="linenos">1379</span></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="initialize_model_parallel-1380"><a href="#initialize_model_parallel-1380"><span class="linenos">1380</span></a><span class="sd">    Initialize model parallel groups.</span>
</span><span id="initialize_model_parallel-1381"><a href="#initialize_model_parallel-1381"><span class="linenos">1381</span></a>
</span><span id="initialize_model_parallel-1382"><a href="#initialize_model_parallel-1382"><span class="linenos">1382</span></a><span class="sd">    Arguments:</span>
</span><span id="initialize_model_parallel-1383"><a href="#initialize_model_parallel-1383"><span class="linenos">1383</span></a><span class="sd">        tensor_model_parallel_size: number of GPUs used for tensor model</span>
</span><span id="initialize_model_parallel-1384"><a href="#initialize_model_parallel-1384"><span class="linenos">1384</span></a><span class="sd">            parallelism.</span>
</span><span id="initialize_model_parallel-1385"><a href="#initialize_model_parallel-1385"><span class="linenos">1385</span></a><span class="sd">        pipeline_model_parallel_size: number of GPUs used for pipeline model</span>
</span><span id="initialize_model_parallel-1386"><a href="#initialize_model_parallel-1386"><span class="linenos">1386</span></a><span class="sd">            parallelism.</span>
</span><span id="initialize_model_parallel-1387"><a href="#initialize_model_parallel-1387"><span class="linenos">1387</span></a>
</span><span id="initialize_model_parallel-1388"><a href="#initialize_model_parallel-1388"><span class="linenos">1388</span></a><span class="sd">    Let&#39;s say we have a total of 8 GPUs denoted by g0 ... g7 and we</span>
</span><span id="initialize_model_parallel-1389"><a href="#initialize_model_parallel-1389"><span class="linenos">1389</span></a><span class="sd">    use 2 GPUs to parallelize the model tensor, and 4 GPUs to parallelize</span>
</span><span id="initialize_model_parallel-1390"><a href="#initialize_model_parallel-1390"><span class="linenos">1390</span></a><span class="sd">    the model pipeline. The present function will</span>
</span><span id="initialize_model_parallel-1391"><a href="#initialize_model_parallel-1391"><span class="linenos">1391</span></a><span class="sd">    create 4 tensor model-parallel groups and 2 pipeline model-parallel groups:</span>
</span><span id="initialize_model_parallel-1392"><a href="#initialize_model_parallel-1392"><span class="linenos">1392</span></a><span class="sd">        4 tensor model-parallel groups:</span>
</span><span id="initialize_model_parallel-1393"><a href="#initialize_model_parallel-1393"><span class="linenos">1393</span></a><span class="sd">            [g0, g1], [g2, g3], [g4, g5], [g6, g7]</span>
</span><span id="initialize_model_parallel-1394"><a href="#initialize_model_parallel-1394"><span class="linenos">1394</span></a><span class="sd">        2 pipeline model-parallel groups:</span>
</span><span id="initialize_model_parallel-1395"><a href="#initialize_model_parallel-1395"><span class="linenos">1395</span></a><span class="sd">            [g0, g2, g4, g6], [g1, g3, g5, g7]</span>
</span><span id="initialize_model_parallel-1396"><a href="#initialize_model_parallel-1396"><span class="linenos">1396</span></a><span class="sd">    Note that for efficiency, the caller should make sure adjacent ranks</span>
</span><span id="initialize_model_parallel-1397"><a href="#initialize_model_parallel-1397"><span class="linenos">1397</span></a><span class="sd">    are on the same DGX box. For example if we are using 2 DGX-1 boxes</span>
</span><span id="initialize_model_parallel-1398"><a href="#initialize_model_parallel-1398"><span class="linenos">1398</span></a><span class="sd">    with a total of 16 GPUs, rank 0 to 7 belong to the first box and</span>
</span><span id="initialize_model_parallel-1399"><a href="#initialize_model_parallel-1399"><span class="linenos">1399</span></a><span class="sd">    ranks 8 to 15 belong to the second box.</span>
</span><span id="initialize_model_parallel-1400"><a href="#initialize_model_parallel-1400"><span class="linenos">1400</span></a><span class="sd">    &quot;&quot;&quot;</span>
</span><span id="initialize_model_parallel-1401"><a href="#initialize_model_parallel-1401"><span class="linenos">1401</span></a>    <span class="c1"># Get world size and rank. Ensure some consistencies.</span>
</span><span id="initialize_model_parallel-1402"><a href="#initialize_model_parallel-1402"><span class="linenos">1402</span></a>    <span class="k">assert</span> <span class="n">torch</span><span class="o">.</span><span class="n">distributed</span><span class="o">.</span><span class="n">is_initialized</span><span class="p">()</span>
</span><span id="initialize_model_parallel-1403"><a href="#initialize_model_parallel-1403"><span class="linenos">1403</span></a>    <span class="n">world_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">distributed</span><span class="o">.</span><span class="n">get_world_size</span><span class="p">()</span>
</span><span id="initialize_model_parallel-1404"><a href="#initialize_model_parallel-1404"><span class="linenos">1404</span></a>    <span class="n">backend</span> <span class="o">=</span> <span class="n">backend</span> <span class="ow">or</span> <span class="n">torch</span><span class="o">.</span><span class="n">distributed</span><span class="o">.</span><span class="n">get_backend</span><span class="p">(</span><span class="n">get_world_group</span><span class="p">()</span><span class="o">.</span><span class="n">device_group</span><span class="p">)</span>
</span><span id="initialize_model_parallel-1405"><a href="#initialize_model_parallel-1405"><span class="linenos">1405</span></a>
</span><span id="initialize_model_parallel-1406"><a href="#initialize_model_parallel-1406"><span class="linenos">1406</span></a>    <span class="k">if</span> <span class="n">world_size</span> <span class="o">!=</span> <span class="n">tensor_model_parallel_size</span> <span class="o">*</span> <span class="n">pipeline_model_parallel_size</span><span class="p">:</span>
</span><span id="initialize_model_parallel-1407"><a href="#initialize_model_parallel-1407"><span class="linenos">1407</span></a>        <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span>
</span><span id="initialize_model_parallel-1408"><a href="#initialize_model_parallel-1408"><span class="linenos">1408</span></a>            <span class="sa">f</span><span class="s2">&quot;world_size (</span><span class="si">{</span><span class="n">world_size</span><span class="si">}</span><span class="s2">) is not equal to &quot;</span>
</span><span id="initialize_model_parallel-1409"><a href="#initialize_model_parallel-1409"><span class="linenos">1409</span></a>            <span class="sa">f</span><span class="s2">&quot;tensor_model_parallel_size (</span><span class="si">{</span><span class="n">tensor_model_parallel_size</span><span class="si">}</span><span class="s2">) x &quot;</span>
</span><span id="initialize_model_parallel-1410"><a href="#initialize_model_parallel-1410"><span class="linenos">1410</span></a>            <span class="sa">f</span><span class="s2">&quot;pipeline_model_parallel_size (</span><span class="si">{</span><span class="n">pipeline_model_parallel_size</span><span class="si">}</span><span class="s2">)&quot;</span>
</span><span id="initialize_model_parallel-1411"><a href="#initialize_model_parallel-1411"><span class="linenos">1411</span></a>        <span class="p">)</span>
</span><span id="initialize_model_parallel-1412"><a href="#initialize_model_parallel-1412"><span class="linenos">1412</span></a>
</span><span id="initialize_model_parallel-1413"><a href="#initialize_model_parallel-1413"><span class="linenos">1413</span></a>    <span class="c1"># Build the tensor model-parallel groups.</span>
</span><span id="initialize_model_parallel-1414"><a href="#initialize_model_parallel-1414"><span class="linenos">1414</span></a>    <span class="n">num_tensor_model_parallel_groups</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="n">world_size</span> <span class="o">//</span> <span class="n">tensor_model_parallel_size</span>
</span><span id="initialize_model_parallel-1415"><a href="#initialize_model_parallel-1415"><span class="linenos">1415</span></a>    <span class="k">global</span> <span class="n">_TP</span>
</span><span id="initialize_model_parallel-1416"><a href="#initialize_model_parallel-1416"><span class="linenos">1416</span></a>    <span class="k">assert</span> <span class="n">_TP</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">,</span> <span class="s2">&quot;tensor model parallel group is already initialized&quot;</span>
</span><span id="initialize_model_parallel-1417"><a href="#initialize_model_parallel-1417"><span class="linenos">1417</span></a>    <span class="n">group_ranks</span> <span class="o">=</span> <span class="p">[]</span>
</span><span id="initialize_model_parallel-1418"><a href="#initialize_model_parallel-1418"><span class="linenos">1418</span></a>    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_tensor_model_parallel_groups</span><span class="p">):</span>
</span><span id="initialize_model_parallel-1419"><a href="#initialize_model_parallel-1419"><span class="linenos">1419</span></a>        <span class="n">ranks</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span>
</span><span id="initialize_model_parallel-1420"><a href="#initialize_model_parallel-1420"><span class="linenos">1420</span></a>            <span class="nb">range</span><span class="p">(</span><span class="n">i</span> <span class="o">*</span> <span class="n">tensor_model_parallel_size</span><span class="p">,</span> <span class="p">(</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="n">tensor_model_parallel_size</span><span class="p">)</span>
</span><span id="initialize_model_parallel-1421"><a href="#initialize_model_parallel-1421"><span class="linenos">1421</span></a>        <span class="p">)</span>
</span><span id="initialize_model_parallel-1422"><a href="#initialize_model_parallel-1422"><span class="linenos">1422</span></a>        <span class="n">group_ranks</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">ranks</span><span class="p">)</span>
</span><span id="initialize_model_parallel-1423"><a href="#initialize_model_parallel-1423"><span class="linenos">1423</span></a>
</span><span id="initialize_model_parallel-1424"><a href="#initialize_model_parallel-1424"><span class="linenos">1424</span></a>    <span class="c1"># message queue broadcaster is only used in tensor model parallel group</span>
</span><span id="initialize_model_parallel-1425"><a href="#initialize_model_parallel-1425"><span class="linenos">1425</span></a>    <span class="n">_TP</span> <span class="o">=</span> <span class="n">init_model_parallel_group</span><span class="p">(</span>
</span><span id="initialize_model_parallel-1426"><a href="#initialize_model_parallel-1426"><span class="linenos">1426</span></a>        <span class="n">group_ranks</span><span class="p">,</span>
</span><span id="initialize_model_parallel-1427"><a href="#initialize_model_parallel-1427"><span class="linenos">1427</span></a>        <span class="n">get_world_group</span><span class="p">()</span><span class="o">.</span><span class="n">local_rank</span><span class="p">,</span>
</span><span id="initialize_model_parallel-1428"><a href="#initialize_model_parallel-1428"><span class="linenos">1428</span></a>        <span class="n">backend</span><span class="p">,</span>
</span><span id="initialize_model_parallel-1429"><a href="#initialize_model_parallel-1429"><span class="linenos">1429</span></a>        <span class="n">use_message_queue_broadcaster</span><span class="o">=</span><span class="n">get_bool_env_var</span><span class="p">(</span>
</span><span id="initialize_model_parallel-1430"><a href="#initialize_model_parallel-1430"><span class="linenos">1430</span></a>            <span class="s2">&quot;SGLANG_USE_MESSAGE_QUEUE_BROADCASTER&quot;</span><span class="p">,</span> <span class="s2">&quot;true&quot;</span>
</span><span id="initialize_model_parallel-1431"><a href="#initialize_model_parallel-1431"><span class="linenos">1431</span></a>        <span class="p">),</span>
</span><span id="initialize_model_parallel-1432"><a href="#initialize_model_parallel-1432"><span class="linenos">1432</span></a>        <span class="n">group_name</span><span class="o">=</span><span class="s2">&quot;tp&quot;</span><span class="p">,</span>
</span><span id="initialize_model_parallel-1433"><a href="#initialize_model_parallel-1433"><span class="linenos">1433</span></a>    <span class="p">)</span>
</span><span id="initialize_model_parallel-1434"><a href="#initialize_model_parallel-1434"><span class="linenos">1434</span></a>
</span><span id="initialize_model_parallel-1435"><a href="#initialize_model_parallel-1435"><span class="linenos">1435</span></a>    <span class="k">if</span> <span class="n">duplicate_tp_group</span><span class="p">:</span>
</span><span id="initialize_model_parallel-1436"><a href="#initialize_model_parallel-1436"><span class="linenos">1436</span></a>        <span class="k">global</span> <span class="n">_PDMUX_PREFILL_TP_GROUP</span>
</span><span id="initialize_model_parallel-1437"><a href="#initialize_model_parallel-1437"><span class="linenos">1437</span></a>        <span class="k">assert</span> <span class="p">(</span>
</span><span id="initialize_model_parallel-1438"><a href="#initialize_model_parallel-1438"><span class="linenos">1438</span></a>            <span class="n">_PDMUX_PREFILL_TP_GROUP</span> <span class="ow">is</span> <span class="kc">None</span>
</span><span id="initialize_model_parallel-1439"><a href="#initialize_model_parallel-1439"><span class="linenos">1439</span></a>        <span class="p">),</span> <span class="s2">&quot;tensor model parallel group for PD-Multiplexing Prefill is already initialized&quot;</span>
</span><span id="initialize_model_parallel-1440"><a href="#initialize_model_parallel-1440"><span class="linenos">1440</span></a>        <span class="n">_PDMUX_PREFILL_TP_GROUP</span> <span class="o">=</span> <span class="n">init_model_parallel_group</span><span class="p">(</span>
</span><span id="initialize_model_parallel-1441"><a href="#initialize_model_parallel-1441"><span class="linenos">1441</span></a>            <span class="n">group_ranks</span><span class="p">,</span>
</span><span id="initialize_model_parallel-1442"><a href="#initialize_model_parallel-1442"><span class="linenos">1442</span></a>            <span class="n">get_world_group</span><span class="p">()</span><span class="o">.</span><span class="n">local_rank</span><span class="p">,</span>
</span><span id="initialize_model_parallel-1443"><a href="#initialize_model_parallel-1443"><span class="linenos">1443</span></a>            <span class="n">backend</span><span class="p">,</span>
</span><span id="initialize_model_parallel-1444"><a href="#initialize_model_parallel-1444"><span class="linenos">1444</span></a>            <span class="n">use_message_queue_broadcaster</span><span class="o">=</span><span class="n">get_bool_env_var</span><span class="p">(</span>
</span><span id="initialize_model_parallel-1445"><a href="#initialize_model_parallel-1445"><span class="linenos">1445</span></a>                <span class="s2">&quot;SGLANG_USE_MESSAGE_QUEUE_BROADCASTER&quot;</span><span class="p">,</span> <span class="s2">&quot;true&quot;</span>
</span><span id="initialize_model_parallel-1446"><a href="#initialize_model_parallel-1446"><span class="linenos">1446</span></a>            <span class="p">),</span>
</span><span id="initialize_model_parallel-1447"><a href="#initialize_model_parallel-1447"><span class="linenos">1447</span></a>            <span class="n">group_name</span><span class="o">=</span><span class="s2">&quot;pdmux_prefill_tp&quot;</span><span class="p">,</span>
</span><span id="initialize_model_parallel-1448"><a href="#initialize_model_parallel-1448"><span class="linenos">1448</span></a>        <span class="p">)</span>
</span><span id="initialize_model_parallel-1449"><a href="#initialize_model_parallel-1449"><span class="linenos">1449</span></a>        <span class="n">_TP</span><span class="o">.</span><span class="n">pynccl_comm</span><span class="o">.</span><span class="n">disabled</span> <span class="o">=</span> <span class="kc">False</span>
</span><span id="initialize_model_parallel-1450"><a href="#initialize_model_parallel-1450"><span class="linenos">1450</span></a>        <span class="n">_PDMUX_PREFILL_TP_GROUP</span><span class="o">.</span><span class="n">pynccl_comm</span><span class="o">.</span><span class="n">disabled</span> <span class="o">=</span> <span class="kc">False</span>
</span><span id="initialize_model_parallel-1451"><a href="#initialize_model_parallel-1451"><span class="linenos">1451</span></a>
</span><span id="initialize_model_parallel-1452"><a href="#initialize_model_parallel-1452"><span class="linenos">1452</span></a>    <span class="n">moe_ep_size</span> <span class="o">=</span> <span class="n">expert_model_parallel_size</span>
</span><span id="initialize_model_parallel-1453"><a href="#initialize_model_parallel-1453"><span class="linenos">1453</span></a>
</span><span id="initialize_model_parallel-1454"><a href="#initialize_model_parallel-1454"><span class="linenos">1454</span></a>    <span class="n">moe_tp_size</span> <span class="o">=</span> <span class="n">tensor_model_parallel_size</span> <span class="o">//</span> <span class="n">moe_ep_size</span>
</span><span id="initialize_model_parallel-1455"><a href="#initialize_model_parallel-1455"><span class="linenos">1455</span></a>    <span class="k">global</span> <span class="n">_MOE_EP</span>
</span><span id="initialize_model_parallel-1456"><a href="#initialize_model_parallel-1456"><span class="linenos">1456</span></a>    <span class="k">assert</span> <span class="n">_MOE_EP</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">,</span> <span class="s2">&quot;expert model parallel group is already initialized&quot;</span>
</span><span id="initialize_model_parallel-1457"><a href="#initialize_model_parallel-1457"><span class="linenos">1457</span></a>    <span class="n">group_ranks</span> <span class="o">=</span> <span class="p">[]</span>
</span><span id="initialize_model_parallel-1458"><a href="#initialize_model_parallel-1458"><span class="linenos">1458</span></a>    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_tensor_model_parallel_groups</span><span class="p">):</span>
</span><span id="initialize_model_parallel-1459"><a href="#initialize_model_parallel-1459"><span class="linenos">1459</span></a>        <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">moe_tp_size</span><span class="p">):</span>
</span><span id="initialize_model_parallel-1460"><a href="#initialize_model_parallel-1460"><span class="linenos">1460</span></a>            <span class="n">st</span> <span class="o">=</span> <span class="n">i</span> <span class="o">*</span> <span class="n">tensor_model_parallel_size</span> <span class="o">+</span> <span class="n">j</span>
</span><span id="initialize_model_parallel-1461"><a href="#initialize_model_parallel-1461"><span class="linenos">1461</span></a>            <span class="n">en</span> <span class="o">=</span> <span class="p">(</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="n">tensor_model_parallel_size</span> <span class="o">+</span> <span class="n">j</span>
</span><span id="initialize_model_parallel-1462"><a href="#initialize_model_parallel-1462"><span class="linenos">1462</span></a>            <span class="n">ranks</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">st</span><span class="p">,</span> <span class="n">en</span><span class="p">,</span> <span class="n">moe_tp_size</span><span class="p">))</span>
</span><span id="initialize_model_parallel-1463"><a href="#initialize_model_parallel-1463"><span class="linenos">1463</span></a>            <span class="n">group_ranks</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">ranks</span><span class="p">)</span>
</span><span id="initialize_model_parallel-1464"><a href="#initialize_model_parallel-1464"><span class="linenos">1464</span></a>
</span><span id="initialize_model_parallel-1465"><a href="#initialize_model_parallel-1465"><span class="linenos">1465</span></a>    <span class="n">_MOE_EP</span> <span class="o">=</span> <span class="n">init_model_parallel_group</span><span class="p">(</span>
</span><span id="initialize_model_parallel-1466"><a href="#initialize_model_parallel-1466"><span class="linenos">1466</span></a>        <span class="n">group_ranks</span><span class="p">,</span>
</span><span id="initialize_model_parallel-1467"><a href="#initialize_model_parallel-1467"><span class="linenos">1467</span></a>        <span class="n">get_world_group</span><span class="p">()</span><span class="o">.</span><span class="n">local_rank</span><span class="p">,</span>
</span><span id="initialize_model_parallel-1468"><a href="#initialize_model_parallel-1468"><span class="linenos">1468</span></a>        <span class="n">backend</span><span class="p">,</span>
</span><span id="initialize_model_parallel-1469"><a href="#initialize_model_parallel-1469"><span class="linenos">1469</span></a>        <span class="n">use_custom_allreduce</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
</span><span id="initialize_model_parallel-1470"><a href="#initialize_model_parallel-1470"><span class="linenos">1470</span></a>        <span class="n">group_name</span><span class="o">=</span><span class="s2">&quot;moe_ep&quot;</span><span class="p">,</span>
</span><span id="initialize_model_parallel-1471"><a href="#initialize_model_parallel-1471"><span class="linenos">1471</span></a>    <span class="p">)</span>
</span><span id="initialize_model_parallel-1472"><a href="#initialize_model_parallel-1472"><span class="linenos">1472</span></a>
</span><span id="initialize_model_parallel-1473"><a href="#initialize_model_parallel-1473"><span class="linenos">1473</span></a>    <span class="k">global</span> <span class="n">_MOE_TP</span>
</span><span id="initialize_model_parallel-1474"><a href="#initialize_model_parallel-1474"><span class="linenos">1474</span></a>    <span class="k">assert</span> <span class="n">_MOE_TP</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">,</span> <span class="s2">&quot;expert model parallel group is already initialized&quot;</span>
</span><span id="initialize_model_parallel-1475"><a href="#initialize_model_parallel-1475"><span class="linenos">1475</span></a>    <span class="n">group_ranks</span> <span class="o">=</span> <span class="p">[]</span>
</span><span id="initialize_model_parallel-1476"><a href="#initialize_model_parallel-1476"><span class="linenos">1476</span></a>    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_tensor_model_parallel_groups</span><span class="p">):</span>
</span><span id="initialize_model_parallel-1477"><a href="#initialize_model_parallel-1477"><span class="linenos">1477</span></a>        <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">moe_ep_size</span><span class="p">):</span>
</span><span id="initialize_model_parallel-1478"><a href="#initialize_model_parallel-1478"><span class="linenos">1478</span></a>            <span class="n">st</span> <span class="o">=</span> <span class="n">i</span> <span class="o">*</span> <span class="n">tensor_model_parallel_size</span> <span class="o">+</span> <span class="n">j</span> <span class="o">*</span> <span class="n">moe_tp_size</span>
</span><span id="initialize_model_parallel-1479"><a href="#initialize_model_parallel-1479"><span class="linenos">1479</span></a>            <span class="n">en</span> <span class="o">=</span> <span class="n">i</span> <span class="o">*</span> <span class="n">tensor_model_parallel_size</span> <span class="o">+</span> <span class="p">(</span><span class="n">j</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="n">moe_tp_size</span>
</span><span id="initialize_model_parallel-1480"><a href="#initialize_model_parallel-1480"><span class="linenos">1480</span></a>            <span class="n">ranks</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">st</span><span class="p">,</span> <span class="n">en</span><span class="p">))</span>
</span><span id="initialize_model_parallel-1481"><a href="#initialize_model_parallel-1481"><span class="linenos">1481</span></a>            <span class="n">group_ranks</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">ranks</span><span class="p">)</span>
</span><span id="initialize_model_parallel-1482"><a href="#initialize_model_parallel-1482"><span class="linenos">1482</span></a>
</span><span id="initialize_model_parallel-1483"><a href="#initialize_model_parallel-1483"><span class="linenos">1483</span></a>    <span class="n">_MOE_TP</span> <span class="o">=</span> <span class="n">init_model_parallel_group</span><span class="p">(</span>
</span><span id="initialize_model_parallel-1484"><a href="#initialize_model_parallel-1484"><span class="linenos">1484</span></a>        <span class="n">group_ranks</span><span class="p">,</span>
</span><span id="initialize_model_parallel-1485"><a href="#initialize_model_parallel-1485"><span class="linenos">1485</span></a>        <span class="n">get_world_group</span><span class="p">()</span><span class="o">.</span><span class="n">local_rank</span><span class="p">,</span>
</span><span id="initialize_model_parallel-1486"><a href="#initialize_model_parallel-1486"><span class="linenos">1486</span></a>        <span class="n">backend</span><span class="p">,</span>
</span><span id="initialize_model_parallel-1487"><a href="#initialize_model_parallel-1487"><span class="linenos">1487</span></a>        <span class="n">use_custom_allreduce</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
</span><span id="initialize_model_parallel-1488"><a href="#initialize_model_parallel-1488"><span class="linenos">1488</span></a>        <span class="n">group_name</span><span class="o">=</span><span class="s2">&quot;moe_tp&quot;</span><span class="p">,</span>
</span><span id="initialize_model_parallel-1489"><a href="#initialize_model_parallel-1489"><span class="linenos">1489</span></a>    <span class="p">)</span>
</span><span id="initialize_model_parallel-1490"><a href="#initialize_model_parallel-1490"><span class="linenos">1490</span></a>
</span><span id="initialize_model_parallel-1491"><a href="#initialize_model_parallel-1491"><span class="linenos">1491</span></a>    <span class="c1"># Build the pipeline model-parallel groups.</span>
</span><span id="initialize_model_parallel-1492"><a href="#initialize_model_parallel-1492"><span class="linenos">1492</span></a>    <span class="n">num_pipeline_model_parallel_groups</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="n">world_size</span> <span class="o">//</span> <span class="n">pipeline_model_parallel_size</span>
</span><span id="initialize_model_parallel-1493"><a href="#initialize_model_parallel-1493"><span class="linenos">1493</span></a>    <span class="k">global</span> <span class="n">_PP</span>
</span><span id="initialize_model_parallel-1494"><a href="#initialize_model_parallel-1494"><span class="linenos">1494</span></a>    <span class="k">assert</span> <span class="n">_PP</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">,</span> <span class="s2">&quot;pipeline model parallel group is already initialized&quot;</span>
</span><span id="initialize_model_parallel-1495"><a href="#initialize_model_parallel-1495"><span class="linenos">1495</span></a>    <span class="n">group_ranks</span> <span class="o">=</span> <span class="p">[]</span>
</span><span id="initialize_model_parallel-1496"><a href="#initialize_model_parallel-1496"><span class="linenos">1496</span></a>    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_pipeline_model_parallel_groups</span><span class="p">):</span>
</span><span id="initialize_model_parallel-1497"><a href="#initialize_model_parallel-1497"><span class="linenos">1497</span></a>        <span class="n">ranks</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">world_size</span><span class="p">,</span> <span class="n">num_pipeline_model_parallel_groups</span><span class="p">))</span>
</span><span id="initialize_model_parallel-1498"><a href="#initialize_model_parallel-1498"><span class="linenos">1498</span></a>        <span class="n">group_ranks</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">ranks</span><span class="p">)</span>
</span><span id="initialize_model_parallel-1499"><a href="#initialize_model_parallel-1499"><span class="linenos">1499</span></a>    <span class="c1"># pipeline parallel does not need custom allreduce</span>
</span><span id="initialize_model_parallel-1500"><a href="#initialize_model_parallel-1500"><span class="linenos">1500</span></a>    <span class="n">_PP</span> <span class="o">=</span> <span class="n">init_model_parallel_group</span><span class="p">(</span>
</span><span id="initialize_model_parallel-1501"><a href="#initialize_model_parallel-1501"><span class="linenos">1501</span></a>        <span class="n">group_ranks</span><span class="p">,</span>
</span><span id="initialize_model_parallel-1502"><a href="#initialize_model_parallel-1502"><span class="linenos">1502</span></a>        <span class="n">get_world_group</span><span class="p">()</span><span class="o">.</span><span class="n">local_rank</span><span class="p">,</span>
</span><span id="initialize_model_parallel-1503"><a href="#initialize_model_parallel-1503"><span class="linenos">1503</span></a>        <span class="n">backend</span><span class="p">,</span>
</span><span id="initialize_model_parallel-1504"><a href="#initialize_model_parallel-1504"><span class="linenos">1504</span></a>        <span class="n">use_custom_allreduce</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
</span><span id="initialize_model_parallel-1505"><a href="#initialize_model_parallel-1505"><span class="linenos">1505</span></a>        <span class="n">group_name</span><span class="o">=</span><span class="s2">&quot;pp&quot;</span><span class="p">,</span>
</span><span id="initialize_model_parallel-1506"><a href="#initialize_model_parallel-1506"><span class="linenos">1506</span></a>    <span class="p">)</span>
</span></pre></div>


            <div class="docstring"><p>Initialize model parallel groups.</p>

<p>Arguments:
    tensor_model_parallel_size: number of GPUs used for tensor model
        parallelism.
    pipeline_model_parallel_size: number of GPUs used for pipeline model
        parallelism.</p>

<p>Let's say we have a total of 8 GPUs denoted by g0 ... g7 and we
use 2 GPUs to parallelize the model tensor, and 4 GPUs to parallelize
the model pipeline. The present function will
create 4 tensor model-parallel groups and 2 pipeline model-parallel groups:
    4 tensor model-parallel groups:
        [g0, g1], [g2, g3], [g4, g5], [g6, g7]
    2 pipeline model-parallel groups:
        [g0, g2, g4, g6], [g1, g3, g5, g7]
Note that for efficiency, the caller should make sure adjacent ranks
are on the same DGX box. For example if we are using 2 DGX-1 boxes
with a total of 16 GPUs, rank 0 to 7 belong to the first box and
ranks 8 to 15 belong to the second box.</p>
</div>


                </section>
                <section id="ensure_model_parallel_initialized">
                            <input id="ensure_model_parallel_initialized-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="def">def</span>
        <span class="name">ensure_model_parallel_initialized</span><span class="signature pdoc-code multiline">(<span class="param">	<span class="n">tensor_model_parallel_size</span><span class="p">:</span> <span class="nb">int</span>,</span><span class="param">	<span class="n">expert_model_parallel_size</span><span class="p">:</span> <span class="nb">int</span>,</span><span class="param">	<span class="n">pipeline_model_parallel_size</span><span class="p">:</span> <span class="nb">int</span>,</span><span class="param">	<span class="n">backend</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span></span><span class="return-annotation">) -> <span class="kc">None</span>:</span></span>

                <label class="view-source-button" for="ensure_model_parallel_initialized-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#ensure_model_parallel_initialized"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="ensure_model_parallel_initialized-1509"><a href="#ensure_model_parallel_initialized-1509"><span class="linenos">1509</span></a><span class="k">def</span><span class="w"> </span><span class="nf">ensure_model_parallel_initialized</span><span class="p">(</span>
</span><span id="ensure_model_parallel_initialized-1510"><a href="#ensure_model_parallel_initialized-1510"><span class="linenos">1510</span></a>    <span class="n">tensor_model_parallel_size</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
</span><span id="ensure_model_parallel_initialized-1511"><a href="#ensure_model_parallel_initialized-1511"><span class="linenos">1511</span></a>    <span class="n">expert_model_parallel_size</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
</span><span id="ensure_model_parallel_initialized-1512"><a href="#ensure_model_parallel_initialized-1512"><span class="linenos">1512</span></a>    <span class="n">pipeline_model_parallel_size</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
</span><span id="ensure_model_parallel_initialized-1513"><a href="#ensure_model_parallel_initialized-1513"><span class="linenos">1513</span></a>    <span class="n">backend</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="ensure_model_parallel_initialized-1514"><a href="#ensure_model_parallel_initialized-1514"><span class="linenos">1514</span></a><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="ensure_model_parallel_initialized-1515"><a href="#ensure_model_parallel_initialized-1515"><span class="linenos">1515</span></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;Helper to initialize model parallel groups if they are not initialized,</span>
</span><span id="ensure_model_parallel_initialized-1516"><a href="#ensure_model_parallel_initialized-1516"><span class="linenos">1516</span></a><span class="sd">    or ensure tensor-parallel and pipeline-parallel sizes are equal to expected</span>
</span><span id="ensure_model_parallel_initialized-1517"><a href="#ensure_model_parallel_initialized-1517"><span class="linenos">1517</span></a><span class="sd">    values if the model parallel groups are initialized.</span>
</span><span id="ensure_model_parallel_initialized-1518"><a href="#ensure_model_parallel_initialized-1518"><span class="linenos">1518</span></a><span class="sd">    &quot;&quot;&quot;</span>
</span><span id="ensure_model_parallel_initialized-1519"><a href="#ensure_model_parallel_initialized-1519"><span class="linenos">1519</span></a>    <span class="n">backend</span> <span class="o">=</span> <span class="n">backend</span> <span class="ow">or</span> <span class="n">torch</span><span class="o">.</span><span class="n">distributed</span><span class="o">.</span><span class="n">get_backend</span><span class="p">(</span><span class="n">get_world_group</span><span class="p">()</span><span class="o">.</span><span class="n">device_group</span><span class="p">)</span>
</span><span id="ensure_model_parallel_initialized-1520"><a href="#ensure_model_parallel_initialized-1520"><span class="linenos">1520</span></a>    <span class="k">if</span> <span class="ow">not</span> <span class="n">model_parallel_is_initialized</span><span class="p">():</span>
</span><span id="ensure_model_parallel_initialized-1521"><a href="#ensure_model_parallel_initialized-1521"><span class="linenos">1521</span></a>        <span class="n">initialize_model_parallel</span><span class="p">(</span>
</span><span id="ensure_model_parallel_initialized-1522"><a href="#ensure_model_parallel_initialized-1522"><span class="linenos">1522</span></a>            <span class="n">tensor_model_parallel_size</span><span class="p">,</span>
</span><span id="ensure_model_parallel_initialized-1523"><a href="#ensure_model_parallel_initialized-1523"><span class="linenos">1523</span></a>            <span class="n">expert_model_parallel_size</span><span class="p">,</span>
</span><span id="ensure_model_parallel_initialized-1524"><a href="#ensure_model_parallel_initialized-1524"><span class="linenos">1524</span></a>            <span class="n">pipeline_model_parallel_size</span><span class="p">,</span>
</span><span id="ensure_model_parallel_initialized-1525"><a href="#ensure_model_parallel_initialized-1525"><span class="linenos">1525</span></a>            <span class="n">backend</span><span class="p">,</span>
</span><span id="ensure_model_parallel_initialized-1526"><a href="#ensure_model_parallel_initialized-1526"><span class="linenos">1526</span></a>        <span class="p">)</span>
</span><span id="ensure_model_parallel_initialized-1527"><a href="#ensure_model_parallel_initialized-1527"><span class="linenos">1527</span></a>        <span class="k">return</span>
</span><span id="ensure_model_parallel_initialized-1528"><a href="#ensure_model_parallel_initialized-1528"><span class="linenos">1528</span></a>
</span><span id="ensure_model_parallel_initialized-1529"><a href="#ensure_model_parallel_initialized-1529"><span class="linenos">1529</span></a>    <span class="k">assert</span> <span class="n">get_tensor_model_parallel_world_size</span><span class="p">()</span> <span class="o">==</span> <span class="n">tensor_model_parallel_size</span><span class="p">,</span> <span class="p">(</span>
</span><span id="ensure_model_parallel_initialized-1530"><a href="#ensure_model_parallel_initialized-1530"><span class="linenos">1530</span></a>        <span class="s2">&quot;tensor parallel group already initialized, but of unexpected size: &quot;</span>
</span><span id="ensure_model_parallel_initialized-1531"><a href="#ensure_model_parallel_initialized-1531"><span class="linenos">1531</span></a>        <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">get_tensor_model_parallel_world_size</span><span class="p">()</span><span class="si">=}</span><span class="s2"> vs. &quot;</span>
</span><span id="ensure_model_parallel_initialized-1532"><a href="#ensure_model_parallel_initialized-1532"><span class="linenos">1532</span></a>        <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">tensor_model_parallel_size</span><span class="si">=}</span><span class="s2">&quot;</span>
</span><span id="ensure_model_parallel_initialized-1533"><a href="#ensure_model_parallel_initialized-1533"><span class="linenos">1533</span></a>    <span class="p">)</span>
</span><span id="ensure_model_parallel_initialized-1534"><a href="#ensure_model_parallel_initialized-1534"><span class="linenos">1534</span></a>    <span class="n">pp_world_size</span> <span class="o">=</span> <span class="n">get_pp_group</span><span class="p">()</span><span class="o">.</span><span class="n">world_size</span>
</span><span id="ensure_model_parallel_initialized-1535"><a href="#ensure_model_parallel_initialized-1535"><span class="linenos">1535</span></a>    <span class="k">assert</span> <span class="n">pp_world_size</span> <span class="o">==</span> <span class="n">pipeline_model_parallel_size</span><span class="p">,</span> <span class="p">(</span>
</span><span id="ensure_model_parallel_initialized-1536"><a href="#ensure_model_parallel_initialized-1536"><span class="linenos">1536</span></a>        <span class="s2">&quot;pipeline parallel group already initialized, but of unexpected size: &quot;</span>
</span><span id="ensure_model_parallel_initialized-1537"><a href="#ensure_model_parallel_initialized-1537"><span class="linenos">1537</span></a>        <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">pp_world_size</span><span class="si">=}</span><span class="s2"> vs. &quot;</span>
</span><span id="ensure_model_parallel_initialized-1538"><a href="#ensure_model_parallel_initialized-1538"><span class="linenos">1538</span></a>        <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">pipeline_model_parallel_size</span><span class="si">=}</span><span class="s2">&quot;</span>
</span><span id="ensure_model_parallel_initialized-1539"><a href="#ensure_model_parallel_initialized-1539"><span class="linenos">1539</span></a>    <span class="p">)</span>
</span></pre></div>


            <div class="docstring"><p>Helper to initialize model parallel groups if they are not initialized,
or ensure tensor-parallel and pipeline-parallel sizes are equal to expected
values if the model parallel groups are initialized.</p>
</div>


                </section>
                <section id="model_parallel_is_initialized">
                            <input id="model_parallel_is_initialized-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="def">def</span>
        <span class="name">model_parallel_is_initialized</span><span class="signature pdoc-code condensed">(<span class="return-annotation">):</span></span>

                <label class="view-source-button" for="model_parallel_is_initialized-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#model_parallel_is_initialized"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="model_parallel_is_initialized-1542"><a href="#model_parallel_is_initialized-1542"><span class="linenos">1542</span></a><span class="k">def</span><span class="w"> </span><span class="nf">model_parallel_is_initialized</span><span class="p">():</span>
</span><span id="model_parallel_is_initialized-1543"><a href="#model_parallel_is_initialized-1543"><span class="linenos">1543</span></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;Check if tensor and pipeline parallel groups are initialized.&quot;&quot;&quot;</span>
</span><span id="model_parallel_is_initialized-1544"><a href="#model_parallel_is_initialized-1544"><span class="linenos">1544</span></a>    <span class="k">return</span> <span class="n">_TP</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">_PP</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
</span></pre></div>


            <div class="docstring"><p>Check if tensor and pipeline parallel groups are initialized.</p>
</div>


                </section>
                <section id="patch_tensor_parallel_group">
                            <input id="patch_tensor_parallel_group-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
                    <div class="decorator decorator-contextmanager">@contextmanager</div>

        <span class="def">def</span>
        <span class="name">patch_tensor_parallel_group</span><span class="signature pdoc-code condensed">(<span class="param"><span class="n">tp_group</span><span class="p">:</span> <span class="n"><a href="#GroupCoordinator">GroupCoordinator</a></span></span><span class="return-annotation">):</span></span>

                <label class="view-source-button" for="patch_tensor_parallel_group-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#patch_tensor_parallel_group"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="patch_tensor_parallel_group-1550"><a href="#patch_tensor_parallel_group-1550"><span class="linenos">1550</span></a><span class="nd">@contextmanager</span>
</span><span id="patch_tensor_parallel_group-1551"><a href="#patch_tensor_parallel_group-1551"><span class="linenos">1551</span></a><span class="k">def</span><span class="w"> </span><span class="nf">patch_tensor_parallel_group</span><span class="p">(</span><span class="n">tp_group</span><span class="p">:</span> <span class="n">GroupCoordinator</span><span class="p">):</span>
</span><span id="patch_tensor_parallel_group-1552"><a href="#patch_tensor_parallel_group-1552"><span class="linenos">1552</span></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;Patch the tp group temporarily until this function ends.</span>
</span><span id="patch_tensor_parallel_group-1553"><a href="#patch_tensor_parallel_group-1553"><span class="linenos">1553</span></a>
</span><span id="patch_tensor_parallel_group-1554"><a href="#patch_tensor_parallel_group-1554"><span class="linenos">1554</span></a><span class="sd">    This method is for draft workers of speculative decoding to run draft model</span>
</span><span id="patch_tensor_parallel_group-1555"><a href="#patch_tensor_parallel_group-1555"><span class="linenos">1555</span></a><span class="sd">    with different tp degree from that of target model workers.</span>
</span><span id="patch_tensor_parallel_group-1556"><a href="#patch_tensor_parallel_group-1556"><span class="linenos">1556</span></a>
</span><span id="patch_tensor_parallel_group-1557"><a href="#patch_tensor_parallel_group-1557"><span class="linenos">1557</span></a><span class="sd">    Args:</span>
</span><span id="patch_tensor_parallel_group-1558"><a href="#patch_tensor_parallel_group-1558"><span class="linenos">1558</span></a><span class="sd">        tp_group (GroupCoordinator): the tp group coordinator</span>
</span><span id="patch_tensor_parallel_group-1559"><a href="#patch_tensor_parallel_group-1559"><span class="linenos">1559</span></a><span class="sd">    &quot;&quot;&quot;</span>
</span><span id="patch_tensor_parallel_group-1560"><a href="#patch_tensor_parallel_group-1560"><span class="linenos">1560</span></a>    <span class="k">global</span> <span class="n">_TP_STATE_PATCHED</span>
</span><span id="patch_tensor_parallel_group-1561"><a href="#patch_tensor_parallel_group-1561"><span class="linenos">1561</span></a>    <span class="k">assert</span> <span class="ow">not</span> <span class="n">_TP_STATE_PATCHED</span><span class="p">,</span> <span class="s2">&quot;Should not call when it&#39;s already patched&quot;</span>
</span><span id="patch_tensor_parallel_group-1562"><a href="#patch_tensor_parallel_group-1562"><span class="linenos">1562</span></a>
</span><span id="patch_tensor_parallel_group-1563"><a href="#patch_tensor_parallel_group-1563"><span class="linenos">1563</span></a>    <span class="n">_TP_STATE_PATCHED</span> <span class="o">=</span> <span class="kc">True</span>
</span><span id="patch_tensor_parallel_group-1564"><a href="#patch_tensor_parallel_group-1564"><span class="linenos">1564</span></a>    <span class="n">old_tp_group</span> <span class="o">=</span> <span class="n">get_tp_group</span><span class="p">()</span>
</span><span id="patch_tensor_parallel_group-1565"><a href="#patch_tensor_parallel_group-1565"><span class="linenos">1565</span></a>    <span class="k">global</span> <span class="n">_TP</span>
</span><span id="patch_tensor_parallel_group-1566"><a href="#patch_tensor_parallel_group-1566"><span class="linenos">1566</span></a>    <span class="n">_TP</span> <span class="o">=</span> <span class="n">tp_group</span>
</span><span id="patch_tensor_parallel_group-1567"><a href="#patch_tensor_parallel_group-1567"><span class="linenos">1567</span></a>    <span class="k">try</span><span class="p">:</span>
</span><span id="patch_tensor_parallel_group-1568"><a href="#patch_tensor_parallel_group-1568"><span class="linenos">1568</span></a>        <span class="k">yield</span>
</span><span id="patch_tensor_parallel_group-1569"><a href="#patch_tensor_parallel_group-1569"><span class="linenos">1569</span></a>    <span class="k">finally</span><span class="p">:</span>
</span><span id="patch_tensor_parallel_group-1570"><a href="#patch_tensor_parallel_group-1570"><span class="linenos">1570</span></a>        <span class="c1"># restore the original state</span>
</span><span id="patch_tensor_parallel_group-1571"><a href="#patch_tensor_parallel_group-1571"><span class="linenos">1571</span></a>        <span class="n">_TP_STATE_PATCHED</span> <span class="o">=</span> <span class="kc">False</span>
</span><span id="patch_tensor_parallel_group-1572"><a href="#patch_tensor_parallel_group-1572"><span class="linenos">1572</span></a>        <span class="n">_TP</span> <span class="o">=</span> <span class="n">old_tp_group</span>
</span></pre></div>


            <div class="docstring"><p>Patch the tp group temporarily until this function ends.</p>

<p>This method is for draft workers of speculative decoding to run draft model
with different tp degree from that of target model workers.</p>

<p>Args:
    tp_group (GroupCoordinator): the tp group coordinator</p>
</div>


                </section>
                <section id="get_tensor_model_parallel_world_size">
                            <input id="get_tensor_model_parallel_world_size-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="def">def</span>
        <span class="name">get_tensor_model_parallel_world_size</span><span class="signature pdoc-code condensed">(<span class="return-annotation">):</span></span>

                <label class="view-source-button" for="get_tensor_model_parallel_world_size-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#get_tensor_model_parallel_world_size"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="get_tensor_model_parallel_world_size-1575"><a href="#get_tensor_model_parallel_world_size-1575"><span class="linenos">1575</span></a><span class="k">def</span><span class="w"> </span><span class="nf">get_tensor_model_parallel_world_size</span><span class="p">():</span>
</span><span id="get_tensor_model_parallel_world_size-1576"><a href="#get_tensor_model_parallel_world_size-1576"><span class="linenos">1576</span></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;Return world size for the tensor model parallel group.&quot;&quot;&quot;</span>
</span><span id="get_tensor_model_parallel_world_size-1577"><a href="#get_tensor_model_parallel_world_size-1577"><span class="linenos">1577</span></a>    <span class="k">return</span> <span class="n">get_tp_group</span><span class="p">()</span><span class="o">.</span><span class="n">world_size</span>
</span></pre></div>


            <div class="docstring"><p>Return world size for the tensor model parallel group.</p>
</div>


                </section>
                <section id="get_tensor_model_parallel_rank">
                            <input id="get_tensor_model_parallel_rank-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="def">def</span>
        <span class="name">get_tensor_model_parallel_rank</span><span class="signature pdoc-code condensed">(<span class="return-annotation">):</span></span>

                <label class="view-source-button" for="get_tensor_model_parallel_rank-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#get_tensor_model_parallel_rank"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="get_tensor_model_parallel_rank-1580"><a href="#get_tensor_model_parallel_rank-1580"><span class="linenos">1580</span></a><span class="k">def</span><span class="w"> </span><span class="nf">get_tensor_model_parallel_rank</span><span class="p">():</span>
</span><span id="get_tensor_model_parallel_rank-1581"><a href="#get_tensor_model_parallel_rank-1581"><span class="linenos">1581</span></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;Return my rank for the tensor model parallel group.&quot;&quot;&quot;</span>
</span><span id="get_tensor_model_parallel_rank-1582"><a href="#get_tensor_model_parallel_rank-1582"><span class="linenos">1582</span></a>    <span class="k">return</span> <span class="n">get_tp_group</span><span class="p">()</span><span class="o">.</span><span class="n">rank_in_group</span>
</span></pre></div>


            <div class="docstring"><p>Return my rank for the tensor model parallel group.</p>
</div>


                </section>
                <section id="get_moe_expert_parallel_world_size">
                            <input id="get_moe_expert_parallel_world_size-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="def">def</span>
        <span class="name">get_moe_expert_parallel_world_size</span><span class="signature pdoc-code condensed">(<span class="return-annotation">):</span></span>

                <label class="view-source-button" for="get_moe_expert_parallel_world_size-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#get_moe_expert_parallel_world_size"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="get_moe_expert_parallel_world_size-1585"><a href="#get_moe_expert_parallel_world_size-1585"><span class="linenos">1585</span></a><span class="k">def</span><span class="w"> </span><span class="nf">get_moe_expert_parallel_world_size</span><span class="p">():</span>
</span><span id="get_moe_expert_parallel_world_size-1586"><a href="#get_moe_expert_parallel_world_size-1586"><span class="linenos">1586</span></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;Return world size for the moe expert parallel group.&quot;&quot;&quot;</span>
</span><span id="get_moe_expert_parallel_world_size-1587"><a href="#get_moe_expert_parallel_world_size-1587"><span class="linenos">1587</span></a>    <span class="k">return</span> <span class="n">get_moe_ep_group</span><span class="p">()</span><span class="o">.</span><span class="n">world_size</span>
</span></pre></div>


            <div class="docstring"><p>Return world size for the moe expert parallel group.</p>
</div>


                </section>
                <section id="get_moe_expert_parallel_rank">
                            <input id="get_moe_expert_parallel_rank-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="def">def</span>
        <span class="name">get_moe_expert_parallel_rank</span><span class="signature pdoc-code condensed">(<span class="return-annotation">):</span></span>

                <label class="view-source-button" for="get_moe_expert_parallel_rank-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#get_moe_expert_parallel_rank"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="get_moe_expert_parallel_rank-1590"><a href="#get_moe_expert_parallel_rank-1590"><span class="linenos">1590</span></a><span class="k">def</span><span class="w"> </span><span class="nf">get_moe_expert_parallel_rank</span><span class="p">():</span>
</span><span id="get_moe_expert_parallel_rank-1591"><a href="#get_moe_expert_parallel_rank-1591"><span class="linenos">1591</span></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;Return my rank for the moe expert parallel group.&quot;&quot;&quot;</span>
</span><span id="get_moe_expert_parallel_rank-1592"><a href="#get_moe_expert_parallel_rank-1592"><span class="linenos">1592</span></a>    <span class="k">return</span> <span class="n">get_moe_ep_group</span><span class="p">()</span><span class="o">.</span><span class="n">rank_in_group</span>
</span></pre></div>


            <div class="docstring"><p>Return my rank for the moe expert parallel group.</p>
</div>


                </section>
                <section id="get_moe_tensor_parallel_world_size">
                            <input id="get_moe_tensor_parallel_world_size-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="def">def</span>
        <span class="name">get_moe_tensor_parallel_world_size</span><span class="signature pdoc-code condensed">(<span class="return-annotation">):</span></span>

                <label class="view-source-button" for="get_moe_tensor_parallel_world_size-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#get_moe_tensor_parallel_world_size"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="get_moe_tensor_parallel_world_size-1595"><a href="#get_moe_tensor_parallel_world_size-1595"><span class="linenos">1595</span></a><span class="k">def</span><span class="w"> </span><span class="nf">get_moe_tensor_parallel_world_size</span><span class="p">():</span>
</span><span id="get_moe_tensor_parallel_world_size-1596"><a href="#get_moe_tensor_parallel_world_size-1596"><span class="linenos">1596</span></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;Return world size for the moe tensor parallel group.&quot;&quot;&quot;</span>
</span><span id="get_moe_tensor_parallel_world_size-1597"><a href="#get_moe_tensor_parallel_world_size-1597"><span class="linenos">1597</span></a>    <span class="k">return</span> <span class="n">get_moe_tp_group</span><span class="p">()</span><span class="o">.</span><span class="n">world_size</span>
</span></pre></div>


            <div class="docstring"><p>Return world size for the moe tensor parallel group.</p>
</div>


                </section>
                <section id="get_moe_tensor_parallel_rank">
                            <input id="get_moe_tensor_parallel_rank-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="def">def</span>
        <span class="name">get_moe_tensor_parallel_rank</span><span class="signature pdoc-code condensed">(<span class="return-annotation">):</span></span>

                <label class="view-source-button" for="get_moe_tensor_parallel_rank-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#get_moe_tensor_parallel_rank"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="get_moe_tensor_parallel_rank-1600"><a href="#get_moe_tensor_parallel_rank-1600"><span class="linenos">1600</span></a><span class="k">def</span><span class="w"> </span><span class="nf">get_moe_tensor_parallel_rank</span><span class="p">():</span>
</span><span id="get_moe_tensor_parallel_rank-1601"><a href="#get_moe_tensor_parallel_rank-1601"><span class="linenos">1601</span></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;Return my rank for the moe tensor parallel group.&quot;&quot;&quot;</span>
</span><span id="get_moe_tensor_parallel_rank-1602"><a href="#get_moe_tensor_parallel_rank-1602"><span class="linenos">1602</span></a>    <span class="k">return</span> <span class="n">get_moe_tp_group</span><span class="p">()</span><span class="o">.</span><span class="n">rank_in_group</span>
</span></pre></div>


            <div class="docstring"><p>Return my rank for the moe tensor parallel group.</p>
</div>


                </section>
                <section id="destroy_model_parallel">
                            <input id="destroy_model_parallel-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="def">def</span>
        <span class="name">destroy_model_parallel</span><span class="signature pdoc-code condensed">(<span class="return-annotation">):</span></span>

                <label class="view-source-button" for="destroy_model_parallel-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#destroy_model_parallel"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="destroy_model_parallel-1605"><a href="#destroy_model_parallel-1605"><span class="linenos">1605</span></a><span class="k">def</span><span class="w"> </span><span class="nf">destroy_model_parallel</span><span class="p">():</span>
</span><span id="destroy_model_parallel-1606"><a href="#destroy_model_parallel-1606"><span class="linenos">1606</span></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;Set the groups to none and destroy them.&quot;&quot;&quot;</span>
</span><span id="destroy_model_parallel-1607"><a href="#destroy_model_parallel-1607"><span class="linenos">1607</span></a>    <span class="k">global</span> <span class="n">_TP</span>
</span><span id="destroy_model_parallel-1608"><a href="#destroy_model_parallel-1608"><span class="linenos">1608</span></a>    <span class="k">if</span> <span class="n">_TP</span><span class="p">:</span>
</span><span id="destroy_model_parallel-1609"><a href="#destroy_model_parallel-1609"><span class="linenos">1609</span></a>        <span class="n">_TP</span><span class="o">.</span><span class="n">destroy</span><span class="p">()</span>
</span><span id="destroy_model_parallel-1610"><a href="#destroy_model_parallel-1610"><span class="linenos">1610</span></a>    <span class="n">_TP</span> <span class="o">=</span> <span class="kc">None</span>
</span><span id="destroy_model_parallel-1611"><a href="#destroy_model_parallel-1611"><span class="linenos">1611</span></a>
</span><span id="destroy_model_parallel-1612"><a href="#destroy_model_parallel-1612"><span class="linenos">1612</span></a>    <span class="k">global</span> <span class="n">_PP</span>
</span><span id="destroy_model_parallel-1613"><a href="#destroy_model_parallel-1613"><span class="linenos">1613</span></a>    <span class="k">if</span> <span class="n">_PP</span><span class="p">:</span>
</span><span id="destroy_model_parallel-1614"><a href="#destroy_model_parallel-1614"><span class="linenos">1614</span></a>        <span class="n">_PP</span><span class="o">.</span><span class="n">destroy</span><span class="p">()</span>
</span><span id="destroy_model_parallel-1615"><a href="#destroy_model_parallel-1615"><span class="linenos">1615</span></a>    <span class="n">_PP</span> <span class="o">=</span> <span class="kc">None</span>
</span></pre></div>


            <div class="docstring"><p>Set the groups to none and destroy them.</p>
</div>


                </section>
                <section id="destroy_distributed_environment">
                            <input id="destroy_distributed_environment-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="def">def</span>
        <span class="name">destroy_distributed_environment</span><span class="signature pdoc-code condensed">(<span class="return-annotation">):</span></span>

                <label class="view-source-button" for="destroy_distributed_environment-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#destroy_distributed_environment"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="destroy_distributed_environment-1618"><a href="#destroy_distributed_environment-1618"><span class="linenos">1618</span></a><span class="k">def</span><span class="w"> </span><span class="nf">destroy_distributed_environment</span><span class="p">():</span>
</span><span id="destroy_distributed_environment-1619"><a href="#destroy_distributed_environment-1619"><span class="linenos">1619</span></a>    <span class="k">global</span> <span class="n">_WORLD</span>
</span><span id="destroy_distributed_environment-1620"><a href="#destroy_distributed_environment-1620"><span class="linenos">1620</span></a>    <span class="k">if</span> <span class="n">_WORLD</span><span class="p">:</span>
</span><span id="destroy_distributed_environment-1621"><a href="#destroy_distributed_environment-1621"><span class="linenos">1621</span></a>        <span class="n">_WORLD</span><span class="o">.</span><span class="n">destroy</span><span class="p">()</span>
</span><span id="destroy_distributed_environment-1622"><a href="#destroy_distributed_environment-1622"><span class="linenos">1622</span></a>    <span class="n">_WORLD</span> <span class="o">=</span> <span class="kc">None</span>
</span><span id="destroy_distributed_environment-1623"><a href="#destroy_distributed_environment-1623"><span class="linenos">1623</span></a>    <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">distributed</span><span class="o">.</span><span class="n">is_initialized</span><span class="p">():</span>
</span><span id="destroy_distributed_environment-1624"><a href="#destroy_distributed_environment-1624"><span class="linenos">1624</span></a>        <span class="n">torch</span><span class="o">.</span><span class="n">distributed</span><span class="o">.</span><span class="n">destroy_process_group</span><span class="p">()</span>
</span></pre></div>


    

                </section>
                <section id="cleanup_dist_env_and_memory">
                            <input id="cleanup_dist_env_and_memory-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="def">def</span>
        <span class="name">cleanup_dist_env_and_memory</span><span class="signature pdoc-code condensed">(<span class="param"><span class="n">shutdown_ray</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span></span><span class="return-annotation">):</span></span>

                <label class="view-source-button" for="cleanup_dist_env_and_memory-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#cleanup_dist_env_and_memory"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="cleanup_dist_env_and_memory-1627"><a href="#cleanup_dist_env_and_memory-1627"><span class="linenos">1627</span></a><span class="k">def</span><span class="w"> </span><span class="nf">cleanup_dist_env_and_memory</span><span class="p">(</span><span class="n">shutdown_ray</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">):</span>
</span><span id="cleanup_dist_env_and_memory-1628"><a href="#cleanup_dist_env_and_memory-1628"><span class="linenos">1628</span></a>    <span class="n">destroy_model_parallel</span><span class="p">()</span>
</span><span id="cleanup_dist_env_and_memory-1629"><a href="#cleanup_dist_env_and_memory-1629"><span class="linenos">1629</span></a>    <span class="n">destroy_distributed_environment</span><span class="p">()</span>
</span><span id="cleanup_dist_env_and_memory-1630"><a href="#cleanup_dist_env_and_memory-1630"><span class="linenos">1630</span></a>    <span class="k">with</span> <span class="n">contextlib</span><span class="o">.</span><span class="n">suppress</span><span class="p">(</span><span class="ne">AssertionError</span><span class="p">):</span>
</span><span id="cleanup_dist_env_and_memory-1631"><a href="#cleanup_dist_env_and_memory-1631"><span class="linenos">1631</span></a>        <span class="n">torch</span><span class="o">.</span><span class="n">distributed</span><span class="o">.</span><span class="n">destroy_process_group</span><span class="p">()</span>
</span><span id="cleanup_dist_env_and_memory-1632"><a href="#cleanup_dist_env_and_memory-1632"><span class="linenos">1632</span></a>    <span class="k">if</span> <span class="n">shutdown_ray</span><span class="p">:</span>
</span><span id="cleanup_dist_env_and_memory-1633"><a href="#cleanup_dist_env_and_memory-1633"><span class="linenos">1633</span></a>        <span class="kn">import</span><span class="w"> </span><span class="nn">ray</span>  <span class="c1"># Lazy import Ray</span>
</span><span id="cleanup_dist_env_and_memory-1634"><a href="#cleanup_dist_env_and_memory-1634"><span class="linenos">1634</span></a>
</span><span id="cleanup_dist_env_and_memory-1635"><a href="#cleanup_dist_env_and_memory-1635"><span class="linenos">1635</span></a>        <span class="n">ray</span><span class="o">.</span><span class="n">shutdown</span><span class="p">()</span>
</span><span id="cleanup_dist_env_and_memory-1636"><a href="#cleanup_dist_env_and_memory-1636"><span class="linenos">1636</span></a>    <span class="n">gc</span><span class="o">.</span><span class="n">collect</span><span class="p">()</span>
</span><span id="cleanup_dist_env_and_memory-1637"><a href="#cleanup_dist_env_and_memory-1637"><span class="linenos">1637</span></a>    <span class="k">if</span> <span class="ow">not</span> <span class="n">current_platform</span><span class="o">.</span><span class="n">is_cpu</span><span class="p">():</span>
</span><span id="cleanup_dist_env_and_memory-1638"><a href="#cleanup_dist_env_and_memory-1638"><span class="linenos">1638</span></a>        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">torch</span><span class="p">,</span> <span class="s2">&quot;cuda&quot;</span><span class="p">)</span> <span class="ow">and</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">():</span>
</span><span id="cleanup_dist_env_and_memory-1639"><a href="#cleanup_dist_env_and_memory-1639"><span class="linenos">1639</span></a>            <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">empty_cache</span><span class="p">()</span>
</span><span id="cleanup_dist_env_and_memory-1640"><a href="#cleanup_dist_env_and_memory-1640"><span class="linenos">1640</span></a>            <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">_C</span><span class="p">,</span> <span class="s2">&quot;_host_emptyCache&quot;</span><span class="p">):</span>
</span><span id="cleanup_dist_env_and_memory-1641"><a href="#cleanup_dist_env_and_memory-1641"><span class="linenos">1641</span></a>                <span class="n">torch</span><span class="o">.</span><span class="n">_C</span><span class="o">.</span><span class="n">_host_emptyCache</span><span class="p">()</span>
</span><span id="cleanup_dist_env_and_memory-1642"><a href="#cleanup_dist_env_and_memory-1642"><span class="linenos">1642</span></a>            <span class="k">else</span><span class="p">:</span>
</span><span id="cleanup_dist_env_and_memory-1643"><a href="#cleanup_dist_env_and_memory-1643"><span class="linenos">1643</span></a>                <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span>
</span><span id="cleanup_dist_env_and_memory-1644"><a href="#cleanup_dist_env_and_memory-1644"><span class="linenos">1644</span></a>                    <span class="s2">&quot;torch._C._host_emptyCache() only available in Pytorch &gt;=2.5&quot;</span>
</span><span id="cleanup_dist_env_and_memory-1645"><a href="#cleanup_dist_env_and_memory-1645"><span class="linenos">1645</span></a>                <span class="p">)</span>
</span><span id="cleanup_dist_env_and_memory-1646"><a href="#cleanup_dist_env_and_memory-1646"><span class="linenos">1646</span></a>        <span class="k">elif</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">torch</span><span class="p">,</span> <span class="s2">&quot;xpu&quot;</span><span class="p">)</span> <span class="ow">and</span> <span class="n">torch</span><span class="o">.</span><span class="n">xpu</span><span class="o">.</span><span class="n">is_available</span><span class="p">():</span>
</span><span id="cleanup_dist_env_and_memory-1647"><a href="#cleanup_dist_env_and_memory-1647"><span class="linenos">1647</span></a>            <span class="n">torch</span><span class="o">.</span><span class="n">xpu</span><span class="o">.</span><span class="n">empty_cache</span><span class="p">()</span>
</span><span id="cleanup_dist_env_and_memory-1648"><a href="#cleanup_dist_env_and_memory-1648"><span class="linenos">1648</span></a>        <span class="k">elif</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">torch</span><span class="p">,</span> <span class="s2">&quot;npu&quot;</span><span class="p">)</span> <span class="ow">and</span> <span class="n">torch</span><span class="o">.</span><span class="n">npu</span><span class="o">.</span><span class="n">is_available</span><span class="p">():</span>
</span><span id="cleanup_dist_env_and_memory-1649"><a href="#cleanup_dist_env_and_memory-1649"><span class="linenos">1649</span></a>            <span class="n">torch</span><span class="o">.</span><span class="n">npu</span><span class="o">.</span><span class="n">empty_cache</span><span class="p">()</span>
</span></pre></div>


    

                </section>
                <section id="in_the_same_node_as">
                            <input id="in_the_same_node_as-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="def">def</span>
        <span class="name">in_the_same_node_as</span><span class="signature pdoc-code multiline">(<span class="param">	<span class="n">pg</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">distributed</span><span class="o">.</span><span class="n">distributed_c10d</span><span class="o">.</span><span class="n">ProcessGroup</span>,</span><span class="param">	<span class="n">source_rank</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span></span><span class="return-annotation">) -> <span class="n">List</span><span class="p">[</span><span class="nb">bool</span><span class="p">]</span>:</span></span>

                <label class="view-source-button" for="in_the_same_node_as-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#in_the_same_node_as"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="in_the_same_node_as-1652"><a href="#in_the_same_node_as-1652"><span class="linenos">1652</span></a><span class="k">def</span><span class="w"> </span><span class="nf">in_the_same_node_as</span><span class="p">(</span><span class="n">pg</span><span class="p">:</span> <span class="n">ProcessGroup</span><span class="p">,</span> <span class="n">source_rank</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="nb">bool</span><span class="p">]:</span>
</span><span id="in_the_same_node_as-1653"><a href="#in_the_same_node_as-1653"><span class="linenos">1653</span></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="in_the_same_node_as-1654"><a href="#in_the_same_node_as-1654"><span class="linenos">1654</span></a><span class="sd">    This is a collective operation that returns if each rank is in the same node</span>
</span><span id="in_the_same_node_as-1655"><a href="#in_the_same_node_as-1655"><span class="linenos">1655</span></a><span class="sd">    as the source rank. It tests if processes are attached to the same</span>
</span><span id="in_the_same_node_as-1656"><a href="#in_the_same_node_as-1656"><span class="linenos">1656</span></a><span class="sd">    memory system (shared access to shared memory).</span>
</span><span id="in_the_same_node_as-1657"><a href="#in_the_same_node_as-1657"><span class="linenos">1657</span></a><span class="sd">    &quot;&quot;&quot;</span>
</span><span id="in_the_same_node_as-1658"><a href="#in_the_same_node_as-1658"><span class="linenos">1658</span></a>    <span class="k">assert</span> <span class="p">(</span>
</span><span id="in_the_same_node_as-1659"><a href="#in_the_same_node_as-1659"><span class="linenos">1659</span></a>        <span class="n">torch</span><span class="o">.</span><span class="n">distributed</span><span class="o">.</span><span class="n">get_backend</span><span class="p">(</span><span class="n">pg</span><span class="p">)</span> <span class="o">!=</span> <span class="n">torch</span><span class="o">.</span><span class="n">distributed</span><span class="o">.</span><span class="n">Backend</span><span class="o">.</span><span class="n">NCCL</span>
</span><span id="in_the_same_node_as-1660"><a href="#in_the_same_node_as-1660"><span class="linenos">1660</span></a>    <span class="p">),</span> <span class="s2">&quot;in_the_same_node_as should be tested with a non-NCCL group.&quot;</span>
</span><span id="in_the_same_node_as-1661"><a href="#in_the_same_node_as-1661"><span class="linenos">1661</span></a>    <span class="c1"># local rank inside the group</span>
</span><span id="in_the_same_node_as-1662"><a href="#in_the_same_node_as-1662"><span class="linenos">1662</span></a>    <span class="n">rank</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">distributed</span><span class="o">.</span><span class="n">get_rank</span><span class="p">(</span><span class="n">group</span><span class="o">=</span><span class="n">pg</span><span class="p">)</span>
</span><span id="in_the_same_node_as-1663"><a href="#in_the_same_node_as-1663"><span class="linenos">1663</span></a>    <span class="n">world_size</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">distributed</span><span class="o">.</span><span class="n">get_world_size</span><span class="p">(</span><span class="n">group</span><span class="o">=</span><span class="n">pg</span><span class="p">)</span>
</span><span id="in_the_same_node_as-1664"><a href="#in_the_same_node_as-1664"><span class="linenos">1664</span></a>
</span><span id="in_the_same_node_as-1665"><a href="#in_the_same_node_as-1665"><span class="linenos">1665</span></a>    <span class="c1"># local tensor in each process to store the result</span>
</span><span id="in_the_same_node_as-1666"><a href="#in_the_same_node_as-1666"><span class="linenos">1666</span></a>    <span class="n">is_in_the_same_node</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mi">0</span><span class="p">]</span> <span class="o">*</span> <span class="n">world_size</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
</span><span id="in_the_same_node_as-1667"><a href="#in_the_same_node_as-1667"><span class="linenos">1667</span></a>
</span><span id="in_the_same_node_as-1668"><a href="#in_the_same_node_as-1668"><span class="linenos">1668</span></a>    <span class="c1"># global ranks of the processes in the group</span>
</span><span id="in_the_same_node_as-1669"><a href="#in_the_same_node_as-1669"><span class="linenos">1669</span></a>    <span class="n">ranks</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">distributed</span><span class="o">.</span><span class="n">get_process_group_ranks</span><span class="p">(</span><span class="n">pg</span><span class="p">)</span>
</span><span id="in_the_same_node_as-1670"><a href="#in_the_same_node_as-1670"><span class="linenos">1670</span></a>
</span><span id="in_the_same_node_as-1671"><a href="#in_the_same_node_as-1671"><span class="linenos">1671</span></a>    <span class="n">magic_message</span> <span class="o">=</span> <span class="sa">b</span><span class="s2">&quot;magic_message&quot;</span>
</span><span id="in_the_same_node_as-1672"><a href="#in_the_same_node_as-1672"><span class="linenos">1672</span></a>    <span class="n">shm</span> <span class="o">=</span> <span class="kc">None</span>
</span><span id="in_the_same_node_as-1673"><a href="#in_the_same_node_as-1673"><span class="linenos">1673</span></a>
</span><span id="in_the_same_node_as-1674"><a href="#in_the_same_node_as-1674"><span class="linenos">1674</span></a>    <span class="k">try</span><span class="p">:</span>
</span><span id="in_the_same_node_as-1675"><a href="#in_the_same_node_as-1675"><span class="linenos">1675</span></a>        <span class="k">with</span> <span class="n">contextlib</span><span class="o">.</span><span class="n">suppress</span><span class="p">(</span><span class="ne">OSError</span><span class="p">):</span>
</span><span id="in_the_same_node_as-1676"><a href="#in_the_same_node_as-1676"><span class="linenos">1676</span></a>            <span class="k">if</span> <span class="n">rank</span> <span class="o">==</span> <span class="n">source_rank</span><span class="p">:</span>
</span><span id="in_the_same_node_as-1677"><a href="#in_the_same_node_as-1677"><span class="linenos">1677</span></a>                <span class="c1"># create a shared memory segment</span>
</span><span id="in_the_same_node_as-1678"><a href="#in_the_same_node_as-1678"><span class="linenos">1678</span></a>                <span class="n">shm</span> <span class="o">=</span> <span class="n">shared_memory</span><span class="o">.</span><span class="n">SharedMemory</span><span class="p">(</span><span class="n">create</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="mi">128</span><span class="p">)</span>
</span><span id="in_the_same_node_as-1679"><a href="#in_the_same_node_as-1679"><span class="linenos">1679</span></a>                <span class="n">shm</span><span class="o">.</span><span class="n">buf</span><span class="p">[:</span> <span class="nb">len</span><span class="p">(</span><span class="n">magic_message</span><span class="p">)]</span> <span class="o">=</span> <span class="n">magic_message</span>
</span><span id="in_the_same_node_as-1680"><a href="#in_the_same_node_as-1680"><span class="linenos">1680</span></a>                <span class="n">torch</span><span class="o">.</span><span class="n">distributed</span><span class="o">.</span><span class="n">broadcast_object_list</span><span class="p">(</span>
</span><span id="in_the_same_node_as-1681"><a href="#in_the_same_node_as-1681"><span class="linenos">1681</span></a>                    <span class="p">[</span><span class="n">shm</span><span class="o">.</span><span class="n">name</span><span class="p">],</span> <span class="n">src</span><span class="o">=</span><span class="n">ranks</span><span class="p">[</span><span class="n">source_rank</span><span class="p">],</span> <span class="n">group</span><span class="o">=</span><span class="n">pg</span>
</span><span id="in_the_same_node_as-1682"><a href="#in_the_same_node_as-1682"><span class="linenos">1682</span></a>                <span class="p">)</span>
</span><span id="in_the_same_node_as-1683"><a href="#in_the_same_node_as-1683"><span class="linenos">1683</span></a>                <span class="n">is_in_the_same_node</span><span class="p">[</span><span class="n">rank</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>
</span><span id="in_the_same_node_as-1684"><a href="#in_the_same_node_as-1684"><span class="linenos">1684</span></a>            <span class="k">else</span><span class="p">:</span>
</span><span id="in_the_same_node_as-1685"><a href="#in_the_same_node_as-1685"><span class="linenos">1685</span></a>                <span class="c1"># try to open the shared memory segment</span>
</span><span id="in_the_same_node_as-1686"><a href="#in_the_same_node_as-1686"><span class="linenos">1686</span></a>                <span class="n">recv</span> <span class="o">=</span> <span class="p">[</span><span class="kc">None</span><span class="p">]</span>
</span><span id="in_the_same_node_as-1687"><a href="#in_the_same_node_as-1687"><span class="linenos">1687</span></a>                <span class="n">torch</span><span class="o">.</span><span class="n">distributed</span><span class="o">.</span><span class="n">broadcast_object_list</span><span class="p">(</span>
</span><span id="in_the_same_node_as-1688"><a href="#in_the_same_node_as-1688"><span class="linenos">1688</span></a>                    <span class="n">recv</span><span class="p">,</span> <span class="n">src</span><span class="o">=</span><span class="n">ranks</span><span class="p">[</span><span class="n">source_rank</span><span class="p">],</span> <span class="n">group</span><span class="o">=</span><span class="n">pg</span>
</span><span id="in_the_same_node_as-1689"><a href="#in_the_same_node_as-1689"><span class="linenos">1689</span></a>                <span class="p">)</span>
</span><span id="in_the_same_node_as-1690"><a href="#in_the_same_node_as-1690"><span class="linenos">1690</span></a>                <span class="n">name</span> <span class="o">=</span> <span class="n">recv</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
</span><span id="in_the_same_node_as-1691"><a href="#in_the_same_node_as-1691"><span class="linenos">1691</span></a>                <span class="c1"># fix to https://stackoverflow.com/q/62748654/9191338</span>
</span><span id="in_the_same_node_as-1692"><a href="#in_the_same_node_as-1692"><span class="linenos">1692</span></a>                <span class="c1"># Python incorrectly tracks shared memory even if it is not</span>
</span><span id="in_the_same_node_as-1693"><a href="#in_the_same_node_as-1693"><span class="linenos">1693</span></a>                <span class="c1"># created by the process. The following patch is a workaround.</span>
</span><span id="in_the_same_node_as-1694"><a href="#in_the_same_node_as-1694"><span class="linenos">1694</span></a>                <span class="k">with</span> <span class="n">patch</span><span class="p">(</span>
</span><span id="in_the_same_node_as-1695"><a href="#in_the_same_node_as-1695"><span class="linenos">1695</span></a>                    <span class="s2">&quot;multiprocessing.resource_tracker.register&quot;</span><span class="p">,</span>
</span><span id="in_the_same_node_as-1696"><a href="#in_the_same_node_as-1696"><span class="linenos">1696</span></a>                    <span class="k">lambda</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">:</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="in_the_same_node_as-1697"><a href="#in_the_same_node_as-1697"><span class="linenos">1697</span></a>                <span class="p">):</span>
</span><span id="in_the_same_node_as-1698"><a href="#in_the_same_node_as-1698"><span class="linenos">1698</span></a>                    <span class="n">shm</span> <span class="o">=</span> <span class="n">shared_memory</span><span class="o">.</span><span class="n">SharedMemory</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
</span><span id="in_the_same_node_as-1699"><a href="#in_the_same_node_as-1699"><span class="linenos">1699</span></a>                <span class="k">if</span> <span class="n">shm</span><span class="o">.</span><span class="n">buf</span><span class="p">[:</span> <span class="nb">len</span><span class="p">(</span><span class="n">magic_message</span><span class="p">)]</span> <span class="o">==</span> <span class="n">magic_message</span><span class="p">:</span>
</span><span id="in_the_same_node_as-1700"><a href="#in_the_same_node_as-1700"><span class="linenos">1700</span></a>                    <span class="n">is_in_the_same_node</span><span class="p">[</span><span class="n">rank</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>
</span><span id="in_the_same_node_as-1701"><a href="#in_the_same_node_as-1701"><span class="linenos">1701</span></a>    <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
</span><span id="in_the_same_node_as-1702"><a href="#in_the_same_node_as-1702"><span class="linenos">1702</span></a>        <span class="n">logger</span><span class="o">.</span><span class="n">error</span><span class="p">(</span><span class="s2">&quot;Error ignored in is_in_the_same_node: </span><span class="si">%s</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">e</span><span class="p">)</span>
</span><span id="in_the_same_node_as-1703"><a href="#in_the_same_node_as-1703"><span class="linenos">1703</span></a>    <span class="k">finally</span><span class="p">:</span>
</span><span id="in_the_same_node_as-1704"><a href="#in_the_same_node_as-1704"><span class="linenos">1704</span></a>        <span class="k">if</span> <span class="n">shm</span><span class="p">:</span>
</span><span id="in_the_same_node_as-1705"><a href="#in_the_same_node_as-1705"><span class="linenos">1705</span></a>            <span class="n">shm</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
</span><span id="in_the_same_node_as-1706"><a href="#in_the_same_node_as-1706"><span class="linenos">1706</span></a>
</span><span id="in_the_same_node_as-1707"><a href="#in_the_same_node_as-1707"><span class="linenos">1707</span></a>    <span class="n">torch</span><span class="o">.</span><span class="n">distributed</span><span class="o">.</span><span class="n">barrier</span><span class="p">(</span><span class="n">group</span><span class="o">=</span><span class="n">pg</span><span class="p">)</span>
</span><span id="in_the_same_node_as-1708"><a href="#in_the_same_node_as-1708"><span class="linenos">1708</span></a>
</span><span id="in_the_same_node_as-1709"><a href="#in_the_same_node_as-1709"><span class="linenos">1709</span></a>    <span class="c1"># clean up the shared memory segment</span>
</span><span id="in_the_same_node_as-1710"><a href="#in_the_same_node_as-1710"><span class="linenos">1710</span></a>    <span class="k">with</span> <span class="n">contextlib</span><span class="o">.</span><span class="n">suppress</span><span class="p">(</span><span class="ne">OSError</span><span class="p">):</span>
</span><span id="in_the_same_node_as-1711"><a href="#in_the_same_node_as-1711"><span class="linenos">1711</span></a>        <span class="k">if</span> <span class="n">rank</span> <span class="o">==</span> <span class="n">source_rank</span> <span class="ow">and</span> <span class="n">shm</span><span class="p">:</span>
</span><span id="in_the_same_node_as-1712"><a href="#in_the_same_node_as-1712"><span class="linenos">1712</span></a>            <span class="n">shm</span><span class="o">.</span><span class="n">unlink</span><span class="p">()</span>
</span><span id="in_the_same_node_as-1713"><a href="#in_the_same_node_as-1713"><span class="linenos">1713</span></a>    <span class="n">torch</span><span class="o">.</span><span class="n">distributed</span><span class="o">.</span><span class="n">all_reduce</span><span class="p">(</span><span class="n">is_in_the_same_node</span><span class="p">,</span> <span class="n">group</span><span class="o">=</span><span class="n">pg</span><span class="p">)</span>
</span><span id="in_the_same_node_as-1714"><a href="#in_the_same_node_as-1714"><span class="linenos">1714</span></a>
</span><span id="in_the_same_node_as-1715"><a href="#in_the_same_node_as-1715"><span class="linenos">1715</span></a>    <span class="k">return</span> <span class="p">[</span><span class="n">x</span> <span class="o">==</span> <span class="mi">1</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">is_in_the_same_node</span><span class="o">.</span><span class="n">tolist</span><span class="p">()]</span>
</span></pre></div>


            <div class="docstring"><p>This is a collective operation that returns if each rank is in the same node
as the source rank. It tests if processes are attached to the same
memory system (shared access to shared memory).</p>
</div>


                </section>
                <section id="vllm_get_pp_group">
                    <div class="attr variable">
            <span class="name">vllm_get_pp_group</span>        =
<span class="default_value">None</span>

        
    </div>
    <a class="headerlink" href="#vllm_get_pp_group"></a>
    
    

                </section>
                <section id="vllm_get_tp_group">
                    <div class="attr variable">
            <span class="name">vllm_get_tp_group</span>        =
<span class="default_value">None</span>

        
    </div>
    <a class="headerlink" href="#vllm_get_tp_group"></a>
    
    

                </section>
                <section id="vllm_get_world_group">
                    <div class="attr variable">
            <span class="name">vllm_get_world_group</span>        =
<span class="default_value">None</span>

        
    </div>
    <a class="headerlink" href="#vllm_get_world_group"></a>
    
    

                </section>
                <section id="monkey_patch_vllm_parallel_state">
                            <input id="monkey_patch_vllm_parallel_state-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="def">def</span>
        <span class="name">monkey_patch_vllm_parallel_state</span><span class="signature pdoc-code condensed">(<span class="param"><span class="n">reverse</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span></span><span class="return-annotation">):</span></span>

                <label class="view-source-button" for="monkey_patch_vllm_parallel_state-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#monkey_patch_vllm_parallel_state"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="monkey_patch_vllm_parallel_state-1723"><a href="#monkey_patch_vllm_parallel_state-1723"><span class="linenos">1723</span></a><span class="k">def</span><span class="w"> </span><span class="nf">monkey_patch_vllm_parallel_state</span><span class="p">(</span><span class="n">reverse</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">):</span>
</span><span id="monkey_patch_vllm_parallel_state-1724"><a href="#monkey_patch_vllm_parallel_state-1724"><span class="linenos">1724</span></a>    <span class="k">try</span><span class="p">:</span>
</span><span id="monkey_patch_vllm_parallel_state-1725"><a href="#monkey_patch_vllm_parallel_state-1725"><span class="linenos">1725</span></a>        <span class="kn">import</span><span class="w"> </span><span class="nn">vllm.distributed.parallel_state</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">vllm_parrlel_state</span>
</span><span id="monkey_patch_vllm_parallel_state-1726"><a href="#monkey_patch_vllm_parallel_state-1726"><span class="linenos">1726</span></a>    <span class="k">except</span> <span class="ne">ImportError</span><span class="p">:</span>
</span><span id="monkey_patch_vllm_parallel_state-1727"><a href="#monkey_patch_vllm_parallel_state-1727"><span class="linenos">1727</span></a>        <span class="k">return</span>
</span><span id="monkey_patch_vllm_parallel_state-1728"><a href="#monkey_patch_vllm_parallel_state-1728"><span class="linenos">1728</span></a>
</span><span id="monkey_patch_vllm_parallel_state-1729"><a href="#monkey_patch_vllm_parallel_state-1729"><span class="linenos">1729</span></a>    <span class="k">global</span> <span class="n">vllm_get_pp_group</span><span class="p">,</span> <span class="n">vllm_get_tp_group</span><span class="p">,</span> <span class="n">vllm_get_world_group</span>
</span><span id="monkey_patch_vllm_parallel_state-1730"><a href="#monkey_patch_vllm_parallel_state-1730"><span class="linenos">1730</span></a>    <span class="k">if</span> <span class="n">vllm_get_pp_group</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="monkey_patch_vllm_parallel_state-1731"><a href="#monkey_patch_vllm_parallel_state-1731"><span class="linenos">1731</span></a>        <span class="n">vllm_get_pp_group</span> <span class="o">=</span> <span class="n">vllm_parrlel_state</span><span class="o">.</span><span class="n">get_pp_group</span>
</span><span id="monkey_patch_vllm_parallel_state-1732"><a href="#monkey_patch_vllm_parallel_state-1732"><span class="linenos">1732</span></a>        <span class="n">vllm_get_tp_group</span> <span class="o">=</span> <span class="n">vllm_parrlel_state</span><span class="o">.</span><span class="n">get_tp_group</span>
</span><span id="monkey_patch_vllm_parallel_state-1733"><a href="#monkey_patch_vllm_parallel_state-1733"><span class="linenos">1733</span></a>        <span class="n">vllm_get_world_group</span> <span class="o">=</span> <span class="n">vllm_parrlel_state</span><span class="o">.</span><span class="n">get_world_group</span>
</span><span id="monkey_patch_vllm_parallel_state-1734"><a href="#monkey_patch_vllm_parallel_state-1734"><span class="linenos">1734</span></a>    <span class="k">if</span> <span class="n">reverse</span><span class="p">:</span>
</span><span id="monkey_patch_vllm_parallel_state-1735"><a href="#monkey_patch_vllm_parallel_state-1735"><span class="linenos">1735</span></a>        <span class="nb">setattr</span><span class="p">(</span><span class="n">vllm_parrlel_state</span><span class="p">,</span> <span class="s2">&quot;get_pp_group&quot;</span><span class="p">,</span> <span class="n">vllm_get_pp_group</span><span class="p">)</span>
</span><span id="monkey_patch_vllm_parallel_state-1736"><a href="#monkey_patch_vllm_parallel_state-1736"><span class="linenos">1736</span></a>        <span class="nb">setattr</span><span class="p">(</span><span class="n">vllm_parrlel_state</span><span class="p">,</span> <span class="s2">&quot;get_tp_group&quot;</span><span class="p">,</span> <span class="n">vllm_get_tp_group</span><span class="p">)</span>
</span><span id="monkey_patch_vllm_parallel_state-1737"><a href="#monkey_patch_vllm_parallel_state-1737"><span class="linenos">1737</span></a>        <span class="nb">setattr</span><span class="p">(</span><span class="n">vllm_parrlel_state</span><span class="p">,</span> <span class="s2">&quot;get_world_group&quot;</span><span class="p">,</span> <span class="n">vllm_get_world_group</span><span class="p">)</span>
</span><span id="monkey_patch_vllm_parallel_state-1738"><a href="#monkey_patch_vllm_parallel_state-1738"><span class="linenos">1738</span></a>    <span class="k">else</span><span class="p">:</span>
</span><span id="monkey_patch_vllm_parallel_state-1739"><a href="#monkey_patch_vllm_parallel_state-1739"><span class="linenos">1739</span></a>        <span class="nb">setattr</span><span class="p">(</span><span class="n">vllm_parrlel_state</span><span class="p">,</span> <span class="s2">&quot;get_pp_group&quot;</span><span class="p">,</span> <span class="n">get_pp_group</span><span class="p">)</span>
</span><span id="monkey_patch_vllm_parallel_state-1740"><a href="#monkey_patch_vllm_parallel_state-1740"><span class="linenos">1740</span></a>        <span class="nb">setattr</span><span class="p">(</span><span class="n">vllm_parrlel_state</span><span class="p">,</span> <span class="s2">&quot;get_tp_group&quot;</span><span class="p">,</span> <span class="n">get_tp_group</span><span class="p">)</span>
</span><span id="monkey_patch_vllm_parallel_state-1741"><a href="#monkey_patch_vllm_parallel_state-1741"><span class="linenos">1741</span></a>        <span class="nb">setattr</span><span class="p">(</span><span class="n">vllm_parrlel_state</span><span class="p">,</span> <span class="s2">&quot;get_world_group&quot;</span><span class="p">,</span> <span class="n">get_world_group</span><span class="p">)</span>
</span></pre></div>


    

                </section>
                <section id="inplace_all_reduce">
                            <input id="inplace_all_reduce-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="def">def</span>
        <span class="name">inplace_all_reduce</span><span class="signature pdoc-code condensed">(<span class="param"><span class="n">tensor</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span>, </span><span class="param"><span class="n">group_name</span><span class="p">:</span> <span class="nb">str</span></span><span class="return-annotation">) -> <span class="kc">None</span>:</span></span>

                <label class="view-source-button" for="inplace_all_reduce-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#inplace_all_reduce"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="inplace_all_reduce-116"><a href="#inplace_all_reduce-116"><span class="linenos">116</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">inplace_all_reduce</span><span class="p">(</span><span class="n">tensor</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">group_name</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="inplace_all_reduce-117"><a href="#inplace_all_reduce-117"><span class="linenos">117</span></a>        <span class="k">assert</span> <span class="n">group_name</span> <span class="ow">in</span> <span class="n">_groups</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;Group </span><span class="si">{</span><span class="n">group_name</span><span class="si">}</span><span class="s2"> is not found.&quot;</span>
</span><span id="inplace_all_reduce-118"><a href="#inplace_all_reduce-118"><span class="linenos">118</span></a>        <span class="n">group</span> <span class="o">=</span> <span class="n">_groups</span><span class="p">[</span><span class="n">group_name</span><span class="p">]()</span>
</span><span id="inplace_all_reduce-119"><a href="#inplace_all_reduce-119"><span class="linenos">119</span></a>        <span class="k">if</span> <span class="n">group</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="inplace_all_reduce-120"><a href="#inplace_all_reduce-120"><span class="linenos">120</span></a>            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Group </span><span class="si">{</span><span class="n">group_name</span><span class="si">}</span><span class="s2"> is destroyed.&quot;</span><span class="p">)</span>
</span><span id="inplace_all_reduce-121"><a href="#inplace_all_reduce-121"><span class="linenos">121</span></a>        <span class="n">group</span><span class="o">.</span><span class="n">_all_reduce_in_place</span><span class="p">(</span><span class="n">tensor</span><span class="p">)</span>
</span></pre></div>


    

                </section>
                <section id="inplace_all_reduce_fake">
                            <input id="inplace_all_reduce_fake-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="def">def</span>
        <span class="name">inplace_all_reduce_fake</span><span class="signature pdoc-code condensed">(<span class="param"><span class="n">tensor</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span>, </span><span class="param"><span class="n">group_name</span><span class="p">:</span> <span class="nb">str</span></span><span class="return-annotation">) -> <span class="kc">None</span>:</span></span>

                <label class="view-source-button" for="inplace_all_reduce_fake-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#inplace_all_reduce_fake"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="inplace_all_reduce_fake-123"><a href="#inplace_all_reduce_fake-123"><span class="linenos">123</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">inplace_all_reduce_fake</span><span class="p">(</span><span class="n">tensor</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">group_name</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="inplace_all_reduce_fake-124"><a href="#inplace_all_reduce_fake-124"><span class="linenos">124</span></a>        <span class="k">return</span>
</span></pre></div>


    

                </section>
                <section id="outplace_all_reduce">
                            <input id="outplace_all_reduce-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="def">def</span>
        <span class="name">outplace_all_reduce</span><span class="signature pdoc-code multiline">(<span class="param">	<span class="n">tensor</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span>,</span><span class="param">	<span class="n">group_name</span><span class="p">:</span> <span class="nb">str</span>,</span><span class="param">	<span class="n">outplace_all_reduce_method</span><span class="p">:</span> <span class="nb">str</span></span><span class="return-annotation">) -> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span>:</span></span>

                <label class="view-source-button" for="outplace_all_reduce-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#outplace_all_reduce"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="outplace_all_reduce-133"><a href="#outplace_all_reduce-133"><span class="linenos">133</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">outplace_all_reduce</span><span class="p">(</span>
</span><span id="outplace_all_reduce-134"><a href="#outplace_all_reduce-134"><span class="linenos">134</span></a>        <span class="n">tensor</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">group_name</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">outplace_all_reduce_method</span><span class="p">:</span> <span class="nb">str</span>
</span><span id="outplace_all_reduce-135"><a href="#outplace_all_reduce-135"><span class="linenos">135</span></a>    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
</span><span id="outplace_all_reduce-136"><a href="#outplace_all_reduce-136"><span class="linenos">136</span></a>        <span class="k">assert</span> <span class="n">group_name</span> <span class="ow">in</span> <span class="n">_groups</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;Group </span><span class="si">{</span><span class="n">group_name</span><span class="si">}</span><span class="s2"> is not found.&quot;</span>
</span><span id="outplace_all_reduce-137"><a href="#outplace_all_reduce-137"><span class="linenos">137</span></a>        <span class="n">group</span> <span class="o">=</span> <span class="n">_groups</span><span class="p">[</span><span class="n">group_name</span><span class="p">]()</span>
</span><span id="outplace_all_reduce-138"><a href="#outplace_all_reduce-138"><span class="linenos">138</span></a>        <span class="k">if</span> <span class="n">group</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="outplace_all_reduce-139"><a href="#outplace_all_reduce-139"><span class="linenos">139</span></a>            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Group </span><span class="si">{</span><span class="n">group_name</span><span class="si">}</span><span class="s2"> is destroyed.&quot;</span><span class="p">)</span>
</span><span id="outplace_all_reduce-140"><a href="#outplace_all_reduce-140"><span class="linenos">140</span></a>        <span class="k">return</span> <span class="n">group</span><span class="o">.</span><span class="n">_all_reduce_out_place</span><span class="p">(</span><span class="n">tensor</span><span class="p">,</span> <span class="n">outplace_all_reduce_method</span><span class="p">)</span>
</span></pre></div>


    

                </section>
                <section id="outplace_all_reduce_fake">
                            <input id="outplace_all_reduce_fake-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="def">def</span>
        <span class="name">outplace_all_reduce_fake</span><span class="signature pdoc-code multiline">(<span class="param">	<span class="n">tensor</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span>,</span><span class="param">	<span class="n">group_name</span><span class="p">:</span> <span class="nb">str</span>,</span><span class="param">	<span class="n">outplace_all_reduce_method</span><span class="p">:</span> <span class="nb">str</span></span><span class="return-annotation">) -> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span>:</span></span>

                <label class="view-source-button" for="outplace_all_reduce_fake-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#outplace_all_reduce_fake"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="outplace_all_reduce_fake-142"><a href="#outplace_all_reduce_fake-142"><span class="linenos">142</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">outplace_all_reduce_fake</span><span class="p">(</span>
</span><span id="outplace_all_reduce_fake-143"><a href="#outplace_all_reduce_fake-143"><span class="linenos">143</span></a>        <span class="n">tensor</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">group_name</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">outplace_all_reduce_method</span><span class="p">:</span> <span class="nb">str</span>
</span><span id="outplace_all_reduce_fake-144"><a href="#outplace_all_reduce_fake-144"><span class="linenos">144</span></a>    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
</span><span id="outplace_all_reduce_fake-145"><a href="#outplace_all_reduce_fake-145"><span class="linenos">145</span></a>        <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">empty_like</span><span class="p">(</span><span class="n">tensor</span><span class="p">)</span>
</span></pre></div>


    

                </section>
                <section id="reg_all_gather_into_tensor">
                            <input id="reg_all_gather_into_tensor-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="def">def</span>
        <span class="name">reg_all_gather_into_tensor</span><span class="signature pdoc-code condensed">(<span class="param"><span class="n">output</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span>, </span><span class="param"><span class="nb">input</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span>, </span><span class="param"><span class="n">group_name</span><span class="p">:</span> <span class="nb">str</span></span><span class="return-annotation">) -> <span class="kc">None</span>:</span></span>

                <label class="view-source-button" for="reg_all_gather_into_tensor-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#reg_all_gather_into_tensor"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="reg_all_gather_into_tensor-154"><a href="#reg_all_gather_into_tensor-154"><span class="linenos">154</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">reg_all_gather_into_tensor</span><span class="p">(</span>
</span><span id="reg_all_gather_into_tensor-155"><a href="#reg_all_gather_into_tensor-155"><span class="linenos">155</span></a>        <span class="n">output</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="nb">input</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">group_name</span><span class="p">:</span> <span class="nb">str</span>
</span><span id="reg_all_gather_into_tensor-156"><a href="#reg_all_gather_into_tensor-156"><span class="linenos">156</span></a>    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="reg_all_gather_into_tensor-157"><a href="#reg_all_gather_into_tensor-157"><span class="linenos">157</span></a>        <span class="k">assert</span> <span class="n">group_name</span> <span class="ow">in</span> <span class="n">_groups</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;Group </span><span class="si">{</span><span class="n">group_name</span><span class="si">}</span><span class="s2"> is not found.&quot;</span>
</span><span id="reg_all_gather_into_tensor-158"><a href="#reg_all_gather_into_tensor-158"><span class="linenos">158</span></a>        <span class="n">group</span> <span class="o">=</span> <span class="n">_groups</span><span class="p">[</span><span class="n">group_name</span><span class="p">]()</span>
</span><span id="reg_all_gather_into_tensor-159"><a href="#reg_all_gather_into_tensor-159"><span class="linenos">159</span></a>        <span class="k">if</span> <span class="n">group</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="reg_all_gather_into_tensor-160"><a href="#reg_all_gather_into_tensor-160"><span class="linenos">160</span></a>            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Group </span><span class="si">{</span><span class="n">group_name</span><span class="si">}</span><span class="s2"> is destroyed.&quot;</span><span class="p">)</span>
</span><span id="reg_all_gather_into_tensor-161"><a href="#reg_all_gather_into_tensor-161"><span class="linenos">161</span></a>        <span class="n">group</span><span class="o">.</span><span class="n">_all_gather_into_tensor</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="nb">input</span><span class="p">)</span>
</span></pre></div>


    

                </section>
                <section id="reg_all_gather_into_tensor_fake">
                            <input id="reg_all_gather_into_tensor_fake-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="def">def</span>
        <span class="name">reg_all_gather_into_tensor_fake</span><span class="signature pdoc-code condensed">(<span class="param"><span class="n">output</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span>, </span><span class="param"><span class="nb">input</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span>, </span><span class="param"><span class="n">group_name</span><span class="p">:</span> <span class="nb">str</span></span><span class="return-annotation">) -> <span class="kc">None</span>:</span></span>

                <label class="view-source-button" for="reg_all_gather_into_tensor_fake-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#reg_all_gather_into_tensor_fake"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="reg_all_gather_into_tensor_fake-163"><a href="#reg_all_gather_into_tensor_fake-163"><span class="linenos">163</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">reg_all_gather_into_tensor_fake</span><span class="p">(</span>
</span><span id="reg_all_gather_into_tensor_fake-164"><a href="#reg_all_gather_into_tensor_fake-164"><span class="linenos">164</span></a>        <span class="n">output</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="nb">input</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">group_name</span><span class="p">:</span> <span class="nb">str</span>
</span><span id="reg_all_gather_into_tensor_fake-165"><a href="#reg_all_gather_into_tensor_fake-165"><span class="linenos">165</span></a>    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="reg_all_gather_into_tensor_fake-166"><a href="#reg_all_gather_into_tensor_fake-166"><span class="linenos">166</span></a>        <span class="k">pass</span>
</span></pre></div>


    

                </section>
    </main>
<script>
    function escapeHTML(html) {
        return document.createElement('div').appendChild(document.createTextNode(html)).parentNode.innerHTML;
    }

    const originalContent = document.querySelector("main.pdoc");
    let currentContent = originalContent;

    function setContent(innerHTML) {
        let elem;
        if (innerHTML) {
            elem = document.createElement("main");
            elem.classList.add("pdoc");
            elem.innerHTML = innerHTML;
        } else {
            elem = originalContent;
        }
        if (currentContent !== elem) {
            currentContent.replaceWith(elem);
            currentContent = elem;
        }
    }

    function getSearchTerm() {
        return (new URL(window.location)).searchParams.get("search");
    }

    const searchBox = document.querySelector(".pdoc input[type=search]");
    searchBox.addEventListener("input", function () {
        let url = new URL(window.location);
        if (searchBox.value.trim()) {
            url.hash = "";
            url.searchParams.set("search", searchBox.value);
        } else {
            url.searchParams.delete("search");
        }
        history.replaceState("", "", url.toString());
        onInput();
    });
    window.addEventListener("popstate", onInput);


    let search, searchErr;

    async function initialize() {
        try {
            search = await new Promise((resolve, reject) => {
                const script = document.createElement("script");
                script.type = "text/javascript";
                script.async = true;
                script.onload = () => resolve(window.pdocSearch);
                script.onerror = (e) => reject(e);
                script.src = "../../../search.js";
                document.getElementsByTagName("head")[0].appendChild(script);
            });
        } catch (e) {
            console.error("Cannot fetch pdoc search index");
            searchErr = "Cannot fetch search index.";
        }
        onInput();

        document.querySelector("nav.pdoc").addEventListener("click", e => {
            if (e.target.hash) {
                searchBox.value = "";
                searchBox.dispatchEvent(new Event("input"));
            }
        });
    }

    function onInput() {
        setContent((() => {
            const term = getSearchTerm();
            if (!term) {
                return null
            }
            if (searchErr) {
                return `<h3>Error: ${searchErr}</h3>`
            }
            if (!search) {
                return "<h3>Searching...</h3>"
            }

            window.scrollTo({top: 0, left: 0, behavior: 'auto'});

            const results = search(term);

            let html;
            if (results.length === 0) {
                html = `No search results for '${escapeHTML(term)}'.`
            } else {
                html = `<h4>${results.length} search result${results.length > 1 ? "s" : ""} for '${escapeHTML(term)}'.</h4>`;
            }
            for (let result of results.slice(0, 10)) {
                let doc = result.doc;
                let url = `../../../${doc.modulename.replaceAll(".", "/")}.html`;
                if (doc.qualname) {
                    url += `#${doc.qualname}`;
                }

                let heading;
                switch (result.doc.kind) {
                    case "function":
                        if (doc.fullname.endsWith(".__init__")) {
                            heading = `<span class="name">${doc.fullname.replace(/\.__init__$/, "")}</span>${doc.signature}`;
                        } else {
                            heading = `<span class="def">${doc.funcdef}</span> <span class="name">${doc.fullname}</span>${doc.signature}`;
                        }
                        break;
                    case "class":
                        heading = `<span class="def">class</span> <span class="name">${doc.fullname}</span>`;
                        if (doc.bases)
                            heading += `<wbr>(<span class="base">${doc.bases}</span>)`;
                        heading += `:`;
                        break;
                    case "variable":
                        heading = `<span class="name">${doc.fullname}</span>`;
                        if (doc.annotation)
                            heading += `<span class="annotation">${doc.annotation}</span>`;
                        if (doc.default_value)
                            heading += `<span class="default_value"> = ${doc.default_value}</span>`;
                        break;
                    default:
                        heading = `<span class="name">${doc.fullname}</span>`;
                        break;
                }
                html += `
                        <section class="search-result">
                        <a href="${url}" class="attr ${doc.kind}">${heading}</a>
                        <div class="docstring">${doc.doc}</div>
                        </section>
                    `;

            }
            return html;
        })());
    }

    if (getSearchTerm()) {
        initialize();
        searchBox.value = getSearchTerm();
        onInput();
    } else {
        searchBox.addEventListener("focus", initialize, {once: true});
    }

    searchBox.addEventListener("keydown", e => {
        if (["ArrowDown", "ArrowUp", "Enter"].includes(e.key)) {
            let focused = currentContent.querySelector(".search-result.focused");
            if (!focused) {
                currentContent.querySelector(".search-result").classList.add("focused");
            } else if (
                e.key === "ArrowDown"
                && focused.nextElementSibling
                && focused.nextElementSibling.classList.contains("search-result")
            ) {
                focused.classList.remove("focused");
                focused.nextElementSibling.classList.add("focused");
                focused.nextElementSibling.scrollIntoView({
                    behavior: "smooth",
                    block: "nearest",
                    inline: "nearest"
                });
            } else if (
                e.key === "ArrowUp"
                && focused.previousElementSibling
                && focused.previousElementSibling.classList.contains("search-result")
            ) {
                focused.classList.remove("focused");
                focused.previousElementSibling.classList.add("focused");
                focused.previousElementSibling.scrollIntoView({
                    behavior: "smooth",
                    block: "nearest",
                    inline: "nearest"
                });
            } else if (
                e.key === "Enter"
            ) {
                focused.querySelector("a").click();
            }
        }
    });
</script></body>
</html>