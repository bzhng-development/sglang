<h1 id="nixl-integration-for-hicache">NIXL Integration for HiCache</h1>
<p>This directory contains the <strong>NIXL (NVIDIA Inference Xfer Library)</strong> integration for <strong>HiCache</strong>, enabling high-performance storage across multiple backends.</p>
<p>NIXL provides a unified API for accessing various storage plugins, including but not limited to:</p>
<ul>
<li><strong>Deepseek’s 3FS APIs</strong> for high-throughput file operations</li>
<li><strong>GPU Direct Storage (GDS)</strong> for direct data movement between storage and GPU memory, bypassing CPU memory copies</li>
<li><strong>Amazon S3-compatible object storage</strong> for key-value access patterns</li>
</ul>
<p>Additional backend integrations are planned for future releases.</p>
<h2 id="nixl-resources">NIXL Resources</h2>
<ul>
<li><strong>Project Repository</strong>: <a href="https://github.com/ai-dynamo/nixl">NIXL on GitHub</a></li>
<li><strong>Documentation</strong>: <a href="https://github.com/ai-dynamo/nixl/tree/main/docs">NIXL Documentation</a></li>
</ul>
<h2 id="overview">Overview</h2>
<p>The NIXL integration consists of two main files:</p>
<ul>
<li><strong><code>hicache_nixl.py</code></strong> - Main HiCache storage connector using NIXL</li>
<li><strong><code>nixl_utils.py</code></strong> - Utility classes for backend selection, registration, and file management</li>
</ul>
<h2 id="components">Components</h2>
<h3 id="hicachenixl">HiCacheNixl</h3>
<p>The main storage connector that provides: - Single and batch tensor set/get operations - Automatic backend selection (3FS &gt; POSIX &gt; GDS_MT &gt; GDS &gt; OBJ) - High-performance file-based (or) object based storage access using NIXL</p>
<h3 id="nixlutils">NixlUtils</h3>
<p>Consolidated utility classes: - <strong>NixlBackendSelection</strong> - Handles backend selection and creation - <strong>NixlRegistration</strong> - Manages memory registration for tensors, files and objects - <strong>NixlFileManager</strong> - Handles file system operations and NIXL tuple creation</p>
<h2 id="using-nixl-for-hicache-backend">Using NIXL for HiCache backend</h2>
<p>When running the SGLang server, indicate <code>nixl</code> for <code>hicache-storage-backend</code> parameter, for instance:</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode bash"><code class="sourceCode bash"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true"></a><span class="ex">python3</span> -m sglang.launch_server --model-path <span class="op">&lt;</span>model<span class="op">&gt;</span> --host <span class="op">&lt;</span>ip<span class="op">&gt;</span> --port <span class="op">&lt;</span>port<span class="op">&gt;</span> --page-size 64 --enable-hierarchical-cache --hicache-ratio 2 --hicache-size 64 --hicache-write-policy write_through --hicache-storage-backend nixl</span></code></pre></div>
<p>To customize the base directory for files, you can set the following environment variable:</p>
<div class="sourceCode" id="cb2"><pre class="sourceCode bash"><code class="sourceCode bash"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true"></a><span class="bu">export</span> <span class="va">SGLANG_HICACHE_NIXL_BACKEND_STORAGE_DIR=</span>/path/to/desired/dir</span></code></pre></div>
<p>Selection of any storage backend like 3FS requires availability of that library on the system, and the backend is selected based on the priority mentioned above.</p>
<h2 id="running-unit-tests">Running Unit Tests</h2>
<h3 id="prerequisites">Prerequisites</h3>
<ul>
<li>NIXL library installed and available (latest main required for supporting object query)</li>
<li>PyTorch installed</li>
<li>Python 3.8+</li>
</ul>
<h3 id="unit-tests-from-current-directory">Unit tests from current directory</h3>
<p>From the current directory run:</p>
<h4 id="run-all-nixl-tests">Run all NIXL tests:</h4>
<div class="sourceCode" id="cb3"><pre class="sourceCode bash"><code class="sourceCode bash"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true"></a><span class="va">PYTHONPATH=</span>. <span class="ex">python</span> -m pytest test_hicache_nixl_storage.py -o asyncio_mode=strict</span></code></pre></div>
<h4 id="run-with-verbose-output">Run with verbose output:</h4>
<div class="sourceCode" id="cb4"><pre class="sourceCode bash"><code class="sourceCode bash"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true"></a><span class="va">PYTHONPATH=</span>. <span class="ex">python</span> -m pytest test_hicache_nixl_storage.py -v -o asyncio_mode=strict</span></code></pre></div>
<p>Note: The <code>-v</code> flag provides more detailed output, showing each test case name and its result.</p>
<h4 id="run-a-specific-test">Run a specific test:</h4>
<div class="sourceCode" id="cb5"><pre class="sourceCode bash"><code class="sourceCode bash"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true"></a><span class="va">PYTHONPATH=</span>. <span class="ex">python</span> -m pytest test_hicache_nixl_storage.py -v -k test_single_set_get -o asyncio_mode=strict</span></code></pre></div>
<p>Note: The <code>-o asyncio_mode=strict</code> flag is added to suppress warnings about asyncio configuration. This is not required for test functionality but provides cleaner output.</p>
<h2 id="test-coverage">Test Coverage</h2>
<p>Tests for this integration, a test suite can be found at <code>test_hicache_nixl_storage.py</code> which covers:</p>
<h3 id="hicache-integration-tests-4-tests">HiCache Integration Tests (4 tests)</h3>
<ul>
<li>Single tensor set/get operations</li>
<li>Batch tensor set/get operations</li>
<li>Mixed single and batch operations</li>
<li>Data integrity for various tensor types</li>
</ul>
<h3 id="file-management-tests-5-tests">File Management Tests (5 tests)</h3>
<ul>
<li>Basic file operations</li>
<li>NIXL tuple creation</li>
<li>Error handling in file operations</li>
</ul>
<h3 id="registration-tests-2-tests">Registration Tests (2 tests)</h3>
<ul>
<li>Tensor registration with memory type detection</li>
<li>File registration using NIXL tuples</li>
</ul>
<h2 id="expected-output">Expected Output</h2>
<p>When tests run successfully, you should see: - NIXL agent initialization messages - Backend selection messages (e.g., “Backend POSIX was instantiated”) - Test results with “ok” for passed tests - Summary showing “Ran X tests in Y seconds” and “OK”</p>
<h2 id="troubleshooting">Troubleshooting</h2>
<h3 id="import-errors">Import Errors</h3>
<p>If you encounter <code>ModuleNotFoundError</code>, ensure: - You’re running from the correct directory - <code>PYTHONPATH</code> is set correctly - NIXL library is properly installed</p>
<h3 id="nixl-errors">NIXL Errors</h3>
<p>If NIXL operations fail: - Check that NIXL is properly installed - Verify that required plugins are available - Ensure file permissions are correct for test directories</p>
<h2 id="file-structure">File Structure</h2>
<pre><code>python/sglang/srt/mem_cache/nixl/
├── hicache_nixl.py          # Main HiCache storage connector
├── nixl_utils.py            # All NIXL utility classes
├── README.md                # This file
└── tests/
    └── test_nixl_unified.py # All tests in one file</code></pre>
<h2 id="dependencies">Dependencies</h2>
<ul>
<li><strong>NIXL</strong>: NVIDIA Inference Xfer Library (version 0.4 or later)
<ul>
<li>Required plugins: POSIX (minimum), 3FS/GDS (optional for better performance)</li>
<li>See <a href="https://github.com/ai-dynamo/nixl/blob/main/README.md#installation">NIXL Installation Guide</a></li>
</ul></li>
<li><strong>PyTorch</strong>: For tensor operations (version 1.8 or later)</li>
<li><strong>Python 3.8+</strong>: For type hints and modern features</li>
</ul>
<h2 id="supported-features">Supported Features</h2>
<h3 id="memory-types">Memory Types</h3>
<ul>
<li><strong>Tensor side</strong>: multi-dimensional tensors of all numeric types (int32, int64, float32, float64) are supported.
<ul>
<li>Tensors can be on CPU or GPU (as long as a GPU capable backend such as GDS_MT is available).</li>
<li>Currently each tensor is mapped to a file or key, but it can be extended to support multiple keys per file or key.</li>
</ul></li>
<li><strong>Storage side</strong>: file and object are supported through their relevant backends (e.g., 3FS or OBJ).</li>
</ul>
<h3 id="backend-priority">Backend Priority</h3>
<p>The NIXL backend selection follows this priority order: 1. <strong>3FS</strong> - Highest performance (if available) - Best for high-throughput file operations using Deepseek 3FS APIs 2. <strong>POSIX</strong> - Standard file I/O (fallback) - Universal compatibility - Good for development and testing - Leverages both libaio/liburing 3. <strong>GDS_MT</strong> - Multi-threaded GDS (if available) - Optimized for concurrent operations - Supports GPU Direct storage with multiple light weight threads 4. <strong>GDS</strong> - GPU Direct Storage (if available) - Direct GPU-storage data path - Best for filesystems benefiting from batch operations and smaller IOs. 5. <strong>OBJ</strong> - Amazon S3 based Object Storage - Key-value based storage The system automatically selects the best available backend, with POSIX as the default fallback.</p>
<h2 id="note">Note</h2>
<p>This is v0 of the NIXL connector. Future versions will focus on further performance optimizations such as memory pre-registration (pre-allocating and registering memory buffers to reduce registration overhead during transfers) and block merging (combining related blocks as offsets within the same file to reduce file operations and improve throughput). These optimizations require changes at a higher layer, as the current HiCache API doesn’t expose information like block relationships or hash patterns that would enable these optimizations.</p>
