
# python/sglang/srt/multimodal/processors/base_processor.py
  BaseMultiModalProcessorOutput.organize_results()
  MultimodalSpecialTokens.build(processor)
  MultimodalSpecialTokens.convert_to_str(token, int], processor)
  MultimodalSpecialTokens.convert_to_strs(processor)
  MultimodalSpecialTokens.get_modality_of_token(token)
  MultimodalSpecialTokens.get_token_id_by_modality(modality)
  MultimodalSpecialTokens.parse_regex()
  MultimodalSpecialTokens.get_combined_regex()
  BaseMultimodalProcessor.__init__(hf_config, server_args, _processor, transport_mode)
  BaseMultimodalProcessor.process_mm_data(input_text, images, videos, audios)
  BaseMultimodalProcessor.process_mm_data_async(image_data, audio_data, input_text, request_obj)
  BaseMultimodalProcessor.get_estimated_frames_list(image_data)
  BaseMultimodalProcessor.submit_data_loading_tasks(text_parts, multimodal_tokens, data_iterators, Iterator[Any]], discard_alpha_channel, image_estimated_frames_iter, image_scaling_factor, max_image_frames, audio_sample_rate)
  BaseMultimodalProcessor.load_mm_data(prompt, multimodal_tokens, image_data, video_data, audio_data, return_text, discard_alpha_channel, audio_sample_rate)
  BaseMultimodalProcessor.get_mm_items_offset(input_ids, mm_token_id)
  BaseMultimodalProcessor.get_mm_items_offset_by_pair(input_ids, mm_start_id, mm_end_id)
  BaseMultimodalProcessor.collect_mm_items_from_processor_output(data_dict)
  BaseMultimodalProcessor.process_and_combine_mm_data(base_output, mm_tokens)

# python/sglang/srt/multimodal/processors/clip.py
  ClipImageProcessor.__init__(hf_config, server_args, _processor)
  ClipImageProcessor.process_mm_data_async(image_data, bytes]], input_text)

# python/sglang/srt/multimodal/processors/deepseek_vl_v2.py
  DeepseekVL2ImageProcessor.__init__(hf_config, server_args, _processor)
  DeepseekVL2ImageProcessor.process_mm_data_async(image_data, bytes]], input_text, request_obj, max_req_input_len)

# python/sglang/srt/multimodal/processors/gemma3.py
  Gemma3SGLangImageProcessor.__init__(hf_config, server_args, _processor)
  Gemma3SGLangImageProcessor.process_mm_data_async(image_data, bytes, Dict]], input_text, request_obj)

# python/sglang/srt/multimodal/processors/gemma3n.py
  Gemma3nSGLangProcessor.__init__(hf_config, server_args, _processor)
  Gemma3nSGLangProcessor.process_mm_data_async(image_data, bytes, Dict]]], audio_data, bytes, Dict]]], input_text, request_obj)

# python/sglang/srt/multimodal/processors/glm4v.py
  Glm4vImageProcessor.__init__(hf_config, server_args, _processor)
  Glm4vImageProcessor.preprocess_video(vr)
  Glm4vImageProcessor.process_mm_data_async(image_data, bytes]], input_text, request_obj)

# python/sglang/srt/multimodal/processors/internvl.py
  InternVLImageProcessor.__init__(hf_config, server_args, _image_processor)
  InternVLImageProcessor.build_transform(input_size)
  InternVLImageProcessor.dynamic_preprocess(image, min_num, max_num, image_size, use_thumbnail)
  InternVLImageProcessor.get_index(bound, fps, max_frame, first_idx, num_segments)
  InternVLImageProcessor.load_video(video_path, bound, input_size, max_num, num_segments)
  InternVLImageProcessor.process_mm_data_async(image_data, input_text, request_obj)

# python/sglang/srt/multimodal/processors/janus_pro.py
  JanusProImageProcessor.__init__(hf_config, server_args, _processor)
  JanusProImageProcessor.process_mm_data_async(image_data, bytes]], input_text, request_obj)

# python/sglang/srt/multimodal/processors/kimi_vl.py
  KimiVLImageProcessor.__init__(hf_config, server_args, _processor)
  KimiVLImageProcessor.process_mm_data_async(image_data, bytes, Dict]], input_text, request_obj)

# python/sglang/srt/multimodal/processors/llava.py
  LlavaImageProcessor.__init__(hf_config, server_args, _processor)
  LlavaImageProcessor.process_mm_data_async(image_data, bytes, ImageData]], input_text, request_obj)
  LlavaMultimodalProcessor.__init__(hf_config, server_args, _processor)
  LlavaMultimodalProcessor.process_mm_data_async()

# python/sglang/srt/multimodal/processors/minicpm.py
  MiniCPMMultimodalProcessor.__init__(hf_config, server_args, _processor)
  MiniCPMMultimodalProcessor.process_mm_data_async(image_data, bytes]], audio_data, bytes]], input_text, request_obj)

# python/sglang/srt/multimodal/processors/mlama.py
  MllamaImageProcessor.__init__(hf_config, server_args, _processor)
  MllamaImageProcessor.process_mm_data_async(image_data, bytes]], input_text)

# python/sglang/srt/multimodal/processors/mllama4.py
  Mllama4ImageProcessor.__init__(hf_config, server_args, _processor)
  Mllama4ImageProcessor.process_mm_data_async(image_data, bytes]], input_text)

# python/sglang/srt/multimodal/processors/phi4mm.py
  Phi4MMProcessorAdapter.__init__(_processor)
  Phi4MMProcessorAdapter.__call__()
  Phi4MMMultimodalProcessor.__init__(hf_config, server_args, _processor)
  Phi4MMMultimodalProcessor.process_mm_data_async(image_data, bytes]], audio_data, input_text, request_obj)

# python/sglang/srt/multimodal/processors/pixtral.py
  PixtralProcessor.get_patch_grid_size()
  PixtralProcessor.__init__(hf_config, server_args, _processor)
  PixtralProcessor.process_mm_data_async(image_data, bytes]], input_text, request_obj)

# python/sglang/srt/multimodal/processors/qwen_audio.py
  Qwen2AudioMultimodalProcessor.__init__(hf_config, server_args, _processor)
  Qwen2AudioMultimodalProcessor.process_mm_data_async(audio_data, input_text)

# python/sglang/srt/multimodal/processors/qwen_vl.py
smart_resize(height, width, factor, min_pixels, max_pixels)
resize_image(image, size_factor)
round_by_factor(number, factor)
ceil_by_factor(number, factor)
floor_by_factor(number, factor)
resize_image_async(image)
smart_nframes(ele, total_frames, video_fps)
preprocess_video(vr, image_factor)
  Qwen2_5VLImageProcessor.__init__(hf_config, server_args, _processor)
  Qwen2_5VLImageProcessor.process_mm_data_async(image_data, bytes]], input_text, request_obj)

# python/sglang/srt/multimodal/processors/step3_vl.py
  GPUToTensor.forward(raw_image, Image.Image])
  Step3VisionProcessor.__init__(size, interpolation_mode, patch_size)
  Step3VisionProcessor.__call__(image, is_patch)
  ImagePatcher.determine_window_size(long, short)
  ImagePatcher.slide_window(width, height, sizes, int]], steps, int]], img_rate_thr)
  ImagePatcher.square_pad(img)
  ImagePatcher.get_image_size_for_padding(img_width, img_height)
  ImagePatcher.get_image_size_for_preprocess(img_width, img_height)
  ImagePatcher.get_image_size_for_crop(img_width, img_height, window_size)
  ImagePatcher.patch_crop(img, i, j, th, tw)
  ImagePatcher.get_num_patches(img_width, img_height)
  ImagePatcher.__call__(img)
  Step3VLProcessor.__init__(config, tokenizer)
  Step3VLProcessor.image_token_id()
  Step3VLProcessor.get_num_image_tokens(img_width, img_height)
  Step3VLProcessor.replace_placeholder(text, placeholder, repls)
  Step3VLProcessor.__call__(text, list[str]]], images, list[Image.Image]]], return_tensors, TensorType]])
  Step3VLImageProcessor.__init__(hf_config, server_args, _processor)
  Step3VLImageProcessor.preprocess(image)
  Step3VLImageProcessor.__call__(image)
  Step3VLImageProcessor.process_mm_data_async(image_data, bytes]], input_text, request_obj)

# python/sglang/srt/multimodal/processors/vila.py
  VILAMultimodalProcessor.__init__(hf_config, server_args, _processor)
  VILAMultimodalProcessor.process_mm_data_async(image_data, input_text, request_obj)