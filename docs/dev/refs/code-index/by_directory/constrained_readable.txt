================================================================================
FUNCTION INDEX: constrained module
================================================================================
Total Functions: 94
Documented: 5


============================================================
FILE: python/sglang/srt/constrained/base_grammar_backend.py
Functions: 24
============================================================

MODULE FUNCTIONS:
----------------------------------------
  L 170: def create_grammar_backend(server_args: ServerArgs,
        tokenizer,
        vocab_size: int,
        eos_token_ids: Optional[set])
         ‚Üí Optional[BaseGrammarBackend]


CLASS: BaseGrammarBackend
----------------------------------------
  L 112: __init__(self)

  L 119: dispatch_fallback(self, key_type: str, key_string: str)
         ‚Üí Optional[BaseGrammarObject]
         üìù This function should not be reached in any case.

  L 127: dispatch_json(self, key_string: str)
         ‚Üí Optional[BaseGrammarObject]

  L 130: dispatch_regex(self, key_string: str)
         ‚Üí Optional[BaseGrammarObject]

  L 133: dispatch_ebnf(self, key_string: str)
         ‚Üí Optional[BaseGrammarObject]

  L 136: dispatch_structural_tag(self, key_string: str)
         ‚Üí Optional[BaseGrammarObject]

  L 154: get_cached_or_future_value(self, key: Tuple[str, str])
         ‚Üí Optional[BaseGrammarObject]

  L 163: set_cache(self, key: Tuple[str, str], value: BaseGrammarObject)

  L 166: reset(self)


CLASS: BaseGrammarObject
----------------------------------------
  L  31: __init__(self)

  L  34: accept_token(self, token: int)
         ‚Üí None
         üìù Accept a token in the grammar.

  L  40: rollback(self, k: int)

  L  43: is_terminated(self)

  L  46: allocate_vocab_mask(self, vocab_size: int, batch_size: int, device)
         ‚Üí torch.Tensor

  L  51: fill_vocab_mask(self, vocab_mask: torch.Tensor, idx: int)
         ‚Üí None

  L  55: move_vocab_mask(vocab_mask: torch.Tensor, device)
         ‚Üí torch.Tensor

  L  59: apply_vocab_mask(logits: torch.Tensor, vocab_mask: torch.Tensor)
         ‚Üí None

  L  62: copy(self)
         ‚Üí 'BaseGrammarObject'

  L  66: finished(self)

  L  70: finished(self, finished)

  L  73: try_jump_forward(self, tokenizer)
         ‚Üí Optional[Tuple[List[int], str]]
         üìù Try to jump forward in the grammar.
            Returns:
            A jump forward helper which may be used in `jump_forward_str_state`.
            None if the jump forward is not possible.

  L  83: jump_forward_str_state(self, helper: Tuple[List[int], str])
         ‚Üí Tuple[str, int]
         üìù Jump forward for the grammar.
            Returns:
            A tuple of the jump forward string and the next state of the grammar
            (which can be used in `jump_and_retokenize` if needed).

  L  93: jump_and_retokenize(self, old_output_ids: List[int], new_output_ids: List[int], next_state: int)
         ‚Üí None
         üìù Jump forward occurs, and update the grammar state if needed.


============================================================
FILE: python/sglang/srt/constrained/llguidance_backend.py
Functions: 15
============================================================


CLASS: GuidanceBackend
----------------------------------------
  L 111: __init__(self, tokenizer, whitespace_pattern: Optional[str], n_vocab: Optional[int])

  L 133: dispatch_json(self, key_string: str)
         ‚Üí Optional[GuidanceGrammar]

  L 146: dispatch_regex(self, key_string: str)
         ‚Üí Optional[GuidanceGrammar]

  L 150: dispatch_ebnf(self, key_string: str)
         ‚Üí Optional[GuidanceGrammar]

  L 158: dispatch_structural_tag(self, key_string: str)
         ‚Üí Optional[GuidanceGrammar]


CLASS: GuidanceGrammar
----------------------------------------
  L  41: __init__(self, llguidance_tokenizer: LLTokenizer, serialized_grammar: str)

  L  54: accept_token(self, token: int)

  L  59: fill_vocab_mask(self, vocab_mask: torch.Tensor, idx: int)
         ‚Üí None

  L  65: allocate_vocab_mask(self, vocab_size: int, batch_size: int, device)
         ‚Üí torch.Tensor

  L  80: move_vocab_mask(vocab_mask: torch.Tensor, device)
         ‚Üí torch.Tensor

  L  84: apply_vocab_mask(logits: torch.Tensor, vocab_mask: torch.Tensor)
         ‚Üí None

  L  87: copy(self)

  L  93: try_jump_forward(self, tokenizer)
         ‚Üí Optional[Tuple[List[int], str]]

  L 100: jump_forward_str_state(self, helper: Tuple[List[int], str])
         ‚Üí Tuple[str, int]

  L 103: jump_and_retokenize(self, old_output_ids: List[int], new_output_ids: List[int], next_state: int)


============================================================
FILE: python/sglang/srt/constrained/outlines_backend.py
Functions: 16
============================================================

MODULE FUNCTIONS:
----------------------------------------
  L 182: def build_regex_from_object(object: Union[str,
        BaseModel,
        Dict],
        whitespace_pattern: Optional[str])


CLASS: OutlinesGrammar
----------------------------------------
  L  43: __init__(self, guide: RegexGuide, jump_forward_map: Union[OutlinesJumpForwardMap, None])
         ‚Üí None

  L  54: accept_token(self, token: int)

  L  57: allocate_vocab_mask(self, vocab_size: int, batch_size: int, device)
         ‚Üí torch.Tensor

  L  63: move_vocab_mask(vocab_mask: torch.Tensor, device)
         ‚Üí torch.Tensor

  L  66: fill_vocab_mask(self, vocab_mask: torch.Tensor, idx: int)
         ‚Üí None

  L  75: apply_vocab_mask(logits: torch.Tensor, vocab_mask: torch.Tensor)

  L  78: copy(self)

  L  81: try_jump_forward(self, tokenizer)
         ‚Üí Optional[Tuple]

  L 105: jump_forward_str_state(self, helper: Tuple[List[int], str])
         ‚Üí Tuple[str, int]

  L 109: jump_and_retokenize(self, old_output_ids: List[int], new_output_ids: List[int], next_state: int)


CLASS: OutlinesGrammarBackend
----------------------------------------
  L 116: __init__(self, tokenizer, whitespace_pattern: bool)

  L 161: dispatch_ebnf(self, key_string: str)

  L 164: dispatch_structural_tag(self, key_string: str)

  L 167: dispatch_json(self, key_string: str)

  L 178: dispatch_regex(self, key_string: str)


============================================================
FILE: python/sglang/srt/constrained/outlines_jump_forward.py
Functions: 7
============================================================

MODULE FUNCTIONS:
----------------------------------------
  L  54: def disk_cache(expire: Optional[float], typed, ignore)

  L  62: def init_state_to_jump_forward(regex_string)
         @disk_cache()

  L 181: def test_main(regex_string)


CLASS: OutlinesJumpForwardMap
----------------------------------------
  L 143: __init__(self, regex_string)

  L 146: jump_forward_symbol(self, state)

  L 159: jump_forward_byte(self, state)

  L 174: is_jump_forward_symbol_state(self, state)


============================================================
FILE: python/sglang/srt/constrained/reasoner_grammar_backend.py
Functions: 13
============================================================


CLASS: ReasonerGrammarBackend
----------------------------------------
  L  79: __init__(self, grammar_backend: BaseGrammarBackend, think_end_id)


CLASS: ReasonerGrammarObject
----------------------------------------
  L  24: __init__(self, grammar: BaseGrammarObject, think_end_id)

  L  30: accept_token(self, token: int)

  L  37: allocate_vocab_mask(self, vocab_size: int, batch_size: int, device)
         ‚Üí torch.Tensor

  L  42: fill_vocab_mask(self, vocab_mask: torch.Tensor, idx: int)
         ‚Üí None

  L  46: move_vocab_mask(self, vocab_mask: torch.Tensor, device)
         ‚Üí torch.Tensor

  L  50: apply_vocab_mask(self)

  L  53: copy(self)
         ‚Üí BaseGrammarObject

  L  57: finished(self)

  L  61: finished(self, finished)

  L  64: try_jump_forward(self, tokenizer)

  L  67: jump_forward_str_state(self, helper)

  L  70: jump_and_retokenize(self, old_output_ids: List[int], new_output_ids: List[int], next_state: int)


============================================================
FILE: python/sglang/srt/constrained/xgrammar_backend.py
Functions: 19
============================================================


CLASS: XGrammarGrammar
----------------------------------------
  L  52: __init__(self, matcher: GrammarMatcher, vocab_size: int, ctx: CompiledGrammar, override_stop_tokens: Optional[Union[List[int], int]], key_string: Optional[str])
         ‚Üí None

  L  68: accept_token(self, token: int)

  L  81: rollback(self, k: int)

  L  85: is_terminated(self)

  L  88: allocate_vocab_mask(self, vocab_size: int, batch_size: int, device)
         ‚Üí torch.Tensor

  L  93: fill_vocab_mask(self, vocab_mask: torch.Tensor, idx: int)
         ‚Üí None

  L  97: move_vocab_mask(vocab_mask: torch.Tensor, device)
         ‚Üí torch.Tensor

  L 100: apply_vocab_mask(self, logits: torch.Tensor, vocab_mask: torch.Tensor)
         ‚Üí None

  L 111: copy(self)

  L 125: try_jump_forward(self, tokenizer)
         ‚Üí Optional[Tuple[List[int], str]]

  L 131: jump_forward_str_state(self, helper: Tuple[List[int], str])
         ‚Üí Tuple[str, int]

  L 135: jump_and_retokenize(self, old_output_ids: List[int], new_output_ids: List[int], next_state: int)

  L 152: __repr__(self)


CLASS: XGrammarGrammarBackend
----------------------------------------
  L 157: __init__(self, tokenizer, vocab_size: int, model_eos_token_ids: Optional[List[int]])

  L 190: dispatch_json(self, key_string: str)
         ‚Üí Optional[XGrammarGrammar]

  L 203: dispatch_ebnf(self, key_string: str)
         ‚Üí Optional[XGrammarGrammar]

  L 211: dispatch_regex(self, key_string: str)
         ‚Üí Optional[XGrammarGrammar]

  L 219: dispatch_structural_tag(self, key_string: str)
         ‚Üí Optional[XGrammarGrammar]

  L 238: reset(self)
