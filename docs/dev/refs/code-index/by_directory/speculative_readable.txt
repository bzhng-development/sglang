================================================================================
FUNCTION INDEX: speculative module
================================================================================
Total Functions: 57
Documented: 7


============================================================
FILE: python/sglang/srt/speculative/build_eagle_tree.py
Functions: 3
============================================================

MODULE FUNCTIONS:
----------------------------------------
  L  17: def build_tree_kernel_efficient_preprocess(verified_id: torch.Tensor,
        score_list: List[torch.Tensor],
        token_list: List[torch.Tensor],
        parents_list: List[torch.Tensor],
        num_verify_tokens: int)

  L  51: def build_tree_kernel_efficient(verified_id: torch.Tensor,
        score_list: List[torch.Tensor],
        token_list: List[torch.Tensor],
        parents_list: List[torch.Tensor],
        seq_lens: torch.Tensor,
        seq_lens_sum: int,
        topk: int,
        spec_steps: int,
        num_verify_tokens: int,
        tree_mask_mode: TreeMaskMode,
        tree_mask_buf: Optional[torch.Tensor],
        position_buf: Optional[torch.Tensor])

  L 154: def test_build_tree_kernel_efficient()


============================================================
FILE: python/sglang/srt/speculative/eagle_draft_cuda_graph_runner.py
Functions: 5
============================================================


CLASS: EAGLEDraftCudaGraphRunner
----------------------------------------
  L  40: __init__(self, eagle_worker: EAGLEWorker)

  L 128: can_run(self, forward_batch: ForwardBatch)

  L 149: capture(self)

  L 152: capture_one_batch_size(self, num_seqs: int, forward: Callable)

  L 280: replay(self, forward_batch: ForwardBatch)


============================================================
FILE: python/sglang/srt/speculative/eagle_draft_extend_cuda_graph_runner.py
Functions: 5
============================================================


CLASS: EAGLEDraftExtendCudaGraphRunner
----------------------------------------
  L  37: __init__(self, eagle_worker: EAGLEWorker)

  L 155: can_run(self, forward_batch: ForwardBatch)

  L 176: capture(self)

  L 179: capture_one_batch_size(self, bs: int, forward: Callable)

  L 308: replay(self, forward_batch: ForwardBatch)


============================================================
FILE: python/sglang/srt/speculative/eagle_utils.py
Functions: 22
============================================================

MODULE FUNCTIONS:
----------------------------------------
  L 730: def create_extend_after_decode_spec_info(verified_id,
        seq_lens,
        accept_lens,
        positions,
        new_verified_id,
        bs_upper: tl.constexpr)
         @triton.jit

  L 756: def assign_req_to_token_pool(req_pool_indices,
        req_to_token,
        start_offset,
        end_offset,
        out_cache_loc,
        pool_len: tl.constexpr,
        bs_upper: tl.constexpr)
         @triton.jit

  L 791: def assign_draft_cache_locs(req_pool_indices,
        req_to_token,
        seq_lens,
        extend_lens,
        num_new_pages_per_topk,
        out_cache_loc,
        pool_len: tl.constexpr,
        topk: tl.constexpr,
        speculative_num_steps: tl.constexpr,
        page_size: tl.constexpr,
        bs_upper: tl.constexpr,
        iter_upper: tl.constexpr)
         @triton.jit

  L 867: def generate_draft_decode_kv_indices(req_pool_indices,
        req_to_token,
        paged_kernel_lens,
        kv_indices,
        kv_indptr,
        positions,
        pool_len: tl.constexpr,
        kv_indices_stride: tl.constexpr,
        kv_indptr_stride: tl.constexpr,
        bs_upper: tl.constexpr,
        iter_upper: tl.constexpr,
        num_tokens_upper: tl.constexpr,
        page_size: tl.constexpr)
         @triton.jit

  L 948: def align_evict_mask_to_page_size(seq_lens,
        evict_mask,
        page_size: tl.constexpr,
        num_draft_tokens: tl.constexpr,
        BLOCK_SIZE: tl.constexpr)
         @triton.jit

  L 973: def get_target_cache_loc(tgt_cache_loc,
        to_free_slots,
        accept_length,
        to_free_num_slots,
        out_cache_loc,
        num_verify_tokens: tl.constexpr,
        num_verify_tokens_upper: tl.constexpr,
        bs_upper: tl.constexpr)
         @triton.jit

  L1019: def get_src_tgt_cache_loc(seq_lens: torch.Tensor,
        out_cache_loc: torch.Tensor,
        accept_index: torch.Tensor,
        accept_length: torch.Tensor,
        draft_token_num: int,
        page_size: int)
         @torch.compile(dynamic=True)

  L1039: def filter_finished_cache_loc_kernel(out_cache_loc,
        tgt_cache_loc,
        accept_length,
        accept_length_filter,
        bs_upper: tl.constexpr,
        num_verify_tokens_upper: tl.constexpr)
         @triton.jit

  L1069: def create_accept_length_filter(accept_length: torch.Tensor,
        unfinished_index_device: torch.Tensor,
        seq_lens: torch.Tensor)
         @torch.compile(dynamic=True)

  L1083: def select_top_k_tokens(i: int,
        topk_p: torch.Tensor,
        topk_index: torch.Tensor,
        hidden_states: torch.Tensor,
        scores: torch.Tensor,
        topk: int)
         @torch.compile(dynamic=True)

  L1183: def traverse_tree(retrieve_next_token: torch.Tensor,
        retrieve_next_sibling: torch.Tensor,
        draft_tokens: torch.Tensor,
        grammar: BaseGrammarObject,
        allocate_token_bitmask: torch.Tensor)
         üìù Traverse the tree constructed by the draft model to generate the logit

  L1249: def generate_token_bitmask(reqs: List[Req],
        verify_input: EagleVerifyInput,
        retrieve_next_token_cpu: torch.Tensor,
        retrieve_next_sibling_cpu: torch.Tensor,
        draft_tokens_cpu: torch.Tensor,
        vocab_size: int)
         üìù Generate the logit mask for structured output.


CLASS: EagleDraftInput
----------------------------------------
  L  85: prepare_for_extend(self, batch: ScheduleBatch)

  L 102: create_idle_input(cls, device: torch.device, hidden_size: int, dtype: torch.dtype, topk: int, capture_hidden_mode: CaptureHiddenMode)

  L 120: prepare_extend_after_decode(self, batch: ScheduleBatch, speculative_num_steps: int)

  L 151: generate_attn_arg_prefill(self, req_pool_indices: torch.Tensor, paged_kernel_lens: torch.Tensor, paged_kernel_lens_sum: int, req_to_token: torch.Tensor)

  L 182: filter_batch(self, new_indices: torch.Tensor, has_been_filtered: bool)

  L 201: merge_batch(self, spec_info: EagleDraftInput)


CLASS: EagleVerifyInput
----------------------------------------
  L 250: create_idle_input(cls, topk: int, spec_steps: int, num_verify_tokens: int)

  L 273: prepare_for_verify(self, batch: ScheduleBatch, page_size: int)

  L 307: generate_attn_arg_prefill(self, req_pool_indices: torch.Tensor, paged_kernel_lens: torch.Tensor, paged_kernel_lens_sum: int, req_to_token: torch.Tensor)

  L 345: verify(self, batch: ScheduleBatch, logits_output: LogitsProcessorOutput, token_to_kv_pool_allocator: BaseTokenToKVPoolAllocator, page_size: int, vocab_mask: Optional[torch.Tensor])
         ‚Üí torch.Tensor
         üìù Verify and find accepted tokens based on logits output and batch


============================================================
FILE: python/sglang/srt/speculative/eagle_worker.py
Functions: 18
============================================================

MODULE FUNCTIONS:
----------------------------------------
  L  60: def draft_tp_context(tp_group: GroupCoordinator)
         @contextmanager

  L 999: def load_token_map(token_map_path: str)
         ‚Üí List[int]

  L1011: def get_last_loc_large_page_size_top_k_1(req_to_token: torch.Tensor,
        req_pool_indices: torch.Tensor,
        seq_lens,
        speculative_num_steps: int)
         @torch.compile(dynamic=True)

  L1030: def get_last_loc_large_page_size_large_top_k(req_to_token: torch.Tensor,
        req_pool_indices: torch.Tensor,
        seq_lens: torch.Tensor,
        speculative_num_steps: int,
        topk: int,
        page_size: int)


CLASS: EAGLEWorker
----------------------------------------
  L  69: __init__(self, server_args: ServerArgs, gpu_id: int, tp_rank: int, dp_rank: Optional[int], moe_ep_rank: int, nccl_port: int, target_worker: TpModelWorker)

  L 182: init_attention_backend(self)

  L 320: init_cuda_graphs(self)
         üìù Capture cuda graphs.

  L 356: draft_model_runner(self)

  L 359: forward_batch_speculative_generation(self, batch: ScheduleBatch)
         ‚Üí Tuple[LogitsProcessorOutput, torch.Tensor, int, int, bool]
         üìù Run speculative decoding forward.

  L 407: check_forward_draft_extend_after_decode(self, batch: ScheduleBatch)

  L 425: forward_target_extend(self, batch: ScheduleBatch)
         ‚Üí Tuple[LogitsProcessorOutput, torch.Tensor, int, Optional[torch.Tensor]]
         üìù Run the target extend.

  L 565: draft(self, batch: ScheduleBatch)

  L 643: draft_forward(self, forward_batch: ForwardBatch)

  L 702: verify(self, batch: ScheduleBatch, spec_info: EagleVerifyInput)

  L 779: add_logprob_values(self, batch: ScheduleBatch, res: EagleVerifyOutput, logits_output: LogitsProcessorOutput)

  L 847: forward_draft_extend(self, batch: ScheduleBatch, hidden_states: torch.Tensor, next_token_ids: torch.Tensor, seq_lens_cpu: Optional[torch.Tensor])
         üìù Run draft model extend. This API modifies the states of the batch.

  L 898: forward_draft_extend_after_decode(self, batch: ScheduleBatch)

  L 984: capture_for_decode(self, logits_output: LogitsProcessorOutput, draft_input: EagleDraftInput)


============================================================
FILE: python/sglang/srt/speculative/spec_info.py
Functions: 4
============================================================


CLASS: SpeculativeAlgorithm
----------------------------------------
  L   9: is_none(self)

  L  12: is_eagle(self)

  L  15: is_eagle3(self)

  L  19: from_string(name: str)
