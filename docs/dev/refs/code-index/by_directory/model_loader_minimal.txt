
# python/sglang/srt/model_loader/__init__.py
get_model()

# python/sglang/srt/model_loader/loader.py
device_loading_context(module, target_device)
  BaseModelLoader.__init__(load_config)
  BaseModelLoader.download_model(model_config)
  BaseModelLoader.load_model()
  Source.init_new(cls, model_config, model)
  DefaultModelLoader.__init__(load_config)
  DefaultModelLoader.download_model(model_config)
  DefaultModelLoader.load_model()
  DefaultModelLoader.load_weights_and_postprocess(model, weights, target_device)
  LayeredModelLoader.__init__(load_config)
  LayeredModelLoader.load_model()
  DummyModelLoader.__init__(load_config)
  DummyModelLoader.download_model(model_config)
  DummyModelLoader.load_model()
  ShardedStateLoader.__init__(load_config)
  ShardedStateLoader.download_model(model_config)
  ShardedStateLoader.load_model()
  ShardedStateLoader.save_model(model, path, pattern, max_size)
  BitsAndBytesModelLoader.__init__(load_config)
  BitsAndBytesModelLoader.download_model(model_config)
  BitsAndBytesModelLoader.load_model()
  GGUFModelLoader.__init__(load_config)
  GGUFModelLoader.download_model(model_config)
  GGUFModelLoader.load_model()
  RemoteModelLoader.__init__(load_config)
  RemoteModelLoader.download_model(model_config)
  RemoteModelLoader.save_model(model, model_path, url)
  RemoteModelLoader.load_model()
load_model_with_cpu_quantization()
get_model_loader(load_config)

# python/sglang/srt/model_loader/utils.py
set_default_torch_dtype(dtype)
resolve_transformers_arch(model_config, architectures)
get_model_architecture(model_config)
get_architecture_class_name(model_config)

# python/sglang/srt/model_loader/weight_utils.py
enable_hf_transfer()
  DisabledTqdm.__init__()
get_lock(model_name_or_path, cache_dir)
convert_bin_to_safetensor_file(pt_filename, sf_filename)
get_quant_config(model_config, load_config, packed_modules_mapping, List[str]])
download_weights_from_hf(model_name_or_path, cache_dir, allow_patterns, revision, ignore_patterns, List[str]]])
download_safetensors_index_file_from_hf(model_name_or_path, index_file, cache_dir, revision)
filter_duplicate_safetensors_files(hf_weights_files, hf_folder, index_file)
filter_files_not_needed_for_inference(hf_weights_files)
np_cache_weights_iterator(model_name_or_path, cache_dir, hf_folder, hf_weights_files)
decrypt(fn, key)
safetensors_encrypted_weights_iterator(hf_weights_files, is_all_weights_sharded, decryption_key)
safetensors_weights_iterator(hf_weights_files, is_all_weights_sharded, decryption_key, disable_mmap)
multi_thread_safetensors_weights_iterator(hf_weights_files, is_all_weights_sharded, decryption_key, max_workers, disable_mmap)
pt_weights_iterator(hf_weights_files)
multi_thread_pt_weights_iterator(hf_weights_files, max_workers)
get_gguf_extra_tensor_names(gguf_file, gguf_to_hf_name_map, str])
gguf_quant_weights_iterator(gguf_file, gguf_to_hf_name_map, str])
convert_pyslice_to_tensor(x)
default_weight_loader(param, loaded_weight)
row_parallel_weight_loader(param, loaded_weight)
sharded_weight_loader(shard_axis)
composed_weight_loader(loader, fn, torch.Tensor])
runai_safetensors_weights_iterator(hf_weights_files)
set_runai_streamer_env(load_config)
initialize_dummy_weights(model, low, high, seed)
maybe_remap_kv_scale_name(name, params_dict)
  KVCacheQuantSchema.check_is_fp8()
  KVCacheQuantSchema.check_tp_ranks(info)
  KVCacheQuantSchema.check_current_rank(info)
  QuantParamSchema.check_model_type(info)
kv_cache_scales_loader(filename, tp_rank, tp_size, num_hidden_layers, model_type)
get_actual_shard_size(shard_size, weight_start, weight_end)
reset_param_data_if_needed(param_data, dim, start, length)
narrow_padded_param_and_loaded_weight(param_data, loaded_weight, param_data_start, weight_start, dim, shard_size, narrow_weight)