
# python/sglang/srt/layers/moe/ep_moe/kernels.py
deepep_permute_triton_kernel(input_ptr, gateup_input_ptr, src2dst_ptr, topk_ids_ptr, a1_scales_ptr, topk, hidden_size, BLOCK_SIZE: tl.constexpr)
deepep_post_reorder_triton_kernel(down_output_ptr, output_ptr, src2dst_ptr, topk_ids_ptr, topk_weights_ptr, topk, hidden_size, BLOCK_SIZE: tl.constexpr)
compute_src2dst_triton_kernel(reorder_ids, src2dst, num_toks, BLOCK_SIZE: tl.constexpr)
deepep_compute_src2dst_triton_kernel(reorder_ids, src2dst, num_toks, num_minus_one, BLOCK_SIZE: tl.constexpr)
deepep_run_moe_deep_preprocess(topk_ids: torch.Tensor, num_experts: int)
compute_seg_indptr_triton_kernel(reorder_topk_ids, seg_indptr, num_toks)
run_moe_ep_preproess(topk_ids: torch.Tensor, num_experts: int)
run_cutlass_moe_ep_preproess(local_topk_ids: torch.Tensor, local_num_experts: int)
pre_reorder_triton_kernel_for_cutlass_moe(input_ptr, gateup_input_ptr, src2dst_ptr, topk_ids_ptr, a1_scales_ptr, num_experts, topk, hidden_size, BLOCK_SIZE: tl.constexpr)
pre_reorder_triton_kernel(input_ptr, gateup_input_ptr, src2dst_ptr, topk_ids_ptr, a1_scales_ptr, start_expert_id, end_expert_id, topk, hidden_size, BLOCK_SIZE: tl.constexpr, use_per_token_if_dynamic: tl.constexpr)
silu_and_mul_triton_kernel(gateup_output, down_input, hidden_size, reorder_topk_ids, scales, start_expert_id, end_expert_id, BLOCK_SIZE: tl.constexpr)
silu_and_mul_masked_post_quant_fwd(input: torch.Tensor, output: torch.Tensor, output_scale: torch.Tensor, quant_group_size: int, masked_m: torch.Tensor, scale_ue8m0: bool)
tanh(x)
gelu_and_mul_triton_kernel(gateup_output, down_input, hidden_size, reorder_topk_ids, scales, start_expert_id, end_expert_id, BLOCK_SIZE: tl.constexpr)
post_reorder_triton_kernel(down_output_ptr, output_ptr, src2dst_ptr, topk_ids_ptr, topk_weights_ptr, start_expert_id, end_expert_id, topk, hidden_size, dst_start, BLOCK_SIZE: tl.constexpr)
post_reorder_triton_kernel_for_cutlass_moe(down_output_ptr, output_ptr, src2dst_ptr, topk_ids_ptr, topk_weights_ptr, num_experts, topk, hidden_size, dst_start, BLOCK_SIZE: tl.constexpr)
compute_m_range(pid, batch_size, seg_indptr, weight_indices, m_num_tiles_indptr, BLOCK_SIZE_M: tl.constexpr)
grouped_gemm_triton_kernel(a, b, c, batch_size, N, K, seg_indptr, weight_indices, m_num_tiles_indptr, scale_a, scale_b, use_fp8_w8a8: tl.constexpr, group_n: tl.constexpr, group_k: tl.constexpr, a_stride_0: tl.constexpr, b_stride_0: tl.constexpr, b_stride_1: tl.constexpr, as_stride_0: tl.constexpr, as_stride_1: tl.constexpr, bs_stride_0: tl.constexpr, bs_stride_2: tl.constexpr, bs_stride_1: tl.constexpr, use_per_token_if_dynamic: tl.constexpr, BLOCK_SIZE_M: tl.constexpr, BLOCK_SIZE_N: tl.constexpr, BLOCK_SIZE_K: tl.constexpr)
compute_m_num_tiles_indptr(m_num_tiles_indptr, seg_indptr, batch_size: tl.constexpr, BLOCK_SIZE_M: tl.constexpr)
grouped_gemm_triton(a: torch.Tensor, b: torch.Tensor, c: torch.Tensor, batch_size: int, weight_column_major: bool, seg_indptr: Optional[torch.Tensor], weight_indices: Optional[torch.Tensor], use_fp8_w8a8: bool, scale_a: torch.Tensor, scale_b: torch.Tensor, block_shape: Optional[List[int]], c_dtype, use_per_token_if_dynamic: bool)
ep_scatter(recv_x: torch.Tensor, recv_x_scale: torch.Tensor, recv_topk: torch.Tensor, num_recv_tokens_per_expert: torch.Tensor, expert_start_loc: torch.Tensor, output_tensor: torch.Tensor, output_tensor_scale: torch.Tensor, m_indices: torch.Tensor, output_index: torch.Tensor, scale_ue8m0: bool)
ep_gather(input_tensor: torch.Tensor, recv_topk_ids: torch.Tensor, recv_topk_weight: torch.Tensor, input_index: torch.Tensor, output_tensor: torch.Tensor)
get_tma_aligned_size(x: int, element_size: int) -> int
tma_align_input_scale(input_scale: torch.Tensor)
compute_masked_m_triton_kernel(seg_indptr, masked_m)
deepgemm_compute_src2dst_triton_kernel(topk_ids, reorder_ids, seg_indptr, src2dst, m_max, num_toks, BLOCK_SIZE: tl.constexpr)
fill_gateup_input_triton_kernel(input_ptr, scale_ptr, gateup_input_ptr, gateup_input_scale_ptr, src2dst_ptr, topk_ids_ptr, start_expert_id, end_expert_id, topk, m_max, hidden_size, scale_size, BLOCK_SIZE: tl.constexpr)
moe_ep_deepgemm_preprocess(topk_ids: torch.Tensor, num_experts: int, hidden_states: torch.Tensor, top_k: int, start_expert_id, end_expert_id, block_shape, output_dtype: torch.dtype)
compute_identity_kernel(top_k, hidden_states_ptr, expert_scales_ptr, num_tokens, output_ptr, hidden_dim, scales_stride, BLOCK_SIZE: tl.constexpr)
zero_experts_compute_triton(expert_indices, expert_scales, num_experts, zero_expert_type, hidden_states)

# python/sglang/srt/layers/moe/ep_moe/layer.py
  EPMoE.__init__(num_experts: int, top_k: int, hidden_size: int, intermediate_size: int, layer_id: int, num_fused_shared_experts: int, params_dtype: Optional[torch.dtype], quant_config: Optional[QuantizationConfig], prefix: str, activation: str, routed_scaling_factor: Optional[float], gemm1_alpha: Optional[float], gemm1_clamp_limit: Optional[float], with_bias: bool)
  EPMoE.forward(hidden_states: torch.Tensor, topk_output: TopKOutput)
  EPMoE.forward_deepgemm(hidden_states: torch.Tensor, topk_output: TopKOutput)
  DeepEPMoE.__init__(num_experts: int, top_k: int, hidden_size: int, intermediate_size: int, layer_id: int, num_fused_shared_experts: int, params_dtype: Optional[torch.dtype], quant_config: Optional[QuantizationConfig], prefix: str, activation: str, routed_scaling_factor: Optional[float])
  DeepEPMoE.forward(hidden_states: torch.Tensor, topk_idx: torch.Tensor, topk_weights: torch.Tensor, forward_batch: ForwardBatch)
  DeepEPMoE.dispatch(hidden_states: torch.Tensor, topk_idx: torch.Tensor, topk_weights: torch.Tensor, forward_batch: ForwardBatch)
  DeepEPMoE.moe_impl(dispatch_output: DispatchOutput)
  DeepEPMoE.combine(hidden_states: torch.Tensor, topk_idx: torch.Tensor, topk_weights: torch.Tensor, forward_batch: ForwardBatch)
  DeepEPMoE.forward_aiter(dispatch_output: Union[DeepEPNormalOutput, DeepEPLLOutput])
  DeepEPMoE.forward_deepgemm_contiguous(dispatch_output: DeepEPNormalOutput)
  DeepEPMoE.forward_deepgemm_masked(dispatch_output: DeepEPLLOutput)
  DeepEPMoE.forward_npu(dispatch_output: DeepEPLLOutput)
get_moe_impl_class(quant_config: Optional[QuantizationConfig])
