================================================================================
FUNCTION INDEX: mem_cache module
================================================================================
Total Functions: 327
Documented: 45


============================================================
FILE: python/sglang/srt/mem_cache/allocator.py
Functions: 48
============================================================

MODULE FUNCTIONS:
----------------------------------------
  L 291: def alloc_extend_kernel(pre_lens_ptr,
        seq_lens_ptr,
        last_loc_ptr,
        free_page_ptr,
        out_indices,
        ret_values,
        bs_upper: tl.constexpr,
        page_size: tl.constexpr,
        max_num_extend_tokens: tl.constexpr)
         @triton.jit

  L 379: def alloc_decode_kernel(seq_lens_ptr,
        last_loc_ptr,
        free_page_ptr,
        out_indices,
        ret_values,
        bs_upper: tl.constexpr,
        page_size: tl.constexpr)
         @triton.jit


CLASS: BaseTokenToKVPoolAllocator
----------------------------------------
  L  38: __init__(self, size: int, page_size: int, dtype: torch.dtype, device: str, kvcache: KVCache, need_sort: bool)

  L  59: debug_print(self)
         ‚Üí str

  L  62: available_size(self)

  L  65: get_kvcache(self)

  L  68: restore_state(self, state)

  L  71: backup_state(self)

  L  74: free_group_begin(self)

  L  78: free_group_end(self)

  L  83: merge_and_sort_free(self)

  L  91: get_cpu_copy(self)

  L  95: load_cpu_copy(self)

  L  99: alloc_extend(self)

  L 102: alloc_decode(self)

  L 106: clear(self)

  L 110: alloc(self, need_size: int)

  L 114: free(self, free_index: torch.Tensor)


CLASS: PagedTokenToKVPoolAllocator
----------------------------------------
  L 429: __init__(self, size: int, page_size: int, dtype: torch.dtype, device: str, kvcache: KVCache, need_sort: bool)

  L 445: alloc(self, need_size: int)

  L 468: alloc_extend(self, prefix_lens: torch.Tensor, seq_lens: torch.Tensor, last_loc: torch.Tensor, extend_num_tokens: int)

  L 517: alloc_decode(self, seq_lens: torch.Tensor, last_loc: torch.Tensor)

  L 552: free(self, free_index: torch.Tensor)

  L 568: clear(self)

  L 577: get_cpu_copy(self, indices)

  L 580: load_cpu_copy(self, kv_cache_cpu, indices)


CLASS: SWATokenToKVPoolAllocator
----------------------------------------
  L 178: __init__(self, size: int, size_swa: int, dtype: torch.dtype, device: str, kvcache: SWAKVPool, need_sort: bool)

  L 214: available_size(self)

  L 217: full_available_size(self)

  L 220: swa_available_size(self)

  L 224: size_full(self)

  L 228: size_swa(self)

  L 231: debug_print(self)
         ‚Üí str

  L 239: get_kvcache(self)

  L 242: translate_loc_from_full_to_swa(self, kv_indices: torch.Tensor)

  L 246: alloc(self, need_size: int)

  L 257: free(self, free_index: torch.Tensor)

  L 270: free_swa(self, free_index: torch.Tensor)

  L 276: backup_state(self)

  L 279: restore_state(self, state)

  L 282: clear(self)


CLASS: TokenToKVPoolAllocator
----------------------------------------
  L 121: __init__(self, size: int, dtype: torch.dtype, device: str, kvcache: KVCache, need_sort: bool)

  L 132: clear(self)

  L 141: available_size(self)

  L 145: alloc(self, need_size: int)

  L 156: free(self, free_index: torch.Tensor)

  L 168: get_cpu_copy(self, indices)

  L 171: load_cpu_copy(self, kv_cache_cpu, indices)


============================================================
FILE: python/sglang/srt/mem_cache/allocator_ascend.py
Functions: 3
============================================================

MODULE FUNCTIONS:
----------------------------------------
  L  13: def alloc_extend_kernel_ascend(prefix_lens,
        seq_lens,
        last_loc,
        free_pages,
        out_indices,
        page_size,
        device)


CLASS: AscendPagedTokenToKVPoolAllocator
----------------------------------------
  L  69: alloc_extend(self, prefix_lens: torch.Tensor, seq_lens: torch.Tensor, last_loc: torch.Tensor, extend_num_tokens: int)

  L 115: alloc_decode(self, seq_lens: torch.Tensor, last_loc: torch.Tensor)


============================================================
FILE: python/sglang/srt/mem_cache/base_prefix_cache.py
Functions: 19
============================================================


CLASS: BasePrefixCache
----------------------------------------
  L  35: reset(self)

  L  39: match_prefix(self, key: List[int])
         ‚Üí MatchResult

  L  43: cache_finished_req(self, req: Req)

  L  47: cache_unfinished_req(self, req: Req)

  L  51: evict(self, num_tokens: int)

  L  55: inc_lock_ref(self, node: Any)

  L  59: dec_lock_ref(self, node: Any, swa_uuid_for_lock: Optional[str])

  L  62: evictable_size(self)

  L  65: full_evictable_size(self)

  L  68: swa_evictable_size(self)

  L  71: protected_size(self)

  L  74: full_protected_size(self)

  L  77: swa_protected_size(self)

  L  80: total_size(self)

  L  83: pretty_print(self)

  L  86: init_load_back(self, last_host_node: Any, host_hit_length: int)
         ‚Üí Tuple[torch.Tensor, Any]
         üìù Preparing KV cache loading from host to device.

  L  96: ready_to_load_host_cache(self)
         ‚Üí Any
         üìù Notify the cache controller to start the KV cache loading

  L 102: check_hicache_events(self)
         ‚Üí Any
         üìù Check HiCache related activities to update radix tree and synchronize 

  L 108: take_events(self)


============================================================
FILE: python/sglang/srt/mem_cache/chunk_cache.py
Functions: 12
============================================================


CLASS: ChunkCache
----------------------------------------
  L  21: __init__(self, req_to_token_pool: ReqToTokenPool, token_to_kv_pool_allocator: BaseTokenToKVPoolAllocator, page_size: int)

  L  31: reset(self)

  L  34: match_prefix(self)
         ‚Üí MatchResult

  L  41: cache_finished_req(self, req: Req)

  L  50: cache_unfinished_req(self, req: Req)

  L  58: evict(self, num_tokens: int)

  L  61: inc_lock_ref(self, node: Any)

  L  64: dec_lock_ref(self, node: Any, swa_uuid_for_lock: Optional[str])

  L  67: pretty_print(self)


CLASS: SWAChunkCache
----------------------------------------
  L  74: __init__(self, req_to_token_pool: ReqToTokenPool, token_to_kv_pool_allocator: SWATokenToKVPoolAllocator, page_size: int)

  L  83: evict_swa(self, req: Req, prelen: int, attention_chunk_size: int)

  L  99: evict(self, num_tokens: int)


============================================================
FILE: python/sglang/srt/mem_cache/hicache_storage.py
Functions: 15
============================================================

MODULE FUNCTIONS:
----------------------------------------
  L  13: def get_hash_str(token_ids: List[int], prior_hash: str)
         ‚Üí str


CLASS: HiCacheFile
----------------------------------------
  L 119: __init__(self, storage_config: HiCacheStorageConfig, file_path: str)

  L 137: get(self, key: str, target_location: torch.Tensor, target_sizes: Optional[Any])
         ‚Üí torch.Tensor | None

  L 158: batch_get(self, keys: List[str], target_locations: List[torch.Tensor], target_sizes: Optional[Any])
         ‚Üí List[torch.Tensor | None]

  L 171: set(self, key: str, value: Optional[Any], target_location: Optional[Any], target_sizes: Optional[Any])
         ‚Üí bool

  L 190: batch_set(self, keys: List[str], values: Optional[Any], target_locations: Optional[Any], target_sizes: Optional[Any])
         ‚Üí bool

  L 202: exists(self, key: str)
         ‚Üí bool

  L 207: delete(self, key: str)
         ‚Üí None

  L 216: clear(self)
         ‚Üí None


CLASS: HiCacheStorage
----------------------------------------
  L  44: get(self, key: str, target_location: Optional[Any], target_sizes: Optional[Any])
         ‚Üí torch.Tensor | None
         üìù Retrieve the value associated with the given key.

  L  57: batch_get(self, keys: List[str], target_locations: Optional[Any], target_sizes: Optional[Any])
         ‚Üí List[torch.Tensor | None] | int
         üìù Retrieve values for multiple keys.

  L  70: set(self, key: str, value: Optional[Any], target_location: Optional[Any], target_sizes: Optional[Any])
         ‚Üí bool
         üìù Store the value associated with the given key.

  L  84: batch_set(self, keys: List[str], values: Optional[Any], target_locations: Optional[Any], target_sizes: Optional[Any])
         ‚Üí bool
         üìù Store multiple key-value pairs.

  L  98: exists(self, key: str)
         ‚Üí bool
         üìù Check if the key exists in the storage.

  L 105: batch_exists(self, keys: List[str])
         ‚Üí int
         üìù Check if the keys exist in the storage.


============================================================
FILE: python/sglang/srt/mem_cache/hiradix_cache.py
Functions: 21
============================================================


CLASS: HiRadixCache
----------------------------------------
  L  29: __init__(self, req_to_token_pool: ReqToTokenPool, token_to_kv_pool_allocator: BaseTokenToKVPoolAllocator, tp_cache_group: torch.distributed.ProcessGroup, page_size: int, hicache_ratio: float, hicache_size: int, hicache_write_policy: str, hicache_io_backend: str, hicache_mem_layout: str, hicache_storage_backend: Optional[str], hicache_storage_prefetch_policy: Optional[str], model_name: Optional[str], storage_backend_extra_config: Optional[str])

  L 115: reset(self)

  L 121: get_height(self, node: TreeNode)

  L 128: write_backup(self, node: TreeNode, write_back)

  L 151: write_backup_storage(self, node: TreeNode)

  L 158: inc_hit_count(self, node: TreeNode)

  L 176: writing_check(self, write_back)

  L 198: loading_check(self)

  L 213: evictable_size(self)

  L 216: evict(self, num_tokens: int)

  L 268: evict_host(self, num_tokens: int)

  L 295: load_back(self, node: TreeNode, mem_quota: Optional[int])
         ‚Üí Optional[torch.Tensor]

  L 347: init_load_back(self, last_node: TreeNode, host_hit_length: int, mem_quota: Optional[int])

  L 370: ready_to_load_host_cache(self)

  L 375: check_hicache_events(self)

  L 382: check_revoked_prefetch(self)

  L 404: check_backup_progress(self)

  L 431: can_terminate_prefetch(self, operation: PrefetchOperation)

  L 465: check_prefetch_progress(self, req_id: str)
         ‚Üí bool

  L 521: match_prefix(self, key: List[int])

  L 556: prefetch_from_storage(self, req_id: str, last_host_node: TreeNode, new_input_tokens: List[int], last_hash: Optional[str])


============================================================
FILE: python/sglang/srt/mem_cache/lora_radix_cache.py
Functions: 21
============================================================

MODULE FUNCTIONS:
----------------------------------------
  L  32: def get_child_key(key: LoRAKey)


CLASS: LoRAKey
----------------------------------------
  L  22: __init__(self, lora_id: str, token_ids: List[int])

  L  28: __len__(self)


CLASS: LoRARadixCache
----------------------------------------
  L  79: __init__(self, req_to_token_pool: ReqToTokenPool, token_to_kv_pool_allocator: BaseTokenToKVPoolAllocator, page_size: int, disable: bool)

  L 104: reset(self)

  L 111: match_prefix(self, key: List[int])
         ‚Üí MatchResult

  L 116: match_prefix_with_lora_id(self, key: LoRAKey)
         ‚Üí MatchResult
         üìù Find the matching prefix from the lora radix tree.

  L 149: insert(self, key: LoRAKey, value)

  L 157: cache_finished_req(self, req: Req)
         üìù Cache request when it finishes.

  L 186: cache_unfinished_req(self, req: Req)
         üìù Cache request when it is unfinished.

  L 221: pretty_print(self)

  L 225: total_size(self)

  L 228: evict(self, num_tokens: int)

  L 251: inc_lock_ref(self, node: LoRATreeNode)

  L 265: dec_lock_ref(self, node: LoRATreeNode)

  L 279: evictable_size(self)

  L 282: protected_size(self)

  L 286: all_values_flatten(self)


CLASS: LoRATreeNode
----------------------------------------
  L  45: __init__(self, id: Optional[int])

  L  57: evicted(self)

  L  60: __lt__(self, other: 'LoRATreeNode')


============================================================
FILE: python/sglang/srt/mem_cache/memory_pool.py
Functions: 62
============================================================

MODULE FUNCTIONS:
----------------------------------------
  L 644: def set_mla_kv_buffer_kernel(kv_buffer_ptr,
        cache_k_nope_ptr,
        cache_k_rope_ptr,
        loc_ptr,
        buffer_stride: tl.constexpr,
        nope_stride: tl.constexpr,
        rope_stride: tl.constexpr,
        nope_dim: tl.constexpr,
        rope_dim: tl.constexpr,
        BLOCK: tl.constexpr)
         @triton.jit

  L 682: def set_mla_kv_buffer_triton(kv_buffer: torch.Tensor,
        loc: torch.Tensor,
        cache_k_nope: torch.Tensor,
        cache_k_rope: torch.Tensor)

  L1106: def copy_all_layer_kv_cache(data_ptrs,
        strides,
        tgt_loc_ptr,
        src_loc_ptr,
        num_locs,
        num_locs_upper: tl.constexpr)
         @triton.jit


CLASS: AscendMLAPagedTokenToKVPool
----------------------------------------
  L 885: __init__(self, size: int, page_size: int, dtype: torch.dtype, kv_lora_rank: int, qk_rope_head_dim: int, layer_num: int, device: str, enable_memory_saver: bool, start_layer: Optional[int], end_layer: Optional[int])

  L 945: get_kv_size_bytes(self)

  L 955: get_kv_buffer(self, layer_id: int)

  L 963: get_key_buffer(self, layer_id: int)

  L 971: get_value_buffer(self, layer_id: int)

  L 980: get_contiguous_buf_infos(self)

  L 993: set_kv_buffer(self, layer: RadixAttention, loc: torch.Tensor, cache_k: torch.Tensor, cache_v: torch.Tensor)


CLASS: AscendTokenToKVPool
----------------------------------------
  L 582: get_contiguous_buf_infos(self)

  L 608: set_kv_buffer(self, layer: RadixAttention, loc: torch.Tensor, cache_k: torch.Tensor, cache_v: torch.Tensor, k_scale: Optional[float], v_scale: Optional[float])


CLASS: DoubleSparseTokenToKVPool
----------------------------------------
  L1027: __init__(self, size: int, page_size: int, dtype: torch.dtype, head_num: int, head_dim: int, layer_num: int, device: str, heavy_channel_num: int, enable_memory_saver: bool, start_layer: Optional[int], end_layer: Optional[int])

  L1075: get_key_buffer(self, layer_id: int)

  L1078: get_value_buffer(self, layer_id: int)

  L1081: get_label_buffer(self, layer_id: int)

  L1084: get_kv_buffer(self, layer_id: int)

  L1090: set_kv_buffer(self, layer: RadixAttention, loc: torch.Tensor, cache_k: torch.Tensor, cache_v: torch.Tensor, cache_label: torch.Tensor)


CLASS: KVCache
----------------------------------------
  L 102: __init__(self, size: int, page_size: int, dtype: torch.dtype, layer_num: int, device: str, enable_memory_saver: bool, start_layer: Optional[int], end_layer: Optional[int])

  L 134: get_key_buffer(self, layer_id: int)
         ‚Üí torch.Tensor

  L 138: get_value_buffer(self, layer_id: int)
         ‚Üí torch.Tensor

  L 142: get_kv_buffer(self, layer_id: int)
         ‚Üí Tuple[torch.Tensor, torch.Tensor]

  L 146: set_kv_buffer(self, layer: RadixAttention, loc: torch.Tensor, cache_k: torch.Tensor, cache_v: torch.Tensor)
         ‚Üí None

  L 155: register_layer_transfer_counter(self, layer_transfer_counter)

  L 158: get_cpu_copy(self, indices)

  L 161: load_cpu_copy(self, kv_cache_cpu, indices)


CLASS: MHATokenToKVPool
----------------------------------------
  L 167: __init__(self, size: int, page_size: int, dtype: torch.dtype, head_num: int, head_dim: int, layer_num: int, device: str, enable_memory_saver: bool, start_layer: Optional[int], end_layer: Optional[int])

  L 267: get_kv_size_bytes(self)

  L 279: get_contiguous_buf_infos(self)

  L 305: maybe_get_custom_mem_pool(self)

  L 308: get_cpu_copy(self, indices)

  L 326: load_cpu_copy(self, kv_cache_cpu, indices)

  L 349: get_key_buffer(self, layer_id: int)

  L 364: get_value_buffer(self, layer_id: int)

  L 369: get_kv_buffer(self, layer_id: int)

  L 372: set_kv_buffer(self, layer: RadixAttention, loc: torch.Tensor, cache_k: torch.Tensor, cache_v: torch.Tensor, k_scale: Optional[float], v_scale: Optional[float], layer_id_override: Optional[int])

  L 412: move_kv_cache(self, tgt_loc: torch.Tensor, src_loc: torch.Tensor)


CLASS: MLATokenToKVPool
----------------------------------------
  L 710: __init__(self, size: int, page_size: int, dtype: torch.dtype, kv_lora_rank: int, qk_rope_head_dim: int, layer_num: int, device: str, enable_memory_saver: bool, start_layer: Optional[int], end_layer: Optional[int])

  L 779: get_kv_size_bytes(self)

  L 787: get_contiguous_buf_infos(self)

  L 796: maybe_get_custom_mem_pool(self)

  L 799: get_key_buffer(self, layer_id: int)

  L 807: get_value_buffer(self, layer_id: int)

  L 817: get_kv_buffer(self, layer_id: int)

  L 820: set_kv_buffer(self, layer: RadixAttention, loc: torch.Tensor, cache_k: torch.Tensor, cache_v: torch.Tensor)

  L 837: set_mla_kv_buffer(self, layer: RadixAttention, loc: torch.Tensor, cache_k_nope: torch.Tensor, cache_k_rope: torch.Tensor)

  L 856: get_cpu_copy(self, indices)

  L 871: load_cpu_copy(self, kv_cache_cpu, indices)


CLASS: ReqToTokenPool
----------------------------------------
  L  53: __init__(self, size: int, max_context_len: int, device: str, enable_memory_saver: bool)

  L  75: write(self, indices, values)

  L  78: available_size(self)

  L  81: alloc(self, need_size: int)
         ‚Üí List[int]

  L  90: free(self, free_index: Union[int, List[int]])

  L  96: clear(self)


CLASS: SWAKVPool
----------------------------------------
  L 426: __init__(self, size: int, size_swa: int, dtype: torch.dtype, head_num: int, head_dim: int, swa_attention_layer_ids: List[int], full_attention_layer_ids: List[int], enable_kvcache_transpose: bool, device: str)

  L 478: get_kv_size_bytes(self)

  L 483: get_contiguous_buf_infos(self)

  L 497: get_key_buffer(self, layer_id: int)

  L 504: get_value_buffer(self, layer_id: int)

  L 511: get_kv_buffer(self, layer_id: int)

  L 518: translate_loc_from_full_to_swa(self, kv_indices: torch.Tensor)

  L 522: set_kv_buffer(self, layer: RadixAttention, loc: torch.Tensor, cache_k: torch.Tensor, cache_v: torch.Tensor, k_scale: float, v_scale: float)


============================================================
FILE: python/sglang/srt/mem_cache/memory_pool_host.py
Functions: 48
============================================================

MODULE FUNCTIONS:
----------------------------------------
  L  38: def synchronized(debug_only)


CLASS: HostKVCache
----------------------------------------
  L  55: __init__(self, device_pool: KVCache, host_to_device_ratio: float, host_size: int, page_size: int, layout: str, pin_memory: bool, device: str)

  L 112: get_size_per_token(self)

  L 116: init_kv_buffer(self)

  L 120: load_to_device_per_layer(self, device_pool, host_indices, device_indices, layer_id, io_backend)
         ‚Üí None
         üìù Load KV data from the host memory pool to the device memory pool for a

  L 129: backup_from_device_all_layer(self, device_pool, host_indices, device_indices, io_backend)
         ‚Üí None
         üìù Backup KV data from the device memory pool to the host memory pool for

  L 138: get_flat_data_page(self, index)
         ‚Üí torch.Tensor
         üìù Get a flat data page from the host memory pool.

  L 145: get_dummy_flat_data_page(self)
         ‚Üí torch.Tensor
         üìù Get a dummy flat data page from the host memory pool.

  L 153: set_from_flat_data_page(self, index: int, data_page: torch.Tensor)
         ‚Üí None
         üìù Set a flat data page to the host memory pool.

  L 160: clear(self)

  L 167: available_size(self)

  L 171: alloc(self, need_size: int)
         ‚Üí torch.Tensor

  L 187: free(self, indices: torch.Tensor)
         ‚Üí int

  L 194: get_state(self, indices: torch.Tensor)
         ‚Üí MemoryStateInt

  L 203: is_reserved(self, indices: torch.Tensor)
         ‚Üí bool

  L 207: is_protected(self, indices: torch.Tensor)
         ‚Üí bool

  L 211: is_synced(self, indices: torch.Tensor)
         ‚Üí bool

  L 215: is_backup(self, indices: torch.Tensor)
         ‚Üí bool

  L 219: update_backup(self, indices: torch.Tensor)

  L 228: update_prefetch(self, indices: torch.Tensor)

  L 237: update_synced(self, indices: torch.Tensor)

  L 241: protect_write(self, indices: torch.Tensor)

  L 250: protect_load(self, indices: torch.Tensor)

  L 259: complete_io(self, indices: torch.Tensor)


CLASS: MHATokenToKVPoolHost
----------------------------------------
  L 271: __init__(self, device_pool: MHATokenToKVPool, host_to_device_ratio: float, host_size: int, page_size: int, layout: str, pin_memory: bool, device: str)

  L 303: get_size_per_token(self)

  L 310: get_ksize_per_token(self)

  L 313: init_kv_buffer(self)

  L 330: k_buffer(self)

  L 334: v_buffer(self)

  L 337: load_to_device_per_layer(self, device_pool, host_indices, device_indices, layer_id, io_backend)

  L 387: backup_from_device_all_layer(self, device_pool, host_indices, device_indices, io_backend)

  L 430: get_flat_data_page(self, index)
         ‚Üí torch.Tensor

  L 438: get_dummy_flat_data_page(self)
         ‚Üí torch.Tensor

  L 446: set_from_flat_data_page(self, index: int, data_page: torch.Tensor)
         ‚Üí None

  L 466: get_buffer_meta(self, keys, indices, local_rank)

  L 502: get_buffer_with_hash(self, keys, indices)


CLASS: MLATokenToKVPoolHost
----------------------------------------
  L 521: __init__(self, device_pool: MLATokenToKVPool, host_to_device_ratio: float, host_size: int, page_size: int, layout: str, pin_memory: bool, device: str)

  L 547: get_size_per_token(self)

  L 559: get_ksize_per_token(self)

  L 562: init_kv_buffer(self)

  L 591: load_to_device_per_layer(self, device_pool, host_indices, device_indices, layer_id, io_backend)

  L 627: backup_from_device_all_layer(self, device_pool, host_indices, device_indices, io_backend)

  L 666: get_flat_data_page(self, index)
         ‚Üí torch.Tensor

  L 674: get_dummy_flat_data_page(self)
         ‚Üí torch.Tensor

  L 687: set_from_flat_data_page(self, index: int, data_page: torch.Tensor)
         ‚Üí None

  L 705: get_buffer_meta(self, keys, indices, local_rank)

  L 729: get_buffer_with_hash(self, keys, indices)


============================================================
FILE: python/sglang/srt/mem_cache/multimodal_cache.py
Functions: 6
============================================================


CLASS: MultiModalCache
----------------------------------------
  L  14: __init__(self, max_size: int)

  L  40: put(self, mm_hash: int, embedding: torch.Tensor)
         ‚Üí bool

  L  49: has(self, mm_hash: int)
         ‚Üí bool

  L  52: get(self, mm_hash: int)
         ‚Üí torch.Tensor
         üìù Get embedding and update LRU order

  L  60: clear(self)

  L  67: __len__(self)


============================================================
FILE: python/sglang/srt/mem_cache/radix_cache.py
Functions: 22
============================================================


CLASS: RadixCache
----------------------------------------
  L 121: __init__(self, req_to_token_pool: ReqToTokenPool, token_to_kv_pool_allocator: BaseTokenToKVPoolAllocator, page_size: int, disable: bool, enable_kv_cache_events: bool)

  L 151: reset(self)

  L 161: match_prefix(self, key: List[int])
         ‚Üí MatchResult
         üìù Find the matching prefix from the radix tree.

  L 198: insert(self, key: List, value)

  L 206: cache_finished_req(self, req: Req)
         üìù Cache request when it finishes.

  L 243: cache_unfinished_req(self, req: Req)
         üìù Cache request when it is unfinished.

  L 288: pretty_print(self)

  L 292: total_size(self)

  L 295: evict(self, num_tokens: int)

  L 320: inc_lock_ref(self, node: TreeNode)

  L 334: dec_lock_ref(self, node: TreeNode)

  L 348: evictable_size(self)

  L 351: protected_size(self)

  L 355: all_values_flatten(self)

  L 542: take_events(self)
         üìù Atomically takes all events and clears the queue.


CLASS: TreeNode
----------------------------------------
  L  47: __init__(self, id: Optional[int])

  L  71: evicted(self)

  L  75: backuped(self)

  L  78: protect_host(self)
         üìù Protect the host value from eviction.

  L  82: release_host(self)
         üìù Release the host value, allowing it to be evicted.

  L  89: get_last_hash_value(self)
         ‚Üí Optional[str]
         üìù Returns the hash value of the last page in this node.

  L  95: __lt__(self, other: 'TreeNode')


============================================================
FILE: python/sglang/srt/mem_cache/radix_cache_cpp.py
Functions: 12
============================================================


CLASS: RadixCacheCpp
----------------------------------------
  L  40: __init__(self, disable: bool, use_hicache: bool, req_to_token_pool: ReqToTokenPool, token_to_kv_pool: BaseTokenToKVPoolAllocator, tp_cache_group: torch.distributed.ProcessGroup, page_size: int, hicache_ratio: float, hicache_size: int, hicache_write_policy: str, enable_kv_cache_events: bool, hicache_oracle: bool, enable_write_cancel: bool)

  L  90: reset(self)

  L  96: match_prefix(self, key: List[int])
         ‚Üí MatchResult

  L 123: dec_lock_ref(self, node: TreeNodeCpp)
         üìù Decrement the reference count of a node to root of the radix tree.

  L 131: inc_lock_ref(self, node: TreeNodeCpp)
         üìù Increment the reference count of from a node to root of the radix tree

  L 139: evict(self, num_tokens: int)

  L 144: evictable_size(self)

  L 147: protected_size(self)

  L 150: total_size(self)

  L 153: cache_finished_req(self, req: Req)
         üìù Cache request when it finishes.

  L 184: cache_unfinished_req(self, req: Req)
         üìù Cache request when it is unfinished.

  L 228: pretty_print(self)


============================================================
FILE: python/sglang/srt/mem_cache/swa_radix_cache.py
Functions: 38
============================================================

MODULE FUNCTIONS:
----------------------------------------
  L 113: def gen_swa_uuid()
         ‚Üí int


CLASS: LRUList
----------------------------------------
  L 119: __init__(self, swa: bool)

  L 168: reset_node_mru(self, node)
         üìù Move a (existing) node to most recently used position

  L 179: reset_node_and_parents_mru(self, node, root_node)
         üìù Move an (existing) node and its parents to most recently used position

  L 196: insert_mru(self, node)
         üìù Insert a (new) node as most recently used

  L 209: remove_node(self, node: TreeNode)
         üìù Remove node from lru list

  L 220: get_lru_no_lock(self)
         ‚Üí Optional[TreeNode]
         üìù Get the least recently used node that is not locked

  L 226: get_leaf_lru_no_lock(self)
         ‚Üí Optional[TreeNode]
         üìù Get the least recently used leaf node that is not locked

  L 232: get_prev_no_lock(self, node: TreeNode, check_id: bool)
         ‚Üí Optional[TreeNode]
         üìù Get the previous (i.e. more recently used) node that is not locked

  L 250: get_prev_leaf_no_lock(self, node: TreeNode, check_id: bool)
         üìù Get the previous (i.e. more recently used) leaf node that is not locke

  L 266: in_list(self, node: Optional[TreeNode])
         üìù Check if the node is in the lru list

  L 275: sanity_check_evictable_size(self)
         üìù Check the evictable size (i.e. the size of the nodes that are not lock

  L 287: sanity_check(self, tree_cache: 'SWARadixCache')
         üìù Check if the lru list is valid by rebuilding the lru list from the tre


CLASS: SWARadixCache
----------------------------------------
  L 340: __init__(self, req_to_token_pool: ReqToTokenPool, token_to_kv_pool_allocator: SWATokenToKVPoolAllocator, sliding_window_size: int, page_size: int, disable: bool)

  L 371: reset(self)
         ‚Üí None

  L 385: match_prefix(self, key: List[int])
         ‚Üí MatchResult
         üìù Find the matching prefix from the radix tree.

  L 422: insert(self, key: List, value, prev_prefix_len: int)
         ‚Üí int

  L 430: cache_finished_req(self, req: Req)
         ‚Üí None
         üìù Cache request when it finishes.

  L 467: cache_unfinished_req(self, req: Req)
         ‚Üí None
         üìù Cache request when it is unfinished.

  L 521: pretty_print(self)
         ‚Üí None

  L 526: total_size(self)
         ‚Üí Tuple[int, int]

  L 529: evict(self, full_num_tokens: int, swa_num_tokens: int)
         ‚Üí None

  L 612: inc_lock_ref(self, node: TreeNode)
         ‚Üí Optional[int]
         üìù Increment the lock reference count for the node. Returns the swa_uuid_

  L 653: dec_lock_ref(self, node: TreeNode, swa_uuid_for_lock: Optional[int])
         üìù Decrement the lock reference count for the node.

  L 690: sanity_check(self)

  L 694: evictable_size(self)
         ‚Üí Tuple[int, int]

  L 698: full_evictable_size(self)
         ‚Üí int

  L 701: swa_evictable_size(self)
         ‚Üí int

  L 705: full_lru_list_evictable_size(self)
         ‚Üí int

  L 709: swa_lru_list_evictable_size(self)
         ‚Üí int

  L 712: protected_size(self)
         ‚Üí Tuple[int, int]

  L 716: full_protected_size(self)
         ‚Üí int

  L 720: swa_protected_size(self)
         ‚Üí int

  L 724: all_values_flatten(self)
         ‚Üí torch.Tensor


CLASS: TreeNode
----------------------------------------
  L  47: __init__(self, id: Optional[int])

  L  81: evicted(self)

  L  85: backuped(self)

  L  88: __lt__(self, other: 'TreeNode')
