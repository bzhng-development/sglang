================================================================================
FUNCTION INDEX: layers module
================================================================================
Total Functions: 272
Documented: 30


============================================================
FILE: python/sglang/srt/layers/activation.py
Functions: 20
============================================================

MODULE FUNCTIONS:
----------------------------------------
  L 203: def get_act_fn(act_fn_name: str,
        quant_config: Optional[QuantizationConfig],
        intermediate_size: Optional[int],
        input_is_parallel: bool,
        params_dtype: Optional[torch.dtype])
         â†’ nn.Module
         ðŸ“ Get an activation function by name.

  L 228: def get_cross_encoder_activation_function(config: PretrainedConfig)


CLASS: GeluAndMul
----------------------------------------
  L  86: __init__(self, approximate)

  L  90: forward_native(self, x: torch.Tensor)
         â†’ torch.Tensor

  L  94: forward_cuda(self, x: torch.Tensor)
         â†’ torch.Tensor

  L 106: forward_npu(self, x: torch.Tensor)
         â†’ torch.Tensor


CLASS: NewGELU
----------------------------------------
  L 117: forward_native(self, x: torch.Tensor)
         â†’ torch.Tensor

  L 121: forward_cuda(self, x: torch.Tensor)
         â†’ torch.Tensor


CLASS: QuickGELU
----------------------------------------
  L 138: forward_native(self, x: torch.Tensor)
         â†’ torch.Tensor

  L 141: forward_cuda(self, x: torch.Tensor)
         â†’ torch.Tensor

  L 144: forward_hip(self, x: torch.Tensor)
         â†’ torch.Tensor

  L 149: forward_npu(self, x: torch.Tensor)
         â†’ torch.Tensor


CLASS: ReLU2
----------------------------------------
  L 132: forward(self, x: torch.Tensor)
         â†’ torch.Tensor


CLASS: ScaledActivation
----------------------------------------
  L 159: __init__(self, act_module: nn.Module, intermediate_size: int, input_is_parallel: bool, params_dtype: Optional[torch.dtype])

  L 181: forward(self, x: torch.Tensor)
         â†’ torch.Tensor

  L 184: weight_loader(self, param: nn.Parameter, loaded_weight: torch.Tensor)


CLASS: SiluAndMul
----------------------------------------
  L  60: forward_native(self, x: torch.Tensor)
         â†’ torch.Tensor

  L  64: forward_cuda(self, x: torch.Tensor)
         â†’ torch.Tensor

  L  71: forward_cpu(self, x: torch.Tensor)
         â†’ torch.Tensor

  L  80: forward_npu(self, x: torch.Tensor)
         â†’ torch.Tensor


============================================================
FILE: python/sglang/srt/layers/amx_utils.py
Functions: 4
============================================================

MODULE FUNCTIONS:
----------------------------------------
  L  10: def amx_process_weight_after_loading(weight)

  L  22: def dim_is_supported(weight)


CLASS: PackWeightMethod
----------------------------------------
  L  79: __init__(self, weight_names, transpose_dims)

  L  83: process_weights_after_loading(self, module)
         â†’ None


============================================================
FILE: python/sglang/srt/layers/communicator.py
Functions: 16
============================================================

MODULE FUNCTIONS:
----------------------------------------
  L 155: def enable_moe_dense_fully_dp()


CLASS: CommunicateContext
----------------------------------------
  L 315: is_same_group_size(self, a: ScatterMode, b: ScatterMode)

  L 319: init_new(cls)


CLASS: CommunicateSimpleFn
----------------------------------------
  L 341: get_fn(input_mode: ScatterMode, output_mode: ScatterMode, context: CommunicateContext)


CLASS: CommunicateSummableTensorPairFn
----------------------------------------
  L 527: execute(cls, hidden_states_input_mode, residual_input_mode, output_mode, context)

  L 543: get_fn(hidden_states_input_mode: ScatterMode, residual_input_mode: ScatterMode, output_mode: ScatterMode, context: CommunicateContext)


CLASS: CommunicateWithAllReduceAndLayerNormFn
----------------------------------------
  L 388: get_fn(hidden_states_input_mode: ScatterMode, residual_input_mode: ScatterMode, hidden_states_output_mode: ScatterMode, residual_output_mode: ScatterMode, context: CommunicateContext)


CLASS: LayerCommunicator
----------------------------------------
  L 160: __init__(self, layer_scatter_modes: LayerScatterModes, input_layernorm: torch.nn.Module, post_attention_layernorm: torch.nn.Module, allow_reduce_scatter: bool, is_last_layer: bool)

  L 199: prepare_attn(self, hidden_states: torch.Tensor, residual: torch.Tensor, forward_batch: ForwardBatch)

  L 235: prepare_mlp(self, hidden_states: torch.Tensor, residual: torch.Tensor, forward_batch: ForwardBatch)

  L 249: postprocess_layer(self, hidden_states: torch.Tensor, residual: torch.Tensor, forward_batch: ForwardBatch)

  L 263: should_use_reduce_scatter(self, forward_batch: ForwardBatch)

  L 271: should_fuse_mlp_allreduce_with_next_layer(self, forward_batch: ForwardBatch)
         â†’ bool


CLASS: LayerScatterModes
----------------------------------------
  L  99: init_new(cls)


CLASS: ScatterMode
----------------------------------------
  L  67: model_input_output()
         ðŸ“ The scatter mode for model forward pass input and output data


CLASS: _LayerModeComputationContext
----------------------------------------
  L  79: previous_layer(self)


============================================================
FILE: python/sglang/srt/layers/dp_attention.py
Functions: 40
============================================================

MODULE FUNCTIONS:
----------------------------------------
  L 123: def set_dp_buffer_len(global_dp_buffer_len: int,
        local_dp_buffer_len: int,
        global_num_tokens: Optional[List[int]])

  L 133: def get_global_dp_buffer()
         â†’ torch.Tensor

  L 137: def get_local_dp_buffer()
         â†’ torch.Tensor

  L 141: def get_global_dp_buffer_len()
         â†’ int

  L 145: def get_local_dp_buffer_len()
         â†’ int

  L 149: def get_dp_global_num_tokens()
         â†’ List[int]

  L 153: def compute_dp_attention_world_info(enable_dp_attention,
        tp_rank,
        tp_size,
        dp_size)

  L 164: def compute_dp_attention_local_info(enable_dp_attention,
        tp_rank,
        tp_size,
        dp_size,
        moe_dense_tp_size)

  L 181: def initialize_dp_attention(server_args: ServerArgs, model_config: ModelConfig)

  L 241: def is_dp_attention_enabled()
         â†’ bool

  L 245: def get_attention_tp_group()
         â†’ GroupCoordinator

  L 250: def get_attention_tp_rank()
         â†’ int

  L 255: def get_attention_tp_size()
         â†’ int

  L 260: def get_attention_dp_rank()
         â†’ int

  L 265: def get_attention_dp_size()
         â†’ int

  L 270: def get_local_attention_dp_rank()
         â†’ int

  L 275: def get_local_attention_dp_size()
         â†’ int

  L 281: def disable_dp_size()
         ðŸ“ Patch the tp group temporarily until this function ends.
            This method is for draft workers of speculative decoding to run draft model
            with different tp degree from that of target model workers.
            Args:
            tp_group (GroupCoordinator): the tp group coordinator
         @contextmanager

  L 301: def get_dp_local_info(forward_batch: ForwardBatch)
         â†’ Tuple[torch.Tensor, torch.Tensor]

  L 320: def memcpy_triton_kernel(dst_ptr,
        src_ptr,
        offset_ptr,
        sz_ptr,
        offset_src: tl.constexpr,
        chunk_size,
        BLOCK_SIZE: tl.constexpr)
         @triton.jit

  L 345: def prod(x)

  L 349: def memcpy_triton(dst, src, dim, offset, sz, offset_src)

  L 431: def dp_gather_partial(global_tokens: torch.Tensor,
        local_tokens: torch.Tensor,
        forward_batch: ForwardBatch)

  L 439: def dp_gather_replicate(global_tokens: torch.Tensor,
        local_tokens: torch.Tensor,
        forward_batch: ForwardBatch)

  L 447: def dp_scatter(local_tokens: torch.Tensor,
        global_tokens: torch.Tensor,
        forward_batch: ForwardBatch)

  L 469: def dp_reduce_scatter_tensor(output: torch.Tensor, input: torch.Tensor)

  L 480: def attn_tp_reduce_scatter_tensor(output: torch.Tensor, input: torch.Tensor)

  L 484: def attn_tp_all_gather_into_tensor(output: torch.Tensor, input: torch.Tensor)

  L 488: def attn_tp_all_gather(output_list: List[torch.Tensor], input: torch.Tensor)


CLASS: DpPaddingMode
----------------------------------------
  L  47: is_max_len(self)

  L  50: is_sum_len(self)

  L  54: get_dp_padding_mode(cls, global_num_tokens: List[int])
         â†’ DpPaddingMode

  L  64: get_default_mode_in_cuda_graph(cls)
         â†’ DpPaddingMode


CLASS: _DpGatheredBufferWrapper
----------------------------------------
  L  78: set_metadata(cls, hidden_size: int, dtype: torch.dtype, device: torch.device)

  L  84: set_dp_buffer_len(cls, global_dp_buffer_len: int, local_dp_buffer_len: int, global_num_tokens: Optional[List[int]])

  L  95: get_global_dp_buffer(cls)
         â†’ torch.Tensor

  L 103: get_local_dp_buffer(cls)
         â†’ torch.Tensor

  L 111: get_global_dp_buffer_len(cls)
         â†’ int

  L 115: get_local_dp_buffer_len(cls)
         â†’ int

  L 119: get_dp_global_num_tokens(cls)
         â†’ List[int]


============================================================
FILE: python/sglang/srt/layers/elementwise.py
Functions: 23
============================================================

MODULE FUNCTIONS:
----------------------------------------
  L  37: def fused_softcap_kernel(output_ptr,
        input_ptr,
        n_ele,
        softcap_const: tl.constexpr,
        BLOCK_SIZE: tl.constexpr)
         @triton.jit

  L  61: def fused_softcap(x, softcap_const, autotune)

  L 138: def fused_dual_residual_rmsnorm_kernel(output_ptr,
        mid_ptr,
        activ_ptr,
        residual_ptr,
        weight1_ptr,
        weight2_ptr,
        eps: tl.constexpr,
        hidden_dim: tl.constexpr,
        BLOCK_SIZE: tl.constexpr)
         @triton.jit

  L 188: def fused_dual_residual_rmsnorm(x, residual, weight1, weight2, eps, autotune)

  L 222: def fused_rmsnorm_kernel(output_ptr,
        activ_ptr,
        weight_ptr,
        eps: tl.constexpr,
        hidden_dim: tl.constexpr,
        BLOCK_SIZE: tl.constexpr)
         @triton.jit

  L 252: def fused_rmsnorm(x, weight, eps, autotune, inplace)

  L 329: def experts_combine_kernel(out_hidden_states,
        moe_hidden_states,
        mlp_hidden_states,
        combine_k: tl.constexpr,
        hidden_dim: tl.constexpr,
        BLOCK_SIZE: tl.constexpr)
         @triton.jit

  L 359: def experts_combine_triton(moe_hidden_states, mlp_hidden_states, output_buffer)

  L 399: def gelu_and_mul_kernel(out_hidden_states_ptr,
        out_scales_ptr,
        hidden_states_ptr,
        quant_max: tl.constexpr,
        static_scale: tl.constexpr,
        hidden_dim: tl.constexpr,
        BLOCK_SIZE: tl.constexpr)
         @triton.jit

  L 436: def gelu_and_mul_triton(hidden_states, scales, quantize, out)

  L 493: def silu_and_mul_kernel(out_hidden_states_ptr,
        out_scales_ptr,
        hidden_states_ptr,
        quant_max: tl.constexpr,
        static_scale: tl.constexpr,
        hidden_dim: tl.constexpr,
        BLOCK_SIZE: tl.constexpr)
         @triton.jit

  L 530: def silu_and_mul_triton(hidden_states, scales, quantize, out)


CLASS: FusedDualResidualRMSNorm
----------------------------------------
  L 279: __init__(self, rmsnorm1, rmsnorm2)
         â†’ None

  L 286: __call__(self)

  L 289: forward(self, x: torch.Tensor, residual: torch.Tensor)
         â†’ Tuple[torch.Tensor, torch.Tensor]

  L 297: forward_cuda(self, x: torch.Tensor, residual: torch.Tensor, autotune)
         â†’ Tuple[torch.Tensor, torch.Tensor]

  L 309: forward_flashinfer(self, x: torch.Tensor, residual: torch.Tensor)
         â†’ Tuple[torch.Tensor, torch.Tensor]

  L 318: forward_native(self, x: torch.Tensor, residual: torch.Tensor)
         â†’ Tuple[torch.Tensor, torch.Tensor]


CLASS: Softcap
----------------------------------------
  L  76: __init__(self, softcap_const: float)

  L  79: __call__(self)

  L  82: forward(self, x: torch.Tensor)
         â†’ torch.Tensor

  L  88: forward_native(self, x: torch.Tensor)
         â†’ torch.Tensor

  L  91: forward_cuda(self, x: torch.Tensor, autotune)
         â†’ torch.Tensor


============================================================
FILE: python/sglang/srt/layers/flashinfer_comm_fusion.py
Functions: 7
============================================================

MODULE FUNCTIONS:
----------------------------------------
  L  98: def ensure_workspace_initialized(max_token_num: int,
        hidden_dim: int,
        use_fp32_lamport: bool)
         ðŸ“ Ensure workspace is initialized

  L 126: def flashinfer_allreduce_residual_rmsnorm(input_tensor: torch.Tensor,
        residual: torch.Tensor,
        weight: torch.Tensor,
        eps: float,
        max_token_num: int,
        use_oneshot: Optional[bool],
        trigger_completion_at_end: bool,
        fp32_acc: bool)
         â†’ Tuple[torch.Tensor, torch.Tensor]
         ðŸ“ Use FlashInfer's fused allreduce + residual + RMS norm operation
            Args:
            input_tensor: Input tensor that needs allreduce
            residual: Residual tensor
            weight: RMS norm weight
            eps: RMS norm epsilon
            max_token_num: Maximum token number
            use_oneshot: Whether to use oneshot mode
            trigger_completion_at_end: Whether to trigger completion at end
            fp32_acc: Whether to use fp32 precision
            Returns:
            Tuple[torch.Tensor, torch.Tensor]: (norm_output, residual_output)

  L 203: def fake_flashinfer_allreduce_residual_rmsnorm(input_tensor: torch.Tensor,
        residual: torch.Tensor,
        weight: torch.Tensor,
        eps: float,
        max_token_num: int,
        use_oneshot: Optional[bool],
        trigger_completion_at_end: bool,
        fp32_acc: bool)
         â†’ Tuple[torch.Tensor, torch.Tensor]

  L 227: def cleanup_flashinfer_workspace()


CLASS: FlashInferWorkspaceManager
----------------------------------------
  L  32: __init__(self)

  L  39: initialize(self, world_size: int, rank: int, max_token_num: int, hidden_dim: int, group, use_fp32_lamport: bool)
         ðŸ“ Initialize workspace

  L  80: cleanup(self)
         ðŸ“ Clean up workspace


============================================================
FILE: python/sglang/srt/layers/layernorm.py
Functions: 17
============================================================


CLASS: Gemma3RMSNorm
----------------------------------------
  L 288: __init__(self, dim: int, eps: float)

  L 297: forward_native(self, x)

  L 304: forward_cuda(self, x)

  L 307: forward_npu(self, x)

  L 311: extra_repr(self)


CLASS: GemmaRMSNorm
----------------------------------------
  L 226: __init__(self, hidden_size: int, eps: float)
         â†’ None

  L 239: forward_native(self, x: torch.Tensor, residual: Optional[torch.Tensor])
         â†’ Union[torch.Tensor, Tuple[torch.Tensor, torch.Tensor]]

  L 256: forward_cuda(self, x: torch.Tensor, residual: Optional[torch.Tensor])
         â†’ Union[torch.Tensor, Tuple[torch.Tensor, torch.Tensor]]

  L 269: forward_npu(self, x: torch.Tensor, residual: Optional[torch.Tensor])
         â†’ Union[torch.Tensor, Tuple[torch.Tensor, torch.Tensor]]


CLASS: RMSNorm
----------------------------------------
  L  61: __init__(self, hidden_size: int, eps: float, var_hidden_size: Optional[int])
         â†’ None

  L  77: forward_cuda(self, x: torch.Tensor, residual: Optional[torch.Tensor])
         â†’ Union[torch.Tensor, Tuple[torch.Tensor, torch.Tensor]]

  L  90: forward_npu(self, x: torch.Tensor, residual: Optional[torch.Tensor])
         â†’ Union[torch.Tensor, Tuple[torch.Tensor, torch.Tensor]]

  L 102: forward_aiter(self, x: torch.Tensor, residual: Optional[torch.Tensor])
         â†’ Union[torch.Tensor, Tuple[torch.Tensor, torch.Tensor]]

  L 121: forward_hip(self, x: torch.Tensor, residual: Optional[torch.Tensor])
         â†’ Union[torch.Tensor, Tuple[torch.Tensor, torch.Tensor]]

  L 136: forward_native(self, x: torch.Tensor, residual: Optional[torch.Tensor])
         â†’ Union[torch.Tensor, Tuple[torch.Tensor, torch.Tensor]]

  L 175: forward_cpu(self, x: torch.Tensor, residual: Optional[torch.Tensor])
         â†’ Union[torch.Tensor, Tuple[torch.Tensor, torch.Tensor]]

  L 192: forward_with_allreduce_fusion(self, x: torch.Tensor, residual: Optional[torch.Tensor])
         â†’ Union[torch.Tensor, Tuple[torch.Tensor, torch.Tensor]]
         ðŸ“ Forward method with allreduce fusion, prioritizing flashinfer fused operations


============================================================
FILE: python/sglang/srt/layers/linear.py
Functions: 26
============================================================

MODULE FUNCTIONS:
----------------------------------------
  L  67: def adjust_marlin_shard(param, shard_size, shard_offset)

  L  75: def adjust_bitsandbytes_4bit_shard(param: Parameter,
        shard_offsets: Dict[str,
        Tuple[int,
        int]],
        loaded_shard_id: str)
         â†’ Tuple[int, int]
         ðŸ“ Adjust the quantization offsets and sizes for BitsAndBytes sharding.

  L  90: def adjust_scalar_to_fused_array(param, loaded_weight, shard_id)
         ðŸ“ For fused modules (QKV and MLP) we have an array of length
            N that holds 1 scale for each "logical" matrix. So the param
            is an array of length N. The loaded_weight corresponds to
            one of the shards on disk. Here, we slice the param based on
            the shard_id for loading.

  L 113: def adjust_shard_offsets(shard_offsets, loaded_weight, dim)


CLASS: ColumnParallelLinear
----------------------------------------
  L 281: __init__(self, input_size: int, output_size: int, bias: bool, gather_output: bool, skip_bias_add: bool, params_dtype: Optional[torch.dtype], quant_config: Optional[QuantizationConfig], output_sizes: Optional[List[int]], prefix: str, tp_rank: Optional[int], tp_size: Optional[int], use_presharded_weights: bool)

  L 348: weight_loader(self, param: Parameter, loaded_weight: torch.Tensor)

  L 398: weight_loader_v2(self, param: Parameter, loaded_weight: torch.Tensor)

  L 416: forward(self, input_)

  L 430: extra_repr(self)
         â†’ str


CLASS: LinearBase
----------------------------------------
  L 139: __init__(self, input_size: int, output_size: int, skip_bias_add: bool, params_dtype: Optional[torch.dtype], quant_config: Optional[QuantizationConfig], prefix: str)

  L 162: forward(self, x: torch.Tensor)
         â†’ torch.Tensor


CLASS: MergedColumnParallelLinear
----------------------------------------
  L 462: __init__(self, input_size: int, output_sizes: List[int], bias: bool, gather_output: bool, skip_bias_add: bool, params_dtype: Optional[torch.dtype], quant_config: Optional[QuantizationConfig], prefix: str, tp_rank: Optional[int], tp_size: Optional[int], use_presharded_weights: bool)

  L 499: weight_loader(self, param: Parameter, loaded_weight: torch.Tensor, loaded_shard_id: Optional[int])

  L 694: weight_loader_v2(self, param: BasevLLMParameter, loaded_weight: torch.Tensor, loaded_shard_id: Optional[int])


CLASS: QKVParallelLinear
----------------------------------------
  L 774: __init__(self, hidden_size: int, head_size: int, total_num_heads: int, total_num_kv_heads: Optional[int], bias: bool, skip_bias_add: bool, params_dtype: Optional[torch.dtype], quant_config: Optional[QuantizationConfig], prefix: str, tp_rank: Optional[int], tp_size: Optional[int], load_presharded_attn: bool)

  L 897: weight_loader_v2(self, param: BasevLLMParameter, loaded_weight: torch.Tensor, loaded_shard_id: Optional[str])

  L 935: weight_loader(self, param: Parameter, loaded_weight: torch.Tensor, loaded_shard_id: Optional[str])


CLASS: ReplicatedLinear
----------------------------------------
  L 180: __init__(self, input_size: int, output_size: int, bias: bool, skip_bias_add: bool, params_dtype: Optional[torch.dtype], quant_config: Optional[QuantizationConfig], prefix: str)

  L 225: weight_loader(self, param: Parameter, loaded_weight: torch.Tensor)

  L 243: forward(self, x: torch.Tensor)
         â†’ Tuple[torch.Tensor, Optional[torch.Tensor]]

  L 250: extra_repr(self)
         â†’ str


CLASS: RowParallelLinear
----------------------------------------
  L1174: __init__(self, input_size: int, output_size: int, bias: bool, input_is_parallel: bool, skip_bias_add: bool, params_dtype: Optional[torch.dtype], reduce_results: bool, quant_config: Optional[QuantizationConfig], prefix: str, tp_rank: Optional[int], tp_size: Optional[int], use_presharded_weights: bool)

  L1232: weight_loader(self, param: Parameter, loaded_weight: torch.Tensor)

  L1284: weight_loader_v2(self, param: BasevLLMParameter, loaded_weight: torch.Tensor)

  L1305: forward(self, input_, skip_all_reduce)

  L1332: extra_repr(self)
         â†’ str


============================================================
FILE: python/sglang/srt/layers/logits_processor.py
Functions: 9
============================================================

MODULE FUNCTIONS:
----------------------------------------
  L 607: def fused_softcap_kernel(full_logits_ptr,
        softcapping_value,
        n_elements,
        BLOCK_SIZE: tl.constexpr)
         @triton.jit

  L 634: def fused_softcap(full_logits, final_logit_softcapping)


CLASS: LogitsMetadata
----------------------------------------
  L 123: from_forward_batch(cls, forward_batch: ForwardBatch)

  L 173: compute_dp_attention_metadata(self)


CLASS: LogitsProcessor
----------------------------------------
  L 202: __init__(self, config, skip_all_gather: bool, logit_scale: Optional[float])

  L 235: forward(self, input_ids, hidden_states, lm_head: VocabParallelEmbedding, logits_metadata: Union[LogitsMetadata, ForwardBatch], aux_hidden_states: Optional[torch.Tensor])
         â†’ LogitsProcessorOutput

  L 525: get_top_logprobs(all_logprobs: torch.Tensor, logits_metadata: LogitsMetadata)

  L 554: get_token_ids_logprobs(all_logprobs: torch.Tensor, logits_metadata: LogitsMetadata)

  L 577: compute_temp_top_p_normalized_logprobs(last_logits: torch.Tensor, logits_metadata: LogitsMetadata)
         â†’ torch.Tensor
         ðŸ“ compute logprobs for the output token from the given logits.
            Returns:
            torch.Tensor: logprobs from logits


============================================================
FILE: python/sglang/srt/layers/multimodal.py
Functions: 3
============================================================

MODULE FUNCTIONS:
----------------------------------------
  L  44: def hash_tiles32_kernel_blocked(in_ptr,
        out_ptr,
        n_u32,
        seed1,
        seed2,
        FM_C1: tl.constexpr,
        FM_C2: tl.constexpr,
        POS_A: tl.constexpr,
        POS_B: tl.constexpr,
        TILE: tl.constexpr,
        BLOCK: tl.constexpr,
        USE_CG: tl.constexpr)
         @triton.jit

  L 108: def add_tree_reduce_u64_kernel(in_ptr, out_ptr, n_elems, CHUNK: tl.constexpr)
         @triton.jit

  L 145: def gpu_tensor_hash(tensor: torch.Tensor)
         â†’ int
         @torch.inference_mode()


============================================================
FILE: python/sglang/srt/layers/parameter.py
Functions: 31
============================================================

MODULE FUNCTIONS:
----------------------------------------
  L 460: def permute_param_layout_(param: BasevLLMParameter,
        input_dim: int,
        output_dim: int)
         â†’ BasevLLMParameter
         ðŸ“ Permute a parameter's layout to the specified input and output dimensions,
            useful for forcing the parameter into a known layout, for example, if I need
            a packed (quantized) weight matrix to be in the layout
            {input_dim = 0, output_dim = 1, packed_dim = 0}
            then I can call:
            permute_param_layout_(x, input_dim=0, output_dim=1, packed_dim=0)
            to ensure x is in the correct layout (permuting it to the correct layout if
            required, asserting if it cannot get it to the correct layout)


CLASS: BasevLLMParameter
----------------------------------------
  L  36: __new__(cls, data: torch.Tensor)

  L  40: __init__(self, data: torch.Tensor, weight_loader: Callable)
         ðŸ“ Initialize the BasevLLMParameter
            :param data: torch tensor with the parameter data
            :param weight_loader: weight loader callable
            :returns: a torch.nn.parameter

  L  53: weight_loader(self)

  L  60: load_column_parallel_weight(self, loaded_weight: torch.Tensor)

  L  63: load_row_parallel_weight(self, loaded_weight: torch.Tensor)

  L  66: load_merged_column_weight(self, loaded_weight: torch.Tensor)

  L  69: load_qkv_weight(self, loaded_weight: torch.Tensor)


CLASS: PackedColumnParameter
----------------------------------------
  L 383: __init__(self, packed_factor: Union[int, Fraction], packed_dim: int, marlin_tile_size: Optional[int])

  L 396: packed_dim(self)

  L 400: packed_factor(self)

  L 404: marlin_tile_size(self)

  L 407: adjust_shard_indexes_for_packing(self, shard_size, shard_offset)


CLASS: PackedvLLMParameter
----------------------------------------
  L 427: __init__(self, packed_factor: Union[int, Fraction], packed_dim: int, marlin_tile_size: Optional[int])

  L 440: packed_dim(self)

  L 444: packed_factor(self)

  L 448: marlin_tile_size(self)

  L 451: adjust_shard_indexes_for_packing(self, shard_size, shard_offset)


CLASS: PerTensorScaleParameter
----------------------------------------
  L 322: __init__(self)

  L 338: load_row_parallel_weight(self)

  L 343: load_merged_column_weight(self)

  L 346: load_qkv_weight(self)

  L 349: load_column_parallel_weight(self)


CLASS: RowvLLMParameter
----------------------------------------
  L 225: __init__(self, input_dim: int)

  L 230: input_dim(self)

  L 233: load_row_parallel_weight(self, loaded_weight: torch.Tensor, tp_rank: int, use_presharded_weights: bool)


CLASS: _ColumnvLLMParameter
----------------------------------------
  L  84: __init__(self, output_dim: int)

  L  89: output_dim(self)

  L  92: load_column_parallel_weight(self, loaded_weight: torch.Tensor, tp_rank: int, use_presharded_weights: bool)

  L 125: load_merged_column_weight(self, loaded_weight: torch.Tensor)

  L 166: load_qkv_weight(self, loaded_weight: torch.Tensor, tp_rank: int, use_presharded_weights: bool)


============================================================
FILE: python/sglang/srt/layers/pooler.py
Functions: 4
============================================================


CLASS: CrossEncodingPooler
----------------------------------------
  L  71: __init__(self, config: PretrainedConfig, classifier: nn.Module, pooler: Optional[nn.Module])

  L  82: forward(self, hidden_states: torch.Tensor, forward_batch: ForwardBatch)
         â†’ EmbeddingPoolerOutput
         ðŸ“ Pools sentence pair scores from the hidden_states.


CLASS: Pooler
----------------------------------------
  L  37: __init__(self, pooling_type: PoolingType, normalize: bool)

  L  42: forward(self, hidden_states: torch.Tensor, forward_batch: ForwardBatch)
         â†’ EmbeddingPoolerOutput


============================================================
FILE: python/sglang/srt/layers/radix_attention.py
Functions: 2
============================================================


CLASS: RadixAttention
----------------------------------------
  L  44: __init__(self, num_heads: int, head_dim: int, scaling: float, num_kv_heads: int, layer_id: int, logit_cap: float, v_head_dim: int, sliding_window_size: int, is_cross_attention: bool, pos_encoding_mode: str, logit_capping_method: str, quant_config: Optional[QuantizationConfig], attn_type: AttentionType, use_irope: bool, prefix: str)

  L  90: forward(self, q, k, v, forward_batch: ForwardBatch, save_kv_cache: bool)


============================================================
FILE: python/sglang/srt/layers/rotary_embedding.py
Functions: 35
============================================================

MODULE FUNCTIONS:
----------------------------------------
  L 646: def yarn_get_mscale(scale: float, mscale: float)
         â†’ float

  L1654: def get_rope(head_size: int,
        rotary_dim: int,
        max_position: int,
        base: int,
        is_neox_style: bool,
        rope_scaling: Optional[Dict[str,
        Any]],
        dtype: Optional[torch.dtype],
        partial_rotary_factor: float,
        dual_chunk_attention_config: Optional[Dict[str,
        Any]])
         â†’ RotaryEmbedding

  L1872: def rotate_half(x)
         ðŸ“ Rotates half the hidden dims of the input.

  L1879: def apply_rotary_pos_emb_native(q: torch.Tensor,
        k: torch.Tensor,
        cos: torch.Tensor,
        sin: torch.Tensor,
        unsqueeze_dim)
         â†’ Tuple[torch.Tensor, torch.Tensor]

  L1902: def apply_rotary_pos_emb_npu(q: torch.Tensor,
        k: torch.Tensor,
        cos: torch.Tensor,
        sin: torch.Tensor,
        unsqueeze_dim)
         â†’ Tuple[torch.Tensor, torch.Tensor]

  L1929: def get_rope_cpu(head_size: int,
        rotary_dim: int,
        max_position: int,
        base: int,
        is_neox_style: bool,
        rope_scaling: Optional[Dict[str,
        Any]],
        dtype: Optional[torch.dtype],
        partial_rotary_factor: float,
        device: Optional[str])
         â†’ RotaryEmbedding

  L2001: def get_rope_wrapper(head_size: int,
        rotary_dim: int,
        max_position: int,
        base: int,
        is_neox_style: bool,
        rope_scaling: Optional[Dict[str,
        Any]],
        dtype: Optional[torch.dtype],
        partial_rotary_factor: float,
        device: Optional[str])


CLASS: DeepseekScalingRotaryEmbedding
----------------------------------------
  L 658: __init__(self, head_size: int, rotary_dim: int, max_position_embeddings: int, base: int, is_neox_style: bool, scaling_factor: float, dtype: torch.dtype)
         â†’ None

  L 737: forward_native(self, positions: torch.Tensor, query: torch.Tensor, key: torch.Tensor, offsets: Optional[torch.Tensor])
         â†’ Tuple[torch.Tensor, torch.Tensor]
         ðŸ“ PyTorch-native implementation equivalent to forward().

  L 778: forward_npu(self, positions: torch.Tensor, query: torch.Tensor, key: torch.Tensor, offsets: Optional[torch.Tensor])
         â†’ Tuple[torch.Tensor, torch.Tensor]

  L 818: forward_cpu(self, positions: torch.Tensor, query: torch.Tensor, key: torch.Tensor, offsets: Optional[torch.Tensor])
         â†’ Tuple[torch.Tensor, torch.Tensor]


CLASS: DualChunkRotaryEmbedding
----------------------------------------
  L1458: __init__(self, head_size: int, rotary_dim: int, max_position_embeddings: int, base: int, is_neox_style: bool, dtype: torch.dtype, chunk_size: int, local_size: int)
         â†’ None

  L1560: forward(self, positions: torch.Tensor, query: torch.Tensor, key: torch.Tensor, offsets: Optional[torch.Tensor])
         â†’ Tuple[torch.Tensor, torch.Tensor]

  L1643: extra_repr(self)
         â†’ str


CLASS: DynamicNTKAlphaRotaryEmbedding
----------------------------------------
  L 950: __init__(self, head_size: int, rotary_dim: int, max_position_embeddings: int, base: int, is_neox_style: bool, scaling_alpha: float, dtype: torch.dtype)
         â†’ None


CLASS: DynamicNTKScalingRotaryEmbedding
----------------------------------------
  L 357: __init__(self, head_size: int, rotary_dim: int, max_position_embeddings: int, base: int, is_neox_style: bool, scaling_factor: float, dtype: torch.dtype)
         â†’ None


CLASS: LinearScalingRotaryEmbedding
----------------------------------------
  L 293: __init__(self, head_size: int, rotary_dim: int, max_position_embeddings: int, base: int, is_neox_style: bool, scaling_factors: Union[List[float], float], dtype: torch.dtype)
         â†’ None

  L 347: scaling_factor_to_offset(self)
         â†’ Dict[float, int]


CLASS: Llama3RotaryEmbedding
----------------------------------------
  L 836: __init__(self, head_size: int, rotary_dim: int, max_position_embeddings: int, base: int, is_neox_style: bool, dtype: torch.dtype, scaling_factor: float, low_freq_factor: float, high_freq_factor: float, orig_max_position: int)
         â†’ None


CLASS: Llama4VisionRotaryEmbedding
----------------------------------------
  L 883: __init__(self, head_size: int, rotary_dim: int, max_position_embeddings: int, base: int, is_neox_style: bool, dtype: torch.dtype)

  L 926: forward(self, query: torch.Tensor, key: torch.Tensor)
         â†’ Tuple[torch.Tensor, torch.Tensor]


CLASS: MRotaryEmbedding
----------------------------------------
  L 984: __init__(self, head_size: int, rotary_dim: int, max_position_embeddings: int, base: int, is_neox_style: bool, dtype: torch.dtype, mrope_section: Optional[List[int]])
         â†’ None

  L1033: forward(self, positions: torch.Tensor, query: torch.Tensor, key: torch.Tensor)
         â†’ Tuple[torch.Tensor, torch.Tensor]
         ðŸ“ PyTorch-native implementation equivalent to forward().
            Args:
            positions:
            [num_tokens,] (text only) or
            [3, num_tokens] (T/H/W positions with multimodal inputs)
            query: [num_tokens, num_heads * head_size]
            key: [num_tokens, num_kv_heads * head_size]

  L1082: get_rope_index(spatial_merge_size: int, image_token_id: int, video_token_id: int, vision_start_token_id: int, model_type: str, tokens_per_second: Optional[int], input_ids: Optional[torch.LongTensor], image_grid_thw: Optional[torch.LongTensor], video_grid_thw: Optional[torch.LongTensor], second_per_grid_ts: Optional[torch.Tensor])
         â†’ Tuple[torch.Tensor, torch.Tensor]

  L1240: get_rope_index_glm4v(input_ids: torch.Tensor, hf_config: Any, image_grid_thw: Union[list[list[int]], torch.Tensor], video_grid_thw: Union[list[list[int]], torch.Tensor], attention_mask: torch.Tensor)
         â†’ tuple[torch.Tensor, torch.Tensor]
         ðŸ“ Get mrope input positions and delta value for GLM4V.

  L1437: get_next_input_positions(mrope_position_delta: int, context_len: int, seq_len: int)
         â†’ torch.Tensor


CLASS: Phi3LongRoPEScaledRotaryEmbedding
----------------------------------------
  L 513: __init__(self, head_size: int, rotary_dim: int, max_position_embeddings: int, original_max_position_embeddings: int, base: int, is_neox_style: bool, dtype: torch.dtype, short_factor: List[float], long_factor: List[float], short_mscale: Optional[float], long_mscale: Optional[float])

  L 604: forward(self, positions: torch.Tensor, query: torch.Tensor, key: torch.Tensor, offsets: Optional[torch.Tensor])
         â†’ Tuple[torch.Tensor, torch.Tensor]


CLASS: RotaryEmbedding
----------------------------------------
  L  82: __init__(self, head_size: int, rotary_dim: int, max_position_embeddings: int, base: int, is_neox_style: bool, dtype: torch.dtype)
         â†’ None

  L 139: forward_native(self, positions: torch.Tensor, query: torch.Tensor, key: torch.Tensor, offsets: Optional[torch.Tensor])
         â†’ Tuple[torch.Tensor, torch.Tensor]
         ðŸ“ A PyTorch-native implementation of forward().

  L 169: forward_npu(self, positions: torch.Tensor, query: torch.Tensor, key: torch.Tensor, offsets: Optional[torch.Tensor])
         â†’ Tuple[torch.Tensor, torch.Tensor]
         ðŸ“ A PyTorch-npu implementation of forward().

  L 199: forward_cpu(self, positions: torch.Tensor, query: torch.Tensor, key: torch.Tensor, offsets: Optional[torch.Tensor])
         â†’ Tuple[torch.Tensor, torch.Tensor]

  L 219: forward_cuda(self, positions: torch.Tensor, query: torch.Tensor, key: torch.Tensor, offsets: Optional[torch.Tensor], fused_set_kv_buffer_arg)
         â†’ Tuple[torch.Tensor, torch.Tensor]

  L 257: extra_repr(self)
         â†’ str


CLASS: YaRNScalingRotaryEmbedding
----------------------------------------
  L 444: __init__(self, head_size: int, rotary_dim: int, max_position_embeddings: int, base: int, is_neox_style: bool, scaling_factor: float, dtype: torch.dtype)
         â†’ None


============================================================
FILE: python/sglang/srt/layers/sampler.py
Functions: 8
============================================================

MODULE FUNCTIONS:
----------------------------------------
  L 168: def top_k_top_p_min_p_sampling_from_probs_torch(probs: torch.Tensor,
        top_ks: torch.Tensor,
        top_ps: torch.Tensor,
        min_ps: torch.Tensor,
        need_min_p_sampling: bool)
         ðŸ“ A top-k, top-p and min-p sampling implementation with native pytorch operations.

  L 195: def sampling_from_probs_torch(probs: torch.Tensor)
         ðŸ“ A sampling implementation with native pytorch operations, without
            top-k, top-p, or min-p filtering.

  L 203: def top_p_normalize_probs_torch(probs: torch.Tensor, top_ps: torch.Tensor)

  L 215: def get_top_logprobs(logprobs: torch.Tensor, top_logprobs_nums: List[int])

  L 236: def get_token_ids_logprobs(logprobs: torch.Tensor,
        token_ids_logprobs: List[List[int]])

  L 256: def apply_custom_logit_processor(logits: torch.Tensor,
        sampling_batch_info: SamplingBatchInfo,
        num_tokens_in_batch: int)
         ðŸ“ Apply custom logit processors to the logits.
            This function will modify the logits in-place.
            num_tokens_in_batch is needed to support spec decoding, where each batch can contain multiple
            tokens. By default, we assume each batch contains only 1 token.


CLASS: Sampler
----------------------------------------
  L  34: __init__(self)

  L  42: forward(self, logits_output: LogitsProcessorOutput, sampling_info: SamplingBatchInfo, return_logprob: bool, top_logprobs_nums: List[int], token_ids_logprobs: List[List[int]])
         ðŸ“ Run a sampler & compute logprobs and update logits_output accordingly.
            Args:
            logits_output: The logits from the model forward
            sampling_info: Metadata for sampling
            return_logprob: If set, store the output logprob information to
            logits_output
            top_logprobs_nums: Number of top lobprobs per sequence in a batch
            batch_next_token_ids: next token IDs. If set, skip sampling and only
            compute output logprobs It is used for speculative decoding which
            performs sampling in draft workers.


============================================================
FILE: python/sglang/srt/layers/torchao_utils.py
Functions: 4
============================================================

MODULE FUNCTIONS:
----------------------------------------
  L  15: def get_gemlite_cache_path()
         â†’ str

  L  19: def save_gemlite_cache(print_error: bool)
         â†’ bool

  L  31: def proj_filter(module: torch.nn.Module, fqn: str)
         ðŸ“ Filter function for quantizing projection layers.

  L  39: def apply_torchao_config_to_model(model: torch.nn.Module,
        torchao_config: str,
        filter_fn: Optional[Callable])
         ðŸ“ Quantize a modelwith torchao quantization specified by torchao_config
            Args:
            `model`: a model to be quantized based on torchao_config
            `torchao_config` (str): type of quantization and their arguments we want to use to
            quantize the model, e.g. int4wo-128 means int4 weight only quantization with group_size
            128


============================================================
FILE: python/sglang/srt/layers/utils.py
Functions: 3
============================================================

MODULE FUNCTIONS:
----------------------------------------
  L  10: def get_layer_id(weight_name)


CLASS: PPMissingLayer
----------------------------------------
  L  25: __init__(self)

  L  29: forward(self)
         ðŸ“ Return the first arg from args or the first value from kwargs.
            Wraps the input in a tuple if `self.return_tuple` is True.


============================================================
FILE: python/sglang/srt/layers/vocab_parallel_embedding.py
Functions: 20
============================================================

MODULE FUNCTIONS:
----------------------------------------
  L  44: def pad_vocab_size(vocab_size: int, pad_to: int)
         â†’ int
         ðŸ“ Pad the vocab size to the given value.

  L  49: def vocab_range_from_per_partition_vocab_size(per_partition_vocab_size: int,
        rank: int,
        offset: int)
         â†’ Sequence[int]

  L  57: def vocab_range_from_global_vocab_size(global_vocab_size: int,
        rank: int,
        world_size: int,
        offset: int)
         â†’ Sequence[int]

  L 126: def get_masked_input_and_mask(input_: torch.Tensor,
        org_vocab_start_index: int,
        org_vocab_end_index: int,
        num_org_vocab_padding: int,
        added_vocab_start_index: int,
        added_vocab_end_index: int)
         â†’ Tuple[torch.Tensor, torch.Tensor]
         @torch.compile(dynamic=True, backend=get_compiler_backend())


CLASS: ParallelLMHead
----------------------------------------
  L 514: __init__(self, num_embeddings: int, embedding_dim: int)

  L 560: tie_weights(self, embed_tokens: VocabParallelEmbedding)
         ðŸ“ Tie the weights with word embeddings.

  L 569: forward(self, input_)


CLASS: VocabParallelEmbedding
----------------------------------------
  L 192: __init__(self, num_embeddings: int, embedding_dim: int)

  L 346: get_sharded_to_full_mapping(self)
         â†’ Optional[List[int]]
         ðŸ“ Get a mapping that can be used to reindex the gathered
            logits for sampling.
            During sampling, we gather logits from all ranks. The relationship
            of index->token_id will follow the same format as outlined in the class
            docstring. However, after the gather, we want to reindex the final
            logits tensor to map index->token_id one-to-one (the index is always
            equal the token_id it corresponds to). The indices returned by this
            method allow us to do that.

  L 411: weight_loader(self, param: Parameter, loaded_weight: torch.Tensor)

  L 462: forward(self, input_)

  L 488: extra_repr(self)
         â†’ str


CLASS: VocabParallelEmbeddingShardIndices
----------------------------------------
  L  81: num_org_elements(self)
         â†’ int

  L  85: num_added_elements(self)
         â†’ int

  L  89: num_org_elements_padded(self)
         â†’ int

  L  93: num_added_elements_padded(self)
         â†’ int

  L  97: num_org_vocab_padding(self)
         â†’ int

  L 101: num_added_vocab_padding(self)
         â†’ int

  L 105: num_elements_padded(self)
         â†’ int

  L 108: __post_init__(self)
