================================================================================
FUNCTION INDEX: hf3fs module
================================================================================
Total Functions: 70
Documented: 29


============================================================
FILE: python/sglang/srt/mem_cache/storage/hf3fs/client_hf3fs.py
Functions: 9
============================================================

MODULE FUNCTIONS:
----------------------------------------
  L  30: def rsynchronized()

  L  42: def wsynchronized()


CLASS: Hf3fsClient
----------------------------------------
  L  55: __init__(self, path: str, size: int, bytes_per_page: int, entries: int)

  L 106: batch_read(self, offsets: List[int], tensors: List[torch.Tensor])
         → List[int]

  L 129: batch_write(self, offsets: List[int], tensors: List[torch.Tensor])
         → List[int]

  L 151: check(self, offsets: List[int], tensors: List[torch.Tensor])
         → None

  L 169: get_size(self)
         → int

  L 172: close(self)
         → None

  L 182: flush(self)
         → None


============================================================
FILE: python/sglang/srt/mem_cache/storage/hf3fs/mini_3fs_metadata_server.py
Functions: 39
============================================================

MODULE FUNCTIONS:
----------------------------------------
  L 405: def run_metadata_server(host: str,
        port: int,
        persistence_path: Optional[str],
        save_interval: int)
         📝 Run the HF3FS metadata server.


CLASS: GlobalMetadataState
----------------------------------------
  L 103: __init__(self, persistence_path: Optional[str], save_interval: int)

  L 111: load_from_disk(self)

  L 139: save_to_disk(self)

  L 163: schedule_save(self)

  L 170: shutdown(self)


CLASS: Hf3fsGlobalMetadataClient
----------------------------------------
  L 302: __init__(self, base_url: str, max_retries: int)

  L 324: initialize(self, rank: int, num_pages: int)
         → None

  L 327: reserve_and_allocate_page_indices(self, rank: int, keys: List[Tuple[str, str]])
         → List[Tuple[bool, int]]

  L 335: confirm_write(self, rank: int, written_keys_to_confirm: List[Tuple[str, int]], pages_to_release: List[int])
         → None

  L 349: delete_keys(self, rank: int, keys: List[str])
         → None

  L 352: exists(self, rank: int, keys: List[str])
         → List[bool]

  L 356: clear(self, rank: int)
         → None

  L 359: get_page_indices(self, rank: int, keys: List[str])
         → List[Optional[int]]


CLASS: Hf3fsLocalMetadataClient
----------------------------------------
  L 367: __init__(self)

  L 370: initialize(self, rank: int, num_pages: int)
         → None

  L 373: reserve_and_allocate_page_indices(self, rank: int, keys: List[Tuple[str, str]])
         → List[Tuple[bool, int]]
         📝 Reserve and allocate page indices for keys.

  L 379: confirm_write(self, rank: int, written_keys_to_confirm: List[Tuple[str, int]], pages_to_release: List[int])
         → None
         📝 Confirm write operations.

  L 388: delete_keys(self, rank: int, keys: List[str])
         → None
         📝 Delete keys.

  L 392: exists(self, rank: int, keys: List[str])
         → List[bool]
         📝 Check if keys exist.

  L 396: clear(self, rank: int)
         → None
         📝 Clear all metadata for rank.

  L 400: get_page_indices(self, rank: int, keys: List[str])
         → List[Optional[int]]
         📝 Get page indices for keys.


CLASS: Hf3fsMetadataServer
----------------------------------------
  L 183: __init__(self, persistence_path: Optional[str], save_interval: int)

  L 200: get_rank_metadata(self, rank: int)
         → RankMetadata
         📝 Get rank metadata with proper error handling.

  L 210: initialize(self, rank: int, request: Request)
         📝 Initialize a rank with specified number of pages.

  L 228: exists(self, rank: int, request: Request)
         📝 Check if keys exist in metadata.

  L 236: reserve_and_allocate_page_indices(self, rank: int, request: Request)
         📝 Reserve and allocate page indices for keys.

  L 244: confirm_write(self, rank: int, request: Request)
         📝 Confirm write operations and release pages.

  L 257: delete_keys(self, rank: int, request: Request)
         📝 Delete keys from metadata.

  L 264: clear(self, rank: int)
         📝 Clear all metadata for a rank.

  L 270: get_page_indices(self, rank: int, request: Request)
         📝 Get page indices for keys.

  L 278: run(self, host: str, port: int)
         📝 Run the metadata server.


CLASS: RankMetadata
----------------------------------------
  L  26: __init__(self, num_pages: int)

  L  33: exists_keys(self, keys: List[str])
         → List[bool]
         📝 Check if keys exist in metadata.

  L  38: reserve_and_allocate_page_indices(self, keys: List[Tuple[str, str]])
         → List[Tuple[bool, int]]
         📝 Reserve and allocate page indices for keys.

  L  62: confirm_write(self, written_keys_to_confirm: List[Tuple[str, int]], pages_to_release: List[int])
         → None
         📝 Confirm write operations and release pages.

  L  76: delete_keys(self, keys: List[str])
         → int
         📝 Delete keys and return count of deleted keys.

  L  88: clear_all(self)
         → None
         📝 Clear all metadata.

  L  94: get_page_indices(self, keys: List[str])
         → List[Optional[int]]
         📝 Get page indices for keys.


============================================================
FILE: python/sglang/srt/mem_cache/storage/hf3fs/storage_hf3fs.py
Functions: 21
============================================================

MODULE FUNCTIONS:
----------------------------------------
  L 103: def synchronized()


CLASS: AtomicCounter
----------------------------------------
  L  90: __init__(self, n: int)

  L  96: next(self)
         → int


CLASS: Hf3fsMetadataInterface
----------------------------------------
  L  24: initialize(self, rank: int, num_pages: int)
         → None
         📝 Initialize the metadata service with specified number of pages.

  L  29: reserve_and_allocate_page_indices(self, rank: int, keys: List[Tuple[str, str]])
         → List[Tuple[bool, int]]
         📝 Reserve and allocate page indices for the specified keys.
            Args:
            rank: The rank of the process.
            keys: The keys to reserve and allocate page indices for. Each tuple contains a key and the key of its prefix block.
            Returns:
            List[Tuple[bool, int]]: A list of tuples, where each tuple contains a boolean indicating whether the key has existed and an integer indicating the allocated page index.

  L  45: confirm_write(self, rank: int, written_keys_to_confirm: List[Tuple[str, int]], pages_to_release: List[int])
         → None
         📝 Confirm that key-value pairs have been successfully written to storage.
            Args:
            rank: The rank of the process.
            written_keys_to_confirm: A list of tuples, where each tuple contains a key and its corresponding page index.
            pages_to_release: A list of page indices to be released.

  L  61: get_page_indices(self, rank: int, keys: List[str])
         → List[Optional[int]]
         📝 Get page indices for the specified keys.
            Args:
            rank: The rank of the process.
            keys: A list of keys.
            Returns:
            List[Optional[int]]: A list of integers representing the page indices for the specified keys.
            If a key is not found, the corresponding index will be None.

  L  74: delete_keys(self, rank: int, keys: List[str])
         → None
         📝 Delete specified keys and their associated pages.

  L  79: exists(self, rank: int, keys: List[str])
         → List[bool]
         📝 Check if the specified keys exist.

  L  84: clear(self, rank: int)
         → None
         📝 Clear all key-value pairs and page allocations for the specified rank.


CLASS: HiCacheHF3FS
----------------------------------------
  L 118: __init__(self, rank: int, file_path: str, file_size: int, numjobs: int, bytes_per_page: int, entries: int, dtype: torch.dtype, metadata_client: Hf3fsMetadataInterface, is_mla_model: bool)

  L 174: from_env_config(bytes_per_page: int, dtype: torch.dtype, storage_config: HiCacheStorageConfig)
         → 'HiCacheHF3FS'

  L 245: get(self, key: str, target_location: Optional[Any], target_sizes: Optional[Any])
         → torch.Tensor | None

  L 258: batch_get(self, keys: List[str], target_locations: Optional[Any], target_sizes: Optional[Any])
         → List[torch.Tensor | None]

  L 305: set(self, key: str, value: Optional[Any], target_location: Optional[Any], target_sizes: Optional[Any])
         → bool

  L 319: batch_set(self, keys: List[str], values: Optional[Any], target_locations: Optional[Any], target_sizes: Optional[Any])
         → bool

  L 381: delete(self, key: str)
         → None

  L 384: exists(self, key: str)
         → bool

  L 388: batch_exists(self, keys: List[str])
         → int

  L 396: clear(self)
         → bool

  L 405: close(self)
         → None


============================================================
FILE: python/sglang/srt/mem_cache/storage/hf3fs/test_hf3fs_utils.py
Functions: 1
============================================================

MODULE FUNCTIONS:
----------------------------------------
  L  15: def test_rw_shm()
