================================================================================
FUNCTION INDEX: compressed_tensors module
================================================================================
Total Functions: 32
Documented: 8


============================================================
FILE: python/sglang/srt/layers/quantization/compressed_tensors/compressed_tensors.py
Functions: 18
============================================================


CLASS: CompressedTensorsConfig
----------------------------------------
  L  79: __init__(self, target_scheme_map: Dict[str, Any], ignore: List[str], quant_format: str, sparsity_scheme_map: Dict[str, SparsityCompressionConfig], sparsity_ignore_list: List[str], kv_cache_scheme: Optional[Dict[str, Any]], config: Optional[Dict[str, Any]], packed_modules_mapping: Dict[str, List[str]])

  L 101: get_linear_method(self)
         ‚Üí CompressedTensorsLinearMethod

  L 104: get_supported_act_dtypes(cls)
         ‚Üí List[torch.dtype]

  L 108: get_min_capability(cls)
         ‚Üí int

  L 111: get_name(self)
         ‚Üí str

  L 114: get_scaled_act_names(self)
         ‚Üí List[str]

  L 117: get_quant_method(self, layer: torch.nn.Module, prefix: str)
         ‚Üí Optional[QuantizeMethodBase]

  L 143: from_config(cls, config: Dict[str, Any])
         ‚Üí CompressedTensorsConfig

  L 234: get_config_filenames(cls)
         ‚Üí List[str]

  L 438: get_scheme(self, layer: torch.nn.Module, layer_name: Optional[str])
         ‚Üí Optional[CompressedTensorsScheme]
         üìù compressed-tensors supports non uniform in the following way:

  L 533: get_cache_scale(self, name: str)
         ‚Üí Optional[str]
         üìù Check whether the param name matches the format for k/v cache scales

  L 550: supports_cutlass_24(weight_quant: Optional[QuantizationArgs], input_quant: Optional[QuantizationArgs], sparsity_scheme: Optional[SparsityCompressionConfig])
         ‚Üí bool
         üìù Check if the layer is supported by the Cutlass 2:4 Kernel


CLASS: CompressedTensorsLinearMethod
----------------------------------------
  L 618: __init__(self, quantization_config: CompressedTensorsConfig)

  L 621: process_weights_after_loading(self, layer: torch.nn.Module)
         ‚Üí None

  L 624: create_weights(self, layer: torch.nn.Module, input_size_per_partition: int, output_partition_sizes: List[int], input_size: int, output_size: int, params_dtype: torch.dtype)
         üìù Use the CompressedTensorsScheme associated with each layer to create

  L 650: apply(self, layer: torch.nn.Module, x: torch.Tensor, bias: Optional[torch.Tensor])
         üìù Use the output of create_weights and the CompressedTensorsScheme


CLASS: DeviceCapability
----------------------------------------
  L  64: as_version_str(self)
         ‚Üí str

  L  67: to_int(self)
         ‚Üí int
         üìù Express device capability as an integer ``<major><minor>``.


============================================================
FILE: python/sglang/srt/layers/quantization/compressed_tensors/compressed_tensors_moe.py
Functions: 10
============================================================


CLASS: CompressedTensorsMoEMethod
----------------------------------------
  L  70: __new__(cls)

  L  76: get_moe_method(quant_config: CompressedTensorsConfig)
         ‚Üí 'CompressedTensorsMoEMethod'


CLASS: CompressedTensorsW8A8Fp8MoEMethod
----------------------------------------
  L 100: __init__(self, quant_config: CompressedTensorsConfig)

  L 109: create_weights(self, layer: torch.nn.Module, num_experts: int, hidden_size: int, intermediate_size_per_partition: int, params_dtype: torch.dtype)

  L 207: process_weights_after_loading(self, layer: FusedMoE)
         ‚Üí None

  L 296: apply(self, layer: torch.nn.Module, x: torch.Tensor, topk_output: TopKOutput, moe_runner_config: MoeRunnerConfig)
         ‚Üí torch.Tensor


CLASS: CompressedTensorsWNA16MoEMethod
----------------------------------------
  L 346: __init__(self, quant_config: CompressedTensorsConfig)

  L 369: create_weights(self, layer: torch.nn.Module, num_experts: int, hidden_size: int, intermediate_size_per_partition: int, params_dtype: torch.dtype)

  L 513: process_weights_after_loading(self, layer: torch.nn.Module)
         ‚Üí None

  L 643: apply(self, layer: torch.nn.Module, x: torch.Tensor, topk_output: TopKOutput, moe_runner_config: MoeRunnerConfig)
         ‚Üí torch.Tensor


============================================================
FILE: python/sglang/srt/layers/quantization/compressed_tensors/utils.py
Functions: 4
============================================================

MODULE FUNCTIONS:
----------------------------------------
  L  12: def is_activation_quantization_format(format: str)
         ‚Üí bool

  L  21: def should_ignore_layer(layer_name: Optional[str],
        ignore: Iterable[str],
        fused_mapping: Mapping[str,
        List[str]])
         ‚Üí bool

  L  76: def check_equal_or_regex_match(layer_name: str, targets: Iterable[str])
         ‚Üí bool
         üìù Checks whether a layer_name is exactly equal or a regex match for

  L  87: def find_matched_target(layer_name: Optional[str],
        module: Module,
        targets: Iterable[str],
        fused_mapping: Mapping[str,
        List[str]])
         ‚Üí str
         üìù Helper function to look up which "target" in the compressed-tensors
