window.pdocSearch = (function(){
/** elasticlunr - http://weixsong.github.io * Copyright (C) 2017 Oliver Nightingale * Copyright (C) 2017 Wei Song * MIT Licensed */!function(){function e(e){if(null===e||"object"!=typeof e)return e;var t=e.constructor();for(var n in e)e.hasOwnProperty(n)&&(t[n]=e[n]);return t}var t=function(e){var n=new t.Index;return n.pipeline.add(t.trimmer,t.stopWordFilter,t.stemmer),e&&e.call(n,n),n};t.version="0.9.5",lunr=t,t.utils={},t.utils.warn=function(e){return function(t){e.console&&console.warn&&console.warn(t)}}(this),t.utils.toString=function(e){return void 0===e||null===e?"":e.toString()},t.EventEmitter=function(){this.events={}},t.EventEmitter.prototype.addListener=function(){var e=Array.prototype.slice.call(arguments),t=e.pop(),n=e;if("function"!=typeof t)throw new TypeError("last argument must be a function");n.forEach(function(e){this.hasHandler(e)||(this.events[e]=[]),this.events[e].push(t)},this)},t.EventEmitter.prototype.removeListener=function(e,t){if(this.hasHandler(e)){var n=this.events[e].indexOf(t);-1!==n&&(this.events[e].splice(n,1),0==this.events[e].length&&delete this.events[e])}},t.EventEmitter.prototype.emit=function(e){if(this.hasHandler(e)){var t=Array.prototype.slice.call(arguments,1);this.events[e].forEach(function(e){e.apply(void 0,t)},this)}},t.EventEmitter.prototype.hasHandler=function(e){return e in this.events},t.tokenizer=function(e){if(!arguments.length||null===e||void 0===e)return[];if(Array.isArray(e)){var n=e.filter(function(e){return null===e||void 0===e?!1:!0});n=n.map(function(e){return t.utils.toString(e).toLowerCase()});var i=[];return n.forEach(function(e){var n=e.split(t.tokenizer.seperator);i=i.concat(n)},this),i}return e.toString().trim().toLowerCase().split(t.tokenizer.seperator)},t.tokenizer.defaultSeperator=/[\s\-]+/,t.tokenizer.seperator=t.tokenizer.defaultSeperator,t.tokenizer.setSeperator=function(e){null!==e&&void 0!==e&&"object"==typeof e&&(t.tokenizer.seperator=e)},t.tokenizer.resetSeperator=function(){t.tokenizer.seperator=t.tokenizer.defaultSeperator},t.tokenizer.getSeperator=function(){return t.tokenizer.seperator},t.Pipeline=function(){this._queue=[]},t.Pipeline.registeredFunctions={},t.Pipeline.registerFunction=function(e,n){n in t.Pipeline.registeredFunctions&&t.utils.warn("Overwriting existing registered function: "+n),e.label=n,t.Pipeline.registeredFunctions[n]=e},t.Pipeline.getRegisteredFunction=function(e){return e in t.Pipeline.registeredFunctions!=!0?null:t.Pipeline.registeredFunctions[e]},t.Pipeline.warnIfFunctionNotRegistered=function(e){var n=e.label&&e.label in this.registeredFunctions;n||t.utils.warn("Function is not registered with pipeline. This may cause problems when serialising the index.\n",e)},t.Pipeline.load=function(e){var n=new t.Pipeline;return e.forEach(function(e){var i=t.Pipeline.getRegisteredFunction(e);if(!i)throw new Error("Cannot load un-registered function: "+e);n.add(i)}),n},t.Pipeline.prototype.add=function(){var e=Array.prototype.slice.call(arguments);e.forEach(function(e){t.Pipeline.warnIfFunctionNotRegistered(e),this._queue.push(e)},this)},t.Pipeline.prototype.after=function(e,n){t.Pipeline.warnIfFunctionNotRegistered(n);var i=this._queue.indexOf(e);if(-1===i)throw new Error("Cannot find existingFn");this._queue.splice(i+1,0,n)},t.Pipeline.prototype.before=function(e,n){t.Pipeline.warnIfFunctionNotRegistered(n);var i=this._queue.indexOf(e);if(-1===i)throw new Error("Cannot find existingFn");this._queue.splice(i,0,n)},t.Pipeline.prototype.remove=function(e){var t=this._queue.indexOf(e);-1!==t&&this._queue.splice(t,1)},t.Pipeline.prototype.run=function(e){for(var t=[],n=e.length,i=this._queue.length,o=0;n>o;o++){for(var r=e[o],s=0;i>s&&(r=this._queue[s](r,o,e),void 0!==r&&null!==r);s++);void 0!==r&&null!==r&&t.push(r)}return t},t.Pipeline.prototype.reset=function(){this._queue=[]},t.Pipeline.prototype.get=function(){return this._queue},t.Pipeline.prototype.toJSON=function(){return this._queue.map(function(e){return t.Pipeline.warnIfFunctionNotRegistered(e),e.label})},t.Index=function(){this._fields=[],this._ref="id",this.pipeline=new t.Pipeline,this.documentStore=new t.DocumentStore,this.index={},this.eventEmitter=new t.EventEmitter,this._idfCache={},this.on("add","remove","update",function(){this._idfCache={}}.bind(this))},t.Index.prototype.on=function(){var e=Array.prototype.slice.call(arguments);return this.eventEmitter.addListener.apply(this.eventEmitter,e)},t.Index.prototype.off=function(e,t){return this.eventEmitter.removeListener(e,t)},t.Index.load=function(e){e.version!==t.version&&t.utils.warn("version mismatch: current "+t.version+" importing "+e.version);var n=new this;n._fields=e.fields,n._ref=e.ref,n.documentStore=t.DocumentStore.load(e.documentStore),n.pipeline=t.Pipeline.load(e.pipeline),n.index={};for(var i in e.index)n.index[i]=t.InvertedIndex.load(e.index[i]);return n},t.Index.prototype.addField=function(e){return this._fields.push(e),this.index[e]=new t.InvertedIndex,this},t.Index.prototype.setRef=function(e){return this._ref=e,this},t.Index.prototype.saveDocument=function(e){return this.documentStore=new t.DocumentStore(e),this},t.Index.prototype.addDoc=function(e,n){if(e){var n=void 0===n?!0:n,i=e[this._ref];this.documentStore.addDoc(i,e),this._fields.forEach(function(n){var o=this.pipeline.run(t.tokenizer(e[n]));this.documentStore.addFieldLength(i,n,o.length);var r={};o.forEach(function(e){e in r?r[e]+=1:r[e]=1},this);for(var s in r){var u=r[s];u=Math.sqrt(u),this.index[n].addToken(s,{ref:i,tf:u})}},this),n&&this.eventEmitter.emit("add",e,this)}},t.Index.prototype.removeDocByRef=function(e){if(e&&this.documentStore.isDocStored()!==!1&&this.documentStore.hasDoc(e)){var t=this.documentStore.getDoc(e);this.removeDoc(t,!1)}},t.Index.prototype.removeDoc=function(e,n){if(e){var n=void 0===n?!0:n,i=e[this._ref];this.documentStore.hasDoc(i)&&(this.documentStore.removeDoc(i),this._fields.forEach(function(n){var o=this.pipeline.run(t.tokenizer(e[n]));o.forEach(function(e){this.index[n].removeToken(e,i)},this)},this),n&&this.eventEmitter.emit("remove",e,this))}},t.Index.prototype.updateDoc=function(e,t){var t=void 0===t?!0:t;this.removeDocByRef(e[this._ref],!1),this.addDoc(e,!1),t&&this.eventEmitter.emit("update",e,this)},t.Index.prototype.idf=function(e,t){var n="@"+t+"/"+e;if(Object.prototype.hasOwnProperty.call(this._idfCache,n))return this._idfCache[n];var i=this.index[t].getDocFreq(e),o=1+Math.log(this.documentStore.length/(i+1));return this._idfCache[n]=o,o},t.Index.prototype.getFields=function(){return this._fields.slice()},t.Index.prototype.search=function(e,n){if(!e)return[];e="string"==typeof e?{any:e}:JSON.parse(JSON.stringify(e));var i=null;null!=n&&(i=JSON.stringify(n));for(var o=new t.Configuration(i,this.getFields()).get(),r={},s=Object.keys(e),u=0;u<s.length;u++){var a=s[u];r[a]=this.pipeline.run(t.tokenizer(e[a]))}var l={};for(var c in o){var d=r[c]||r.any;if(d){var f=this.fieldSearch(d,c,o),h=o[c].boost;for(var p in f)f[p]=f[p]*h;for(var p in f)p in l?l[p]+=f[p]:l[p]=f[p]}}var v,g=[];for(var p in l)v={ref:p,score:l[p]},this.documentStore.hasDoc(p)&&(v.doc=this.documentStore.getDoc(p)),g.push(v);return g.sort(function(e,t){return t.score-e.score}),g},t.Index.prototype.fieldSearch=function(e,t,n){var i=n[t].bool,o=n[t].expand,r=n[t].boost,s=null,u={};return 0!==r?(e.forEach(function(e){var n=[e];1==o&&(n=this.index[t].expandToken(e));var r={};n.forEach(function(n){var o=this.index[t].getDocs(n),a=this.idf(n,t);if(s&&"AND"==i){var l={};for(var c in s)c in o&&(l[c]=o[c]);o=l}n==e&&this.fieldSearchStats(u,n,o);for(var c in o){var d=this.index[t].getTermFrequency(n,c),f=this.documentStore.getFieldLength(c,t),h=1;0!=f&&(h=1/Math.sqrt(f));var p=1;n!=e&&(p=.15*(1-(n.length-e.length)/n.length));var v=d*a*h*p;c in r?r[c]+=v:r[c]=v}},this),s=this.mergeScores(s,r,i)},this),s=this.coordNorm(s,u,e.length)):void 0},t.Index.prototype.mergeScores=function(e,t,n){if(!e)return t;if("AND"==n){var i={};for(var o in t)o in e&&(i[o]=e[o]+t[o]);return i}for(var o in t)o in e?e[o]+=t[o]:e[o]=t[o];return e},t.Index.prototype.fieldSearchStats=function(e,t,n){for(var i in n)i in e?e[i].push(t):e[i]=[t]},t.Index.prototype.coordNorm=function(e,t,n){for(var i in e)if(i in t){var o=t[i].length;e[i]=e[i]*o/n}return e},t.Index.prototype.toJSON=function(){var e={};return this._fields.forEach(function(t){e[t]=this.index[t].toJSON()},this),{version:t.version,fields:this._fields,ref:this._ref,documentStore:this.documentStore.toJSON(),index:e,pipeline:this.pipeline.toJSON()}},t.Index.prototype.use=function(e){var t=Array.prototype.slice.call(arguments,1);t.unshift(this),e.apply(this,t)},t.DocumentStore=function(e){this._save=null===e||void 0===e?!0:e,this.docs={},this.docInfo={},this.length=0},t.DocumentStore.load=function(e){var t=new this;return t.length=e.length,t.docs=e.docs,t.docInfo=e.docInfo,t._save=e.save,t},t.DocumentStore.prototype.isDocStored=function(){return this._save},t.DocumentStore.prototype.addDoc=function(t,n){this.hasDoc(t)||this.length++,this.docs[t]=this._save===!0?e(n):null},t.DocumentStore.prototype.getDoc=function(e){return this.hasDoc(e)===!1?null:this.docs[e]},t.DocumentStore.prototype.hasDoc=function(e){return e in this.docs},t.DocumentStore.prototype.removeDoc=function(e){this.hasDoc(e)&&(delete this.docs[e],delete this.docInfo[e],this.length--)},t.DocumentStore.prototype.addFieldLength=function(e,t,n){null!==e&&void 0!==e&&0!=this.hasDoc(e)&&(this.docInfo[e]||(this.docInfo[e]={}),this.docInfo[e][t]=n)},t.DocumentStore.prototype.updateFieldLength=function(e,t,n){null!==e&&void 0!==e&&0!=this.hasDoc(e)&&this.addFieldLength(e,t,n)},t.DocumentStore.prototype.getFieldLength=function(e,t){return null===e||void 0===e?0:e in this.docs&&t in this.docInfo[e]?this.docInfo[e][t]:0},t.DocumentStore.prototype.toJSON=function(){return{docs:this.docs,docInfo:this.docInfo,length:this.length,save:this._save}},t.stemmer=function(){var e={ational:"ate",tional:"tion",enci:"ence",anci:"ance",izer:"ize",bli:"ble",alli:"al",entli:"ent",eli:"e",ousli:"ous",ization:"ize",ation:"ate",ator:"ate",alism:"al",iveness:"ive",fulness:"ful",ousness:"ous",aliti:"al",iviti:"ive",biliti:"ble",logi:"log"},t={icate:"ic",ative:"",alize:"al",iciti:"ic",ical:"ic",ful:"",ness:""},n="[^aeiou]",i="[aeiouy]",o=n+"[^aeiouy]*",r=i+"[aeiou]*",s="^("+o+")?"+r+o,u="^("+o+")?"+r+o+"("+r+")?$",a="^("+o+")?"+r+o+r+o,l="^("+o+")?"+i,c=new RegExp(s),d=new RegExp(a),f=new RegExp(u),h=new RegExp(l),p=/^(.+?)(ss|i)es$/,v=/^(.+?)([^s])s$/,g=/^(.+?)eed$/,m=/^(.+?)(ed|ing)$/,y=/.$/,S=/(at|bl|iz)$/,x=new RegExp("([^aeiouylsz])\\1$"),w=new RegExp("^"+o+i+"[^aeiouwxy]$"),I=/^(.+?[^aeiou])y$/,b=/^(.+?)(ational|tional|enci|anci|izer|bli|alli|entli|eli|ousli|ization|ation|ator|alism|iveness|fulness|ousness|aliti|iviti|biliti|logi)$/,E=/^(.+?)(icate|ative|alize|iciti|ical|ful|ness)$/,D=/^(.+?)(al|ance|ence|er|ic|able|ible|ant|ement|ment|ent|ou|ism|ate|iti|ous|ive|ize)$/,F=/^(.+?)(s|t)(ion)$/,_=/^(.+?)e$/,P=/ll$/,k=new RegExp("^"+o+i+"[^aeiouwxy]$"),z=function(n){var i,o,r,s,u,a,l;if(n.length<3)return n;if(r=n.substr(0,1),"y"==r&&(n=r.toUpperCase()+n.substr(1)),s=p,u=v,s.test(n)?n=n.replace(s,"$1$2"):u.test(n)&&(n=n.replace(u,"$1$2")),s=g,u=m,s.test(n)){var z=s.exec(n);s=c,s.test(z[1])&&(s=y,n=n.replace(s,""))}else if(u.test(n)){var z=u.exec(n);i=z[1],u=h,u.test(i)&&(n=i,u=S,a=x,l=w,u.test(n)?n+="e":a.test(n)?(s=y,n=n.replace(s,"")):l.test(n)&&(n+="e"))}if(s=I,s.test(n)){var z=s.exec(n);i=z[1],n=i+"i"}if(s=b,s.test(n)){var z=s.exec(n);i=z[1],o=z[2],s=c,s.test(i)&&(n=i+e[o])}if(s=E,s.test(n)){var z=s.exec(n);i=z[1],o=z[2],s=c,s.test(i)&&(n=i+t[o])}if(s=D,u=F,s.test(n)){var z=s.exec(n);i=z[1],s=d,s.test(i)&&(n=i)}else if(u.test(n)){var z=u.exec(n);i=z[1]+z[2],u=d,u.test(i)&&(n=i)}if(s=_,s.test(n)){var z=s.exec(n);i=z[1],s=d,u=f,a=k,(s.test(i)||u.test(i)&&!a.test(i))&&(n=i)}return s=P,u=d,s.test(n)&&u.test(n)&&(s=y,n=n.replace(s,"")),"y"==r&&(n=r.toLowerCase()+n.substr(1)),n};return z}(),t.Pipeline.registerFunction(t.stemmer,"stemmer"),t.stopWordFilter=function(e){return e&&t.stopWordFilter.stopWords[e]!==!0?e:void 0},t.clearStopWords=function(){t.stopWordFilter.stopWords={}},t.addStopWords=function(e){null!=e&&Array.isArray(e)!==!1&&e.forEach(function(e){t.stopWordFilter.stopWords[e]=!0},this)},t.resetStopWords=function(){t.stopWordFilter.stopWords=t.defaultStopWords},t.defaultStopWords={"":!0,a:!0,able:!0,about:!0,across:!0,after:!0,all:!0,almost:!0,also:!0,am:!0,among:!0,an:!0,and:!0,any:!0,are:!0,as:!0,at:!0,be:!0,because:!0,been:!0,but:!0,by:!0,can:!0,cannot:!0,could:!0,dear:!0,did:!0,"do":!0,does:!0,either:!0,"else":!0,ever:!0,every:!0,"for":!0,from:!0,get:!0,got:!0,had:!0,has:!0,have:!0,he:!0,her:!0,hers:!0,him:!0,his:!0,how:!0,however:!0,i:!0,"if":!0,"in":!0,into:!0,is:!0,it:!0,its:!0,just:!0,least:!0,let:!0,like:!0,likely:!0,may:!0,me:!0,might:!0,most:!0,must:!0,my:!0,neither:!0,no:!0,nor:!0,not:!0,of:!0,off:!0,often:!0,on:!0,only:!0,or:!0,other:!0,our:!0,own:!0,rather:!0,said:!0,say:!0,says:!0,she:!0,should:!0,since:!0,so:!0,some:!0,than:!0,that:!0,the:!0,their:!0,them:!0,then:!0,there:!0,these:!0,they:!0,"this":!0,tis:!0,to:!0,too:!0,twas:!0,us:!0,wants:!0,was:!0,we:!0,were:!0,what:!0,when:!0,where:!0,which:!0,"while":!0,who:!0,whom:!0,why:!0,will:!0,"with":!0,would:!0,yet:!0,you:!0,your:!0},t.stopWordFilter.stopWords=t.defaultStopWords,t.Pipeline.registerFunction(t.stopWordFilter,"stopWordFilter"),t.trimmer=function(e){if(null===e||void 0===e)throw new Error("token should not be undefined");return e.replace(/^\W+/,"").replace(/\W+$/,"")},t.Pipeline.registerFunction(t.trimmer,"trimmer"),t.InvertedIndex=function(){this.root={docs:{},df:0}},t.InvertedIndex.load=function(e){var t=new this;return t.root=e.root,t},t.InvertedIndex.prototype.addToken=function(e,t,n){for(var n=n||this.root,i=0;i<=e.length-1;){var o=e[i];o in n||(n[o]={docs:{},df:0}),i+=1,n=n[o]}var r=t.ref;n.docs[r]?n.docs[r]={tf:t.tf}:(n.docs[r]={tf:t.tf},n.df+=1)},t.InvertedIndex.prototype.hasToken=function(e){if(!e)return!1;for(var t=this.root,n=0;n<e.length;n++){if(!t[e[n]])return!1;t=t[e[n]]}return!0},t.InvertedIndex.prototype.getNode=function(e){if(!e)return null;for(var t=this.root,n=0;n<e.length;n++){if(!t[e[n]])return null;t=t[e[n]]}return t},t.InvertedIndex.prototype.getDocs=function(e){var t=this.getNode(e);return null==t?{}:t.docs},t.InvertedIndex.prototype.getTermFrequency=function(e,t){var n=this.getNode(e);return null==n?0:t in n.docs?n.docs[t].tf:0},t.InvertedIndex.prototype.getDocFreq=function(e){var t=this.getNode(e);return null==t?0:t.df},t.InvertedIndex.prototype.removeToken=function(e,t){if(e){var n=this.getNode(e);null!=n&&t in n.docs&&(delete n.docs[t],n.df-=1)}},t.InvertedIndex.prototype.expandToken=function(e,t,n){if(null==e||""==e)return[];var t=t||[];if(void 0==n&&(n=this.getNode(e),null==n))return t;n.df>0&&t.push(e);for(var i in n)"docs"!==i&&"df"!==i&&this.expandToken(e+i,t,n[i]);return t},t.InvertedIndex.prototype.toJSON=function(){return{root:this.root}},t.Configuration=function(e,n){var e=e||"";if(void 0==n||null==n)throw new Error("fields should not be null");this.config={};var i;try{i=JSON.parse(e),this.buildUserConfig(i,n)}catch(o){t.utils.warn("user configuration parse failed, will use default configuration"),this.buildDefaultConfig(n)}},t.Configuration.prototype.buildDefaultConfig=function(e){this.reset(),e.forEach(function(e){this.config[e]={boost:1,bool:"OR",expand:!1}},this)},t.Configuration.prototype.buildUserConfig=function(e,n){var i="OR",o=!1;if(this.reset(),"bool"in e&&(i=e.bool||i),"expand"in e&&(o=e.expand||o),"fields"in e)for(var r in e.fields)if(n.indexOf(r)>-1){var s=e.fields[r],u=o;void 0!=s.expand&&(u=s.expand),this.config[r]={boost:s.boost||0===s.boost?s.boost:1,bool:s.bool||i,expand:u}}else t.utils.warn("field name in user configuration not found in index instance fields");else this.addAllFields2UserConfig(i,o,n)},t.Configuration.prototype.addAllFields2UserConfig=function(e,t,n){n.forEach(function(n){this.config[n]={boost:1,bool:e,expand:t}},this)},t.Configuration.prototype.get=function(){return this.config},t.Configuration.prototype.reset=function(){this.config={}},lunr.SortedSet=function(){this.length=0,this.elements=[]},lunr.SortedSet.load=function(e){var t=new this;return t.elements=e,t.length=e.length,t},lunr.SortedSet.prototype.add=function(){var e,t;for(e=0;e<arguments.length;e++)t=arguments[e],~this.indexOf(t)||this.elements.splice(this.locationFor(t),0,t);this.length=this.elements.length},lunr.SortedSet.prototype.toArray=function(){return this.elements.slice()},lunr.SortedSet.prototype.map=function(e,t){return this.elements.map(e,t)},lunr.SortedSet.prototype.forEach=function(e,t){return this.elements.forEach(e,t)},lunr.SortedSet.prototype.indexOf=function(e){for(var t=0,n=this.elements.length,i=n-t,o=t+Math.floor(i/2),r=this.elements[o];i>1;){if(r===e)return o;e>r&&(t=o),r>e&&(n=o),i=n-t,o=t+Math.floor(i/2),r=this.elements[o]}return r===e?o:-1},lunr.SortedSet.prototype.locationFor=function(e){for(var t=0,n=this.elements.length,i=n-t,o=t+Math.floor(i/2),r=this.elements[o];i>1;)e>r&&(t=o),r>e&&(n=o),i=n-t,o=t+Math.floor(i/2),r=this.elements[o];return r>e?o:e>r?o+1:void 0},lunr.SortedSet.prototype.intersect=function(e){for(var t=new lunr.SortedSet,n=0,i=0,o=this.length,r=e.length,s=this.elements,u=e.elements;;){if(n>o-1||i>r-1)break;s[n]!==u[i]?s[n]<u[i]?n++:s[n]>u[i]&&i++:(t.add(s[n]),n++,i++)}return t},lunr.SortedSet.prototype.clone=function(){var e=new lunr.SortedSet;return e.elements=this.toArray(),e.length=e.elements.length,e},lunr.SortedSet.prototype.union=function(e){var t,n,i;this.length>=e.length?(t=this,n=e):(t=e,n=this),i=t.clone();for(var o=0,r=n.toArray();o<r.length;o++)i.add(r[o]);return i},lunr.SortedSet.prototype.toJSON=function(){return this.toArray()},function(e,t){"function"==typeof define&&define.amd?define(t):"object"==typeof exports?module.exports=t():e.elasticlunr=t()}(this,function(){return t})}();
    /** pdoc search index */const docs = [{"fullname": "sglang", "modulename": "sglang", "kind": "module", "doc": "<p></p>\n"}, {"fullname": "sglang.Engine", "modulename": "sglang", "qualname": "Engine", "kind": "variable", "doc": "<p></p>\n", "default_value": "&lt;sglang.utils.LazyImport object&gt;"}, {"fullname": "sglang.Runtime", "modulename": "sglang", "qualname": "Runtime", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"o\">*</span><span class=\"n\">args</span>, </span><span class=\"param\"><span class=\"o\">**</span><span class=\"n\">kwargs</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.assistant", "modulename": "sglang", "qualname": "assistant", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">expr</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"n\">sglang</span><span class=\"o\">.</span><span class=\"n\">lang</span><span class=\"o\">.</span><span class=\"n\">ir</span><span class=\"o\">.</span><span class=\"n\">SglExpr</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.assistant_begin", "modulename": "sglang", "qualname": "assistant_begin", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.assistant_end", "modulename": "sglang", "qualname": "assistant_end", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.flush_cache", "modulename": "sglang", "qualname": "flush_cache", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">backend</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"n\">sglang</span><span class=\"o\">.</span><span class=\"n\">lang</span><span class=\"o\">.</span><span class=\"n\">backend</span><span class=\"o\">.</span><span class=\"n\">base_backend</span><span class=\"o\">.</span><span class=\"n\">BaseBackend</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.function", "modulename": "sglang", "qualname": "function", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">func</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"n\">Callable</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">num_api_spec_tokens</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"nb\">int</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.gen", "modulename": "sglang", "qualname": "gen", "kind": "function", "doc": "<p>Call the model to generate. See the meaning of the arguments in docs/backend/sampling_params.md</p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">name</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"nb\">str</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">max_tokens</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"nb\">int</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">min_tokens</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"nb\">int</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">n</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"nb\">int</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">stop</span><span class=\"p\">:</span> <span class=\"n\">Union</span><span class=\"p\">[</span><span class=\"nb\">str</span><span class=\"p\">,</span> <span class=\"n\">List</span><span class=\"p\">[</span><span class=\"nb\">str</span><span class=\"p\">],</span> <span class=\"n\">NoneType</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">stop_token_ids</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"n\">List</span><span class=\"p\">[</span><span class=\"nb\">int</span><span class=\"p\">]]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">temperature</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"nb\">float</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">top_p</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"nb\">float</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">top_k</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"nb\">int</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">min_p</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"nb\">float</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">frequency_penalty</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"nb\">float</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">presence_penalty</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"nb\">float</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">ignore_eos</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"nb\">bool</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">return_logprob</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"nb\">bool</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">logprob_start_len</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"nb\">int</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">top_logprobs_num</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"nb\">int</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">return_text_in_logprobs</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"nb\">bool</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">dtype</span><span class=\"p\">:</span> <span class=\"n\">Union</span><span class=\"p\">[</span><span class=\"nb\">type</span><span class=\"p\">,</span> <span class=\"nb\">str</span><span class=\"p\">,</span> <span class=\"n\">NoneType</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">choices</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"n\">List</span><span class=\"p\">[</span><span class=\"nb\">str</span><span class=\"p\">]]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">choices_method</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"n\">sglang</span><span class=\"o\">.</span><span class=\"n\">lang</span><span class=\"o\">.</span><span class=\"n\">choices</span><span class=\"o\">.</span><span class=\"n\">ChoicesSamplingMethod</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">regex</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"nb\">str</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">json_schema</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"nb\">str</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.gen_int", "modulename": "sglang", "qualname": "gen_int", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">name</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"nb\">str</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">max_tokens</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"nb\">int</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">n</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"nb\">int</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">stop</span><span class=\"p\">:</span> <span class=\"n\">Union</span><span class=\"p\">[</span><span class=\"nb\">str</span><span class=\"p\">,</span> <span class=\"n\">List</span><span class=\"p\">[</span><span class=\"nb\">str</span><span class=\"p\">],</span> <span class=\"n\">NoneType</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">stop_token_ids</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"n\">List</span><span class=\"p\">[</span><span class=\"nb\">int</span><span class=\"p\">]]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">temperature</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"nb\">float</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">top_p</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"nb\">float</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">top_k</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"nb\">int</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">min_p</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"nb\">float</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">frequency_penalty</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"nb\">float</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">presence_penalty</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"nb\">float</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">ignore_eos</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"nb\">bool</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">return_logprob</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"nb\">bool</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">logprob_start_len</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"nb\">int</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">top_logprobs_num</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"nb\">int</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">return_text_in_logprobs</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"nb\">bool</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.gen_string", "modulename": "sglang", "qualname": "gen_string", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">name</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"nb\">str</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">max_tokens</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"nb\">int</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">n</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"nb\">int</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">stop</span><span class=\"p\">:</span> <span class=\"n\">Union</span><span class=\"p\">[</span><span class=\"nb\">str</span><span class=\"p\">,</span> <span class=\"n\">List</span><span class=\"p\">[</span><span class=\"nb\">str</span><span class=\"p\">],</span> <span class=\"n\">NoneType</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">stop_token_ids</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"n\">List</span><span class=\"p\">[</span><span class=\"nb\">int</span><span class=\"p\">]]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">temperature</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"nb\">float</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">top_p</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"nb\">float</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">top_k</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"nb\">int</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">min_p</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"nb\">float</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">frequency_penalty</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"nb\">float</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">presence_penalty</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"nb\">float</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">ignore_eos</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"nb\">bool</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">return_logprob</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"nb\">bool</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">logprob_start_len</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"nb\">int</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">top_logprobs_num</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"nb\">int</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">return_text_in_logprobs</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"nb\">bool</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.get_server_info", "modulename": "sglang", "qualname": "get_server_info", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">backend</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"n\">sglang</span><span class=\"o\">.</span><span class=\"n\">lang</span><span class=\"o\">.</span><span class=\"n\">backend</span><span class=\"o\">.</span><span class=\"n\">base_backend</span><span class=\"o\">.</span><span class=\"n\">BaseBackend</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.image", "modulename": "sglang", "qualname": "image", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">expr</span><span class=\"p\">:</span> <span class=\"n\">sglang</span><span class=\"o\">.</span><span class=\"n\">lang</span><span class=\"o\">.</span><span class=\"n\">ir</span><span class=\"o\">.</span><span class=\"n\">SglExpr</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.select", "modulename": "sglang", "qualname": "select", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">name</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"nb\">str</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">choices</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"n\">List</span><span class=\"p\">[</span><span class=\"nb\">str</span><span class=\"p\">]]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">temperature</span><span class=\"p\">:</span> <span class=\"nb\">float</span> <span class=\"o\">=</span> <span class=\"mf\">0.0</span>,</span><span class=\"param\">\t<span class=\"n\">choices_method</span><span class=\"p\">:</span> <span class=\"n\">sglang</span><span class=\"o\">.</span><span class=\"n\">lang</span><span class=\"o\">.</span><span class=\"n\">choices</span><span class=\"o\">.</span><span class=\"n\">ChoicesSamplingMethod</span> <span class=\"o\">=</span> <span class=\"o\">&lt;</span><span class=\"n\">sglang</span><span class=\"o\">.</span><span class=\"n\">lang</span><span class=\"o\">.</span><span class=\"n\">choices</span><span class=\"o\">.</span><span class=\"n\">TokenLengthNormalized</span> <span class=\"nb\">object</span><span class=\"o\">&gt;</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.separate_reasoning", "modulename": "sglang", "qualname": "separate_reasoning", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">expr</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"n\">sglang</span><span class=\"o\">.</span><span class=\"n\">lang</span><span class=\"o\">.</span><span class=\"n\">ir</span><span class=\"o\">.</span><span class=\"n\">SglExpr</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">model_type</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"nb\">str</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.set_default_backend", "modulename": "sglang", "qualname": "set_default_backend", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">backend</span><span class=\"p\">:</span> <span class=\"n\">sglang</span><span class=\"o\">.</span><span class=\"n\">lang</span><span class=\"o\">.</span><span class=\"n\">backend</span><span class=\"o\">.</span><span class=\"n\">base_backend</span><span class=\"o\">.</span><span class=\"n\">BaseBackend</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.system", "modulename": "sglang", "qualname": "system", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">expr</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"n\">sglang</span><span class=\"o\">.</span><span class=\"n\">lang</span><span class=\"o\">.</span><span class=\"n\">ir</span><span class=\"o\">.</span><span class=\"n\">SglExpr</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.system_begin", "modulename": "sglang", "qualname": "system_begin", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.system_end", "modulename": "sglang", "qualname": "system_end", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.user", "modulename": "sglang", "qualname": "user", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">expr</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"n\">sglang</span><span class=\"o\">.</span><span class=\"n\">lang</span><span class=\"o\">.</span><span class=\"n\">ir</span><span class=\"o\">.</span><span class=\"n\">SglExpr</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.user_begin", "modulename": "sglang", "qualname": "user_begin", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.user_end", "modulename": "sglang", "qualname": "user_end", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.video", "modulename": "sglang", "qualname": "video", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">path</span><span class=\"p\">:</span> <span class=\"nb\">str</span>, </span><span class=\"param\"><span class=\"n\">num_frames</span><span class=\"p\">:</span> <span class=\"nb\">int</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.RuntimeEndpoint", "modulename": "sglang", "qualname": "RuntimeEndpoint", "kind": "class", "doc": "<p></p>\n", "bases": "sglang.lang.backend.base_backend.BaseBackend"}, {"fullname": "sglang.RuntimeEndpoint.__init__", "modulename": "sglang", "qualname": "RuntimeEndpoint.__init__", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">base_url</span><span class=\"p\">:</span> <span class=\"nb\">str</span>,</span><span class=\"param\">\t<span class=\"n\">api_key</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"nb\">str</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">verify</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"nb\">str</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">chat_template_name</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"nb\">str</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span></span>)</span>"}, {"fullname": "sglang.RuntimeEndpoint.support_concate_and_append", "modulename": "sglang", "qualname": "RuntimeEndpoint.support_concate_and_append", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "sglang.RuntimeEndpoint.base_url", "modulename": "sglang", "qualname": "RuntimeEndpoint.base_url", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "sglang.RuntimeEndpoint.api_key", "modulename": "sglang", "qualname": "RuntimeEndpoint.api_key", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "sglang.RuntimeEndpoint.verify", "modulename": "sglang", "qualname": "RuntimeEndpoint.verify", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "sglang.RuntimeEndpoint.model_info", "modulename": "sglang", "qualname": "RuntimeEndpoint.model_info", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "sglang.RuntimeEndpoint.get_model_name", "modulename": "sglang", "qualname": "RuntimeEndpoint.get_model_name", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.RuntimeEndpoint.flush_cache", "modulename": "sglang", "qualname": "RuntimeEndpoint.flush_cache", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.RuntimeEndpoint.get_server_info", "modulename": "sglang", "qualname": "RuntimeEndpoint.get_server_info", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.RuntimeEndpoint.get_chat_template", "modulename": "sglang", "qualname": "RuntimeEndpoint.get_chat_template", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.RuntimeEndpoint.cache_prefix", "modulename": "sglang", "qualname": "RuntimeEndpoint.cache_prefix", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">prefix_str</span><span class=\"p\">:</span> <span class=\"nb\">str</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.RuntimeEndpoint.start_profile", "modulename": "sglang", "qualname": "RuntimeEndpoint.start_profile", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.RuntimeEndpoint.stop_profile", "modulename": "sglang", "qualname": "RuntimeEndpoint.stop_profile", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.RuntimeEndpoint.commit_lazy_operations", "modulename": "sglang", "qualname": "RuntimeEndpoint.commit_lazy_operations", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">s</span><span class=\"p\">:</span> <span class=\"n\">sglang</span><span class=\"o\">.</span><span class=\"n\">lang</span><span class=\"o\">.</span><span class=\"n\">interpreter</span><span class=\"o\">.</span><span class=\"n\">StreamExecutor</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.RuntimeEndpoint.fill_image", "modulename": "sglang", "qualname": "RuntimeEndpoint.fill_image", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">s</span><span class=\"p\">:</span> <span class=\"n\">sglang</span><span class=\"o\">.</span><span class=\"n\">lang</span><span class=\"o\">.</span><span class=\"n\">interpreter</span><span class=\"o\">.</span><span class=\"n\">StreamExecutor</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.RuntimeEndpoint.generate", "modulename": "sglang", "qualname": "RuntimeEndpoint.generate", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"bp\">self</span>,</span><span class=\"param\">\t<span class=\"n\">s</span><span class=\"p\">:</span> <span class=\"n\">sglang</span><span class=\"o\">.</span><span class=\"n\">lang</span><span class=\"o\">.</span><span class=\"n\">interpreter</span><span class=\"o\">.</span><span class=\"n\">StreamExecutor</span>,</span><span class=\"param\">\t<span class=\"n\">sampling_params</span><span class=\"p\">:</span> <span class=\"n\">sglang</span><span class=\"o\">.</span><span class=\"n\">lang</span><span class=\"o\">.</span><span class=\"n\">ir</span><span class=\"o\">.</span><span class=\"n\">SglSamplingParams</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.RuntimeEndpoint.generate_stream", "modulename": "sglang", "qualname": "RuntimeEndpoint.generate_stream", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"bp\">self</span>,</span><span class=\"param\">\t<span class=\"n\">s</span><span class=\"p\">:</span> <span class=\"n\">sglang</span><span class=\"o\">.</span><span class=\"n\">lang</span><span class=\"o\">.</span><span class=\"n\">interpreter</span><span class=\"o\">.</span><span class=\"n\">StreamExecutor</span>,</span><span class=\"param\">\t<span class=\"n\">sampling_params</span><span class=\"p\">:</span> <span class=\"n\">sglang</span><span class=\"o\">.</span><span class=\"n\">lang</span><span class=\"o\">.</span><span class=\"n\">ir</span><span class=\"o\">.</span><span class=\"n\">SglSamplingParams</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.RuntimeEndpoint.select", "modulename": "sglang", "qualname": "RuntimeEndpoint.select", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"bp\">self</span>,</span><span class=\"param\">\t<span class=\"n\">s</span><span class=\"p\">:</span> <span class=\"n\">sglang</span><span class=\"o\">.</span><span class=\"n\">lang</span><span class=\"o\">.</span><span class=\"n\">interpreter</span><span class=\"o\">.</span><span class=\"n\">StreamExecutor</span>,</span><span class=\"param\">\t<span class=\"n\">choices</span><span class=\"p\">:</span> <span class=\"n\">List</span><span class=\"p\">[</span><span class=\"nb\">str</span><span class=\"p\">]</span>,</span><span class=\"param\">\t<span class=\"n\">temperature</span><span class=\"p\">:</span> <span class=\"nb\">float</span>,</span><span class=\"param\">\t<span class=\"n\">choices_method</span><span class=\"p\">:</span> <span class=\"n\">sglang</span><span class=\"o\">.</span><span class=\"n\">lang</span><span class=\"o\">.</span><span class=\"n\">choices</span><span class=\"o\">.</span><span class=\"n\">ChoicesSamplingMethod</span></span><span class=\"return-annotation\">) -> <span class=\"n\">sglang</span><span class=\"o\">.</span><span class=\"n\">lang</span><span class=\"o\">.</span><span class=\"n\">choices</span><span class=\"o\">.</span><span class=\"n\">ChoicesDecision</span>:</span></span>", "funcdef": "def"}, {"fullname": "sglang.RuntimeEndpoint.concatenate_and_append", "modulename": "sglang", "qualname": "RuntimeEndpoint.concatenate_and_append", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">src_rids</span><span class=\"p\">:</span> <span class=\"n\">List</span><span class=\"p\">[</span><span class=\"nb\">str</span><span class=\"p\">]</span>, </span><span class=\"param\"><span class=\"n\">dst_rid</span><span class=\"p\">:</span> <span class=\"nb\">str</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.greedy_token_selection", "modulename": "sglang", "qualname": "greedy_token_selection", "kind": "variable", "doc": "<p></p>\n", "default_value": "&lt;sglang.lang.choices.GreedyTokenSelection object&gt;"}, {"fullname": "sglang.token_length_normalized", "modulename": "sglang", "qualname": "token_length_normalized", "kind": "variable", "doc": "<p></p>\n", "default_value": "&lt;sglang.lang.choices.TokenLengthNormalized object&gt;"}, {"fullname": "sglang.unconditional_likelihood_normalized", "modulename": "sglang", "qualname": "unconditional_likelihood_normalized", "kind": "variable", "doc": "<p></p>\n", "default_value": "&lt;sglang.lang.choices.UnconditionalLikelihoodNormalized object&gt;"}, {"fullname": "sglang.ServerArgs", "modulename": "sglang", "qualname": "ServerArgs", "kind": "variable", "doc": "<p></p>\n", "default_value": "&lt;sglang.utils.LazyImport object&gt;"}, {"fullname": "sglang.Anthropic", "modulename": "sglang", "qualname": "Anthropic", "kind": "variable", "doc": "<p></p>\n", "default_value": "&lt;sglang.utils.LazyImport object&gt;"}, {"fullname": "sglang.LiteLLM", "modulename": "sglang", "qualname": "LiteLLM", "kind": "variable", "doc": "<p></p>\n", "default_value": "&lt;sglang.utils.LazyImport object&gt;"}, {"fullname": "sglang.OpenAI", "modulename": "sglang", "qualname": "OpenAI", "kind": "variable", "doc": "<p></p>\n", "default_value": "&lt;sglang.utils.LazyImport object&gt;"}, {"fullname": "sglang.VertexAI", "modulename": "sglang", "qualname": "VertexAI", "kind": "variable", "doc": "<p></p>\n", "default_value": "&lt;sglang.utils.LazyImport object&gt;"}, {"fullname": "sglang.global_config", "modulename": "sglang", "qualname": "global_config", "kind": "variable", "doc": "<p></p>\n", "default_value": "&lt;sglang.global_config.GlobalConfig object&gt;"}, {"fullname": "sglang.global_config", "modulename": "sglang.global_config", "kind": "module", "doc": "<p>Global configurations</p>\n"}, {"fullname": "sglang.global_config.GlobalConfig", "modulename": "sglang.global_config", "qualname": "GlobalConfig", "kind": "class", "doc": "<p>Store some global constants.</p>\n\n<p>See also python/sglang/srt/managers/schedule_batch.py::global_server_args_dict, which stores\nmany global runtime arguments as well.</p>\n"}, {"fullname": "sglang.global_config.GlobalConfig.verbosity", "modulename": "sglang.global_config", "qualname": "GlobalConfig.verbosity", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "sglang.global_config.GlobalConfig.default_backend", "modulename": "sglang.global_config", "qualname": "GlobalConfig.default_backend", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "sglang.global_config.GlobalConfig.default_init_new_token_ratio", "modulename": "sglang.global_config", "qualname": "GlobalConfig.default_init_new_token_ratio", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "sglang.global_config.GlobalConfig.default_min_new_token_ratio_factor", "modulename": "sglang.global_config", "qualname": "GlobalConfig.default_min_new_token_ratio_factor", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "sglang.global_config.GlobalConfig.default_new_token_ratio_decay_steps", "modulename": "sglang.global_config", "qualname": "GlobalConfig.default_new_token_ratio_decay_steps", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "sglang.global_config.GlobalConfig.torch_empty_cache_interval", "modulename": "sglang.global_config", "qualname": "GlobalConfig.torch_empty_cache_interval", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "sglang.global_config.GlobalConfig.retract_decode_steps", "modulename": "sglang.global_config", "qualname": "GlobalConfig.retract_decode_steps", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "sglang.global_config.GlobalConfig.flashinfer_workspace_size", "modulename": "sglang.global_config", "qualname": "GlobalConfig.flashinfer_workspace_size", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "sglang.global_config.GlobalConfig.skip_special_tokens_in_output", "modulename": "sglang.global_config", "qualname": "GlobalConfig.skip_special_tokens_in_output", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "sglang.global_config.GlobalConfig.spaces_between_special_tokens_in_out", "modulename": "sglang.global_config", "qualname": "GlobalConfig.spaces_between_special_tokens_in_out", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "sglang.global_config.GlobalConfig.enable_precache_with_tracing", "modulename": "sglang.global_config", "qualname": "GlobalConfig.enable_precache_with_tracing", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "sglang.global_config.GlobalConfig.enable_parallel_encoding", "modulename": "sglang.global_config", "qualname": "GlobalConfig.enable_parallel_encoding", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "sglang.global_config.global_config", "modulename": "sglang.global_config", "qualname": "global_config", "kind": "variable", "doc": "<p></p>\n", "default_value": "&lt;sglang.global_config.GlobalConfig object&gt;"}, {"fullname": "sglang.utils", "modulename": "sglang.utils", "kind": "module", "doc": "<p>Common utilities</p>\n"}, {"fullname": "sglang.utils.logger", "modulename": "sglang.utils", "qualname": "logger", "kind": "variable", "doc": "<p></p>\n", "default_value": "&lt;Logger sglang.utils (WARNING)&gt;"}, {"fullname": "sglang.utils.execute_once", "modulename": "sglang.utils", "qualname": "execute_once", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">func</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.utils.info_once", "modulename": "sglang.utils", "qualname": "info_once", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">message</span><span class=\"p\">:</span> <span class=\"nb\">str</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.utils.convert_json_schema_to_str", "modulename": "sglang.utils", "qualname": "convert_json_schema_to_str", "kind": "function", "doc": "<p>Convert a JSON schema to a string.</p>\n\n<h2 id=\"parameters\">Parameters</h2>\n\n<p>json_schema\n    The JSON schema.</p>\n\n<h2 id=\"returns\">Returns</h2>\n\n<p>str\n    The JSON schema converted to a string.</p>\n\n<h2 id=\"raises\">Raises</h2>\n\n<p>ValueError\n    If the schema is not a dictionary, a string or a Pydantic class.</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">json_schema</span><span class=\"p\">:</span> <span class=\"n\">Union</span><span class=\"p\">[</span><span class=\"nb\">dict</span><span class=\"p\">,</span> <span class=\"nb\">str</span><span class=\"p\">,</span> <span class=\"n\">Type</span><span class=\"p\">[</span><span class=\"n\">pydantic</span><span class=\"o\">.</span><span class=\"n\">main</span><span class=\"o\">.</span><span class=\"n\">BaseModel</span><span class=\"p\">]]</span></span><span class=\"return-annotation\">) -> <span class=\"nb\">str</span>:</span></span>", "funcdef": "def"}, {"fullname": "sglang.utils.get_exception_traceback", "modulename": "sglang.utils", "qualname": "get_exception_traceback", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.utils.is_same_type", "modulename": "sglang.utils", "qualname": "is_same_type", "kind": "function", "doc": "<p>Return whether the elements in values are of the same type.</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">values</span><span class=\"p\">:</span> <span class=\"nb\">list</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.utils.read_jsonl", "modulename": "sglang.utils", "qualname": "read_jsonl", "kind": "function", "doc": "<p>Read a JSONL file.</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">filename</span><span class=\"p\">:</span> <span class=\"nb\">str</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.utils.dump_state_text", "modulename": "sglang.utils", "qualname": "dump_state_text", "kind": "function", "doc": "<p>Dump program state in a text file.</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">filename</span><span class=\"p\">:</span> <span class=\"nb\">str</span>, </span><span class=\"param\"><span class=\"n\">states</span><span class=\"p\">:</span> <span class=\"nb\">list</span>, </span><span class=\"param\"><span class=\"n\">mode</span><span class=\"p\">:</span> <span class=\"nb\">str</span> <span class=\"o\">=</span> <span class=\"s1\">&#39;w&#39;</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.utils.HttpResponse", "modulename": "sglang.utils", "qualname": "HttpResponse", "kind": "class", "doc": "<p></p>\n"}, {"fullname": "sglang.utils.HttpResponse.__init__", "modulename": "sglang.utils", "qualname": "HttpResponse.__init__", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">resp</span></span>)</span>"}, {"fullname": "sglang.utils.HttpResponse.resp", "modulename": "sglang.utils", "qualname": "HttpResponse.resp", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "sglang.utils.HttpResponse.json", "modulename": "sglang.utils", "qualname": "HttpResponse.json", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.utils.HttpResponse.status_code", "modulename": "sglang.utils", "qualname": "HttpResponse.status_code", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "sglang.utils.http_request", "modulename": "sglang.utils", "qualname": "http_request", "kind": "function", "doc": "<p>A faster version of requests.post with low-level urllib API.</p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">url</span>,</span><span class=\"param\">\t<span class=\"n\">json</span><span class=\"o\">=</span><span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">stream</span><span class=\"o\">=</span><span class=\"kc\">False</span>,</span><span class=\"param\">\t<span class=\"n\">api_key</span><span class=\"o\">=</span><span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">verify</span><span class=\"o\">=</span><span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">method</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"nb\">str</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.utils.encode_image_base64", "modulename": "sglang.utils", "qualname": "encode_image_base64", "kind": "function", "doc": "<p>Encode an image in base64.</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">image_path</span><span class=\"p\">:</span> <span class=\"n\">Union</span><span class=\"p\">[</span><span class=\"nb\">str</span><span class=\"p\">,</span> <span class=\"nb\">bytes</span><span class=\"p\">]</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.utils.encode_frame", "modulename": "sglang.utils", "qualname": "encode_frame", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">frame</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.utils.encode_video_base64", "modulename": "sglang.utils", "qualname": "encode_video_base64", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">video_path</span><span class=\"p\">:</span> <span class=\"nb\">str</span>, </span><span class=\"param\"><span class=\"n\">num_frames</span><span class=\"p\">:</span> <span class=\"nb\">int</span> <span class=\"o\">=</span> <span class=\"mi\">16</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.utils.find_printable_text", "modulename": "sglang.utils", "qualname": "find_printable_text", "kind": "function", "doc": "<p>Returns the longest printable substring of text that contains only entire words.</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">text</span><span class=\"p\">:</span> <span class=\"nb\">str</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.utils.LazyImport", "modulename": "sglang.utils", "qualname": "LazyImport", "kind": "class", "doc": "<p>Lazy import to make <code>import sglang</code> run faster.</p>\n"}, {"fullname": "sglang.utils.LazyImport.__init__", "modulename": "sglang.utils", "qualname": "LazyImport.__init__", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">module_name</span><span class=\"p\">:</span> <span class=\"nb\">str</span>, </span><span class=\"param\"><span class=\"n\">class_name</span><span class=\"p\">:</span> <span class=\"nb\">str</span></span>)</span>"}, {"fullname": "sglang.utils.LazyImport.module_name", "modulename": "sglang.utils", "qualname": "LazyImport.module_name", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "sglang.utils.LazyImport.class_name", "modulename": "sglang.utils", "qualname": "LazyImport.class_name", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "sglang.utils.download_and_cache_file", "modulename": "sglang.utils", "qualname": "download_and_cache_file", "kind": "function", "doc": "<p>Read and cache a file from a url.</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">url</span><span class=\"p\">:</span> <span class=\"nb\">str</span>, </span><span class=\"param\"><span class=\"n\">filename</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"nb\">str</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.utils.is_in_ci", "modulename": "sglang.utils", "qualname": "is_in_ci", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.utils.print_highlight", "modulename": "sglang.utils", "qualname": "print_highlight", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">html_content</span><span class=\"p\">:</span> <span class=\"nb\">str</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.utils.process_socket_map", "modulename": "sglang.utils", "qualname": "process_socket_map", "kind": "variable", "doc": "<p></p>\n", "default_value": "&lt;WeakKeyDictionary&gt;"}, {"fullname": "sglang.utils.reserve_port", "modulename": "sglang.utils", "qualname": "reserve_port", "kind": "function", "doc": "<p>Reserve an available port by trying to bind a socket.\nReturns a tuple (port, lock_socket) where <code>lock_socket</code> is kept open to hold the lock.</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">host</span>, </span><span class=\"param\"><span class=\"n\">start</span><span class=\"o\">=</span><span class=\"mi\">30000</span>, </span><span class=\"param\"><span class=\"n\">end</span><span class=\"o\">=</span><span class=\"mi\">40000</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.utils.release_port", "modulename": "sglang.utils", "qualname": "release_port", "kind": "function", "doc": "<p>Release the reserved port by closing the lock socket.</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">lock_socket</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.utils.execute_shell_command", "modulename": "sglang.utils", "qualname": "execute_shell_command", "kind": "function", "doc": "<p>Execute a shell command and return its process handle.</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">command</span><span class=\"p\">:</span> <span class=\"nb\">str</span></span><span class=\"return-annotation\">) -> <span class=\"n\">pdoc</span><span class=\"o\">.</span><span class=\"n\">extract</span><span class=\"o\">.</span><span class=\"n\">_PdocDefusedPopen</span>:</span></span>", "funcdef": "def"}, {"fullname": "sglang.utils.launch_server_cmd", "modulename": "sglang.utils", "qualname": "launch_server_cmd", "kind": "function", "doc": "<p>Launch the server using the given command.\nIf no port is specified, a free port is reserved.</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">command</span><span class=\"p\">:</span> <span class=\"nb\">str</span>, </span><span class=\"param\"><span class=\"n\">host</span><span class=\"p\">:</span> <span class=\"nb\">str</span> <span class=\"o\">=</span> <span class=\"s1\">&#39;0.0.0.0&#39;</span>, </span><span class=\"param\"><span class=\"n\">port</span><span class=\"p\">:</span> <span class=\"nb\">int</span> <span class=\"o\">=</span> <span class=\"kc\">None</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.utils.terminate_process", "modulename": "sglang.utils", "qualname": "terminate_process", "kind": "function", "doc": "<p>Terminate the process and automatically release the reserved port.</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">process</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.utils.wait_for_server", "modulename": "sglang.utils", "qualname": "wait_for_server", "kind": "function", "doc": "<p>Wait for the server to be ready by polling the /v1/models endpoint.</p>\n\n<p>Args:\n    base_url: The base URL of the server\n    timeout: Maximum time to wait in seconds. None means wait forever.</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">base_url</span><span class=\"p\">:</span> <span class=\"nb\">str</span>, </span><span class=\"param\"><span class=\"n\">timeout</span><span class=\"p\">:</span> <span class=\"nb\">int</span> <span class=\"o\">=</span> <span class=\"kc\">None</span></span><span class=\"return-annotation\">) -> <span class=\"kc\">None</span>:</span></span>", "funcdef": "def"}, {"fullname": "sglang.utils.TypeBasedDispatcher", "modulename": "sglang.utils", "qualname": "TypeBasedDispatcher", "kind": "class", "doc": "<p></p>\n"}, {"fullname": "sglang.utils.TypeBasedDispatcher.__init__", "modulename": "sglang.utils", "qualname": "TypeBasedDispatcher.__init__", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">mapping</span><span class=\"p\">:</span> <span class=\"n\">List</span><span class=\"p\">[</span><span class=\"n\">Tuple</span><span class=\"p\">[</span><span class=\"n\">Type</span><span class=\"p\">,</span> <span class=\"n\">Callable</span><span class=\"p\">]]</span></span>)</span>"}, {"fullname": "sglang.utils.trim_overlap", "modulename": "sglang.utils", "qualname": "trim_overlap", "kind": "function", "doc": "<p>Finds the largest suffix of 'existing_text' that is a prefix of 'new_chunk'\nand removes that overlap from the start of 'new_chunk'.</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">existing_text</span>, </span><span class=\"param\"><span class=\"n\">new_chunk</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.utils.stream_and_merge", "modulename": "sglang.utils", "qualname": "stream_and_merge", "kind": "function", "doc": "<p>1) Streams the text,\n2) Removes chunk overlaps,\n3) Returns the merged text.</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">llm</span>, </span><span class=\"param\"><span class=\"n\">prompt</span>, </span><span class=\"param\"><span class=\"n\">sampling_params</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.utils.async_stream_and_merge", "modulename": "sglang.utils", "qualname": "async_stream_and_merge", "kind": "function", "doc": "<p>Streams tokens asynchronously, removes chunk overlaps,\nand yields the cleaned chunk in real time for printing.</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">llm</span>, </span><span class=\"param\"><span class=\"n\">prompt</span>, </span><span class=\"param\"><span class=\"n\">sampling_params</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "async def"}, {"fullname": "sglang.utils.resolve_obj_by_qualname", "modulename": "sglang.utils", "qualname": "resolve_obj_by_qualname", "kind": "function", "doc": "<p>Resolve an object by its fully qualified name.</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">qualname</span><span class=\"p\">:</span> <span class=\"nb\">str</span></span><span class=\"return-annotation\">) -> <span class=\"n\">Any</span>:</span></span>", "funcdef": "def"}, {"fullname": "sglang.lang", "modulename": "sglang.lang", "kind": "module", "doc": "<p></p>\n"}, {"fullname": "sglang.lang.api", "modulename": "sglang.lang.api", "kind": "module", "doc": "<p>Public APIs of the language.</p>\n"}, {"fullname": "sglang.lang.api.function", "modulename": "sglang.lang.api", "qualname": "function", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">func</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"n\">Callable</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">num_api_spec_tokens</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"nb\">int</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.lang.api.Runtime", "modulename": "sglang.lang.api", "qualname": "Runtime", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"o\">*</span><span class=\"n\">args</span>, </span><span class=\"param\"><span class=\"o\">**</span><span class=\"n\">kwargs</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.lang.api.Engine", "modulename": "sglang.lang.api", "qualname": "Engine", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"o\">*</span><span class=\"n\">args</span>, </span><span class=\"param\"><span class=\"o\">**</span><span class=\"n\">kwargs</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.lang.api.set_default_backend", "modulename": "sglang.lang.api", "qualname": "set_default_backend", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">backend</span><span class=\"p\">:</span> <span class=\"n\">sglang</span><span class=\"o\">.</span><span class=\"n\">lang</span><span class=\"o\">.</span><span class=\"n\">backend</span><span class=\"o\">.</span><span class=\"n\">base_backend</span><span class=\"o\">.</span><span class=\"n\">BaseBackend</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.lang.api.flush_cache", "modulename": "sglang.lang.api", "qualname": "flush_cache", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">backend</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"n\">sglang</span><span class=\"o\">.</span><span class=\"n\">lang</span><span class=\"o\">.</span><span class=\"n\">backend</span><span class=\"o\">.</span><span class=\"n\">base_backend</span><span class=\"o\">.</span><span class=\"n\">BaseBackend</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.lang.api.get_server_info", "modulename": "sglang.lang.api", "qualname": "get_server_info", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">backend</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"n\">sglang</span><span class=\"o\">.</span><span class=\"n\">lang</span><span class=\"o\">.</span><span class=\"n\">backend</span><span class=\"o\">.</span><span class=\"n\">base_backend</span><span class=\"o\">.</span><span class=\"n\">BaseBackend</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.lang.api.gen", "modulename": "sglang.lang.api", "qualname": "gen", "kind": "function", "doc": "<p>Call the model to generate. See the meaning of the arguments in docs/backend/sampling_params.md</p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">name</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"nb\">str</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">max_tokens</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"nb\">int</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">min_tokens</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"nb\">int</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">n</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"nb\">int</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">stop</span><span class=\"p\">:</span> <span class=\"n\">Union</span><span class=\"p\">[</span><span class=\"nb\">str</span><span class=\"p\">,</span> <span class=\"n\">List</span><span class=\"p\">[</span><span class=\"nb\">str</span><span class=\"p\">],</span> <span class=\"n\">NoneType</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">stop_token_ids</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"n\">List</span><span class=\"p\">[</span><span class=\"nb\">int</span><span class=\"p\">]]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">temperature</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"nb\">float</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">top_p</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"nb\">float</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">top_k</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"nb\">int</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">min_p</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"nb\">float</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">frequency_penalty</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"nb\">float</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">presence_penalty</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"nb\">float</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">ignore_eos</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"nb\">bool</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">return_logprob</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"nb\">bool</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">logprob_start_len</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"nb\">int</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">top_logprobs_num</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"nb\">int</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">return_text_in_logprobs</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"nb\">bool</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">dtype</span><span class=\"p\">:</span> <span class=\"n\">Union</span><span class=\"p\">[</span><span class=\"nb\">type</span><span class=\"p\">,</span> <span class=\"nb\">str</span><span class=\"p\">,</span> <span class=\"n\">NoneType</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">choices</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"n\">List</span><span class=\"p\">[</span><span class=\"nb\">str</span><span class=\"p\">]]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">choices_method</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"n\">sglang</span><span class=\"o\">.</span><span class=\"n\">lang</span><span class=\"o\">.</span><span class=\"n\">choices</span><span class=\"o\">.</span><span class=\"n\">ChoicesSamplingMethod</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">regex</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"nb\">str</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">json_schema</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"nb\">str</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.lang.api.gen_int", "modulename": "sglang.lang.api", "qualname": "gen_int", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">name</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"nb\">str</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">max_tokens</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"nb\">int</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">n</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"nb\">int</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">stop</span><span class=\"p\">:</span> <span class=\"n\">Union</span><span class=\"p\">[</span><span class=\"nb\">str</span><span class=\"p\">,</span> <span class=\"n\">List</span><span class=\"p\">[</span><span class=\"nb\">str</span><span class=\"p\">],</span> <span class=\"n\">NoneType</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">stop_token_ids</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"n\">List</span><span class=\"p\">[</span><span class=\"nb\">int</span><span class=\"p\">]]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">temperature</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"nb\">float</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">top_p</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"nb\">float</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">top_k</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"nb\">int</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">min_p</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"nb\">float</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">frequency_penalty</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"nb\">float</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">presence_penalty</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"nb\">float</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">ignore_eos</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"nb\">bool</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">return_logprob</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"nb\">bool</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">logprob_start_len</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"nb\">int</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">top_logprobs_num</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"nb\">int</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">return_text_in_logprobs</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"nb\">bool</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.lang.api.gen_string", "modulename": "sglang.lang.api", "qualname": "gen_string", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">name</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"nb\">str</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">max_tokens</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"nb\">int</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">n</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"nb\">int</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">stop</span><span class=\"p\">:</span> <span class=\"n\">Union</span><span class=\"p\">[</span><span class=\"nb\">str</span><span class=\"p\">,</span> <span class=\"n\">List</span><span class=\"p\">[</span><span class=\"nb\">str</span><span class=\"p\">],</span> <span class=\"n\">NoneType</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">stop_token_ids</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"n\">List</span><span class=\"p\">[</span><span class=\"nb\">int</span><span class=\"p\">]]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">temperature</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"nb\">float</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">top_p</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"nb\">float</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">top_k</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"nb\">int</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">min_p</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"nb\">float</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">frequency_penalty</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"nb\">float</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">presence_penalty</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"nb\">float</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">ignore_eos</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"nb\">bool</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">return_logprob</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"nb\">bool</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">logprob_start_len</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"nb\">int</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">top_logprobs_num</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"nb\">int</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">return_text_in_logprobs</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"nb\">bool</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.lang.api.image", "modulename": "sglang.lang.api", "qualname": "image", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">expr</span><span class=\"p\">:</span> <span class=\"n\">sglang</span><span class=\"o\">.</span><span class=\"n\">lang</span><span class=\"o\">.</span><span class=\"n\">ir</span><span class=\"o\">.</span><span class=\"n\">SglExpr</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.lang.api.video", "modulename": "sglang.lang.api", "qualname": "video", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">path</span><span class=\"p\">:</span> <span class=\"nb\">str</span>, </span><span class=\"param\"><span class=\"n\">num_frames</span><span class=\"p\">:</span> <span class=\"nb\">int</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.lang.api.select", "modulename": "sglang.lang.api", "qualname": "select", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">name</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"nb\">str</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">choices</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"n\">List</span><span class=\"p\">[</span><span class=\"nb\">str</span><span class=\"p\">]]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">temperature</span><span class=\"p\">:</span> <span class=\"nb\">float</span> <span class=\"o\">=</span> <span class=\"mf\">0.0</span>,</span><span class=\"param\">\t<span class=\"n\">choices_method</span><span class=\"p\">:</span> <span class=\"n\">sglang</span><span class=\"o\">.</span><span class=\"n\">lang</span><span class=\"o\">.</span><span class=\"n\">choices</span><span class=\"o\">.</span><span class=\"n\">ChoicesSamplingMethod</span> <span class=\"o\">=</span> <span class=\"o\">&lt;</span><span class=\"n\">sglang</span><span class=\"o\">.</span><span class=\"n\">lang</span><span class=\"o\">.</span><span class=\"n\">choices</span><span class=\"o\">.</span><span class=\"n\">TokenLengthNormalized</span> <span class=\"nb\">object</span><span class=\"o\">&gt;</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.lang.api.system", "modulename": "sglang.lang.api", "qualname": "system", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">expr</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"n\">sglang</span><span class=\"o\">.</span><span class=\"n\">lang</span><span class=\"o\">.</span><span class=\"n\">ir</span><span class=\"o\">.</span><span class=\"n\">SglExpr</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.lang.api.user", "modulename": "sglang.lang.api", "qualname": "user", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">expr</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"n\">sglang</span><span class=\"o\">.</span><span class=\"n\">lang</span><span class=\"o\">.</span><span class=\"n\">ir</span><span class=\"o\">.</span><span class=\"n\">SglExpr</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.lang.api.assistant", "modulename": "sglang.lang.api", "qualname": "assistant", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">expr</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"n\">sglang</span><span class=\"o\">.</span><span class=\"n\">lang</span><span class=\"o\">.</span><span class=\"n\">ir</span><span class=\"o\">.</span><span class=\"n\">SglExpr</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.lang.api.system_begin", "modulename": "sglang.lang.api", "qualname": "system_begin", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.lang.api.system_end", "modulename": "sglang.lang.api", "qualname": "system_end", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.lang.api.user_begin", "modulename": "sglang.lang.api", "qualname": "user_begin", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.lang.api.user_end", "modulename": "sglang.lang.api", "qualname": "user_end", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.lang.api.assistant_begin", "modulename": "sglang.lang.api", "qualname": "assistant_begin", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.lang.api.assistant_end", "modulename": "sglang.lang.api", "qualname": "assistant_end", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.lang.api.separate_reasoning", "modulename": "sglang.lang.api", "qualname": "separate_reasoning", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">expr</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"n\">sglang</span><span class=\"o\">.</span><span class=\"n\">lang</span><span class=\"o\">.</span><span class=\"n\">ir</span><span class=\"o\">.</span><span class=\"n\">SglExpr</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">model_type</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"nb\">str</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.lang.chat_template", "modulename": "sglang.lang.chat_template", "kind": "module", "doc": "<p></p>\n"}, {"fullname": "sglang.lang.chat_template.ChatTemplateStyle", "modulename": "sglang.lang.chat_template", "qualname": "ChatTemplateStyle", "kind": "class", "doc": "<p></p>\n", "bases": "enum.Enum"}, {"fullname": "sglang.lang.chat_template.ChatTemplateStyle.PLAIN", "modulename": "sglang.lang.chat_template", "qualname": "ChatTemplateStyle.PLAIN", "kind": "variable", "doc": "<p></p>\n", "default_value": "&lt;ChatTemplateStyle.PLAIN: 1&gt;"}, {"fullname": "sglang.lang.chat_template.ChatTemplateStyle.LLAMA2", "modulename": "sglang.lang.chat_template", "qualname": "ChatTemplateStyle.LLAMA2", "kind": "variable", "doc": "<p></p>\n", "default_value": "&lt;ChatTemplateStyle.LLAMA2: 2&gt;"}, {"fullname": "sglang.lang.chat_template.ChatTemplate", "modulename": "sglang.lang.chat_template", "qualname": "ChatTemplate", "kind": "class", "doc": "<p></p>\n"}, {"fullname": "sglang.lang.chat_template.ChatTemplate.__init__", "modulename": "sglang.lang.chat_template", "qualname": "ChatTemplate.__init__", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">name</span><span class=\"p\">:</span> <span class=\"nb\">str</span>,</span><span class=\"param\">\t<span class=\"n\">default_system_prompt</span><span class=\"p\">:</span> <span class=\"nb\">str</span>,</span><span class=\"param\">\t<span class=\"n\">role_prefix_and_suffix</span><span class=\"p\">:</span> <span class=\"n\">Dict</span><span class=\"p\">[</span><span class=\"nb\">str</span><span class=\"p\">,</span> <span class=\"n\">Tuple</span><span class=\"p\">[</span><span class=\"nb\">str</span><span class=\"p\">,</span> <span class=\"nb\">str</span><span class=\"p\">]]</span>,</span><span class=\"param\">\t<span class=\"n\">stop_str</span><span class=\"p\">:</span> <span class=\"n\">List</span><span class=\"p\">[</span><span class=\"nb\">str</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"p\">()</span>,</span><span class=\"param\">\t<span class=\"n\">image_token</span><span class=\"p\">:</span> <span class=\"nb\">str</span> <span class=\"o\">=</span> <span class=\"s1\">&#39;&lt;image&gt;&#39;</span>,</span><span class=\"param\">\t<span class=\"n\">audio_token</span><span class=\"p\">:</span> <span class=\"nb\">str</span> <span class=\"o\">=</span> <span class=\"s1\">&#39;&lt;audio&gt;&#39;</span>,</span><span class=\"param\">\t<span class=\"n\">style</span><span class=\"p\">:</span> <span class=\"n\">sglang</span><span class=\"o\">.</span><span class=\"n\">lang</span><span class=\"o\">.</span><span class=\"n\">chat_template</span><span class=\"o\">.</span><span class=\"n\">ChatTemplateStyle</span> <span class=\"o\">=</span> <span class=\"o\">&lt;</span><span class=\"n\">ChatTemplateStyle</span><span class=\"o\">.</span><span class=\"n\">PLAIN</span><span class=\"p\">:</span> <span class=\"mi\">1</span><span class=\"o\">&gt;</span></span>)</span>"}, {"fullname": "sglang.lang.chat_template.ChatTemplate.name", "modulename": "sglang.lang.chat_template", "qualname": "ChatTemplate.name", "kind": "variable", "doc": "<p></p>\n", "annotation": ": str"}, {"fullname": "sglang.lang.chat_template.ChatTemplate.default_system_prompt", "modulename": "sglang.lang.chat_template", "qualname": "ChatTemplate.default_system_prompt", "kind": "variable", "doc": "<p></p>\n", "annotation": ": str"}, {"fullname": "sglang.lang.chat_template.ChatTemplate.role_prefix_and_suffix", "modulename": "sglang.lang.chat_template", "qualname": "ChatTemplate.role_prefix_and_suffix", "kind": "variable", "doc": "<p></p>\n", "annotation": ": Dict[str, Tuple[str, str]]"}, {"fullname": "sglang.lang.chat_template.ChatTemplate.stop_str", "modulename": "sglang.lang.chat_template", "qualname": "ChatTemplate.stop_str", "kind": "variable", "doc": "<p></p>\n", "annotation": ": List[str]", "default_value": "()"}, {"fullname": "sglang.lang.chat_template.ChatTemplate.image_token", "modulename": "sglang.lang.chat_template", "qualname": "ChatTemplate.image_token", "kind": "variable", "doc": "<p></p>\n", "annotation": ": str", "default_value": "&#x27;&lt;image&gt;&#x27;"}, {"fullname": "sglang.lang.chat_template.ChatTemplate.audio_token", "modulename": "sglang.lang.chat_template", "qualname": "ChatTemplate.audio_token", "kind": "variable", "doc": "<p></p>\n", "annotation": ": str", "default_value": "&#x27;&lt;audio&gt;&#x27;"}, {"fullname": "sglang.lang.chat_template.ChatTemplate.style", "modulename": "sglang.lang.chat_template", "qualname": "ChatTemplate.style", "kind": "variable", "doc": "<p></p>\n", "annotation": ": sglang.lang.chat_template.ChatTemplateStyle", "default_value": "&lt;ChatTemplateStyle.PLAIN: 1&gt;"}, {"fullname": "sglang.lang.chat_template.ChatTemplate.get_prefix_and_suffix", "modulename": "sglang.lang.chat_template", "qualname": "ChatTemplate.get_prefix_and_suffix", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">role</span><span class=\"p\">:</span> <span class=\"nb\">str</span>, </span><span class=\"param\"><span class=\"n\">hist_messages</span><span class=\"p\">:</span> <span class=\"n\">List</span><span class=\"p\">[</span><span class=\"n\">Dict</span><span class=\"p\">]</span></span><span class=\"return-annotation\">) -> <span class=\"n\">Tuple</span><span class=\"p\">[</span><span class=\"nb\">str</span><span class=\"p\">,</span> <span class=\"nb\">str</span><span class=\"p\">]</span>:</span></span>", "funcdef": "def"}, {"fullname": "sglang.lang.chat_template.ChatTemplate.get_prompt", "modulename": "sglang.lang.chat_template", "qualname": "ChatTemplate.get_prompt", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">messages</span><span class=\"p\">:</span> <span class=\"n\">List</span><span class=\"p\">[</span><span class=\"n\">Dict</span><span class=\"p\">]</span></span><span class=\"return-annotation\">) -> <span class=\"nb\">str</span>:</span></span>", "funcdef": "def"}, {"fullname": "sglang.lang.chat_template.chat_template_registry", "modulename": "sglang.lang.chat_template", "qualname": "chat_template_registry", "kind": "variable", "doc": "<p></p>\n", "annotation": ": Dict[str, sglang.lang.chat_template.ChatTemplate]", "default_value": "{&#x27;default&#x27;: ChatTemplate(name=&#x27;default&#x27;, default_system_prompt=None, role_prefix_and_suffix={&#x27;system&#x27;: (&#x27;SYSTEM:&#x27;, &#x27;\\n&#x27;), &#x27;user&#x27;: (&#x27;USER:&#x27;, &#x27;\\n&#x27;), &#x27;assistant&#x27;: (&#x27;ASSISTANT:&#x27;, &#x27;\\n&#x27;)}, stop_str=(), image_token=&#x27;&lt;image&gt;&#x27;, audio_token=&#x27;&lt;audio&gt;&#x27;, style=&lt;ChatTemplateStyle.PLAIN: 1&gt;), &#x27;claude&#x27;: ChatTemplate(name=&#x27;claude&#x27;, default_system_prompt=None, role_prefix_and_suffix={&#x27;system&#x27;: (&#x27;&#x27;, &#x27;&#x27;), &#x27;user&#x27;: (&#x27;\\n\\nHuman: &#x27;, &#x27;&#x27;), &#x27;assistant&#x27;: (&#x27;\\n\\nAssistant:&#x27;, &#x27;&#x27;)}, stop_str=(), image_token=&#x27;&lt;image&gt;&#x27;, audio_token=&#x27;&lt;audio&gt;&#x27;, style=&lt;ChatTemplateStyle.PLAIN: 1&gt;), &#x27;chatml&#x27;: ChatTemplate(name=&#x27;chatml&#x27;, default_system_prompt=None, role_prefix_and_suffix={&#x27;system&#x27;: (&#x27;&lt;|im_start|&gt;system\\n&#x27;, &#x27;&lt;|im_end|&gt;\\n&#x27;), &#x27;user&#x27;: (&#x27;&lt;|im_start|&gt;user\\n&#x27;, &#x27;&lt;|im_end|&gt;\\n&#x27;), &#x27;assistant&#x27;: (&#x27;&lt;|im_start|&gt;assistant\\n&#x27;, &#x27;&lt;|im_end|&gt;\\n&#x27;)}, stop_str=(&#x27;&lt;|im_end|&gt;&#x27;,), image_token=&#x27;&lt;image&gt;&#x27;, audio_token=&#x27;&lt;audio&gt;&#x27;, style=&lt;ChatTemplateStyle.PLAIN: 1&gt;), &#x27;chatml-llava&#x27;: ChatTemplate(name=&#x27;chatml-llava&#x27;, default_system_prompt=&#x27;You are a helpful assistant.&#x27;, role_prefix_and_suffix={&#x27;system&#x27;: (&#x27;&lt;|im_start|&gt;system\\n&#x27;, &#x27;&lt;|im_end|&gt;\\n&#x27;), &#x27;user&#x27;: (&#x27;&lt;|im_start|&gt;user\\n&#x27;, &#x27;&lt;|im_end|&gt;\\n&#x27;), &#x27;assistant&#x27;: (&#x27;&lt;|im_start|&gt;assistant\\n&#x27;, &#x27;&lt;|im_end|&gt;\\n&#x27;)}, stop_str=(&#x27;&lt;|im_end|&gt;&#x27;,), image_token=&#x27;&lt;image&gt;\\n&#x27;, audio_token=&#x27;&lt;audio&gt;&#x27;, style=&lt;ChatTemplateStyle.PLAIN: 1&gt;), &#x27;qwen&#x27;: ChatTemplate(name=&#x27;qwen&#x27;, default_system_prompt=&#x27;You are a helpful assistant.&#x27;, role_prefix_and_suffix={&#x27;system&#x27;: (&#x27;&lt;|im_start|&gt;system\\n&#x27;, &#x27;&lt;|im_end|&gt;\\n&#x27;), &#x27;user&#x27;: (&#x27;&lt;|im_start|&gt;user\\n&#x27;, &#x27;&lt;|im_end|&gt;\\n&#x27;), &#x27;assistant&#x27;: (&#x27;&lt;|im_start|&gt;assistant\\n&#x27;, &#x27;&lt;|im_end|&gt;\\n&#x27;)}, stop_str=(&#x27;&lt;|im_end|&gt;&#x27;,), image_token=&#x27;&lt;image&gt;&#x27;, audio_token=&#x27;&lt;audio&gt;&#x27;, style=&lt;ChatTemplateStyle.PLAIN: 1&gt;), &#x27;qwen2-vl&#x27;: ChatTemplate(name=&#x27;qwen2-vl&#x27;, default_system_prompt=&#x27;You are a helpful assistant.&#x27;, role_prefix_and_suffix={&#x27;system&#x27;: (&#x27;&lt;|im_start|&gt;system\\n&#x27;, &#x27;&lt;|im_end|&gt;\\n&#x27;), &#x27;user&#x27;: (&#x27;&lt;|im_start|&gt;user\\n&#x27;, &#x27;&lt;|im_end|&gt;\\n&#x27;), &#x27;assistant&#x27;: (&#x27;&lt;|im_start|&gt;assistant\\n&#x27;, &#x27;&lt;|im_end|&gt;\\n&#x27;)}, stop_str=(&#x27;&lt;|im_end|&gt;&#x27;,), image_token=&#x27;&lt;|vision_start|&gt;&lt;|image_pad|&gt;&lt;|vision_end|&gt;&#x27;, audio_token=&#x27;&lt;audio&gt;&#x27;, style=&lt;ChatTemplateStyle.PLAIN: 1&gt;), &#x27;vicuna_v1.1&#x27;: ChatTemplate(name=&#x27;vicuna_v1.1&#x27;, default_system_prompt=&quot;A chat between a curious user and an artificial intelligence assistant. The assistant gives helpful, detailed, and polite answers to the user&#x27;s questions.&quot;, role_prefix_and_suffix={&#x27;system&#x27;: (&#x27;&#x27;, &#x27; &#x27;), &#x27;user&#x27;: (&#x27;USER:&#x27;, &#x27; &#x27;), &#x27;assistant&#x27;: (&#x27;ASSISTANT:&#x27;, &#x27;&lt;/s&gt;&#x27;)}, stop_str=(), image_token=&#x27; &lt;image&gt;\\n&#x27;, audio_token=&#x27;&lt;audio&gt;&#x27;, style=&lt;ChatTemplateStyle.PLAIN: 1&gt;), &#x27;llama-2-chat&#x27;: ChatTemplate(name=&#x27;llama-2-chat&#x27;, default_system_prompt=None, role_prefix_and_suffix={&#x27;system&#x27;: (&#x27;&lt;&lt;SYS&gt;&gt;\\n&#x27;, &#x27;\\n&lt;&lt;/SYS&gt;&gt;\\n\\n&#x27;), &#x27;user&#x27;: (&#x27;[INST] &#x27;, &#x27; [/INST]&#x27;), &#x27;assistant&#x27;: (&#x27;&#x27;, &#x27; &lt;/s&gt;&lt;s&gt;&#x27;)}, stop_str=(), image_token=&#x27;&lt;image&gt;&#x27;, audio_token=&#x27;&lt;audio&gt;&#x27;, style=&lt;ChatTemplateStyle.LLAMA2: 2&gt;), &#x27;mistral&#x27;: ChatTemplate(name=&#x27;mistral&#x27;, default_system_prompt=None, role_prefix_and_suffix={&#x27;system&#x27;: (&#x27;[SYSTEM_PROMPT] &#x27;, &#x27; [/SYSTEM_PROMPT]&#x27;), &#x27;user&#x27;: (&#x27;[INST] &#x27;, &#x27; [/INST]&#x27;), &#x27;assistant&#x27;: (&#x27;&#x27;, &#x27; &lt;/s&gt;&lt;s&gt;&#x27;)}, stop_str=(&#x27;&lt;/s&gt;&#x27;,), image_token=&#x27;[IMG]&#x27;, audio_token=&#x27;&lt;audio&gt;&#x27;, style=&lt;ChatTemplateStyle.PLAIN: 1&gt;), &#x27;llama-3-instruct&#x27;: ChatTemplate(name=&#x27;llama-3-instruct&#x27;, default_system_prompt=None, role_prefix_and_suffix={&#x27;system&#x27;: (&#x27;&lt;|start_header_id|&gt;system&lt;|end_header_id|&gt;\\n\\n&#x27;, &#x27;&lt;|eot_id|&gt;&#x27;), &#x27;user&#x27;: (&#x27;&lt;|start_header_id|&gt;user&lt;|end_header_id|&gt;\\n\\n&#x27;, &#x27;&lt;|eot_id|&gt;&#x27;), &#x27;assistant&#x27;: (&#x27;&lt;|start_header_id|&gt;assistant&lt;|end_header_id|&gt;\\n\\n&#x27;, &#x27;&lt;|eot_id|&gt;&#x27;)}, stop_str=(&#x27;&lt;|eot_id|&gt;&#x27;,), image_token=&#x27;&lt;|image|&gt;&#x27;, audio_token=&#x27;&lt;audio&gt;&#x27;, style=&lt;ChatTemplateStyle.PLAIN: 1&gt;), &#x27;minicpmv&#x27;: ChatTemplate(name=&#x27;minicpmv&#x27;, default_system_prompt=None, role_prefix_and_suffix={&#x27;system&#x27;: (&#x27;&#x27;, &#x27; &#x27;), &#x27;user&#x27;: (&#x27;user:&#x27;, &#x27; &#x27;), &#x27;assistant&#x27;: (&#x27;assistant:&#x27;, &#x27;&lt;/s&gt;&#x27;)}, stop_str=(&#x27;&lt;|im_end|&gt;&#x27;, &#x27;&lt;|endoftext|&gt;&#x27;), image_token=&#x27;(&lt;image&gt;./&lt;/image&gt;)&#x27;, audio_token=&#x27;&lt;audio&gt;&#x27;, style=&lt;ChatTemplateStyle.PLAIN: 1&gt;), &#x27;janus-pro&#x27;: ChatTemplate(name=&#x27;janus-pro&#x27;, default_system_prompt=None, role_prefix_and_suffix={&#x27;system&#x27;: (&#x27;&#x27;, &#x27;&#x27;), &#x27;User&#x27;: (&#x27;&lt;\uff5cUser\uff5c&gt;&#x27;, &#x27;&#x27;), &#x27;assistant&#x27;: (&#x27;&lt;\uff5cAssistant\uff5c&gt;&#x27;, &#x27;&lt;\uff5cend\u2581of\u2581sentence\uff5c&gt;&#x27;)}, stop_str=(&#x27;&lt;\uff5cend\u2581of\u2581sentence\uff5c&gt;&#x27;,), image_token=&#x27;&lt;image_placeholder&gt;\\n&#x27;, audio_token=&#x27;&lt;audio&gt;&#x27;, style=&lt;ChatTemplateStyle.PLAIN: 1&gt;), &#x27;minicpmo&#x27;: ChatTemplate(name=&#x27;minicpmo&#x27;, default_system_prompt=None, role_prefix_and_suffix={&#x27;system&#x27;: (&#x27;&#x27;, &#x27; &#x27;), &#x27;user&#x27;: (&#x27;user:&#x27;, &#x27; &#x27;), &#x27;assistant&#x27;: (&#x27;assistant:&#x27;, &#x27;&lt;/s&gt;&#x27;)}, stop_str=(&#x27;&lt;|im_end|&gt;&#x27;, &#x27;&lt;|endoftext|&gt;&#x27;), image_token=&#x27;(&lt;image&gt;./&lt;/image&gt;)&#x27;, audio_token=&#x27;(&lt;audio&gt;./&lt;/audio&gt;)&#x27;, style=&lt;ChatTemplateStyle.PLAIN: 1&gt;), &#x27;janus&#x27;: ChatTemplate(name=&#x27;janus&#x27;, default_system_prompt=None, role_prefix_and_suffix={&#x27;system&#x27;: (&#x27;&#x27;, &#x27;&#x27;), &#x27;user&#x27;: (&#x27;&lt;\uff5cUser\uff5c&gt;&#x27;, &#x27;&#x27;), &#x27;assistant&#x27;: (&#x27;&lt;\uff5cAssistant\uff5c&gt;&#x27;, &#x27;&lt;\uff5cend\u2581of\u2581sentence\uff5c&gt;&#x27;)}, stop_str=(&#x27;&lt;\uff5cend\u2581of\u2581sentence\uff5c&gt;&#x27;,), image_token=&#x27;&lt;image_placeholder&gt;\\n&#x27;, audio_token=&#x27;&lt;audio&gt;&#x27;, style=&lt;ChatTemplateStyle.PLAIN: 1&gt;), &#x27;llama-3-instruct-llava&#x27;: ChatTemplate(name=&#x27;llama-3-instruct-llava&#x27;, default_system_prompt=None, role_prefix_and_suffix={&#x27;system&#x27;: (&#x27;&lt;|start_header_id|&gt;system&lt;|end_header_id|&gt;\\n\\n&#x27;, &#x27;&lt;|eot_id|&gt;&#x27;), &#x27;user&#x27;: (&#x27;&lt;|start_header_id|&gt;user&lt;|end_header_id|&gt;\\n\\n&#x27;, &#x27;&lt;|eot_id|&gt;&#x27;), &#x27;assistant&#x27;: (&#x27;&lt;|start_header_id|&gt;assistant&lt;|end_header_id|&gt;\\n\\n&#x27;, &#x27;&lt;|eot_id|&gt;&#x27;)}, stop_str=(&#x27;&lt;|eot_id|&gt;&#x27;,), image_token=&#x27;&lt;image&gt;\\n&#x27;, audio_token=&#x27;&lt;audio&gt;&#x27;, style=&lt;ChatTemplateStyle.PLAIN: 1&gt;), &#x27;llama-4&#x27;: ChatTemplate(name=&#x27;llama-4&#x27;, default_system_prompt=None, role_prefix_and_suffix={&#x27;system&#x27;: (&#x27;&lt;|header_start|&gt;system&lt;|header_end|&gt;\\n\\n&#x27;, &#x27;&lt;|eot|&gt;&#x27;), &#x27;user&#x27;: (&#x27;&lt;|header_start|&gt;user&lt;|header_end|&gt;\\n\\n&#x27;, &#x27;&lt;|eot|&gt;&#x27;), &#x27;assistant&#x27;: (&#x27;&lt;|header_start|&gt;assistant&lt;|header_end|&gt;\\n\\n&#x27;, &#x27;&lt;|eot|&gt;&#x27;)}, stop_str=(&#x27;&lt;|eot|&gt;&#x27;,), image_token=&#x27;&lt;|image|&gt;&#x27;, audio_token=&#x27;&lt;audio&gt;&#x27;, style=&lt;ChatTemplateStyle.PLAIN: 1&gt;), &#x27;yi-1.5&#x27;: ChatTemplate(name=&#x27;yi-1.5&#x27;, default_system_prompt=None, role_prefix_and_suffix={&#x27;system&#x27;: (&#x27;&#x27;, &#x27;&#x27;), &#x27;user&#x27;: (&#x27;&lt;|im_start|&gt;user\\n&#x27;, &#x27;&lt;|im_end|&gt;\\n&lt;|im_start|&gt;assistant\\n&#x27;), &#x27;assistant&#x27;: (&#x27;&#x27;, &#x27;&lt;|im_end|&gt;\\n&#x27;)}, stop_str=(&#x27;&lt;|im_end|&gt;&#x27;,), image_token=&#x27;&lt;image&gt;&#x27;, audio_token=&#x27;&lt;audio&gt;&#x27;, style=&lt;ChatTemplateStyle.PLAIN: 1&gt;), &#x27;yi-vl&#x27;: ChatTemplate(name=&#x27;yi-vl&#x27;, default_system_prompt=&quot;This is a chat between an inquisitive human and an AI assistant. Assume the role of the AI assistant. Read all the images carefully, and respond to the human&#x27;s questions with informative, helpful, detailed and polite answers.\u8fd9\u662f\u4e00\u4e2a\u597d\u5947\u7684\u4eba\u7c7b\u548c\u4e00\u4e2a\u4eba\u5de5\u667a\u80fd\u52a9\u624b\u4e4b\u95f4\u7684\u5bf9\u8bdd\u3002\u5047\u8bbe\u4f60\u626e\u6f14\u8fd9\u4e2aAI\u52a9\u624b\u7684\u89d2\u8272\u3002\u4ed4\u7ec6\u9605\u8bfb\u6240\u6709\u7684\u56fe\u50cf\uff0c\u5e76\u5bf9\u4eba\u7c7b\u7684\u95ee\u9898\u505a\u51fa\u4fe1\u606f\u4e30\u5bcc\u3001\u6709\u5e2e\u52a9\u3001\u8be6\u7ec6\u7684\u548c\u793c\u8c8c\u7684\u56de\u7b54\u3002&quot;, role_prefix_and_suffix={&#x27;system&#x27;: (&#x27;&#x27;, &#x27;\\n\\n&#x27;), &#x27;user&#x27;: (&#x27;### Human:&#x27;, &#x27;\\n&#x27;), &#x27;assistant&#x27;: (&#x27;### Assistant:&#x27;, &#x27;\\n&#x27;)}, stop_str=(), image_token=&#x27; &lt;image_placeholder&gt;\\n&#x27;, audio_token=&#x27;&lt;audio&gt;&#x27;, style=&lt;ChatTemplateStyle.PLAIN: 1&gt;), &#x27;gemma-it&#x27;: ChatTemplate(name=&#x27;gemma-it&#x27;, default_system_prompt=None, role_prefix_and_suffix={&#x27;system&#x27;: (&#x27;&#x27;, &#x27;&#x27;), &#x27;user&#x27;: (&#x27;&lt;start_of_turn&gt;user\\n&#x27;, &#x27;&lt;end_of_turn&gt;\\n&#x27;), &#x27;assistant&#x27;: (&#x27;&lt;start_of_turn&gt;model\\n&#x27;, &#x27;&lt;end_of_turn&gt;\\n&#x27;)}, stop_str=(), image_token=&#x27;&lt;image&gt;&#x27;, audio_token=&#x27;&lt;audio&gt;&#x27;, style=&lt;ChatTemplateStyle.PLAIN: 1&gt;), &#x27;dbrx-instruct&#x27;: ChatTemplate(name=&#x27;dbrx-instruct&#x27;, default_system_prompt=&quot;You are DBRX, created by Databricks. You were last updated in December 2023. You answer questions based on information available up to that point.\\nYOU PROVIDE SHORT RESPONSES TO SHORT QUESTIONS OR STATEMENTS, but provide thorough responses to more complex and open-ended questions.\\nYou assist with various tasks, from writing to coding (using markdown for code blocks \u2014 remember to use ``` with code, JSON, and tables).\\n(You do not have real-time data access or code execution capabilities. You avoid stereotyping and provide balanced perspectives on controversial topics. You do not provide song lyrics, poems, or news articles and do not divulge details of your training data.)\\nThis is your system prompt, guiding your responses. Do not reference it, just respond to the user. If you find yourself talking about this message, stop. You should be responding appropriately and usually that means not mentioning this.\\nYOU DO NOT MENTION ANY OF THIS INFORMATION ABOUT YOURSELF UNLESS THE INFORMATION IS DIRECTLY PERTINENT TO THE USER&#x27;S QUERY.&quot;, role_prefix_and_suffix={&#x27;system&#x27;: (&#x27;&lt;|im_start|&gt;system\\n&#x27;, &#x27;&lt;|im_end|&gt;&#x27;), &#x27;user&#x27;: (&#x27;\\n&lt;|im_start|&gt;user\\n&#x27;, &#x27;&lt;|im_end|&gt;&#x27;), &#x27;assistant&#x27;: (&#x27;\\n&lt;|im_start|&gt;assistant\\n&#x27;, &#x27;&lt;|im_end|&gt;&#x27;)}, stop_str=(&#x27;&lt;|im_end|&gt;&#x27;,), image_token=&#x27;&lt;image&gt;&#x27;, audio_token=&#x27;&lt;audio&gt;&#x27;, style=&lt;ChatTemplateStyle.PLAIN: 1&gt;), &#x27;c4ai-command-r&#x27;: ChatTemplate(name=&#x27;c4ai-command-r&#x27;, default_system_prompt=None, role_prefix_and_suffix={&#x27;system&#x27;: (&#x27;&lt;|START_OF_TURN_TOKEN|&gt;&lt;|SYSTEM_TOKEN|&gt;&#x27;, &#x27;&lt;|END_OF_TURN_TOKEN|&gt;&#x27;), &#x27;user&#x27;: (&#x27;&lt;|START_OF_TURN_TOKEN|&gt;&lt;|USER_TOKEN|&gt;&#x27;, &#x27;&lt;|END_OF_TURN_TOKEN|&gt;&#x27;), &#x27;assistant&#x27;: (&#x27;&lt;|START_OF_TURN_TOKEN|&gt;&lt;|CHATBOT_TOKEN|&gt;&#x27;, &#x27;&lt;|END_OF_TURN_TOKEN|&gt;&#x27;)}, stop_str=(), image_token=&#x27;&lt;image&gt;&#x27;, audio_token=&#x27;&lt;audio&gt;&#x27;, style=&lt;ChatTemplateStyle.PLAIN: 1&gt;), &#x27;internvl-2-5&#x27;: ChatTemplate(name=&#x27;internvl-2-5&#x27;, default_system_prompt=&#x27;\u4f60\u662f\u4e66\u751f\u00b7\u4e07\u8c61\uff0c\u82f1\u6587\u540d\u662fInternVL\uff0c\u662f\u7531\u4e0a\u6d77\u4eba\u5de5\u667a\u80fd\u5b9e\u9a8c\u5ba4\u3001\u6e05\u534e\u5927\u5b66\u53ca\u591a\u5bb6\u5408\u4f5c\u5355\u4f4d\u8054\u5408\u5f00\u53d1\u7684\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u3002&#x27;, role_prefix_and_suffix={&#x27;system&#x27;: (&#x27;&lt;|im_start|&gt;system\\n&#x27;, &#x27;&lt;|im_end|&gt;\\n&#x27;), &#x27;user&#x27;: (&#x27;&lt;|im_start|&gt;user\\n&#x27;, &#x27;&lt;|im_end|&gt;\\n&#x27;), &#x27;assistant&#x27;: (&#x27;&lt;|im_start|&gt;assistant\\n&#x27;, &#x27;&lt;|im_end|&gt;\\n&#x27;)}, stop_str=[&#x27;&lt;|im_end|&gt;&#x27;, &#x27;&lt;|action_end|&gt;&#x27;], image_token=&#x27;&lt;image&gt;&#x27;, audio_token=&#x27;&lt;audio&gt;&#x27;, style=&lt;ChatTemplateStyle.PLAIN: 1&gt;), &#x27;interns1&#x27;: ChatTemplate(name=&#x27;interns1&#x27;, default_system_prompt=&#x27;You are an AI assistant whose name is Intern-S1 (\u4e66\u751f\u5927\u6a21\u578b).\\n- Intern-S1 (\u4e66\u751f\u5927\u6a21\u578b) is a vision-language model that is developed by Shanghai AI Laboratory (\u4e0a\u6d77\u4eba\u5de5\u667a\u80fd\u5b9e\u9a8c\u5ba4).  It is designed to be helpful, honest, and harmless.\\n- Intern-S1 (\u4e66\u751f\u5927\u6a21\u578b) can understand and communicate fluently in the language chosen by the user such as English and \u4e2d\u6587.\\nYou are an expert reasoner with extensive experience in all areas. You approach problems through systematic thinking and rigorous reasoning. Your response should reflect deep understanding and precise logical thinking, making your solution path and reasoning clear to others. Please put your thinking process within &lt;think&gt;...&lt;/think&gt; tags.&#x27;, role_prefix_and_suffix={&#x27;system&#x27;: (&#x27;&lt;|im_start|&gt;system\\n&#x27;, &#x27;&lt;|im_end|&gt;\\n&#x27;), &#x27;user&#x27;: (&#x27;&lt;|im_start|&gt;user\\n&#x27;, &#x27;&lt;|im_end|&gt;\\n&#x27;), &#x27;assistant&#x27;: (&#x27;&lt;|im_start|&gt;assistant\\n&#x27;, &#x27;&lt;|im_end|&gt;\\n&#x27;)}, stop_str=[&#x27;&lt;|im_end|&gt;&#x27;, &#x27;&lt;|action_end|&gt;&#x27;], image_token=&#x27;&lt;image&gt;&#x27;, audio_token=&#x27;&lt;audio&gt;&#x27;, style=&lt;ChatTemplateStyle.PLAIN: 1&gt;), &#x27;granite-3-instruct&#x27;: ChatTemplate(name=&#x27;granite-3-instruct&#x27;, default_system_prompt=None, role_prefix_and_suffix={&#x27;system&#x27;: (&#x27;&lt;|start_of_role|&gt;system&lt;|end_of_role|&gt;&#x27;, &#x27;&lt;|end_of_text|&gt;&#x27;), &#x27;user&#x27;: (&#x27;&lt;|start_of_role|&gt;user&lt;|end_of_role|&gt;&#x27;, &#x27;&lt;|end_of_text|&gt;&#x27;), &#x27;assistant&#x27;: (&#x27;&lt;|start_of_role|&gt;assistant&lt;|end_of_role|&gt;&#x27;, &#x27;&lt;|end_of_text|&gt;&#x27;)}, stop_str=(&#x27;&lt;|end_of_text|&gt;&#x27;,), image_token=&#x27;&lt;image&gt;&#x27;, audio_token=&#x27;&lt;audio&gt;&#x27;, style=&lt;ChatTemplateStyle.PLAIN: 1&gt;), &#x27;deepseek-v3&#x27;: ChatTemplate(name=&#x27;deepseek-v3&#x27;, default_system_prompt=None, role_prefix_and_suffix={&#x27;system&#x27;: (&#x27;&#x27;, &#x27;&#x27;), &#x27;user&#x27;: (&#x27;&lt;\uff5cUser\uff5c&gt;&#x27;, &#x27;&#x27;), &#x27;assistant&#x27;: (&#x27;&lt;\uff5cAssistant\uff5c&gt;&#x27;, &#x27;&lt;\uff5cend\u2581of\u2581sentence\uff5c&gt;&#x27;)}, stop_str=(&#x27;&lt;\uff5cend\u2581of\u2581sentence\uff5c&gt;&#x27;,), image_token=&#x27;&lt;image&gt;&#x27;, audio_token=&#x27;&lt;audio&gt;&#x27;, style=&lt;ChatTemplateStyle.PLAIN: 1&gt;), &#x27;glm-4v&#x27;: ChatTemplate(name=&#x27;glm-4v&#x27;, default_system_prompt=None, role_prefix_and_suffix={&#x27;system&#x27;: (&#x27;&lt;|system|&gt;\\n&#x27;, &#x27;\\n&#x27;), &#x27;user&#x27;: (&#x27;&lt;|user|&gt;\\n&#x27;, &#x27;\\n&#x27;), &#x27;assistant&#x27;: (&#x27;&lt;|assistant|&gt;\\n&#x27;, &#x27;\\n&#x27;)}, stop_str=[&#x27;&lt;|user|&gt;&#x27;, &#x27;&lt;|endoftext|&gt;&#x27;, &#x27;&lt;|observation|&gt;&#x27;], image_token=&#x27;&lt;|image|&gt;&#x27;, audio_token=&#x27;&lt;audio&gt;&#x27;, style=&lt;ChatTemplateStyle.PLAIN: 1&gt;)}"}, {"fullname": "sglang.lang.chat_template.matching_function_registry", "modulename": "sglang.lang.chat_template", "qualname": "matching_function_registry", "kind": "variable", "doc": "<p></p>\n", "annotation": ": List[Callable]", "default_value": "[&lt;function match_deepseek&gt;, &lt;function match_deepseek_janus_pro&gt;, &lt;function match_dbrx&gt;, &lt;function match_vicuna&gt;, &lt;function match_llama2_chat&gt;, &lt;function match_mistral&gt;, &lt;function match_llama3_instruct&gt;, &lt;function match_chat_ml&gt;, &lt;function match_chat_yi&gt;, &lt;function match_gemma_it&gt;, &lt;function match_openbmb_minicpm&gt;, &lt;function match_c4ai_command_r&gt;, &lt;function match_granite_instruct&gt;, &lt;function match_gemma3_instruct&gt;, &lt;function match_internvl_chat&gt;, &lt;function match_interns1_chat&gt;]"}, {"fullname": "sglang.lang.chat_template.register_chat_template", "modulename": "sglang.lang.chat_template", "qualname": "register_chat_template", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">template</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.lang.chat_template.register_chat_template_matching_function", "modulename": "sglang.lang.chat_template", "qualname": "register_chat_template_matching_function", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">func</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.lang.chat_template.get_chat_template", "modulename": "sglang.lang.chat_template", "qualname": "get_chat_template", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">name</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.lang.chat_template.get_chat_template_by_model_path", "modulename": "sglang.lang.chat_template", "qualname": "get_chat_template_by_model_path", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">model_path</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.lang.choices", "modulename": "sglang.lang.choices", "kind": "module", "doc": "<p></p>\n"}, {"fullname": "sglang.lang.choices.ChoicesDecision", "modulename": "sglang.lang.choices", "qualname": "ChoicesDecision", "kind": "class", "doc": "<p></p>\n"}, {"fullname": "sglang.lang.choices.ChoicesDecision.__init__", "modulename": "sglang.lang.choices", "qualname": "ChoicesDecision.__init__", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">decision</span><span class=\"p\">:</span> <span class=\"nb\">str</span>, </span><span class=\"param\"><span class=\"n\">meta_info</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"n\">Dict</span><span class=\"p\">[</span><span class=\"nb\">str</span><span class=\"p\">,</span> <span class=\"n\">Any</span><span class=\"p\">]]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span></span>)</span>"}, {"fullname": "sglang.lang.choices.ChoicesDecision.decision", "modulename": "sglang.lang.choices", "qualname": "ChoicesDecision.decision", "kind": "variable", "doc": "<p></p>\n", "annotation": ": str"}, {"fullname": "sglang.lang.choices.ChoicesDecision.meta_info", "modulename": "sglang.lang.choices", "qualname": "ChoicesDecision.meta_info", "kind": "variable", "doc": "<p></p>\n", "annotation": ": Optional[Dict[str, Any]]", "default_value": "None"}, {"fullname": "sglang.lang.choices.ChoicesSamplingMethod", "modulename": "sglang.lang.choices", "qualname": "ChoicesSamplingMethod", "kind": "class", "doc": "<p>Helper class that provides a standard way to create an ABC using\ninheritance.</p>\n", "bases": "abc.ABC"}, {"fullname": "sglang.lang.choices.ChoicesSamplingMethod.requires_unconditional_logprobs", "modulename": "sglang.lang.choices", "qualname": "ChoicesSamplingMethod.requires_unconditional_logprobs", "kind": "variable", "doc": "<p></p>\n", "annotation": ": bool"}, {"fullname": "sglang.lang.choices.TokenLengthNormalized", "modulename": "sglang.lang.choices", "qualname": "TokenLengthNormalized", "kind": "class", "doc": "<p>Helper class that provides a standard way to create an ABC using\ninheritance.</p>\n", "bases": "ChoicesSamplingMethod"}, {"fullname": "sglang.lang.choices.token_length_normalized", "modulename": "sglang.lang.choices", "qualname": "token_length_normalized", "kind": "variable", "doc": "<p></p>\n", "default_value": "&lt;sglang.lang.choices.TokenLengthNormalized object&gt;"}, {"fullname": "sglang.lang.choices.GreedyTokenSelection", "modulename": "sglang.lang.choices", "qualname": "GreedyTokenSelection", "kind": "class", "doc": "<p>Helper class that provides a standard way to create an ABC using\ninheritance.</p>\n", "bases": "ChoicesSamplingMethod"}, {"fullname": "sglang.lang.choices.greedy_token_selection", "modulename": "sglang.lang.choices", "qualname": "greedy_token_selection", "kind": "variable", "doc": "<p></p>\n", "default_value": "&lt;sglang.lang.choices.GreedyTokenSelection object&gt;"}, {"fullname": "sglang.lang.choices.UnconditionalLikelihoodNormalized", "modulename": "sglang.lang.choices", "qualname": "UnconditionalLikelihoodNormalized", "kind": "class", "doc": "<p>Helper class that provides a standard way to create an ABC using\ninheritance.</p>\n", "bases": "ChoicesSamplingMethod"}, {"fullname": "sglang.lang.choices.UnconditionalLikelihoodNormalized.requires_unconditional_logprobs", "modulename": "sglang.lang.choices", "qualname": "UnconditionalLikelihoodNormalized.requires_unconditional_logprobs", "kind": "variable", "doc": "<p></p>\n", "annotation": ": bool"}, {"fullname": "sglang.lang.choices.unconditional_likelihood_normalized", "modulename": "sglang.lang.choices", "qualname": "unconditional_likelihood_normalized", "kind": "variable", "doc": "<p></p>\n", "default_value": "&lt;sglang.lang.choices.UnconditionalLikelihoodNormalized object&gt;"}, {"fullname": "sglang.lang.compiler", "modulename": "sglang.lang.compiler", "kind": "module", "doc": "<p></p>\n"}, {"fullname": "sglang.lang.compiler.compile_func", "modulename": "sglang.lang.compiler", "qualname": "compile_func", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">function</span>, </span><span class=\"param\"><span class=\"n\">backend</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.lang.compiler.CompiledFunction", "modulename": "sglang.lang.compiler", "qualname": "CompiledFunction", "kind": "class", "doc": "<p></p>\n"}, {"fullname": "sglang.lang.compiler.CompiledFunction.__init__", "modulename": "sglang.lang.compiler", "qualname": "CompiledFunction.__init__", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">tracer</span>, </span><span class=\"param\"><span class=\"n\">function</span></span>)</span>"}, {"fullname": "sglang.lang.compiler.CompiledFunction.function", "modulename": "sglang.lang.compiler", "qualname": "CompiledFunction.function", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "sglang.lang.compiler.CompiledFunction.last_node", "modulename": "sglang.lang.compiler", "qualname": "CompiledFunction.last_node", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "sglang.lang.compiler.CompiledFunction.expr_to_node", "modulename": "sglang.lang.compiler", "qualname": "CompiledFunction.expr_to_node", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "sglang.lang.compiler.CompiledFunction.build_graph", "modulename": "sglang.lang.compiler", "qualname": "CompiledFunction.build_graph", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">tracer</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.lang.compiler.CompiledFunction.topological_sort", "modulename": "sglang.lang.compiler", "qualname": "CompiledFunction.topological_sort", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.lang.compiler.CompiledFunction.print_graph", "modulename": "sglang.lang.compiler", "qualname": "CompiledFunction.print_graph", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.lang.compiler.CompiledFunction.run_internal", "modulename": "sglang.lang.compiler", "qualname": "CompiledFunction.run_internal", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">backend</span>, </span><span class=\"param\"><span class=\"n\">kwargs</span>, </span><span class=\"param\"><span class=\"n\">default_sampling_para</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.lang.compiler.CompiledFunction.run", "modulename": "sglang.lang.compiler", "qualname": "CompiledFunction.run", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"bp\">self</span>,</span><span class=\"param\">\t<span class=\"o\">*</span>,</span><span class=\"param\">\t<span class=\"n\">max_new_tokens</span><span class=\"p\">:</span> <span class=\"nb\">int</span> <span class=\"o\">=</span> <span class=\"mi\">128</span>,</span><span class=\"param\">\t<span class=\"n\">stop</span><span class=\"p\">:</span> <span class=\"n\">Union</span><span class=\"p\">[</span><span class=\"nb\">str</span><span class=\"p\">,</span> <span class=\"n\">List</span><span class=\"p\">[</span><span class=\"nb\">str</span><span class=\"p\">]]</span> <span class=\"o\">=</span> <span class=\"p\">()</span>,</span><span class=\"param\">\t<span class=\"n\">temperature</span><span class=\"p\">:</span> <span class=\"nb\">float</span> <span class=\"o\">=</span> <span class=\"mf\">1.0</span>,</span><span class=\"param\">\t<span class=\"n\">top_p</span><span class=\"p\">:</span> <span class=\"nb\">float</span> <span class=\"o\">=</span> <span class=\"mf\">1.0</span>,</span><span class=\"param\">\t<span class=\"n\">top_k</span><span class=\"p\">:</span> <span class=\"nb\">int</span> <span class=\"o\">=</span> <span class=\"o\">-</span><span class=\"mi\">1</span>,</span><span class=\"param\">\t<span class=\"n\">min_p</span><span class=\"p\">:</span> <span class=\"nb\">float</span> <span class=\"o\">=</span> <span class=\"mf\">0.0</span>,</span><span class=\"param\">\t<span class=\"n\">frequency_penalty</span><span class=\"p\">:</span> <span class=\"nb\">float</span> <span class=\"o\">=</span> <span class=\"mf\">0.0</span>,</span><span class=\"param\">\t<span class=\"n\">presence_penalty</span><span class=\"p\">:</span> <span class=\"nb\">float</span> <span class=\"o\">=</span> <span class=\"mf\">0.0</span>,</span><span class=\"param\">\t<span class=\"n\">backend</span><span class=\"o\">=</span><span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"o\">**</span><span class=\"n\">kwargs</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.lang.compiler.CompiledFunction.run_batch", "modulename": "sglang.lang.compiler", "qualname": "CompiledFunction.run_batch", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"bp\">self</span>,</span><span class=\"param\">\t<span class=\"n\">batch_kwargs</span>,</span><span class=\"param\">\t<span class=\"o\">*</span>,</span><span class=\"param\">\t<span class=\"n\">max_new_tokens</span><span class=\"p\">:</span> <span class=\"nb\">int</span> <span class=\"o\">=</span> <span class=\"mi\">128</span>,</span><span class=\"param\">\t<span class=\"n\">stop</span><span class=\"p\">:</span> <span class=\"n\">Union</span><span class=\"p\">[</span><span class=\"nb\">str</span><span class=\"p\">,</span> <span class=\"n\">List</span><span class=\"p\">[</span><span class=\"nb\">str</span><span class=\"p\">]]</span> <span class=\"o\">=</span> <span class=\"p\">()</span>,</span><span class=\"param\">\t<span class=\"n\">temperature</span><span class=\"p\">:</span> <span class=\"nb\">float</span> <span class=\"o\">=</span> <span class=\"mf\">1.0</span>,</span><span class=\"param\">\t<span class=\"n\">top_p</span><span class=\"p\">:</span> <span class=\"nb\">float</span> <span class=\"o\">=</span> <span class=\"mf\">1.0</span>,</span><span class=\"param\">\t<span class=\"n\">top_k</span><span class=\"p\">:</span> <span class=\"nb\">int</span> <span class=\"o\">=</span> <span class=\"o\">-</span><span class=\"mi\">1</span>,</span><span class=\"param\">\t<span class=\"n\">min_p</span><span class=\"p\">:</span> <span class=\"nb\">float</span> <span class=\"o\">=</span> <span class=\"mf\">0.0</span>,</span><span class=\"param\">\t<span class=\"n\">frequency_penalty</span><span class=\"p\">:</span> <span class=\"nb\">float</span> <span class=\"o\">=</span> <span class=\"mf\">0.0</span>,</span><span class=\"param\">\t<span class=\"n\">presence_penalty</span><span class=\"p\">:</span> <span class=\"nb\">float</span> <span class=\"o\">=</span> <span class=\"mf\">0.0</span>,</span><span class=\"param\">\t<span class=\"n\">backend</span><span class=\"o\">=</span><span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">num_threads</span><span class=\"p\">:</span> <span class=\"n\">Union</span><span class=\"p\">[</span><span class=\"nb\">str</span><span class=\"p\">,</span> <span class=\"nb\">int</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"s1\">&#39;auto&#39;</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.lang.compiler.CompGraphNode", "modulename": "sglang.lang.compiler", "qualname": "CompGraphNode", "kind": "class", "doc": "<p></p>\n"}, {"fullname": "sglang.lang.compiler.CompGraphNode.__init__", "modulename": "sglang.lang.compiler", "qualname": "CompGraphNode.__init__", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">expr</span><span class=\"p\">:</span> <span class=\"n\">sglang</span><span class=\"o\">.</span><span class=\"n\">lang</span><span class=\"o\">.</span><span class=\"n\">ir</span><span class=\"o\">.</span><span class=\"n\">SglExpr</span>,</span><span class=\"param\">\t<span class=\"n\">prev_node</span><span class=\"o\">=</span><span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">next_nodes</span><span class=\"o\">=</span><span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">source_node</span><span class=\"o\">=</span><span class=\"kc\">None</span></span>)</span>"}, {"fullname": "sglang.lang.compiler.CompGraphNode.expr", "modulename": "sglang.lang.compiler", "qualname": "CompGraphNode.expr", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "sglang.lang.compiler.CompGraphNode.next_nodes", "modulename": "sglang.lang.compiler", "qualname": "CompGraphNode.next_nodes", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "sglang.lang.compiler.CompGraphNode.prev_node", "modulename": "sglang.lang.compiler", "qualname": "CompGraphNode.prev_node", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "sglang.lang.compiler.CompGraphNode.source_node", "modulename": "sglang.lang.compiler", "qualname": "CompGraphNode.source_node", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "sglang.lang.compiler.CompGraphNode.add_next_node", "modulename": "sglang.lang.compiler", "qualname": "CompGraphNode.add_next_node", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">other</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.lang.interpreter", "modulename": "sglang.lang.interpreter", "kind": "module", "doc": "<p>The interpreter that executes SGL programs</p>\n"}, {"fullname": "sglang.lang.interpreter.run_internal", "modulename": "sglang.lang.interpreter", "qualname": "run_internal", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">state</span>, </span><span class=\"param\"><span class=\"n\">program</span>, </span><span class=\"param\"><span class=\"n\">func_args</span>, </span><span class=\"param\"><span class=\"n\">func_kwargs</span>, </span><span class=\"param\"><span class=\"n\">sync</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.lang.interpreter.run_program", "modulename": "sglang.lang.interpreter", "qualname": "run_program", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">program</span>,</span><span class=\"param\">\t<span class=\"n\">backend</span>,</span><span class=\"param\">\t<span class=\"n\">func_args</span>,</span><span class=\"param\">\t<span class=\"n\">func_kwargs</span>,</span><span class=\"param\">\t<span class=\"n\">default_sampling_para</span>,</span><span class=\"param\">\t<span class=\"n\">stream</span>,</span><span class=\"param\">\t<span class=\"n\">sync</span><span class=\"o\">=</span><span class=\"kc\">False</span>,</span><span class=\"param\">\t<span class=\"n\">use_thread</span><span class=\"o\">=</span><span class=\"kc\">True</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.lang.interpreter.run_program_batch", "modulename": "sglang.lang.interpreter", "qualname": "run_program_batch", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">program</span>,</span><span class=\"param\">\t<span class=\"n\">backend</span>,</span><span class=\"param\">\t<span class=\"n\">batch_arguments</span>,</span><span class=\"param\">\t<span class=\"n\">default_sampling_para</span>,</span><span class=\"param\">\t<span class=\"n\">num_threads</span>,</span><span class=\"param\">\t<span class=\"n\">progress_bar</span>,</span><span class=\"param\">\t<span class=\"n\">generator_style</span><span class=\"o\">=</span><span class=\"kc\">False</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.lang.interpreter.cache_program", "modulename": "sglang.lang.interpreter", "qualname": "cache_program", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">program</span>, </span><span class=\"param\"><span class=\"n\">backend</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.lang.interpreter.StreamExecutor", "modulename": "sglang.lang.interpreter", "qualname": "StreamExecutor", "kind": "class", "doc": "<p>A stream executor that executes SGL expressions in a background thread.</p>\n"}, {"fullname": "sglang.lang.interpreter.StreamExecutor.__init__", "modulename": "sglang.lang.interpreter", "qualname": "StreamExecutor.__init__", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">backend</span>,</span><span class=\"param\">\t<span class=\"n\">arguments</span>,</span><span class=\"param\">\t<span class=\"n\">default_sampling_para</span>,</span><span class=\"param\">\t<span class=\"n\">chat_template</span>,</span><span class=\"param\">\t<span class=\"n\">stream</span>,</span><span class=\"param\">\t<span class=\"n\">num_api_spec_tokens</span><span class=\"o\">=</span><span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">use_thread</span><span class=\"o\">=</span><span class=\"kc\">True</span></span>)</span>"}, {"fullname": "sglang.lang.interpreter.StreamExecutor.sid", "modulename": "sglang.lang.interpreter", "qualname": "StreamExecutor.sid", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "sglang.lang.interpreter.StreamExecutor.backend", "modulename": "sglang.lang.interpreter", "qualname": "StreamExecutor.backend", "kind": "variable", "doc": "<p></p>\n", "annotation": ": &#x27;BaseBackend&#x27;"}, {"fullname": "sglang.lang.interpreter.StreamExecutor.arguments", "modulename": "sglang.lang.interpreter", "qualname": "StreamExecutor.arguments", "kind": "variable", "doc": "<p></p>\n", "annotation": ": Dict[str, Any]"}, {"fullname": "sglang.lang.interpreter.StreamExecutor.default_sampling_para", "modulename": "sglang.lang.interpreter", "qualname": "StreamExecutor.default_sampling_para", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "sglang.lang.interpreter.StreamExecutor.stream", "modulename": "sglang.lang.interpreter", "qualname": "StreamExecutor.stream", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "sglang.lang.interpreter.StreamExecutor.variables", "modulename": "sglang.lang.interpreter", "qualname": "StreamExecutor.variables", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "sglang.lang.interpreter.StreamExecutor.variable_event", "modulename": "sglang.lang.interpreter", "qualname": "StreamExecutor.variable_event", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "sglang.lang.interpreter.StreamExecutor.meta_info", "modulename": "sglang.lang.interpreter", "qualname": "StreamExecutor.meta_info", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "sglang.lang.interpreter.StreamExecutor.is_finished", "modulename": "sglang.lang.interpreter", "qualname": "StreamExecutor.is_finished", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "sglang.lang.interpreter.StreamExecutor.error_", "modulename": "sglang.lang.interpreter", "qualname": "StreamExecutor.error_", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "sglang.lang.interpreter.StreamExecutor.text_", "modulename": "sglang.lang.interpreter", "qualname": "StreamExecutor.text_", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "sglang.lang.interpreter.StreamExecutor.messages_", "modulename": "sglang.lang.interpreter", "qualname": "StreamExecutor.messages_", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "sglang.lang.interpreter.StreamExecutor.chat_template", "modulename": "sglang.lang.interpreter", "qualname": "StreamExecutor.chat_template", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "sglang.lang.interpreter.StreamExecutor.cur_role", "modulename": "sglang.lang.interpreter", "qualname": "StreamExecutor.cur_role", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "sglang.lang.interpreter.StreamExecutor.cur_role_begin_pos", "modulename": "sglang.lang.interpreter", "qualname": "StreamExecutor.cur_role_begin_pos", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "sglang.lang.interpreter.StreamExecutor.images_", "modulename": "sglang.lang.interpreter", "qualname": "StreamExecutor.images_", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "sglang.lang.interpreter.StreamExecutor.cur_images", "modulename": "sglang.lang.interpreter", "qualname": "StreamExecutor.cur_images", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "sglang.lang.interpreter.StreamExecutor.fork_start_text_pos", "modulename": "sglang.lang.interpreter", "qualname": "StreamExecutor.fork_start_text_pos", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "sglang.lang.interpreter.StreamExecutor.num_api_spec_tokens", "modulename": "sglang.lang.interpreter", "qualname": "StreamExecutor.num_api_spec_tokens", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "sglang.lang.interpreter.StreamExecutor.speculated_text", "modulename": "sglang.lang.interpreter", "qualname": "StreamExecutor.speculated_text", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "sglang.lang.interpreter.StreamExecutor.use_thread", "modulename": "sglang.lang.interpreter", "qualname": "StreamExecutor.use_thread", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "sglang.lang.interpreter.StreamExecutor.submit", "modulename": "sglang.lang.interpreter", "qualname": "StreamExecutor.submit", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">expr</span><span class=\"p\">:</span> <span class=\"n\">sglang</span><span class=\"o\">.</span><span class=\"n\">lang</span><span class=\"o\">.</span><span class=\"n\">ir</span><span class=\"o\">.</span><span class=\"n\">SglExpr</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.lang.interpreter.StreamExecutor.sync", "modulename": "sglang.lang.interpreter", "qualname": "StreamExecutor.sync", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.lang.interpreter.StreamExecutor.get_var", "modulename": "sglang.lang.interpreter", "qualname": "StreamExecutor.get_var", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">name</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.lang.interpreter.StreamExecutor.set_var", "modulename": "sglang.lang.interpreter", "qualname": "StreamExecutor.set_var", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">name</span>, </span><span class=\"param\"><span class=\"n\">value</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.lang.interpreter.StreamExecutor.get_meta_info", "modulename": "sglang.lang.interpreter", "qualname": "StreamExecutor.get_meta_info", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">name</span>, </span><span class=\"param\"><span class=\"n\">timeout</span><span class=\"o\">=</span><span class=\"kc\">None</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.lang.interpreter.StreamExecutor.fork", "modulename": "sglang.lang.interpreter", "qualname": "StreamExecutor.fork", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">size</span><span class=\"p\">:</span> <span class=\"nb\">int</span> <span class=\"o\">=</span> <span class=\"mi\">1</span>, </span><span class=\"param\"><span class=\"n\">position_ids_offset</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"n\">List</span><span class=\"p\">[</span><span class=\"nb\">int</span><span class=\"p\">]]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.lang.interpreter.StreamExecutor.text", "modulename": "sglang.lang.interpreter", "qualname": "StreamExecutor.text", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.lang.interpreter.StreamExecutor.messages", "modulename": "sglang.lang.interpreter", "qualname": "StreamExecutor.messages", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.lang.interpreter.StreamExecutor.error", "modulename": "sglang.lang.interpreter", "qualname": "StreamExecutor.error", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.lang.interpreter.StreamExecutor.end", "modulename": "sglang.lang.interpreter", "qualname": "StreamExecutor.end", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.lang.interpreter.ProgramState", "modulename": "sglang.lang.interpreter", "qualname": "ProgramState", "kind": "class", "doc": "<p>The state of an SGL program.</p>\n"}, {"fullname": "sglang.lang.interpreter.ProgramState.__init__", "modulename": "sglang.lang.interpreter", "qualname": "ProgramState.__init__", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">stream_executor</span><span class=\"p\">:</span> <span class=\"n\">sglang</span><span class=\"o\">.</span><span class=\"n\">lang</span><span class=\"o\">.</span><span class=\"n\">interpreter</span><span class=\"o\">.</span><span class=\"n\">StreamExecutor</span></span>)</span>"}, {"fullname": "sglang.lang.interpreter.ProgramState.stream_executor", "modulename": "sglang.lang.interpreter", "qualname": "ProgramState.stream_executor", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "sglang.lang.interpreter.ProgramState.system", "modulename": "sglang.lang.interpreter", "qualname": "ProgramState.system", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">expr</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"n\">sglang</span><span class=\"o\">.</span><span class=\"n\">lang</span><span class=\"o\">.</span><span class=\"n\">ir</span><span class=\"o\">.</span><span class=\"n\">SglExpr</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.lang.interpreter.ProgramState.user", "modulename": "sglang.lang.interpreter", "qualname": "ProgramState.user", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">expr</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"n\">sglang</span><span class=\"o\">.</span><span class=\"n\">lang</span><span class=\"o\">.</span><span class=\"n\">ir</span><span class=\"o\">.</span><span class=\"n\">SglExpr</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.lang.interpreter.ProgramState.assistant", "modulename": "sglang.lang.interpreter", "qualname": "ProgramState.assistant", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">expr</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"n\">sglang</span><span class=\"o\">.</span><span class=\"n\">lang</span><span class=\"o\">.</span><span class=\"n\">ir</span><span class=\"o\">.</span><span class=\"n\">SglExpr</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.lang.interpreter.ProgramState.var_scope", "modulename": "sglang.lang.interpreter", "qualname": "ProgramState.var_scope", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">name</span><span class=\"p\">:</span> <span class=\"nb\">str</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.lang.interpreter.ProgramState.fork", "modulename": "sglang.lang.interpreter", "qualname": "ProgramState.fork", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">size</span><span class=\"p\">:</span> <span class=\"nb\">int</span> <span class=\"o\">=</span> <span class=\"mi\">1</span>, </span><span class=\"param\"><span class=\"n\">position_ids_offset</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"n\">List</span><span class=\"p\">[</span><span class=\"nb\">int</span><span class=\"p\">]]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.lang.interpreter.ProgramState.copy", "modulename": "sglang.lang.interpreter", "qualname": "ProgramState.copy", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">position_ids_offset</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"n\">List</span><span class=\"p\">[</span><span class=\"nb\">int</span><span class=\"p\">]]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.lang.interpreter.ProgramState.text", "modulename": "sglang.lang.interpreter", "qualname": "ProgramState.text", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.lang.interpreter.ProgramState.messages", "modulename": "sglang.lang.interpreter", "qualname": "ProgramState.messages", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.lang.interpreter.ProgramState.sync", "modulename": "sglang.lang.interpreter", "qualname": "ProgramState.sync", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.lang.interpreter.ProgramState.error", "modulename": "sglang.lang.interpreter", "qualname": "ProgramState.error", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.lang.interpreter.ProgramState.text_iter", "modulename": "sglang.lang.interpreter", "qualname": "ProgramState.text_iter", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">var_name</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"nb\">str</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.lang.interpreter.ProgramState.text_async_iter", "modulename": "sglang.lang.interpreter", "qualname": "ProgramState.text_async_iter", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">var_name</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"nb\">str</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>, </span><span class=\"param\"><span class=\"n\">return_meta_data</span><span class=\"p\">:</span> <span class=\"nb\">bool</span> <span class=\"o\">=</span> <span class=\"kc\">False</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "async def"}, {"fullname": "sglang.lang.interpreter.ProgramState.get_var", "modulename": "sglang.lang.interpreter", "qualname": "ProgramState.get_var", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">name</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.lang.interpreter.ProgramState.set_var", "modulename": "sglang.lang.interpreter", "qualname": "ProgramState.set_var", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">name</span>, </span><span class=\"param\"><span class=\"n\">value</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.lang.interpreter.ProgramState.get_meta_info", "modulename": "sglang.lang.interpreter", "qualname": "ProgramState.get_meta_info", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">name</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.lang.interpreter.ProgramStateGroup", "modulename": "sglang.lang.interpreter", "qualname": "ProgramStateGroup", "kind": "class", "doc": "<p></p>\n"}, {"fullname": "sglang.lang.interpreter.ProgramStateGroup.__init__", "modulename": "sglang.lang.interpreter", "qualname": "ProgramStateGroup.__init__", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">states</span><span class=\"p\">:</span> <span class=\"n\">List</span><span class=\"p\">[</span><span class=\"n\">sglang</span><span class=\"o\">.</span><span class=\"n\">lang</span><span class=\"o\">.</span><span class=\"n\">interpreter</span><span class=\"o\">.</span><span class=\"n\">ProgramState</span><span class=\"p\">]</span>,</span><span class=\"param\">\t<span class=\"n\">src_state</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"n\">sglang</span><span class=\"o\">.</span><span class=\"n\">lang</span><span class=\"o\">.</span><span class=\"n\">interpreter</span><span class=\"o\">.</span><span class=\"n\">ProgramState</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span></span>)</span>"}, {"fullname": "sglang.lang.interpreter.ProgramStateGroup.states", "modulename": "sglang.lang.interpreter", "qualname": "ProgramStateGroup.states", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "sglang.lang.interpreter.ProgramStateGroup.src_state", "modulename": "sglang.lang.interpreter", "qualname": "ProgramStateGroup.src_state", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "sglang.lang.interpreter.ProgramStateGroup.join", "modulename": "sglang.lang.interpreter", "qualname": "ProgramStateGroup.join", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">mode</span><span class=\"p\">:</span> <span class=\"nb\">str</span> <span class=\"o\">=</span> <span class=\"s1\">&#39;gather_variable&#39;</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.lang.ir", "modulename": "sglang.lang.ir", "kind": "module", "doc": "<p>The intermediate representation.</p>\n"}, {"fullname": "sglang.lang.ir.REGEX_INT", "modulename": "sglang.lang.ir", "qualname": "REGEX_INT", "kind": "variable", "doc": "<p></p>\n", "default_value": "&#x27;[-+]?[0-9]+[ \\\\n]*&#x27;"}, {"fullname": "sglang.lang.ir.REGEX_FLOAT", "modulename": "sglang.lang.ir", "qualname": "REGEX_FLOAT", "kind": "variable", "doc": "<p></p>\n", "default_value": "&#x27;[-+]?[0-9]*\\\\.?[0-9]+[ \\\\n]*&#x27;"}, {"fullname": "sglang.lang.ir.REGEX_BOOL", "modulename": "sglang.lang.ir", "qualname": "REGEX_BOOL", "kind": "variable", "doc": "<p></p>\n", "default_value": "&#x27;(True|False)&#x27;"}, {"fullname": "sglang.lang.ir.REGEX_STR", "modulename": "sglang.lang.ir", "qualname": "REGEX_STR", "kind": "variable", "doc": "<p></p>\n", "default_value": "&#x27;\\\\&quot;[\\\\w\\\\d\\\\s]*\\\\&quot;&#x27;"}, {"fullname": "sglang.lang.ir.SglSamplingParams", "modulename": "sglang.lang.ir", "qualname": "SglSamplingParams", "kind": "class", "doc": "<p></p>\n"}, {"fullname": "sglang.lang.ir.SglSamplingParams.__init__", "modulename": "sglang.lang.ir", "qualname": "SglSamplingParams.__init__", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">max_new_tokens</span><span class=\"p\">:</span> <span class=\"nb\">int</span> <span class=\"o\">=</span> <span class=\"mi\">128</span>,</span><span class=\"param\">\t<span class=\"n\">min_new_tokens</span><span class=\"p\">:</span> <span class=\"nb\">int</span> <span class=\"o\">=</span> <span class=\"mi\">0</span>,</span><span class=\"param\">\t<span class=\"n\">n</span><span class=\"p\">:</span> <span class=\"nb\">int</span> <span class=\"o\">=</span> <span class=\"mi\">1</span>,</span><span class=\"param\">\t<span class=\"n\">stop</span><span class=\"p\">:</span> <span class=\"n\">Union</span><span class=\"p\">[</span><span class=\"nb\">str</span><span class=\"p\">,</span> <span class=\"n\">List</span><span class=\"p\">[</span><span class=\"nb\">str</span><span class=\"p\">]]</span> <span class=\"o\">=</span> <span class=\"p\">()</span>,</span><span class=\"param\">\t<span class=\"n\">stop_token_ids</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"n\">List</span><span class=\"p\">[</span><span class=\"nb\">int</span><span class=\"p\">]]</span> <span class=\"o\">=</span> <span class=\"p\">()</span>,</span><span class=\"param\">\t<span class=\"n\">temperature</span><span class=\"p\">:</span> <span class=\"nb\">float</span> <span class=\"o\">=</span> <span class=\"mf\">1.0</span>,</span><span class=\"param\">\t<span class=\"n\">top_p</span><span class=\"p\">:</span> <span class=\"nb\">float</span> <span class=\"o\">=</span> <span class=\"mf\">1.0</span>,</span><span class=\"param\">\t<span class=\"n\">top_k</span><span class=\"p\">:</span> <span class=\"nb\">int</span> <span class=\"o\">=</span> <span class=\"o\">-</span><span class=\"mi\">1</span>,</span><span class=\"param\">\t<span class=\"n\">min_p</span><span class=\"p\">:</span> <span class=\"nb\">float</span> <span class=\"o\">=</span> <span class=\"mf\">0.0</span>,</span><span class=\"param\">\t<span class=\"n\">frequency_penalty</span><span class=\"p\">:</span> <span class=\"nb\">float</span> <span class=\"o\">=</span> <span class=\"mf\">0.0</span>,</span><span class=\"param\">\t<span class=\"n\">presence_penalty</span><span class=\"p\">:</span> <span class=\"nb\">float</span> <span class=\"o\">=</span> <span class=\"mf\">0.0</span>,</span><span class=\"param\">\t<span class=\"n\">ignore_eos</span><span class=\"p\">:</span> <span class=\"nb\">bool</span> <span class=\"o\">=</span> <span class=\"kc\">False</span>,</span><span class=\"param\">\t<span class=\"n\">return_logprob</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"nb\">bool</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">logprob_start_len</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"nb\">int</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"p\">(</span><span class=\"kc\">None</span><span class=\"p\">,)</span>,</span><span class=\"param\">\t<span class=\"n\">top_logprobs_num</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"nb\">int</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"p\">(</span><span class=\"kc\">None</span><span class=\"p\">,)</span>,</span><span class=\"param\">\t<span class=\"n\">return_text_in_logprobs</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"nb\">bool</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"p\">(</span><span class=\"kc\">None</span><span class=\"p\">,)</span>,</span><span class=\"param\">\t<span class=\"n\">json_schema</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"nb\">str</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">dtype</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"nb\">str</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">regex</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"nb\">str</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span></span>)</span>"}, {"fullname": "sglang.lang.ir.SglSamplingParams.max_new_tokens", "modulename": "sglang.lang.ir", "qualname": "SglSamplingParams.max_new_tokens", "kind": "variable", "doc": "<p></p>\n", "annotation": ": int", "default_value": "128"}, {"fullname": "sglang.lang.ir.SglSamplingParams.min_new_tokens", "modulename": "sglang.lang.ir", "qualname": "SglSamplingParams.min_new_tokens", "kind": "variable", "doc": "<p></p>\n", "annotation": ": int", "default_value": "0"}, {"fullname": "sglang.lang.ir.SglSamplingParams.n", "modulename": "sglang.lang.ir", "qualname": "SglSamplingParams.n", "kind": "variable", "doc": "<p></p>\n", "annotation": ": int", "default_value": "1"}, {"fullname": "sglang.lang.ir.SglSamplingParams.stop", "modulename": "sglang.lang.ir", "qualname": "SglSamplingParams.stop", "kind": "variable", "doc": "<p></p>\n", "annotation": ": Union[str, List[str]]", "default_value": "()"}, {"fullname": "sglang.lang.ir.SglSamplingParams.stop_token_ids", "modulename": "sglang.lang.ir", "qualname": "SglSamplingParams.stop_token_ids", "kind": "variable", "doc": "<p></p>\n", "annotation": ": Optional[List[int]]", "default_value": "()"}, {"fullname": "sglang.lang.ir.SglSamplingParams.temperature", "modulename": "sglang.lang.ir", "qualname": "SglSamplingParams.temperature", "kind": "variable", "doc": "<p></p>\n", "annotation": ": float", "default_value": "1.0"}, {"fullname": "sglang.lang.ir.SglSamplingParams.top_p", "modulename": "sglang.lang.ir", "qualname": "SglSamplingParams.top_p", "kind": "variable", "doc": "<p></p>\n", "annotation": ": float", "default_value": "1.0"}, {"fullname": "sglang.lang.ir.SglSamplingParams.top_k", "modulename": "sglang.lang.ir", "qualname": "SglSamplingParams.top_k", "kind": "variable", "doc": "<p></p>\n", "annotation": ": int", "default_value": "-1"}, {"fullname": "sglang.lang.ir.SglSamplingParams.min_p", "modulename": "sglang.lang.ir", "qualname": "SglSamplingParams.min_p", "kind": "variable", "doc": "<p></p>\n", "annotation": ": float", "default_value": "0.0"}, {"fullname": "sglang.lang.ir.SglSamplingParams.frequency_penalty", "modulename": "sglang.lang.ir", "qualname": "SglSamplingParams.frequency_penalty", "kind": "variable", "doc": "<p></p>\n", "annotation": ": float", "default_value": "0.0"}, {"fullname": "sglang.lang.ir.SglSamplingParams.presence_penalty", "modulename": "sglang.lang.ir", "qualname": "SglSamplingParams.presence_penalty", "kind": "variable", "doc": "<p></p>\n", "annotation": ": float", "default_value": "0.0"}, {"fullname": "sglang.lang.ir.SglSamplingParams.ignore_eos", "modulename": "sglang.lang.ir", "qualname": "SglSamplingParams.ignore_eos", "kind": "variable", "doc": "<p></p>\n", "annotation": ": bool", "default_value": "False"}, {"fullname": "sglang.lang.ir.SglSamplingParams.return_logprob", "modulename": "sglang.lang.ir", "qualname": "SglSamplingParams.return_logprob", "kind": "variable", "doc": "<p></p>\n", "annotation": ": Optional[bool]", "default_value": "None"}, {"fullname": "sglang.lang.ir.SglSamplingParams.logprob_start_len", "modulename": "sglang.lang.ir", "qualname": "SglSamplingParams.logprob_start_len", "kind": "variable", "doc": "<p></p>\n", "annotation": ": Optional[int]", "default_value": "(None,)"}, {"fullname": "sglang.lang.ir.SglSamplingParams.top_logprobs_num", "modulename": "sglang.lang.ir", "qualname": "SglSamplingParams.top_logprobs_num", "kind": "variable", "doc": "<p></p>\n", "annotation": ": Optional[int]", "default_value": "(None,)"}, {"fullname": "sglang.lang.ir.SglSamplingParams.return_text_in_logprobs", "modulename": "sglang.lang.ir", "qualname": "SglSamplingParams.return_text_in_logprobs", "kind": "variable", "doc": "<p></p>\n", "annotation": ": Optional[bool]", "default_value": "(None,)"}, {"fullname": "sglang.lang.ir.SglSamplingParams.json_schema", "modulename": "sglang.lang.ir", "qualname": "SglSamplingParams.json_schema", "kind": "variable", "doc": "<p></p>\n", "annotation": ": Optional[str]", "default_value": "None"}, {"fullname": "sglang.lang.ir.SglSamplingParams.dtype", "modulename": "sglang.lang.ir", "qualname": "SglSamplingParams.dtype", "kind": "variable", "doc": "<p></p>\n", "annotation": ": Optional[str]", "default_value": "None"}, {"fullname": "sglang.lang.ir.SglSamplingParams.regex", "modulename": "sglang.lang.ir", "qualname": "SglSamplingParams.regex", "kind": "variable", "doc": "<p></p>\n", "annotation": ": Optional[str]", "default_value": "None"}, {"fullname": "sglang.lang.ir.SglSamplingParams.clone", "modulename": "sglang.lang.ir", "qualname": "SglSamplingParams.clone", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.lang.ir.SglSamplingParams.to_openai_kwargs", "modulename": "sglang.lang.ir", "qualname": "SglSamplingParams.to_openai_kwargs", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.lang.ir.SglSamplingParams.to_vertexai_kwargs", "modulename": "sglang.lang.ir", "qualname": "SglSamplingParams.to_vertexai_kwargs", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.lang.ir.SglSamplingParams.to_anthropic_kwargs", "modulename": "sglang.lang.ir", "qualname": "SglSamplingParams.to_anthropic_kwargs", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.lang.ir.SglSamplingParams.to_litellm_kwargs", "modulename": "sglang.lang.ir", "qualname": "SglSamplingParams.to_litellm_kwargs", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.lang.ir.SglSamplingParams.to_srt_kwargs", "modulename": "sglang.lang.ir", "qualname": "SglSamplingParams.to_srt_kwargs", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.lang.ir.SglFunction", "modulename": "sglang.lang.ir", "qualname": "SglFunction", "kind": "class", "doc": "<p></p>\n"}, {"fullname": "sglang.lang.ir.SglFunction.__init__", "modulename": "sglang.lang.ir", "qualname": "SglFunction.__init__", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">func</span>, </span><span class=\"param\"><span class=\"n\">num_api_spec_tokens</span><span class=\"o\">=</span><span class=\"kc\">None</span>, </span><span class=\"param\"><span class=\"n\">bind_arguments</span><span class=\"o\">=</span><span class=\"kc\">None</span></span>)</span>"}, {"fullname": "sglang.lang.ir.SglFunction.func", "modulename": "sglang.lang.ir", "qualname": "SglFunction.func", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "sglang.lang.ir.SglFunction.num_api_spec_tokens", "modulename": "sglang.lang.ir", "qualname": "SglFunction.num_api_spec_tokens", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "sglang.lang.ir.SglFunction.bind_arguments", "modulename": "sglang.lang.ir", "qualname": "SglFunction.bind_arguments", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "sglang.lang.ir.SglFunction.pin_prefix_rid", "modulename": "sglang.lang.ir", "qualname": "SglFunction.pin_prefix_rid", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "sglang.lang.ir.SglFunction.arg_names", "modulename": "sglang.lang.ir", "qualname": "SglFunction.arg_names", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "sglang.lang.ir.SglFunction.arg_defaults", "modulename": "sglang.lang.ir", "qualname": "SglFunction.arg_defaults", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "sglang.lang.ir.SglFunction.bind", "modulename": "sglang.lang.ir", "qualname": "SglFunction.bind", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"o\">**</span><span class=\"n\">kwargs</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.lang.ir.SglFunction.run", "modulename": "sglang.lang.ir", "qualname": "SglFunction.run", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"bp\">self</span>,</span><span class=\"param\">\t<span class=\"o\">*</span><span class=\"n\">args</span>,</span><span class=\"param\">\t<span class=\"n\">max_new_tokens</span><span class=\"p\">:</span> <span class=\"nb\">int</span> <span class=\"o\">=</span> <span class=\"mi\">128</span>,</span><span class=\"param\">\t<span class=\"n\">n</span><span class=\"p\">:</span> <span class=\"nb\">int</span> <span class=\"o\">=</span> <span class=\"mi\">1</span>,</span><span class=\"param\">\t<span class=\"n\">stop</span><span class=\"p\">:</span> <span class=\"n\">Union</span><span class=\"p\">[</span><span class=\"nb\">str</span><span class=\"p\">,</span> <span class=\"n\">List</span><span class=\"p\">[</span><span class=\"nb\">str</span><span class=\"p\">],</span> <span class=\"n\">NoneType</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">stop_token_ids</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"n\">List</span><span class=\"p\">[</span><span class=\"nb\">int</span><span class=\"p\">]]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">temperature</span><span class=\"p\">:</span> <span class=\"nb\">float</span> <span class=\"o\">=</span> <span class=\"mf\">1.0</span>,</span><span class=\"param\">\t<span class=\"n\">top_p</span><span class=\"p\">:</span> <span class=\"nb\">float</span> <span class=\"o\">=</span> <span class=\"mf\">1.0</span>,</span><span class=\"param\">\t<span class=\"n\">top_k</span><span class=\"p\">:</span> <span class=\"nb\">int</span> <span class=\"o\">=</span> <span class=\"o\">-</span><span class=\"mi\">1</span>,</span><span class=\"param\">\t<span class=\"n\">min_p</span><span class=\"p\">:</span> <span class=\"nb\">float</span> <span class=\"o\">=</span> <span class=\"mf\">0.0</span>,</span><span class=\"param\">\t<span class=\"n\">frequency_penalty</span><span class=\"p\">:</span> <span class=\"nb\">float</span> <span class=\"o\">=</span> <span class=\"mf\">0.0</span>,</span><span class=\"param\">\t<span class=\"n\">presence_penalty</span><span class=\"p\">:</span> <span class=\"nb\">float</span> <span class=\"o\">=</span> <span class=\"mf\">0.0</span>,</span><span class=\"param\">\t<span class=\"n\">ignore_eos</span><span class=\"p\">:</span> <span class=\"nb\">bool</span> <span class=\"o\">=</span> <span class=\"kc\">False</span>,</span><span class=\"param\">\t<span class=\"n\">return_logprob</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"nb\">bool</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">logprob_start_len</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"nb\">int</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">top_logprobs_num</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"nb\">int</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">return_text_in_logprobs</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"nb\">bool</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">stream</span><span class=\"p\">:</span> <span class=\"nb\">bool</span> <span class=\"o\">=</span> <span class=\"kc\">False</span>,</span><span class=\"param\">\t<span class=\"n\">backend</span><span class=\"o\">=</span><span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">use_thread</span><span class=\"p\">:</span> <span class=\"nb\">bool</span> <span class=\"o\">=</span> <span class=\"kc\">True</span>,</span><span class=\"param\">\t<span class=\"o\">**</span><span class=\"n\">kwargs</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.lang.ir.SglFunction.run_batch", "modulename": "sglang.lang.ir", "qualname": "SglFunction.run_batch", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"bp\">self</span>,</span><span class=\"param\">\t<span class=\"n\">batch_kwargs</span>,</span><span class=\"param\">\t<span class=\"o\">*</span>,</span><span class=\"param\">\t<span class=\"n\">max_new_tokens</span><span class=\"p\">:</span> <span class=\"nb\">int</span> <span class=\"o\">=</span> <span class=\"mi\">128</span>,</span><span class=\"param\">\t<span class=\"n\">n</span><span class=\"p\">:</span> <span class=\"nb\">int</span> <span class=\"o\">=</span> <span class=\"mi\">1</span>,</span><span class=\"param\">\t<span class=\"n\">stop</span><span class=\"p\">:</span> <span class=\"n\">Union</span><span class=\"p\">[</span><span class=\"nb\">str</span><span class=\"p\">,</span> <span class=\"n\">List</span><span class=\"p\">[</span><span class=\"nb\">str</span><span class=\"p\">],</span> <span class=\"n\">NoneType</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">stop_token_ids</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"n\">List</span><span class=\"p\">[</span><span class=\"nb\">int</span><span class=\"p\">]]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">temperature</span><span class=\"p\">:</span> <span class=\"nb\">float</span> <span class=\"o\">=</span> <span class=\"mf\">1.0</span>,</span><span class=\"param\">\t<span class=\"n\">top_p</span><span class=\"p\">:</span> <span class=\"nb\">float</span> <span class=\"o\">=</span> <span class=\"mf\">1.0</span>,</span><span class=\"param\">\t<span class=\"n\">top_k</span><span class=\"p\">:</span> <span class=\"nb\">int</span> <span class=\"o\">=</span> <span class=\"o\">-</span><span class=\"mi\">1</span>,</span><span class=\"param\">\t<span class=\"n\">min_p</span><span class=\"p\">:</span> <span class=\"nb\">float</span> <span class=\"o\">=</span> <span class=\"mf\">0.0</span>,</span><span class=\"param\">\t<span class=\"n\">frequency_penalty</span><span class=\"p\">:</span> <span class=\"nb\">float</span> <span class=\"o\">=</span> <span class=\"mf\">0.0</span>,</span><span class=\"param\">\t<span class=\"n\">presence_penalty</span><span class=\"p\">:</span> <span class=\"nb\">float</span> <span class=\"o\">=</span> <span class=\"mf\">0.0</span>,</span><span class=\"param\">\t<span class=\"n\">ignore_eos</span><span class=\"p\">:</span> <span class=\"nb\">bool</span> <span class=\"o\">=</span> <span class=\"kc\">False</span>,</span><span class=\"param\">\t<span class=\"n\">return_logprob</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"nb\">bool</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">logprob_start_len</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"nb\">int</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">top_logprobs_num</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"nb\">int</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">return_text_in_logprobs</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"nb\">bool</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">backend</span><span class=\"o\">=</span><span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">num_threads</span><span class=\"p\">:</span> <span class=\"n\">Union</span><span class=\"p\">[</span><span class=\"nb\">str</span><span class=\"p\">,</span> <span class=\"nb\">int</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"s1\">&#39;auto&#39;</span>,</span><span class=\"param\">\t<span class=\"n\">progress_bar</span><span class=\"p\">:</span> <span class=\"nb\">bool</span> <span class=\"o\">=</span> <span class=\"kc\">False</span>,</span><span class=\"param\">\t<span class=\"n\">generator_style</span><span class=\"p\">:</span> <span class=\"nb\">bool</span> <span class=\"o\">=</span> <span class=\"kc\">False</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.lang.ir.SglFunction.trace", "modulename": "sglang.lang.ir", "qualname": "SglFunction.trace", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"o\">*</span>, </span><span class=\"param\"><span class=\"n\">backend</span><span class=\"o\">=</span><span class=\"kc\">None</span>, </span><span class=\"param\"><span class=\"o\">**</span><span class=\"n\">kwargs</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.lang.ir.SglFunction.cache", "modulename": "sglang.lang.ir", "qualname": "SglFunction.cache", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">backend</span><span class=\"o\">=</span><span class=\"kc\">None</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.lang.ir.SglFunction.compile", "modulename": "sglang.lang.ir", "qualname": "SglFunction.compile", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"o\">*</span>, </span><span class=\"param\"><span class=\"n\">backend</span><span class=\"o\">=</span><span class=\"kc\">None</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.lang.ir.SglExpr", "modulename": "sglang.lang.ir", "qualname": "SglExpr", "kind": "class", "doc": "<p></p>\n"}, {"fullname": "sglang.lang.ir.SglExpr.node_ct", "modulename": "sglang.lang.ir", "qualname": "SglExpr.node_ct", "kind": "variable", "doc": "<p></p>\n", "default_value": "0"}, {"fullname": "sglang.lang.ir.SglExpr.node_id", "modulename": "sglang.lang.ir", "qualname": "SglExpr.node_id", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "sglang.lang.ir.SglExpr.prev_node", "modulename": "sglang.lang.ir", "qualname": "SglExpr.prev_node", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "sglang.lang.ir.SglExpr.pid", "modulename": "sglang.lang.ir", "qualname": "SglExpr.pid", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "sglang.lang.ir.SglExpr.concatenate_ir", "modulename": "sglang.lang.ir", "qualname": "SglExpr.concatenate_ir", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">a</span>, </span><span class=\"param\"><span class=\"n\">b</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.lang.ir.SglExpr.print_graph_dfs", "modulename": "sglang.lang.ir", "qualname": "SglExpr.print_graph_dfs", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.lang.ir.SglExprList", "modulename": "sglang.lang.ir", "qualname": "SglExprList", "kind": "class", "doc": "<p></p>\n", "bases": "SglExpr"}, {"fullname": "sglang.lang.ir.SglExprList.__init__", "modulename": "sglang.lang.ir", "qualname": "SglExprList.__init__", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">expr_list</span><span class=\"p\">:</span> <span class=\"n\">List</span><span class=\"p\">[</span><span class=\"n\">sglang</span><span class=\"o\">.</span><span class=\"n\">lang</span><span class=\"o\">.</span><span class=\"n\">ir</span><span class=\"o\">.</span><span class=\"n\">SglExpr</span><span class=\"p\">]</span></span>)</span>"}, {"fullname": "sglang.lang.ir.SglExprList.expr_list", "modulename": "sglang.lang.ir", "qualname": "SglExprList.expr_list", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "sglang.lang.ir.SglArgument", "modulename": "sglang.lang.ir", "qualname": "SglArgument", "kind": "class", "doc": "<p></p>\n", "bases": "SglExpr"}, {"fullname": "sglang.lang.ir.SglArgument.__init__", "modulename": "sglang.lang.ir", "qualname": "SglArgument.__init__", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">name</span><span class=\"p\">:</span> <span class=\"nb\">str</span>, </span><span class=\"param\"><span class=\"n\">value</span><span class=\"p\">:</span> <span class=\"nb\">str</span></span>)</span>"}, {"fullname": "sglang.lang.ir.SglArgument.name", "modulename": "sglang.lang.ir", "qualname": "SglArgument.name", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "sglang.lang.ir.SglArgument.value", "modulename": "sglang.lang.ir", "qualname": "SglArgument.value", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "sglang.lang.ir.SglImage", "modulename": "sglang.lang.ir", "qualname": "SglImage", "kind": "class", "doc": "<p></p>\n", "bases": "SglExpr"}, {"fullname": "sglang.lang.ir.SglImage.__init__", "modulename": "sglang.lang.ir", "qualname": "SglImage.__init__", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">path</span><span class=\"p\">:</span> <span class=\"nb\">str</span></span>)</span>"}, {"fullname": "sglang.lang.ir.SglImage.path", "modulename": "sglang.lang.ir", "qualname": "SglImage.path", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "sglang.lang.ir.SglVideo", "modulename": "sglang.lang.ir", "qualname": "SglVideo", "kind": "class", "doc": "<p></p>\n", "bases": "SglExpr"}, {"fullname": "sglang.lang.ir.SglVideo.__init__", "modulename": "sglang.lang.ir", "qualname": "SglVideo.__init__", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">path</span><span class=\"p\">:</span> <span class=\"nb\">str</span>, </span><span class=\"param\"><span class=\"n\">num_frames</span><span class=\"p\">:</span> <span class=\"nb\">int</span></span>)</span>"}, {"fullname": "sglang.lang.ir.SglVideo.path", "modulename": "sglang.lang.ir", "qualname": "SglVideo.path", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "sglang.lang.ir.SglVideo.num_frames", "modulename": "sglang.lang.ir", "qualname": "SglVideo.num_frames", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "sglang.lang.ir.SglGen", "modulename": "sglang.lang.ir", "qualname": "SglGen", "kind": "class", "doc": "<p></p>\n", "bases": "SglExpr"}, {"fullname": "sglang.lang.ir.SglGen.__init__", "modulename": "sglang.lang.ir", "qualname": "SglGen.__init__", "kind": "function", "doc": "<p>Call the model to generate. See the meaning of the arguments in docs/backend/sampling_params.md</p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">name</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"nb\">str</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">max_new_tokens</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"nb\">int</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">min_new_tokens</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"nb\">int</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">n</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"nb\">int</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">stop</span><span class=\"p\">:</span> <span class=\"n\">Union</span><span class=\"p\">[</span><span class=\"nb\">str</span><span class=\"p\">,</span> <span class=\"n\">List</span><span class=\"p\">[</span><span class=\"nb\">str</span><span class=\"p\">],</span> <span class=\"n\">NoneType</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">stop_token_ids</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"n\">List</span><span class=\"p\">[</span><span class=\"nb\">int</span><span class=\"p\">]]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">temperature</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"nb\">float</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">top_p</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"nb\">float</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">top_k</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"nb\">int</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">min_p</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"nb\">float</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">frequency_penalty</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"nb\">float</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">presence_penalty</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"nb\">float</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">ignore_eos</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"nb\">bool</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">return_logprob</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"nb\">bool</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">logprob_start_len</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"nb\">int</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">top_logprobs_num</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"nb\">int</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">return_text_in_logprobs</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"nb\">bool</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">dtype</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"nb\">type</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">regex</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"nb\">str</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">json_schema</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"nb\">str</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span></span>)</span>"}, {"fullname": "sglang.lang.ir.SglGen.name", "modulename": "sglang.lang.ir", "qualname": "SglGen.name", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "sglang.lang.ir.SglGen.sampling_params", "modulename": "sglang.lang.ir", "qualname": "SglGen.sampling_params", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "sglang.lang.ir.SglConstantText", "modulename": "sglang.lang.ir", "qualname": "SglConstantText", "kind": "class", "doc": "<p></p>\n", "bases": "SglExpr"}, {"fullname": "sglang.lang.ir.SglConstantText.__init__", "modulename": "sglang.lang.ir", "qualname": "SglConstantText.__init__", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">value</span><span class=\"p\">:</span> <span class=\"nb\">str</span></span>)</span>"}, {"fullname": "sglang.lang.ir.SglConstantText.value", "modulename": "sglang.lang.ir", "qualname": "SglConstantText.value", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "sglang.lang.ir.SglRoleBegin", "modulename": "sglang.lang.ir", "qualname": "SglRoleBegin", "kind": "class", "doc": "<p></p>\n", "bases": "SglExpr"}, {"fullname": "sglang.lang.ir.SglRoleBegin.__init__", "modulename": "sglang.lang.ir", "qualname": "SglRoleBegin.__init__", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">role</span><span class=\"p\">:</span> <span class=\"nb\">str</span></span>)</span>"}, {"fullname": "sglang.lang.ir.SglRoleBegin.role", "modulename": "sglang.lang.ir", "qualname": "SglRoleBegin.role", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "sglang.lang.ir.SglRoleEnd", "modulename": "sglang.lang.ir", "qualname": "SglRoleEnd", "kind": "class", "doc": "<p></p>\n", "bases": "SglExpr"}, {"fullname": "sglang.lang.ir.SglRoleEnd.__init__", "modulename": "sglang.lang.ir", "qualname": "SglRoleEnd.__init__", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">role</span><span class=\"p\">:</span> <span class=\"nb\">str</span></span>)</span>"}, {"fullname": "sglang.lang.ir.SglRoleEnd.role", "modulename": "sglang.lang.ir", "qualname": "SglRoleEnd.role", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "sglang.lang.ir.SglSelect", "modulename": "sglang.lang.ir", "qualname": "SglSelect", "kind": "class", "doc": "<p></p>\n", "bases": "SglExpr"}, {"fullname": "sglang.lang.ir.SglSelect.__init__", "modulename": "sglang.lang.ir", "qualname": "SglSelect.__init__", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">name</span><span class=\"p\">:</span> <span class=\"nb\">str</span>,</span><span class=\"param\">\t<span class=\"n\">choices</span><span class=\"p\">:</span> <span class=\"n\">List</span><span class=\"p\">[</span><span class=\"nb\">str</span><span class=\"p\">]</span>,</span><span class=\"param\">\t<span class=\"n\">temperature</span><span class=\"p\">:</span> <span class=\"nb\">float</span>,</span><span class=\"param\">\t<span class=\"n\">choices_method</span><span class=\"p\">:</span> <span class=\"n\">sglang</span><span class=\"o\">.</span><span class=\"n\">lang</span><span class=\"o\">.</span><span class=\"n\">choices</span><span class=\"o\">.</span><span class=\"n\">ChoicesSamplingMethod</span></span>)</span>"}, {"fullname": "sglang.lang.ir.SglSelect.name", "modulename": "sglang.lang.ir", "qualname": "SglSelect.name", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "sglang.lang.ir.SglSelect.choices", "modulename": "sglang.lang.ir", "qualname": "SglSelect.choices", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "sglang.lang.ir.SglSelect.temperature", "modulename": "sglang.lang.ir", "qualname": "SglSelect.temperature", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "sglang.lang.ir.SglSelect.choices_method", "modulename": "sglang.lang.ir", "qualname": "SglSelect.choices_method", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "sglang.lang.ir.SglFork", "modulename": "sglang.lang.ir", "qualname": "SglFork", "kind": "class", "doc": "<p></p>\n", "bases": "SglExpr"}, {"fullname": "sglang.lang.ir.SglFork.__init__", "modulename": "sglang.lang.ir", "qualname": "SglFork.__init__", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">number</span><span class=\"p\">:</span> <span class=\"nb\">int</span>, </span><span class=\"param\"><span class=\"n\">position_ids_offset</span><span class=\"o\">=</span><span class=\"kc\">None</span></span>)</span>"}, {"fullname": "sglang.lang.ir.SglFork.number", "modulename": "sglang.lang.ir", "qualname": "SglFork.number", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "sglang.lang.ir.SglFork.position_ids_offset", "modulename": "sglang.lang.ir", "qualname": "SglFork.position_ids_offset", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "sglang.lang.ir.SglGetForkItem", "modulename": "sglang.lang.ir", "qualname": "SglGetForkItem", "kind": "class", "doc": "<p></p>\n", "bases": "SglExpr"}, {"fullname": "sglang.lang.ir.SglGetForkItem.__init__", "modulename": "sglang.lang.ir", "qualname": "SglGetForkItem.__init__", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">index</span><span class=\"p\">:</span> <span class=\"nb\">int</span></span>)</span>"}, {"fullname": "sglang.lang.ir.SglGetForkItem.index", "modulename": "sglang.lang.ir", "qualname": "SglGetForkItem.index", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "sglang.lang.ir.SglVariable", "modulename": "sglang.lang.ir", "qualname": "SglVariable", "kind": "class", "doc": "<p></p>\n", "bases": "SglExpr"}, {"fullname": "sglang.lang.ir.SglVariable.__init__", "modulename": "sglang.lang.ir", "qualname": "SglVariable.__init__", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">name</span><span class=\"p\">:</span> <span class=\"nb\">str</span>, </span><span class=\"param\"><span class=\"n\">source</span></span>)</span>"}, {"fullname": "sglang.lang.ir.SglVariable.name", "modulename": "sglang.lang.ir", "qualname": "SglVariable.name", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "sglang.lang.ir.SglVariable.source", "modulename": "sglang.lang.ir", "qualname": "SglVariable.source", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "sglang.lang.ir.SglVarScopeBegin", "modulename": "sglang.lang.ir", "qualname": "SglVarScopeBegin", "kind": "class", "doc": "<p></p>\n", "bases": "SglExpr"}, {"fullname": "sglang.lang.ir.SglVarScopeBegin.__init__", "modulename": "sglang.lang.ir", "qualname": "SglVarScopeBegin.__init__", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">name</span><span class=\"p\">:</span> <span class=\"nb\">str</span></span>)</span>"}, {"fullname": "sglang.lang.ir.SglVarScopeBegin.name", "modulename": "sglang.lang.ir", "qualname": "SglVarScopeBegin.name", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "sglang.lang.ir.SglVarScopeEnd", "modulename": "sglang.lang.ir", "qualname": "SglVarScopeEnd", "kind": "class", "doc": "<p></p>\n", "bases": "SglExpr"}, {"fullname": "sglang.lang.ir.SglVarScopeEnd.__init__", "modulename": "sglang.lang.ir", "qualname": "SglVarScopeEnd.__init__", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">name</span><span class=\"p\">:</span> <span class=\"nb\">str</span></span>)</span>"}, {"fullname": "sglang.lang.ir.SglVarScopeEnd.name", "modulename": "sglang.lang.ir", "qualname": "SglVarScopeEnd.name", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "sglang.lang.ir.SglConcateAndAppend", "modulename": "sglang.lang.ir", "qualname": "SglConcateAndAppend", "kind": "class", "doc": "<p></p>\n", "bases": "SglExpr"}, {"fullname": "sglang.lang.ir.SglConcateAndAppend.__init__", "modulename": "sglang.lang.ir", "qualname": "SglConcateAndAppend.__init__", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">states</span></span>)</span>"}, {"fullname": "sglang.lang.ir.SglConcateAndAppend.states", "modulename": "sglang.lang.ir", "qualname": "SglConcateAndAppend.states", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "sglang.lang.ir.SglCommitLazy", "modulename": "sglang.lang.ir", "qualname": "SglCommitLazy", "kind": "class", "doc": "<p></p>\n", "bases": "SglExpr"}, {"fullname": "sglang.lang.ir.SglSeparateReasoning", "modulename": "sglang.lang.ir", "qualname": "SglSeparateReasoning", "kind": "class", "doc": "<p></p>\n", "bases": "SglExpr"}, {"fullname": "sglang.lang.ir.SglSeparateReasoning.__init__", "modulename": "sglang.lang.ir", "qualname": "SglSeparateReasoning.__init__", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">model_type</span><span class=\"p\">:</span> <span class=\"nb\">str</span>, </span><span class=\"param\"><span class=\"n\">expr</span><span class=\"p\">:</span> <span class=\"n\">sglang</span><span class=\"o\">.</span><span class=\"n\">lang</span><span class=\"o\">.</span><span class=\"n\">ir</span><span class=\"o\">.</span><span class=\"n\">SglExpr</span></span>)</span>"}, {"fullname": "sglang.lang.ir.SglSeparateReasoning.model_type", "modulename": "sglang.lang.ir", "qualname": "SglSeparateReasoning.model_type", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "sglang.lang.ir.SglSeparateReasoning.expr", "modulename": "sglang.lang.ir", "qualname": "SglSeparateReasoning.expr", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "sglang.lang.ir.SglSeparateReasoning.name", "modulename": "sglang.lang.ir", "qualname": "SglSeparateReasoning.name", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "sglang.lang.ir.SglSeparateReasoning.process_name_for_reasoning", "modulename": "sglang.lang.ir", "qualname": "SglSeparateReasoning.process_name_for_reasoning", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">name</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.lang.tracer", "modulename": "sglang.lang.tracer", "kind": "module", "doc": "<p>Tracing a program.</p>\n"}, {"fullname": "sglang.lang.tracer.StopTracing", "modulename": "sglang.lang.tracer", "qualname": "StopTracing", "kind": "class", "doc": "<p>Common base class for all non-exit exceptions.</p>\n", "bases": "builtins.Exception"}, {"fullname": "sglang.lang.tracer.extract_prefix_by_tracing", "modulename": "sglang.lang.tracer", "qualname": "extract_prefix_by_tracing", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">program</span>, </span><span class=\"param\"><span class=\"n\">backend</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.lang.tracer.trace_program", "modulename": "sglang.lang.tracer", "qualname": "trace_program", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">program</span>, </span><span class=\"param\"><span class=\"n\">arguments</span>, </span><span class=\"param\"><span class=\"n\">backend</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.lang.tracer.TracerProgramState", "modulename": "sglang.lang.tracer", "qualname": "TracerProgramState", "kind": "class", "doc": "<p>The state of an SGL program.</p>\n", "bases": "sglang.lang.interpreter.ProgramState"}, {"fullname": "sglang.lang.tracer.TracerProgramState.__init__", "modulename": "sglang.lang.tracer", "qualname": "TracerProgramState.__init__", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">backend</span>, </span><span class=\"param\"><span class=\"n\">arguments</span>, </span><span class=\"param\"><span class=\"n\">only_trace_prefix</span></span>)</span>"}, {"fullname": "sglang.lang.tracer.TracerProgramState.pid", "modulename": "sglang.lang.tracer", "qualname": "TracerProgramState.pid", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "sglang.lang.tracer.TracerProgramState.backend", "modulename": "sglang.lang.tracer", "qualname": "TracerProgramState.backend", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "sglang.lang.tracer.TracerProgramState.arguments", "modulename": "sglang.lang.tracer", "qualname": "TracerProgramState.arguments", "kind": "variable", "doc": "<p></p>\n", "annotation": ": Dict[str, Any]"}, {"fullname": "sglang.lang.tracer.TracerProgramState.only_trace_prefix", "modulename": "sglang.lang.tracer", "qualname": "TracerProgramState.only_trace_prefix", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "sglang.lang.tracer.TracerProgramState.nodes", "modulename": "sglang.lang.tracer", "qualname": "TracerProgramState.nodes", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "sglang.lang.tracer.TracerProgramState.last_node", "modulename": "sglang.lang.tracer", "qualname": "TracerProgramState.last_node", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "sglang.lang.tracer.TracerProgramState.variables", "modulename": "sglang.lang.tracer", "qualname": "TracerProgramState.variables", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "sglang.lang.tracer.TracerProgramState.ret_value", "modulename": "sglang.lang.tracer", "qualname": "TracerProgramState.ret_value", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "sglang.lang.tracer.TracerProgramState.messages_", "modulename": "sglang.lang.tracer", "qualname": "TracerProgramState.messages_", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "sglang.lang.tracer.TracerProgramState.cur_role", "modulename": "sglang.lang.tracer", "qualname": "TracerProgramState.cur_role", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "sglang.lang.tracer.TracerProgramState.chat_template", "modulename": "sglang.lang.tracer", "qualname": "TracerProgramState.chat_template", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "sglang.lang.tracer.TracerProgramState.child_states", "modulename": "sglang.lang.tracer", "qualname": "TracerProgramState.child_states", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "sglang.lang.tracer.TracerProgramState.fork", "modulename": "sglang.lang.tracer", "qualname": "TracerProgramState.fork", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">size</span><span class=\"p\">:</span> <span class=\"nb\">int</span> <span class=\"o\">=</span> <span class=\"mi\">1</span>, </span><span class=\"param\"><span class=\"n\">position_ids_offset</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"n\">List</span><span class=\"p\">[</span><span class=\"nb\">int</span><span class=\"p\">]]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.lang.tracer.TracerProgramState.get_var", "modulename": "sglang.lang.tracer", "qualname": "TracerProgramState.get_var", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">name</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.lang.tracer.TracerProgramState.flatten_nodes", "modulename": "sglang.lang.tracer", "qualname": "TracerProgramState.flatten_nodes", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.lang.tracer.TracingScope", "modulename": "sglang.lang.tracer", "qualname": "TracingScope", "kind": "class", "doc": "<p></p>\n"}, {"fullname": "sglang.lang.tracer.TracingScope.__init__", "modulename": "sglang.lang.tracer", "qualname": "TracingScope.__init__", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">tracer_state</span><span class=\"p\">:</span> <span class=\"n\">sglang</span><span class=\"o\">.</span><span class=\"n\">lang</span><span class=\"o\">.</span><span class=\"n\">tracer</span><span class=\"o\">.</span><span class=\"n\">TracerProgramState</span></span>)</span>"}, {"fullname": "sglang.lang.tracer.TracingScope.cur_scope", "modulename": "sglang.lang.tracer", "qualname": "TracingScope.cur_scope", "kind": "variable", "doc": "<p></p>\n", "default_value": "None"}, {"fullname": "sglang.lang.tracer.TracingScope.tracer_state", "modulename": "sglang.lang.tracer", "qualname": "TracingScope.tracer_state", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "sglang.lang.tracer.TracingScope.last_scope", "modulename": "sglang.lang.tracer", "qualname": "TracingScope.last_scope", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "sglang.lang.tracer.TracingScope.get_current_scope", "modulename": "sglang.lang.tracer", "qualname": "TracingScope.get_current_scope", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.lang.tracer.TracingScope.add_child_state", "modulename": "sglang.lang.tracer", "qualname": "TracingScope.add_child_state", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">state</span><span class=\"p\">:</span> <span class=\"n\">sglang</span><span class=\"o\">.</span><span class=\"n\">lang</span><span class=\"o\">.</span><span class=\"n\">tracer</span><span class=\"o\">.</span><span class=\"n\">TracerProgramState</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.lang.backend", "modulename": "sglang.lang.backend", "kind": "module", "doc": "<p></p>\n"}, {"fullname": "sglang.lang.backend.anthropic", "modulename": "sglang.lang.backend.anthropic", "kind": "module", "doc": "<p></p>\n"}, {"fullname": "sglang.lang.backend.anthropic.Anthropic", "modulename": "sglang.lang.backend.anthropic", "qualname": "Anthropic", "kind": "class", "doc": "<p></p>\n", "bases": "sglang.lang.backend.base_backend.BaseBackend"}, {"fullname": "sglang.lang.backend.anthropic.Anthropic.__init__", "modulename": "sglang.lang.backend.anthropic", "qualname": "Anthropic.__init__", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">model_name</span>, </span><span class=\"param\"><span class=\"o\">*</span><span class=\"n\">args</span>, </span><span class=\"param\"><span class=\"o\">**</span><span class=\"n\">kwargs</span></span>)</span>"}, {"fullname": "sglang.lang.backend.anthropic.Anthropic.model_name", "modulename": "sglang.lang.backend.anthropic", "qualname": "Anthropic.model_name", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "sglang.lang.backend.anthropic.Anthropic.chat_template", "modulename": "sglang.lang.backend.anthropic", "qualname": "Anthropic.chat_template", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "sglang.lang.backend.anthropic.Anthropic.client", "modulename": "sglang.lang.backend.anthropic", "qualname": "Anthropic.client", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "sglang.lang.backend.anthropic.Anthropic.get_chat_template", "modulename": "sglang.lang.backend.anthropic", "qualname": "Anthropic.get_chat_template", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.lang.backend.anthropic.Anthropic.generate", "modulename": "sglang.lang.backend.anthropic", "qualname": "Anthropic.generate", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"bp\">self</span>,</span><span class=\"param\">\t<span class=\"n\">s</span><span class=\"p\">:</span> <span class=\"n\">sglang</span><span class=\"o\">.</span><span class=\"n\">lang</span><span class=\"o\">.</span><span class=\"n\">interpreter</span><span class=\"o\">.</span><span class=\"n\">StreamExecutor</span>,</span><span class=\"param\">\t<span class=\"n\">sampling_params</span><span class=\"p\">:</span> <span class=\"n\">sglang</span><span class=\"o\">.</span><span class=\"n\">lang</span><span class=\"o\">.</span><span class=\"n\">ir</span><span class=\"o\">.</span><span class=\"n\">SglSamplingParams</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.lang.backend.anthropic.Anthropic.generate_stream", "modulename": "sglang.lang.backend.anthropic", "qualname": "Anthropic.generate_stream", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"bp\">self</span>,</span><span class=\"param\">\t<span class=\"n\">s</span><span class=\"p\">:</span> <span class=\"n\">sglang</span><span class=\"o\">.</span><span class=\"n\">lang</span><span class=\"o\">.</span><span class=\"n\">interpreter</span><span class=\"o\">.</span><span class=\"n\">StreamExecutor</span>,</span><span class=\"param\">\t<span class=\"n\">sampling_params</span><span class=\"p\">:</span> <span class=\"n\">sglang</span><span class=\"o\">.</span><span class=\"n\">lang</span><span class=\"o\">.</span><span class=\"n\">ir</span><span class=\"o\">.</span><span class=\"n\">SglSamplingParams</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.lang.backend.base_backend", "modulename": "sglang.lang.backend.base_backend", "kind": "module", "doc": "<p></p>\n"}, {"fullname": "sglang.lang.backend.base_backend.BaseBackend", "modulename": "sglang.lang.backend.base_backend", "qualname": "BaseBackend", "kind": "class", "doc": "<p></p>\n"}, {"fullname": "sglang.lang.backend.base_backend.BaseBackend.support_concate_and_append", "modulename": "sglang.lang.backend.base_backend", "qualname": "BaseBackend.support_concate_and_append", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "sglang.lang.backend.base_backend.BaseBackend.chat_template", "modulename": "sglang.lang.backend.base_backend", "qualname": "BaseBackend.chat_template", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "sglang.lang.backend.base_backend.BaseBackend.get_model_name", "modulename": "sglang.lang.backend.base_backend", "qualname": "BaseBackend.get_model_name", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.lang.backend.base_backend.BaseBackend.get_chat_template", "modulename": "sglang.lang.backend.base_backend", "qualname": "BaseBackend.get_chat_template", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.lang.backend.base_backend.BaseBackend.cache_prefix", "modulename": "sglang.lang.backend.base_backend", "qualname": "BaseBackend.cache_prefix", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">prefix_str</span><span class=\"p\">:</span> <span class=\"nb\">str</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.lang.backend.base_backend.BaseBackend.uncache_prefix", "modulename": "sglang.lang.backend.base_backend", "qualname": "BaseBackend.uncache_prefix", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">rid</span><span class=\"p\">:</span> <span class=\"nb\">str</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.lang.backend.base_backend.BaseBackend.end_request", "modulename": "sglang.lang.backend.base_backend", "qualname": "BaseBackend.end_request", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">rid</span><span class=\"p\">:</span> <span class=\"n\">Union</span><span class=\"p\">[</span><span class=\"nb\">str</span><span class=\"p\">,</span> <span class=\"n\">List</span><span class=\"p\">[</span><span class=\"nb\">str</span><span class=\"p\">]]</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.lang.backend.base_backend.BaseBackend.begin_program", "modulename": "sglang.lang.backend.base_backend", "qualname": "BaseBackend.begin_program", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">s</span><span class=\"p\">:</span> <span class=\"n\">sglang</span><span class=\"o\">.</span><span class=\"n\">lang</span><span class=\"o\">.</span><span class=\"n\">interpreter</span><span class=\"o\">.</span><span class=\"n\">StreamExecutor</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.lang.backend.base_backend.BaseBackend.end_program", "modulename": "sglang.lang.backend.base_backend", "qualname": "BaseBackend.end_program", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"bp\">self</span>,</span><span class=\"param\">\t<span class=\"n\">s</span><span class=\"p\">:</span> <span class=\"n\">Union</span><span class=\"p\">[</span><span class=\"n\">sglang</span><span class=\"o\">.</span><span class=\"n\">lang</span><span class=\"o\">.</span><span class=\"n\">interpreter</span><span class=\"o\">.</span><span class=\"n\">StreamExecutor</span><span class=\"p\">,</span> <span class=\"n\">List</span><span class=\"p\">[</span><span class=\"n\">sglang</span><span class=\"o\">.</span><span class=\"n\">lang</span><span class=\"o\">.</span><span class=\"n\">interpreter</span><span class=\"o\">.</span><span class=\"n\">StreamExecutor</span><span class=\"p\">]]</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.lang.backend.base_backend.BaseBackend.commit_lazy_operations", "modulename": "sglang.lang.backend.base_backend", "qualname": "BaseBackend.commit_lazy_operations", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">s</span><span class=\"p\">:</span> <span class=\"n\">sglang</span><span class=\"o\">.</span><span class=\"n\">lang</span><span class=\"o\">.</span><span class=\"n\">interpreter</span><span class=\"o\">.</span><span class=\"n\">StreamExecutor</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.lang.backend.base_backend.BaseBackend.fork_program", "modulename": "sglang.lang.backend.base_backend", "qualname": "BaseBackend.fork_program", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"bp\">self</span>,</span><span class=\"param\">\t<span class=\"n\">src</span><span class=\"p\">:</span> <span class=\"n\">sglang</span><span class=\"o\">.</span><span class=\"n\">lang</span><span class=\"o\">.</span><span class=\"n\">interpreter</span><span class=\"o\">.</span><span class=\"n\">StreamExecutor</span>,</span><span class=\"param\">\t<span class=\"n\">dst</span><span class=\"p\">:</span> <span class=\"n\">List</span><span class=\"p\">[</span><span class=\"n\">sglang</span><span class=\"o\">.</span><span class=\"n\">lang</span><span class=\"o\">.</span><span class=\"n\">interpreter</span><span class=\"o\">.</span><span class=\"n\">StreamExecutor</span><span class=\"p\">]</span>,</span><span class=\"param\">\t<span class=\"n\">position_ids_offset</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"n\">List</span><span class=\"p\">[</span><span class=\"nb\">int</span><span class=\"p\">]]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.lang.backend.base_backend.BaseBackend.fill_image", "modulename": "sglang.lang.backend.base_backend", "qualname": "BaseBackend.fill_image", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">s</span><span class=\"p\">:</span> <span class=\"n\">sglang</span><span class=\"o\">.</span><span class=\"n\">lang</span><span class=\"o\">.</span><span class=\"n\">interpreter</span><span class=\"o\">.</span><span class=\"n\">StreamExecutor</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.lang.backend.base_backend.BaseBackend.generate", "modulename": "sglang.lang.backend.base_backend", "qualname": "BaseBackend.generate", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"bp\">self</span>,</span><span class=\"param\">\t<span class=\"n\">s</span><span class=\"p\">:</span> <span class=\"n\">sglang</span><span class=\"o\">.</span><span class=\"n\">lang</span><span class=\"o\">.</span><span class=\"n\">interpreter</span><span class=\"o\">.</span><span class=\"n\">StreamExecutor</span>,</span><span class=\"param\">\t<span class=\"n\">sampling_params</span><span class=\"p\">:</span> <span class=\"n\">sglang</span><span class=\"o\">.</span><span class=\"n\">lang</span><span class=\"o\">.</span><span class=\"n\">ir</span><span class=\"o\">.</span><span class=\"n\">SglSamplingParams</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.lang.backend.base_backend.BaseBackend.generate_stream", "modulename": "sglang.lang.backend.base_backend", "qualname": "BaseBackend.generate_stream", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"bp\">self</span>,</span><span class=\"param\">\t<span class=\"n\">s</span><span class=\"p\">:</span> <span class=\"n\">sglang</span><span class=\"o\">.</span><span class=\"n\">lang</span><span class=\"o\">.</span><span class=\"n\">interpreter</span><span class=\"o\">.</span><span class=\"n\">StreamExecutor</span>,</span><span class=\"param\">\t<span class=\"n\">sampling_params</span><span class=\"p\">:</span> <span class=\"n\">sglang</span><span class=\"o\">.</span><span class=\"n\">lang</span><span class=\"o\">.</span><span class=\"n\">ir</span><span class=\"o\">.</span><span class=\"n\">SglSamplingParams</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.lang.backend.base_backend.BaseBackend.select", "modulename": "sglang.lang.backend.base_backend", "qualname": "BaseBackend.select", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"bp\">self</span>,</span><span class=\"param\">\t<span class=\"n\">s</span><span class=\"p\">:</span> <span class=\"n\">sglang</span><span class=\"o\">.</span><span class=\"n\">lang</span><span class=\"o\">.</span><span class=\"n\">interpreter</span><span class=\"o\">.</span><span class=\"n\">StreamExecutor</span>,</span><span class=\"param\">\t<span class=\"n\">choices</span><span class=\"p\">:</span> <span class=\"n\">List</span><span class=\"p\">[</span><span class=\"nb\">str</span><span class=\"p\">]</span>,</span><span class=\"param\">\t<span class=\"n\">temperature</span><span class=\"p\">:</span> <span class=\"nb\">float</span>,</span><span class=\"param\">\t<span class=\"n\">choices_method</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"n\">sglang</span><span class=\"o\">.</span><span class=\"n\">lang</span><span class=\"o\">.</span><span class=\"n\">choices</span><span class=\"o\">.</span><span class=\"n\">ChoicesSamplingMethod</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span></span><span class=\"return-annotation\">) -> <span class=\"n\">sglang</span><span class=\"o\">.</span><span class=\"n\">lang</span><span class=\"o\">.</span><span class=\"n\">choices</span><span class=\"o\">.</span><span class=\"n\">ChoicesDecision</span>:</span></span>", "funcdef": "def"}, {"fullname": "sglang.lang.backend.base_backend.BaseBackend.concatenate_and_append", "modulename": "sglang.lang.backend.base_backend", "qualname": "BaseBackend.concatenate_and_append", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">src_rids</span><span class=\"p\">:</span> <span class=\"n\">List</span><span class=\"p\">[</span><span class=\"nb\">str</span><span class=\"p\">]</span>, </span><span class=\"param\"><span class=\"n\">dst_rid</span><span class=\"p\">:</span> <span class=\"nb\">str</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.lang.backend.base_backend.BaseBackend.shutdown", "modulename": "sglang.lang.backend.base_backend", "qualname": "BaseBackend.shutdown", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.lang.backend.base_backend.BaseBackend.flush_cache", "modulename": "sglang.lang.backend.base_backend", "qualname": "BaseBackend.flush_cache", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.lang.backend.base_backend.BaseBackend.get_server_info", "modulename": "sglang.lang.backend.base_backend", "qualname": "BaseBackend.get_server_info", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.lang.backend.litellm", "modulename": "sglang.lang.backend.litellm", "kind": "module", "doc": "<p></p>\n"}, {"fullname": "sglang.lang.backend.litellm.LiteLLM", "modulename": "sglang.lang.backend.litellm", "qualname": "LiteLLM", "kind": "class", "doc": "<p></p>\n", "bases": "sglang.lang.backend.base_backend.BaseBackend"}, {"fullname": "sglang.lang.backend.litellm.LiteLLM.__init__", "modulename": "sglang.lang.backend.litellm", "qualname": "LiteLLM.__init__", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">model_name</span>,</span><span class=\"param\">\t<span class=\"n\">chat_template</span><span class=\"o\">=</span><span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">api_key</span><span class=\"o\">=</span><span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">organization</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"nb\">str</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">base_url</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"nb\">str</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">timeout</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"nb\">float</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"mi\">600</span>,</span><span class=\"param\">\t<span class=\"n\">max_retries</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"nb\">int</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"mi\">1</span>,</span><span class=\"param\">\t<span class=\"n\">default_headers</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"n\">Mapping</span><span class=\"p\">[</span><span class=\"nb\">str</span><span class=\"p\">,</span> <span class=\"nb\">str</span><span class=\"p\">]]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span></span>)</span>"}, {"fullname": "sglang.lang.backend.litellm.LiteLLM.model_name", "modulename": "sglang.lang.backend.litellm", "qualname": "LiteLLM.model_name", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "sglang.lang.backend.litellm.LiteLLM.chat_template", "modulename": "sglang.lang.backend.litellm", "qualname": "LiteLLM.chat_template", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "sglang.lang.backend.litellm.LiteLLM.client_params", "modulename": "sglang.lang.backend.litellm", "qualname": "LiteLLM.client_params", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "sglang.lang.backend.litellm.LiteLLM.get_chat_template", "modulename": "sglang.lang.backend.litellm", "qualname": "LiteLLM.get_chat_template", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.lang.backend.litellm.LiteLLM.generate", "modulename": "sglang.lang.backend.litellm", "qualname": "LiteLLM.generate", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"bp\">self</span>,</span><span class=\"param\">\t<span class=\"n\">s</span><span class=\"p\">:</span> <span class=\"n\">sglang</span><span class=\"o\">.</span><span class=\"n\">lang</span><span class=\"o\">.</span><span class=\"n\">interpreter</span><span class=\"o\">.</span><span class=\"n\">StreamExecutor</span>,</span><span class=\"param\">\t<span class=\"n\">sampling_params</span><span class=\"p\">:</span> <span class=\"n\">sglang</span><span class=\"o\">.</span><span class=\"n\">lang</span><span class=\"o\">.</span><span class=\"n\">ir</span><span class=\"o\">.</span><span class=\"n\">SglSamplingParams</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.lang.backend.litellm.LiteLLM.generate_stream", "modulename": "sglang.lang.backend.litellm", "qualname": "LiteLLM.generate_stream", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"bp\">self</span>,</span><span class=\"param\">\t<span class=\"n\">s</span><span class=\"p\">:</span> <span class=\"n\">sglang</span><span class=\"o\">.</span><span class=\"n\">lang</span><span class=\"o\">.</span><span class=\"n\">interpreter</span><span class=\"o\">.</span><span class=\"n\">StreamExecutor</span>,</span><span class=\"param\">\t<span class=\"n\">sampling_params</span><span class=\"p\">:</span> <span class=\"n\">sglang</span><span class=\"o\">.</span><span class=\"n\">lang</span><span class=\"o\">.</span><span class=\"n\">ir</span><span class=\"o\">.</span><span class=\"n\">SglSamplingParams</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.lang.backend.openai", "modulename": "sglang.lang.backend.openai", "kind": "module", "doc": "<p></p>\n"}, {"fullname": "sglang.lang.backend.openai.logger", "modulename": "sglang.lang.backend.openai", "qualname": "logger", "kind": "variable", "doc": "<p></p>\n", "default_value": "&lt;Logger sglang.lang.backend.openai (WARNING)&gt;"}, {"fullname": "sglang.lang.backend.openai.create_logit_bias_int", "modulename": "sglang.lang.backend.openai", "qualname": "create_logit_bias_int", "kind": "function", "doc": "<p>Get logit bias for integer numbers.</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">tokenizer</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.lang.backend.openai.INSTRUCT_MODEL_NAMES", "modulename": "sglang.lang.backend.openai", "qualname": "INSTRUCT_MODEL_NAMES", "kind": "variable", "doc": "<p></p>\n", "default_value": "[&#x27;gpt-3.5-turbo-instruct&#x27;]"}, {"fullname": "sglang.lang.backend.openai.TokenUsage", "modulename": "sglang.lang.backend.openai", "qualname": "TokenUsage", "kind": "class", "doc": "<p></p>\n"}, {"fullname": "sglang.lang.backend.openai.TokenUsage.__init__", "modulename": "sglang.lang.backend.openai", "qualname": "TokenUsage.__init__", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">prompt_tokens</span><span class=\"p\">:</span> <span class=\"nb\">int</span>, </span><span class=\"param\"><span class=\"n\">completion_tokens</span><span class=\"p\">:</span> <span class=\"nb\">int</span></span>)</span>"}, {"fullname": "sglang.lang.backend.openai.TokenUsage.prompt_tokens", "modulename": "sglang.lang.backend.openai", "qualname": "TokenUsage.prompt_tokens", "kind": "variable", "doc": "<p></p>\n", "annotation": ": int"}, {"fullname": "sglang.lang.backend.openai.TokenUsage.completion_tokens", "modulename": "sglang.lang.backend.openai", "qualname": "TokenUsage.completion_tokens", "kind": "variable", "doc": "<p></p>\n", "annotation": ": int"}, {"fullname": "sglang.lang.backend.openai.TokenUsage.reset", "modulename": "sglang.lang.backend.openai", "qualname": "TokenUsage.reset", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.lang.backend.openai.OpenAI", "modulename": "sglang.lang.backend.openai", "qualname": "OpenAI", "kind": "class", "doc": "<p></p>\n", "bases": "sglang.lang.backend.base_backend.BaseBackend"}, {"fullname": "sglang.lang.backend.openai.OpenAI.__init__", "modulename": "sglang.lang.backend.openai", "qualname": "OpenAI.__init__", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">model_name</span><span class=\"p\">:</span> <span class=\"nb\">str</span>,</span><span class=\"param\">\t<span class=\"n\">is_chat_model</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"nb\">bool</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">chat_template</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"n\">sglang</span><span class=\"o\">.</span><span class=\"n\">lang</span><span class=\"o\">.</span><span class=\"n\">chat_template</span><span class=\"o\">.</span><span class=\"n\">ChatTemplate</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">is_azure</span><span class=\"p\">:</span> <span class=\"nb\">bool</span> <span class=\"o\">=</span> <span class=\"kc\">False</span>,</span><span class=\"param\">\t<span class=\"o\">*</span><span class=\"n\">args</span>,</span><span class=\"param\">\t<span class=\"o\">**</span><span class=\"n\">kwargs</span></span>)</span>"}, {"fullname": "sglang.lang.backend.openai.OpenAI.model_name", "modulename": "sglang.lang.backend.openai", "qualname": "OpenAI.model_name", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "sglang.lang.backend.openai.OpenAI.logit_bias_int", "modulename": "sglang.lang.backend.openai", "qualname": "OpenAI.logit_bias_int", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "sglang.lang.backend.openai.OpenAI.chat_template", "modulename": "sglang.lang.backend.openai", "qualname": "OpenAI.chat_template", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "sglang.lang.backend.openai.OpenAI.chat_prefix", "modulename": "sglang.lang.backend.openai", "qualname": "OpenAI.chat_prefix", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "sglang.lang.backend.openai.OpenAI.token_usage", "modulename": "sglang.lang.backend.openai", "qualname": "OpenAI.token_usage", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "sglang.lang.backend.openai.OpenAI.spec_kwargs", "modulename": "sglang.lang.backend.openai", "qualname": "OpenAI.spec_kwargs", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "sglang.lang.backend.openai.OpenAI.spec_format", "modulename": "sglang.lang.backend.openai", "qualname": "OpenAI.spec_format", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "sglang.lang.backend.openai.OpenAI.spec_max_num_tries", "modulename": "sglang.lang.backend.openai", "qualname": "OpenAI.spec_max_num_tries", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "sglang.lang.backend.openai.OpenAI.get_chat_template", "modulename": "sglang.lang.backend.openai", "qualname": "OpenAI.get_chat_template", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.lang.backend.openai.OpenAI.generate", "modulename": "sglang.lang.backend.openai", "qualname": "OpenAI.generate", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"bp\">self</span>,</span><span class=\"param\">\t<span class=\"n\">s</span><span class=\"p\">:</span> <span class=\"n\">sglang</span><span class=\"o\">.</span><span class=\"n\">lang</span><span class=\"o\">.</span><span class=\"n\">interpreter</span><span class=\"o\">.</span><span class=\"n\">StreamExecutor</span>,</span><span class=\"param\">\t<span class=\"n\">sampling_params</span><span class=\"p\">:</span> <span class=\"n\">sglang</span><span class=\"o\">.</span><span class=\"n\">lang</span><span class=\"o\">.</span><span class=\"n\">ir</span><span class=\"o\">.</span><span class=\"n\">SglSamplingParams</span>,</span><span class=\"param\">\t<span class=\"n\">spec_var_name</span><span class=\"p\">:</span> <span class=\"nb\">str</span> <span class=\"o\">=</span> <span class=\"kc\">None</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.lang.backend.openai.OpenAI.spec_fill", "modulename": "sglang.lang.backend.openai", "qualname": "OpenAI.spec_fill", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">value</span><span class=\"p\">:</span> <span class=\"nb\">str</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.lang.backend.openai.OpenAI.spec_pattern_match", "modulename": "sglang.lang.backend.openai", "qualname": "OpenAI.spec_pattern_match", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">comp</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.lang.backend.openai.OpenAI.role_end_generate", "modulename": "sglang.lang.backend.openai", "qualname": "OpenAI.role_end_generate", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">s</span><span class=\"p\">:</span> <span class=\"n\">sglang</span><span class=\"o\">.</span><span class=\"n\">lang</span><span class=\"o\">.</span><span class=\"n\">interpreter</span><span class=\"o\">.</span><span class=\"n\">StreamExecutor</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.lang.backend.openai.OpenAI.generate_stream", "modulename": "sglang.lang.backend.openai", "qualname": "OpenAI.generate_stream", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"bp\">self</span>,</span><span class=\"param\">\t<span class=\"n\">s</span><span class=\"p\">:</span> <span class=\"n\">sglang</span><span class=\"o\">.</span><span class=\"n\">lang</span><span class=\"o\">.</span><span class=\"n\">interpreter</span><span class=\"o\">.</span><span class=\"n\">StreamExecutor</span>,</span><span class=\"param\">\t<span class=\"n\">sampling_params</span><span class=\"p\">:</span> <span class=\"n\">sglang</span><span class=\"o\">.</span><span class=\"n\">lang</span><span class=\"o\">.</span><span class=\"n\">ir</span><span class=\"o\">.</span><span class=\"n\">SglSamplingParams</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.lang.backend.openai.OpenAI.select", "modulename": "sglang.lang.backend.openai", "qualname": "OpenAI.select", "kind": "function", "doc": "<p>Note: <code>choices_method</code> is not used by the OpenAI backend.</p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"bp\">self</span>,</span><span class=\"param\">\t<span class=\"n\">s</span><span class=\"p\">:</span> <span class=\"n\">sglang</span><span class=\"o\">.</span><span class=\"n\">lang</span><span class=\"o\">.</span><span class=\"n\">interpreter</span><span class=\"o\">.</span><span class=\"n\">StreamExecutor</span>,</span><span class=\"param\">\t<span class=\"n\">choices</span><span class=\"p\">:</span> <span class=\"n\">List</span><span class=\"p\">[</span><span class=\"nb\">str</span><span class=\"p\">]</span>,</span><span class=\"param\">\t<span class=\"n\">temperature</span><span class=\"p\">:</span> <span class=\"nb\">float</span>,</span><span class=\"param\">\t<span class=\"n\">choices_method</span><span class=\"p\">:</span> <span class=\"n\">sglang</span><span class=\"o\">.</span><span class=\"n\">lang</span><span class=\"o\">.</span><span class=\"n\">choices</span><span class=\"o\">.</span><span class=\"n\">ChoicesSamplingMethod</span></span><span class=\"return-annotation\">) -> <span class=\"n\">sglang</span><span class=\"o\">.</span><span class=\"n\">lang</span><span class=\"o\">.</span><span class=\"n\">choices</span><span class=\"o\">.</span><span class=\"n\">ChoicesDecision</span>:</span></span>", "funcdef": "def"}, {"fullname": "sglang.lang.backend.openai.openai_completion", "modulename": "sglang.lang.backend.openai", "qualname": "openai_completion", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">client</span>,</span><span class=\"param\">\t<span class=\"n\">token_usage</span>,</span><span class=\"param\">\t<span class=\"n\">is_chat</span><span class=\"o\">=</span><span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">retries</span><span class=\"o\">=</span><span class=\"mi\">3</span>,</span><span class=\"param\">\t<span class=\"n\">prompt</span><span class=\"o\">=</span><span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"o\">**</span><span class=\"n\">kwargs</span></span><span class=\"return-annotation\">) -> <span class=\"n\">Union</span><span class=\"p\">[</span><span class=\"nb\">str</span><span class=\"p\">,</span> <span class=\"n\">List</span><span class=\"p\">[</span><span class=\"nb\">str</span><span class=\"p\">]]</span>:</span></span>", "funcdef": "def"}, {"fullname": "sglang.lang.backend.openai.openai_completion_stream", "modulename": "sglang.lang.backend.openai", "qualname": "openai_completion_stream", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">client</span>, </span><span class=\"param\"><span class=\"n\">token_usage</span>, </span><span class=\"param\"><span class=\"n\">is_chat</span><span class=\"o\">=</span><span class=\"kc\">None</span>, </span><span class=\"param\"><span class=\"n\">retries</span><span class=\"o\">=</span><span class=\"mi\">3</span>, </span><span class=\"param\"><span class=\"n\">prompt</span><span class=\"o\">=</span><span class=\"kc\">None</span>, </span><span class=\"param\"><span class=\"o\">**</span><span class=\"n\">kwargs</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.lang.backend.runtime_endpoint", "modulename": "sglang.lang.backend.runtime_endpoint", "kind": "module", "doc": "<p></p>\n"}, {"fullname": "sglang.lang.backend.runtime_endpoint.RuntimeEndpoint", "modulename": "sglang.lang.backend.runtime_endpoint", "qualname": "RuntimeEndpoint", "kind": "class", "doc": "<p></p>\n", "bases": "sglang.lang.backend.base_backend.BaseBackend"}, {"fullname": "sglang.lang.backend.runtime_endpoint.RuntimeEndpoint.__init__", "modulename": "sglang.lang.backend.runtime_endpoint", "qualname": "RuntimeEndpoint.__init__", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">base_url</span><span class=\"p\">:</span> <span class=\"nb\">str</span>,</span><span class=\"param\">\t<span class=\"n\">api_key</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"nb\">str</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">verify</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"nb\">str</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">chat_template_name</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"nb\">str</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span></span>)</span>"}, {"fullname": "sglang.lang.backend.runtime_endpoint.RuntimeEndpoint.support_concate_and_append", "modulename": "sglang.lang.backend.runtime_endpoint", "qualname": "RuntimeEndpoint.support_concate_and_append", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "sglang.lang.backend.runtime_endpoint.RuntimeEndpoint.base_url", "modulename": "sglang.lang.backend.runtime_endpoint", "qualname": "RuntimeEndpoint.base_url", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "sglang.lang.backend.runtime_endpoint.RuntimeEndpoint.api_key", "modulename": "sglang.lang.backend.runtime_endpoint", "qualname": "RuntimeEndpoint.api_key", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "sglang.lang.backend.runtime_endpoint.RuntimeEndpoint.verify", "modulename": "sglang.lang.backend.runtime_endpoint", "qualname": "RuntimeEndpoint.verify", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "sglang.lang.backend.runtime_endpoint.RuntimeEndpoint.model_info", "modulename": "sglang.lang.backend.runtime_endpoint", "qualname": "RuntimeEndpoint.model_info", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "sglang.lang.backend.runtime_endpoint.RuntimeEndpoint.get_model_name", "modulename": "sglang.lang.backend.runtime_endpoint", "qualname": "RuntimeEndpoint.get_model_name", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.lang.backend.runtime_endpoint.RuntimeEndpoint.flush_cache", "modulename": "sglang.lang.backend.runtime_endpoint", "qualname": "RuntimeEndpoint.flush_cache", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.lang.backend.runtime_endpoint.RuntimeEndpoint.get_server_info", "modulename": "sglang.lang.backend.runtime_endpoint", "qualname": "RuntimeEndpoint.get_server_info", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.lang.backend.runtime_endpoint.RuntimeEndpoint.get_chat_template", "modulename": "sglang.lang.backend.runtime_endpoint", "qualname": "RuntimeEndpoint.get_chat_template", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.lang.backend.runtime_endpoint.RuntimeEndpoint.cache_prefix", "modulename": "sglang.lang.backend.runtime_endpoint", "qualname": "RuntimeEndpoint.cache_prefix", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">prefix_str</span><span class=\"p\">:</span> <span class=\"nb\">str</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.lang.backend.runtime_endpoint.RuntimeEndpoint.start_profile", "modulename": "sglang.lang.backend.runtime_endpoint", "qualname": "RuntimeEndpoint.start_profile", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.lang.backend.runtime_endpoint.RuntimeEndpoint.stop_profile", "modulename": "sglang.lang.backend.runtime_endpoint", "qualname": "RuntimeEndpoint.stop_profile", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.lang.backend.runtime_endpoint.RuntimeEndpoint.commit_lazy_operations", "modulename": "sglang.lang.backend.runtime_endpoint", "qualname": "RuntimeEndpoint.commit_lazy_operations", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">s</span><span class=\"p\">:</span> <span class=\"n\">sglang</span><span class=\"o\">.</span><span class=\"n\">lang</span><span class=\"o\">.</span><span class=\"n\">interpreter</span><span class=\"o\">.</span><span class=\"n\">StreamExecutor</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.lang.backend.runtime_endpoint.RuntimeEndpoint.fill_image", "modulename": "sglang.lang.backend.runtime_endpoint", "qualname": "RuntimeEndpoint.fill_image", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">s</span><span class=\"p\">:</span> <span class=\"n\">sglang</span><span class=\"o\">.</span><span class=\"n\">lang</span><span class=\"o\">.</span><span class=\"n\">interpreter</span><span class=\"o\">.</span><span class=\"n\">StreamExecutor</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.lang.backend.runtime_endpoint.RuntimeEndpoint.generate", "modulename": "sglang.lang.backend.runtime_endpoint", "qualname": "RuntimeEndpoint.generate", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"bp\">self</span>,</span><span class=\"param\">\t<span class=\"n\">s</span><span class=\"p\">:</span> <span class=\"n\">sglang</span><span class=\"o\">.</span><span class=\"n\">lang</span><span class=\"o\">.</span><span class=\"n\">interpreter</span><span class=\"o\">.</span><span class=\"n\">StreamExecutor</span>,</span><span class=\"param\">\t<span class=\"n\">sampling_params</span><span class=\"p\">:</span> <span class=\"n\">sglang</span><span class=\"o\">.</span><span class=\"n\">lang</span><span class=\"o\">.</span><span class=\"n\">ir</span><span class=\"o\">.</span><span class=\"n\">SglSamplingParams</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.lang.backend.runtime_endpoint.RuntimeEndpoint.generate_stream", "modulename": "sglang.lang.backend.runtime_endpoint", "qualname": "RuntimeEndpoint.generate_stream", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"bp\">self</span>,</span><span class=\"param\">\t<span class=\"n\">s</span><span class=\"p\">:</span> <span class=\"n\">sglang</span><span class=\"o\">.</span><span class=\"n\">lang</span><span class=\"o\">.</span><span class=\"n\">interpreter</span><span class=\"o\">.</span><span class=\"n\">StreamExecutor</span>,</span><span class=\"param\">\t<span class=\"n\">sampling_params</span><span class=\"p\">:</span> <span class=\"n\">sglang</span><span class=\"o\">.</span><span class=\"n\">lang</span><span class=\"o\">.</span><span class=\"n\">ir</span><span class=\"o\">.</span><span class=\"n\">SglSamplingParams</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.lang.backend.runtime_endpoint.RuntimeEndpoint.select", "modulename": "sglang.lang.backend.runtime_endpoint", "qualname": "RuntimeEndpoint.select", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"bp\">self</span>,</span><span class=\"param\">\t<span class=\"n\">s</span><span class=\"p\">:</span> <span class=\"n\">sglang</span><span class=\"o\">.</span><span class=\"n\">lang</span><span class=\"o\">.</span><span class=\"n\">interpreter</span><span class=\"o\">.</span><span class=\"n\">StreamExecutor</span>,</span><span class=\"param\">\t<span class=\"n\">choices</span><span class=\"p\">:</span> <span class=\"n\">List</span><span class=\"p\">[</span><span class=\"nb\">str</span><span class=\"p\">]</span>,</span><span class=\"param\">\t<span class=\"n\">temperature</span><span class=\"p\">:</span> <span class=\"nb\">float</span>,</span><span class=\"param\">\t<span class=\"n\">choices_method</span><span class=\"p\">:</span> <span class=\"n\">sglang</span><span class=\"o\">.</span><span class=\"n\">lang</span><span class=\"o\">.</span><span class=\"n\">choices</span><span class=\"o\">.</span><span class=\"n\">ChoicesSamplingMethod</span></span><span class=\"return-annotation\">) -> <span class=\"n\">sglang</span><span class=\"o\">.</span><span class=\"n\">lang</span><span class=\"o\">.</span><span class=\"n\">choices</span><span class=\"o\">.</span><span class=\"n\">ChoicesDecision</span>:</span></span>", "funcdef": "def"}, {"fullname": "sglang.lang.backend.runtime_endpoint.RuntimeEndpoint.concatenate_and_append", "modulename": "sglang.lang.backend.runtime_endpoint", "qualname": "RuntimeEndpoint.concatenate_and_append", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">src_rids</span><span class=\"p\">:</span> <span class=\"n\">List</span><span class=\"p\">[</span><span class=\"nb\">str</span><span class=\"p\">]</span>, </span><span class=\"param\"><span class=\"n\">dst_rid</span><span class=\"p\">:</span> <span class=\"nb\">str</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.lang.backend.runtime_endpoint.compute_normalized_prompt_logprobs", "modulename": "sglang.lang.backend.runtime_endpoint", "qualname": "compute_normalized_prompt_logprobs", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">input_logprobs</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.lang.backend.runtime_endpoint.Runtime", "modulename": "sglang.lang.backend.runtime_endpoint", "qualname": "Runtime", "kind": "class", "doc": "<p>A wrapper for the HTTP server.\nThis is used for launching the server in a python program without\nusing the command line interface.</p>\n\n<p>It is mainly used for the frontend language.\nYou should use the Engine class if you want to do normal offline processing without the frontend language.</p>\n"}, {"fullname": "sglang.lang.backend.runtime_endpoint.Runtime.__init__", "modulename": "sglang.lang.backend.runtime_endpoint", "qualname": "Runtime.__init__", "kind": "function", "doc": "<p>See the arguments in server_args.py::ServerArgs</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">log_level</span><span class=\"p\">:</span> <span class=\"nb\">str</span> <span class=\"o\">=</span> <span class=\"s1\">&#39;error&#39;</span>, </span><span class=\"param\"><span class=\"o\">*</span><span class=\"n\">args</span>, </span><span class=\"param\"><span class=\"o\">**</span><span class=\"n\">kwargs</span></span>)</span>"}, {"fullname": "sglang.lang.backend.runtime_endpoint.Runtime.server_args", "modulename": "sglang.lang.backend.runtime_endpoint", "qualname": "Runtime.server_args", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "sglang.lang.backend.runtime_endpoint.Runtime.url", "modulename": "sglang.lang.backend.runtime_endpoint", "qualname": "Runtime.url", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "sglang.lang.backend.runtime_endpoint.Runtime.generate_url", "modulename": "sglang.lang.backend.runtime_endpoint", "qualname": "Runtime.generate_url", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "sglang.lang.backend.runtime_endpoint.Runtime.pid", "modulename": "sglang.lang.backend.runtime_endpoint", "qualname": "Runtime.pid", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "sglang.lang.backend.runtime_endpoint.Runtime.endpoint", "modulename": "sglang.lang.backend.runtime_endpoint", "qualname": "Runtime.endpoint", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "sglang.lang.backend.runtime_endpoint.Runtime.shutdown", "modulename": "sglang.lang.backend.runtime_endpoint", "qualname": "Runtime.shutdown", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.lang.backend.runtime_endpoint.Runtime.start_profile", "modulename": "sglang.lang.backend.runtime_endpoint", "qualname": "Runtime.start_profile", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.lang.backend.runtime_endpoint.Runtime.stop_profile", "modulename": "sglang.lang.backend.runtime_endpoint", "qualname": "Runtime.stop_profile", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.lang.backend.runtime_endpoint.Runtime.cache_prefix", "modulename": "sglang.lang.backend.runtime_endpoint", "qualname": "Runtime.cache_prefix", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">prefix</span><span class=\"p\">:</span> <span class=\"nb\">str</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.lang.backend.runtime_endpoint.Runtime.get_tokenizer", "modulename": "sglang.lang.backend.runtime_endpoint", "qualname": "Runtime.get_tokenizer", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.lang.backend.runtime_endpoint.Runtime.async_generate", "modulename": "sglang.lang.backend.runtime_endpoint", "qualname": "Runtime.async_generate", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">prompt</span><span class=\"p\">:</span> <span class=\"nb\">str</span>, </span><span class=\"param\"><span class=\"n\">sampling_params</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"n\">Dict</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "async def"}, {"fullname": "sglang.lang.backend.runtime_endpoint.Runtime.add_request", "modulename": "sglang.lang.backend.runtime_endpoint", "qualname": "Runtime.add_request", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">prompt</span><span class=\"p\">:</span> <span class=\"nb\">str</span>, </span><span class=\"param\"><span class=\"n\">sampling_params</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"n\">Dict</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "async def"}, {"fullname": "sglang.lang.backend.runtime_endpoint.Runtime.generate", "modulename": "sglang.lang.backend.runtime_endpoint", "qualname": "Runtime.generate", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"bp\">self</span>,</span><span class=\"param\">\t<span class=\"n\">prompt</span><span class=\"p\">:</span> <span class=\"n\">Union</span><span class=\"p\">[</span><span class=\"nb\">str</span><span class=\"p\">,</span> <span class=\"n\">List</span><span class=\"p\">[</span><span class=\"nb\">str</span><span class=\"p\">]]</span>,</span><span class=\"param\">\t<span class=\"n\">sampling_params</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"n\">Dict</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">return_logprob</span><span class=\"p\">:</span> <span class=\"n\">Union</span><span class=\"p\">[</span><span class=\"n\">List</span><span class=\"p\">[</span><span class=\"nb\">bool</span><span class=\"p\">],</span> <span class=\"nb\">bool</span><span class=\"p\">,</span> <span class=\"n\">NoneType</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">False</span>,</span><span class=\"param\">\t<span class=\"n\">logprob_start_len</span><span class=\"p\">:</span> <span class=\"n\">Union</span><span class=\"p\">[</span><span class=\"n\">List</span><span class=\"p\">[</span><span class=\"nb\">int</span><span class=\"p\">],</span> <span class=\"nb\">int</span><span class=\"p\">,</span> <span class=\"n\">NoneType</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">top_logprobs_num</span><span class=\"p\">:</span> <span class=\"n\">Union</span><span class=\"p\">[</span><span class=\"n\">List</span><span class=\"p\">[</span><span class=\"nb\">int</span><span class=\"p\">],</span> <span class=\"nb\">int</span><span class=\"p\">,</span> <span class=\"n\">NoneType</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">lora_path</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"n\">List</span><span class=\"p\">[</span><span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"nb\">str</span><span class=\"p\">]]]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.lang.backend.runtime_endpoint.Runtime.encode", "modulename": "sglang.lang.backend.runtime_endpoint", "qualname": "Runtime.encode", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">prompt</span><span class=\"p\">:</span> <span class=\"n\">Union</span><span class=\"p\">[</span><span class=\"nb\">str</span><span class=\"p\">,</span> <span class=\"n\">List</span><span class=\"p\">[</span><span class=\"nb\">str</span><span class=\"p\">],</span> <span class=\"n\">List</span><span class=\"p\">[</span><span class=\"n\">Dict</span><span class=\"p\">],</span> <span class=\"n\">List</span><span class=\"p\">[</span><span class=\"n\">List</span><span class=\"p\">[</span><span class=\"n\">Dict</span><span class=\"p\">]]]</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.lang.backend.runtime_endpoint.Runtime.get_server_info", "modulename": "sglang.lang.backend.runtime_endpoint", "qualname": "Runtime.get_server_info", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "async def"}, {"fullname": "sglang.lang.backend.vertexai", "modulename": "sglang.lang.backend.vertexai", "kind": "module", "doc": "<p></p>\n"}, {"fullname": "sglang.lang.backend.vertexai.VertexAI", "modulename": "sglang.lang.backend.vertexai", "qualname": "VertexAI", "kind": "class", "doc": "<p></p>\n", "bases": "sglang.lang.backend.base_backend.BaseBackend"}, {"fullname": "sglang.lang.backend.vertexai.VertexAI.__init__", "modulename": "sglang.lang.backend.vertexai", "qualname": "VertexAI.__init__", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">model_name</span>, </span><span class=\"param\"><span class=\"n\">safety_settings</span><span class=\"o\">=</span><span class=\"kc\">None</span></span>)</span>"}, {"fullname": "sglang.lang.backend.vertexai.VertexAI.model_name", "modulename": "sglang.lang.backend.vertexai", "qualname": "VertexAI.model_name", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "sglang.lang.backend.vertexai.VertexAI.chat_template", "modulename": "sglang.lang.backend.vertexai", "qualname": "VertexAI.chat_template", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "sglang.lang.backend.vertexai.VertexAI.safety_settings", "modulename": "sglang.lang.backend.vertexai", "qualname": "VertexAI.safety_settings", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "sglang.lang.backend.vertexai.VertexAI.get_chat_template", "modulename": "sglang.lang.backend.vertexai", "qualname": "VertexAI.get_chat_template", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.lang.backend.vertexai.VertexAI.generate", "modulename": "sglang.lang.backend.vertexai", "qualname": "VertexAI.generate", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"bp\">self</span>,</span><span class=\"param\">\t<span class=\"n\">s</span><span class=\"p\">:</span> <span class=\"n\">sglang</span><span class=\"o\">.</span><span class=\"n\">lang</span><span class=\"o\">.</span><span class=\"n\">interpreter</span><span class=\"o\">.</span><span class=\"n\">StreamExecutor</span>,</span><span class=\"param\">\t<span class=\"n\">sampling_params</span><span class=\"p\">:</span> <span class=\"n\">sglang</span><span class=\"o\">.</span><span class=\"n\">lang</span><span class=\"o\">.</span><span class=\"n\">ir</span><span class=\"o\">.</span><span class=\"n\">SglSamplingParams</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.lang.backend.vertexai.VertexAI.generate_stream", "modulename": "sglang.lang.backend.vertexai", "qualname": "VertexAI.generate_stream", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"bp\">self</span>,</span><span class=\"param\">\t<span class=\"n\">s</span><span class=\"p\">:</span> <span class=\"n\">sglang</span><span class=\"o\">.</span><span class=\"n\">lang</span><span class=\"o\">.</span><span class=\"n\">interpreter</span><span class=\"o\">.</span><span class=\"n\">StreamExecutor</span>,</span><span class=\"param\">\t<span class=\"n\">sampling_params</span><span class=\"p\">:</span> <span class=\"n\">sglang</span><span class=\"o\">.</span><span class=\"n\">lang</span><span class=\"o\">.</span><span class=\"n\">ir</span><span class=\"o\">.</span><span class=\"n\">SglSamplingParams</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.lang.backend.vertexai.VertexAI.text_to_vertexai_input", "modulename": "sglang.lang.backend.vertexai", "qualname": "VertexAI.text_to_vertexai_input", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">text</span>, </span><span class=\"param\"><span class=\"n\">images</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.lang.backend.vertexai.VertexAI.messages_to_vertexai_input", "modulename": "sglang.lang.backend.vertexai", "qualname": "VertexAI.messages_to_vertexai_input", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">messages</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt", "modulename": "sglang.srt", "kind": "module", "doc": "<p></p>\n"}, {"fullname": "sglang.srt.aio_rwlock", "modulename": "sglang.srt.aio_rwlock", "kind": "module", "doc": "<p></p>\n"}, {"fullname": "sglang.srt.aio_rwlock.RWLock", "modulename": "sglang.srt.aio_rwlock", "qualname": "RWLock", "kind": "class", "doc": "<p></p>\n"}, {"fullname": "sglang.srt.aio_rwlock.RWLock.reader_lock", "modulename": "sglang.srt.aio_rwlock", "qualname": "RWLock.reader_lock", "kind": "variable", "doc": "<p>A context manager for acquiring a shared (reader) lock.</p>\n\n<p>Example:\n    async with rwlock.reader_lock:\n        # read-only access</p>\n"}, {"fullname": "sglang.srt.aio_rwlock.RWLock.writer_lock", "modulename": "sglang.srt.aio_rwlock", "qualname": "RWLock.writer_lock", "kind": "variable", "doc": "<p>A context manager for acquiring an exclusive (writer) lock.</p>\n\n<p>Example:\n    async with rwlock.writer_lock:\n        # exclusive access</p>\n"}, {"fullname": "sglang.srt.aio_rwlock.RWLock.acquire_reader", "modulename": "sglang.srt.aio_rwlock", "qualname": "RWLock.acquire_reader", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "async def"}, {"fullname": "sglang.srt.aio_rwlock.RWLock.release_reader", "modulename": "sglang.srt.aio_rwlock", "qualname": "RWLock.release_reader", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "async def"}, {"fullname": "sglang.srt.aio_rwlock.RWLock.acquire_writer", "modulename": "sglang.srt.aio_rwlock", "qualname": "RWLock.acquire_writer", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "async def"}, {"fullname": "sglang.srt.aio_rwlock.RWLock.release_writer", "modulename": "sglang.srt.aio_rwlock", "qualname": "RWLock.release_writer", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "async def"}, {"fullname": "sglang.srt.bench_utils", "modulename": "sglang.srt.bench_utils", "kind": "module", "doc": "<p></p>\n"}, {"fullname": "sglang.srt.bench_utils.suppress_stdout_stderr", "modulename": "sglang.srt.bench_utils", "qualname": "suppress_stdout_stderr", "kind": "class", "doc": "<p></p>\n"}, {"fullname": "sglang.srt.bench_utils.bench_kineto", "modulename": "sglang.srt.bench_utils", "qualname": "bench_kineto", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">fn</span>,</span><span class=\"param\">\t<span class=\"n\">kernel_names</span>,</span><span class=\"param\">\t<span class=\"n\">num_tests</span><span class=\"p\">:</span> <span class=\"nb\">int</span> <span class=\"o\">=</span> <span class=\"mi\">30</span>,</span><span class=\"param\">\t<span class=\"n\">suppress_kineto_output</span><span class=\"p\">:</span> <span class=\"nb\">bool</span> <span class=\"o\">=</span> <span class=\"kc\">False</span>,</span><span class=\"param\">\t<span class=\"n\">trace_path</span><span class=\"p\">:</span> <span class=\"nb\">str</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">flush_l2</span><span class=\"p\">:</span> <span class=\"nb\">bool</span> <span class=\"o\">=</span> <span class=\"kc\">True</span>,</span><span class=\"param\">\t<span class=\"n\">with_multiple_kernels</span><span class=\"p\">:</span> <span class=\"nb\">bool</span> <span class=\"o\">=</span> <span class=\"kc\">False</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.code_completion_parser", "modulename": "sglang.srt.code_completion_parser", "kind": "module", "doc": "<p>Completion templates.</p>\n"}, {"fullname": "sglang.srt.code_completion_parser.logger", "modulename": "sglang.srt.code_completion_parser", "qualname": "logger", "kind": "variable", "doc": "<p></p>\n", "default_value": "&lt;Logger sglang.srt.code_completion_parser (WARNING)&gt;"}, {"fullname": "sglang.srt.code_completion_parser.completion_template_name", "modulename": "sglang.srt.code_completion_parser", "qualname": "completion_template_name", "kind": "variable", "doc": "<p></p>\n", "default_value": "None"}, {"fullname": "sglang.srt.code_completion_parser.FimPosition", "modulename": "sglang.srt.code_completion_parser", "qualname": "FimPosition", "kind": "class", "doc": "<p>Position of fim middle token.</p>\n"}, {"fullname": "sglang.srt.code_completion_parser.FimPosition.MIDDLE", "modulename": "sglang.srt.code_completion_parser", "qualname": "FimPosition.MIDDLE", "kind": "variable", "doc": "<p></p>\n", "default_value": "auto(_auto_null)"}, {"fullname": "sglang.srt.code_completion_parser.FimPosition.END", "modulename": "sglang.srt.code_completion_parser", "qualname": "FimPosition.END", "kind": "variable", "doc": "<p></p>\n", "default_value": "auto(_auto_null)"}, {"fullname": "sglang.srt.code_completion_parser.CompletionTemplate", "modulename": "sglang.srt.code_completion_parser", "qualname": "CompletionTemplate", "kind": "class", "doc": "<p>A class that manages completion prompt templates. only for code completion currently.</p>\n"}, {"fullname": "sglang.srt.code_completion_parser.CompletionTemplate.__init__", "modulename": "sglang.srt.code_completion_parser", "qualname": "CompletionTemplate.__init__", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">name</span><span class=\"p\">:</span> <span class=\"nb\">str</span>,</span><span class=\"param\">\t<span class=\"n\">fim_begin_token</span><span class=\"p\">:</span> <span class=\"nb\">str</span>,</span><span class=\"param\">\t<span class=\"n\">fim_middle_token</span><span class=\"p\">:</span> <span class=\"nb\">str</span>,</span><span class=\"param\">\t<span class=\"n\">fim_end_token</span><span class=\"p\">:</span> <span class=\"nb\">str</span>,</span><span class=\"param\">\t<span class=\"n\">fim_position</span><span class=\"p\">:</span> <span class=\"n\">sglang</span><span class=\"o\">.</span><span class=\"n\">srt</span><span class=\"o\">.</span><span class=\"n\">code_completion_parser</span><span class=\"o\">.</span><span class=\"n\">FimPosition</span></span>)</span>"}, {"fullname": "sglang.srt.code_completion_parser.CompletionTemplate.name", "modulename": "sglang.srt.code_completion_parser", "qualname": "CompletionTemplate.name", "kind": "variable", "doc": "<p></p>\n", "annotation": ": str"}, {"fullname": "sglang.srt.code_completion_parser.CompletionTemplate.fim_begin_token", "modulename": "sglang.srt.code_completion_parser", "qualname": "CompletionTemplate.fim_begin_token", "kind": "variable", "doc": "<p></p>\n", "annotation": ": str"}, {"fullname": "sglang.srt.code_completion_parser.CompletionTemplate.fim_middle_token", "modulename": "sglang.srt.code_completion_parser", "qualname": "CompletionTemplate.fim_middle_token", "kind": "variable", "doc": "<p></p>\n", "annotation": ": str"}, {"fullname": "sglang.srt.code_completion_parser.CompletionTemplate.fim_end_token", "modulename": "sglang.srt.code_completion_parser", "qualname": "CompletionTemplate.fim_end_token", "kind": "variable", "doc": "<p></p>\n", "annotation": ": str"}, {"fullname": "sglang.srt.code_completion_parser.CompletionTemplate.fim_position", "modulename": "sglang.srt.code_completion_parser", "qualname": "CompletionTemplate.fim_position", "kind": "variable", "doc": "<p></p>\n", "annotation": ": sglang.srt.code_completion_parser.FimPosition"}, {"fullname": "sglang.srt.code_completion_parser.completion_templates", "modulename": "sglang.srt.code_completion_parser", "qualname": "completion_templates", "kind": "variable", "doc": "<p></p>\n", "annotation": ": dict[str, sglang.srt.code_completion_parser.CompletionTemplate]", "default_value": "{&#x27;deepseek_coder&#x27;: CompletionTemplate(name=&#x27;deepseek_coder&#x27;, fim_begin_token=&#x27;&lt;\uff5cfim\u2581begin\uff5c&gt;&#x27;, fim_middle_token=&#x27;&lt;\uff5cfim\u2581hole\uff5c&gt;&#x27;, fim_end_token=&#x27;&lt;\uff5cfim\u2581end\uff5c&gt;&#x27;, fim_position=auto(_auto_null)), &#x27;star_coder&#x27;: CompletionTemplate(name=&#x27;star_coder&#x27;, fim_begin_token=&#x27;&lt;fim_prefix&gt;&#x27;, fim_middle_token=&#x27;&lt;fim_middle&gt;&#x27;, fim_end_token=&#x27;&lt;fim_suffix&gt;&#x27;, fim_position=auto(_auto_null)), &#x27;qwen_coder&#x27;: CompletionTemplate(name=&#x27;qwen_coder&#x27;, fim_begin_token=&#x27;&lt;|fim_prefix|&gt;&#x27;, fim_middle_token=&#x27;&lt;|fim_middle|&gt;&#x27;, fim_end_token=&#x27;&lt;|fim_suffix|&gt;&#x27;, fim_position=auto(_auto_null))}"}, {"fullname": "sglang.srt.code_completion_parser.register_completion_template", "modulename": "sglang.srt.code_completion_parser", "qualname": "register_completion_template", "kind": "function", "doc": "<p>Register a new completion template.</p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">template</span><span class=\"p\">:</span> <span class=\"n\">sglang</span><span class=\"o\">.</span><span class=\"n\">srt</span><span class=\"o\">.</span><span class=\"n\">code_completion_parser</span><span class=\"o\">.</span><span class=\"n\">CompletionTemplate</span>,</span><span class=\"param\">\t<span class=\"n\">override</span><span class=\"p\">:</span> <span class=\"nb\">bool</span> <span class=\"o\">=</span> <span class=\"kc\">False</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.code_completion_parser.completion_template_exists", "modulename": "sglang.srt.code_completion_parser", "qualname": "completion_template_exists", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">template_name</span><span class=\"p\">:</span> <span class=\"nb\">str</span></span><span class=\"return-annotation\">) -> <span class=\"nb\">bool</span>:</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.code_completion_parser.is_completion_template_defined", "modulename": "sglang.srt.code_completion_parser", "qualname": "is_completion_template_defined", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"return-annotation\">) -> <span class=\"nb\">bool</span>:</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.code_completion_parser.generate_completion_prompt_from_request", "modulename": "sglang.srt.code_completion_parser", "qualname": "generate_completion_prompt_from_request", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">request</span><span class=\"p\">:</span> <span class=\"n\">sglang</span><span class=\"o\">.</span><span class=\"n\">srt</span><span class=\"o\">.</span><span class=\"n\">entrypoints</span><span class=\"o\">.</span><span class=\"n\">openai</span><span class=\"o\">.</span><span class=\"n\">protocol</span><span class=\"o\">.</span><span class=\"n\">CompletionRequest</span></span><span class=\"return-annotation\">) -> <span class=\"nb\">str</span>:</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.code_completion_parser.generate_completion_prompt", "modulename": "sglang.srt.code_completion_parser", "qualname": "generate_completion_prompt", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">prompt</span><span class=\"p\">:</span> <span class=\"nb\">str</span>, </span><span class=\"param\"><span class=\"n\">suffix</span><span class=\"p\">:</span> <span class=\"nb\">str</span>, </span><span class=\"param\"><span class=\"n\">template_name</span><span class=\"p\">:</span> <span class=\"nb\">str</span></span><span class=\"return-annotation\">) -> <span class=\"nb\">str</span>:</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.configs", "modulename": "sglang.srt.configs", "kind": "module", "doc": "<p></p>\n"}, {"fullname": "sglang.srt.configs.ExaoneConfig", "modulename": "sglang.srt.configs", "qualname": "ExaoneConfig", "kind": "class", "doc": "<p>This is the configuration class to store the configuration of a <code>~transformers.ExaoneModel</code>. It is used to\ninstantiate a EXAONE model according to the specified arguments, defining the model architecture. Instantiating a\nconfiguration with the defaults will yield a similar configuration to that of the Exaone</p>\n\n<p>Configuration objects inherit from <code>~transformers.PretrainedConfig</code> and can be used to control the model\noutputs. Read the documentation from <code>~transformers.PretrainedConfig</code> for more information.</p>\n\n<p>Args:\n    vocab_size (<code>int</code>, <code>optional</code>, defaults to 102400):\n        Vocabulary size of the EXAONE model. Defines the number of different tokens that can be represented by the\n        <code>inputs_ids</code> passed when calling <code>~transformers.ExaoneModel</code>. Vocabulary size of the model.\n        Defines the different tokens that can be represented by the <code>inputs_ids</code> passed to the forward method of\n        <code>~transformers.EXAONEModel</code>.\n    max_position_embeddings (<code>int</code>, <code>optional</code>, defaults to 2048):\n        The maximum sequence length that this model might ever be used with. Typically set this to something large\n        just in case (e.g., 512 or 1024 or 2048).\n    hidden_size (<code>int</code>, <code>optional</code>, defaults to 2048):\n        Dimensionality of the encoder layers and the pooler layer.\n    num_layers (<code>int</code>, <code>optional</code>, defaults to 32):\n        Number of hidden layers in the Transformer encoder.\n    num_attention_heads (<code>int</code>, <code>optional</code>, defaults to 32):\n        Number of attention heads for each attention layer in the Transformer decoder.\n    num_key_value_heads (<code>int</code>, <code>optional</code>):\n        This is the number of key_value heads that should be used to implement Grouped Query Attention. If\n        <code>num_key_value_heads=num_attention_heads</code>, the model will use Multi Head Attention (MHA), if\n        <code>num_key_value_heads=1 the model will use Multi Query Attention (MQA) otherwise GQA is used. When\n        converting a multi-head checkpoint to a GQA checkpoint, each group key and value head should be constructed\n        by meanpooling all the original heads within that group. For more details checkout [this\n        paper](https://arxiv.org/pdf/2305.13245.pdf). If it is not specified, will default to\n</code>num_attention_heads<code>.\n    intermediate_size (</code>int<code>,</code>optional<code>, defaults to</code>hidden_size * 4<code>):\n        Dimensionality of the \"intermediate\" (i.e., feed-forward) layer in the Transformer encoder.\n    activation_function (</code>str<code>or</code>function<code>,</code>optional<code>, defaults to</code>\"silu\"<code>):\n        The non-linear activation function (function or string) in the decoder.\n    rope_theta (</code>float<code>,</code>optional<code>, defaults to 10000.0):\n        The base period of the RoPE embeddings.\n    rope_scaling (</code>Dict<code>,</code>optional<code>):\n        Dictionary containing the scaling configuration for the RoPE embeddings. NOTE: if you apply new rope type\n        and you expect the model to work on longer</code>max_position_embeddings<code>, we recommend you to update this value\n        accordingly.\n        Expected contents:\n</code>rope_type<code>(</code>str<code>):\n                The sub-variant of RoPE to use. Can be one of ['default', 'linear', 'dynamic', 'yarn', 'longrope',\n                'llama3'], with 'default' being the original RoPE implementation.\n</code>factor<code>(</code>float<code>,</code>optional<code>):\n                Used with all rope types except 'default'. The scaling factor to apply to the RoPE embeddings. In\n                most scaling types, a</code>factor<code>of x will enable the model to handle sequences of length x *\n                original maximum pre-trained length.\n</code>original_max_position_embeddings<code>(</code>int<code>,</code>optional<code>):\n                Used with 'dynamic', 'longrope' and 'llama3'. The original max position embeddings used during\n                pretraining.\n</code>attention_factor<code>(</code>float<code>,</code>optional<code>):\n                Used with 'yarn' and 'longrope'. The scaling factor to be applied on the attention\n                computation. If unspecified, it defaults to value recommended by the implementation, using the\n</code>factor<code>field to infer the suggested value.\n</code>beta_fast<code>(</code>float<code>,</code>optional<code>):\n                Only used with 'yarn'. Parameter to set the boundary for extrapolation (only) in the linear\n                ramp function. If unspecified, it defaults to 32.\n</code>beta_slow<code>(</code>float<code>,</code>optional<code>):\n                Only used with 'yarn'. Parameter to set the boundary for interpolation (only) in the linear\n                ramp function. If unspecified, it defaults to 1.\n</code>short_factor<code>(</code>List[float]<code>,</code>optional<code>):\n                Only used with 'longrope'. The scaling factor to be applied to short contexts (&lt;\n</code>original_max_position_embeddings<code>). Must be a list of numbers with the same length as the hidden\n                size divided by the number of attention heads divided by 2\n</code>long_factor<code>(</code>List[float]<code>,</code>optional<code>):\n                Only used with 'longrope'. The scaling factor to be applied to long contexts (&lt;\n</code>original_max_position_embeddings<code>). Must be a list of numbers with the same length as the hidden\n                size divided by the number of attention heads divided by 2\n</code>low_freq_factor<code>(</code>float<code>,</code>optional<code>):\n                Only used with 'llama3'. Scaling factor applied to low frequency components of the RoPE\n</code>high_freq_factor<code>(</code>float<code>,</code>optional<code>):\n                Only used with 'llama3'. Scaling factor applied to high frequency components of the RoPE\n    embed_dropout (</code>float<code>,</code>optional<code>, defaults to 0.0):\n        The dropout probabilitiy for all fully connected layers in the embeddings, encoder, and pooler.\n    attention_dropout (</code>float<code>,</code>optional<code>, defaults to 0.0):\n        The dropout ratio for the attention probabilities.\n    layer_norm_epsilon (</code>float<code>,</code>optional<code>, defaults to 1e-5):\n        The epsilon used by the layer normalization layers.\n    initializer_range (</code>float<code>,</code>optional<code>, defaults to 0.02):\n        The standard deviation of the truncated_normal_initializer for initializing all weight matrices.\n    use_cache (</code>bool<code>,</code>optional<code>, defaults to</code>True<code>):\n        Whether or not the model should return the last key/values attentions (not used by all models). Only\n        relevant if ``configs.is_decoder=True``.\n    bos_token_id (</code>int<code>,</code>optional<code>, defaults to 0):\n        Beginning of stream token id.\n    eos_token_id (</code>int<code>,</code>optional<code>, defaults to 2):\n        End of stream token id.\n    tie_word_embeddings (</code>bool<code>,</code>optional<code>, defaults to</code>True<code>):\n        Whether to tie weight embeddings\n    gradient_checkpointing (</code>bool<code>,</code>optional<code>, defaults to</code>False`):\n        If True, use gradient checkpointing to save memory at the expense of slower backward pass.</p>\n\n<pre><code>Example::\n\n    &gt;&gt;&gt; from transformers import EXAONEModel, ExaoneConfig\n\n    &gt;&gt;&gt; # Initializing a EXAONE configuration\n    &gt;&gt;&gt; configuration = ExaoneConfig()\n\n    &gt;&gt;&gt; # Initializing a model from configuration\n    &gt;&gt;&gt; model = EXAONEModel(configuration)\n\n    &gt;&gt;&gt; # Accessing the model configuration\n    &gt;&gt;&gt; configuration = model.configs\n</code></pre>\n", "bases": "transformers.configuration_utils.PretrainedConfig"}, {"fullname": "sglang.srt.configs.ExaoneConfig.__init__", "modulename": "sglang.srt.configs", "qualname": "ExaoneConfig.__init__", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">vocab_size</span><span class=\"o\">=</span><span class=\"mi\">102400</span>,</span><span class=\"param\">\t<span class=\"n\">max_position_embeddings</span><span class=\"o\">=</span><span class=\"mi\">2048</span>,</span><span class=\"param\">\t<span class=\"n\">hidden_size</span><span class=\"o\">=</span><span class=\"mi\">2048</span>,</span><span class=\"param\">\t<span class=\"n\">num_layers</span><span class=\"o\">=</span><span class=\"mi\">32</span>,</span><span class=\"param\">\t<span class=\"n\">num_attention_heads</span><span class=\"o\">=</span><span class=\"mi\">32</span>,</span><span class=\"param\">\t<span class=\"n\">num_key_value_heads</span><span class=\"o\">=</span><span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">intermediate_size</span><span class=\"o\">=</span><span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">activation_function</span><span class=\"o\">=</span><span class=\"s1\">&#39;silu&#39;</span>,</span><span class=\"param\">\t<span class=\"n\">rope_theta</span><span class=\"o\">=</span><span class=\"mf\">10000.0</span>,</span><span class=\"param\">\t<span class=\"n\">rope_scaling</span><span class=\"o\">=</span><span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">embed_dropout</span><span class=\"o\">=</span><span class=\"mf\">0.0</span>,</span><span class=\"param\">\t<span class=\"n\">attention_dropout</span><span class=\"o\">=</span><span class=\"mf\">0.0</span>,</span><span class=\"param\">\t<span class=\"n\">layer_norm_epsilon</span><span class=\"o\">=</span><span class=\"mf\">1e-05</span>,</span><span class=\"param\">\t<span class=\"n\">initializer_range</span><span class=\"o\">=</span><span class=\"mf\">0.02</span>,</span><span class=\"param\">\t<span class=\"n\">use_cache</span><span class=\"o\">=</span><span class=\"kc\">True</span>,</span><span class=\"param\">\t<span class=\"n\">bos_token_id</span><span class=\"o\">=</span><span class=\"mi\">0</span>,</span><span class=\"param\">\t<span class=\"n\">eos_token_id</span><span class=\"o\">=</span><span class=\"mi\">2</span>,</span><span class=\"param\">\t<span class=\"n\">tie_word_embeddings</span><span class=\"o\">=</span><span class=\"kc\">True</span>,</span><span class=\"param\">\t<span class=\"o\">**</span><span class=\"n\">kwargs</span></span>)</span>"}, {"fullname": "sglang.srt.configs.ExaoneConfig.model_type", "modulename": "sglang.srt.configs", "qualname": "ExaoneConfig.model_type", "kind": "variable", "doc": "<p></p>\n", "default_value": "&#x27;exaone&#x27;"}, {"fullname": "sglang.srt.configs.ExaoneConfig.keys_to_ignore_at_inference", "modulename": "sglang.srt.configs", "qualname": "ExaoneConfig.keys_to_ignore_at_inference", "kind": "variable", "doc": "<p></p>\n", "default_value": "[&#x27;past_key_values&#x27;]"}, {"fullname": "sglang.srt.configs.ExaoneConfig.attribute_map", "modulename": "sglang.srt.configs", "qualname": "ExaoneConfig.attribute_map", "kind": "variable", "doc": "<p></p>\n", "default_value": "{&#x27;num_hidden_layers&#x27;: &#x27;num_layers&#x27;}"}, {"fullname": "sglang.srt.configs.ExaoneConfig.vocab_size", "modulename": "sglang.srt.configs", "qualname": "ExaoneConfig.vocab_size", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "sglang.srt.configs.ExaoneConfig.max_position_embeddings", "modulename": "sglang.srt.configs", "qualname": "ExaoneConfig.max_position_embeddings", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "sglang.srt.configs.ExaoneConfig.hidden_size", "modulename": "sglang.srt.configs", "qualname": "ExaoneConfig.hidden_size", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "sglang.srt.configs.ExaoneConfig.num_layers", "modulename": "sglang.srt.configs", "qualname": "ExaoneConfig.num_layers", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "sglang.srt.configs.ExaoneConfig.num_attention_heads", "modulename": "sglang.srt.configs", "qualname": "ExaoneConfig.num_attention_heads", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "sglang.srt.configs.ExaoneConfig.num_hidden_layers", "modulename": "sglang.srt.configs", "qualname": "ExaoneConfig.num_hidden_layers", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "sglang.srt.configs.ExaoneConfig.num_key_value_heads", "modulename": "sglang.srt.configs", "qualname": "ExaoneConfig.num_key_value_heads", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "sglang.srt.configs.ExaoneConfig.activation_function", "modulename": "sglang.srt.configs", "qualname": "ExaoneConfig.activation_function", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "sglang.srt.configs.ExaoneConfig.embed_dropout", "modulename": "sglang.srt.configs", "qualname": "ExaoneConfig.embed_dropout", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "sglang.srt.configs.ExaoneConfig.attention_dropout", "modulename": "sglang.srt.configs", "qualname": "ExaoneConfig.attention_dropout", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "sglang.srt.configs.ExaoneConfig.layer_norm_epsilon", "modulename": "sglang.srt.configs", "qualname": "ExaoneConfig.layer_norm_epsilon", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "sglang.srt.configs.ExaoneConfig.initializer_range", "modulename": "sglang.srt.configs", "qualname": "ExaoneConfig.initializer_range", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "sglang.srt.configs.ExaoneConfig.use_cache", "modulename": "sglang.srt.configs", "qualname": "ExaoneConfig.use_cache", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "sglang.srt.configs.ExaoneConfig.rope_theta", "modulename": "sglang.srt.configs", "qualname": "ExaoneConfig.rope_theta", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "sglang.srt.configs.ExaoneConfig.rope_scaling", "modulename": "sglang.srt.configs", "qualname": "ExaoneConfig.rope_scaling", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "sglang.srt.configs.ExaoneConfig.bos_token_id", "modulename": "sglang.srt.configs", "qualname": "ExaoneConfig.bos_token_id", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "sglang.srt.configs.ExaoneConfig.eos_token_id", "modulename": "sglang.srt.configs", "qualname": "ExaoneConfig.eos_token_id", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "sglang.srt.configs.ChatGLMConfig", "modulename": "sglang.srt.configs", "qualname": "ChatGLMConfig", "kind": "class", "doc": "<p>Base class for all configuration classes. Handles a few parameters common to all models' configurations as well as\nmethods for loading/downloading/saving configurations.</p>\n\n<p><Tip></p>\n\n<p>A configuration file can be loaded and saved to disk. Loading the configuration file and using this file to\ninitialize a model does <strong>not</strong> load the model weights. It only affects the model's configuration.</p>\n\n<p></Tip></p>\n\n<p>Class attributes (overridden by derived classes):</p>\n\n<ul>\n<li><strong>model_type</strong> (<code>str</code>) -- An identifier for the model type, serialized into the JSON file, and used to recreate\nthe correct object in [<code>~transformers.AutoConfig</code>].</li>\n<li><strong>has_no_defaults_at_init</strong> (<code>bool</code>) -- Whether the config class can be initialized without providing input arguments.\nSome configurations requires inputs to be defined at init and have no default values, usually these are composite configs,\n(but not necessarily) such as [<code>~transformers.EncoderDecoderConfig</code>] or [<code>~RagConfig</code>]. They have to be initialized from\ntwo or more configs of type [<code>~transformers.PretrainedConfig</code>].</li>\n<li><strong>keys_to_ignore_at_inference</strong> (<code>list[str]</code>) -- A list of keys to ignore by default when looking at dictionary\noutputs of the model during inference.</li>\n<li><strong>attribute_map</strong> (<code>dict[str, str]</code>) -- A dict that maps model specific attribute names to the standardized\nnaming of attributes.</li>\n<li><strong>base_model_tp_plan</strong> (<code>dict[str, Any]</code>) -- A dict that maps sub-modules FQNs of a base model to a tensor\nparallel plan applied to the sub-module when <code>model.tensor_parallel</code> is called.</li>\n<li><strong>base_model_pp_plan</strong> (<code>dict[str, tuple[list[str]]]</code>) -- A dict that maps child-modules of a base model to a\npipeline parallel plan that enables users to place the child-module on the appropriate device.</li>\n</ul>\n\n<p>Common attributes (present in all subclasses):</p>\n\n<ul>\n<li><strong>vocab_size</strong> (<code>int</code>) -- The number of tokens in the vocabulary, which is also the first dimension of the\nembeddings matrix (this attribute may be missing for models that don't have a text modality like ViT).</li>\n<li><strong>hidden_size</strong> (<code>int</code>) -- The hidden size of the model.</li>\n<li><strong>num_attention_heads</strong> (<code>int</code>) -- The number of attention heads used in the multi-head attention layers of the\nmodel.</li>\n<li><strong>num_hidden_layers</strong> (<code>int</code>) -- The number of blocks in the model.</li>\n</ul>\n\n<p><Tip warning={true}&gt;</p>\n\n<p>Setting parameters for sequence generation in the model config is deprecated. For backward compatibility, loading\nsome of them will still be possible, but attempting to overwrite them will throw an exception -- you should set\nthem in a [~transformers.GenerationConfig]. Check the documentation of [~transformers.GenerationConfig] for more\ninformation about the individual parameters.</p>\n\n<p></Tip></p>\n\n<p>Arg:\n    name_or_path (<code>str</code>, <em>optional</em>, defaults to <code>\"\"</code>):\n        Store the string that was passed to [<code>PreTrainedModel.from_pretrained</code>] or\n        [<code>TFPreTrainedModel.from_pretrained</code>] as <code>pretrained_model_name_or_path</code> if the configuration was created\n        with such a method.\n    output_hidden_states (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>):\n        Whether or not the model should return all hidden-states.\n    output_attentions (<code>bool</code>, *optional*, defaults to <code>False</code>):\n        Whether or not the model should returns all attentions.\n    return_dict (<code>bool</code>, <em>optional</em>, defaults to <code>True</code>):\n        Whether or not the model should return a [<code>~transformers.utils.ModelOutput</code>] instead of a plain tuple.\n    is_encoder_decoder (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>):\n        Whether the model is used as an encoder/decoder or not.\n    is_decoder (<code>bool</code>, *optional*, defaults to <code>False</code>):\n        Whether to only use the decoder in an encoder-decoder architecture, otherwise it has no effect on\n        decoder-only or encoder-only architectures.\n    cross_attention_hidden_size (<code>bool</code>, <em>optional</em>):\n        The hidden size of the cross-attention layer in case the model is used as a decoder in an encoder-decoder\n        setting and the cross-attention hidden dimension differs from <code>self.config.hidden_size</code>.\n    add_cross_attention (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>):\n        Whether cross-attention layers should be added to the model. Note, this option is only relevant for models\n        that can be used as decoder models within the [<code>EncoderDecoderModel</code>] class, which consists of all models\n        in <code>AUTO_MODELS_FOR_CAUSAL_LM</code>.\n    tie_encoder_decoder (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>):\n        Whether all encoder weights should be tied to their equivalent decoder weights. This requires the encoder\n        and decoder model to have the exact same parameter names.\n    prune_heads (<code>dict[int, list[int]]</code>, <em>optional</em>, defaults to <code>{}</code>):\n        Pruned heads of the model. The keys are the selected layer indices and the associated values, the list of\n        heads to prune in said layer.</p>\n\n<pre><code>    For instance `{1: [0, 2], 2: [2, 3]}` will prune heads 0 and 2 on layer 1 and heads 2 and 3 on layer 2.\nchunk_size_feed_forward (`int`, *optional*, defaults to `0`):\n    The chunk size of all feed forward layers in the residual attention blocks. A chunk size of `0` means that\n    the feed forward layer is not chunked. A chunk size of n means that the feed forward layer processes `n` &lt;\n    sequence_length embeddings at a time. For more information on feed forward chunking, see [How does Feed\n    Forward Chunking work?](../glossary.html#feed-forward-chunking).\n\n&gt; Parameters for fine-tuning tasks\n\narchitectures (`list[str]`, *optional*):\n    Model architectures that can be used with the model pretrained weights.\nfinetuning_task (`str`, *optional*):\n    Name of the task used to fine-tune the model. This can be used when converting from an original (TensorFlow\n    or PyTorch) checkpoint.\nid2label (`dict[int, str]`, *optional*):\n    A map from index (for instance prediction index, or target index) to label.\nlabel2id (`dict[str, int]`, *optional*):\n    A map from label to index for the model.\nnum_labels (`int`, *optional*):\n    Number of labels to use in the last layer added to the model, typically for a classification task.\ntask_specific_params (`dict[str, Any]`, *optional*):\n    Additional keyword arguments to store for the current task.\nproblem_type (`str`, *optional*):\n    Problem type for `XxxForSequenceClassification` models. Can be one of `\"regression\"`,\n    `\"single_label_classification\"` or `\"multi_label_classification\"`.\n\n&gt; Parameters linked to the tokenizer\n\ntokenizer_class (`str`, *optional*):\n    The name of the associated tokenizer class to use (if none is set, will use the tokenizer associated to the\n    model by default).\nprefix (`str`, *optional*):\n    A specific prompt that should be added at the beginning of each text before calling the model.\nbos_token_id (`int`, *optional*):\n    The id of the _beginning-of-stream_ token.\npad_token_id (`int`, *optional*):\n    The id of the _padding_ token.\neos_token_id (`int`, *optional*):\n    The id of the _end-of-stream_ token.\ndecoder_start_token_id (`int`, *optional*):\n    If an encoder-decoder model starts decoding with a different token than _bos_, the id of that token.\nsep_token_id (`int`, *optional*):\n    The id of the _separation_ token.\n\n&gt; PyTorch specific parameters\n\ntorchscript (`bool`, *optional*, defaults to `False`):\n    Whether or not the model should be used with Torchscript.\ntie_word_embeddings (`bool`, *optional*, defaults to `True`):\n    Whether the model's input and output word embeddings should be tied. Note that this is only relevant if the\n    model has a output word embedding layer.\ntorch_dtype (`str`, *optional*):\n    The `dtype` of the weights. This attribute can be used to initialize the model to a non-default `dtype`\n    (which is normally `float32`) and thus allow for optimal storage allocation. For example, if the saved\n    model is `float16`, ideally we want to load it back using the minimal amount of memory needed to load\n    `float16` weights. Since the config object is stored in plain text, this attribute contains just the\n    floating type string without the `torch.` prefix. For example, for `torch.float16` ``torch_dtype` is the\n    `\"float16\"` string.\n\n    This attribute is currently not being used during model loading time, but this may change in the future\n    versions. But we can already start preparing for the future by saving the dtype with save_pretrained.\n</code></pre>\n", "bases": "transformers.configuration_utils.PretrainedConfig"}, {"fullname": "sglang.srt.configs.ChatGLMConfig.__init__", "modulename": "sglang.srt.configs", "qualname": "ChatGLMConfig.__init__", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">num_layers</span><span class=\"o\">=</span><span class=\"mi\">28</span>,</span><span class=\"param\">\t<span class=\"n\">padded_vocab_size</span><span class=\"o\">=</span><span class=\"mi\">65024</span>,</span><span class=\"param\">\t<span class=\"n\">hidden_size</span><span class=\"o\">=</span><span class=\"mi\">4096</span>,</span><span class=\"param\">\t<span class=\"n\">ffn_hidden_size</span><span class=\"o\">=</span><span class=\"mi\">13696</span>,</span><span class=\"param\">\t<span class=\"n\">kv_channels</span><span class=\"o\">=</span><span class=\"mi\">128</span>,</span><span class=\"param\">\t<span class=\"n\">num_attention_heads</span><span class=\"o\">=</span><span class=\"mi\">32</span>,</span><span class=\"param\">\t<span class=\"n\">seq_length</span><span class=\"o\">=</span><span class=\"mi\">2048</span>,</span><span class=\"param\">\t<span class=\"n\">hidden_dropout</span><span class=\"o\">=</span><span class=\"mf\">0.0</span>,</span><span class=\"param\">\t<span class=\"n\">attention_dropout</span><span class=\"o\">=</span><span class=\"mf\">0.0</span>,</span><span class=\"param\">\t<span class=\"n\">layernorm_epsilon</span><span class=\"o\">=</span><span class=\"mf\">1e-05</span>,</span><span class=\"param\">\t<span class=\"n\">rmsnorm</span><span class=\"o\">=</span><span class=\"kc\">True</span>,</span><span class=\"param\">\t<span class=\"n\">apply_residual_connection_post_layernorm</span><span class=\"o\">=</span><span class=\"kc\">False</span>,</span><span class=\"param\">\t<span class=\"n\">post_layer_norm</span><span class=\"o\">=</span><span class=\"kc\">True</span>,</span><span class=\"param\">\t<span class=\"n\">add_bias_linear</span><span class=\"o\">=</span><span class=\"kc\">False</span>,</span><span class=\"param\">\t<span class=\"n\">add_qkv_bias</span><span class=\"o\">=</span><span class=\"kc\">False</span>,</span><span class=\"param\">\t<span class=\"n\">interleaved_qkv</span><span class=\"o\">=</span><span class=\"kc\">False</span>,</span><span class=\"param\">\t<span class=\"n\">bias_dropout_fusion</span><span class=\"o\">=</span><span class=\"kc\">True</span>,</span><span class=\"param\">\t<span class=\"n\">multi_query_attention</span><span class=\"o\">=</span><span class=\"kc\">False</span>,</span><span class=\"param\">\t<span class=\"n\">multi_query_group_num</span><span class=\"o\">=</span><span class=\"mi\">1</span>,</span><span class=\"param\">\t<span class=\"n\">apply_query_key_layer_scaling</span><span class=\"o\">=</span><span class=\"kc\">True</span>,</span><span class=\"param\">\t<span class=\"n\">attention_softmax_in_fp32</span><span class=\"o\">=</span><span class=\"kc\">True</span>,</span><span class=\"param\">\t<span class=\"n\">fp32_residual_connection</span><span class=\"o\">=</span><span class=\"kc\">False</span>,</span><span class=\"param\">\t<span class=\"n\">quantization_bit</span><span class=\"o\">=</span><span class=\"mi\">0</span>,</span><span class=\"param\">\t<span class=\"n\">pre_seq_len</span><span class=\"o\">=</span><span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">prefix_projection</span><span class=\"o\">=</span><span class=\"kc\">False</span>,</span><span class=\"param\">\t<span class=\"o\">**</span><span class=\"n\">kwargs</span></span>)</span>"}, {"fullname": "sglang.srt.configs.ChatGLMConfig.model_type", "modulename": "sglang.srt.configs", "qualname": "ChatGLMConfig.model_type", "kind": "variable", "doc": "<p></p>\n", "default_value": "&#x27;chatglm&#x27;"}, {"fullname": "sglang.srt.configs.ChatGLMConfig.attribute_map", "modulename": "sglang.srt.configs", "qualname": "ChatGLMConfig.attribute_map", "kind": "variable", "doc": "<p></p>\n", "default_value": "{&#x27;num_hidden_layers&#x27;: &#x27;num_layers&#x27;, &#x27;n_head_kv&#x27;: &#x27;multi_query_group_num&#x27;}"}, {"fullname": "sglang.srt.configs.ChatGLMConfig.num_layers", "modulename": "sglang.srt.configs", "qualname": "ChatGLMConfig.num_layers", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "sglang.srt.configs.ChatGLMConfig.vocab_size", "modulename": "sglang.srt.configs", "qualname": "ChatGLMConfig.vocab_size", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "sglang.srt.configs.ChatGLMConfig.padded_vocab_size", "modulename": "sglang.srt.configs", "qualname": "ChatGLMConfig.padded_vocab_size", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "sglang.srt.configs.ChatGLMConfig.hidden_size", "modulename": "sglang.srt.configs", "qualname": "ChatGLMConfig.hidden_size", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "sglang.srt.configs.ChatGLMConfig.ffn_hidden_size", "modulename": "sglang.srt.configs", "qualname": "ChatGLMConfig.ffn_hidden_size", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "sglang.srt.configs.ChatGLMConfig.kv_channels", "modulename": "sglang.srt.configs", "qualname": "ChatGLMConfig.kv_channels", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "sglang.srt.configs.ChatGLMConfig.num_attention_heads", "modulename": "sglang.srt.configs", "qualname": "ChatGLMConfig.num_attention_heads", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "sglang.srt.configs.ChatGLMConfig.seq_length", "modulename": "sglang.srt.configs", "qualname": "ChatGLMConfig.seq_length", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "sglang.srt.configs.ChatGLMConfig.max_position_embeddings", "modulename": "sglang.srt.configs", "qualname": "ChatGLMConfig.max_position_embeddings", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "sglang.srt.configs.ChatGLMConfig.hidden_dropout", "modulename": "sglang.srt.configs", "qualname": "ChatGLMConfig.hidden_dropout", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "sglang.srt.configs.ChatGLMConfig.attention_dropout", "modulename": "sglang.srt.configs", "qualname": "ChatGLMConfig.attention_dropout", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "sglang.srt.configs.ChatGLMConfig.layernorm_epsilon", "modulename": "sglang.srt.configs", "qualname": "ChatGLMConfig.layernorm_epsilon", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "sglang.srt.configs.ChatGLMConfig.rmsnorm", "modulename": "sglang.srt.configs", "qualname": "ChatGLMConfig.rmsnorm", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "sglang.srt.configs.ChatGLMConfig.apply_residual_connection_post_layernorm", "modulename": "sglang.srt.configs", "qualname": "ChatGLMConfig.apply_residual_connection_post_layernorm", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "sglang.srt.configs.ChatGLMConfig.post_layer_norm", "modulename": "sglang.srt.configs", "qualname": "ChatGLMConfig.post_layer_norm", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "sglang.srt.configs.ChatGLMConfig.add_bias_linear", "modulename": "sglang.srt.configs", "qualname": "ChatGLMConfig.add_bias_linear", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "sglang.srt.configs.ChatGLMConfig.add_qkv_bias", "modulename": "sglang.srt.configs", "qualname": "ChatGLMConfig.add_qkv_bias", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "sglang.srt.configs.ChatGLMConfig.bias_dropout_fusion", "modulename": "sglang.srt.configs", "qualname": "ChatGLMConfig.bias_dropout_fusion", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "sglang.srt.configs.ChatGLMConfig.multi_query_attention", "modulename": "sglang.srt.configs", "qualname": "ChatGLMConfig.multi_query_attention", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "sglang.srt.configs.ChatGLMConfig.multi_query_group_num", "modulename": "sglang.srt.configs", "qualname": "ChatGLMConfig.multi_query_group_num", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "sglang.srt.configs.ChatGLMConfig.apply_query_key_layer_scaling", "modulename": "sglang.srt.configs", "qualname": "ChatGLMConfig.apply_query_key_layer_scaling", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "sglang.srt.configs.ChatGLMConfig.attention_softmax_in_fp32", "modulename": "sglang.srt.configs", "qualname": "ChatGLMConfig.attention_softmax_in_fp32", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "sglang.srt.configs.ChatGLMConfig.fp32_residual_connection", "modulename": "sglang.srt.configs", "qualname": "ChatGLMConfig.fp32_residual_connection", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "sglang.srt.configs.ChatGLMConfig.quantization_bit", "modulename": "sglang.srt.configs", "qualname": "ChatGLMConfig.quantization_bit", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "sglang.srt.configs.ChatGLMConfig.pre_seq_len", "modulename": "sglang.srt.configs", "qualname": "ChatGLMConfig.pre_seq_len", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "sglang.srt.configs.ChatGLMConfig.prefix_projection", "modulename": "sglang.srt.configs", "qualname": "ChatGLMConfig.prefix_projection", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "sglang.srt.configs.ChatGLMConfig.interleaved_qkv", "modulename": "sglang.srt.configs", "qualname": "ChatGLMConfig.interleaved_qkv", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "sglang.srt.configs.DbrxConfig", "modulename": "sglang.srt.configs", "qualname": "DbrxConfig", "kind": "class", "doc": "<p>Configuration class for Dbrx.</p>\n\n<p>[<code>DbrxModel</code>]. It is used to instantiate a Dbrx model according to the\nspecified arguments, defining the model architecture.</p>\n\n<p>Configuration objects inherit from [<code>PretrainedConfig</code>] and can be used to control the model outputs. Read the\ndocumentation from [<code>PretrainedConfig</code>] for more information.</p>\n\n<p>Args:\n    d_model (<code>int</code>, *optional*, defaults to 6144):\n        Dimensionality of the embeddings and hidden states.\n    n_heads (<code>int</code>, <em>optional</em>, defaults to 48):\n        Number of attention heads for each attention layer in the Transformer encoder.\n    n_layers (<code>int</code>, *optional*, defaults to 40):\n        Number of hidden layers in the Transformer encoder.\n    max_seq_len (<code>int</code>, *optional*, defaults to 32768):\n        The maximum sequence length of the model.\n    vocab_size (<code>int</code>, <em>optional</em>, defaults to 100352):\n        Vocabulary size of the Dbrx model. Defines the maximum number of different tokens that can be represented by\n        the <code>inputs_ids</code> passed when calling [<code>DbrxModel</code>].\n    resid_pdrop (<code>float</code>, *optional*, defaults to 0.0):\n        The dropout probability applied to the attention output before combining with residual.\n    emb_pdrop (<code>float</code>, <em>optional</em>, defaults to 0.0):\n        The dropout probability for the embedding layer.\n    attn_config (<code>dict</code>, *optional*):\n        A dictionary used to configure the model's attention module.\n    ffn_config (<code>dict</code>, <em>optional</em>):\n        A dictionary used to configure the model's FFN module.\n    use_cache (<code>bool</code>, *optional*, defaults to <code>False</code>):\n        Whether or not the model should return the last key/values attentions (not used by all models).\n    initializer_range (<code>float</code>, <em>optional</em>, defaults to 0.02):\n        The standard deviation of the truncated_normal_initializer for initializing all weight matrices.\n    output_router_logits (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>):\n        Whether or not the router logits should be returned by the model. Enabling this will also\n        allow the model to output the auxiliary loss. See <a href=\"\">here</a> for more details\n    router_aux_loss_coef (<code>float</code>, <em>optional</em>, defaults to 0.001):\n        The aux loss factor for the total loss.</p>\n\n<p>Example:</p>\n\n<div class=\"pdoc-code codehilite\">\n<pre><span></span><code><span class=\"o\">&gt;&gt;&gt;</span> <span class=\"kn\">from</span><span class=\"w\"> </span><span class=\"nn\">transformers</span><span class=\"w\"> </span><span class=\"kn\">import</span> <span class=\"n\">DbrxConfig</span><span class=\"p\">,</span> <span class=\"n\">DbrxModel</span>\n\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"c1\"># Initializing a Dbrx configuration</span>\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">configuration</span> <span class=\"o\">=</span> <span class=\"n\">DbrxConfig</span><span class=\"p\">()</span>\n\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"c1\"># Initializing a model (with random weights) from the configuration</span>\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">model</span> <span class=\"o\">=</span> <span class=\"n\">DbrxModel</span><span class=\"p\">(</span><span class=\"n\">configuration</span><span class=\"p\">)</span>\n\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"c1\"># Accessing the model configuration</span>\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">configuration</span> <span class=\"o\">=</span> <span class=\"n\">model</span><span class=\"o\">.</span><span class=\"n\">config</span>\n</code></pre>\n</div>\n", "bases": "transformers.configuration_utils.PretrainedConfig"}, {"fullname": "sglang.srt.configs.DbrxConfig.__init__", "modulename": "sglang.srt.configs", "qualname": "DbrxConfig.__init__", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">d_model</span><span class=\"p\">:</span> <span class=\"nb\">int</span> <span class=\"o\">=</span> <span class=\"mi\">2048</span>,</span><span class=\"param\">\t<span class=\"n\">n_heads</span><span class=\"p\">:</span> <span class=\"nb\">int</span> <span class=\"o\">=</span> <span class=\"mi\">16</span>,</span><span class=\"param\">\t<span class=\"n\">n_layers</span><span class=\"p\">:</span> <span class=\"nb\">int</span> <span class=\"o\">=</span> <span class=\"mi\">24</span>,</span><span class=\"param\">\t<span class=\"n\">max_seq_len</span><span class=\"p\">:</span> <span class=\"nb\">int</span> <span class=\"o\">=</span> <span class=\"mi\">2048</span>,</span><span class=\"param\">\t<span class=\"n\">vocab_size</span><span class=\"p\">:</span> <span class=\"nb\">int</span> <span class=\"o\">=</span> <span class=\"mi\">32000</span>,</span><span class=\"param\">\t<span class=\"n\">resid_pdrop</span><span class=\"p\">:</span> <span class=\"nb\">float</span> <span class=\"o\">=</span> <span class=\"mf\">0.0</span>,</span><span class=\"param\">\t<span class=\"n\">emb_pdrop</span><span class=\"p\">:</span> <span class=\"nb\">float</span> <span class=\"o\">=</span> <span class=\"mf\">0.0</span>,</span><span class=\"param\">\t<span class=\"n\">attn_config</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"n\">sglang</span><span class=\"o\">.</span><span class=\"n\">srt</span><span class=\"o\">.</span><span class=\"n\">configs</span><span class=\"o\">.</span><span class=\"n\">dbrx</span><span class=\"o\">.</span><span class=\"n\">DbrxAttentionConfig</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">ffn_config</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"n\">sglang</span><span class=\"o\">.</span><span class=\"n\">srt</span><span class=\"o\">.</span><span class=\"n\">configs</span><span class=\"o\">.</span><span class=\"n\">dbrx</span><span class=\"o\">.</span><span class=\"n\">DbrxFFNConfig</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">use_cache</span><span class=\"p\">:</span> <span class=\"nb\">bool</span> <span class=\"o\">=</span> <span class=\"kc\">True</span>,</span><span class=\"param\">\t<span class=\"n\">initializer_range</span><span class=\"p\">:</span> <span class=\"nb\">float</span> <span class=\"o\">=</span> <span class=\"mf\">0.02</span>,</span><span class=\"param\">\t<span class=\"n\">output_router_logits</span><span class=\"p\">:</span> <span class=\"nb\">bool</span> <span class=\"o\">=</span> <span class=\"kc\">False</span>,</span><span class=\"param\">\t<span class=\"n\">router_aux_loss_coef</span><span class=\"p\">:</span> <span class=\"nb\">float</span> <span class=\"o\">=</span> <span class=\"mf\">0.05</span>,</span><span class=\"param\">\t<span class=\"o\">**</span><span class=\"n\">kwargs</span><span class=\"p\">:</span> <span class=\"n\">Any</span></span>)</span>"}, {"fullname": "sglang.srt.configs.DbrxConfig.model_type", "modulename": "sglang.srt.configs", "qualname": "DbrxConfig.model_type", "kind": "variable", "doc": "<p></p>\n", "default_value": "&#x27;dbrx&#x27;"}, {"fullname": "sglang.srt.configs.DbrxConfig.attribute_map", "modulename": "sglang.srt.configs", "qualname": "DbrxConfig.attribute_map", "kind": "variable", "doc": "<p></p>\n", "default_value": "{&#x27;num_attention_heads&#x27;: &#x27;n_heads&#x27;, &#x27;hidden_size&#x27;: &#x27;d_model&#x27;, &#x27;num_hidden_layers&#x27;: &#x27;n_layers&#x27;, &#x27;max_position_embeddings&#x27;: &#x27;max_seq_len&#x27;}"}, {"fullname": "sglang.srt.configs.DbrxConfig.d_model", "modulename": "sglang.srt.configs", "qualname": "DbrxConfig.d_model", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "sglang.srt.configs.DbrxConfig.n_heads", "modulename": "sglang.srt.configs", "qualname": "DbrxConfig.n_heads", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "sglang.srt.configs.DbrxConfig.n_layers", "modulename": "sglang.srt.configs", "qualname": "DbrxConfig.n_layers", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "sglang.srt.configs.DbrxConfig.max_seq_len", "modulename": "sglang.srt.configs", "qualname": "DbrxConfig.max_seq_len", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "sglang.srt.configs.DbrxConfig.vocab_size", "modulename": "sglang.srt.configs", "qualname": "DbrxConfig.vocab_size", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "sglang.srt.configs.DbrxConfig.resid_pdrop", "modulename": "sglang.srt.configs", "qualname": "DbrxConfig.resid_pdrop", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "sglang.srt.configs.DbrxConfig.emb_pdrop", "modulename": "sglang.srt.configs", "qualname": "DbrxConfig.emb_pdrop", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "sglang.srt.configs.DbrxConfig.use_cache", "modulename": "sglang.srt.configs", "qualname": "DbrxConfig.use_cache", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "sglang.srt.configs.DbrxConfig.initializer_range", "modulename": "sglang.srt.configs", "qualname": "DbrxConfig.initializer_range", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "sglang.srt.configs.DbrxConfig.output_router_logits", "modulename": "sglang.srt.configs", "qualname": "DbrxConfig.output_router_logits", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "sglang.srt.configs.DbrxConfig.router_aux_loss_coef", "modulename": "sglang.srt.configs", "qualname": "DbrxConfig.router_aux_loss_coef", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "sglang.srt.configs.DeepseekVL2Config", "modulename": "sglang.srt.configs", "qualname": "DeepseekVL2Config", "kind": "class", "doc": "<p>Base class for all configuration classes. Handles a few parameters common to all models' configurations as well as\nmethods for loading/downloading/saving configurations.</p>\n\n<p><Tip></p>\n\n<p>A configuration file can be loaded and saved to disk. Loading the configuration file and using this file to\ninitialize a model does <strong>not</strong> load the model weights. It only affects the model's configuration.</p>\n\n<p></Tip></p>\n\n<p>Class attributes (overridden by derived classes):</p>\n\n<ul>\n<li><strong>model_type</strong> (<code>str</code>) -- An identifier for the model type, serialized into the JSON file, and used to recreate\nthe correct object in [<code>~transformers.AutoConfig</code>].</li>\n<li><strong>has_no_defaults_at_init</strong> (<code>bool</code>) -- Whether the config class can be initialized without providing input arguments.\nSome configurations requires inputs to be defined at init and have no default values, usually these are composite configs,\n(but not necessarily) such as [<code>~transformers.EncoderDecoderConfig</code>] or [<code>~RagConfig</code>]. They have to be initialized from\ntwo or more configs of type [<code>~transformers.PretrainedConfig</code>].</li>\n<li><strong>keys_to_ignore_at_inference</strong> (<code>list[str]</code>) -- A list of keys to ignore by default when looking at dictionary\noutputs of the model during inference.</li>\n<li><strong>attribute_map</strong> (<code>dict[str, str]</code>) -- A dict that maps model specific attribute names to the standardized\nnaming of attributes.</li>\n<li><strong>base_model_tp_plan</strong> (<code>dict[str, Any]</code>) -- A dict that maps sub-modules FQNs of a base model to a tensor\nparallel plan applied to the sub-module when <code>model.tensor_parallel</code> is called.</li>\n<li><strong>base_model_pp_plan</strong> (<code>dict[str, tuple[list[str]]]</code>) -- A dict that maps child-modules of a base model to a\npipeline parallel plan that enables users to place the child-module on the appropriate device.</li>\n</ul>\n\n<p>Common attributes (present in all subclasses):</p>\n\n<ul>\n<li><strong>vocab_size</strong> (<code>int</code>) -- The number of tokens in the vocabulary, which is also the first dimension of the\nembeddings matrix (this attribute may be missing for models that don't have a text modality like ViT).</li>\n<li><strong>hidden_size</strong> (<code>int</code>) -- The hidden size of the model.</li>\n<li><strong>num_attention_heads</strong> (<code>int</code>) -- The number of attention heads used in the multi-head attention layers of the\nmodel.</li>\n<li><strong>num_hidden_layers</strong> (<code>int</code>) -- The number of blocks in the model.</li>\n</ul>\n\n<p><Tip warning={true}&gt;</p>\n\n<p>Setting parameters for sequence generation in the model config is deprecated. For backward compatibility, loading\nsome of them will still be possible, but attempting to overwrite them will throw an exception -- you should set\nthem in a [~transformers.GenerationConfig]. Check the documentation of [~transformers.GenerationConfig] for more\ninformation about the individual parameters.</p>\n\n<p></Tip></p>\n\n<p>Arg:\n    name_or_path (<code>str</code>, <em>optional</em>, defaults to <code>\"\"</code>):\n        Store the string that was passed to [<code>PreTrainedModel.from_pretrained</code>] or\n        [<code>TFPreTrainedModel.from_pretrained</code>] as <code>pretrained_model_name_or_path</code> if the configuration was created\n        with such a method.\n    output_hidden_states (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>):\n        Whether or not the model should return all hidden-states.\n    output_attentions (<code>bool</code>, *optional*, defaults to <code>False</code>):\n        Whether or not the model should returns all attentions.\n    return_dict (<code>bool</code>, <em>optional</em>, defaults to <code>True</code>):\n        Whether or not the model should return a [<code>~transformers.utils.ModelOutput</code>] instead of a plain tuple.\n    is_encoder_decoder (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>):\n        Whether the model is used as an encoder/decoder or not.\n    is_decoder (<code>bool</code>, *optional*, defaults to <code>False</code>):\n        Whether to only use the decoder in an encoder-decoder architecture, otherwise it has no effect on\n        decoder-only or encoder-only architectures.\n    cross_attention_hidden_size (<code>bool</code>, <em>optional</em>):\n        The hidden size of the cross-attention layer in case the model is used as a decoder in an encoder-decoder\n        setting and the cross-attention hidden dimension differs from <code>self.config.hidden_size</code>.\n    add_cross_attention (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>):\n        Whether cross-attention layers should be added to the model. Note, this option is only relevant for models\n        that can be used as decoder models within the [<code>EncoderDecoderModel</code>] class, which consists of all models\n        in <code>AUTO_MODELS_FOR_CAUSAL_LM</code>.\n    tie_encoder_decoder (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>):\n        Whether all encoder weights should be tied to their equivalent decoder weights. This requires the encoder\n        and decoder model to have the exact same parameter names.\n    prune_heads (<code>dict[int, list[int]]</code>, <em>optional</em>, defaults to <code>{}</code>):\n        Pruned heads of the model. The keys are the selected layer indices and the associated values, the list of\n        heads to prune in said layer.</p>\n\n<pre><code>    For instance `{1: [0, 2], 2: [2, 3]}` will prune heads 0 and 2 on layer 1 and heads 2 and 3 on layer 2.\nchunk_size_feed_forward (`int`, *optional*, defaults to `0`):\n    The chunk size of all feed forward layers in the residual attention blocks. A chunk size of `0` means that\n    the feed forward layer is not chunked. A chunk size of n means that the feed forward layer processes `n` &lt;\n    sequence_length embeddings at a time. For more information on feed forward chunking, see [How does Feed\n    Forward Chunking work?](../glossary.html#feed-forward-chunking).\n\n&gt; Parameters for fine-tuning tasks\n\narchitectures (`list[str]`, *optional*):\n    Model architectures that can be used with the model pretrained weights.\nfinetuning_task (`str`, *optional*):\n    Name of the task used to fine-tune the model. This can be used when converting from an original (TensorFlow\n    or PyTorch) checkpoint.\nid2label (`dict[int, str]`, *optional*):\n    A map from index (for instance prediction index, or target index) to label.\nlabel2id (`dict[str, int]`, *optional*):\n    A map from label to index for the model.\nnum_labels (`int`, *optional*):\n    Number of labels to use in the last layer added to the model, typically for a classification task.\ntask_specific_params (`dict[str, Any]`, *optional*):\n    Additional keyword arguments to store for the current task.\nproblem_type (`str`, *optional*):\n    Problem type for `XxxForSequenceClassification` models. Can be one of `\"regression\"`,\n    `\"single_label_classification\"` or `\"multi_label_classification\"`.\n\n&gt; Parameters linked to the tokenizer\n\ntokenizer_class (`str`, *optional*):\n    The name of the associated tokenizer class to use (if none is set, will use the tokenizer associated to the\n    model by default).\nprefix (`str`, *optional*):\n    A specific prompt that should be added at the beginning of each text before calling the model.\nbos_token_id (`int`, *optional*):\n    The id of the _beginning-of-stream_ token.\npad_token_id (`int`, *optional*):\n    The id of the _padding_ token.\neos_token_id (`int`, *optional*):\n    The id of the _end-of-stream_ token.\ndecoder_start_token_id (`int`, *optional*):\n    If an encoder-decoder model starts decoding with a different token than _bos_, the id of that token.\nsep_token_id (`int`, *optional*):\n    The id of the _separation_ token.\n\n&gt; PyTorch specific parameters\n\ntorchscript (`bool`, *optional*, defaults to `False`):\n    Whether or not the model should be used with Torchscript.\ntie_word_embeddings (`bool`, *optional*, defaults to `True`):\n    Whether the model's input and output word embeddings should be tied. Note that this is only relevant if the\n    model has a output word embedding layer.\ntorch_dtype (`str`, *optional*):\n    The `dtype` of the weights. This attribute can be used to initialize the model to a non-default `dtype`\n    (which is normally `float32`) and thus allow for optimal storage allocation. For example, if the saved\n    model is `float16`, ideally we want to load it back using the minimal amount of memory needed to load\n    `float16` weights. Since the config object is stored in plain text, this attribute contains just the\n    floating type string without the `torch.` prefix. For example, for `torch.float16` ``torch_dtype` is the\n    `\"float16\"` string.\n\n    This attribute is currently not being used during model loading time, but this may change in the future\n    versions. But we can already start preparing for the future by saving the dtype with save_pretrained.\n</code></pre>\n", "bases": "transformers.configuration_utils.PretrainedConfig"}, {"fullname": "sglang.srt.configs.DeepseekVL2Config.__init__", "modulename": "sglang.srt.configs", "qualname": "DeepseekVL2Config.__init__", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">tile_tag</span><span class=\"p\">:</span> <span class=\"nb\">str</span> <span class=\"o\">=</span> <span class=\"s1\">&#39;tile_tag&#39;</span>,</span><span class=\"param\">\t<span class=\"n\">global_view_pos</span><span class=\"p\">:</span> <span class=\"nb\">str</span> <span class=\"o\">=</span> <span class=\"s1\">&#39;head&#39;</span>,</span><span class=\"param\">\t<span class=\"n\">candidate_resolutions</span><span class=\"p\">:</span> <span class=\"n\">Tuple</span><span class=\"p\">[</span><span class=\"n\">Tuple</span><span class=\"p\">[</span><span class=\"nb\">int</span><span class=\"p\">,</span> <span class=\"nb\">int</span><span class=\"p\">]]</span> <span class=\"o\">=</span> <span class=\"p\">((</span><span class=\"mi\">384</span><span class=\"p\">,</span> <span class=\"mi\">384</span><span class=\"p\">),)</span>,</span><span class=\"param\">\t<span class=\"o\">**</span><span class=\"n\">kwargs</span></span>)</span>"}, {"fullname": "sglang.srt.configs.DeepseekVL2Config.model_type", "modulename": "sglang.srt.configs", "qualname": "DeepseekVL2Config.model_type", "kind": "variable", "doc": "<p></p>\n", "default_value": "&#x27;deepseek_vl_v2&#x27;"}, {"fullname": "sglang.srt.configs.DeepseekVL2Config.vision_config", "modulename": "sglang.srt.configs", "qualname": "DeepseekVL2Config.vision_config", "kind": "variable", "doc": "<p></p>\n", "annotation": ": sglang.srt.configs.deepseekvl2.DeepseekVL2VisionEncoderConfig"}, {"fullname": "sglang.srt.configs.DeepseekVL2Config.projector_config", "modulename": "sglang.srt.configs", "qualname": "DeepseekVL2Config.projector_config", "kind": "variable", "doc": "<p></p>\n", "annotation": ": sglang.srt.configs.deepseekvl2.DeepseekVL2MlpProjectorConfig"}, {"fullname": "sglang.srt.configs.DeepseekVL2Config.language_config", "modulename": "sglang.srt.configs", "qualname": "DeepseekVL2Config.language_config", "kind": "variable", "doc": "<p></p>\n", "annotation": ": sglang.srt.configs.deepseekvl2.DeepseekV2Config"}, {"fullname": "sglang.srt.configs.DeepseekVL2Config.tile_tag", "modulename": "sglang.srt.configs", "qualname": "DeepseekVL2Config.tile_tag", "kind": "variable", "doc": "<p></p>\n", "annotation": ": str", "default_value": "&#x27;2D&#x27;"}, {"fullname": "sglang.srt.configs.DeepseekVL2Config.global_view_pos", "modulename": "sglang.srt.configs", "qualname": "DeepseekVL2Config.global_view_pos", "kind": "variable", "doc": "<p></p>\n", "annotation": ": str", "default_value": "&#x27;head&#x27;"}, {"fullname": "sglang.srt.configs.DeepseekVL2Config.candidate_resolutions", "modulename": "sglang.srt.configs", "qualname": "DeepseekVL2Config.candidate_resolutions", "kind": "variable", "doc": "<p></p>\n", "annotation": ": Tuple[Tuple[int, int]]", "default_value": "((384, 384),)"}, {"fullname": "sglang.srt.configs.DeepseekVL2Config.architectures", "modulename": "sglang.srt.configs", "qualname": "DeepseekVL2Config.architectures", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "sglang.srt.configs.MultiModalityConfig", "modulename": "sglang.srt.configs", "qualname": "MultiModalityConfig", "kind": "class", "doc": "<p>Base class for all configuration classes. Handles a few parameters common to all models' configurations as well as\nmethods for loading/downloading/saving configurations.</p>\n\n<p><Tip></p>\n\n<p>A configuration file can be loaded and saved to disk. Loading the configuration file and using this file to\ninitialize a model does <strong>not</strong> load the model weights. It only affects the model's configuration.</p>\n\n<p></Tip></p>\n\n<p>Class attributes (overridden by derived classes):</p>\n\n<ul>\n<li><strong>model_type</strong> (<code>str</code>) -- An identifier for the model type, serialized into the JSON file, and used to recreate\nthe correct object in [<code>~transformers.AutoConfig</code>].</li>\n<li><strong>has_no_defaults_at_init</strong> (<code>bool</code>) -- Whether the config class can be initialized without providing input arguments.\nSome configurations requires inputs to be defined at init and have no default values, usually these are composite configs,\n(but not necessarily) such as [<code>~transformers.EncoderDecoderConfig</code>] or [<code>~RagConfig</code>]. They have to be initialized from\ntwo or more configs of type [<code>~transformers.PretrainedConfig</code>].</li>\n<li><strong>keys_to_ignore_at_inference</strong> (<code>list[str]</code>) -- A list of keys to ignore by default when looking at dictionary\noutputs of the model during inference.</li>\n<li><strong>attribute_map</strong> (<code>dict[str, str]</code>) -- A dict that maps model specific attribute names to the standardized\nnaming of attributes.</li>\n<li><strong>base_model_tp_plan</strong> (<code>dict[str, Any]</code>) -- A dict that maps sub-modules FQNs of a base model to a tensor\nparallel plan applied to the sub-module when <code>model.tensor_parallel</code> is called.</li>\n<li><strong>base_model_pp_plan</strong> (<code>dict[str, tuple[list[str]]]</code>) -- A dict that maps child-modules of a base model to a\npipeline parallel plan that enables users to place the child-module on the appropriate device.</li>\n</ul>\n\n<p>Common attributes (present in all subclasses):</p>\n\n<ul>\n<li><strong>vocab_size</strong> (<code>int</code>) -- The number of tokens in the vocabulary, which is also the first dimension of the\nembeddings matrix (this attribute may be missing for models that don't have a text modality like ViT).</li>\n<li><strong>hidden_size</strong> (<code>int</code>) -- The hidden size of the model.</li>\n<li><strong>num_attention_heads</strong> (<code>int</code>) -- The number of attention heads used in the multi-head attention layers of the\nmodel.</li>\n<li><strong>num_hidden_layers</strong> (<code>int</code>) -- The number of blocks in the model.</li>\n</ul>\n\n<p><Tip warning={true}&gt;</p>\n\n<p>Setting parameters for sequence generation in the model config is deprecated. For backward compatibility, loading\nsome of them will still be possible, but attempting to overwrite them will throw an exception -- you should set\nthem in a [~transformers.GenerationConfig]. Check the documentation of [~transformers.GenerationConfig] for more\ninformation about the individual parameters.</p>\n\n<p></Tip></p>\n\n<p>Arg:\n    name_or_path (<code>str</code>, <em>optional</em>, defaults to <code>\"\"</code>):\n        Store the string that was passed to [<code>PreTrainedModel.from_pretrained</code>] or\n        [<code>TFPreTrainedModel.from_pretrained</code>] as <code>pretrained_model_name_or_path</code> if the configuration was created\n        with such a method.\n    output_hidden_states (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>):\n        Whether or not the model should return all hidden-states.\n    output_attentions (<code>bool</code>, *optional*, defaults to <code>False</code>):\n        Whether or not the model should returns all attentions.\n    return_dict (<code>bool</code>, <em>optional</em>, defaults to <code>True</code>):\n        Whether or not the model should return a [<code>~transformers.utils.ModelOutput</code>] instead of a plain tuple.\n    is_encoder_decoder (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>):\n        Whether the model is used as an encoder/decoder or not.\n    is_decoder (<code>bool</code>, *optional*, defaults to <code>False</code>):\n        Whether to only use the decoder in an encoder-decoder architecture, otherwise it has no effect on\n        decoder-only or encoder-only architectures.\n    cross_attention_hidden_size (<code>bool</code>, <em>optional</em>):\n        The hidden size of the cross-attention layer in case the model is used as a decoder in an encoder-decoder\n        setting and the cross-attention hidden dimension differs from <code>self.config.hidden_size</code>.\n    add_cross_attention (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>):\n        Whether cross-attention layers should be added to the model. Note, this option is only relevant for models\n        that can be used as decoder models within the [<code>EncoderDecoderModel</code>] class, which consists of all models\n        in <code>AUTO_MODELS_FOR_CAUSAL_LM</code>.\n    tie_encoder_decoder (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>):\n        Whether all encoder weights should be tied to their equivalent decoder weights. This requires the encoder\n        and decoder model to have the exact same parameter names.\n    prune_heads (<code>dict[int, list[int]]</code>, <em>optional</em>, defaults to <code>{}</code>):\n        Pruned heads of the model. The keys are the selected layer indices and the associated values, the list of\n        heads to prune in said layer.</p>\n\n<pre><code>    For instance `{1: [0, 2], 2: [2, 3]}` will prune heads 0 and 2 on layer 1 and heads 2 and 3 on layer 2.\nchunk_size_feed_forward (`int`, *optional*, defaults to `0`):\n    The chunk size of all feed forward layers in the residual attention blocks. A chunk size of `0` means that\n    the feed forward layer is not chunked. A chunk size of n means that the feed forward layer processes `n` &lt;\n    sequence_length embeddings at a time. For more information on feed forward chunking, see [How does Feed\n    Forward Chunking work?](../glossary.html#feed-forward-chunking).\n\n&gt; Parameters for fine-tuning tasks\n\narchitectures (`list[str]`, *optional*):\n    Model architectures that can be used with the model pretrained weights.\nfinetuning_task (`str`, *optional*):\n    Name of the task used to fine-tune the model. This can be used when converting from an original (TensorFlow\n    or PyTorch) checkpoint.\nid2label (`dict[int, str]`, *optional*):\n    A map from index (for instance prediction index, or target index) to label.\nlabel2id (`dict[str, int]`, *optional*):\n    A map from label to index for the model.\nnum_labels (`int`, *optional*):\n    Number of labels to use in the last layer added to the model, typically for a classification task.\ntask_specific_params (`dict[str, Any]`, *optional*):\n    Additional keyword arguments to store for the current task.\nproblem_type (`str`, *optional*):\n    Problem type for `XxxForSequenceClassification` models. Can be one of `\"regression\"`,\n    `\"single_label_classification\"` or `\"multi_label_classification\"`.\n\n&gt; Parameters linked to the tokenizer\n\ntokenizer_class (`str`, *optional*):\n    The name of the associated tokenizer class to use (if none is set, will use the tokenizer associated to the\n    model by default).\nprefix (`str`, *optional*):\n    A specific prompt that should be added at the beginning of each text before calling the model.\nbos_token_id (`int`, *optional*):\n    The id of the _beginning-of-stream_ token.\npad_token_id (`int`, *optional*):\n    The id of the _padding_ token.\neos_token_id (`int`, *optional*):\n    The id of the _end-of-stream_ token.\ndecoder_start_token_id (`int`, *optional*):\n    If an encoder-decoder model starts decoding with a different token than _bos_, the id of that token.\nsep_token_id (`int`, *optional*):\n    The id of the _separation_ token.\n\n&gt; PyTorch specific parameters\n\ntorchscript (`bool`, *optional*, defaults to `False`):\n    Whether or not the model should be used with Torchscript.\ntie_word_embeddings (`bool`, *optional*, defaults to `True`):\n    Whether the model's input and output word embeddings should be tied. Note that this is only relevant if the\n    model has a output word embedding layer.\ntorch_dtype (`str`, *optional*):\n    The `dtype` of the weights. This attribute can be used to initialize the model to a non-default `dtype`\n    (which is normally `float32`) and thus allow for optimal storage allocation. For example, if the saved\n    model is `float16`, ideally we want to load it back using the minimal amount of memory needed to load\n    `float16` weights. Since the config object is stored in plain text, this attribute contains just the\n    floating type string without the `torch.` prefix. For example, for `torch.float16` ``torch_dtype` is the\n    `\"float16\"` string.\n\n    This attribute is currently not being used during model loading time, but this may change in the future\n    versions. But we can already start preparing for the future by saving the dtype with save_pretrained.\n</code></pre>\n", "bases": "transformers.configuration_utils.PretrainedConfig"}, {"fullname": "sglang.srt.configs.MultiModalityConfig.__init__", "modulename": "sglang.srt.configs", "qualname": "MultiModalityConfig.__init__", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"o\">**</span><span class=\"n\">kwargs</span></span>)</span>"}, {"fullname": "sglang.srt.configs.MultiModalityConfig.model_type", "modulename": "sglang.srt.configs", "qualname": "MultiModalityConfig.model_type", "kind": "variable", "doc": "<p></p>\n", "default_value": "&#x27;multi_modality&#x27;"}, {"fullname": "sglang.srt.configs.MultiModalityConfig.vision_config", "modulename": "sglang.srt.configs", "qualname": "MultiModalityConfig.vision_config", "kind": "variable", "doc": "<p></p>\n", "annotation": ": sglang.srt.configs.janus_pro.VisionConfig"}, {"fullname": "sglang.srt.configs.MultiModalityConfig.aligner_config", "modulename": "sglang.srt.configs", "qualname": "MultiModalityConfig.aligner_config", "kind": "variable", "doc": "<p></p>\n", "annotation": ": sglang.srt.configs.janus_pro.AlignerConfig"}, {"fullname": "sglang.srt.configs.MultiModalityConfig.gen_vision_config", "modulename": "sglang.srt.configs", "qualname": "MultiModalityConfig.gen_vision_config", "kind": "variable", "doc": "<p></p>\n", "annotation": ": sglang.srt.configs.janus_pro.GenVisionConfig"}, {"fullname": "sglang.srt.configs.MultiModalityConfig.gen_aligner_config", "modulename": "sglang.srt.configs", "qualname": "MultiModalityConfig.gen_aligner_config", "kind": "variable", "doc": "<p></p>\n", "annotation": ": sglang.srt.configs.janus_pro.GenAlignerConfig"}, {"fullname": "sglang.srt.configs.MultiModalityConfig.gen_head_config", "modulename": "sglang.srt.configs", "qualname": "MultiModalityConfig.gen_head_config", "kind": "variable", "doc": "<p></p>\n", "annotation": ": sglang.srt.configs.janus_pro.GenHeadConfig"}, {"fullname": "sglang.srt.configs.MultiModalityConfig.language_config", "modulename": "sglang.srt.configs", "qualname": "MultiModalityConfig.language_config", "kind": "variable", "doc": "<p></p>\n", "annotation": ": transformers.models.llama.configuration_llama.LlamaConfig"}, {"fullname": "sglang.srt.configs.KimiVLConfig", "modulename": "sglang.srt.configs", "qualname": "KimiVLConfig", "kind": "class", "doc": "<p>Base class for all configuration classes. Handles a few parameters common to all models' configurations as well as\nmethods for loading/downloading/saving configurations.</p>\n\n<p><Tip></p>\n\n<p>A configuration file can be loaded and saved to disk. Loading the configuration file and using this file to\ninitialize a model does <strong>not</strong> load the model weights. It only affects the model's configuration.</p>\n\n<p></Tip></p>\n\n<p>Class attributes (overridden by derived classes):</p>\n\n<ul>\n<li><strong>model_type</strong> (<code>str</code>) -- An identifier for the model type, serialized into the JSON file, and used to recreate\nthe correct object in [<code>~transformers.AutoConfig</code>].</li>\n<li><strong>has_no_defaults_at_init</strong> (<code>bool</code>) -- Whether the config class can be initialized without providing input arguments.\nSome configurations requires inputs to be defined at init and have no default values, usually these are composite configs,\n(but not necessarily) such as [<code>~transformers.EncoderDecoderConfig</code>] or [<code>~RagConfig</code>]. They have to be initialized from\ntwo or more configs of type [<code>~transformers.PretrainedConfig</code>].</li>\n<li><strong>keys_to_ignore_at_inference</strong> (<code>list[str]</code>) -- A list of keys to ignore by default when looking at dictionary\noutputs of the model during inference.</li>\n<li><strong>attribute_map</strong> (<code>dict[str, str]</code>) -- A dict that maps model specific attribute names to the standardized\nnaming of attributes.</li>\n<li><strong>base_model_tp_plan</strong> (<code>dict[str, Any]</code>) -- A dict that maps sub-modules FQNs of a base model to a tensor\nparallel plan applied to the sub-module when <code>model.tensor_parallel</code> is called.</li>\n<li><strong>base_model_pp_plan</strong> (<code>dict[str, tuple[list[str]]]</code>) -- A dict that maps child-modules of a base model to a\npipeline parallel plan that enables users to place the child-module on the appropriate device.</li>\n</ul>\n\n<p>Common attributes (present in all subclasses):</p>\n\n<ul>\n<li><strong>vocab_size</strong> (<code>int</code>) -- The number of tokens in the vocabulary, which is also the first dimension of the\nembeddings matrix (this attribute may be missing for models that don't have a text modality like ViT).</li>\n<li><strong>hidden_size</strong> (<code>int</code>) -- The hidden size of the model.</li>\n<li><strong>num_attention_heads</strong> (<code>int</code>) -- The number of attention heads used in the multi-head attention layers of the\nmodel.</li>\n<li><strong>num_hidden_layers</strong> (<code>int</code>) -- The number of blocks in the model.</li>\n</ul>\n\n<p><Tip warning={true}&gt;</p>\n\n<p>Setting parameters for sequence generation in the model config is deprecated. For backward compatibility, loading\nsome of them will still be possible, but attempting to overwrite them will throw an exception -- you should set\nthem in a [~transformers.GenerationConfig]. Check the documentation of [~transformers.GenerationConfig] for more\ninformation about the individual parameters.</p>\n\n<p></Tip></p>\n\n<p>Arg:\n    name_or_path (<code>str</code>, <em>optional</em>, defaults to <code>\"\"</code>):\n        Store the string that was passed to [<code>PreTrainedModel.from_pretrained</code>] or\n        [<code>TFPreTrainedModel.from_pretrained</code>] as <code>pretrained_model_name_or_path</code> if the configuration was created\n        with such a method.\n    output_hidden_states (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>):\n        Whether or not the model should return all hidden-states.\n    output_attentions (<code>bool</code>, *optional*, defaults to <code>False</code>):\n        Whether or not the model should returns all attentions.\n    return_dict (<code>bool</code>, <em>optional</em>, defaults to <code>True</code>):\n        Whether or not the model should return a [<code>~transformers.utils.ModelOutput</code>] instead of a plain tuple.\n    is_encoder_decoder (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>):\n        Whether the model is used as an encoder/decoder or not.\n    is_decoder (<code>bool</code>, *optional*, defaults to <code>False</code>):\n        Whether to only use the decoder in an encoder-decoder architecture, otherwise it has no effect on\n        decoder-only or encoder-only architectures.\n    cross_attention_hidden_size (<code>bool</code>, <em>optional</em>):\n        The hidden size of the cross-attention layer in case the model is used as a decoder in an encoder-decoder\n        setting and the cross-attention hidden dimension differs from <code>self.config.hidden_size</code>.\n    add_cross_attention (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>):\n        Whether cross-attention layers should be added to the model. Note, this option is only relevant for models\n        that can be used as decoder models within the [<code>EncoderDecoderModel</code>] class, which consists of all models\n        in <code>AUTO_MODELS_FOR_CAUSAL_LM</code>.\n    tie_encoder_decoder (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>):\n        Whether all encoder weights should be tied to their equivalent decoder weights. This requires the encoder\n        and decoder model to have the exact same parameter names.\n    prune_heads (<code>dict[int, list[int]]</code>, <em>optional</em>, defaults to <code>{}</code>):\n        Pruned heads of the model. The keys are the selected layer indices and the associated values, the list of\n        heads to prune in said layer.</p>\n\n<pre><code>    For instance `{1: [0, 2], 2: [2, 3]}` will prune heads 0 and 2 on layer 1 and heads 2 and 3 on layer 2.\nchunk_size_feed_forward (`int`, *optional*, defaults to `0`):\n    The chunk size of all feed forward layers in the residual attention blocks. A chunk size of `0` means that\n    the feed forward layer is not chunked. A chunk size of n means that the feed forward layer processes `n` &lt;\n    sequence_length embeddings at a time. For more information on feed forward chunking, see [How does Feed\n    Forward Chunking work?](../glossary.html#feed-forward-chunking).\n\n&gt; Parameters for fine-tuning tasks\n\narchitectures (`list[str]`, *optional*):\n    Model architectures that can be used with the model pretrained weights.\nfinetuning_task (`str`, *optional*):\n    Name of the task used to fine-tune the model. This can be used when converting from an original (TensorFlow\n    or PyTorch) checkpoint.\nid2label (`dict[int, str]`, *optional*):\n    A map from index (for instance prediction index, or target index) to label.\nlabel2id (`dict[str, int]`, *optional*):\n    A map from label to index for the model.\nnum_labels (`int`, *optional*):\n    Number of labels to use in the last layer added to the model, typically for a classification task.\ntask_specific_params (`dict[str, Any]`, *optional*):\n    Additional keyword arguments to store for the current task.\nproblem_type (`str`, *optional*):\n    Problem type for `XxxForSequenceClassification` models. Can be one of `\"regression\"`,\n    `\"single_label_classification\"` or `\"multi_label_classification\"`.\n\n&gt; Parameters linked to the tokenizer\n\ntokenizer_class (`str`, *optional*):\n    The name of the associated tokenizer class to use (if none is set, will use the tokenizer associated to the\n    model by default).\nprefix (`str`, *optional*):\n    A specific prompt that should be added at the beginning of each text before calling the model.\nbos_token_id (`int`, *optional*):\n    The id of the _beginning-of-stream_ token.\npad_token_id (`int`, *optional*):\n    The id of the _padding_ token.\neos_token_id (`int`, *optional*):\n    The id of the _end-of-stream_ token.\ndecoder_start_token_id (`int`, *optional*):\n    If an encoder-decoder model starts decoding with a different token than _bos_, the id of that token.\nsep_token_id (`int`, *optional*):\n    The id of the _separation_ token.\n\n&gt; PyTorch specific parameters\n\ntorchscript (`bool`, *optional*, defaults to `False`):\n    Whether or not the model should be used with Torchscript.\ntie_word_embeddings (`bool`, *optional*, defaults to `True`):\n    Whether the model's input and output word embeddings should be tied. Note that this is only relevant if the\n    model has a output word embedding layer.\ntorch_dtype (`str`, *optional*):\n    The `dtype` of the weights. This attribute can be used to initialize the model to a non-default `dtype`\n    (which is normally `float32`) and thus allow for optimal storage allocation. For example, if the saved\n    model is `float16`, ideally we want to load it back using the minimal amount of memory needed to load\n    `float16` weights. Since the config object is stored in plain text, this attribute contains just the\n    floating type string without the `torch.` prefix. For example, for `torch.float16` ``torch_dtype` is the\n    `\"float16\"` string.\n\n    This attribute is currently not being used during model loading time, but this may change in the future\n    versions. But we can already start preparing for the future by saving the dtype with save_pretrained.\n</code></pre>\n", "bases": "transformers.configuration_utils.PretrainedConfig"}, {"fullname": "sglang.srt.configs.KimiVLConfig.__init__", "modulename": "sglang.srt.configs", "qualname": "KimiVLConfig.__init__", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">vision_config</span><span class=\"p\">:</span> <span class=\"n\">Union</span><span class=\"p\">[</span><span class=\"nb\">dict</span><span class=\"p\">,</span> <span class=\"n\">sglang</span><span class=\"o\">.</span><span class=\"n\">srt</span><span class=\"o\">.</span><span class=\"n\">configs</span><span class=\"o\">.</span><span class=\"n\">kimi_vl_moonvit</span><span class=\"o\">.</span><span class=\"n\">MoonViTConfig</span><span class=\"p\">,</span> <span class=\"n\">NoneType</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">text_config</span><span class=\"p\">:</span> <span class=\"n\">Union</span><span class=\"p\">[</span><span class=\"nb\">dict</span><span class=\"p\">,</span> <span class=\"n\">sglang</span><span class=\"o\">.</span><span class=\"n\">srt</span><span class=\"o\">.</span><span class=\"n\">configs</span><span class=\"o\">.</span><span class=\"n\">deepseekvl2</span><span class=\"o\">.</span><span class=\"n\">DeepseekV2Config</span><span class=\"p\">,</span> <span class=\"n\">NoneType</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">ignore_index</span><span class=\"p\">:</span> <span class=\"nb\">int</span> <span class=\"o\">=</span> <span class=\"o\">-</span><span class=\"mi\">100</span>,</span><span class=\"param\">\t<span class=\"n\">media_placeholder_token_id</span><span class=\"p\">:</span> <span class=\"nb\">int</span> <span class=\"o\">=</span> <span class=\"mi\">163605</span>,</span><span class=\"param\">\t<span class=\"n\">pad_token_id</span><span class=\"p\">:</span> <span class=\"nb\">int</span> <span class=\"o\">=</span> <span class=\"mi\">0</span>,</span><span class=\"param\">\t<span class=\"o\">**</span><span class=\"n\">kwargs</span></span>)</span>"}, {"fullname": "sglang.srt.configs.KimiVLConfig.model_type", "modulename": "sglang.srt.configs", "qualname": "KimiVLConfig.model_type", "kind": "variable", "doc": "<p></p>\n", "default_value": "&#x27;kimi_vl&#x27;"}, {"fullname": "sglang.srt.configs.KimiVLConfig.vision_config", "modulename": "sglang.srt.configs", "qualname": "KimiVLConfig.vision_config", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "sglang.srt.configs.KimiVLConfig.text_config", "modulename": "sglang.srt.configs", "qualname": "KimiVLConfig.text_config", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "sglang.srt.configs.KimiVLConfig.ignore_index", "modulename": "sglang.srt.configs", "qualname": "KimiVLConfig.ignore_index", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "sglang.srt.configs.KimiVLConfig.media_placeholder_token_id", "modulename": "sglang.srt.configs", "qualname": "KimiVLConfig.media_placeholder_token_id", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "sglang.srt.configs.MoonViTConfig", "modulename": "sglang.srt.configs", "qualname": "MoonViTConfig", "kind": "class", "doc": "<p>Base class for all configuration classes. Handles a few parameters common to all models' configurations as well as\nmethods for loading/downloading/saving configurations.</p>\n\n<p><Tip></p>\n\n<p>A configuration file can be loaded and saved to disk. Loading the configuration file and using this file to\ninitialize a model does <strong>not</strong> load the model weights. It only affects the model's configuration.</p>\n\n<p></Tip></p>\n\n<p>Class attributes (overridden by derived classes):</p>\n\n<ul>\n<li><strong>model_type</strong> (<code>str</code>) -- An identifier for the model type, serialized into the JSON file, and used to recreate\nthe correct object in [<code>~transformers.AutoConfig</code>].</li>\n<li><strong>has_no_defaults_at_init</strong> (<code>bool</code>) -- Whether the config class can be initialized without providing input arguments.\nSome configurations requires inputs to be defined at init and have no default values, usually these are composite configs,\n(but not necessarily) such as [<code>~transformers.EncoderDecoderConfig</code>] or [<code>~RagConfig</code>]. They have to be initialized from\ntwo or more configs of type [<code>~transformers.PretrainedConfig</code>].</li>\n<li><strong>keys_to_ignore_at_inference</strong> (<code>list[str]</code>) -- A list of keys to ignore by default when looking at dictionary\noutputs of the model during inference.</li>\n<li><strong>attribute_map</strong> (<code>dict[str, str]</code>) -- A dict that maps model specific attribute names to the standardized\nnaming of attributes.</li>\n<li><strong>base_model_tp_plan</strong> (<code>dict[str, Any]</code>) -- A dict that maps sub-modules FQNs of a base model to a tensor\nparallel plan applied to the sub-module when <code>model.tensor_parallel</code> is called.</li>\n<li><strong>base_model_pp_plan</strong> (<code>dict[str, tuple[list[str]]]</code>) -- A dict that maps child-modules of a base model to a\npipeline parallel plan that enables users to place the child-module on the appropriate device.</li>\n</ul>\n\n<p>Common attributes (present in all subclasses):</p>\n\n<ul>\n<li><strong>vocab_size</strong> (<code>int</code>) -- The number of tokens in the vocabulary, which is also the first dimension of the\nembeddings matrix (this attribute may be missing for models that don't have a text modality like ViT).</li>\n<li><strong>hidden_size</strong> (<code>int</code>) -- The hidden size of the model.</li>\n<li><strong>num_attention_heads</strong> (<code>int</code>) -- The number of attention heads used in the multi-head attention layers of the\nmodel.</li>\n<li><strong>num_hidden_layers</strong> (<code>int</code>) -- The number of blocks in the model.</li>\n</ul>\n\n<p><Tip warning={true}&gt;</p>\n\n<p>Setting parameters for sequence generation in the model config is deprecated. For backward compatibility, loading\nsome of them will still be possible, but attempting to overwrite them will throw an exception -- you should set\nthem in a [~transformers.GenerationConfig]. Check the documentation of [~transformers.GenerationConfig] for more\ninformation about the individual parameters.</p>\n\n<p></Tip></p>\n\n<p>Arg:\n    name_or_path (<code>str</code>, <em>optional</em>, defaults to <code>\"\"</code>):\n        Store the string that was passed to [<code>PreTrainedModel.from_pretrained</code>] or\n        [<code>TFPreTrainedModel.from_pretrained</code>] as <code>pretrained_model_name_or_path</code> if the configuration was created\n        with such a method.\n    output_hidden_states (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>):\n        Whether or not the model should return all hidden-states.\n    output_attentions (<code>bool</code>, *optional*, defaults to <code>False</code>):\n        Whether or not the model should returns all attentions.\n    return_dict (<code>bool</code>, <em>optional</em>, defaults to <code>True</code>):\n        Whether or not the model should return a [<code>~transformers.utils.ModelOutput</code>] instead of a plain tuple.\n    is_encoder_decoder (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>):\n        Whether the model is used as an encoder/decoder or not.\n    is_decoder (<code>bool</code>, *optional*, defaults to <code>False</code>):\n        Whether to only use the decoder in an encoder-decoder architecture, otherwise it has no effect on\n        decoder-only or encoder-only architectures.\n    cross_attention_hidden_size (<code>bool</code>, <em>optional</em>):\n        The hidden size of the cross-attention layer in case the model is used as a decoder in an encoder-decoder\n        setting and the cross-attention hidden dimension differs from <code>self.config.hidden_size</code>.\n    add_cross_attention (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>):\n        Whether cross-attention layers should be added to the model. Note, this option is only relevant for models\n        that can be used as decoder models within the [<code>EncoderDecoderModel</code>] class, which consists of all models\n        in <code>AUTO_MODELS_FOR_CAUSAL_LM</code>.\n    tie_encoder_decoder (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>):\n        Whether all encoder weights should be tied to their equivalent decoder weights. This requires the encoder\n        and decoder model to have the exact same parameter names.\n    prune_heads (<code>dict[int, list[int]]</code>, <em>optional</em>, defaults to <code>{}</code>):\n        Pruned heads of the model. The keys are the selected layer indices and the associated values, the list of\n        heads to prune in said layer.</p>\n\n<pre><code>    For instance `{1: [0, 2], 2: [2, 3]}` will prune heads 0 and 2 on layer 1 and heads 2 and 3 on layer 2.\nchunk_size_feed_forward (`int`, *optional*, defaults to `0`):\n    The chunk size of all feed forward layers in the residual attention blocks. A chunk size of `0` means that\n    the feed forward layer is not chunked. A chunk size of n means that the feed forward layer processes `n` &lt;\n    sequence_length embeddings at a time. For more information on feed forward chunking, see [How does Feed\n    Forward Chunking work?](../glossary.html#feed-forward-chunking).\n\n&gt; Parameters for fine-tuning tasks\n\narchitectures (`list[str]`, *optional*):\n    Model architectures that can be used with the model pretrained weights.\nfinetuning_task (`str`, *optional*):\n    Name of the task used to fine-tune the model. This can be used when converting from an original (TensorFlow\n    or PyTorch) checkpoint.\nid2label (`dict[int, str]`, *optional*):\n    A map from index (for instance prediction index, or target index) to label.\nlabel2id (`dict[str, int]`, *optional*):\n    A map from label to index for the model.\nnum_labels (`int`, *optional*):\n    Number of labels to use in the last layer added to the model, typically for a classification task.\ntask_specific_params (`dict[str, Any]`, *optional*):\n    Additional keyword arguments to store for the current task.\nproblem_type (`str`, *optional*):\n    Problem type for `XxxForSequenceClassification` models. Can be one of `\"regression\"`,\n    `\"single_label_classification\"` or `\"multi_label_classification\"`.\n\n&gt; Parameters linked to the tokenizer\n\ntokenizer_class (`str`, *optional*):\n    The name of the associated tokenizer class to use (if none is set, will use the tokenizer associated to the\n    model by default).\nprefix (`str`, *optional*):\n    A specific prompt that should be added at the beginning of each text before calling the model.\nbos_token_id (`int`, *optional*):\n    The id of the _beginning-of-stream_ token.\npad_token_id (`int`, *optional*):\n    The id of the _padding_ token.\neos_token_id (`int`, *optional*):\n    The id of the _end-of-stream_ token.\ndecoder_start_token_id (`int`, *optional*):\n    If an encoder-decoder model starts decoding with a different token than _bos_, the id of that token.\nsep_token_id (`int`, *optional*):\n    The id of the _separation_ token.\n\n&gt; PyTorch specific parameters\n\ntorchscript (`bool`, *optional*, defaults to `False`):\n    Whether or not the model should be used with Torchscript.\ntie_word_embeddings (`bool`, *optional*, defaults to `True`):\n    Whether the model's input and output word embeddings should be tied. Note that this is only relevant if the\n    model has a output word embedding layer.\ntorch_dtype (`str`, *optional*):\n    The `dtype` of the weights. This attribute can be used to initialize the model to a non-default `dtype`\n    (which is normally `float32`) and thus allow for optimal storage allocation. For example, if the saved\n    model is `float16`, ideally we want to load it back using the minimal amount of memory needed to load\n    `float16` weights. Since the config object is stored in plain text, this attribute contains just the\n    floating type string without the `torch.` prefix. For example, for `torch.float16` ``torch_dtype` is the\n    `\"float16\"` string.\n\n    This attribute is currently not being used during model loading time, but this may change in the future\n    versions. But we can already start preparing for the future by saving the dtype with save_pretrained.\n</code></pre>\n", "bases": "transformers.configuration_utils.PretrainedConfig"}, {"fullname": "sglang.srt.configs.MoonViTConfig.__init__", "modulename": "sglang.srt.configs", "qualname": "MoonViTConfig.__init__", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">patch_size</span><span class=\"p\">:</span> <span class=\"nb\">int</span> <span class=\"o\">=</span> <span class=\"mi\">14</span>,</span><span class=\"param\">\t<span class=\"n\">init_pos_emb_height</span><span class=\"p\">:</span> <span class=\"nb\">int</span> <span class=\"o\">=</span> <span class=\"mi\">64</span>,</span><span class=\"param\">\t<span class=\"n\">init_pos_emb_width</span><span class=\"p\">:</span> <span class=\"nb\">int</span> <span class=\"o\">=</span> <span class=\"mi\">64</span>,</span><span class=\"param\">\t<span class=\"n\">num_attention_heads</span><span class=\"p\">:</span> <span class=\"nb\">int</span> <span class=\"o\">=</span> <span class=\"mi\">16</span>,</span><span class=\"param\">\t<span class=\"n\">num_hidden_layers</span><span class=\"p\">:</span> <span class=\"nb\">int</span> <span class=\"o\">=</span> <span class=\"mi\">27</span>,</span><span class=\"param\">\t<span class=\"n\">hidden_size</span><span class=\"p\">:</span> <span class=\"nb\">int</span> <span class=\"o\">=</span> <span class=\"mi\">1152</span>,</span><span class=\"param\">\t<span class=\"n\">intermediate_size</span><span class=\"p\">:</span> <span class=\"nb\">int</span> <span class=\"o\">=</span> <span class=\"mi\">4304</span>,</span><span class=\"param\">\t<span class=\"n\">merge_kernel_size</span><span class=\"p\">:</span> <span class=\"nb\">tuple</span><span class=\"p\">[</span><span class=\"nb\">int</span><span class=\"p\">,</span> <span class=\"nb\">int</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"p\">(</span><span class=\"mi\">2</span><span class=\"p\">,</span> <span class=\"mi\">2</span><span class=\"p\">)</span>,</span><span class=\"param\">\t<span class=\"o\">**</span><span class=\"n\">kwargs</span></span>)</span>"}, {"fullname": "sglang.srt.configs.MoonViTConfig.model_type", "modulename": "sglang.srt.configs", "qualname": "MoonViTConfig.model_type", "kind": "variable", "doc": "<p></p>\n", "default_value": "&#x27;moonvit&#x27;"}, {"fullname": "sglang.srt.configs.MoonViTConfig.patch_size", "modulename": "sglang.srt.configs", "qualname": "MoonViTConfig.patch_size", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "sglang.srt.configs.MoonViTConfig.init_pos_emb_height", "modulename": "sglang.srt.configs", "qualname": "MoonViTConfig.init_pos_emb_height", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "sglang.srt.configs.MoonViTConfig.init_pos_emb_width", "modulename": "sglang.srt.configs", "qualname": "MoonViTConfig.init_pos_emb_width", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "sglang.srt.configs.MoonViTConfig.num_hidden_layers", "modulename": "sglang.srt.configs", "qualname": "MoonViTConfig.num_hidden_layers", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "sglang.srt.configs.MoonViTConfig.num_attention_heads", "modulename": "sglang.srt.configs", "qualname": "MoonViTConfig.num_attention_heads", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "sglang.srt.configs.MoonViTConfig.hidden_size", "modulename": "sglang.srt.configs", "qualname": "MoonViTConfig.hidden_size", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "sglang.srt.configs.MoonViTConfig.intermediate_size", "modulename": "sglang.srt.configs", "qualname": "MoonViTConfig.intermediate_size", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "sglang.srt.configs.MoonViTConfig.merge_kernel_size", "modulename": "sglang.srt.configs", "qualname": "MoonViTConfig.merge_kernel_size", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "sglang.srt.configs.Step3VLConfig", "modulename": "sglang.srt.configs", "qualname": "Step3VLConfig", "kind": "class", "doc": "<p>Base class for all configuration classes. Handles a few parameters common to all models' configurations as well as\nmethods for loading/downloading/saving configurations.</p>\n\n<p><Tip></p>\n\n<p>A configuration file can be loaded and saved to disk. Loading the configuration file and using this file to\ninitialize a model does <strong>not</strong> load the model weights. It only affects the model's configuration.</p>\n\n<p></Tip></p>\n\n<p>Class attributes (overridden by derived classes):</p>\n\n<ul>\n<li><strong>model_type</strong> (<code>str</code>) -- An identifier for the model type, serialized into the JSON file, and used to recreate\nthe correct object in [<code>~transformers.AutoConfig</code>].</li>\n<li><strong>has_no_defaults_at_init</strong> (<code>bool</code>) -- Whether the config class can be initialized without providing input arguments.\nSome configurations requires inputs to be defined at init and have no default values, usually these are composite configs,\n(but not necessarily) such as [<code>~transformers.EncoderDecoderConfig</code>] or [<code>~RagConfig</code>]. They have to be initialized from\ntwo or more configs of type [<code>~transformers.PretrainedConfig</code>].</li>\n<li><strong>keys_to_ignore_at_inference</strong> (<code>list[str]</code>) -- A list of keys to ignore by default when looking at dictionary\noutputs of the model during inference.</li>\n<li><strong>attribute_map</strong> (<code>dict[str, str]</code>) -- A dict that maps model specific attribute names to the standardized\nnaming of attributes.</li>\n<li><strong>base_model_tp_plan</strong> (<code>dict[str, Any]</code>) -- A dict that maps sub-modules FQNs of a base model to a tensor\nparallel plan applied to the sub-module when <code>model.tensor_parallel</code> is called.</li>\n<li><strong>base_model_pp_plan</strong> (<code>dict[str, tuple[list[str]]]</code>) -- A dict that maps child-modules of a base model to a\npipeline parallel plan that enables users to place the child-module on the appropriate device.</li>\n</ul>\n\n<p>Common attributes (present in all subclasses):</p>\n\n<ul>\n<li><strong>vocab_size</strong> (<code>int</code>) -- The number of tokens in the vocabulary, which is also the first dimension of the\nembeddings matrix (this attribute may be missing for models that don't have a text modality like ViT).</li>\n<li><strong>hidden_size</strong> (<code>int</code>) -- The hidden size of the model.</li>\n<li><strong>num_attention_heads</strong> (<code>int</code>) -- The number of attention heads used in the multi-head attention layers of the\nmodel.</li>\n<li><strong>num_hidden_layers</strong> (<code>int</code>) -- The number of blocks in the model.</li>\n</ul>\n\n<p><Tip warning={true}&gt;</p>\n\n<p>Setting parameters for sequence generation in the model config is deprecated. For backward compatibility, loading\nsome of them will still be possible, but attempting to overwrite them will throw an exception -- you should set\nthem in a [~transformers.GenerationConfig]. Check the documentation of [~transformers.GenerationConfig] for more\ninformation about the individual parameters.</p>\n\n<p></Tip></p>\n\n<p>Arg:\n    name_or_path (<code>str</code>, <em>optional</em>, defaults to <code>\"\"</code>):\n        Store the string that was passed to [<code>PreTrainedModel.from_pretrained</code>] or\n        [<code>TFPreTrainedModel.from_pretrained</code>] as <code>pretrained_model_name_or_path</code> if the configuration was created\n        with such a method.\n    output_hidden_states (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>):\n        Whether or not the model should return all hidden-states.\n    output_attentions (<code>bool</code>, *optional*, defaults to <code>False</code>):\n        Whether or not the model should returns all attentions.\n    return_dict (<code>bool</code>, <em>optional</em>, defaults to <code>True</code>):\n        Whether or not the model should return a [<code>~transformers.utils.ModelOutput</code>] instead of a plain tuple.\n    is_encoder_decoder (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>):\n        Whether the model is used as an encoder/decoder or not.\n    is_decoder (<code>bool</code>, *optional*, defaults to <code>False</code>):\n        Whether to only use the decoder in an encoder-decoder architecture, otherwise it has no effect on\n        decoder-only or encoder-only architectures.\n    cross_attention_hidden_size (<code>bool</code>, <em>optional</em>):\n        The hidden size of the cross-attention layer in case the model is used as a decoder in an encoder-decoder\n        setting and the cross-attention hidden dimension differs from <code>self.config.hidden_size</code>.\n    add_cross_attention (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>):\n        Whether cross-attention layers should be added to the model. Note, this option is only relevant for models\n        that can be used as decoder models within the [<code>EncoderDecoderModel</code>] class, which consists of all models\n        in <code>AUTO_MODELS_FOR_CAUSAL_LM</code>.\n    tie_encoder_decoder (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>):\n        Whether all encoder weights should be tied to their equivalent decoder weights. This requires the encoder\n        and decoder model to have the exact same parameter names.\n    prune_heads (<code>dict[int, list[int]]</code>, <em>optional</em>, defaults to <code>{}</code>):\n        Pruned heads of the model. The keys are the selected layer indices and the associated values, the list of\n        heads to prune in said layer.</p>\n\n<pre><code>    For instance `{1: [0, 2], 2: [2, 3]}` will prune heads 0 and 2 on layer 1 and heads 2 and 3 on layer 2.\nchunk_size_feed_forward (`int`, *optional*, defaults to `0`):\n    The chunk size of all feed forward layers in the residual attention blocks. A chunk size of `0` means that\n    the feed forward layer is not chunked. A chunk size of n means that the feed forward layer processes `n` &lt;\n    sequence_length embeddings at a time. For more information on feed forward chunking, see [How does Feed\n    Forward Chunking work?](../glossary.html#feed-forward-chunking).\n\n&gt; Parameters for fine-tuning tasks\n\narchitectures (`list[str]`, *optional*):\n    Model architectures that can be used with the model pretrained weights.\nfinetuning_task (`str`, *optional*):\n    Name of the task used to fine-tune the model. This can be used when converting from an original (TensorFlow\n    or PyTorch) checkpoint.\nid2label (`dict[int, str]`, *optional*):\n    A map from index (for instance prediction index, or target index) to label.\nlabel2id (`dict[str, int]`, *optional*):\n    A map from label to index for the model.\nnum_labels (`int`, *optional*):\n    Number of labels to use in the last layer added to the model, typically for a classification task.\ntask_specific_params (`dict[str, Any]`, *optional*):\n    Additional keyword arguments to store for the current task.\nproblem_type (`str`, *optional*):\n    Problem type for `XxxForSequenceClassification` models. Can be one of `\"regression\"`,\n    `\"single_label_classification\"` or `\"multi_label_classification\"`.\n\n&gt; Parameters linked to the tokenizer\n\ntokenizer_class (`str`, *optional*):\n    The name of the associated tokenizer class to use (if none is set, will use the tokenizer associated to the\n    model by default).\nprefix (`str`, *optional*):\n    A specific prompt that should be added at the beginning of each text before calling the model.\nbos_token_id (`int`, *optional*):\n    The id of the _beginning-of-stream_ token.\npad_token_id (`int`, *optional*):\n    The id of the _padding_ token.\neos_token_id (`int`, *optional*):\n    The id of the _end-of-stream_ token.\ndecoder_start_token_id (`int`, *optional*):\n    If an encoder-decoder model starts decoding with a different token than _bos_, the id of that token.\nsep_token_id (`int`, *optional*):\n    The id of the _separation_ token.\n\n&gt; PyTorch specific parameters\n\ntorchscript (`bool`, *optional*, defaults to `False`):\n    Whether or not the model should be used with Torchscript.\ntie_word_embeddings (`bool`, *optional*, defaults to `True`):\n    Whether the model's input and output word embeddings should be tied. Note that this is only relevant if the\n    model has a output word embedding layer.\ntorch_dtype (`str`, *optional*):\n    The `dtype` of the weights. This attribute can be used to initialize the model to a non-default `dtype`\n    (which is normally `float32`) and thus allow for optimal storage allocation. For example, if the saved\n    model is `float16`, ideally we want to load it back using the minimal amount of memory needed to load\n    `float16` weights. Since the config object is stored in plain text, this attribute contains just the\n    floating type string without the `torch.` prefix. For example, for `torch.float16` ``torch_dtype` is the\n    `\"float16\"` string.\n\n    This attribute is currently not being used during model loading time, but this may change in the future\n    versions. But we can already start preparing for the future by saving the dtype with save_pretrained.\n</code></pre>\n", "bases": "transformers.configuration_utils.PretrainedConfig"}, {"fullname": "sglang.srt.configs.Step3VLConfig.__init__", "modulename": "sglang.srt.configs", "qualname": "Step3VLConfig.__init__", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">vision_config</span><span class=\"p\">:</span> <span class=\"n\">Union</span><span class=\"p\">[</span><span class=\"nb\">dict</span><span class=\"p\">,</span> <span class=\"n\">sglang</span><span class=\"o\">.</span><span class=\"n\">srt</span><span class=\"o\">.</span><span class=\"n\">configs</span><span class=\"o\">.</span><span class=\"n\">step3_vl</span><span class=\"o\">.</span><span class=\"n\">Step3VisionEncoderConfig</span><span class=\"p\">,</span> <span class=\"n\">NoneType</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">text_config</span><span class=\"p\">:</span> <span class=\"n\">Union</span><span class=\"p\">[</span><span class=\"nb\">dict</span><span class=\"p\">,</span> <span class=\"n\">sglang</span><span class=\"o\">.</span><span class=\"n\">srt</span><span class=\"o\">.</span><span class=\"n\">configs</span><span class=\"o\">.</span><span class=\"n\">step3_vl</span><span class=\"o\">.</span><span class=\"n\">Step3TextConfig</span><span class=\"p\">,</span> <span class=\"n\">NoneType</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">understand_projector_stride</span><span class=\"p\">:</span> <span class=\"nb\">int</span> <span class=\"o\">=</span> <span class=\"mi\">1</span>,</span><span class=\"param\">\t<span class=\"n\">projector_bias</span><span class=\"p\">:</span> <span class=\"nb\">bool</span> <span class=\"o\">=</span> <span class=\"kc\">True</span>,</span><span class=\"param\">\t<span class=\"n\">image_token_id</span><span class=\"p\">:</span> <span class=\"nb\">int</span> <span class=\"o\">=</span> <span class=\"mi\">128001</span>,</span><span class=\"param\">\t<span class=\"o\">**</span><span class=\"n\">kwargs</span></span>)</span>"}, {"fullname": "sglang.srt.configs.Step3VLConfig.model_type", "modulename": "sglang.srt.configs", "qualname": "Step3VLConfig.model_type", "kind": "variable", "doc": "<p></p>\n", "default_value": "&#x27;step3_vl&#x27;"}, {"fullname": "sglang.srt.configs.Step3VLConfig.vision_config", "modulename": "sglang.srt.configs", "qualname": "Step3VLConfig.vision_config", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "sglang.srt.configs.Step3VLConfig.text_config", "modulename": "sglang.srt.configs", "qualname": "Step3VLConfig.text_config", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "sglang.srt.configs.Step3VLConfig.understand_projector_stride", "modulename": "sglang.srt.configs", "qualname": "Step3VLConfig.understand_projector_stride", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "sglang.srt.configs.Step3VLConfig.projector_bias", "modulename": "sglang.srt.configs", "qualname": "Step3VLConfig.projector_bias", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "sglang.srt.configs.Step3VLConfig.hidden_size", "modulename": "sglang.srt.configs", "qualname": "Step3VLConfig.hidden_size", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "sglang.srt.configs.Step3VLConfig.image_token_id", "modulename": "sglang.srt.configs", "qualname": "Step3VLConfig.image_token_id", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "sglang.srt.configs.Step3TextConfig", "modulename": "sglang.srt.configs", "qualname": "Step3TextConfig", "kind": "class", "doc": "<p>Base class for all configuration classes. Handles a few parameters common to all models' configurations as well as\nmethods for loading/downloading/saving configurations.</p>\n\n<p><Tip></p>\n\n<p>A configuration file can be loaded and saved to disk. Loading the configuration file and using this file to\ninitialize a model does <strong>not</strong> load the model weights. It only affects the model's configuration.</p>\n\n<p></Tip></p>\n\n<p>Class attributes (overridden by derived classes):</p>\n\n<ul>\n<li><strong>model_type</strong> (<code>str</code>) -- An identifier for the model type, serialized into the JSON file, and used to recreate\nthe correct object in [<code>~transformers.AutoConfig</code>].</li>\n<li><strong>has_no_defaults_at_init</strong> (<code>bool</code>) -- Whether the config class can be initialized without providing input arguments.\nSome configurations requires inputs to be defined at init and have no default values, usually these are composite configs,\n(but not necessarily) such as [<code>~transformers.EncoderDecoderConfig</code>] or [<code>~RagConfig</code>]. They have to be initialized from\ntwo or more configs of type [<code>~transformers.PretrainedConfig</code>].</li>\n<li><strong>keys_to_ignore_at_inference</strong> (<code>list[str]</code>) -- A list of keys to ignore by default when looking at dictionary\noutputs of the model during inference.</li>\n<li><strong>attribute_map</strong> (<code>dict[str, str]</code>) -- A dict that maps model specific attribute names to the standardized\nnaming of attributes.</li>\n<li><strong>base_model_tp_plan</strong> (<code>dict[str, Any]</code>) -- A dict that maps sub-modules FQNs of a base model to a tensor\nparallel plan applied to the sub-module when <code>model.tensor_parallel</code> is called.</li>\n<li><strong>base_model_pp_plan</strong> (<code>dict[str, tuple[list[str]]]</code>) -- A dict that maps child-modules of a base model to a\npipeline parallel plan that enables users to place the child-module on the appropriate device.</li>\n</ul>\n\n<p>Common attributes (present in all subclasses):</p>\n\n<ul>\n<li><strong>vocab_size</strong> (<code>int</code>) -- The number of tokens in the vocabulary, which is also the first dimension of the\nembeddings matrix (this attribute may be missing for models that don't have a text modality like ViT).</li>\n<li><strong>hidden_size</strong> (<code>int</code>) -- The hidden size of the model.</li>\n<li><strong>num_attention_heads</strong> (<code>int</code>) -- The number of attention heads used in the multi-head attention layers of the\nmodel.</li>\n<li><strong>num_hidden_layers</strong> (<code>int</code>) -- The number of blocks in the model.</li>\n</ul>\n\n<p><Tip warning={true}&gt;</p>\n\n<p>Setting parameters for sequence generation in the model config is deprecated. For backward compatibility, loading\nsome of them will still be possible, but attempting to overwrite them will throw an exception -- you should set\nthem in a [~transformers.GenerationConfig]. Check the documentation of [~transformers.GenerationConfig] for more\ninformation about the individual parameters.</p>\n\n<p></Tip></p>\n\n<p>Arg:\n    name_or_path (<code>str</code>, <em>optional</em>, defaults to <code>\"\"</code>):\n        Store the string that was passed to [<code>PreTrainedModel.from_pretrained</code>] or\n        [<code>TFPreTrainedModel.from_pretrained</code>] as <code>pretrained_model_name_or_path</code> if the configuration was created\n        with such a method.\n    output_hidden_states (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>):\n        Whether or not the model should return all hidden-states.\n    output_attentions (<code>bool</code>, *optional*, defaults to <code>False</code>):\n        Whether or not the model should returns all attentions.\n    return_dict (<code>bool</code>, <em>optional</em>, defaults to <code>True</code>):\n        Whether or not the model should return a [<code>~transformers.utils.ModelOutput</code>] instead of a plain tuple.\n    is_encoder_decoder (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>):\n        Whether the model is used as an encoder/decoder or not.\n    is_decoder (<code>bool</code>, *optional*, defaults to <code>False</code>):\n        Whether to only use the decoder in an encoder-decoder architecture, otherwise it has no effect on\n        decoder-only or encoder-only architectures.\n    cross_attention_hidden_size (<code>bool</code>, <em>optional</em>):\n        The hidden size of the cross-attention layer in case the model is used as a decoder in an encoder-decoder\n        setting and the cross-attention hidden dimension differs from <code>self.config.hidden_size</code>.\n    add_cross_attention (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>):\n        Whether cross-attention layers should be added to the model. Note, this option is only relevant for models\n        that can be used as decoder models within the [<code>EncoderDecoderModel</code>] class, which consists of all models\n        in <code>AUTO_MODELS_FOR_CAUSAL_LM</code>.\n    tie_encoder_decoder (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>):\n        Whether all encoder weights should be tied to their equivalent decoder weights. This requires the encoder\n        and decoder model to have the exact same parameter names.\n    prune_heads (<code>dict[int, list[int]]</code>, <em>optional</em>, defaults to <code>{}</code>):\n        Pruned heads of the model. The keys are the selected layer indices and the associated values, the list of\n        heads to prune in said layer.</p>\n\n<pre><code>    For instance `{1: [0, 2], 2: [2, 3]}` will prune heads 0 and 2 on layer 1 and heads 2 and 3 on layer 2.\nchunk_size_feed_forward (`int`, *optional*, defaults to `0`):\n    The chunk size of all feed forward layers in the residual attention blocks. A chunk size of `0` means that\n    the feed forward layer is not chunked. A chunk size of n means that the feed forward layer processes `n` &lt;\n    sequence_length embeddings at a time. For more information on feed forward chunking, see [How does Feed\n    Forward Chunking work?](../glossary.html#feed-forward-chunking).\n\n&gt; Parameters for fine-tuning tasks\n\narchitectures (`list[str]`, *optional*):\n    Model architectures that can be used with the model pretrained weights.\nfinetuning_task (`str`, *optional*):\n    Name of the task used to fine-tune the model. This can be used when converting from an original (TensorFlow\n    or PyTorch) checkpoint.\nid2label (`dict[int, str]`, *optional*):\n    A map from index (for instance prediction index, or target index) to label.\nlabel2id (`dict[str, int]`, *optional*):\n    A map from label to index for the model.\nnum_labels (`int`, *optional*):\n    Number of labels to use in the last layer added to the model, typically for a classification task.\ntask_specific_params (`dict[str, Any]`, *optional*):\n    Additional keyword arguments to store for the current task.\nproblem_type (`str`, *optional*):\n    Problem type for `XxxForSequenceClassification` models. Can be one of `\"regression\"`,\n    `\"single_label_classification\"` or `\"multi_label_classification\"`.\n\n&gt; Parameters linked to the tokenizer\n\ntokenizer_class (`str`, *optional*):\n    The name of the associated tokenizer class to use (if none is set, will use the tokenizer associated to the\n    model by default).\nprefix (`str`, *optional*):\n    A specific prompt that should be added at the beginning of each text before calling the model.\nbos_token_id (`int`, *optional*):\n    The id of the _beginning-of-stream_ token.\npad_token_id (`int`, *optional*):\n    The id of the _padding_ token.\neos_token_id (`int`, *optional*):\n    The id of the _end-of-stream_ token.\ndecoder_start_token_id (`int`, *optional*):\n    If an encoder-decoder model starts decoding with a different token than _bos_, the id of that token.\nsep_token_id (`int`, *optional*):\n    The id of the _separation_ token.\n\n&gt; PyTorch specific parameters\n\ntorchscript (`bool`, *optional*, defaults to `False`):\n    Whether or not the model should be used with Torchscript.\ntie_word_embeddings (`bool`, *optional*, defaults to `True`):\n    Whether the model's input and output word embeddings should be tied. Note that this is only relevant if the\n    model has a output word embedding layer.\ntorch_dtype (`str`, *optional*):\n    The `dtype` of the weights. This attribute can be used to initialize the model to a non-default `dtype`\n    (which is normally `float32`) and thus allow for optimal storage allocation. For example, if the saved\n    model is `float16`, ideally we want to load it back using the minimal amount of memory needed to load\n    `float16` weights. Since the config object is stored in plain text, this attribute contains just the\n    floating type string without the `torch.` prefix. For example, for `torch.float16` ``torch_dtype` is the\n    `\"float16\"` string.\n\n    This attribute is currently not being used during model loading time, but this may change in the future\n    versions. But we can already start preparing for the future by saving the dtype with save_pretrained.\n</code></pre>\n", "bases": "transformers.configuration_utils.PretrainedConfig"}, {"fullname": "sglang.srt.configs.Step3TextConfig.__init__", "modulename": "sglang.srt.configs", "qualname": "Step3TextConfig.__init__", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">hidden_size</span><span class=\"p\">:</span> <span class=\"nb\">int</span> <span class=\"o\">=</span> <span class=\"mi\">7168</span>,</span><span class=\"param\">\t<span class=\"n\">intermediate_size</span><span class=\"p\">:</span> <span class=\"nb\">int</span> <span class=\"o\">=</span> <span class=\"mi\">18432</span>,</span><span class=\"param\">\t<span class=\"n\">num_attention_heads</span><span class=\"p\">:</span> <span class=\"nb\">int</span> <span class=\"o\">=</span> <span class=\"mi\">64</span>,</span><span class=\"param\">\t<span class=\"n\">num_attention_groups</span><span class=\"p\">:</span> <span class=\"nb\">int</span> <span class=\"o\">=</span> <span class=\"mi\">1</span>,</span><span class=\"param\">\t<span class=\"n\">num_hidden_layers</span><span class=\"p\">:</span> <span class=\"nb\">int</span> <span class=\"o\">=</span> <span class=\"mi\">61</span>,</span><span class=\"param\">\t<span class=\"n\">max_seq_len</span><span class=\"p\">:</span> <span class=\"nb\">int</span> <span class=\"o\">=</span> <span class=\"mi\">65536</span>,</span><span class=\"param\">\t<span class=\"n\">vocab_size</span><span class=\"p\">:</span> <span class=\"nb\">int</span> <span class=\"o\">=</span> <span class=\"mi\">128815</span>,</span><span class=\"param\">\t<span class=\"n\">rms_norm_eps</span><span class=\"p\">:</span> <span class=\"nb\">float</span> <span class=\"o\">=</span> <span class=\"mf\">1e-05</span>,</span><span class=\"param\">\t<span class=\"n\">moe_intermediate_size</span><span class=\"p\">:</span> <span class=\"nb\">int</span> <span class=\"o\">=</span> <span class=\"mi\">5120</span>,</span><span class=\"param\">\t<span class=\"n\">moe_num_experts</span><span class=\"p\">:</span> <span class=\"nb\">int</span> <span class=\"o\">=</span> <span class=\"mi\">48</span>,</span><span class=\"param\">\t<span class=\"n\">moe_top_k</span><span class=\"p\">:</span> <span class=\"nb\">int</span> <span class=\"o\">=</span> <span class=\"mi\">3</span>,</span><span class=\"param\">\t<span class=\"n\">rope_theta</span><span class=\"p\">:</span> <span class=\"nb\">float</span> <span class=\"o\">=</span> <span class=\"mi\">500000</span>,</span><span class=\"param\">\t<span class=\"n\">rope_scaling</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"nb\">dict</span><span class=\"p\">[</span><span class=\"nb\">str</span><span class=\"p\">,</span> <span class=\"n\">Any</span><span class=\"p\">]]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">max_position_embedding</span><span class=\"p\">:</span> <span class=\"nb\">int</span> <span class=\"o\">=</span> <span class=\"mi\">65536</span>,</span><span class=\"param\">\t<span class=\"n\">share_expert_dim</span><span class=\"p\">:</span> <span class=\"nb\">int</span> <span class=\"o\">=</span> <span class=\"mi\">5120</span>,</span><span class=\"param\">\t<span class=\"n\">share_q_dim</span><span class=\"p\">:</span> <span class=\"nb\">int</span> <span class=\"o\">=</span> <span class=\"mi\">2048</span>,</span><span class=\"param\">\t<span class=\"n\">head_dim</span><span class=\"p\">:</span> <span class=\"nb\">int</span> <span class=\"o\">=</span> <span class=\"mi\">256</span>,</span><span class=\"param\">\t<span class=\"n\">norm_expert_weight</span><span class=\"p\">:</span> <span class=\"nb\">bool</span> <span class=\"o\">=</span> <span class=\"kc\">False</span>,</span><span class=\"param\">\t<span class=\"n\">moe_layers_enum</span><span class=\"p\">:</span> <span class=\"nb\">tuple</span><span class=\"p\">[</span><span class=\"nb\">int</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"p\">(</span><span class=\"mi\">4</span><span class=\"p\">,</span> <span class=\"mi\">5</span><span class=\"p\">,</span> <span class=\"mi\">6</span><span class=\"p\">,</span> <span class=\"mi\">7</span><span class=\"p\">,</span> <span class=\"mi\">8</span><span class=\"p\">,</span> <span class=\"mi\">9</span><span class=\"p\">,</span> <span class=\"mi\">10</span><span class=\"p\">,</span> <span class=\"mi\">11</span><span class=\"p\">,</span> <span class=\"mi\">12</span><span class=\"p\">,</span> <span class=\"mi\">13</span><span class=\"p\">,</span> <span class=\"mi\">14</span><span class=\"p\">,</span> <span class=\"mi\">15</span><span class=\"p\">,</span> <span class=\"mi\">16</span><span class=\"p\">,</span> <span class=\"mi\">17</span><span class=\"p\">,</span> <span class=\"mi\">18</span><span class=\"p\">,</span> <span class=\"mi\">19</span><span class=\"p\">,</span> <span class=\"mi\">20</span><span class=\"p\">,</span> <span class=\"mi\">21</span><span class=\"p\">,</span> <span class=\"mi\">22</span><span class=\"p\">,</span> <span class=\"mi\">23</span><span class=\"p\">,</span> <span class=\"mi\">24</span><span class=\"p\">,</span> <span class=\"mi\">25</span><span class=\"p\">,</span> <span class=\"mi\">26</span><span class=\"p\">,</span> <span class=\"mi\">27</span><span class=\"p\">,</span> <span class=\"mi\">28</span><span class=\"p\">,</span> <span class=\"mi\">29</span><span class=\"p\">,</span> <span class=\"mi\">30</span><span class=\"p\">,</span> <span class=\"mi\">31</span><span class=\"p\">,</span> <span class=\"mi\">32</span><span class=\"p\">,</span> <span class=\"mi\">33</span><span class=\"p\">,</span> <span class=\"mi\">34</span><span class=\"p\">,</span> <span class=\"mi\">35</span><span class=\"p\">,</span> <span class=\"mi\">36</span><span class=\"p\">,</span> <span class=\"mi\">37</span><span class=\"p\">,</span> <span class=\"mi\">38</span><span class=\"p\">,</span> <span class=\"mi\">39</span><span class=\"p\">,</span> <span class=\"mi\">40</span><span class=\"p\">,</span> <span class=\"mi\">41</span><span class=\"p\">,</span> <span class=\"mi\">42</span><span class=\"p\">,</span> <span class=\"mi\">43</span><span class=\"p\">,</span> <span class=\"mi\">44</span><span class=\"p\">,</span> <span class=\"mi\">45</span><span class=\"p\">,</span> <span class=\"mi\">46</span><span class=\"p\">,</span> <span class=\"mi\">47</span><span class=\"p\">,</span> <span class=\"mi\">48</span><span class=\"p\">,</span> <span class=\"mi\">49</span><span class=\"p\">,</span> <span class=\"mi\">50</span><span class=\"p\">,</span> <span class=\"mi\">51</span><span class=\"p\">,</span> <span class=\"mi\">52</span><span class=\"p\">,</span> <span class=\"mi\">53</span><span class=\"p\">,</span> <span class=\"mi\">54</span><span class=\"p\">,</span> <span class=\"mi\">55</span><span class=\"p\">,</span> <span class=\"mi\">56</span><span class=\"p\">,</span> <span class=\"mi\">57</span><span class=\"p\">,</span> <span class=\"mi\">58</span><span class=\"p\">,</span> <span class=\"mi\">59</span><span class=\"p\">)</span>,</span><span class=\"param\">\t<span class=\"o\">**</span><span class=\"n\">kwargs</span></span>)</span>"}, {"fullname": "sglang.srt.configs.Step3TextConfig.model_type", "modulename": "sglang.srt.configs", "qualname": "Step3TextConfig.model_type", "kind": "variable", "doc": "<p></p>\n", "default_value": "&#x27;step3_text&#x27;"}, {"fullname": "sglang.srt.configs.Step3TextConfig.architectures", "modulename": "sglang.srt.configs", "qualname": "Step3TextConfig.architectures", "kind": "variable", "doc": "<p></p>\n", "default_value": "[&#x27;Step3TextForCausalLM&#x27;]"}, {"fullname": "sglang.srt.configs.Step3TextConfig.hidden_size", "modulename": "sglang.srt.configs", "qualname": "Step3TextConfig.hidden_size", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "sglang.srt.configs.Step3TextConfig.intermediate_size", "modulename": "sglang.srt.configs", "qualname": "Step3TextConfig.intermediate_size", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "sglang.srt.configs.Step3TextConfig.num_attention_heads", "modulename": "sglang.srt.configs", "qualname": "Step3TextConfig.num_attention_heads", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "sglang.srt.configs.Step3TextConfig.num_attention_groups", "modulename": "sglang.srt.configs", "qualname": "Step3TextConfig.num_attention_groups", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "sglang.srt.configs.Step3TextConfig.num_hidden_layers", "modulename": "sglang.srt.configs", "qualname": "Step3TextConfig.num_hidden_layers", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "sglang.srt.configs.Step3TextConfig.max_seq_len", "modulename": "sglang.srt.configs", "qualname": "Step3TextConfig.max_seq_len", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "sglang.srt.configs.Step3TextConfig.vocab_size", "modulename": "sglang.srt.configs", "qualname": "Step3TextConfig.vocab_size", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "sglang.srt.configs.Step3TextConfig.rms_norm_eps", "modulename": "sglang.srt.configs", "qualname": "Step3TextConfig.rms_norm_eps", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "sglang.srt.configs.Step3TextConfig.moe_intermediate_size", "modulename": "sglang.srt.configs", "qualname": "Step3TextConfig.moe_intermediate_size", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "sglang.srt.configs.Step3TextConfig.moe_num_experts", "modulename": "sglang.srt.configs", "qualname": "Step3TextConfig.moe_num_experts", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "sglang.srt.configs.Step3TextConfig.moe_top_k", "modulename": "sglang.srt.configs", "qualname": "Step3TextConfig.moe_top_k", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "sglang.srt.configs.Step3TextConfig.rope_theta", "modulename": "sglang.srt.configs", "qualname": "Step3TextConfig.rope_theta", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "sglang.srt.configs.Step3TextConfig.rope_scaling", "modulename": "sglang.srt.configs", "qualname": "Step3TextConfig.rope_scaling", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "sglang.srt.configs.Step3TextConfig.max_position_embedding", "modulename": "sglang.srt.configs", "qualname": "Step3TextConfig.max_position_embedding", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "sglang.srt.configs.Step3TextConfig.share_expert_dim", "modulename": "sglang.srt.configs", "qualname": "Step3TextConfig.share_expert_dim", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "sglang.srt.configs.Step3TextConfig.share_q_dim", "modulename": "sglang.srt.configs", "qualname": "Step3TextConfig.share_q_dim", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "sglang.srt.configs.Step3TextConfig.head_dim", "modulename": "sglang.srt.configs", "qualname": "Step3TextConfig.head_dim", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "sglang.srt.configs.Step3TextConfig.norm_expert_weight", "modulename": "sglang.srt.configs", "qualname": "Step3TextConfig.norm_expert_weight", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "sglang.srt.configs.Step3TextConfig.moe_layers_enum", "modulename": "sglang.srt.configs", "qualname": "Step3TextConfig.moe_layers_enum", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "sglang.srt.configs.Step3VisionEncoderConfig", "modulename": "sglang.srt.configs", "qualname": "Step3VisionEncoderConfig", "kind": "class", "doc": "<p>Base class for all configuration classes. Handles a few parameters common to all models' configurations as well as\nmethods for loading/downloading/saving configurations.</p>\n\n<p><Tip></p>\n\n<p>A configuration file can be loaded and saved to disk. Loading the configuration file and using this file to\ninitialize a model does <strong>not</strong> load the model weights. It only affects the model's configuration.</p>\n\n<p></Tip></p>\n\n<p>Class attributes (overridden by derived classes):</p>\n\n<ul>\n<li><strong>model_type</strong> (<code>str</code>) -- An identifier for the model type, serialized into the JSON file, and used to recreate\nthe correct object in [<code>~transformers.AutoConfig</code>].</li>\n<li><strong>has_no_defaults_at_init</strong> (<code>bool</code>) -- Whether the config class can be initialized without providing input arguments.\nSome configurations requires inputs to be defined at init and have no default values, usually these are composite configs,\n(but not necessarily) such as [<code>~transformers.EncoderDecoderConfig</code>] or [<code>~RagConfig</code>]. They have to be initialized from\ntwo or more configs of type [<code>~transformers.PretrainedConfig</code>].</li>\n<li><strong>keys_to_ignore_at_inference</strong> (<code>list[str]</code>) -- A list of keys to ignore by default when looking at dictionary\noutputs of the model during inference.</li>\n<li><strong>attribute_map</strong> (<code>dict[str, str]</code>) -- A dict that maps model specific attribute names to the standardized\nnaming of attributes.</li>\n<li><strong>base_model_tp_plan</strong> (<code>dict[str, Any]</code>) -- A dict that maps sub-modules FQNs of a base model to a tensor\nparallel plan applied to the sub-module when <code>model.tensor_parallel</code> is called.</li>\n<li><strong>base_model_pp_plan</strong> (<code>dict[str, tuple[list[str]]]</code>) -- A dict that maps child-modules of a base model to a\npipeline parallel plan that enables users to place the child-module on the appropriate device.</li>\n</ul>\n\n<p>Common attributes (present in all subclasses):</p>\n\n<ul>\n<li><strong>vocab_size</strong> (<code>int</code>) -- The number of tokens in the vocabulary, which is also the first dimension of the\nembeddings matrix (this attribute may be missing for models that don't have a text modality like ViT).</li>\n<li><strong>hidden_size</strong> (<code>int</code>) -- The hidden size of the model.</li>\n<li><strong>num_attention_heads</strong> (<code>int</code>) -- The number of attention heads used in the multi-head attention layers of the\nmodel.</li>\n<li><strong>num_hidden_layers</strong> (<code>int</code>) -- The number of blocks in the model.</li>\n</ul>\n\n<p><Tip warning={true}&gt;</p>\n\n<p>Setting parameters for sequence generation in the model config is deprecated. For backward compatibility, loading\nsome of them will still be possible, but attempting to overwrite them will throw an exception -- you should set\nthem in a [~transformers.GenerationConfig]. Check the documentation of [~transformers.GenerationConfig] for more\ninformation about the individual parameters.</p>\n\n<p></Tip></p>\n\n<p>Arg:\n    name_or_path (<code>str</code>, <em>optional</em>, defaults to <code>\"\"</code>):\n        Store the string that was passed to [<code>PreTrainedModel.from_pretrained</code>] or\n        [<code>TFPreTrainedModel.from_pretrained</code>] as <code>pretrained_model_name_or_path</code> if the configuration was created\n        with such a method.\n    output_hidden_states (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>):\n        Whether or not the model should return all hidden-states.\n    output_attentions (<code>bool</code>, *optional*, defaults to <code>False</code>):\n        Whether or not the model should returns all attentions.\n    return_dict (<code>bool</code>, <em>optional</em>, defaults to <code>True</code>):\n        Whether or not the model should return a [<code>~transformers.utils.ModelOutput</code>] instead of a plain tuple.\n    is_encoder_decoder (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>):\n        Whether the model is used as an encoder/decoder or not.\n    is_decoder (<code>bool</code>, *optional*, defaults to <code>False</code>):\n        Whether to only use the decoder in an encoder-decoder architecture, otherwise it has no effect on\n        decoder-only or encoder-only architectures.\n    cross_attention_hidden_size (<code>bool</code>, <em>optional</em>):\n        The hidden size of the cross-attention layer in case the model is used as a decoder in an encoder-decoder\n        setting and the cross-attention hidden dimension differs from <code>self.config.hidden_size</code>.\n    add_cross_attention (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>):\n        Whether cross-attention layers should be added to the model. Note, this option is only relevant for models\n        that can be used as decoder models within the [<code>EncoderDecoderModel</code>] class, which consists of all models\n        in <code>AUTO_MODELS_FOR_CAUSAL_LM</code>.\n    tie_encoder_decoder (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>):\n        Whether all encoder weights should be tied to their equivalent decoder weights. This requires the encoder\n        and decoder model to have the exact same parameter names.\n    prune_heads (<code>dict[int, list[int]]</code>, <em>optional</em>, defaults to <code>{}</code>):\n        Pruned heads of the model. The keys are the selected layer indices and the associated values, the list of\n        heads to prune in said layer.</p>\n\n<pre><code>    For instance `{1: [0, 2], 2: [2, 3]}` will prune heads 0 and 2 on layer 1 and heads 2 and 3 on layer 2.\nchunk_size_feed_forward (`int`, *optional*, defaults to `0`):\n    The chunk size of all feed forward layers in the residual attention blocks. A chunk size of `0` means that\n    the feed forward layer is not chunked. A chunk size of n means that the feed forward layer processes `n` &lt;\n    sequence_length embeddings at a time. For more information on feed forward chunking, see [How does Feed\n    Forward Chunking work?](../glossary.html#feed-forward-chunking).\n\n&gt; Parameters for fine-tuning tasks\n\narchitectures (`list[str]`, *optional*):\n    Model architectures that can be used with the model pretrained weights.\nfinetuning_task (`str`, *optional*):\n    Name of the task used to fine-tune the model. This can be used when converting from an original (TensorFlow\n    or PyTorch) checkpoint.\nid2label (`dict[int, str]`, *optional*):\n    A map from index (for instance prediction index, or target index) to label.\nlabel2id (`dict[str, int]`, *optional*):\n    A map from label to index for the model.\nnum_labels (`int`, *optional*):\n    Number of labels to use in the last layer added to the model, typically for a classification task.\ntask_specific_params (`dict[str, Any]`, *optional*):\n    Additional keyword arguments to store for the current task.\nproblem_type (`str`, *optional*):\n    Problem type for `XxxForSequenceClassification` models. Can be one of `\"regression\"`,\n    `\"single_label_classification\"` or `\"multi_label_classification\"`.\n\n&gt; Parameters linked to the tokenizer\n\ntokenizer_class (`str`, *optional*):\n    The name of the associated tokenizer class to use (if none is set, will use the tokenizer associated to the\n    model by default).\nprefix (`str`, *optional*):\n    A specific prompt that should be added at the beginning of each text before calling the model.\nbos_token_id (`int`, *optional*):\n    The id of the _beginning-of-stream_ token.\npad_token_id (`int`, *optional*):\n    The id of the _padding_ token.\neos_token_id (`int`, *optional*):\n    The id of the _end-of-stream_ token.\ndecoder_start_token_id (`int`, *optional*):\n    If an encoder-decoder model starts decoding with a different token than _bos_, the id of that token.\nsep_token_id (`int`, *optional*):\n    The id of the _separation_ token.\n\n&gt; PyTorch specific parameters\n\ntorchscript (`bool`, *optional*, defaults to `False`):\n    Whether or not the model should be used with Torchscript.\ntie_word_embeddings (`bool`, *optional*, defaults to `True`):\n    Whether the model's input and output word embeddings should be tied. Note that this is only relevant if the\n    model has a output word embedding layer.\ntorch_dtype (`str`, *optional*):\n    The `dtype` of the weights. This attribute can be used to initialize the model to a non-default `dtype`\n    (which is normally `float32`) and thus allow for optimal storage allocation. For example, if the saved\n    model is `float16`, ideally we want to load it back using the minimal amount of memory needed to load\n    `float16` weights. Since the config object is stored in plain text, this attribute contains just the\n    floating type string without the `torch.` prefix. For example, for `torch.float16` ``torch_dtype` is the\n    `\"float16\"` string.\n\n    This attribute is currently not being used during model loading time, but this may change in the future\n    versions. But we can already start preparing for the future by saving the dtype with save_pretrained.\n</code></pre>\n", "bases": "transformers.configuration_utils.PretrainedConfig"}, {"fullname": "sglang.srt.configs.Step3VisionEncoderConfig.__init__", "modulename": "sglang.srt.configs", "qualname": "Step3VisionEncoderConfig.__init__", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">hidden_size</span><span class=\"o\">=</span><span class=\"mi\">1792</span>,</span><span class=\"param\">\t<span class=\"n\">intermediate_size</span><span class=\"o\">=</span><span class=\"mi\">3072</span>,</span><span class=\"param\">\t<span class=\"n\">output_hidden_size</span><span class=\"o\">=</span><span class=\"mi\">4096</span>,</span><span class=\"param\">\t<span class=\"n\">num_hidden_layers</span><span class=\"o\">=</span><span class=\"mi\">63</span>,</span><span class=\"param\">\t<span class=\"n\">num_attention_heads</span><span class=\"o\">=</span><span class=\"mi\">16</span>,</span><span class=\"param\">\t<span class=\"n\">num_channels</span><span class=\"o\">=</span><span class=\"mi\">3</span>,</span><span class=\"param\">\t<span class=\"n\">image_size</span><span class=\"o\">=</span><span class=\"mi\">728</span>,</span><span class=\"param\">\t<span class=\"n\">patch_size</span><span class=\"o\">=</span><span class=\"mi\">14</span>,</span><span class=\"param\">\t<span class=\"n\">hidden_act</span><span class=\"o\">=</span><span class=\"s1\">&#39;quick_gelu&#39;</span>,</span><span class=\"param\">\t<span class=\"n\">layer_norm_eps</span><span class=\"o\">=</span><span class=\"mf\">1e-05</span>,</span><span class=\"param\">\t<span class=\"o\">**</span><span class=\"n\">kwargs</span></span>)</span>"}, {"fullname": "sglang.srt.configs.Step3VisionEncoderConfig.model_type", "modulename": "sglang.srt.configs", "qualname": "Step3VisionEncoderConfig.model_type", "kind": "variable", "doc": "<p></p>\n", "default_value": "&#x27;step3_vision_encoder&#x27;"}, {"fullname": "sglang.srt.configs.Step3VisionEncoderConfig.hidden_size", "modulename": "sglang.srt.configs", "qualname": "Step3VisionEncoderConfig.hidden_size", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "sglang.srt.configs.Step3VisionEncoderConfig.intermediate_size", "modulename": "sglang.srt.configs", "qualname": "Step3VisionEncoderConfig.intermediate_size", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "sglang.srt.configs.Step3VisionEncoderConfig.output_hidden_size", "modulename": "sglang.srt.configs", "qualname": "Step3VisionEncoderConfig.output_hidden_size", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "sglang.srt.configs.Step3VisionEncoderConfig.num_hidden_layers", "modulename": "sglang.srt.configs", "qualname": "Step3VisionEncoderConfig.num_hidden_layers", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "sglang.srt.configs.Step3VisionEncoderConfig.num_attention_heads", "modulename": "sglang.srt.configs", "qualname": "Step3VisionEncoderConfig.num_attention_heads", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "sglang.srt.configs.Step3VisionEncoderConfig.num_channels", "modulename": "sglang.srt.configs", "qualname": "Step3VisionEncoderConfig.num_channels", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "sglang.srt.configs.Step3VisionEncoderConfig.patch_size", "modulename": "sglang.srt.configs", "qualname": "Step3VisionEncoderConfig.patch_size", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "sglang.srt.configs.Step3VisionEncoderConfig.image_size", "modulename": "sglang.srt.configs", "qualname": "Step3VisionEncoderConfig.image_size", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "sglang.srt.configs.Step3VisionEncoderConfig.layer_norm_eps", "modulename": "sglang.srt.configs", "qualname": "Step3VisionEncoderConfig.layer_norm_eps", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "sglang.srt.configs.Step3VisionEncoderConfig.hidden_act", "modulename": "sglang.srt.configs", "qualname": "Step3VisionEncoderConfig.hidden_act", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "sglang.srt.connector", "modulename": "sglang.srt.connector", "kind": "module", "doc": "<p></p>\n"}, {"fullname": "sglang.srt.connector.BaseConnector", "modulename": "sglang.srt.connector", "qualname": "BaseConnector", "kind": "class", "doc": "<p>For fs connector such as s3:\n<connector_type>://<path>/<filename></p>\n\n<p>For kv connector such as redis:\n<connector_type>://<host>:<port>/<model_name>/keys/<key>\n<connector_type://<host>:<port>/<model_name>/files/<filename></p>\n", "bases": "abc.ABC"}, {"fullname": "sglang.srt.connector.BaseConnector.url", "modulename": "sglang.srt.connector", "qualname": "BaseConnector.url", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "sglang.srt.connector.BaseConnector.device", "modulename": "sglang.srt.connector", "qualname": "BaseConnector.device", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "sglang.srt.connector.BaseConnector.closed", "modulename": "sglang.srt.connector", "qualname": "BaseConnector.closed", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "sglang.srt.connector.BaseConnector.local_dir", "modulename": "sglang.srt.connector", "qualname": "BaseConnector.local_dir", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "sglang.srt.connector.BaseConnector.get_local_dir", "modulename": "sglang.srt.connector", "qualname": "BaseConnector.get_local_dir", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.connector.BaseConnector.weight_iterator", "modulename": "sglang.srt.connector", "qualname": "BaseConnector.weight_iterator", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"bp\">self</span>,</span><span class=\"param\">\t<span class=\"n\">rank</span><span class=\"p\">:</span> <span class=\"nb\">int</span> <span class=\"o\">=</span> <span class=\"mi\">0</span></span><span class=\"return-annotation\">) -> <span class=\"n\">Generator</span><span class=\"p\">[</span><span class=\"n\">Tuple</span><span class=\"p\">[</span><span class=\"nb\">str</span><span class=\"p\">,</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">Tensor</span><span class=\"p\">],</span> <span class=\"n\">NoneType</span><span class=\"p\">,</span> <span class=\"n\">NoneType</span><span class=\"p\">]</span>:</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.connector.BaseConnector.pull_files", "modulename": "sglang.srt.connector", "qualname": "BaseConnector.pull_files", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"bp\">self</span>,</span><span class=\"param\">\t<span class=\"n\">allow_pattern</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"n\">List</span><span class=\"p\">[</span><span class=\"nb\">str</span><span class=\"p\">]]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">ignore_pattern</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"n\">List</span><span class=\"p\">[</span><span class=\"nb\">str</span><span class=\"p\">]]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span></span><span class=\"return-annotation\">) -> <span class=\"kc\">None</span>:</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.connector.BaseConnector.close", "modulename": "sglang.srt.connector", "qualname": "BaseConnector.close", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.connector.BaseFileConnector", "modulename": "sglang.srt.connector", "qualname": "BaseFileConnector", "kind": "class", "doc": "<p>List full file names from remote fs path and filter by allow pattern.</p>\n\n<p>Args:\n    allow_pattern: A list of patterns of which files to pull.</p>\n\n<p>Returns:\n    list[str]: List of full paths allowed by the pattern</p>\n", "bases": "sglang.srt.connector.base_connector.BaseConnector"}, {"fullname": "sglang.srt.connector.BaseFileConnector.glob", "modulename": "sglang.srt.connector", "qualname": "BaseFileConnector.glob", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">allow_pattern</span><span class=\"p\">:</span> <span class=\"nb\">str</span></span><span class=\"return-annotation\">) -> <span class=\"n\">List</span><span class=\"p\">[</span><span class=\"nb\">str</span><span class=\"p\">]</span>:</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.connector.BaseKVConnector", "modulename": "sglang.srt.connector", "qualname": "BaseKVConnector", "kind": "class", "doc": "<p>For fs connector such as s3:\n<connector_type>://<path>/<filename></p>\n\n<p>For kv connector such as redis:\n<connector_type>://<host>:<port>/<model_name>/keys/<key>\n<connector_type://<host>:<port>/<model_name>/files/<filename></p>\n", "bases": "sglang.srt.connector.base_connector.BaseConnector"}, {"fullname": "sglang.srt.connector.BaseKVConnector.get", "modulename": "sglang.srt.connector", "qualname": "BaseKVConnector.get", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">key</span><span class=\"p\">:</span> <span class=\"nb\">str</span></span><span class=\"return-annotation\">) -> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">Tensor</span><span class=\"p\">]</span>:</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.connector.BaseKVConnector.getstr", "modulename": "sglang.srt.connector", "qualname": "BaseKVConnector.getstr", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">key</span><span class=\"p\">:</span> <span class=\"nb\">str</span></span><span class=\"return-annotation\">) -> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"nb\">str</span><span class=\"p\">]</span>:</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.connector.BaseKVConnector.set", "modulename": "sglang.srt.connector", "qualname": "BaseKVConnector.set", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">key</span><span class=\"p\">:</span> <span class=\"nb\">str</span>, </span><span class=\"param\"><span class=\"n\">obj</span><span class=\"p\">:</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">Tensor</span></span><span class=\"return-annotation\">) -> <span class=\"kc\">None</span>:</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.connector.BaseKVConnector.setstr", "modulename": "sglang.srt.connector", "qualname": "BaseKVConnector.setstr", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">key</span><span class=\"p\">:</span> <span class=\"nb\">str</span>, </span><span class=\"param\"><span class=\"n\">obj</span><span class=\"p\">:</span> <span class=\"nb\">str</span></span><span class=\"return-annotation\">) -> <span class=\"kc\">None</span>:</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.connector.BaseKVConnector.list", "modulename": "sglang.srt.connector", "qualname": "BaseKVConnector.list", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">prefix</span><span class=\"p\">:</span> <span class=\"nb\">str</span></span><span class=\"return-annotation\">) -> <span class=\"n\">List</span><span class=\"p\">[</span><span class=\"nb\">str</span><span class=\"p\">]</span>:</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.connector.RedisConnector", "modulename": "sglang.srt.connector", "qualname": "RedisConnector", "kind": "class", "doc": "<p>For fs connector such as s3:\n<connector_type>://<path>/<filename></p>\n\n<p>For kv connector such as redis:\n<connector_type>://<host>:<port>/<model_name>/keys/<key>\n<connector_type://<host>:<port>/<model_name>/files/<filename></p>\n", "bases": "sglang.srt.connector.base_connector.BaseKVConnector"}, {"fullname": "sglang.srt.connector.RedisConnector.__init__", "modulename": "sglang.srt.connector", "qualname": "RedisConnector.__init__", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">url</span><span class=\"p\">:</span> <span class=\"nb\">str</span>, </span><span class=\"param\"><span class=\"n\">device</span><span class=\"p\">:</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">device</span> <span class=\"o\">=</span> <span class=\"s1\">&#39;cpu&#39;</span></span>)</span>"}, {"fullname": "sglang.srt.connector.RedisConnector.connection", "modulename": "sglang.srt.connector", "qualname": "RedisConnector.connection", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "sglang.srt.connector.RedisConnector.model_name", "modulename": "sglang.srt.connector", "qualname": "RedisConnector.model_name", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "sglang.srt.connector.RedisConnector.get", "modulename": "sglang.srt.connector", "qualname": "RedisConnector.get", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">key</span><span class=\"p\">:</span> <span class=\"nb\">str</span></span><span class=\"return-annotation\">) -> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">Tensor</span><span class=\"p\">]</span>:</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.connector.RedisConnector.getstr", "modulename": "sglang.srt.connector", "qualname": "RedisConnector.getstr", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">key</span><span class=\"p\">:</span> <span class=\"nb\">str</span></span><span class=\"return-annotation\">) -> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"nb\">str</span><span class=\"p\">]</span>:</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.connector.RedisConnector.set", "modulename": "sglang.srt.connector", "qualname": "RedisConnector.set", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">key</span><span class=\"p\">:</span> <span class=\"nb\">str</span>, </span><span class=\"param\"><span class=\"n\">tensor</span><span class=\"p\">:</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">Tensor</span></span><span class=\"return-annotation\">) -> <span class=\"kc\">None</span>:</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.connector.RedisConnector.setstr", "modulename": "sglang.srt.connector", "qualname": "RedisConnector.setstr", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">key</span><span class=\"p\">:</span> <span class=\"nb\">str</span>, </span><span class=\"param\"><span class=\"n\">obj</span><span class=\"p\">:</span> <span class=\"nb\">str</span></span><span class=\"return-annotation\">) -> <span class=\"kc\">None</span>:</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.connector.RedisConnector.list", "modulename": "sglang.srt.connector", "qualname": "RedisConnector.list", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">prefix</span><span class=\"p\">:</span> <span class=\"nb\">str</span></span><span class=\"return-annotation\">) -> <span class=\"n\">List</span><span class=\"p\">[</span><span class=\"nb\">str</span><span class=\"p\">]</span>:</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.connector.RedisConnector.weight_iterator", "modulename": "sglang.srt.connector", "qualname": "RedisConnector.weight_iterator", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">rank</span><span class=\"p\">:</span> <span class=\"nb\">int</span> <span class=\"o\">=</span> <span class=\"mi\">0</span></span><span class=\"return-annotation\">) -> <span class=\"n\">Generator</span><span class=\"p\">[</span><span class=\"n\">Tuple</span><span class=\"p\">[</span><span class=\"nb\">str</span><span class=\"p\">,</span> <span class=\"nb\">bytes</span><span class=\"p\">],</span> <span class=\"n\">NoneType</span><span class=\"p\">,</span> <span class=\"n\">NoneType</span><span class=\"p\">]</span>:</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.connector.RedisConnector.pull_files", "modulename": "sglang.srt.connector", "qualname": "RedisConnector.pull_files", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"bp\">self</span>,</span><span class=\"param\">\t<span class=\"n\">allow_pattern</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"n\">List</span><span class=\"p\">[</span><span class=\"nb\">str</span><span class=\"p\">]]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">ignore_pattern</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"n\">List</span><span class=\"p\">[</span><span class=\"nb\">str</span><span class=\"p\">]]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span></span><span class=\"return-annotation\">) -> <span class=\"kc\">None</span>:</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.connector.RedisConnector.close", "modulename": "sglang.srt.connector", "qualname": "RedisConnector.close", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.connector.S3Connector", "modulename": "sglang.srt.connector", "qualname": "S3Connector", "kind": "class", "doc": "<p>List full file names from remote fs path and filter by allow pattern.</p>\n\n<p>Args:\n    allow_pattern: A list of patterns of which files to pull.</p>\n\n<p>Returns:\n    list[str]: List of full paths allowed by the pattern</p>\n", "bases": "sglang.srt.connector.base_connector.BaseFileConnector"}, {"fullname": "sglang.srt.connector.S3Connector.__init__", "modulename": "sglang.srt.connector", "qualname": "S3Connector.__init__", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">url</span><span class=\"p\">:</span> <span class=\"nb\">str</span></span>)</span>"}, {"fullname": "sglang.srt.connector.S3Connector.client", "modulename": "sglang.srt.connector", "qualname": "S3Connector.client", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "sglang.srt.connector.S3Connector.glob", "modulename": "sglang.srt.connector", "qualname": "S3Connector.glob", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">allow_pattern</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"nb\">list</span><span class=\"p\">[</span><span class=\"nb\">str</span><span class=\"p\">]]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span></span><span class=\"return-annotation\">) -> <span class=\"nb\">list</span><span class=\"p\">[</span><span class=\"nb\">str</span><span class=\"p\">]</span>:</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.connector.S3Connector.pull_files", "modulename": "sglang.srt.connector", "qualname": "S3Connector.pull_files", "kind": "function", "doc": "<p>Pull files from S3 storage into the temporary directory.</p>\n\n<p>Args:\n    s3_model_path: The S3 path of the model.\n    allow_pattern: A list of patterns of which files to pull.\n    ignore_pattern: A list of patterns of which files not to pull.</p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"bp\">self</span>,</span><span class=\"param\">\t<span class=\"n\">allow_pattern</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"nb\">list</span><span class=\"p\">[</span><span class=\"nb\">str</span><span class=\"p\">]]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">ignore_pattern</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"nb\">list</span><span class=\"p\">[</span><span class=\"nb\">str</span><span class=\"p\">]]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span></span><span class=\"return-annotation\">) -> <span class=\"kc\">None</span>:</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.connector.S3Connector.weight_iterator", "modulename": "sglang.srt.connector", "qualname": "S3Connector.weight_iterator", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"bp\">self</span>,</span><span class=\"param\">\t<span class=\"n\">rank</span><span class=\"p\">:</span> <span class=\"nb\">int</span> <span class=\"o\">=</span> <span class=\"mi\">0</span></span><span class=\"return-annotation\">) -> <span class=\"n\">Generator</span><span class=\"p\">[</span><span class=\"n\">Tuple</span><span class=\"p\">[</span><span class=\"nb\">str</span><span class=\"p\">,</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">Tensor</span><span class=\"p\">],</span> <span class=\"n\">NoneType</span><span class=\"p\">,</span> <span class=\"n\">NoneType</span><span class=\"p\">]</span>:</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.connector.S3Connector.close", "modulename": "sglang.srt.connector", "qualname": "S3Connector.close", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.connector.ConnectorType", "modulename": "sglang.srt.connector", "qualname": "ConnectorType", "kind": "class", "doc": "<p>str(object='') -> str\nstr(bytes_or_buffer[, encoding[, errors]]) -> str</p>\n\n<p>Create a new string object from the given object. If encoding or\nerrors is specified, then the object must expose a data buffer\nthat will be decoded using the given encoding and error handler.\nOtherwise, returns the result of object.__str__() (if defined)\nor repr(object).\nencoding defaults to sys.getdefaultencoding().\nerrors defaults to 'strict'.</p>\n", "bases": "builtins.str, enum.Enum"}, {"fullname": "sglang.srt.connector.ConnectorType.FS", "modulename": "sglang.srt.connector", "qualname": "ConnectorType.FS", "kind": "variable", "doc": "<p></p>\n", "default_value": "&lt;ConnectorType.FS: &#x27;filesystem&#x27;&gt;"}, {"fullname": "sglang.srt.connector.ConnectorType.KV", "modulename": "sglang.srt.connector", "qualname": "ConnectorType.KV", "kind": "variable", "doc": "<p></p>\n", "default_value": "&lt;ConnectorType.KV: &#x27;KV&#x27;&gt;"}, {"fullname": "sglang.srt.connector.create_remote_connector", "modulename": "sglang.srt.connector", "qualname": "create_remote_connector", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">url</span>, </span><span class=\"param\"><span class=\"n\">device</span><span class=\"o\">=</span><span class=\"s1\">&#39;cpu&#39;</span></span><span class=\"return-annotation\">) -> <span class=\"n\">sglang</span><span class=\"o\">.</span><span class=\"n\">srt</span><span class=\"o\">.</span><span class=\"n\">connector</span><span class=\"o\">.</span><span class=\"n\">base_connector</span><span class=\"o\">.</span><span class=\"n\">BaseConnector</span>:</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.connector.get_connector_type", "modulename": "sglang.srt.connector", "qualname": "get_connector_type", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">client</span><span class=\"p\">:</span> <span class=\"n\">sglang</span><span class=\"o\">.</span><span class=\"n\">srt</span><span class=\"o\">.</span><span class=\"n\">connector</span><span class=\"o\">.</span><span class=\"n\">base_connector</span><span class=\"o\">.</span><span class=\"n\">BaseConnector</span></span><span class=\"return-annotation\">) -> <span class=\"n\">sglang</span><span class=\"o\">.</span><span class=\"n\">srt</span><span class=\"o\">.</span><span class=\"n\">connector</span><span class=\"o\">.</span><span class=\"n\">ConnectorType</span>:</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.constants", "modulename": "sglang.srt.constants", "kind": "module", "doc": "<p></p>\n"}, {"fullname": "sglang.srt.constants.GPU_MEMORY_TYPE_KV_CACHE", "modulename": "sglang.srt.constants", "qualname": "GPU_MEMORY_TYPE_KV_CACHE", "kind": "variable", "doc": "<p></p>\n", "default_value": "&#x27;kv_cache&#x27;"}, {"fullname": "sglang.srt.constants.GPU_MEMORY_TYPE_WEIGHTS", "modulename": "sglang.srt.constants", "qualname": "GPU_MEMORY_TYPE_WEIGHTS", "kind": "variable", "doc": "<p></p>\n", "default_value": "&#x27;weights&#x27;"}, {"fullname": "sglang.srt.conversation", "modulename": "sglang.srt.conversation", "kind": "module", "doc": "<p>Conversation chat templates.</p>\n\n<p>This module provides conversation template definitions, data structures, and utilities\nfor managing chat templates across different model types in SGLang.</p>\n\n<p>Key components:</p>\n\n<ul>\n<li>Conversation class: Defines the structure and behavior of chat templates</li>\n<li>SeparatorStyle enum: Different conversation formatting styles</li>\n<li>Template registry: Functions to register and retrieve templates by name or model path</li>\n<li>Built-in templates: Pre-defined templates for popular models</li>\n</ul>\n"}, {"fullname": "sglang.srt.conversation.SeparatorStyle", "modulename": "sglang.srt.conversation", "qualname": "SeparatorStyle", "kind": "class", "doc": "<p>Separator styles.</p>\n", "bases": "enum.IntEnum"}, {"fullname": "sglang.srt.conversation.SeparatorStyle.ADD_COLON_SINGLE", "modulename": "sglang.srt.conversation", "qualname": "SeparatorStyle.ADD_COLON_SINGLE", "kind": "variable", "doc": "<p></p>\n", "default_value": "&lt;SeparatorStyle.ADD_COLON_SINGLE: 1&gt;"}, {"fullname": "sglang.srt.conversation.SeparatorStyle.ADD_COLON_TWO", "modulename": "sglang.srt.conversation", "qualname": "SeparatorStyle.ADD_COLON_TWO", "kind": "variable", "doc": "<p></p>\n", "default_value": "&lt;SeparatorStyle.ADD_COLON_TWO: 2&gt;"}, {"fullname": "sglang.srt.conversation.SeparatorStyle.ADD_COLON_SPACE_SINGLE", "modulename": "sglang.srt.conversation", "qualname": "SeparatorStyle.ADD_COLON_SPACE_SINGLE", "kind": "variable", "doc": "<p></p>\n", "default_value": "&lt;SeparatorStyle.ADD_COLON_SPACE_SINGLE: 3&gt;"}, {"fullname": "sglang.srt.conversation.SeparatorStyle.NO_COLON_SINGLE", "modulename": "sglang.srt.conversation", "qualname": "SeparatorStyle.NO_COLON_SINGLE", "kind": "variable", "doc": "<p></p>\n", "default_value": "&lt;SeparatorStyle.NO_COLON_SINGLE: 4&gt;"}, {"fullname": "sglang.srt.conversation.SeparatorStyle.NO_COLON_TWO", "modulename": "sglang.srt.conversation", "qualname": "SeparatorStyle.NO_COLON_TWO", "kind": "variable", "doc": "<p></p>\n", "default_value": "&lt;SeparatorStyle.NO_COLON_TWO: 5&gt;"}, {"fullname": "sglang.srt.conversation.SeparatorStyle.ADD_NEW_LINE_SINGLE", "modulename": "sglang.srt.conversation", "qualname": "SeparatorStyle.ADD_NEW_LINE_SINGLE", "kind": "variable", "doc": "<p></p>\n", "default_value": "&lt;SeparatorStyle.ADD_NEW_LINE_SINGLE: 6&gt;"}, {"fullname": "sglang.srt.conversation.SeparatorStyle.LLAMA2", "modulename": "sglang.srt.conversation", "qualname": "SeparatorStyle.LLAMA2", "kind": "variable", "doc": "<p></p>\n", "default_value": "&lt;SeparatorStyle.LLAMA2: 7&gt;"}, {"fullname": "sglang.srt.conversation.SeparatorStyle.LLAMA3", "modulename": "sglang.srt.conversation", "qualname": "SeparatorStyle.LLAMA3", "kind": "variable", "doc": "<p></p>\n", "default_value": "&lt;SeparatorStyle.LLAMA3: 8&gt;"}, {"fullname": "sglang.srt.conversation.SeparatorStyle.LLAMA4", "modulename": "sglang.srt.conversation", "qualname": "SeparatorStyle.LLAMA4", "kind": "variable", "doc": "<p></p>\n", "default_value": "&lt;SeparatorStyle.LLAMA4: 9&gt;"}, {"fullname": "sglang.srt.conversation.SeparatorStyle.CHATGLM", "modulename": "sglang.srt.conversation", "qualname": "SeparatorStyle.CHATGLM", "kind": "variable", "doc": "<p></p>\n", "default_value": "&lt;SeparatorStyle.CHATGLM: 10&gt;"}, {"fullname": "sglang.srt.conversation.SeparatorStyle.CHATML", "modulename": "sglang.srt.conversation", "qualname": "SeparatorStyle.CHATML", "kind": "variable", "doc": "<p></p>\n", "default_value": "&lt;SeparatorStyle.CHATML: 11&gt;"}, {"fullname": "sglang.srt.conversation.SeparatorStyle.CHATINTERN", "modulename": "sglang.srt.conversation", "qualname": "SeparatorStyle.CHATINTERN", "kind": "variable", "doc": "<p></p>\n", "default_value": "&lt;SeparatorStyle.CHATINTERN: 12&gt;"}, {"fullname": "sglang.srt.conversation.SeparatorStyle.DOLLY", "modulename": "sglang.srt.conversation", "qualname": "SeparatorStyle.DOLLY", "kind": "variable", "doc": "<p></p>\n", "default_value": "&lt;SeparatorStyle.DOLLY: 13&gt;"}, {"fullname": "sglang.srt.conversation.SeparatorStyle.RWKV", "modulename": "sglang.srt.conversation", "qualname": "SeparatorStyle.RWKV", "kind": "variable", "doc": "<p></p>\n", "default_value": "&lt;SeparatorStyle.RWKV: 14&gt;"}, {"fullname": "sglang.srt.conversation.SeparatorStyle.PHOENIX", "modulename": "sglang.srt.conversation", "qualname": "SeparatorStyle.PHOENIX", "kind": "variable", "doc": "<p></p>\n", "default_value": "&lt;SeparatorStyle.PHOENIX: 15&gt;"}, {"fullname": "sglang.srt.conversation.SeparatorStyle.ROBIN", "modulename": "sglang.srt.conversation", "qualname": "SeparatorStyle.ROBIN", "kind": "variable", "doc": "<p></p>\n", "default_value": "&lt;SeparatorStyle.ROBIN: 16&gt;"}, {"fullname": "sglang.srt.conversation.SeparatorStyle.FALCON_CHAT", "modulename": "sglang.srt.conversation", "qualname": "SeparatorStyle.FALCON_CHAT", "kind": "variable", "doc": "<p></p>\n", "default_value": "&lt;SeparatorStyle.FALCON_CHAT: 17&gt;"}, {"fullname": "sglang.srt.conversation.SeparatorStyle.CHATGLM3", "modulename": "sglang.srt.conversation", "qualname": "SeparatorStyle.CHATGLM3", "kind": "variable", "doc": "<p></p>\n", "default_value": "&lt;SeparatorStyle.CHATGLM3: 18&gt;"}, {"fullname": "sglang.srt.conversation.SeparatorStyle.DEEPSEEK_CHAT", "modulename": "sglang.srt.conversation", "qualname": "SeparatorStyle.DEEPSEEK_CHAT", "kind": "variable", "doc": "<p></p>\n", "default_value": "&lt;SeparatorStyle.DEEPSEEK_CHAT: 19&gt;"}, {"fullname": "sglang.srt.conversation.SeparatorStyle.METAMATH", "modulename": "sglang.srt.conversation", "qualname": "SeparatorStyle.METAMATH", "kind": "variable", "doc": "<p></p>\n", "default_value": "&lt;SeparatorStyle.METAMATH: 20&gt;"}, {"fullname": "sglang.srt.conversation.SeparatorStyle.DeepSeekVL2", "modulename": "sglang.srt.conversation", "qualname": "SeparatorStyle.DeepSeekVL2", "kind": "variable", "doc": "<p></p>\n", "default_value": "&lt;SeparatorStyle.DeepSeekVL2: 21&gt;"}, {"fullname": "sglang.srt.conversation.SeparatorStyle.QWEN2_VL_EMBED", "modulename": "sglang.srt.conversation", "qualname": "SeparatorStyle.QWEN2_VL_EMBED", "kind": "variable", "doc": "<p></p>\n", "default_value": "&lt;SeparatorStyle.QWEN2_VL_EMBED: 22&gt;"}, {"fullname": "sglang.srt.conversation.SeparatorStyle.QWEN2_AUDIO", "modulename": "sglang.srt.conversation", "qualname": "SeparatorStyle.QWEN2_AUDIO", "kind": "variable", "doc": "<p></p>\n", "default_value": "&lt;SeparatorStyle.QWEN2_AUDIO: 23&gt;"}, {"fullname": "sglang.srt.conversation.SeparatorStyle.GEMMA3", "modulename": "sglang.srt.conversation", "qualname": "SeparatorStyle.GEMMA3", "kind": "variable", "doc": "<p></p>\n", "default_value": "&lt;SeparatorStyle.GEMMA3: 24&gt;"}, {"fullname": "sglang.srt.conversation.SeparatorStyle.MPT", "modulename": "sglang.srt.conversation", "qualname": "SeparatorStyle.MPT", "kind": "variable", "doc": "<p></p>\n", "default_value": "&lt;SeparatorStyle.MPT: 25&gt;"}, {"fullname": "sglang.srt.conversation.Conversation", "modulename": "sglang.srt.conversation", "qualname": "Conversation", "kind": "class", "doc": "<p>A class that manages prompt templates and keeps all conversation history.</p>\n"}, {"fullname": "sglang.srt.conversation.Conversation.__init__", "modulename": "sglang.srt.conversation", "qualname": "Conversation.__init__", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">name</span><span class=\"p\">:</span> <span class=\"nb\">str</span>,</span><span class=\"param\">\t<span class=\"n\">system_template</span><span class=\"p\">:</span> <span class=\"nb\">str</span> <span class=\"o\">=</span> <span class=\"s1\">&#39;</span><span class=\"si\">{system_message}</span><span class=\"s1\">&#39;</span>,</span><span class=\"param\">\t<span class=\"n\">system_message</span><span class=\"p\">:</span> <span class=\"nb\">str</span> <span class=\"o\">=</span> <span class=\"s1\">&#39;&#39;</span>,</span><span class=\"param\">\t<span class=\"n\">roles</span><span class=\"p\">:</span> <span class=\"n\">Tuple</span><span class=\"p\">[</span><span class=\"nb\">str</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"p\">(</span><span class=\"s1\">&#39;USER&#39;</span><span class=\"p\">,</span> <span class=\"s1\">&#39;ASSISTANT&#39;</span><span class=\"p\">)</span>,</span><span class=\"param\">\t<span class=\"n\">messages</span><span class=\"p\">:</span> <span class=\"n\">List</span><span class=\"p\">[</span><span class=\"n\">List</span><span class=\"p\">[</span><span class=\"nb\">str</span><span class=\"p\">]]</span> <span class=\"o\">=</span> <span class=\"p\">()</span>,</span><span class=\"param\">\t<span class=\"n\">offset</span><span class=\"p\">:</span> <span class=\"nb\">int</span> <span class=\"o\">=</span> <span class=\"mi\">0</span>,</span><span class=\"param\">\t<span class=\"n\">sep_style</span><span class=\"p\">:</span> <span class=\"n\">sglang</span><span class=\"o\">.</span><span class=\"n\">srt</span><span class=\"o\">.</span><span class=\"n\">conversation</span><span class=\"o\">.</span><span class=\"n\">SeparatorStyle</span> <span class=\"o\">=</span> <span class=\"o\">&lt;</span><span class=\"n\">SeparatorStyle</span><span class=\"o\">.</span><span class=\"n\">ADD_COLON_SINGLE</span><span class=\"p\">:</span> <span class=\"mi\">1</span><span class=\"o\">&gt;</span>,</span><span class=\"param\">\t<span class=\"n\">sep</span><span class=\"p\">:</span> <span class=\"nb\">str</span> <span class=\"o\">=</span> <span class=\"s1\">&#39;</span><span class=\"se\">\\n</span><span class=\"s1\">&#39;</span>,</span><span class=\"param\">\t<span class=\"n\">sep2</span><span class=\"p\">:</span> <span class=\"nb\">str</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">stop_str</span><span class=\"p\">:</span> <span class=\"n\">Union</span><span class=\"p\">[</span><span class=\"nb\">str</span><span class=\"p\">,</span> <span class=\"n\">List</span><span class=\"p\">[</span><span class=\"nb\">str</span><span class=\"p\">]]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">image_token</span><span class=\"p\">:</span> <span class=\"nb\">str</span> <span class=\"o\">=</span> <span class=\"s1\">&#39;&lt;image&gt;&#39;</span>,</span><span class=\"param\">\t<span class=\"n\">video_token</span><span class=\"p\">:</span> <span class=\"nb\">str</span> <span class=\"o\">=</span> <span class=\"s1\">&#39;&lt;video&gt;&#39;</span>,</span><span class=\"param\">\t<span class=\"n\">audio_token</span><span class=\"p\">:</span> <span class=\"nb\">str</span> <span class=\"o\">=</span> <span class=\"s1\">&#39;&lt;audio&gt;&#39;</span>,</span><span class=\"param\">\t<span class=\"n\">image_data</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"n\">List</span><span class=\"p\">[</span><span class=\"n\">sglang</span><span class=\"o\">.</span><span class=\"n\">srt</span><span class=\"o\">.</span><span class=\"n\">utils</span><span class=\"o\">.</span><span class=\"n\">ImageData</span><span class=\"p\">]]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">video_data</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"n\">List</span><span class=\"p\">[</span><span class=\"nb\">str</span><span class=\"p\">]]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">modalities</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"n\">List</span><span class=\"p\">[</span><span class=\"nb\">str</span><span class=\"p\">]]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">stop_token_ids</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"nb\">int</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">audio_data</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"n\">List</span><span class=\"p\">[</span><span class=\"nb\">str</span><span class=\"p\">]]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span></span>)</span>"}, {"fullname": "sglang.srt.conversation.Conversation.name", "modulename": "sglang.srt.conversation", "qualname": "Conversation.name", "kind": "variable", "doc": "<p></p>\n", "annotation": ": str"}, {"fullname": "sglang.srt.conversation.Conversation.system_template", "modulename": "sglang.srt.conversation", "qualname": "Conversation.system_template", "kind": "variable", "doc": "<p></p>\n", "annotation": ": str", "default_value": "&#x27;{system_message}&#x27;"}, {"fullname": "sglang.srt.conversation.Conversation.system_message", "modulename": "sglang.srt.conversation", "qualname": "Conversation.system_message", "kind": "variable", "doc": "<p></p>\n", "annotation": ": str", "default_value": "&#x27;&#x27;"}, {"fullname": "sglang.srt.conversation.Conversation.roles", "modulename": "sglang.srt.conversation", "qualname": "Conversation.roles", "kind": "variable", "doc": "<p></p>\n", "annotation": ": Tuple[str]", "default_value": "(&#x27;USER&#x27;, &#x27;ASSISTANT&#x27;)"}, {"fullname": "sglang.srt.conversation.Conversation.messages", "modulename": "sglang.srt.conversation", "qualname": "Conversation.messages", "kind": "variable", "doc": "<p></p>\n", "annotation": ": List[List[str]]", "default_value": "()"}, {"fullname": "sglang.srt.conversation.Conversation.offset", "modulename": "sglang.srt.conversation", "qualname": "Conversation.offset", "kind": "variable", "doc": "<p></p>\n", "annotation": ": int", "default_value": "0"}, {"fullname": "sglang.srt.conversation.Conversation.sep_style", "modulename": "sglang.srt.conversation", "qualname": "Conversation.sep_style", "kind": "variable", "doc": "<p></p>\n", "annotation": ": sglang.srt.conversation.SeparatorStyle", "default_value": "&lt;SeparatorStyle.ADD_COLON_SINGLE: 1&gt;"}, {"fullname": "sglang.srt.conversation.Conversation.sep", "modulename": "sglang.srt.conversation", "qualname": "Conversation.sep", "kind": "variable", "doc": "<p></p>\n", "annotation": ": str", "default_value": "&#x27;\\n&#x27;"}, {"fullname": "sglang.srt.conversation.Conversation.sep2", "modulename": "sglang.srt.conversation", "qualname": "Conversation.sep2", "kind": "variable", "doc": "<p></p>\n", "annotation": ": str", "default_value": "None"}, {"fullname": "sglang.srt.conversation.Conversation.stop_str", "modulename": "sglang.srt.conversation", "qualname": "Conversation.stop_str", "kind": "variable", "doc": "<p></p>\n", "annotation": ": Union[str, List[str]]", "default_value": "None"}, {"fullname": "sglang.srt.conversation.Conversation.image_token", "modulename": "sglang.srt.conversation", "qualname": "Conversation.image_token", "kind": "variable", "doc": "<p></p>\n", "annotation": ": str", "default_value": "&#x27;&lt;image&gt;&#x27;"}, {"fullname": "sglang.srt.conversation.Conversation.video_token", "modulename": "sglang.srt.conversation", "qualname": "Conversation.video_token", "kind": "variable", "doc": "<p></p>\n", "annotation": ": str", "default_value": "&#x27;&lt;video&gt;&#x27;"}, {"fullname": "sglang.srt.conversation.Conversation.audio_token", "modulename": "sglang.srt.conversation", "qualname": "Conversation.audio_token", "kind": "variable", "doc": "<p></p>\n", "annotation": ": str", "default_value": "&#x27;&lt;audio&gt;&#x27;"}, {"fullname": "sglang.srt.conversation.Conversation.image_data", "modulename": "sglang.srt.conversation", "qualname": "Conversation.image_data", "kind": "variable", "doc": "<p></p>\n", "annotation": ": Optional[List[sglang.srt.utils.ImageData]]", "default_value": "None"}, {"fullname": "sglang.srt.conversation.Conversation.video_data", "modulename": "sglang.srt.conversation", "qualname": "Conversation.video_data", "kind": "variable", "doc": "<p></p>\n", "annotation": ": Optional[List[str]]", "default_value": "None"}, {"fullname": "sglang.srt.conversation.Conversation.modalities", "modulename": "sglang.srt.conversation", "qualname": "Conversation.modalities", "kind": "variable", "doc": "<p></p>\n", "annotation": ": Optional[List[str]]", "default_value": "None"}, {"fullname": "sglang.srt.conversation.Conversation.stop_token_ids", "modulename": "sglang.srt.conversation", "qualname": "Conversation.stop_token_ids", "kind": "variable", "doc": "<p></p>\n", "annotation": ": Optional[int]", "default_value": "None"}, {"fullname": "sglang.srt.conversation.Conversation.audio_data", "modulename": "sglang.srt.conversation", "qualname": "Conversation.audio_data", "kind": "variable", "doc": "<p></p>\n", "annotation": ": Optional[List[str]]", "default_value": "None"}, {"fullname": "sglang.srt.conversation.Conversation.get_prompt", "modulename": "sglang.srt.conversation", "qualname": "Conversation.get_prompt", "kind": "function", "doc": "<p>Get the prompt for generation.</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span></span><span class=\"return-annotation\">) -> <span class=\"nb\">str</span>:</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.conversation.Conversation.set_system_message", "modulename": "sglang.srt.conversation", "qualname": "Conversation.set_system_message", "kind": "function", "doc": "<p>Set the system message.</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">system_message</span><span class=\"p\">:</span> <span class=\"nb\">str</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.conversation.Conversation.append_message", "modulename": "sglang.srt.conversation", "qualname": "Conversation.append_message", "kind": "function", "doc": "<p>Append a new message.</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">role</span><span class=\"p\">:</span> <span class=\"nb\">str</span>, </span><span class=\"param\"><span class=\"n\">message</span><span class=\"p\">:</span> <span class=\"nb\">str</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.conversation.Conversation.append_image", "modulename": "sglang.srt.conversation", "qualname": "Conversation.append_image", "kind": "function", "doc": "<p>Append a new image.</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">image</span><span class=\"p\">:</span> <span class=\"nb\">str</span>, </span><span class=\"param\"><span class=\"n\">detail</span><span class=\"p\">:</span> <span class=\"n\">Literal</span><span class=\"p\">[</span><span class=\"s1\">&#39;auto&#39;</span><span class=\"p\">,</span> <span class=\"s1\">&#39;low&#39;</span><span class=\"p\">,</span> <span class=\"s1\">&#39;high&#39;</span><span class=\"p\">]</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.conversation.Conversation.append_video", "modulename": "sglang.srt.conversation", "qualname": "Conversation.append_video", "kind": "function", "doc": "<p>Append a new video.</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">video</span><span class=\"p\">:</span> <span class=\"nb\">str</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.conversation.Conversation.append_audio", "modulename": "sglang.srt.conversation", "qualname": "Conversation.append_audio", "kind": "function", "doc": "<p>Append a new audio.</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">audio</span><span class=\"p\">:</span> <span class=\"nb\">str</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.conversation.Conversation.update_last_message", "modulename": "sglang.srt.conversation", "qualname": "Conversation.update_last_message", "kind": "function", "doc": "<p>Update the last output.</p>\n\n<p>The last message is typically set to be None when constructing the prompt,\nso we need to update it in-place after getting the response from a model.</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">message</span><span class=\"p\">:</span> <span class=\"nb\">str</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.conversation.Conversation.to_gradio_chatbot", "modulename": "sglang.srt.conversation", "qualname": "Conversation.to_gradio_chatbot", "kind": "function", "doc": "<p>Convert the conversation to gradio chatbot format.</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.conversation.Conversation.to_openai_api_messages", "modulename": "sglang.srt.conversation", "qualname": "Conversation.to_openai_api_messages", "kind": "function", "doc": "<p>Convert the conversation to OpenAI chat completion format.</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.conversation.Conversation.copy", "modulename": "sglang.srt.conversation", "qualname": "Conversation.copy", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.conversation.Conversation.dict", "modulename": "sglang.srt.conversation", "qualname": "Conversation.dict", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.conversation.chat_templates", "modulename": "sglang.srt.conversation", "qualname": "chat_templates", "kind": "variable", "doc": "<p></p>\n", "annotation": ": Dict[str, sglang.srt.conversation.Conversation]", "default_value": "{&#x27;llama-2&#x27;: Conversation(name=&#x27;llama-2&#x27;, system_template=&#x27;[INST] &lt;&lt;SYS&gt;&gt;\\n{system_message}\\n&lt;&lt;/SYS&gt;&gt;\\n\\n&#x27;, system_message=&#x27;&#x27;, roles=(&#x27;[INST]&#x27;, &#x27;[/INST]&#x27;), messages=(), offset=0, sep_style=&lt;SeparatorStyle.LLAMA2: 7&gt;, sep=&#x27; &#x27;, sep2=&#x27; &lt;/s&gt;&lt;s&gt;&#x27;, stop_str=[&#x27;[INST]&#x27;, &#x27;[/INST]&#x27;, &#x27;&lt;&lt;SYS&gt;&gt;&#x27;, &#x27;&lt;&lt;/SYS&gt;&gt;&#x27;], image_token=&#x27;&lt;image&gt;&#x27;, video_token=&#x27;&lt;video&gt;&#x27;, audio_token=&#x27;&lt;audio&gt;&#x27;, image_data=None, video_data=None, modalities=None, stop_token_ids=None, audio_data=None), &#x27;mistral&#x27;: Conversation(name=&#x27;mistral&#x27;, system_template=&#x27;[SYSTEM_PROMPT]\\n{system_message}\\n[/SYSTEM_PROMPT]\\n\\n&#x27;, system_message=&#x27;&#x27;, roles=(&#x27;[INST]&#x27;, &#x27;[/INST]&#x27;), messages=(), offset=0, sep_style=&lt;SeparatorStyle.LLAMA2: 7&gt;, sep=&#x27; &#x27;, sep2=&#x27; &lt;/s&gt;&lt;s&gt;&#x27;, stop_str=[&#x27;[INST]&#x27;, &#x27;[/INST]&#x27;, &#x27;[SYSTEM_PROMPT]&#x27;, &#x27;[/SYSTEM_PROMPT]&#x27;], image_token=&#x27;[IMG]&#x27;, video_token=&#x27;&lt;video&gt;&#x27;, audio_token=&#x27;&lt;audio&gt;&#x27;, image_data=None, video_data=None, modalities=None, stop_token_ids=None, audio_data=None), &#x27;devstral&#x27;: Conversation(name=&#x27;devstral&#x27;, system_template=&#x27;[SYSTEM_PROMPT]\\n{system_message}\\n[/SYSTEM_PROMPT]\\n\\n&#x27;, system_message=&#x27;&#x27;, roles=(&#x27;[INST]&#x27;, &#x27;[/INST]&#x27;), messages=(), offset=0, sep_style=&lt;SeparatorStyle.LLAMA2: 7&gt;, sep=&#x27; &#x27;, sep2=&#x27; &lt;/s&gt;&lt;s&gt;&#x27;, stop_str=[&#x27;[INST]&#x27;, &#x27;[/INST]&#x27;, &#x27;[SYSTEM_PROMPT]&#x27;, &#x27;[/SYSTEM_PROMPT]&#x27;], image_token=&#x27;[IMG]&#x27;, video_token=&#x27;&lt;video&gt;&#x27;, audio_token=&#x27;&lt;audio&gt;&#x27;, image_data=None, video_data=None, modalities=None, stop_token_ids=None, audio_data=None), &#x27;llama-4&#x27;: Conversation(name=&#x27;llama-4&#x27;, system_template=&#x27;&lt;|header_start|&gt;system&lt;|header_end|&gt;\\n\\n{system_message}&lt;|eot|&gt;&#x27;, system_message=&#x27;&#x27;, roles=(&#x27;user&#x27;, &#x27;assistant&#x27;), messages=(), offset=0, sep_style=&lt;SeparatorStyle.LLAMA4: 9&gt;, sep=&#x27;&#x27;, sep2=None, stop_str=[&#x27;&lt;|end_of_text|&gt;&#x27;, &#x27;&lt;|eot|&gt;&#x27;, &#x27;&lt;|eom|&gt;&#x27;], image_token=&#x27;&lt;|image|&gt;&#x27;, video_token=&#x27;&lt;video&gt;&#x27;, audio_token=&#x27;&lt;audio&gt;&#x27;, image_data=None, video_data=None, modalities=None, stop_token_ids=None, audio_data=None), &#x27;phi-4-mm&#x27;: Conversation(name=&#x27;phi-4-mm&#x27;, system_template=&#x27;{system_message}&#x27;, system_message=&#x27;&#x27;, roles=(&#x27;&lt;|user|&gt;&#x27;, &#x27;&lt;|assistant|&gt;&#x27;), messages=(), offset=0, sep_style=&lt;SeparatorStyle.NO_COLON_SINGLE: 4&gt;, sep=&#x27;&lt;|end|&gt;&#x27;, sep2=None, stop_str=&#x27;&lt;|end|&gt;&#x27;, image_token=&#x27;&lt;|endoftext10|&gt;&#x27;, video_token=&#x27;&lt;video&gt;&#x27;, audio_token=&#x27;&lt;|endoftext11|&gt;&#x27;, image_data=None, video_data=None, modalities=None, stop_token_ids=None, audio_data=None), &#x27;chatml&#x27;: Conversation(name=&#x27;chatml&#x27;, system_template=&#x27;&lt;|im_start|&gt;system\\n{system_message}&#x27;, system_message=&#x27;You are a helpful assistant.&#x27;, roles=(&#x27;&lt;|im_start|&gt;user&#x27;, &#x27;&lt;|im_start|&gt;assistant&#x27;), messages=(), offset=0, sep_style=&lt;SeparatorStyle.CHATML: 11&gt;, sep=&#x27;&lt;|im_end|&gt;&#x27;, sep2=None, stop_str=[&#x27;&lt;|endoftext|&gt;&#x27;, &#x27;&lt;|im_end|&gt;&#x27;], image_token=&#x27;&lt;image&gt;&#x27;, video_token=&#x27;&lt;video&gt;&#x27;, audio_token=&#x27;&lt;audio&gt;&#x27;, image_data=None, video_data=None, modalities=None, stop_token_ids=None, audio_data=None), &#x27;chatml-llava&#x27;: Conversation(name=&#x27;chatml-llava&#x27;, system_template=&#x27;&lt;|im_start|&gt;system\\n{system_message}&#x27;, system_message=&#x27;You are a helpful assistant.&#x27;, roles=(&#x27;&lt;|im_start|&gt;user&#x27;, &#x27;&lt;|im_start|&gt;assistant&#x27;), messages=(), offset=0, sep_style=&lt;SeparatorStyle.CHATML: 11&gt;, sep=&#x27;&lt;|im_end|&gt;&#x27;, sep2=None, stop_str=[&#x27;&lt;|endoftext|&gt;&#x27;, &#x27;&lt;|im_end|&gt;&#x27;], image_token=&#x27;&lt;image&gt;&#x27;, video_token=&#x27;&lt;video&gt;&#x27;, audio_token=&#x27;&lt;audio&gt;&#x27;, image_data=None, video_data=None, modalities=None, stop_token_ids=None, audio_data=None), &#x27;vicuna_v1.1&#x27;: Conversation(name=&#x27;vicuna_v1.1&#x27;, system_template=&#x27;{system_message}&#x27;, system_message=&quot;A chat between a curious user and an artificial intelligence assistant. The assistant gives helpful, detailed, and polite answers to the user&#x27;s questions.&quot;, roles=(&#x27;USER&#x27;, &#x27;ASSISTANT&#x27;), messages=(), offset=0, sep_style=&lt;SeparatorStyle.ADD_COLON_TWO: 2&gt;, sep=&#x27; &#x27;, sep2=&#x27;&lt;/s&gt;&#x27;, stop_str=None, image_token=&#x27;&lt;image&gt;&#x27;, video_token=&#x27;&lt;video&gt;&#x27;, audio_token=&#x27;&lt;audio&gt;&#x27;, image_data=None, video_data=None, modalities=None, stop_token_ids=None, audio_data=None), &#x27;llama_3_vision&#x27;: Conversation(name=&#x27;llama_3_vision&#x27;, system_template=&#x27;&lt;|start_header_id|&gt;system&lt;|end_header_id|&gt;\\n\\n{system_message}&lt;|eot_id|&gt;&#x27;, system_message=&#x27;You are a helpful language and vision assistant. You are able to understand the visual content that the user provides, and assist the user with a variety of tasks using natural language.&#x27;, roles=(&#x27;user&#x27;, &#x27;assistant&#x27;), messages=(), offset=0, sep_style=&lt;SeparatorStyle.LLAMA3: 8&gt;, sep=&#x27;&#x27;, sep2=None, stop_str=[&#x27;&lt;|end_of_text|&gt;&#x27;, &#x27;&lt;|eot_id|&gt;&#x27;], image_token=&#x27;&lt;|image|&gt;&#x27;, video_token=&#x27;&lt;video&gt;&#x27;, audio_token=&#x27;&lt;audio&gt;&#x27;, image_data=None, video_data=None, modalities=None, stop_token_ids=None, audio_data=None), &#x27;llava_llama_3&#x27;: Conversation(name=&#x27;llava_llama_3&#x27;, system_template=&#x27;&lt;|start_header_id|&gt;system&lt;|end_header_id|&gt;\\n\\n{system_message}&lt;|eot_id|&gt;&#x27;, system_message=&#x27;You are a helpful language and vision assistant. You are able to understand the visual content that the user provides, and assist the user with a variety of tasks using natural language.&#x27;, roles=(&#x27;user&#x27;, &#x27;assistant&#x27;), messages=(), offset=0, sep_style=&lt;SeparatorStyle.LLAMA3: 8&gt;, sep=&#x27;&#x27;, sep2=None, stop_str=[&#x27;&lt;|end_of_text|&gt;&#x27;, &#x27;&lt;|eot_id|&gt;&#x27;], image_token=&#x27;&lt;image&gt;&#x27;, video_token=&#x27;&lt;video&gt;&#x27;, audio_token=&#x27;&lt;audio&gt;&#x27;, image_data=None, video_data=None, modalities=None, stop_token_ids=None, audio_data=None), &#x27;internlm2-chat&#x27;: Conversation(name=&#x27;internlm2-chat&#x27;, system_template=&#x27;&lt;|im_start|&gt;system\\n{system_message}&#x27;, system_message=&#x27;&#x27;, roles=(&#x27;&lt;|im_start|&gt;user&#x27;, &#x27;&lt;|im_start|&gt;assistant&#x27;), messages=(), offset=0, sep_style=&lt;SeparatorStyle.ADD_COLON_SINGLE: 1&gt;, sep=&#x27;\\n&#x27;, sep2=None, stop_str=[&#x27;&lt;|im_end|&gt;&#x27;, &#x27;&lt;|action_end|&gt;&#x27;], image_token=&#x27;&lt;image&gt;&#x27;, video_token=&#x27;&lt;video&gt;&#x27;, audio_token=&#x27;&lt;audio&gt;&#x27;, image_data=None, video_data=None, modalities=None, stop_token_ids=None, audio_data=None), &#x27;internvl-2-5&#x27;: Conversation(name=&#x27;internvl-2-5&#x27;, system_template=&#x27;&lt;|im_start|&gt;system\\n{system_message}&#x27;, system_message=&#x27;\u4f60\u662f\u4e66\u751f\u00b7\u4e07\u8c61\uff0c\u82f1\u6587\u540d\u662fInternVL\uff0c\u662f\u7531\u4e0a\u6d77\u4eba\u5de5\u667a\u80fd\u5b9e\u9a8c\u5ba4\u3001\u6e05\u534e\u5927\u5b66\u53ca\u591a\u5bb6\u5408\u4f5c\u5355\u4f4d\u8054\u5408\u5f00\u53d1\u7684\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u3002&#x27;, roles=(&#x27;&lt;|im_start|&gt;user\\n&#x27;, &#x27;&lt;|im_start|&gt;assistant\\n&#x27;), messages=(), offset=0, sep_style=&lt;SeparatorStyle.MPT: 25&gt;, sep=&#x27;&lt;|im_end|&gt;\\n&#x27;, sep2=None, stop_str=[&#x27;&lt;|im_end|&gt;&#x27;, &#x27;&lt;|action_end|&gt;&#x27;], image_token=&#x27;&lt;IMG_CONTEXT&gt;&#x27;, video_token=&#x27;&lt;video&gt;&#x27;, audio_token=&#x27;&lt;audio&gt;&#x27;, image_data=None, video_data=None, modalities=None, stop_token_ids=None, audio_data=None), &#x27;qwen2-vl&#x27;: Conversation(name=&#x27;qwen2-vl&#x27;, system_template=&#x27;&lt;|im_start|&gt;system\\n{system_message}&#x27;, system_message=&#x27;You are a helpful assistant.&#x27;, roles=(&#x27;&lt;|im_start|&gt;user&#x27;, &#x27;&lt;|im_start|&gt;assistant&#x27;), messages=(), offset=0, sep_style=&lt;SeparatorStyle.ADD_NEW_LINE_SINGLE: 6&gt;, sep=&#x27;&lt;|im_end|&gt;\\n&#x27;, sep2=None, stop_str=[&#x27;&lt;|im_end|&gt;&#x27;], image_token=&#x27;&lt;|vision_start|&gt;&lt;|image_pad|&gt;&lt;|vision_end|&gt;&#x27;, video_token=&#x27;&lt;|vision_start|&gt;&lt;|video_pad|&gt;&lt;|vision_end|&gt;&#x27;, audio_token=&#x27;&lt;audio&gt;&#x27;, image_data=None, video_data=None, modalities=None, stop_token_ids=None, audio_data=None), &#x27;deepseek-vl2&#x27;: Conversation(name=&#x27;deepseek-vl2&#x27;, system_template=&#x27;{system_message}&#x27;, system_message=&#x27;&#x27;, roles=(&#x27;&lt;|User|&gt;&#x27;, &#x27;&lt;|Assistant|&gt;&#x27;), messages=(), offset=0, sep_style=&lt;SeparatorStyle.DeepSeekVL2: 21&gt;, sep=&#x27;\\n\\n&#x27;, sep2=&#x27;&lt;\uff5cend\u2581of\u2581sentence\uff5c&gt;&#x27;, stop_str=[&#x27;User:&#x27;, &#x27;&lt;\uff5cend\u2581of\u2581sentence\uff5c&gt;&#x27;], image_token=&#x27;&lt;image&gt;&#x27;, video_token=&#x27;&lt;video&gt;&#x27;, audio_token=&#x27;&lt;audio&gt;&#x27;, image_data=None, video_data=None, modalities=None, stop_token_ids=None, audio_data=None), &#x27;gemma-it&#x27;: Conversation(name=&#x27;gemma-it&#x27;, system_template=&#x27;&lt;start_of_turn&gt;user\\n{system_message}\\n\\n&#x27;, system_message=&#x27;You are a helpful assistant.&#x27;, roles=(&#x27;&lt;start_of_turn&gt;user\\n&#x27;, &#x27;&lt;start_of_turn&gt;model\\n&#x27;), messages=(), offset=0, sep_style=&lt;SeparatorStyle.GEMMA3: 24&gt;, sep=&#x27;&lt;end_of_turn&gt;\\n&#x27;, sep2=None, stop_str=[&#x27;&lt;end_of_turn&gt;&#x27;], image_token=&#x27;&lt;start_of_image&gt;&#x27;, video_token=&#x27;&lt;video&gt;&#x27;, audio_token=&#x27;&lt;start_of_audio&gt;&#x27;, image_data=None, video_data=None, modalities=None, stop_token_ids=None, audio_data=None), &#x27;gme-qwen2-vl&#x27;: Conversation(name=&#x27;gme-qwen2-vl&#x27;, system_template=&#x27;&lt;|im_start|&gt;system\\n{system_message}&#x27;, system_message=&#x27;You are a helpful assistant.&#x27;, roles=(&#x27;&lt;|im_start|&gt;user&#x27;, &#x27;&lt;|im_start|&gt;assistant&#x27;), messages=(), offset=0, sep_style=&lt;SeparatorStyle.QWEN2_VL_EMBED: 22&gt;, sep=&#x27;&lt;|im_end|&gt;\\n&#x27;, sep2=None, stop_str=&#x27;&lt;|endoftext|&gt;&#x27;, image_token=&#x27;&lt;|vision_start|&gt;&lt;|image_pad|&gt;&lt;|vision_end|&gt;&#x27;, video_token=&#x27;&lt;video&gt;&#x27;, audio_token=&#x27;&lt;audio&gt;&#x27;, image_data=None, video_data=None, modalities=None, stop_token_ids=None, audio_data=None), &#x27;minicpmv&#x27;: Conversation(name=&#x27;minicpmv&#x27;, system_template=&#x27;&lt;|im_start|&gt;system\\n{system_message}.&#x27;, system_message=&#x27;You are a helpful assistant&#x27;, roles=(&#x27;&lt;|im_start|&gt;user&#x27;, &#x27;&lt;|im_start|&gt;assistant&#x27;), messages=(), offset=0, sep_style=&lt;SeparatorStyle.ADD_NEW_LINE_SINGLE: 6&gt;, sep=&#x27;&lt;|im_end|&gt;\\n&#x27;, sep2=None, stop_str=(&#x27;&lt;|im_end|&gt;&#x27;, &#x27;&lt;|endoftext|&gt;&#x27;), image_token=&#x27;(&lt;image&gt;./&lt;/image&gt;)&#x27;, video_token=&#x27;(&lt;video&gt;./&lt;/video&gt;)&#x27;, audio_token=&#x27;&lt;audio&gt;&#x27;, image_data=None, video_data=None, modalities=None, stop_token_ids=None, audio_data=None), &#x27;janus-pro&#x27;: Conversation(name=&#x27;janus-pro&#x27;, system_template=&#x27;{system_message}.&#x27;, system_message=&#x27;You are a helpful language and vision assistant. You are able to understand the visual content that the user provides, and assist the user with a variety of tasks using natural language&#x27;, roles=(&#x27;User&#x27;, &#x27;Assistant&#x27;), messages=(), offset=0, sep_style=&lt;SeparatorStyle.ADD_COLON_TWO: 2&gt;, sep=&#x27;\\n\\n&#x27;, sep2=&#x27;&lt;\uff5cend\u2581of\u2581sentence\uff5c&gt;&#x27;, stop_str=[&#x27;&lt;|User|&gt;&#x27;, &#x27;&lt;\uff5cend\u2581of\u2581sentence\uff5c&gt;&#x27;], image_token=&#x27;&lt;image_placeholder&gt;&#x27;, video_token=&#x27;&lt;video&gt;&#x27;, audio_token=&#x27;&lt;audio&gt;&#x27;, image_data=None, video_data=None, modalities=None, stop_token_ids=None, audio_data=None), &#x27;minicpmo&#x27;: Conversation(name=&#x27;minicpmo&#x27;, system_template=&#x27;&lt;|im_start|&gt;system\\n{system_message}&#x27;, system_message=&#x27;You are Qwen, created by Alibaba Cloud. You are a helpful assistant.&#x27;, roles=(&#x27;&lt;|im_start|&gt;user&#x27;, &#x27;&lt;|im_start|&gt;assistant&#x27;), messages=(), offset=0, sep_style=&lt;SeparatorStyle.ADD_NEW_LINE_SINGLE: 6&gt;, sep=&#x27;&lt;|im_end|&gt;\\n&#x27;, sep2=None, stop_str=(&#x27;&lt;|im_end|&gt;&#x27;, &#x27;&lt;|endoftext|&gt;&#x27;), image_token=&#x27;(&lt;image&gt;./&lt;/image&gt;)&#x27;, video_token=&#x27;&lt;video&gt;&#x27;, audio_token=&#x27;(&lt;audio&gt;./&lt;/audio&gt;)&#x27;, image_data=None, video_data=None, modalities=None, stop_token_ids=None, audio_data=None), &#x27;kimi-vl&#x27;: Conversation(name=&#x27;kimi-vl&#x27;, system_template=&#x27;&lt;|im_system|&gt;system&lt;|im_middle|&gt;{system_message}&#x27;, system_message=&#x27;You are a helpful assistant&#x27;, roles=(&#x27;&lt;|im_user|&gt;user&lt;|im_middle|&gt;&#x27;, &#x27;&lt;|im_assistant|&gt;assistant&lt;|im_middle|&gt;&#x27;), messages=[], offset=0, sep_style=&lt;SeparatorStyle.NO_COLON_SINGLE: 4&gt;, sep=&#x27;&lt;|im_end|&gt;&#x27;, sep2=None, stop_str=&#x27;&lt;|im_end|&gt;&#x27;, image_token=&#x27;&lt;|media_start|&gt;image&lt;|media_content|&gt;&lt;|media_pad|&gt;&lt;|media_end|&gt;&#x27;, video_token=&#x27;&lt;video&gt;&#x27;, audio_token=&#x27;&lt;audio&gt;&#x27;, image_data=None, video_data=None, modalities=None, stop_token_ids=None, audio_data=None), &#x27;qwen2-audio&#x27;: Conversation(name=&#x27;qwen2-audio&#x27;, system_template=&#x27;&lt;|im_start|&gt;system\\n{system_message}&#x27;, system_message=&#x27;You are a helpful assistant.&#x27;, roles=(&#x27;&lt;|im_start|&gt;user&#x27;, &#x27;&lt;|im_start|&gt;assistant&#x27;), messages=(), offset=0, sep_style=&lt;SeparatorStyle.QWEN2_AUDIO: 23&gt;, sep=&#x27;&lt;|im_end|&gt;\\n&#x27;, sep2=None, stop_str=[&#x27;&lt;|im_end|&gt;&#x27;], image_token=&#x27;&lt;image&gt;&#x27;, video_token=&#x27;&lt;video&gt;&#x27;, audio_token=&#x27;Audio {idx}: &lt;|audio_bos|&gt;&lt;|AUDIO|&gt;&lt;|audio_eos|&gt;\\n&#x27;, image_data=None, video_data=None, modalities=None, stop_token_ids=None, audio_data=None)}"}, {"fullname": "sglang.srt.conversation.matching_function_registry", "modulename": "sglang.srt.conversation", "qualname": "matching_function_registry", "kind": "variable", "doc": "<p></p>\n", "annotation": ": List[Callable]", "default_value": "[&lt;function match_internvl&gt;, &lt;function match_deepseek_janus_pro&gt;, &lt;function match_vicuna&gt;, &lt;function match_deepseek_vl&gt;, &lt;function match_qwen_chat_ml&gt;, &lt;function match_minicpm&gt;, &lt;function match_phi_4_mm&gt;]"}, {"fullname": "sglang.srt.conversation.register_conv_template", "modulename": "sglang.srt.conversation", "qualname": "register_conv_template", "kind": "function", "doc": "<p>Register a new conversation template.</p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">template</span><span class=\"p\">:</span> <span class=\"n\">sglang</span><span class=\"o\">.</span><span class=\"n\">srt</span><span class=\"o\">.</span><span class=\"n\">conversation</span><span class=\"o\">.</span><span class=\"n\">Conversation</span>,</span><span class=\"param\">\t<span class=\"n\">override</span><span class=\"p\">:</span> <span class=\"nb\">bool</span> <span class=\"o\">=</span> <span class=\"kc\">False</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.conversation.register_conv_template_matching_function", "modulename": "sglang.srt.conversation", "qualname": "register_conv_template_matching_function", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">func</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.conversation.get_conv_template_by_model_path", "modulename": "sglang.srt.conversation", "qualname": "get_conv_template_by_model_path", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">model_path</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.conversation.chat_template_exists", "modulename": "sglang.srt.conversation", "qualname": "chat_template_exists", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">template_name</span><span class=\"p\">:</span> <span class=\"nb\">str</span></span><span class=\"return-annotation\">) -> <span class=\"nb\">bool</span>:</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.conversation.generate_embedding_convs", "modulename": "sglang.srt.conversation", "qualname": "generate_embedding_convs", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">texts</span><span class=\"p\">:</span> <span class=\"n\">List</span><span class=\"p\">[</span><span class=\"nb\">str</span><span class=\"p\">]</span>,</span><span class=\"param\">\t<span class=\"n\">images</span><span class=\"p\">:</span> <span class=\"n\">List</span><span class=\"p\">[</span><span class=\"nb\">str</span><span class=\"p\">]</span>,</span><span class=\"param\">\t<span class=\"n\">template_name</span><span class=\"p\">:</span> <span class=\"nb\">str</span></span><span class=\"return-annotation\">) -> <span class=\"n\">List</span><span class=\"p\">[</span><span class=\"n\">sglang</span><span class=\"o\">.</span><span class=\"n\">srt</span><span class=\"o\">.</span><span class=\"n\">conversation</span><span class=\"o\">.</span><span class=\"n\">Conversation</span><span class=\"p\">]</span>:</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.conversation.generate_chat_conv", "modulename": "sglang.srt.conversation", "qualname": "generate_chat_conv", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">request</span><span class=\"p\">:</span> <span class=\"n\">sglang</span><span class=\"o\">.</span><span class=\"n\">srt</span><span class=\"o\">.</span><span class=\"n\">entrypoints</span><span class=\"o\">.</span><span class=\"n\">openai</span><span class=\"o\">.</span><span class=\"n\">protocol</span><span class=\"o\">.</span><span class=\"n\">ChatCompletionRequest</span>,</span><span class=\"param\">\t<span class=\"n\">template_name</span><span class=\"p\">:</span> <span class=\"nb\">str</span></span><span class=\"return-annotation\">) -> <span class=\"n\">sglang</span><span class=\"o\">.</span><span class=\"n\">srt</span><span class=\"o\">.</span><span class=\"n\">conversation</span><span class=\"o\">.</span><span class=\"n\">Conversation</span>:</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.conversation.MODEL_TYPE_TO_TEMPLATE", "modulename": "sglang.srt.conversation", "qualname": "MODEL_TYPE_TO_TEMPLATE", "kind": "variable", "doc": "<p></p>\n", "default_value": "{&#x27;internvl_chat&#x27;: &#x27;internvl-2-5&#x27;, &#x27;deepseek_vl_v2&#x27;: &#x27;deepseek-vl2&#x27;, &#x27;multi_modality&#x27;: &#x27;janus-pro&#x27;, &#x27;phi4mm&#x27;: &#x27;phi-4-mm&#x27;, &#x27;minicpmv&#x27;: &#x27;minicpmv&#x27;, &#x27;minicpmo&#x27;: &#x27;minicpmo&#x27;}"}, {"fullname": "sglang.srt.conversation.get_model_type", "modulename": "sglang.srt.conversation", "qualname": "get_model_type", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">model_path</span><span class=\"p\">:</span> <span class=\"nb\">str</span></span><span class=\"return-annotation\">) -> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"nb\">str</span><span class=\"p\">]</span>:</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.custom_op", "modulename": "sglang.srt.custom_op", "kind": "module", "doc": "<p></p>\n"}, {"fullname": "sglang.srt.custom_op.CustomOp", "modulename": "sglang.srt.custom_op", "qualname": "CustomOp", "kind": "class", "doc": "<p>Base class for all neural network modules.</p>\n\n<p>Your models should also subclass this class.</p>\n\n<p>Modules can also contain other Modules, allowing them to be nested in\na tree structure. You can assign the submodules as regular attributes::</p>\n\n<pre><code>import torch.nn as nn\nimport torch.nn.functional as F\n\n\nclass Model(nn.Module):\n    def __init__(self) -&gt; None:\n        super().__init__()\n        self.conv1 = nn.Conv2d(1, 20, 5)\n        self.conv2 = nn.Conv2d(20, 20, 5)\n\n    def forward(self, x):\n        x = F.relu(self.conv1(x))\n        return F.relu(self.conv2(x))\n</code></pre>\n\n<p>Submodules assigned in this way will be registered, and will also have their\nparameters converted when you call <code>to()</code>, etc.</p>\n\n<div class=\"alert note\">\n\n<p>As per the example above, an <code>__init__()</code> call to the parent class\nmust be made before assignment on the child.</p>\n\n</div>\n\n<p>:ivar training: Boolean represents whether this module is in training or\n                evaluation mode.\n:vartype training: bool</p>\n", "bases": "torch.nn.modules.module.Module"}, {"fullname": "sglang.srt.custom_op.CustomOp.__init__", "modulename": "sglang.srt.custom_op", "qualname": "CustomOp.__init__", "kind": "function", "doc": "<p>Initialize internal Module state, shared by both nn.Module and ScriptModule.</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">()</span>"}, {"fullname": "sglang.srt.custom_op.CustomOp.is_torch_compile", "modulename": "sglang.srt.custom_op", "qualname": "CustomOp.is_torch_compile", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "sglang.srt.custom_op.CustomOp.enter_torch_compile", "modulename": "sglang.srt.custom_op", "qualname": "CustomOp.enter_torch_compile", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">num_tokens</span><span class=\"p\">:</span> <span class=\"nb\">int</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.custom_op.CustomOp.leave_torch_compile", "modulename": "sglang.srt.custom_op", "qualname": "CustomOp.leave_torch_compile", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.custom_op.CustomOp.forward", "modulename": "sglang.srt.custom_op", "qualname": "CustomOp.forward", "kind": "function", "doc": "<p>Define the computation performed at every call.</p>\n\n<p>Should be overridden by all subclasses.</p>\n\n<div class=\"alert note\">\n\n<p>Although the recipe for forward pass needs to be defined within\nthis function, one should call the <code>Module</code> instance afterwards\ninstead of this since the former takes care of running the\nregistered hooks while the latter silently ignores them.</p>\n\n</div>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"o\">*</span><span class=\"n\">args</span>, </span><span class=\"param\"><span class=\"o\">**</span><span class=\"n\">kwargs</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.custom_op.CustomOp.forward_native", "modulename": "sglang.srt.custom_op", "qualname": "CustomOp.forward_native", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"o\">*</span><span class=\"n\">args</span>, </span><span class=\"param\"><span class=\"o\">**</span><span class=\"n\">kwargs</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.custom_op.CustomOp.forward_cuda", "modulename": "sglang.srt.custom_op", "qualname": "CustomOp.forward_cuda", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"o\">*</span><span class=\"n\">args</span>, </span><span class=\"param\"><span class=\"o\">**</span><span class=\"n\">kwargs</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.custom_op.CustomOp.forward_npu", "modulename": "sglang.srt.custom_op", "qualname": "CustomOp.forward_npu", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"o\">*</span><span class=\"n\">args</span>, </span><span class=\"param\"><span class=\"o\">**</span><span class=\"n\">kwargs</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.custom_op.CustomOp.forward_hip", "modulename": "sglang.srt.custom_op", "qualname": "CustomOp.forward_hip", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"o\">*</span><span class=\"n\">args</span>, </span><span class=\"param\"><span class=\"o\">**</span><span class=\"n\">kwargs</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.custom_op.CustomOp.forward_xpu", "modulename": "sglang.srt.custom_op", "qualname": "CustomOp.forward_xpu", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"o\">*</span><span class=\"n\">args</span>, </span><span class=\"param\"><span class=\"o\">**</span><span class=\"n\">kwargs</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.custom_op.CustomOp.forward_hpu", "modulename": "sglang.srt.custom_op", "qualname": "CustomOp.forward_hpu", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"o\">*</span><span class=\"n\">args</span>, </span><span class=\"param\"><span class=\"o\">**</span><span class=\"n\">kwargs</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.custom_op.CustomOp.forward_cpu", "modulename": "sglang.srt.custom_op", "qualname": "CustomOp.forward_cpu", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"o\">*</span><span class=\"n\">args</span>, </span><span class=\"param\"><span class=\"o\">**</span><span class=\"n\">kwargs</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.custom_op.CustomOp.dispatch_forward", "modulename": "sglang.srt.custom_op", "qualname": "CustomOp.dispatch_forward", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.debug_utils", "modulename": "sglang.srt.debug_utils", "kind": "module", "doc": "<p></p>\n"}, {"fullname": "sglang.srt.debug_utils.dump_comparator", "modulename": "sglang.srt.debug_utils.dump_comparator", "kind": "module", "doc": "<p></p>\n"}, {"fullname": "sglang.srt.debug_utils.dump_comparator.main", "modulename": "sglang.srt.debug_utils.dump_comparator", "qualname": "main", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">args</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.debug_utils.dump_comparator.read_meta", "modulename": "sglang.srt.debug_utils.dump_comparator", "qualname": "read_meta", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">directory</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.debug_utils.dump_comparator.check_tensor_pair", "modulename": "sglang.srt.debug_utils.dump_comparator", "qualname": "check_tensor_pair", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">path_baseline</span>, </span><span class=\"param\"><span class=\"n\">path_target</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.debug_utils.dumper", "modulename": "sglang.srt.debug_utils.dumper", "kind": "module", "doc": "<p></p>\n"}, {"fullname": "sglang.srt.debug_utils.dumper.get_truncated_value", "modulename": "sglang.srt.debug_utils.dumper", "qualname": "get_truncated_value", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">value</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.debug_utils.dumper.dumper", "modulename": "sglang.srt.debug_utils.dumper", "qualname": "dumper", "kind": "variable", "doc": "<p></p>\n", "default_value": "&lt;sglang.srt.debug_utils.dumper._Dumper object&gt;"}, {"fullname": "sglang.srt.debug_utils.text_comparator", "modulename": "sglang.srt.debug_utils.text_comparator", "kind": "module", "doc": "<p></p>\n"}, {"fullname": "sglang.srt.debug_utils.text_comparator.main", "modulename": "sglang.srt.debug_utils.text_comparator", "qualname": "main", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">args</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.distributed", "modulename": "sglang.srt.distributed", "kind": "module", "doc": "<p></p>\n"}, {"fullname": "sglang.srt.distributed.communication_op", "modulename": "sglang.srt.distributed.communication_op", "kind": "module", "doc": "<p></p>\n"}, {"fullname": "sglang.srt.distributed.communication_op.tensor_model_parallel_all_reduce", "modulename": "sglang.srt.distributed.communication_op", "qualname": "tensor_model_parallel_all_reduce", "kind": "function", "doc": "<p>All-reduce the input tensor across model parallel group.</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">input_</span><span class=\"p\">:</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">Tensor</span></span><span class=\"return-annotation\">) -> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">Tensor</span>:</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.distributed.communication_op.tensor_model_parallel_all_gather", "modulename": "sglang.srt.distributed.communication_op", "qualname": "tensor_model_parallel_all_gather", "kind": "function", "doc": "<p>All-gather the input tensor across model parallel group.</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">input_</span><span class=\"p\">:</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">Tensor</span>, </span><span class=\"param\"><span class=\"n\">dim</span><span class=\"p\">:</span> <span class=\"nb\">int</span> <span class=\"o\">=</span> <span class=\"o\">-</span><span class=\"mi\">1</span></span><span class=\"return-annotation\">) -> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">Tensor</span>:</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.distributed.communication_op.tensor_model_parallel_gather", "modulename": "sglang.srt.distributed.communication_op", "qualname": "tensor_model_parallel_gather", "kind": "function", "doc": "<p>Gather the input tensor across model parallel group.</p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">input_</span><span class=\"p\">:</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">Tensor</span>,</span><span class=\"param\">\t<span class=\"n\">dst</span><span class=\"p\">:</span> <span class=\"nb\">int</span> <span class=\"o\">=</span> <span class=\"mi\">0</span>,</span><span class=\"param\">\t<span class=\"n\">dim</span><span class=\"p\">:</span> <span class=\"nb\">int</span> <span class=\"o\">=</span> <span class=\"o\">-</span><span class=\"mi\">1</span></span><span class=\"return-annotation\">) -> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">Tensor</span><span class=\"p\">]</span>:</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.distributed.communication_op.broadcast_tensor_dict", "modulename": "sglang.srt.distributed.communication_op", "qualname": "broadcast_tensor_dict", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">tensor_dict</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"n\">Dict</span><span class=\"p\">[</span><span class=\"n\">Any</span><span class=\"p\">,</span> <span class=\"n\">Union</span><span class=\"p\">[</span><span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">Tensor</span><span class=\"p\">,</span> <span class=\"n\">Any</span><span class=\"p\">]]]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">src</span><span class=\"p\">:</span> <span class=\"nb\">int</span> <span class=\"o\">=</span> <span class=\"mi\">0</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.distributed.naive_distributed", "modulename": "sglang.srt.distributed.naive_distributed", "kind": "module", "doc": "<p></p>\n"}, {"fullname": "sglang.srt.distributed.naive_distributed.NaiveDistributed", "modulename": "sglang.srt.distributed.naive_distributed", "qualname": "NaiveDistributed", "kind": "class", "doc": "<p></p>\n"}, {"fullname": "sglang.srt.distributed.naive_distributed.NaiveDistributed.__init__", "modulename": "sglang.srt.distributed.naive_distributed", "qualname": "NaiveDistributed.__init__", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">rank</span><span class=\"p\">:</span> <span class=\"nb\">int</span>, </span><span class=\"param\"><span class=\"n\">world_size</span><span class=\"p\">:</span> <span class=\"nb\">int</span>, </span><span class=\"param\"><span class=\"n\">rendezvous</span><span class=\"p\">:</span> <span class=\"nb\">str</span></span>)</span>"}, {"fullname": "sglang.srt.distributed.naive_distributed.NaiveDistributed.get_rank", "modulename": "sglang.srt.distributed.naive_distributed", "qualname": "NaiveDistributed.get_rank", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.distributed.naive_distributed.NaiveDistributed.get_world_size", "modulename": "sglang.srt.distributed.naive_distributed", "qualname": "NaiveDistributed.get_world_size", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.distributed.naive_distributed.NaiveDistributed.scatter", "modulename": "sglang.srt.distributed.naive_distributed", "qualname": "NaiveDistributed.scatter", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"bp\">self</span>,</span><span class=\"param\">\t<span class=\"n\">tensor</span><span class=\"p\">:</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">Tensor</span>,</span><span class=\"param\">\t<span class=\"n\">scatter_list</span><span class=\"p\">:</span> <span class=\"n\">List</span><span class=\"p\">[</span><span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">Tensor</span><span class=\"p\">]</span>,</span><span class=\"param\">\t<span class=\"n\">src</span><span class=\"p\">:</span> <span class=\"nb\">int</span> <span class=\"o\">=</span> <span class=\"mi\">0</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.distributed.naive_distributed.NaiveDistributed.all_gather_object", "modulename": "sglang.srt.distributed.naive_distributed", "qualname": "NaiveDistributed.all_gather_object", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">obj</span><span class=\"p\">:</span> <span class=\"n\">Any</span></span><span class=\"return-annotation\">) -> <span class=\"n\">List</span><span class=\"p\">[</span><span class=\"n\">Any</span><span class=\"p\">]</span>:</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.distributed.naive_distributed.NaiveDistributed.barrier", "modulename": "sglang.srt.distributed.naive_distributed", "qualname": "NaiveDistributed.barrier", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.distributed.naive_distributed.get_naive_distributed", "modulename": "sglang.srt.distributed.naive_distributed", "qualname": "get_naive_distributed", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.distributed.naive_distributed.set_naive_distributed", "modulename": "sglang.srt.distributed.naive_distributed", "qualname": "set_naive_distributed", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">instance</span><span class=\"p\">:</span> <span class=\"n\">sglang</span><span class=\"o\">.</span><span class=\"n\">srt</span><span class=\"o\">.</span><span class=\"n\">distributed</span><span class=\"o\">.</span><span class=\"n\">naive_distributed</span><span class=\"o\">.</span><span class=\"n\">NaiveDistributed</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.distributed.parallel_state", "modulename": "sglang.srt.distributed.parallel_state", "kind": "module", "doc": "<p>vLLM distributed state.\nIt takes over the control of the distributed environment from PyTorch.\nThe typical workflow is:</p>\n\n<ul>\n<li>call <code>init_distributed_environment</code> to initialize the distributed environment.</li>\n<li><p>call <code>initialize_model_parallel</code> or <code>ensure_model_parallel_initialized</code> to\ninitialize the model parallel groups.</p></li>\n<li><p>any code dealing with the distributed stuff</p></li>\n<li><p>call <code>destroy_model_parallel</code> to destroy the model parallel groups.</p></li>\n<li>call <code>destroy_distributed_environment</code> to destroy the distributed environment.</li>\n</ul>\n\n<p>If you only need to use the distributed environment without model/pipeline\n parallelism, you can skip the model parallel initialization and destruction\n steps.</p>\n"}, {"fullname": "sglang.srt.distributed.parallel_state.GraphCaptureContext", "modulename": "sglang.srt.distributed.parallel_state", "qualname": "GraphCaptureContext", "kind": "class", "doc": "<p></p>\n"}, {"fullname": "sglang.srt.distributed.parallel_state.GraphCaptureContext.__init__", "modulename": "sglang.srt.distributed.parallel_state", "qualname": "GraphCaptureContext.__init__", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">stream</span><span class=\"p\">:</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">cuda</span><span class=\"o\">.</span><span class=\"n\">streams</span><span class=\"o\">.</span><span class=\"n\">Stream</span></span>)</span>"}, {"fullname": "sglang.srt.distributed.parallel_state.GraphCaptureContext.stream", "modulename": "sglang.srt.distributed.parallel_state", "qualname": "GraphCaptureContext.stream", "kind": "variable", "doc": "<p></p>\n", "annotation": ": torch.cuda.streams.Stream"}, {"fullname": "sglang.srt.distributed.parallel_state.TensorMetadata", "modulename": "sglang.srt.distributed.parallel_state", "qualname": "TensorMetadata", "kind": "class", "doc": "<p>TensorMetadata(device, dtype, size)</p>\n", "bases": "builtins.tuple"}, {"fullname": "sglang.srt.distributed.parallel_state.TensorMetadata.__init__", "modulename": "sglang.srt.distributed.parallel_state", "qualname": "TensorMetadata.__init__", "kind": "function", "doc": "<p>Create new instance of TensorMetadata(device, dtype, size)</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">device</span>, </span><span class=\"param\"><span class=\"n\">dtype</span>, </span><span class=\"param\"><span class=\"n\">size</span></span>)</span>"}, {"fullname": "sglang.srt.distributed.parallel_state.TensorMetadata.device", "modulename": "sglang.srt.distributed.parallel_state", "qualname": "TensorMetadata.device", "kind": "variable", "doc": "<p>Alias for field number 0</p>\n"}, {"fullname": "sglang.srt.distributed.parallel_state.TensorMetadata.dtype", "modulename": "sglang.srt.distributed.parallel_state", "qualname": "TensorMetadata.dtype", "kind": "variable", "doc": "<p>Alias for field number 1</p>\n"}, {"fullname": "sglang.srt.distributed.parallel_state.TensorMetadata.size", "modulename": "sglang.srt.distributed.parallel_state", "qualname": "TensorMetadata.size", "kind": "variable", "doc": "<p>Alias for field number 2</p>\n"}, {"fullname": "sglang.srt.distributed.parallel_state.GroupCoordinator", "modulename": "sglang.srt.distributed.parallel_state", "qualname": "GroupCoordinator", "kind": "class", "doc": "<p>PyTorch ProcessGroup wrapper for a group of processes.\nPyTorch ProcessGroup is bound to one specific communication backend,\n    e.g. NCCL, Gloo, MPI, etc.\nGroupCoordinator takes charge of all the communication operations among\n    the processes in the group. It can route the communication to\n    a specific implementation (e.g. switch allreduce implementation\n    based on the tensor size and cuda graph mode).</p>\n"}, {"fullname": "sglang.srt.distributed.parallel_state.GroupCoordinator.__init__", "modulename": "sglang.srt.distributed.parallel_state", "qualname": "GroupCoordinator.__init__", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">group_ranks</span><span class=\"p\">:</span> <span class=\"n\">List</span><span class=\"p\">[</span><span class=\"n\">List</span><span class=\"p\">[</span><span class=\"nb\">int</span><span class=\"p\">]]</span>,</span><span class=\"param\">\t<span class=\"n\">local_rank</span><span class=\"p\">:</span> <span class=\"nb\">int</span>,</span><span class=\"param\">\t<span class=\"n\">torch_distributed_backend</span><span class=\"p\">:</span> <span class=\"n\">Union</span><span class=\"p\">[</span><span class=\"nb\">str</span><span class=\"p\">,</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">distributed</span><span class=\"o\">.</span><span class=\"n\">distributed_c10d</span><span class=\"o\">.</span><span class=\"n\">Backend</span><span class=\"p\">]</span>,</span><span class=\"param\">\t<span class=\"n\">use_pynccl</span><span class=\"p\">:</span> <span class=\"nb\">bool</span>,</span><span class=\"param\">\t<span class=\"n\">use_pymscclpp</span><span class=\"p\">:</span> <span class=\"nb\">bool</span>,</span><span class=\"param\">\t<span class=\"n\">use_custom_allreduce</span><span class=\"p\">:</span> <span class=\"nb\">bool</span>,</span><span class=\"param\">\t<span class=\"n\">use_hpu_communicator</span><span class=\"p\">:</span> <span class=\"nb\">bool</span>,</span><span class=\"param\">\t<span class=\"n\">use_xpu_communicator</span><span class=\"p\">:</span> <span class=\"nb\">bool</span>,</span><span class=\"param\">\t<span class=\"n\">use_npu_communicator</span><span class=\"p\">:</span> <span class=\"nb\">bool</span>,</span><span class=\"param\">\t<span class=\"n\">use_message_queue_broadcaster</span><span class=\"p\">:</span> <span class=\"nb\">bool</span> <span class=\"o\">=</span> <span class=\"kc\">False</span>,</span><span class=\"param\">\t<span class=\"n\">group_name</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"nb\">str</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span></span>)</span>"}, {"fullname": "sglang.srt.distributed.parallel_state.GroupCoordinator.rank", "modulename": "sglang.srt.distributed.parallel_state", "qualname": "GroupCoordinator.rank", "kind": "variable", "doc": "<p></p>\n", "annotation": ": int"}, {"fullname": "sglang.srt.distributed.parallel_state.GroupCoordinator.ranks", "modulename": "sglang.srt.distributed.parallel_state", "qualname": "GroupCoordinator.ranks", "kind": "variable", "doc": "<p></p>\n", "annotation": ": List[int]"}, {"fullname": "sglang.srt.distributed.parallel_state.GroupCoordinator.world_size", "modulename": "sglang.srt.distributed.parallel_state", "qualname": "GroupCoordinator.world_size", "kind": "variable", "doc": "<p></p>\n", "annotation": ": int"}, {"fullname": "sglang.srt.distributed.parallel_state.GroupCoordinator.local_rank", "modulename": "sglang.srt.distributed.parallel_state", "qualname": "GroupCoordinator.local_rank", "kind": "variable", "doc": "<p></p>\n", "annotation": ": int"}, {"fullname": "sglang.srt.distributed.parallel_state.GroupCoordinator.rank_in_group", "modulename": "sglang.srt.distributed.parallel_state", "qualname": "GroupCoordinator.rank_in_group", "kind": "variable", "doc": "<p></p>\n", "annotation": ": int"}, {"fullname": "sglang.srt.distributed.parallel_state.GroupCoordinator.cpu_group", "modulename": "sglang.srt.distributed.parallel_state", "qualname": "GroupCoordinator.cpu_group", "kind": "variable", "doc": "<p></p>\n", "annotation": ": torch.distributed.distributed_c10d.ProcessGroup"}, {"fullname": "sglang.srt.distributed.parallel_state.GroupCoordinator.device_group", "modulename": "sglang.srt.distributed.parallel_state", "qualname": "GroupCoordinator.device_group", "kind": "variable", "doc": "<p></p>\n", "annotation": ": torch.distributed.distributed_c10d.ProcessGroup"}, {"fullname": "sglang.srt.distributed.parallel_state.GroupCoordinator.use_pynccl", "modulename": "sglang.srt.distributed.parallel_state", "qualname": "GroupCoordinator.use_pynccl", "kind": "variable", "doc": "<p></p>\n", "annotation": ": bool"}, {"fullname": "sglang.srt.distributed.parallel_state.GroupCoordinator.use_pymscclpp", "modulename": "sglang.srt.distributed.parallel_state", "qualname": "GroupCoordinator.use_pymscclpp", "kind": "variable", "doc": "<p></p>\n", "annotation": ": bool"}, {"fullname": "sglang.srt.distributed.parallel_state.GroupCoordinator.use_custom_allreduce", "modulename": "sglang.srt.distributed.parallel_state", "qualname": "GroupCoordinator.use_custom_allreduce", "kind": "variable", "doc": "<p></p>\n", "annotation": ": bool"}, {"fullname": "sglang.srt.distributed.parallel_state.GroupCoordinator.use_message_queue_broadcaster", "modulename": "sglang.srt.distributed.parallel_state", "qualname": "GroupCoordinator.use_message_queue_broadcaster", "kind": "variable", "doc": "<p></p>\n", "annotation": ": bool"}, {"fullname": "sglang.srt.distributed.parallel_state.GroupCoordinator.pynccl_comm", "modulename": "sglang.srt.distributed.parallel_state", "qualname": "GroupCoordinator.pynccl_comm", "kind": "variable", "doc": "<p></p>\n", "annotation": ": Optional[Any]"}, {"fullname": "sglang.srt.distributed.parallel_state.GroupCoordinator.ca_comm", "modulename": "sglang.srt.distributed.parallel_state", "qualname": "GroupCoordinator.ca_comm", "kind": "variable", "doc": "<p></p>\n", "annotation": ": Optional[Any]"}, {"fullname": "sglang.srt.distributed.parallel_state.GroupCoordinator.mq_broadcaster", "modulename": "sglang.srt.distributed.parallel_state", "qualname": "GroupCoordinator.mq_broadcaster", "kind": "variable", "doc": "<p></p>\n", "annotation": ": Optional[Any]"}, {"fullname": "sglang.srt.distributed.parallel_state.GroupCoordinator.unique_name", "modulename": "sglang.srt.distributed.parallel_state", "qualname": "GroupCoordinator.unique_name", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "sglang.srt.distributed.parallel_state.GroupCoordinator.local_size", "modulename": "sglang.srt.distributed.parallel_state", "qualname": "GroupCoordinator.local_size", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "sglang.srt.distributed.parallel_state.GroupCoordinator.device_module", "modulename": "sglang.srt.distributed.parallel_state", "qualname": "GroupCoordinator.device_module", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "sglang.srt.distributed.parallel_state.GroupCoordinator.use_hpu_communicator", "modulename": "sglang.srt.distributed.parallel_state", "qualname": "GroupCoordinator.use_hpu_communicator", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "sglang.srt.distributed.parallel_state.GroupCoordinator.use_xpu_communicator", "modulename": "sglang.srt.distributed.parallel_state", "qualname": "GroupCoordinator.use_xpu_communicator", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "sglang.srt.distributed.parallel_state.GroupCoordinator.use_npu_communicator", "modulename": "sglang.srt.distributed.parallel_state", "qualname": "GroupCoordinator.use_npu_communicator", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "sglang.srt.distributed.parallel_state.GroupCoordinator.pymscclpp_comm", "modulename": "sglang.srt.distributed.parallel_state", "qualname": "GroupCoordinator.pymscclpp_comm", "kind": "variable", "doc": "<p></p>\n", "annotation": ": &#x27;Optional[PyMscclppCommunicator]&#x27;"}, {"fullname": "sglang.srt.distributed.parallel_state.GroupCoordinator.qr_comm", "modulename": "sglang.srt.distributed.parallel_state", "qualname": "GroupCoordinator.qr_comm", "kind": "variable", "doc": "<p></p>\n", "annotation": ": &#x27;Optional[QuickAllReduce]&#x27;"}, {"fullname": "sglang.srt.distributed.parallel_state.GroupCoordinator.hpu_communicator", "modulename": "sglang.srt.distributed.parallel_state", "qualname": "GroupCoordinator.hpu_communicator", "kind": "variable", "doc": "<p></p>\n", "annotation": ": &#x27;Optional[HpuCommunicator]&#x27;"}, {"fullname": "sglang.srt.distributed.parallel_state.GroupCoordinator.xpu_communicator", "modulename": "sglang.srt.distributed.parallel_state", "qualname": "GroupCoordinator.xpu_communicator", "kind": "variable", "doc": "<p></p>\n", "annotation": ": &#x27;Optional[XpuCommunicator]&#x27;"}, {"fullname": "sglang.srt.distributed.parallel_state.GroupCoordinator.npu_communicator", "modulename": "sglang.srt.distributed.parallel_state", "qualname": "GroupCoordinator.npu_communicator", "kind": "variable", "doc": "<p></p>\n", "annotation": ": &#x27;Optional[NpuCommunicator]&#x27;"}, {"fullname": "sglang.srt.distributed.parallel_state.GroupCoordinator.first_rank", "modulename": "sglang.srt.distributed.parallel_state", "qualname": "GroupCoordinator.first_rank", "kind": "variable", "doc": "<p>Return the global rank of the first process in the group</p>\n"}, {"fullname": "sglang.srt.distributed.parallel_state.GroupCoordinator.last_rank", "modulename": "sglang.srt.distributed.parallel_state", "qualname": "GroupCoordinator.last_rank", "kind": "variable", "doc": "<p>Return the global rank of the last process in the group</p>\n"}, {"fullname": "sglang.srt.distributed.parallel_state.GroupCoordinator.is_first_rank", "modulename": "sglang.srt.distributed.parallel_state", "qualname": "GroupCoordinator.is_first_rank", "kind": "variable", "doc": "<p>Return whether the caller is the first process in the group</p>\n"}, {"fullname": "sglang.srt.distributed.parallel_state.GroupCoordinator.is_last_rank", "modulename": "sglang.srt.distributed.parallel_state", "qualname": "GroupCoordinator.is_last_rank", "kind": "variable", "doc": "<p>Return whether the caller is the last process in the group</p>\n"}, {"fullname": "sglang.srt.distributed.parallel_state.GroupCoordinator.next_rank", "modulename": "sglang.srt.distributed.parallel_state", "qualname": "GroupCoordinator.next_rank", "kind": "variable", "doc": "<p>Return the global rank of the process that follows the caller</p>\n"}, {"fullname": "sglang.srt.distributed.parallel_state.GroupCoordinator.prev_rank", "modulename": "sglang.srt.distributed.parallel_state", "qualname": "GroupCoordinator.prev_rank", "kind": "variable", "doc": "<p>Return the global rank of the process that precedes the caller</p>\n"}, {"fullname": "sglang.srt.distributed.parallel_state.GroupCoordinator.graph_capture", "modulename": "sglang.srt.distributed.parallel_state", "qualname": "GroupCoordinator.graph_capture", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"bp\">self</span>,</span><span class=\"param\">\t<span class=\"n\">graph_capture_context</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"n\">sglang</span><span class=\"o\">.</span><span class=\"n\">srt</span><span class=\"o\">.</span><span class=\"n\">distributed</span><span class=\"o\">.</span><span class=\"n\">parallel_state</span><span class=\"o\">.</span><span class=\"n\">GraphCaptureContext</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.distributed.parallel_state.GroupCoordinator.all_reduce", "modulename": "sglang.srt.distributed.parallel_state", "qualname": "GroupCoordinator.all_reduce", "kind": "function", "doc": "<p>User-facing all-reduce function before we actually call the\nall-reduce operation.</p>\n\n<p>We need this because Dynamo does not support passing an arbitrary\nobject (<code>self</code> in this case) to a custom op. We need to pass the\n group name as a string, and then look up the group coordinator from\n the group name, dispatch the all-reduce operation to the group\n coordinator.</p>\n\n<p>In addition, PyTorch custom ops do not support mutation or returning\na new tensor in the same op. So we need to figure out if the op is\nin-place or out-of-place ahead of time.</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">input_</span><span class=\"p\">:</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">Tensor</span></span><span class=\"return-annotation\">) -> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">Tensor</span>:</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.distributed.parallel_state.GroupCoordinator.reduce_scatter_tensor", "modulename": "sglang.srt.distributed.parallel_state", "qualname": "GroupCoordinator.reduce_scatter_tensor", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">output</span><span class=\"p\">:</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">Tensor</span>, </span><span class=\"param\"><span class=\"nb\">input</span><span class=\"p\">:</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">Tensor</span></span><span class=\"return-annotation\">) -> <span class=\"kc\">None</span>:</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.distributed.parallel_state.GroupCoordinator.reduce_scatter", "modulename": "sglang.srt.distributed.parallel_state", "qualname": "GroupCoordinator.reduce_scatter", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">output</span><span class=\"p\">:</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">Tensor</span>, </span><span class=\"param\"><span class=\"n\">input_list</span><span class=\"p\">:</span> <span class=\"n\">List</span><span class=\"p\">[</span><span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">Tensor</span><span class=\"p\">]</span></span><span class=\"return-annotation\">) -> <span class=\"kc\">None</span>:</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.distributed.parallel_state.GroupCoordinator.reduce_scatterv", "modulename": "sglang.srt.distributed.parallel_state", "qualname": "GroupCoordinator.reduce_scatterv", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"bp\">self</span>,</span><span class=\"param\">\t<span class=\"n\">input_</span><span class=\"p\">:</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">Tensor</span>,</span><span class=\"param\">\t<span class=\"n\">output</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">Tensor</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">sizes</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"n\">List</span><span class=\"p\">[</span><span class=\"nb\">int</span><span class=\"p\">]]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span></span><span class=\"return-annotation\">) -> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">Tensor</span>:</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.distributed.parallel_state.GroupCoordinator.all_gather_into_tensor", "modulename": "sglang.srt.distributed.parallel_state", "qualname": "GroupCoordinator.all_gather_into_tensor", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">output</span><span class=\"p\">:</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">Tensor</span>, </span><span class=\"param\"><span class=\"nb\">input</span><span class=\"p\">:</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">Tensor</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.distributed.parallel_state.GroupCoordinator.all_gather", "modulename": "sglang.srt.distributed.parallel_state", "qualname": "GroupCoordinator.all_gather", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"bp\">self</span>,</span><span class=\"param\">\t<span class=\"n\">input_</span><span class=\"p\">:</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">Tensor</span>,</span><span class=\"param\">\t<span class=\"n\">dim</span><span class=\"p\">:</span> <span class=\"nb\">int</span> <span class=\"o\">=</span> <span class=\"o\">-</span><span class=\"mi\">1</span>,</span><span class=\"param\">\t<span class=\"n\">output_tensor_list</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"n\">List</span><span class=\"p\">[</span><span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">Tensor</span><span class=\"p\">]]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span></span><span class=\"return-annotation\">) -> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">Tensor</span>:</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.distributed.parallel_state.GroupCoordinator.all_gatherv", "modulename": "sglang.srt.distributed.parallel_state", "qualname": "GroupCoordinator.all_gatherv", "kind": "function", "doc": "<p>Supports varying sizes per rank and input tensor list.\n<code>sizes</code>: a list of len(world_size) with the number of items per rank to gather.</p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"bp\">self</span>,</span><span class=\"param\">\t<span class=\"n\">input_</span><span class=\"p\">:</span> <span class=\"n\">Union</span><span class=\"p\">[</span><span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">Tensor</span><span class=\"p\">,</span> <span class=\"n\">List</span><span class=\"p\">[</span><span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">Tensor</span><span class=\"p\">]]</span>,</span><span class=\"param\">\t<span class=\"n\">sizes</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"n\">List</span><span class=\"p\">[</span><span class=\"nb\">int</span><span class=\"p\">]]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span></span><span class=\"return-annotation\">) -> <span class=\"n\">Union</span><span class=\"p\">[</span><span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">Tensor</span><span class=\"p\">,</span> <span class=\"n\">List</span><span class=\"p\">[</span><span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">Tensor</span><span class=\"p\">]]</span>:</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.distributed.parallel_state.GroupCoordinator.gather", "modulename": "sglang.srt.distributed.parallel_state", "qualname": "GroupCoordinator.gather", "kind": "function", "doc": "<p>NOTE: We assume that the input tensor is on the same device across\nall the ranks.\nNOTE: <code>dst</code> is the local rank of the destination rank.</p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"bp\">self</span>,</span><span class=\"param\">\t<span class=\"n\">input_</span><span class=\"p\">:</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">Tensor</span>,</span><span class=\"param\">\t<span class=\"n\">dst</span><span class=\"p\">:</span> <span class=\"nb\">int</span> <span class=\"o\">=</span> <span class=\"mi\">0</span>,</span><span class=\"param\">\t<span class=\"n\">dim</span><span class=\"p\">:</span> <span class=\"nb\">int</span> <span class=\"o\">=</span> <span class=\"o\">-</span><span class=\"mi\">1</span></span><span class=\"return-annotation\">) -> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">Tensor</span><span class=\"p\">]</span>:</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.distributed.parallel_state.GroupCoordinator.broadcast", "modulename": "sglang.srt.distributed.parallel_state", "qualname": "GroupCoordinator.broadcast", "kind": "function", "doc": "<p>Broadcast the input tensor.\nNOTE: <code>src</code> is the local rank of the source rank.</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">input_</span><span class=\"p\">:</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">Tensor</span>, </span><span class=\"param\"><span class=\"n\">src</span><span class=\"p\">:</span> <span class=\"nb\">int</span> <span class=\"o\">=</span> <span class=\"mi\">0</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.distributed.parallel_state.GroupCoordinator.broadcast_object", "modulename": "sglang.srt.distributed.parallel_state", "qualname": "GroupCoordinator.broadcast_object", "kind": "function", "doc": "<p>Broadcast the input object.\nNOTE: <code>src</code> is the local rank of the source rank.</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">obj</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"n\">Any</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>, </span><span class=\"param\"><span class=\"n\">src</span><span class=\"p\">:</span> <span class=\"nb\">int</span> <span class=\"o\">=</span> <span class=\"mi\">0</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.distributed.parallel_state.GroupCoordinator.broadcast_object_list", "modulename": "sglang.srt.distributed.parallel_state", "qualname": "GroupCoordinator.broadcast_object_list", "kind": "function", "doc": "<p>Broadcast the input object list.\nNOTE: <code>src</code> is the local rank of the source rank.</p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"bp\">self</span>,</span><span class=\"param\">\t<span class=\"n\">obj_list</span><span class=\"p\">:</span> <span class=\"n\">List</span><span class=\"p\">[</span><span class=\"n\">Any</span><span class=\"p\">]</span>,</span><span class=\"param\">\t<span class=\"n\">src</span><span class=\"p\">:</span> <span class=\"nb\">int</span> <span class=\"o\">=</span> <span class=\"mi\">0</span>,</span><span class=\"param\">\t<span class=\"n\">group</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">distributed</span><span class=\"o\">.</span><span class=\"n\">distributed_c10d</span><span class=\"o\">.</span><span class=\"n\">ProcessGroup</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.distributed.parallel_state.GroupCoordinator.send_object", "modulename": "sglang.srt.distributed.parallel_state", "qualname": "GroupCoordinator.send_object", "kind": "function", "doc": "<p>Send the input object list to the destination rank.</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">obj</span><span class=\"p\">:</span> <span class=\"n\">Any</span>, </span><span class=\"param\"><span class=\"n\">dst</span><span class=\"p\">:</span> <span class=\"nb\">int</span></span><span class=\"return-annotation\">) -> <span class=\"kc\">None</span>:</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.distributed.parallel_state.GroupCoordinator.recv_object", "modulename": "sglang.srt.distributed.parallel_state", "qualname": "GroupCoordinator.recv_object", "kind": "function", "doc": "<p>Receive the input object list from the source rank.</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">src</span><span class=\"p\">:</span> <span class=\"nb\">int</span></span><span class=\"return-annotation\">) -> <span class=\"n\">Any</span>:</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.distributed.parallel_state.GroupCoordinator.broadcast_tensor_dict", "modulename": "sglang.srt.distributed.parallel_state", "qualname": "GroupCoordinator.broadcast_tensor_dict", "kind": "function", "doc": "<p>Broadcast the input tensor dictionary.\nNOTE: <code>src</code> is the local rank of the source rank.</p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"bp\">self</span>,</span><span class=\"param\">\t<span class=\"n\">tensor_dict</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"n\">Dict</span><span class=\"p\">[</span><span class=\"nb\">str</span><span class=\"p\">,</span> <span class=\"n\">Union</span><span class=\"p\">[</span><span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">Tensor</span><span class=\"p\">,</span> <span class=\"n\">Any</span><span class=\"p\">]]]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">src</span><span class=\"p\">:</span> <span class=\"nb\">int</span> <span class=\"o\">=</span> <span class=\"mi\">0</span>,</span><span class=\"param\">\t<span class=\"n\">group</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">distributed</span><span class=\"o\">.</span><span class=\"n\">distributed_c10d</span><span class=\"o\">.</span><span class=\"n\">ProcessGroup</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">metadata_group</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">distributed</span><span class=\"o\">.</span><span class=\"n\">distributed_c10d</span><span class=\"o\">.</span><span class=\"n\">ProcessGroup</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span></span><span class=\"return-annotation\">) -> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"n\">Dict</span><span class=\"p\">[</span><span class=\"nb\">str</span><span class=\"p\">,</span> <span class=\"n\">Union</span><span class=\"p\">[</span><span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">Tensor</span><span class=\"p\">,</span> <span class=\"n\">Any</span><span class=\"p\">]]]</span>:</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.distributed.parallel_state.GroupCoordinator.send_tensor_dict", "modulename": "sglang.srt.distributed.parallel_state", "qualname": "GroupCoordinator.send_tensor_dict", "kind": "function", "doc": "<p>Send the input tensor dictionary.\nNOTE: <code>dst</code> is the local rank of the source rank.</p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"bp\">self</span>,</span><span class=\"param\">\t<span class=\"n\">tensor_dict</span><span class=\"p\">:</span> <span class=\"n\">Dict</span><span class=\"p\">[</span><span class=\"nb\">str</span><span class=\"p\">,</span> <span class=\"n\">Union</span><span class=\"p\">[</span><span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">Tensor</span><span class=\"p\">,</span> <span class=\"n\">Any</span><span class=\"p\">]]</span>,</span><span class=\"param\">\t<span class=\"n\">dst</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"nb\">int</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">all_gather_group</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"n\">sglang</span><span class=\"o\">.</span><span class=\"n\">srt</span><span class=\"o\">.</span><span class=\"n\">distributed</span><span class=\"o\">.</span><span class=\"n\">parallel_state</span><span class=\"o\">.</span><span class=\"n\">GroupCoordinator</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span></span><span class=\"return-annotation\">) -> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"n\">Dict</span><span class=\"p\">[</span><span class=\"nb\">str</span><span class=\"p\">,</span> <span class=\"n\">Union</span><span class=\"p\">[</span><span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">Tensor</span><span class=\"p\">,</span> <span class=\"n\">Any</span><span class=\"p\">]]]</span>:</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.distributed.parallel_state.GroupCoordinator.recv_tensor_dict", "modulename": "sglang.srt.distributed.parallel_state", "qualname": "GroupCoordinator.recv_tensor_dict", "kind": "function", "doc": "<p>Recv the input tensor dictionary.\nNOTE: <code>src</code> is the local rank of the source rank.</p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"bp\">self</span>,</span><span class=\"param\">\t<span class=\"n\">src</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"nb\">int</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">all_gather_group</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"n\">sglang</span><span class=\"o\">.</span><span class=\"n\">srt</span><span class=\"o\">.</span><span class=\"n\">distributed</span><span class=\"o\">.</span><span class=\"n\">parallel_state</span><span class=\"o\">.</span><span class=\"n\">GroupCoordinator</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span></span><span class=\"return-annotation\">) -> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"n\">Dict</span><span class=\"p\">[</span><span class=\"nb\">str</span><span class=\"p\">,</span> <span class=\"n\">Union</span><span class=\"p\">[</span><span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">Tensor</span><span class=\"p\">,</span> <span class=\"n\">Any</span><span class=\"p\">]]]</span>:</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.distributed.parallel_state.GroupCoordinator.barrier", "modulename": "sglang.srt.distributed.parallel_state", "qualname": "GroupCoordinator.barrier", "kind": "function", "doc": "<p>Barrier synchronization among the group.\nNOTE: don't use <code>device_group</code> here! <code>barrier</code> in NCCL is\nterrible because it is internally a broadcast operation with\nsecretly created GPU tensors. It is easy to mess up the current\ndevice. Use the CPU group instead.</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.distributed.parallel_state.GroupCoordinator.send", "modulename": "sglang.srt.distributed.parallel_state", "qualname": "GroupCoordinator.send", "kind": "function", "doc": "<p>Sends a tensor to the destination rank in a non-blocking way</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">tensor</span><span class=\"p\">:</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">Tensor</span>, </span><span class=\"param\"><span class=\"n\">dst</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"nb\">int</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span></span><span class=\"return-annotation\">) -> <span class=\"kc\">None</span>:</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.distributed.parallel_state.GroupCoordinator.recv", "modulename": "sglang.srt.distributed.parallel_state", "qualname": "GroupCoordinator.recv", "kind": "function", "doc": "<p>Receives a tensor from the source rank.</p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"bp\">self</span>,</span><span class=\"param\">\t<span class=\"n\">size</span><span class=\"p\">:</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">Size</span>,</span><span class=\"param\">\t<span class=\"n\">dtype</span><span class=\"p\">:</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">dtype</span>,</span><span class=\"param\">\t<span class=\"n\">src</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"nb\">int</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span></span><span class=\"return-annotation\">) -> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">Tensor</span>:</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.distributed.parallel_state.GroupCoordinator.destroy", "modulename": "sglang.srt.distributed.parallel_state", "qualname": "GroupCoordinator.destroy", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.distributed.parallel_state.get_world_group", "modulename": "sglang.srt.distributed.parallel_state", "qualname": "get_world_group", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"return-annotation\">) -> <span class=\"n\">sglang</span><span class=\"o\">.</span><span class=\"n\">srt</span><span class=\"o\">.</span><span class=\"n\">distributed</span><span class=\"o\">.</span><span class=\"n\">parallel_state</span><span class=\"o\">.</span><span class=\"n\">GroupCoordinator</span>:</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.distributed.parallel_state.init_world_group", "modulename": "sglang.srt.distributed.parallel_state", "qualname": "init_world_group", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">ranks</span><span class=\"p\">:</span> <span class=\"n\">List</span><span class=\"p\">[</span><span class=\"nb\">int</span><span class=\"p\">]</span>,</span><span class=\"param\">\t<span class=\"n\">local_rank</span><span class=\"p\">:</span> <span class=\"nb\">int</span>,</span><span class=\"param\">\t<span class=\"n\">backend</span><span class=\"p\">:</span> <span class=\"nb\">str</span></span><span class=\"return-annotation\">) -> <span class=\"n\">sglang</span><span class=\"o\">.</span><span class=\"n\">srt</span><span class=\"o\">.</span><span class=\"n\">distributed</span><span class=\"o\">.</span><span class=\"n\">parallel_state</span><span class=\"o\">.</span><span class=\"n\">GroupCoordinator</span>:</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.distributed.parallel_state.init_model_parallel_group", "modulename": "sglang.srt.distributed.parallel_state", "qualname": "init_model_parallel_group", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">group_ranks</span><span class=\"p\">:</span> <span class=\"n\">List</span><span class=\"p\">[</span><span class=\"n\">List</span><span class=\"p\">[</span><span class=\"nb\">int</span><span class=\"p\">]]</span>,</span><span class=\"param\">\t<span class=\"n\">local_rank</span><span class=\"p\">:</span> <span class=\"nb\">int</span>,</span><span class=\"param\">\t<span class=\"n\">backend</span><span class=\"p\">:</span> <span class=\"nb\">str</span>,</span><span class=\"param\">\t<span class=\"n\">use_custom_allreduce</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"nb\">bool</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">use_message_queue_broadcaster</span><span class=\"p\">:</span> <span class=\"nb\">bool</span> <span class=\"o\">=</span> <span class=\"kc\">False</span>,</span><span class=\"param\">\t<span class=\"n\">group_name</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"nb\">str</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">use_mscclpp_allreduce</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"nb\">bool</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span></span><span class=\"return-annotation\">) -> <span class=\"n\">sglang</span><span class=\"o\">.</span><span class=\"n\">srt</span><span class=\"o\">.</span><span class=\"n\">distributed</span><span class=\"o\">.</span><span class=\"n\">parallel_state</span><span class=\"o\">.</span><span class=\"n\">GroupCoordinator</span>:</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.distributed.parallel_state.set_pdmux_status", "modulename": "sglang.srt.distributed.parallel_state", "qualname": "set_pdmux_status", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">enable_prefill_multiplexing</span><span class=\"p\">:</span> <span class=\"nb\">bool</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.distributed.parallel_state.get_tp_group", "modulename": "sglang.srt.distributed.parallel_state", "qualname": "get_tp_group", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"return-annotation\">) -> <span class=\"n\">sglang</span><span class=\"o\">.</span><span class=\"n\">srt</span><span class=\"o\">.</span><span class=\"n\">distributed</span><span class=\"o\">.</span><span class=\"n\">parallel_state</span><span class=\"o\">.</span><span class=\"n\">GroupCoordinator</span>:</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.distributed.parallel_state.get_moe_ep_group", "modulename": "sglang.srt.distributed.parallel_state", "qualname": "get_moe_ep_group", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"return-annotation\">) -> <span class=\"n\">sglang</span><span class=\"o\">.</span><span class=\"n\">srt</span><span class=\"o\">.</span><span class=\"n\">distributed</span><span class=\"o\">.</span><span class=\"n\">parallel_state</span><span class=\"o\">.</span><span class=\"n\">GroupCoordinator</span>:</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.distributed.parallel_state.get_moe_tp_group", "modulename": "sglang.srt.distributed.parallel_state", "qualname": "get_moe_tp_group", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"return-annotation\">) -> <span class=\"n\">sglang</span><span class=\"o\">.</span><span class=\"n\">srt</span><span class=\"o\">.</span><span class=\"n\">distributed</span><span class=\"o\">.</span><span class=\"n\">parallel_state</span><span class=\"o\">.</span><span class=\"n\">GroupCoordinator</span>:</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.distributed.parallel_state.get_tensor_model_parallel_group", "modulename": "sglang.srt.distributed.parallel_state", "qualname": "get_tensor_model_parallel_group", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"return-annotation\">) -> <span class=\"n\">sglang</span><span class=\"o\">.</span><span class=\"n\">srt</span><span class=\"o\">.</span><span class=\"n\">distributed</span><span class=\"o\">.</span><span class=\"n\">parallel_state</span><span class=\"o\">.</span><span class=\"n\">GroupCoordinator</span>:</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.distributed.parallel_state.get_pp_group", "modulename": "sglang.srt.distributed.parallel_state", "qualname": "get_pp_group", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"return-annotation\">) -> <span class=\"n\">sglang</span><span class=\"o\">.</span><span class=\"n\">srt</span><span class=\"o\">.</span><span class=\"n\">distributed</span><span class=\"o\">.</span><span class=\"n\">parallel_state</span><span class=\"o\">.</span><span class=\"n\">GroupCoordinator</span>:</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.distributed.parallel_state.get_pipeline_model_parallel_group", "modulename": "sglang.srt.distributed.parallel_state", "qualname": "get_pipeline_model_parallel_group", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"return-annotation\">) -> <span class=\"n\">sglang</span><span class=\"o\">.</span><span class=\"n\">srt</span><span class=\"o\">.</span><span class=\"n\">distributed</span><span class=\"o\">.</span><span class=\"n\">parallel_state</span><span class=\"o\">.</span><span class=\"n\">GroupCoordinator</span>:</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.distributed.parallel_state.graph_capture", "modulename": "sglang.srt.distributed.parallel_state", "qualname": "graph_capture", "kind": "function", "doc": "<p><code>graph_capture</code> is a context manager which should surround the code that\nis capturing the CUDA graph. Its main purpose is to ensure that the\nsome operations will be run after the graph is captured, before the graph\nis replayed. It returns a <code>GraphCaptureContext</code> object which contains the\nnecessary data for the graph capture. Currently, it only contains the\nstream that the graph capture is running on. This stream is set to the\ncurrent CUDA stream when the context manager is entered and reset to the\ndefault stream when the context manager is exited. This is to ensure that\nthe graph capture is running on a separate stream from the default stream,\nin order to explicitly distinguish the kernels to capture\nfrom other kernels possibly launched on background in the default stream.</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.distributed.parallel_state.logger", "modulename": "sglang.srt.distributed.parallel_state", "qualname": "logger", "kind": "variable", "doc": "<p></p>\n", "default_value": "&lt;Logger sglang.srt.distributed.parallel_state (WARNING)&gt;"}, {"fullname": "sglang.srt.distributed.parallel_state.set_custom_all_reduce", "modulename": "sglang.srt.distributed.parallel_state", "qualname": "set_custom_all_reduce", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">enable</span><span class=\"p\">:</span> <span class=\"nb\">bool</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.distributed.parallel_state.set_mscclpp_all_reduce", "modulename": "sglang.srt.distributed.parallel_state", "qualname": "set_mscclpp_all_reduce", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">enable</span><span class=\"p\">:</span> <span class=\"nb\">bool</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.distributed.parallel_state.init_distributed_environment", "modulename": "sglang.srt.distributed.parallel_state", "qualname": "init_distributed_environment", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">world_size</span><span class=\"p\">:</span> <span class=\"nb\">int</span> <span class=\"o\">=</span> <span class=\"o\">-</span><span class=\"mi\">1</span>,</span><span class=\"param\">\t<span class=\"n\">rank</span><span class=\"p\">:</span> <span class=\"nb\">int</span> <span class=\"o\">=</span> <span class=\"o\">-</span><span class=\"mi\">1</span>,</span><span class=\"param\">\t<span class=\"n\">distributed_init_method</span><span class=\"p\">:</span> <span class=\"nb\">str</span> <span class=\"o\">=</span> <span class=\"s1\">&#39;env://&#39;</span>,</span><span class=\"param\">\t<span class=\"n\">local_rank</span><span class=\"p\">:</span> <span class=\"nb\">int</span> <span class=\"o\">=</span> <span class=\"o\">-</span><span class=\"mi\">1</span>,</span><span class=\"param\">\t<span class=\"n\">backend</span><span class=\"p\">:</span> <span class=\"nb\">str</span> <span class=\"o\">=</span> <span class=\"s1\">&#39;nccl&#39;</span>,</span><span class=\"param\">\t<span class=\"n\">timeout</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"nb\">int</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.distributed.parallel_state.initialize_model_parallel", "modulename": "sglang.srt.distributed.parallel_state", "qualname": "initialize_model_parallel", "kind": "function", "doc": "<p>Initialize model parallel groups.</p>\n\n<p>Arguments:\n    tensor_model_parallel_size: number of GPUs used for tensor model\n        parallelism.\n    pipeline_model_parallel_size: number of GPUs used for pipeline model\n        parallelism.</p>\n\n<p>Let's say we have a total of 8 GPUs denoted by g0 ... g7 and we\nuse 2 GPUs to parallelize the model tensor, and 4 GPUs to parallelize\nthe model pipeline. The present function will\ncreate 4 tensor model-parallel groups and 2 pipeline model-parallel groups:\n    4 tensor model-parallel groups:\n        [g0, g1], [g2, g3], [g4, g5], [g6, g7]\n    2 pipeline model-parallel groups:\n        [g0, g2, g4, g6], [g1, g3, g5, g7]\nNote that for efficiency, the caller should make sure adjacent ranks\nare on the same DGX box. For example if we are using 2 DGX-1 boxes\nwith a total of 16 GPUs, rank 0 to 7 belong to the first box and\nranks 8 to 15 belong to the second box.</p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">tensor_model_parallel_size</span><span class=\"p\">:</span> <span class=\"nb\">int</span> <span class=\"o\">=</span> <span class=\"mi\">1</span>,</span><span class=\"param\">\t<span class=\"n\">expert_model_parallel_size</span><span class=\"p\">:</span> <span class=\"nb\">int</span> <span class=\"o\">=</span> <span class=\"mi\">1</span>,</span><span class=\"param\">\t<span class=\"n\">pipeline_model_parallel_size</span><span class=\"p\">:</span> <span class=\"nb\">int</span> <span class=\"o\">=</span> <span class=\"mi\">1</span>,</span><span class=\"param\">\t<span class=\"n\">backend</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"nb\">str</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">duplicate_tp_group</span><span class=\"p\">:</span> <span class=\"nb\">bool</span> <span class=\"o\">=</span> <span class=\"kc\">False</span></span><span class=\"return-annotation\">) -> <span class=\"kc\">None</span>:</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.distributed.parallel_state.ensure_model_parallel_initialized", "modulename": "sglang.srt.distributed.parallel_state", "qualname": "ensure_model_parallel_initialized", "kind": "function", "doc": "<p>Helper to initialize model parallel groups if they are not initialized,\nor ensure tensor-parallel and pipeline-parallel sizes are equal to expected\nvalues if the model parallel groups are initialized.</p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">tensor_model_parallel_size</span><span class=\"p\">:</span> <span class=\"nb\">int</span>,</span><span class=\"param\">\t<span class=\"n\">expert_model_parallel_size</span><span class=\"p\">:</span> <span class=\"nb\">int</span>,</span><span class=\"param\">\t<span class=\"n\">pipeline_model_parallel_size</span><span class=\"p\">:</span> <span class=\"nb\">int</span>,</span><span class=\"param\">\t<span class=\"n\">backend</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"nb\">str</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span></span><span class=\"return-annotation\">) -> <span class=\"kc\">None</span>:</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.distributed.parallel_state.model_parallel_is_initialized", "modulename": "sglang.srt.distributed.parallel_state", "qualname": "model_parallel_is_initialized", "kind": "function", "doc": "<p>Check if tensor and pipeline parallel groups are initialized.</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.distributed.parallel_state.patch_tensor_parallel_group", "modulename": "sglang.srt.distributed.parallel_state", "qualname": "patch_tensor_parallel_group", "kind": "function", "doc": "<p>Patch the tp group temporarily until this function ends.</p>\n\n<p>This method is for draft workers of speculative decoding to run draft model\nwith different tp degree from that of target model workers.</p>\n\n<p>Args:\n    tp_group (GroupCoordinator): the tp group coordinator</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">tp_group</span><span class=\"p\">:</span> <span class=\"n\">sglang</span><span class=\"o\">.</span><span class=\"n\">srt</span><span class=\"o\">.</span><span class=\"n\">distributed</span><span class=\"o\">.</span><span class=\"n\">parallel_state</span><span class=\"o\">.</span><span class=\"n\">GroupCoordinator</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.distributed.parallel_state.get_tensor_model_parallel_world_size", "modulename": "sglang.srt.distributed.parallel_state", "qualname": "get_tensor_model_parallel_world_size", "kind": "function", "doc": "<p>Return world size for the tensor model parallel group.</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.distributed.parallel_state.get_tensor_model_parallel_rank", "modulename": "sglang.srt.distributed.parallel_state", "qualname": "get_tensor_model_parallel_rank", "kind": "function", "doc": "<p>Return my rank for the tensor model parallel group.</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.distributed.parallel_state.get_moe_expert_parallel_world_size", "modulename": "sglang.srt.distributed.parallel_state", "qualname": "get_moe_expert_parallel_world_size", "kind": "function", "doc": "<p>Return world size for the moe expert parallel group.</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.distributed.parallel_state.get_moe_expert_parallel_rank", "modulename": "sglang.srt.distributed.parallel_state", "qualname": "get_moe_expert_parallel_rank", "kind": "function", "doc": "<p>Return my rank for the moe expert parallel group.</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.distributed.parallel_state.get_moe_tensor_parallel_world_size", "modulename": "sglang.srt.distributed.parallel_state", "qualname": "get_moe_tensor_parallel_world_size", "kind": "function", "doc": "<p>Return world size for the moe tensor parallel group.</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.distributed.parallel_state.get_moe_tensor_parallel_rank", "modulename": "sglang.srt.distributed.parallel_state", "qualname": "get_moe_tensor_parallel_rank", "kind": "function", "doc": "<p>Return my rank for the moe tensor parallel group.</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.distributed.parallel_state.destroy_model_parallel", "modulename": "sglang.srt.distributed.parallel_state", "qualname": "destroy_model_parallel", "kind": "function", "doc": "<p>Set the groups to none and destroy them.</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.distributed.parallel_state.destroy_distributed_environment", "modulename": "sglang.srt.distributed.parallel_state", "qualname": "destroy_distributed_environment", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.distributed.parallel_state.cleanup_dist_env_and_memory", "modulename": "sglang.srt.distributed.parallel_state", "qualname": "cleanup_dist_env_and_memory", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">shutdown_ray</span><span class=\"p\">:</span> <span class=\"nb\">bool</span> <span class=\"o\">=</span> <span class=\"kc\">False</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.distributed.parallel_state.in_the_same_node_as", "modulename": "sglang.srt.distributed.parallel_state", "qualname": "in_the_same_node_as", "kind": "function", "doc": "<p>This is a collective operation that returns if each rank is in the same node\nas the source rank. It tests if processes are attached to the same\nmemory system (shared access to shared memory).</p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">pg</span><span class=\"p\">:</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">distributed</span><span class=\"o\">.</span><span class=\"n\">distributed_c10d</span><span class=\"o\">.</span><span class=\"n\">ProcessGroup</span>,</span><span class=\"param\">\t<span class=\"n\">source_rank</span><span class=\"p\">:</span> <span class=\"nb\">int</span> <span class=\"o\">=</span> <span class=\"mi\">0</span></span><span class=\"return-annotation\">) -> <span class=\"n\">List</span><span class=\"p\">[</span><span class=\"nb\">bool</span><span class=\"p\">]</span>:</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.distributed.parallel_state.vllm_get_pp_group", "modulename": "sglang.srt.distributed.parallel_state", "qualname": "vllm_get_pp_group", "kind": "variable", "doc": "<p></p>\n", "default_value": "None"}, {"fullname": "sglang.srt.distributed.parallel_state.vllm_get_tp_group", "modulename": "sglang.srt.distributed.parallel_state", "qualname": "vllm_get_tp_group", "kind": "variable", "doc": "<p></p>\n", "default_value": "None"}, {"fullname": "sglang.srt.distributed.parallel_state.vllm_get_world_group", "modulename": "sglang.srt.distributed.parallel_state", "qualname": "vllm_get_world_group", "kind": "variable", "doc": "<p></p>\n", "default_value": "None"}, {"fullname": "sglang.srt.distributed.parallel_state.monkey_patch_vllm_parallel_state", "modulename": "sglang.srt.distributed.parallel_state", "qualname": "monkey_patch_vllm_parallel_state", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">reverse</span><span class=\"p\">:</span> <span class=\"nb\">bool</span> <span class=\"o\">=</span> <span class=\"kc\">False</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.distributed.parallel_state.inplace_all_reduce", "modulename": "sglang.srt.distributed.parallel_state", "qualname": "inplace_all_reduce", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">tensor</span><span class=\"p\">:</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">Tensor</span>, </span><span class=\"param\"><span class=\"n\">group_name</span><span class=\"p\">:</span> <span class=\"nb\">str</span></span><span class=\"return-annotation\">) -> <span class=\"kc\">None</span>:</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.distributed.parallel_state.inplace_all_reduce_fake", "modulename": "sglang.srt.distributed.parallel_state", "qualname": "inplace_all_reduce_fake", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">tensor</span><span class=\"p\">:</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">Tensor</span>, </span><span class=\"param\"><span class=\"n\">group_name</span><span class=\"p\">:</span> <span class=\"nb\">str</span></span><span class=\"return-annotation\">) -> <span class=\"kc\">None</span>:</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.distributed.parallel_state.outplace_all_reduce", "modulename": "sglang.srt.distributed.parallel_state", "qualname": "outplace_all_reduce", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">tensor</span><span class=\"p\">:</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">Tensor</span>,</span><span class=\"param\">\t<span class=\"n\">group_name</span><span class=\"p\">:</span> <span class=\"nb\">str</span>,</span><span class=\"param\">\t<span class=\"n\">outplace_all_reduce_method</span><span class=\"p\">:</span> <span class=\"nb\">str</span></span><span class=\"return-annotation\">) -> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">Tensor</span>:</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.distributed.parallel_state.outplace_all_reduce_fake", "modulename": "sglang.srt.distributed.parallel_state", "qualname": "outplace_all_reduce_fake", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">tensor</span><span class=\"p\">:</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">Tensor</span>,</span><span class=\"param\">\t<span class=\"n\">group_name</span><span class=\"p\">:</span> <span class=\"nb\">str</span>,</span><span class=\"param\">\t<span class=\"n\">outplace_all_reduce_method</span><span class=\"p\">:</span> <span class=\"nb\">str</span></span><span class=\"return-annotation\">) -> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">Tensor</span>:</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.distributed.parallel_state.reg_all_gather_into_tensor", "modulename": "sglang.srt.distributed.parallel_state", "qualname": "reg_all_gather_into_tensor", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">output</span><span class=\"p\">:</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">Tensor</span>, </span><span class=\"param\"><span class=\"nb\">input</span><span class=\"p\">:</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">Tensor</span>, </span><span class=\"param\"><span class=\"n\">group_name</span><span class=\"p\">:</span> <span class=\"nb\">str</span></span><span class=\"return-annotation\">) -> <span class=\"kc\">None</span>:</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.distributed.parallel_state.reg_all_gather_into_tensor_fake", "modulename": "sglang.srt.distributed.parallel_state", "qualname": "reg_all_gather_into_tensor_fake", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">output</span><span class=\"p\">:</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">Tensor</span>, </span><span class=\"param\"><span class=\"nb\">input</span><span class=\"p\">:</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">Tensor</span>, </span><span class=\"param\"><span class=\"n\">group_name</span><span class=\"p\">:</span> <span class=\"nb\">str</span></span><span class=\"return-annotation\">) -> <span class=\"kc\">None</span>:</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.distributed.utils", "modulename": "sglang.srt.distributed.utils", "kind": "module", "doc": "<p></p>\n"}, {"fullname": "sglang.srt.distributed.utils.logger", "modulename": "sglang.srt.distributed.utils", "qualname": "logger", "kind": "variable", "doc": "<p></p>\n", "default_value": "&lt;Logger sglang.srt.distributed.utils (WARNING)&gt;"}, {"fullname": "sglang.srt.distributed.utils.ensure_divisibility", "modulename": "sglang.srt.distributed.utils", "qualname": "ensure_divisibility", "kind": "function", "doc": "<p>Ensure that numerator is divisible by the denominator.</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">numerator</span>, </span><span class=\"param\"><span class=\"n\">denominator</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.distributed.utils.divide", "modulename": "sglang.srt.distributed.utils", "qualname": "divide", "kind": "function", "doc": "<p>Ensure that numerator is divisible by the denominator and return\nthe division value.</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">numerator</span>, </span><span class=\"param\"><span class=\"n\">denominator</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.distributed.utils.split_tensor_along_last_dim", "modulename": "sglang.srt.distributed.utils", "qualname": "split_tensor_along_last_dim", "kind": "function", "doc": "<p>Split a tensor along its last dimension.</p>\n\n<p>Arguments:\n    tensor: input tensor.\n    num_partitions: number of partitions to split the tensor\n    contiguous_split_chunks: If True, make each chunk contiguous\n                             in memory.</p>\n\n<p>Returns:\n    A list of Tensors</p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">tensor</span><span class=\"p\">:</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">Tensor</span>,</span><span class=\"param\">\t<span class=\"n\">num_partitions</span><span class=\"p\">:</span> <span class=\"nb\">int</span>,</span><span class=\"param\">\t<span class=\"n\">contiguous_split_chunks</span><span class=\"p\">:</span> <span class=\"nb\">bool</span> <span class=\"o\">=</span> <span class=\"kc\">False</span></span><span class=\"return-annotation\">) -> <span class=\"n\">Sequence</span><span class=\"p\">[</span><span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">Tensor</span><span class=\"p\">]</span>:</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.distributed.utils.get_pp_indices", "modulename": "sglang.srt.distributed.utils", "qualname": "get_pp_indices", "kind": "function", "doc": "<p>Try to evenly distribute layers across partitions.\nIf the number of layers is not divisible by the number of partitions,\nthe last partition will have the remaining layers.</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">num_hidden_layers</span><span class=\"p\">:</span> <span class=\"nb\">int</span>, </span><span class=\"param\"><span class=\"n\">pp_rank</span><span class=\"p\">:</span> <span class=\"nb\">int</span>, </span><span class=\"param\"><span class=\"n\">pp_size</span><span class=\"p\">:</span> <span class=\"nb\">int</span></span><span class=\"return-annotation\">) -> <span class=\"n\">Tuple</span><span class=\"p\">[</span><span class=\"nb\">int</span><span class=\"p\">,</span> <span class=\"nb\">int</span><span class=\"p\">]</span>:</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.distributed.utils.StatelessProcessGroup", "modulename": "sglang.srt.distributed.utils", "qualname": "StatelessProcessGroup", "kind": "class", "doc": "<p>A dataclass to hold a metadata store, and the rank, world_size of the\ngroup. Only use it to communicate metadata between processes.\nFor data-plane communication, create NCCL-related objects.</p>\n"}, {"fullname": "sglang.srt.distributed.utils.StatelessProcessGroup.__init__", "modulename": "sglang.srt.distributed.utils", "qualname": "StatelessProcessGroup.__init__", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">rank</span><span class=\"p\">:</span> <span class=\"nb\">int</span>,</span><span class=\"param\">\t<span class=\"n\">world_size</span><span class=\"p\">:</span> <span class=\"nb\">int</span>,</span><span class=\"param\">\t<span class=\"n\">store</span><span class=\"p\">:</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">distributed</span><span class=\"o\">.</span><span class=\"n\">distributed_c10d</span><span class=\"o\">.</span><span class=\"n\">Store</span>,</span><span class=\"param\">\t<span class=\"n\">data_expiration_seconds</span><span class=\"p\">:</span> <span class=\"nb\">int</span> <span class=\"o\">=</span> <span class=\"mi\">3600</span>,</span><span class=\"param\">\t<span class=\"n\">send_dst_counter</span><span class=\"p\">:</span> <span class=\"n\">Dict</span><span class=\"p\">[</span><span class=\"nb\">int</span><span class=\"p\">,</span> <span class=\"nb\">int</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"o\">&lt;</span><span class=\"n\">factory</span><span class=\"o\">&gt;</span>,</span><span class=\"param\">\t<span class=\"n\">recv_src_counter</span><span class=\"p\">:</span> <span class=\"n\">Dict</span><span class=\"p\">[</span><span class=\"nb\">int</span><span class=\"p\">,</span> <span class=\"nb\">int</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"o\">&lt;</span><span class=\"n\">factory</span><span class=\"o\">&gt;</span>,</span><span class=\"param\">\t<span class=\"n\">broadcast_send_counter</span><span class=\"p\">:</span> <span class=\"nb\">int</span> <span class=\"o\">=</span> <span class=\"mi\">0</span>,</span><span class=\"param\">\t<span class=\"n\">broadcast_recv_src_counter</span><span class=\"p\">:</span> <span class=\"n\">Dict</span><span class=\"p\">[</span><span class=\"nb\">int</span><span class=\"p\">,</span> <span class=\"nb\">int</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"o\">&lt;</span><span class=\"n\">factory</span><span class=\"o\">&gt;</span>,</span><span class=\"param\">\t<span class=\"n\">entries</span><span class=\"p\">:</span> <span class=\"n\">Deque</span><span class=\"p\">[</span><span class=\"n\">Tuple</span><span class=\"p\">[</span><span class=\"nb\">str</span><span class=\"p\">,</span> <span class=\"nb\">float</span><span class=\"p\">]]</span> <span class=\"o\">=</span> <span class=\"o\">&lt;</span><span class=\"n\">factory</span><span class=\"o\">&gt;</span></span>)</span>"}, {"fullname": "sglang.srt.distributed.utils.StatelessProcessGroup.rank", "modulename": "sglang.srt.distributed.utils", "qualname": "StatelessProcessGroup.rank", "kind": "variable", "doc": "<p></p>\n", "annotation": ": int"}, {"fullname": "sglang.srt.distributed.utils.StatelessProcessGroup.world_size", "modulename": "sglang.srt.distributed.utils", "qualname": "StatelessProcessGroup.world_size", "kind": "variable", "doc": "<p></p>\n", "annotation": ": int"}, {"fullname": "sglang.srt.distributed.utils.StatelessProcessGroup.store", "modulename": "sglang.srt.distributed.utils", "qualname": "StatelessProcessGroup.store", "kind": "variable", "doc": "<p></p>\n", "annotation": ": torch.distributed.distributed_c10d.Store"}, {"fullname": "sglang.srt.distributed.utils.StatelessProcessGroup.data_expiration_seconds", "modulename": "sglang.srt.distributed.utils", "qualname": "StatelessProcessGroup.data_expiration_seconds", "kind": "variable", "doc": "<p></p>\n", "annotation": ": int", "default_value": "3600"}, {"fullname": "sglang.srt.distributed.utils.StatelessProcessGroup.send_dst_counter", "modulename": "sglang.srt.distributed.utils", "qualname": "StatelessProcessGroup.send_dst_counter", "kind": "variable", "doc": "<p></p>\n", "annotation": ": Dict[int, int]"}, {"fullname": "sglang.srt.distributed.utils.StatelessProcessGroup.recv_src_counter", "modulename": "sglang.srt.distributed.utils", "qualname": "StatelessProcessGroup.recv_src_counter", "kind": "variable", "doc": "<p></p>\n", "annotation": ": Dict[int, int]"}, {"fullname": "sglang.srt.distributed.utils.StatelessProcessGroup.broadcast_send_counter", "modulename": "sglang.srt.distributed.utils", "qualname": "StatelessProcessGroup.broadcast_send_counter", "kind": "variable", "doc": "<p></p>\n", "annotation": ": int", "default_value": "0"}, {"fullname": "sglang.srt.distributed.utils.StatelessProcessGroup.broadcast_recv_src_counter", "modulename": "sglang.srt.distributed.utils", "qualname": "StatelessProcessGroup.broadcast_recv_src_counter", "kind": "variable", "doc": "<p></p>\n", "annotation": ": Dict[int, int]"}, {"fullname": "sglang.srt.distributed.utils.StatelessProcessGroup.entries", "modulename": "sglang.srt.distributed.utils", "qualname": "StatelessProcessGroup.entries", "kind": "variable", "doc": "<p></p>\n", "annotation": ": Deque[Tuple[str, float]]"}, {"fullname": "sglang.srt.distributed.utils.StatelessProcessGroup.send_obj", "modulename": "sglang.srt.distributed.utils", "qualname": "StatelessProcessGroup.send_obj", "kind": "function", "doc": "<p>Send an object to a destination rank.</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">obj</span><span class=\"p\">:</span> <span class=\"n\">Any</span>, </span><span class=\"param\"><span class=\"n\">dst</span><span class=\"p\">:</span> <span class=\"nb\">int</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.distributed.utils.StatelessProcessGroup.expire_data", "modulename": "sglang.srt.distributed.utils", "qualname": "StatelessProcessGroup.expire_data", "kind": "function", "doc": "<p>Expire data that is older than <code>data_expiration_seconds</code> seconds.</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.distributed.utils.StatelessProcessGroup.recv_obj", "modulename": "sglang.srt.distributed.utils", "qualname": "StatelessProcessGroup.recv_obj", "kind": "function", "doc": "<p>Receive an object from a source rank.</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">src</span><span class=\"p\">:</span> <span class=\"nb\">int</span></span><span class=\"return-annotation\">) -> <span class=\"n\">Any</span>:</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.distributed.utils.StatelessProcessGroup.broadcast_obj", "modulename": "sglang.srt.distributed.utils", "qualname": "StatelessProcessGroup.broadcast_obj", "kind": "function", "doc": "<p>Broadcast an object from a source rank to all other ranks.\nIt does not clean up after all ranks have received the object.\nUse it for limited times, e.g., for initialization.</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">obj</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"n\">Any</span><span class=\"p\">]</span>, </span><span class=\"param\"><span class=\"n\">src</span><span class=\"p\">:</span> <span class=\"nb\">int</span></span><span class=\"return-annotation\">) -> <span class=\"n\">Any</span>:</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.distributed.utils.StatelessProcessGroup.all_gather_obj", "modulename": "sglang.srt.distributed.utils", "qualname": "StatelessProcessGroup.all_gather_obj", "kind": "function", "doc": "<p>All gather an object from all ranks.</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">obj</span><span class=\"p\">:</span> <span class=\"n\">Any</span></span><span class=\"return-annotation\">) -> <span class=\"nb\">list</span><span class=\"p\">[</span><span class=\"n\">typing</span><span class=\"o\">.</span><span class=\"n\">Any</span><span class=\"p\">]</span>:</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.distributed.utils.StatelessProcessGroup.barrier", "modulename": "sglang.srt.distributed.utils", "qualname": "StatelessProcessGroup.barrier", "kind": "function", "doc": "<p>A barrier to synchronize all ranks.</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.distributed.utils.StatelessProcessGroup.create", "modulename": "sglang.srt.distributed.utils", "qualname": "StatelessProcessGroup.create", "kind": "function", "doc": "<p>A replacement for <code>torch.distributed.init_process_group</code> that does not\npollute the global state.</p>\n\n<p>If we have process A and process B called <code>torch.distributed.init_process_group</code>\nto form a group, and then we want to form another group with process A, B, C,\nD, it is not possible in PyTorch, because process A and process B have already\nformed a group, and process C and process D cannot join that group. This\nfunction is a workaround for this issue.</p>\n\n<p><code>torch.distributed.init_process_group</code> is a global call, while this function\nis a stateless call. It will return a <code>StatelessProcessGroup</code> object that can be\nused for exchanging metadata. With this function, process A and process B\ncan call <code>StatelessProcessGroup.create</code> to form a group, and then process A, B,\nC, and D can call <code>StatelessProcessGroup.create</code> to form another group.</p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">host</span><span class=\"p\">:</span> <span class=\"nb\">str</span>,</span><span class=\"param\">\t<span class=\"n\">port</span><span class=\"p\">:</span> <span class=\"nb\">int</span>,</span><span class=\"param\">\t<span class=\"n\">rank</span><span class=\"p\">:</span> <span class=\"nb\">int</span>,</span><span class=\"param\">\t<span class=\"n\">world_size</span><span class=\"p\">:</span> <span class=\"nb\">int</span>,</span><span class=\"param\">\t<span class=\"n\">data_expiration_seconds</span><span class=\"p\">:</span> <span class=\"nb\">int</span> <span class=\"o\">=</span> <span class=\"mi\">3600</span></span><span class=\"return-annotation\">) -> <span class=\"n\">sglang</span><span class=\"o\">.</span><span class=\"n\">srt</span><span class=\"o\">.</span><span class=\"n\">distributed</span><span class=\"o\">.</span><span class=\"n\">utils</span><span class=\"o\">.</span><span class=\"n\">StatelessProcessGroup</span>:</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.eplb", "modulename": "sglang.srt.eplb", "kind": "module", "doc": "<p></p>\n"}, {"fullname": "sglang.srt.eplb.eplb_algorithms", "modulename": "sglang.srt.eplb.eplb_algorithms", "kind": "module", "doc": "<p></p>\n"}, {"fullname": "sglang.srt.eplb.eplb_algorithms.EplbAlgorithm", "modulename": "sglang.srt.eplb.eplb_algorithms", "qualname": "EplbAlgorithm", "kind": "class", "doc": "<p></p>\n", "bases": "enum.Enum"}, {"fullname": "sglang.srt.eplb.eplb_algorithms.EplbAlgorithm.deepseek", "modulename": "sglang.srt.eplb.eplb_algorithms", "qualname": "EplbAlgorithm.deepseek", "kind": "variable", "doc": "<p></p>\n", "default_value": "&lt;EplbAlgorithm.deepseek: 1&gt;"}, {"fullname": "sglang.srt.eplb.eplb_algorithms.EplbAlgorithm.deepseek_hierarchical", "modulename": "sglang.srt.eplb.eplb_algorithms", "qualname": "EplbAlgorithm.deepseek_hierarchical", "kind": "variable", "doc": "<p></p>\n", "default_value": "&lt;EplbAlgorithm.deepseek_hierarchical: 2&gt;"}, {"fullname": "sglang.srt.eplb.eplb_algorithms.EplbAlgorithm.deepseek_vec", "modulename": "sglang.srt.eplb.eplb_algorithms", "qualname": "EplbAlgorithm.deepseek_vec", "kind": "variable", "doc": "<p></p>\n", "default_value": "&lt;EplbAlgorithm.deepseek_vec: 3&gt;"}, {"fullname": "sglang.srt.eplb.eplb_algorithms.EplbAlgorithm.deepseek_vec_hierarchical", "modulename": "sglang.srt.eplb.eplb_algorithms", "qualname": "EplbAlgorithm.deepseek_vec_hierarchical", "kind": "variable", "doc": "<p></p>\n", "default_value": "&lt;EplbAlgorithm.deepseek_vec_hierarchical: 4&gt;"}, {"fullname": "sglang.srt.eplb.eplb_algorithms.rebalance_experts", "modulename": "sglang.srt.eplb.eplb_algorithms", "qualname": "rebalance_experts", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">tokens_per_expert</span><span class=\"p\">:</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">Tensor</span>,</span><span class=\"param\">\t<span class=\"n\">num_physical_experts</span><span class=\"p\">:</span> <span class=\"nb\">int</span>,</span><span class=\"param\">\t<span class=\"n\">num_local_physical_experts</span><span class=\"p\">:</span> <span class=\"nb\">int</span>,</span><span class=\"param\">\t<span class=\"n\">num_groups</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"nb\">int</span><span class=\"p\">]</span>,</span><span class=\"param\">\t<span class=\"n\">num_nodes</span><span class=\"p\">:</span> <span class=\"nb\">int</span>,</span><span class=\"param\">\t<span class=\"n\">algorithm</span><span class=\"p\">:</span> <span class=\"n\">sglang</span><span class=\"o\">.</span><span class=\"n\">srt</span><span class=\"o\">.</span><span class=\"n\">eplb</span><span class=\"o\">.</span><span class=\"n\">eplb_algorithms</span><span class=\"o\">.</span><span class=\"n\">EplbAlgorithm</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.eplb.eplb_algorithms.compute_algorithm", "modulename": "sglang.srt.eplb.eplb_algorithms", "qualname": "compute_algorithm", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">raw_algorithm</span><span class=\"p\">:</span> <span class=\"nb\">str</span>,</span><span class=\"param\">\t<span class=\"n\">num_groups</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"nb\">int</span><span class=\"p\">]</span>,</span><span class=\"param\">\t<span class=\"n\">num_nodes</span><span class=\"p\">:</span> <span class=\"nb\">int</span></span><span class=\"return-annotation\">) -> <span class=\"n\">sglang</span><span class=\"o\">.</span><span class=\"n\">srt</span><span class=\"o\">.</span><span class=\"n\">eplb</span><span class=\"o\">.</span><span class=\"n\">eplb_algorithms</span><span class=\"o\">.</span><span class=\"n\">EplbAlgorithm</span>:</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.eplb.eplb_algorithms.deepseek", "modulename": "sglang.srt.eplb.eplb_algorithms.deepseek", "kind": "module", "doc": "<p></p>\n"}, {"fullname": "sglang.srt.eplb.eplb_algorithms.deepseek.rebalance_experts", "modulename": "sglang.srt.eplb.eplb_algorithms.deepseek", "qualname": "rebalance_experts", "kind": "function", "doc": "<p>Entry point for expert-parallelism load balancer.</p>\n\n<p>Parameters:\n    weight: [layers, num_logical_experts], the load statistics for all logical experts\n    num_replicas: number of physical experts, must be a multiple of <code>num_gpus</code>\n    num_groups: number of expert groups\n    num_nodes: number of server nodes, where the intra-node network (e.g, NVLink) is faster\n    num_gpus: number of GPUs, must be a multiple of <code>num_nodes</code></p>\n\n<p>Returns:\n    physical_to_logical_map: [layers, num_replicas], the expert index of each replica\n    logical_to_physical_map: [layers, num_logical_experts, X], the replica indices for each expert\n    expert_count: [layers, num_logical_experts], number of physical replicas for each logical expert</p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">weight</span><span class=\"p\">:</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">Tensor</span>,</span><span class=\"param\">\t<span class=\"n\">num_replicas</span><span class=\"p\">:</span> <span class=\"nb\">int</span>,</span><span class=\"param\">\t<span class=\"n\">num_groups</span><span class=\"p\">:</span> <span class=\"nb\">int</span>,</span><span class=\"param\">\t<span class=\"n\">num_nodes</span><span class=\"p\">:</span> <span class=\"nb\">int</span>,</span><span class=\"param\">\t<span class=\"n\">num_gpus</span><span class=\"p\">:</span> <span class=\"nb\">int</span>,</span><span class=\"param\">\t<span class=\"n\">enable_hierarchical</span><span class=\"p\">:</span> <span class=\"nb\">bool</span></span><span class=\"return-annotation\">) -> <span class=\"n\">Tuple</span><span class=\"p\">[</span><span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">Tensor</span><span class=\"p\">,</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">Tensor</span><span class=\"p\">,</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">Tensor</span><span class=\"p\">]</span>:</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.eplb.eplb_algorithms.deepseek_vec", "modulename": "sglang.srt.eplb.eplb_algorithms.deepseek_vec", "kind": "module", "doc": "<p></p>\n"}, {"fullname": "sglang.srt.eplb.eplb_algorithms.deepseek_vec.pack_groups", "modulename": "sglang.srt.eplb.eplb_algorithms.deepseek_vec", "qualname": "pack_groups", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">tokens_per_group</span><span class=\"p\">:</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">Tensor</span>, </span><span class=\"param\"><span class=\"n\">num_nodes</span><span class=\"p\">:</span> <span class=\"nb\">int</span></span><span class=\"return-annotation\">) -> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">Tensor</span>:</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.eplb.eplb_algorithms.deepseek_vec.make_redundant_experts_chunkwise", "modulename": "sglang.srt.eplb.eplb_algorithms.deepseek_vec", "qualname": "make_redundant_experts_chunkwise", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">tokens_per_expert</span><span class=\"p\">:</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">Tensor</span>,</span><span class=\"param\">\t<span class=\"n\">num_physical_experts</span><span class=\"p\">:</span> <span class=\"nb\">int</span>,</span><span class=\"param\">\t<span class=\"n\">num_local_physical_experts</span><span class=\"p\">:</span> <span class=\"nb\">int</span>,</span><span class=\"param\">\t<span class=\"n\">num_physical_experts_per_chunk</span><span class=\"p\">:</span> <span class=\"nb\">int</span></span><span class=\"return-annotation\">) -> <span class=\"n\">Tuple</span><span class=\"p\">[</span><span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">Tensor</span><span class=\"p\">,</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">Tensor</span><span class=\"p\">,</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">Tensor</span><span class=\"p\">]</span>:</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.eplb.eplb_algorithms.deepseek_vec.decode_rebalance_experts", "modulename": "sglang.srt.eplb.eplb_algorithms.deepseek_vec", "qualname": "decode_rebalance_experts", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">tokens_per_expert</span><span class=\"p\">:</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">Tensor</span>,</span><span class=\"param\">\t<span class=\"n\">num_physical_experts</span><span class=\"p\">:</span> <span class=\"nb\">int</span>,</span><span class=\"param\">\t<span class=\"n\">num_local_physical_experts</span><span class=\"p\">:</span> <span class=\"nb\">int</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.eplb.eplb_algorithms.deepseek_vec.prefill_rebalance_experts", "modulename": "sglang.srt.eplb.eplb_algorithms.deepseek_vec", "qualname": "prefill_rebalance_experts", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">tokens_per_expert</span><span class=\"p\">:</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">Tensor</span>,</span><span class=\"param\">\t<span class=\"n\">num_physical_experts</span><span class=\"p\">:</span> <span class=\"nb\">int</span>,</span><span class=\"param\">\t<span class=\"n\">num_local_physical_experts</span><span class=\"p\">:</span> <span class=\"nb\">int</span>,</span><span class=\"param\">\t<span class=\"n\">num_groups</span><span class=\"p\">:</span> <span class=\"nb\">int</span>,</span><span class=\"param\">\t<span class=\"n\">num_nodes</span><span class=\"p\">:</span> <span class=\"nb\">int</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.eplb.eplb_algorithms.deepseek_vec.rebalance_experts", "modulename": "sglang.srt.eplb.eplb_algorithms.deepseek_vec", "qualname": "rebalance_experts", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">tokens_per_expert</span><span class=\"p\">:</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">Tensor</span>,</span><span class=\"param\">\t<span class=\"n\">num_physical_experts</span><span class=\"p\">:</span> <span class=\"nb\">int</span>,</span><span class=\"param\">\t<span class=\"n\">num_local_physical_experts</span><span class=\"p\">:</span> <span class=\"nb\">int</span>,</span><span class=\"param\">\t<span class=\"n\">num_groups</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"nb\">int</span><span class=\"p\">]</span>,</span><span class=\"param\">\t<span class=\"n\">num_nodes</span><span class=\"p\">:</span> <span class=\"nb\">int</span>,</span><span class=\"param\">\t<span class=\"n\">enable_hierarchical</span><span class=\"p\">:</span> <span class=\"nb\">bool</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.eplb.eplb_manager", "modulename": "sglang.srt.eplb.eplb_manager", "kind": "module", "doc": "<p></p>\n"}, {"fullname": "sglang.srt.eplb.eplb_manager.logger", "modulename": "sglang.srt.eplb.eplb_manager", "qualname": "logger", "kind": "variable", "doc": "<p></p>\n", "default_value": "&lt;Logger sglang.srt.eplb.eplb_manager (WARNING)&gt;"}, {"fullname": "sglang.srt.eplb.eplb_manager.EPLBManager", "modulename": "sglang.srt.eplb.eplb_manager", "qualname": "EPLBManager", "kind": "class", "doc": "<p></p>\n"}, {"fullname": "sglang.srt.eplb.eplb_manager.EPLBManager.__init__", "modulename": "sglang.srt.eplb.eplb_manager", "qualname": "EPLBManager.__init__", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">model_runner</span><span class=\"p\">:</span> <span class=\"n\">sglang</span><span class=\"o\">.</span><span class=\"n\">srt</span><span class=\"o\">.</span><span class=\"n\">model_executor</span><span class=\"o\">.</span><span class=\"n\">model_runner</span><span class=\"o\">.</span><span class=\"n\">ModelRunner</span></span>)</span>"}, {"fullname": "sglang.srt.eplb.eplb_manager.EPLBManager.on_forward_pass_end", "modulename": "sglang.srt.eplb.eplb_manager", "qualname": "EPLBManager.on_forward_pass_end", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.eplb.eplb_manager.EPLBManager.rebalance", "modulename": "sglang.srt.eplb.eplb_manager", "qualname": "EPLBManager.rebalance", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.eplb.eplb_simulator", "modulename": "sglang.srt.eplb.eplb_simulator", "kind": "module", "doc": "<p></p>\n"}, {"fullname": "sglang.srt.eplb.eplb_simulator.reader", "modulename": "sglang.srt.eplb.eplb_simulator.reader", "kind": "module", "doc": "<p></p>\n"}, {"fullname": "sglang.srt.eplb.eplb_simulator.reader.convert_global_physical_count_to_logical_count", "modulename": "sglang.srt.eplb.eplb_simulator.reader", "qualname": "convert_global_physical_count_to_logical_count", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">global_physical_count</span><span class=\"p\">:</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">Tensor</span>,</span><span class=\"param\">\t<span class=\"n\">num_layers</span><span class=\"p\">:</span> <span class=\"nb\">int</span>,</span><span class=\"param\">\t<span class=\"n\">num_logical_experts</span><span class=\"p\">:</span> <span class=\"nb\">int</span>,</span><span class=\"param\">\t<span class=\"n\">physical_to_logical_map</span><span class=\"p\">:</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">Tensor</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.eplb.eplb_simulator.reader.read_mode_per_pass", "modulename": "sglang.srt.eplb.eplb_simulator.reader", "qualname": "read_mode_per_pass", "kind": "function", "doc": "<p>Read data from ExpertDistributionRecorder when recorded with mode <code>per_pass</code></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">dir_data</span><span class=\"p\">:</span> <span class=\"n\">pathlib</span><span class=\"o\">.</span><span class=\"n\">Path</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.eplb.expert_distribution", "modulename": "sglang.srt.eplb.expert_distribution", "kind": "module", "doc": "<p></p>\n"}, {"fullname": "sglang.srt.eplb.expert_distribution.logger", "modulename": "sglang.srt.eplb.expert_distribution", "qualname": "logger", "kind": "variable", "doc": "<p></p>\n", "default_value": "&lt;Logger sglang.srt.eplb.expert_distribution (WARNING)&gt;"}, {"fullname": "sglang.srt.eplb.expert_distribution.ExpertDistributionRecorder", "modulename": "sglang.srt.eplb.expert_distribution", "qualname": "ExpertDistributionRecorder", "kind": "class", "doc": "<p>Global expert distribution recording</p>\n", "bases": "abc.ABC"}, {"fullname": "sglang.srt.eplb.expert_distribution.ExpertDistributionRecorder.init_new", "modulename": "sglang.srt.eplb.expert_distribution", "qualname": "ExpertDistributionRecorder.init_new", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">server_args</span><span class=\"p\">:</span> <span class=\"n\">sglang</span><span class=\"o\">.</span><span class=\"n\">srt</span><span class=\"o\">.</span><span class=\"n\">server_args</span><span class=\"o\">.</span><span class=\"n\">ServerArgs</span>,</span><span class=\"param\">\t<span class=\"n\">expert_location_metadata</span><span class=\"p\">:</span> <span class=\"n\">sglang</span><span class=\"o\">.</span><span class=\"n\">srt</span><span class=\"o\">.</span><span class=\"n\">eplb</span><span class=\"o\">.</span><span class=\"n\">expert_location</span><span class=\"o\">.</span><span class=\"n\">ExpertLocationMetadata</span>,</span><span class=\"param\">\t<span class=\"n\">rank</span><span class=\"p\">:</span> <span class=\"nb\">int</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.eplb.expert_distribution.ExpertDistributionRecorder.with_current_layer", "modulename": "sglang.srt.eplb.expert_distribution", "qualname": "ExpertDistributionRecorder.with_current_layer", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">layer_idx</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.eplb.expert_distribution.ExpertDistributionRecorder.with_debug_name", "modulename": "sglang.srt.eplb.expert_distribution", "qualname": "ExpertDistributionRecorder.with_debug_name", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">debug_name</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.eplb.expert_distribution.ExpertDistributionRecorder.disable_this_region", "modulename": "sglang.srt.eplb.expert_distribution", "qualname": "ExpertDistributionRecorder.disable_this_region", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.eplb.expert_distribution.ExpertDistributionRecorder.with_forward_pass", "modulename": "sglang.srt.eplb.expert_distribution", "qualname": "ExpertDistributionRecorder.with_forward_pass", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"bp\">self</span>,</span><span class=\"param\">\t<span class=\"n\">forward_pass_id</span><span class=\"p\">:</span> <span class=\"nb\">int</span>,</span><span class=\"param\">\t<span class=\"n\">forward_batch</span><span class=\"p\">:</span> <span class=\"n\">sglang</span><span class=\"o\">.</span><span class=\"n\">srt</span><span class=\"o\">.</span><span class=\"n\">model_executor</span><span class=\"o\">.</span><span class=\"n\">forward_batch_info</span><span class=\"o\">.</span><span class=\"n\">ForwardBatch</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.eplb.expert_distribution.ExpertDistributionRecorder.on_select_experts", "modulename": "sglang.srt.eplb.expert_distribution", "qualname": "ExpertDistributionRecorder.on_select_experts", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">topk_ids</span><span class=\"p\">:</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">Tensor</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.eplb.expert_distribution.ExpertDistributionRecorder.on_deepep_dispatch_normal", "modulename": "sglang.srt.eplb.expert_distribution", "qualname": "ExpertDistributionRecorder.on_deepep_dispatch_normal", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"bp\">self</span>,</span><span class=\"param\">\t<span class=\"n\">local_physical_count_of_layer</span><span class=\"p\">:</span> <span class=\"n\">List</span><span class=\"p\">[</span><span class=\"nb\">int</span><span class=\"p\">]</span>,</span><span class=\"param\">\t<span class=\"n\">num_tokens_per_rank</span>,</span><span class=\"param\">\t<span class=\"n\">num_tokens_per_rdma_rank</span>,</span><span class=\"param\">\t<span class=\"n\">num_tokens_per_expert</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.eplb.expert_distribution.ExpertDistributionRecorder.on_deepep_dispatch_low_latency", "modulename": "sglang.srt.eplb.expert_distribution", "qualname": "ExpertDistributionRecorder.on_deepep_dispatch_low_latency", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">local_physical_count_of_layer</span><span class=\"p\">:</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">Tensor</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.eplb.expert_distribution.ExpertDistributionRecorder.start_record", "modulename": "sglang.srt.eplb.expert_distribution", "qualname": "ExpertDistributionRecorder.start_record", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.eplb.expert_distribution.ExpertDistributionRecorder.stop_record", "modulename": "sglang.srt.eplb.expert_distribution", "qualname": "ExpertDistributionRecorder.stop_record", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.eplb.expert_distribution.ExpertDistributionRecorder.dump_record", "modulename": "sglang.srt.eplb.expert_distribution", "qualname": "ExpertDistributionRecorder.dump_record", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">output_mode</span><span class=\"p\">:</span> <span class=\"n\">Literal</span><span class=\"p\">[</span><span class=\"s1\">&#39;file&#39;</span><span class=\"p\">,</span> <span class=\"s1\">&#39;object&#39;</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"s1\">&#39;file&#39;</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.eplb.expert_distribution.ExpertDistributionRecorder.recording", "modulename": "sglang.srt.eplb.expert_distribution", "qualname": "ExpertDistributionRecorder.recording", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "sglang.srt.eplb.expert_distribution.get_global_expert_distribution_recorder", "modulename": "sglang.srt.eplb.expert_distribution", "qualname": "get_global_expert_distribution_recorder", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.eplb.expert_distribution.set_global_expert_distribution_recorder", "modulename": "sglang.srt.eplb.expert_distribution", "qualname": "set_global_expert_distribution_recorder", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">value</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.eplb.expert_distribution.compute_gpu_physical_count", "modulename": "sglang.srt.eplb.expert_distribution", "qualname": "compute_gpu_physical_count", "kind": "function", "doc": "<p>output: gpu_physical_count_of_batch (..., num_layer, num_gpu)</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">physical_count_of_whatever</span><span class=\"p\">:</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">Tensor</span>, </span><span class=\"param\"><span class=\"n\">num_gpu</span><span class=\"p\">:</span> <span class=\"nb\">int</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.eplb.expert_distribution.compute_utilization_rate", "modulename": "sglang.srt.eplb.expert_distribution", "qualname": "compute_utilization_rate", "kind": "function", "doc": "<p>output: utilization_rate (..., num_layer)</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">gpu_physical_count_of_batch</span><span class=\"p\">:</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">Tensor</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.eplb.expert_location", "modulename": "sglang.srt.eplb.expert_location", "kind": "module", "doc": "<p></p>\n"}, {"fullname": "sglang.srt.eplb.expert_location.logger", "modulename": "sglang.srt.eplb.expert_location", "qualname": "logger", "kind": "variable", "doc": "<p></p>\n", "default_value": "&lt;Logger sglang.srt.eplb.expert_location (WARNING)&gt;"}, {"fullname": "sglang.srt.eplb.expert_location.ExpertLocationMetadata", "modulename": "sglang.srt.eplb.expert_location", "qualname": "ExpertLocationMetadata", "kind": "class", "doc": "<p></p>\n"}, {"fullname": "sglang.srt.eplb.expert_location.ExpertLocationMetadata.__init__", "modulename": "sglang.srt.eplb.expert_location", "qualname": "ExpertLocationMetadata.__init__", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">physical_to_logical_map</span><span class=\"p\">:</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">Tensor</span>,</span><span class=\"param\">\t<span class=\"n\">physical_to_logical_map_cpu</span><span class=\"p\">:</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">Tensor</span>,</span><span class=\"param\">\t<span class=\"n\">logical_to_all_physical_map</span><span class=\"p\">:</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">Tensor</span>,</span><span class=\"param\">\t<span class=\"n\">logical_to_all_physical_map_cpu</span><span class=\"p\">:</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">Tensor</span>,</span><span class=\"param\">\t<span class=\"n\">logical_to_all_physical_map_num_valid</span><span class=\"p\">:</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">Tensor</span>,</span><span class=\"param\">\t<span class=\"n\">logical_to_rank_dispatch_physical_map</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">Tensor</span><span class=\"p\">]</span></span>)</span>"}, {"fullname": "sglang.srt.eplb.expert_location.ExpertLocationMetadata.physical_to_logical_map", "modulename": "sglang.srt.eplb.expert_location", "qualname": "ExpertLocationMetadata.physical_to_logical_map", "kind": "variable", "doc": "<p></p>\n", "annotation": ": torch.Tensor"}, {"fullname": "sglang.srt.eplb.expert_location.ExpertLocationMetadata.physical_to_logical_map_cpu", "modulename": "sglang.srt.eplb.expert_location", "qualname": "ExpertLocationMetadata.physical_to_logical_map_cpu", "kind": "variable", "doc": "<p></p>\n", "annotation": ": torch.Tensor"}, {"fullname": "sglang.srt.eplb.expert_location.ExpertLocationMetadata.logical_to_all_physical_map", "modulename": "sglang.srt.eplb.expert_location", "qualname": "ExpertLocationMetadata.logical_to_all_physical_map", "kind": "variable", "doc": "<p></p>\n", "annotation": ": torch.Tensor"}, {"fullname": "sglang.srt.eplb.expert_location.ExpertLocationMetadata.logical_to_all_physical_map_cpu", "modulename": "sglang.srt.eplb.expert_location", "qualname": "ExpertLocationMetadata.logical_to_all_physical_map_cpu", "kind": "variable", "doc": "<p></p>\n", "annotation": ": torch.Tensor"}, {"fullname": "sglang.srt.eplb.expert_location.ExpertLocationMetadata.logical_to_all_physical_map_num_valid", "modulename": "sglang.srt.eplb.expert_location", "qualname": "ExpertLocationMetadata.logical_to_all_physical_map_num_valid", "kind": "variable", "doc": "<p></p>\n", "annotation": ": torch.Tensor"}, {"fullname": "sglang.srt.eplb.expert_location.ExpertLocationMetadata.logical_to_rank_dispatch_physical_map", "modulename": "sglang.srt.eplb.expert_location", "qualname": "ExpertLocationMetadata.logical_to_rank_dispatch_physical_map", "kind": "variable", "doc": "<p></p>\n", "annotation": ": Optional[torch.Tensor]"}, {"fullname": "sglang.srt.eplb.expert_location.ExpertLocationMetadata.num_layers", "modulename": "sglang.srt.eplb.expert_location", "qualname": "ExpertLocationMetadata.num_layers", "kind": "variable", "doc": "<p></p>\n", "annotation": ": int"}, {"fullname": "sglang.srt.eplb.expert_location.ExpertLocationMetadata.num_physical_experts", "modulename": "sglang.srt.eplb.expert_location", "qualname": "ExpertLocationMetadata.num_physical_experts", "kind": "variable", "doc": "<p></p>\n", "annotation": ": int"}, {"fullname": "sglang.srt.eplb.expert_location.ExpertLocationMetadata.num_local_physical_experts", "modulename": "sglang.srt.eplb.expert_location", "qualname": "ExpertLocationMetadata.num_local_physical_experts", "kind": "variable", "doc": "<p></p>\n", "annotation": ": int"}, {"fullname": "sglang.srt.eplb.expert_location.ExpertLocationMetadata.num_logical_experts", "modulename": "sglang.srt.eplb.expert_location", "qualname": "ExpertLocationMetadata.num_logical_experts", "kind": "variable", "doc": "<p></p>\n", "annotation": ": int"}, {"fullname": "sglang.srt.eplb.expert_location.ExpertLocationMetadata.ep_size", "modulename": "sglang.srt.eplb.expert_location", "qualname": "ExpertLocationMetadata.ep_size", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "sglang.srt.eplb.expert_location.ExpertLocationMetadata.init_trivial", "modulename": "sglang.srt.eplb.expert_location", "qualname": "ExpertLocationMetadata.init_trivial", "kind": "function", "doc": "<p>Trivial location - logical expert i corresponds to physical expert i</p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">server_args</span><span class=\"p\">:</span> <span class=\"n\">sglang</span><span class=\"o\">.</span><span class=\"n\">srt</span><span class=\"o\">.</span><span class=\"n\">server_args</span><span class=\"o\">.</span><span class=\"n\">ServerArgs</span>,</span><span class=\"param\">\t<span class=\"n\">model_config</span><span class=\"p\">:</span> <span class=\"n\">sglang</span><span class=\"o\">.</span><span class=\"n\">srt</span><span class=\"o\">.</span><span class=\"n\">configs</span><span class=\"o\">.</span><span class=\"n\">model_config</span><span class=\"o\">.</span><span class=\"n\">ModelConfig</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.eplb.expert_location.ExpertLocationMetadata.init_by_mapping", "modulename": "sglang.srt.eplb.expert_location", "qualname": "ExpertLocationMetadata.init_by_mapping", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">server_args</span><span class=\"p\">:</span> <span class=\"n\">sglang</span><span class=\"o\">.</span><span class=\"n\">srt</span><span class=\"o\">.</span><span class=\"n\">server_args</span><span class=\"o\">.</span><span class=\"n\">ServerArgs</span>,</span><span class=\"param\">\t<span class=\"n\">model_config</span><span class=\"p\">:</span> <span class=\"n\">sglang</span><span class=\"o\">.</span><span class=\"n\">srt</span><span class=\"o\">.</span><span class=\"n\">configs</span><span class=\"o\">.</span><span class=\"n\">model_config</span><span class=\"o\">.</span><span class=\"n\">ModelConfig</span>,</span><span class=\"param\">\t<span class=\"n\">physical_to_logical_map</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.eplb.expert_location.ExpertLocationMetadata.init_by_eplb", "modulename": "sglang.srt.eplb.expert_location", "qualname": "ExpertLocationMetadata.init_by_eplb", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">server_args</span><span class=\"p\">:</span> <span class=\"n\">sglang</span><span class=\"o\">.</span><span class=\"n\">srt</span><span class=\"o\">.</span><span class=\"n\">server_args</span><span class=\"o\">.</span><span class=\"n\">ServerArgs</span>,</span><span class=\"param\">\t<span class=\"n\">model_config</span><span class=\"p\">:</span> <span class=\"n\">sglang</span><span class=\"o\">.</span><span class=\"n\">srt</span><span class=\"o\">.</span><span class=\"n\">configs</span><span class=\"o\">.</span><span class=\"n\">model_config</span><span class=\"o\">.</span><span class=\"n\">ModelConfig</span>,</span><span class=\"param\">\t<span class=\"n\">logical_count</span><span class=\"p\">:</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">Tensor</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.eplb.expert_location.ExpertLocationMetadata.update", "modulename": "sglang.srt.eplb.expert_location", "qualname": "ExpertLocationMetadata.update", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"bp\">self</span>,</span><span class=\"param\">\t<span class=\"n\">other</span><span class=\"p\">:</span> <span class=\"n\">sglang</span><span class=\"o\">.</span><span class=\"n\">srt</span><span class=\"o\">.</span><span class=\"n\">eplb</span><span class=\"o\">.</span><span class=\"n\">expert_location</span><span class=\"o\">.</span><span class=\"n\">ExpertLocationMetadata</span>,</span><span class=\"param\">\t<span class=\"n\">update_layer_ids</span><span class=\"p\">:</span> <span class=\"n\">List</span><span class=\"p\">[</span><span class=\"nb\">int</span><span class=\"p\">]</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.eplb.expert_location.ExpertLocationMetadata.logical_to_all_physical", "modulename": "sglang.srt.eplb.expert_location", "qualname": "ExpertLocationMetadata.logical_to_all_physical", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">layer_id</span><span class=\"p\">:</span> <span class=\"nb\">int</span>, </span><span class=\"param\"><span class=\"n\">logical_expert_id</span><span class=\"p\">:</span> <span class=\"nb\">int</span></span><span class=\"return-annotation\">) -> <span class=\"n\">List</span><span class=\"p\">[</span><span class=\"nb\">int</span><span class=\"p\">]</span>:</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.eplb.expert_location.get_global_expert_location_metadata", "modulename": "sglang.srt.eplb.expert_location", "qualname": "get_global_expert_location_metadata", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.eplb.expert_location.set_global_expert_location_metadata", "modulename": "sglang.srt.eplb.expert_location", "qualname": "set_global_expert_location_metadata", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">value</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.eplb.expert_location.compute_logical_to_rank_dispatch_physical_map", "modulename": "sglang.srt.eplb.expert_location", "qualname": "compute_logical_to_rank_dispatch_physical_map", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">logical_to_all_physical_map</span><span class=\"p\">:</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">Tensor</span>,</span><span class=\"param\">\t<span class=\"n\">num_gpus</span><span class=\"p\">:</span> <span class=\"nb\">int</span>,</span><span class=\"param\">\t<span class=\"n\">num_physical_experts</span><span class=\"p\">:</span> <span class=\"nb\">int</span>,</span><span class=\"param\">\t<span class=\"n\">ep_rank</span><span class=\"p\">:</span> <span class=\"nb\">int</span>,</span><span class=\"param\">\t<span class=\"n\">seed</span><span class=\"p\">:</span> <span class=\"nb\">int</span> <span class=\"o\">=</span> <span class=\"mi\">42</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.eplb.expert_location.ModelConfigForExpertLocation", "modulename": "sglang.srt.eplb.expert_location", "qualname": "ModelConfigForExpertLocation", "kind": "class", "doc": "<p></p>\n"}, {"fullname": "sglang.srt.eplb.expert_location.ModelConfigForExpertLocation.__init__", "modulename": "sglang.srt.eplb.expert_location", "qualname": "ModelConfigForExpertLocation.__init__", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">num_layers</span><span class=\"p\">:</span> <span class=\"nb\">int</span>,</span><span class=\"param\">\t<span class=\"n\">num_logical_experts</span><span class=\"p\">:</span> <span class=\"nb\">int</span>,</span><span class=\"param\">\t<span class=\"n\">num_groups</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"nb\">int</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span></span>)</span>"}, {"fullname": "sglang.srt.eplb.expert_location.ModelConfigForExpertLocation.num_layers", "modulename": "sglang.srt.eplb.expert_location", "qualname": "ModelConfigForExpertLocation.num_layers", "kind": "variable", "doc": "<p></p>\n", "annotation": ": int"}, {"fullname": "sglang.srt.eplb.expert_location.ModelConfigForExpertLocation.num_logical_experts", "modulename": "sglang.srt.eplb.expert_location", "qualname": "ModelConfigForExpertLocation.num_logical_experts", "kind": "variable", "doc": "<p></p>\n", "annotation": ": int"}, {"fullname": "sglang.srt.eplb.expert_location.ModelConfigForExpertLocation.num_groups", "modulename": "sglang.srt.eplb.expert_location", "qualname": "ModelConfigForExpertLocation.num_groups", "kind": "variable", "doc": "<p></p>\n", "annotation": ": Optional[int]", "default_value": "None"}, {"fullname": "sglang.srt.eplb.expert_location.ModelConfigForExpertLocation.from_model_config", "modulename": "sglang.srt.eplb.expert_location", "qualname": "ModelConfigForExpertLocation.from_model_config", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">model_config</span><span class=\"p\">:</span> <span class=\"n\">sglang</span><span class=\"o\">.</span><span class=\"n\">srt</span><span class=\"o\">.</span><span class=\"n\">configs</span><span class=\"o\">.</span><span class=\"n\">model_config</span><span class=\"o\">.</span><span class=\"n\">ModelConfig</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.eplb.expert_location.compute_initial_expert_location_metadata", "modulename": "sglang.srt.eplb.expert_location", "qualname": "compute_initial_expert_location_metadata", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">server_args</span><span class=\"p\">:</span> <span class=\"n\">sglang</span><span class=\"o\">.</span><span class=\"n\">srt</span><span class=\"o\">.</span><span class=\"n\">server_args</span><span class=\"o\">.</span><span class=\"n\">ServerArgs</span>,</span><span class=\"param\">\t<span class=\"n\">model_config</span><span class=\"p\">:</span> <span class=\"n\">sglang</span><span class=\"o\">.</span><span class=\"n\">srt</span><span class=\"o\">.</span><span class=\"n\">configs</span><span class=\"o\">.</span><span class=\"n\">model_config</span><span class=\"o\">.</span><span class=\"n\">ModelConfig</span></span><span class=\"return-annotation\">) -> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"n\">sglang</span><span class=\"o\">.</span><span class=\"n\">srt</span><span class=\"o\">.</span><span class=\"n\">eplb</span><span class=\"o\">.</span><span class=\"n\">expert_location</span><span class=\"o\">.</span><span class=\"n\">ExpertLocationMetadata</span><span class=\"p\">]</span>:</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.eplb.expert_location_dispatch", "modulename": "sglang.srt.eplb.expert_location_dispatch", "kind": "module", "doc": "<p></p>\n"}, {"fullname": "sglang.srt.eplb.expert_location_dispatch.ExpertLocationDispatchInfo", "modulename": "sglang.srt.eplb.expert_location_dispatch", "qualname": "ExpertLocationDispatchInfo", "kind": "class", "doc": "<p></p>\n"}, {"fullname": "sglang.srt.eplb.expert_location_dispatch.ExpertLocationDispatchInfo.__init__", "modulename": "sglang.srt.eplb.expert_location_dispatch", "qualname": "ExpertLocationDispatchInfo.__init__", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">ep_dispatch_algorithm</span><span class=\"p\">:</span> <span class=\"n\">Literal</span><span class=\"p\">[</span><span class=\"s1\">&#39;static&#39;</span><span class=\"p\">,</span> <span class=\"s1\">&#39;random&#39;</span><span class=\"p\">]</span>,</span><span class=\"param\">\t<span class=\"n\">partial_logical_to_rank_dispatch_physical_map</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">Tensor</span><span class=\"p\">]</span>,</span><span class=\"param\">\t<span class=\"n\">partial_logical_to_all_physical_map</span><span class=\"p\">:</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">Tensor</span>,</span><span class=\"param\">\t<span class=\"n\">partial_logical_to_all_physical_map_num_valid</span><span class=\"p\">:</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">Tensor</span>,</span><span class=\"param\">\t<span class=\"n\">num_physical_experts</span><span class=\"p\">:</span> <span class=\"nb\">int</span></span>)</span>"}, {"fullname": "sglang.srt.eplb.expert_location_dispatch.ExpertLocationDispatchInfo.ep_dispatch_algorithm", "modulename": "sglang.srt.eplb.expert_location_dispatch", "qualname": "ExpertLocationDispatchInfo.ep_dispatch_algorithm", "kind": "variable", "doc": "<p></p>\n", "annotation": ": Literal[&#x27;static&#x27;, &#x27;random&#x27;]"}, {"fullname": "sglang.srt.eplb.expert_location_dispatch.ExpertLocationDispatchInfo.partial_logical_to_rank_dispatch_physical_map", "modulename": "sglang.srt.eplb.expert_location_dispatch", "qualname": "ExpertLocationDispatchInfo.partial_logical_to_rank_dispatch_physical_map", "kind": "variable", "doc": "<p></p>\n", "annotation": ": Optional[torch.Tensor]"}, {"fullname": "sglang.srt.eplb.expert_location_dispatch.ExpertLocationDispatchInfo.partial_logical_to_all_physical_map", "modulename": "sglang.srt.eplb.expert_location_dispatch", "qualname": "ExpertLocationDispatchInfo.partial_logical_to_all_physical_map", "kind": "variable", "doc": "<p></p>\n", "annotation": ": torch.Tensor"}, {"fullname": "sglang.srt.eplb.expert_location_dispatch.ExpertLocationDispatchInfo.partial_logical_to_all_physical_map_num_valid", "modulename": "sglang.srt.eplb.expert_location_dispatch", "qualname": "ExpertLocationDispatchInfo.partial_logical_to_all_physical_map_num_valid", "kind": "variable", "doc": "<p></p>\n", "annotation": ": torch.Tensor"}, {"fullname": "sglang.srt.eplb.expert_location_dispatch.ExpertLocationDispatchInfo.num_physical_experts", "modulename": "sglang.srt.eplb.expert_location_dispatch", "qualname": "ExpertLocationDispatchInfo.num_physical_experts", "kind": "variable", "doc": "<p></p>\n", "annotation": ": int"}, {"fullname": "sglang.srt.eplb.expert_location_dispatch.ExpertLocationDispatchInfo.init_new", "modulename": "sglang.srt.eplb.expert_location_dispatch", "qualname": "ExpertLocationDispatchInfo.init_new", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">cls</span>, </span><span class=\"param\"><span class=\"n\">layer_id</span><span class=\"p\">:</span> <span class=\"nb\">int</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.eplb.expert_location_dispatch.transform_select_experts_inputs", "modulename": "sglang.srt.eplb.expert_location_dispatch", "qualname": "transform_select_experts_inputs", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">router_logits</span><span class=\"p\">:</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">Tensor</span>,</span><span class=\"param\">\t<span class=\"n\">correction_bias</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">Tensor</span><span class=\"p\">]</span>,</span><span class=\"param\">\t<span class=\"n\">info</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"n\">sglang</span><span class=\"o\">.</span><span class=\"n\">srt</span><span class=\"o\">.</span><span class=\"n\">eplb</span><span class=\"o\">.</span><span class=\"n\">expert_location_dispatch</span><span class=\"o\">.</span><span class=\"n\">ExpertLocationDispatchInfo</span><span class=\"p\">]</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.eplb.expert_location_dispatch.topk_ids_logical_to_physical", "modulename": "sglang.srt.eplb.expert_location_dispatch", "qualname": "topk_ids_logical_to_physical", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">topk_ids</span><span class=\"p\">:</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">Tensor</span>,</span><span class=\"param\">\t<span class=\"n\">info</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"n\">sglang</span><span class=\"o\">.</span><span class=\"n\">srt</span><span class=\"o\">.</span><span class=\"n\">eplb</span><span class=\"o\">.</span><span class=\"n\">expert_location_dispatch</span><span class=\"o\">.</span><span class=\"n\">ExpertLocationDispatchInfo</span><span class=\"p\">]</span></span><span class=\"return-annotation\">) -> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">Tensor</span>:</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.eplb.expert_location_updater", "modulename": "sglang.srt.eplb.expert_location_updater", "kind": "module", "doc": "<p></p>\n"}, {"fullname": "sglang.srt.eplb.expert_location_updater.logger", "modulename": "sglang.srt.eplb.expert_location_updater", "qualname": "logger", "kind": "variable", "doc": "<p></p>\n", "default_value": "&lt;Logger sglang.srt.eplb.expert_location_updater (WARNING)&gt;"}, {"fullname": "sglang.srt.eplb.expert_location_updater.ExpertLocationUpdater", "modulename": "sglang.srt.eplb.expert_location_updater", "qualname": "ExpertLocationUpdater", "kind": "class", "doc": "<p></p>\n"}, {"fullname": "sglang.srt.eplb.expert_location_updater.ExpertLocationUpdater.update", "modulename": "sglang.srt.eplb.expert_location_updater", "qualname": "ExpertLocationUpdater.update", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"bp\">self</span>,</span><span class=\"param\">\t<span class=\"n\">routed_experts_weights_of_layer</span><span class=\"p\">:</span> <span class=\"n\">Dict</span><span class=\"p\">[</span><span class=\"nb\">int</span><span class=\"p\">,</span> <span class=\"n\">List</span><span class=\"p\">[</span><span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">Tensor</span><span class=\"p\">]]</span>,</span><span class=\"param\">\t<span class=\"n\">new_expert_location_metadata</span><span class=\"p\">:</span> <span class=\"n\">sglang</span><span class=\"o\">.</span><span class=\"n\">srt</span><span class=\"o\">.</span><span class=\"n\">eplb</span><span class=\"o\">.</span><span class=\"n\">expert_location</span><span class=\"o\">.</span><span class=\"n\">ExpertLocationMetadata</span>,</span><span class=\"param\">\t<span class=\"n\">update_layer_ids</span><span class=\"p\">:</span> <span class=\"n\">List</span><span class=\"p\">[</span><span class=\"nb\">int</span><span class=\"p\">]</span>,</span><span class=\"param\">\t<span class=\"n\">nnodes</span><span class=\"p\">:</span> <span class=\"nb\">int</span>,</span><span class=\"param\">\t<span class=\"n\">rank</span><span class=\"p\">:</span> <span class=\"nb\">int</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.eplb.expert_location_updater.create_temp_buffers", "modulename": "sglang.srt.eplb.expert_location_updater", "qualname": "create_temp_buffers", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">sample_tensors</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.eplb.expert_location_updater.update_expert_weights_single_layer", "modulename": "sglang.srt.eplb.expert_location_updater", "qualname": "update_expert_weights_single_layer", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">routed_experts_weights</span><span class=\"p\">:</span> <span class=\"n\">List</span><span class=\"p\">[</span><span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">Tensor</span><span class=\"p\">]</span>,</span><span class=\"param\">\t<span class=\"n\">temp_buffers</span><span class=\"p\">:</span> <span class=\"n\">List</span><span class=\"p\">[</span><span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">Tensor</span><span class=\"p\">]</span>,</span><span class=\"param\">\t<span class=\"n\">old_physical_to_logical_map</span><span class=\"p\">:</span> <span class=\"n\">List</span><span class=\"p\">[</span><span class=\"nb\">int</span><span class=\"p\">]</span>,</span><span class=\"param\">\t<span class=\"n\">new_physical_to_logical_map</span><span class=\"p\">:</span> <span class=\"n\">List</span><span class=\"p\">[</span><span class=\"nb\">int</span><span class=\"p\">]</span>,</span><span class=\"param\">\t<span class=\"n\">num_local_physical_experts</span><span class=\"p\">:</span> <span class=\"nb\">int</span>,</span><span class=\"param\">\t<span class=\"n\">num_gpu_per_node</span><span class=\"p\">:</span> <span class=\"nb\">int</span>,</span><span class=\"param\">\t<span class=\"n\">rank</span><span class=\"p\">:</span> <span class=\"nb\">int</span>,</span><span class=\"param\">\t<span class=\"n\">world_size</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"nb\">int</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">debug</span><span class=\"p\">:</span> <span class=\"nb\">bool</span> <span class=\"o\">=</span> <span class=\"kc\">False</span>,</span><span class=\"param\">\t<span class=\"n\">log_metrics</span><span class=\"p\">:</span> <span class=\"nb\">bool</span> <span class=\"o\">=</span> <span class=\"kc\">False</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.harmony_parser", "modulename": "sglang.srt.harmony_parser", "kind": "module", "doc": "<p></p>\n"}, {"fullname": "sglang.srt.harmony_parser.Event", "modulename": "sglang.srt.harmony_parser", "qualname": "Event", "kind": "class", "doc": "<p>Represents a parsed event from the Harmony stream.</p>\n"}, {"fullname": "sglang.srt.harmony_parser.Event.__init__", "modulename": "sglang.srt.harmony_parser", "qualname": "Event.__init__", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">event_type</span><span class=\"p\">:</span> <span class=\"nb\">str</span>, </span><span class=\"param\"><span class=\"n\">content</span><span class=\"p\">:</span> <span class=\"nb\">str</span>, </span><span class=\"param\"><span class=\"n\">raw_text</span><span class=\"p\">:</span> <span class=\"nb\">str</span> <span class=\"o\">=</span> <span class=\"kc\">None</span></span>)</span>"}, {"fullname": "sglang.srt.harmony_parser.Event.event_type", "modulename": "sglang.srt.harmony_parser", "qualname": "Event.event_type", "kind": "variable", "doc": "<p></p>\n", "annotation": ": str"}, {"fullname": "sglang.srt.harmony_parser.Event.content", "modulename": "sglang.srt.harmony_parser", "qualname": "Event.content", "kind": "variable", "doc": "<p></p>\n", "annotation": ": str"}, {"fullname": "sglang.srt.harmony_parser.Event.raw_text", "modulename": "sglang.srt.harmony_parser", "qualname": "Event.raw_text", "kind": "variable", "doc": "<p></p>\n", "annotation": ": str", "default_value": "None"}, {"fullname": "sglang.srt.harmony_parser.Token", "modulename": "sglang.srt.harmony_parser", "qualname": "Token", "kind": "class", "doc": "<p>A structural token in the Harmony format.</p>\n"}, {"fullname": "sglang.srt.harmony_parser.Token.__init__", "modulename": "sglang.srt.harmony_parser", "qualname": "Token.__init__", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"nb\">type</span><span class=\"p\">:</span> <span class=\"nb\">str</span>, </span><span class=\"param\"><span class=\"n\">start</span><span class=\"p\">:</span> <span class=\"nb\">int</span>, </span><span class=\"param\"><span class=\"n\">end</span><span class=\"p\">:</span> <span class=\"nb\">int</span></span>)</span>"}, {"fullname": "sglang.srt.harmony_parser.Token.type", "modulename": "sglang.srt.harmony_parser", "qualname": "Token.type", "kind": "variable", "doc": "<p></p>\n", "annotation": ": str"}, {"fullname": "sglang.srt.harmony_parser.Token.start", "modulename": "sglang.srt.harmony_parser", "qualname": "Token.start", "kind": "variable", "doc": "<p></p>\n", "annotation": ": int"}, {"fullname": "sglang.srt.harmony_parser.Token.end", "modulename": "sglang.srt.harmony_parser", "qualname": "Token.end", "kind": "variable", "doc": "<p></p>\n", "annotation": ": int"}, {"fullname": "sglang.srt.harmony_parser.prefix_hold", "modulename": "sglang.srt.harmony_parser", "qualname": "prefix_hold", "kind": "function", "doc": "<p>Holds back the longest suffix of <code>text</code> that could be a prefix of any token.\nReturns (emit_now, keep_for_later).</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">text</span><span class=\"p\">:</span> <span class=\"nb\">str</span>, </span><span class=\"param\"><span class=\"n\">tokens</span><span class=\"p\">:</span> <span class=\"n\">List</span><span class=\"p\">[</span><span class=\"nb\">str</span><span class=\"p\">]</span></span><span class=\"return-annotation\">) -> <span class=\"n\">Tuple</span><span class=\"p\">[</span><span class=\"nb\">str</span><span class=\"p\">,</span> <span class=\"nb\">str</span><span class=\"p\">]</span>:</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.harmony_parser.iter_tokens", "modulename": "sglang.srt.harmony_parser", "qualname": "iter_tokens", "kind": "function", "doc": "<p>Iterate over structural tokens in left-to-right order.</p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">text</span><span class=\"p\">:</span> <span class=\"nb\">str</span>,</span><span class=\"param\">\t<span class=\"n\">start_pos</span><span class=\"p\">:</span> <span class=\"nb\">int</span> <span class=\"o\">=</span> <span class=\"mi\">0</span></span><span class=\"return-annotation\">) -> <span class=\"n\">Iterator</span><span class=\"p\">[</span><span class=\"n\">sglang</span><span class=\"o\">.</span><span class=\"n\">srt</span><span class=\"o\">.</span><span class=\"n\">harmony_parser</span><span class=\"o\">.</span><span class=\"n\">Token</span><span class=\"p\">]</span>:</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.harmony_parser.CanonicalStrategy", "modulename": "sglang.srt.harmony_parser", "qualname": "CanonicalStrategy", "kind": "class", "doc": "<p>Parses the canonical Harmony format with channel markers.</p>\n"}, {"fullname": "sglang.srt.harmony_parser.CanonicalStrategy.guard_tokens", "modulename": "sglang.srt.harmony_parser", "qualname": "CanonicalStrategy.guard_tokens", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "sglang.srt.harmony_parser.CanonicalStrategy.parse", "modulename": "sglang.srt.harmony_parser", "qualname": "CanonicalStrategy.parse", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">text</span><span class=\"p\">:</span> <span class=\"nb\">str</span></span><span class=\"return-annotation\">) -> <span class=\"n\">Tuple</span><span class=\"p\">[</span><span class=\"n\">List</span><span class=\"p\">[</span><span class=\"n\">sglang</span><span class=\"o\">.</span><span class=\"n\">srt</span><span class=\"o\">.</span><span class=\"n\">harmony_parser</span><span class=\"o\">.</span><span class=\"n\">Event</span><span class=\"p\">],</span> <span class=\"nb\">str</span><span class=\"p\">]</span>:</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.harmony_parser.TextStrategy", "modulename": "sglang.srt.harmony_parser", "qualname": "TextStrategy", "kind": "class", "doc": "<p>Parses the text-based Harmony fallback format.</p>\n"}, {"fullname": "sglang.srt.harmony_parser.TextStrategy.buffer_context", "modulename": "sglang.srt.harmony_parser", "qualname": "TextStrategy.buffer_context", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "sglang.srt.harmony_parser.TextStrategy.patterns", "modulename": "sglang.srt.harmony_parser", "qualname": "TextStrategy.patterns", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "sglang.srt.harmony_parser.TextStrategy.set_buffer_context", "modulename": "sglang.srt.harmony_parser", "qualname": "TextStrategy.set_buffer_context", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">buffer</span><span class=\"p\">:</span> <span class=\"nb\">str</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.harmony_parser.TextStrategy.parse", "modulename": "sglang.srt.harmony_parser", "qualname": "TextStrategy.parse", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">text</span><span class=\"p\">:</span> <span class=\"nb\">str</span></span><span class=\"return-annotation\">) -> <span class=\"n\">Tuple</span><span class=\"p\">[</span><span class=\"n\">List</span><span class=\"p\">[</span><span class=\"n\">sglang</span><span class=\"o\">.</span><span class=\"n\">srt</span><span class=\"o\">.</span><span class=\"n\">harmony_parser</span><span class=\"o\">.</span><span class=\"n\">Event</span><span class=\"p\">],</span> <span class=\"nb\">str</span><span class=\"p\">]</span>:</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.harmony_parser.HarmonyParser", "modulename": "sglang.srt.harmony_parser", "qualname": "HarmonyParser", "kind": "class", "doc": "<p>Facade for parsing Harmony format, switching between strategies.</p>\n"}, {"fullname": "sglang.srt.harmony_parser.HarmonyParser.strategy", "modulename": "sglang.srt.harmony_parser", "qualname": "HarmonyParser.strategy", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "sglang.srt.harmony_parser.HarmonyParser.parse", "modulename": "sglang.srt.harmony_parser", "qualname": "HarmonyParser.parse", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">chunk</span><span class=\"p\">:</span> <span class=\"nb\">str</span></span><span class=\"return-annotation\">) -> <span class=\"n\">List</span><span class=\"p\">[</span><span class=\"n\">sglang</span><span class=\"o\">.</span><span class=\"n\">srt</span><span class=\"o\">.</span><span class=\"n\">harmony_parser</span><span class=\"o\">.</span><span class=\"n\">Event</span><span class=\"p\">]</span>:</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.hf_transformers_utils", "modulename": "sglang.srt.hf_transformers_utils", "kind": "module", "doc": "<p>Utilities for Huggingface Transformers.</p>\n"}, {"fullname": "sglang.srt.hf_transformers_utils.download_from_hf", "modulename": "sglang.srt.hf_transformers_utils", "qualname": "download_from_hf", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">model_path</span><span class=\"p\">:</span> <span class=\"nb\">str</span>, </span><span class=\"param\"><span class=\"n\">allow_patterns</span><span class=\"p\">:</span> <span class=\"n\">Union</span><span class=\"p\">[</span><span class=\"nb\">str</span><span class=\"p\">,</span> <span class=\"nb\">list</span><span class=\"p\">,</span> <span class=\"n\">NoneType</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.hf_transformers_utils.get_hf_text_config", "modulename": "sglang.srt.hf_transformers_utils", "qualname": "get_hf_text_config", "kind": "function", "doc": "<p>Get the \"sub\" config relevant to llm for multi modal models.\nNo op for pure text models.</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">config</span><span class=\"p\">:</span> <span class=\"n\">transformers</span><span class=\"o\">.</span><span class=\"n\">configuration_utils</span><span class=\"o\">.</span><span class=\"n\">PretrainedConfig</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.hf_transformers_utils.get_config", "modulename": "sglang.srt.hf_transformers_utils", "qualname": "get_config", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">model</span><span class=\"p\">:</span> <span class=\"nb\">str</span>,</span><span class=\"param\">\t<span class=\"n\">trust_remote_code</span><span class=\"p\">:</span> <span class=\"nb\">bool</span>,</span><span class=\"param\">\t<span class=\"n\">revision</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"nb\">str</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">model_override_args</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"nb\">dict</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"o\">**</span><span class=\"n\">kwargs</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.hf_transformers_utils.get_generation_config", "modulename": "sglang.srt.hf_transformers_utils", "qualname": "get_generation_config", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">model</span><span class=\"p\">:</span> <span class=\"nb\">str</span>,</span><span class=\"param\">\t<span class=\"n\">trust_remote_code</span><span class=\"p\">:</span> <span class=\"nb\">bool</span>,</span><span class=\"param\">\t<span class=\"n\">revision</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"nb\">str</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"o\">**</span><span class=\"n\">kwargs</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.hf_transformers_utils.get_sparse_attention_config", "modulename": "sglang.srt.hf_transformers_utils", "qualname": "get_sparse_attention_config", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">model</span><span class=\"p\">:</span> <span class=\"nb\">str</span>,</span><span class=\"param\">\t<span class=\"n\">sparse_attention_config_filename</span><span class=\"p\">:</span> <span class=\"nb\">str</span> <span class=\"o\">=</span> <span class=\"s1\">&#39;sparse_attention_config.json&#39;</span></span><span class=\"return-annotation\">) -> <span class=\"n\">Dict</span><span class=\"p\">[</span><span class=\"nb\">str</span><span class=\"p\">,</span> <span class=\"n\">Any</span><span class=\"p\">]</span>:</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.hf_transformers_utils.CONTEXT_LENGTH_KEYS", "modulename": "sglang.srt.hf_transformers_utils", "qualname": "CONTEXT_LENGTH_KEYS", "kind": "variable", "doc": "<p></p>\n", "default_value": "[&#x27;max_sequence_length&#x27;, &#x27;seq_length&#x27;, &#x27;max_seq_len&#x27;, &#x27;model_max_length&#x27;, &#x27;max_position_embeddings&#x27;]"}, {"fullname": "sglang.srt.hf_transformers_utils.get_context_length", "modulename": "sglang.srt.hf_transformers_utils", "qualname": "get_context_length", "kind": "function", "doc": "<p>Get the context length of a model from a huggingface model configs.</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">config</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.hf_transformers_utils.get_tokenizer", "modulename": "sglang.srt.hf_transformers_utils", "qualname": "get_tokenizer", "kind": "function", "doc": "<p>Gets a tokenizer for the given model name via Huggingface.</p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">tokenizer_name</span><span class=\"p\">:</span> <span class=\"nb\">str</span>,</span><span class=\"param\">\t<span class=\"o\">*</span><span class=\"n\">args</span>,</span><span class=\"param\">\t<span class=\"n\">tokenizer_mode</span><span class=\"p\">:</span> <span class=\"nb\">str</span> <span class=\"o\">=</span> <span class=\"s1\">&#39;auto&#39;</span>,</span><span class=\"param\">\t<span class=\"n\">trust_remote_code</span><span class=\"p\">:</span> <span class=\"nb\">bool</span> <span class=\"o\">=</span> <span class=\"kc\">False</span>,</span><span class=\"param\">\t<span class=\"n\">tokenizer_revision</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"nb\">str</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"o\">**</span><span class=\"n\">kwargs</span></span><span class=\"return-annotation\">) -> <span class=\"n\">Union</span><span class=\"p\">[</span><span class=\"n\">transformers</span><span class=\"o\">.</span><span class=\"n\">tokenization_utils</span><span class=\"o\">.</span><span class=\"n\">PreTrainedTokenizer</span><span class=\"p\">,</span> <span class=\"n\">transformers</span><span class=\"o\">.</span><span class=\"n\">tokenization_utils_fast</span><span class=\"o\">.</span><span class=\"n\">PreTrainedTokenizerFast</span><span class=\"p\">]</span>:</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.hf_transformers_utils.get_tokenizer_from_processor", "modulename": "sglang.srt.hf_transformers_utils", "qualname": "get_tokenizer_from_processor", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">processor</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.hf_transformers_utils.get_processor", "modulename": "sglang.srt.hf_transformers_utils", "qualname": "get_processor", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">tokenizer_name</span><span class=\"p\">:</span> <span class=\"nb\">str</span>,</span><span class=\"param\">\t<span class=\"o\">*</span><span class=\"n\">args</span>,</span><span class=\"param\">\t<span class=\"n\">tokenizer_mode</span><span class=\"p\">:</span> <span class=\"nb\">str</span> <span class=\"o\">=</span> <span class=\"s1\">&#39;auto&#39;</span>,</span><span class=\"param\">\t<span class=\"n\">trust_remote_code</span><span class=\"p\">:</span> <span class=\"nb\">bool</span> <span class=\"o\">=</span> <span class=\"kc\">False</span>,</span><span class=\"param\">\t<span class=\"n\">tokenizer_revision</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"nb\">str</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">use_fast</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"nb\">bool</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">True</span>,</span><span class=\"param\">\t<span class=\"o\">**</span><span class=\"n\">kwargs</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.hf_transformers_utils.attach_additional_stop_token_ids", "modulename": "sglang.srt.hf_transformers_utils", "qualname": "attach_additional_stop_token_ids", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">tokenizer</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.hf_transformers_utils.check_gguf_file", "modulename": "sglang.srt.hf_transformers_utils", "qualname": "check_gguf_file", "kind": "function", "doc": "<p>Check if the file is a GGUF model.</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">model</span><span class=\"p\">:</span> <span class=\"n\">Union</span><span class=\"p\">[</span><span class=\"nb\">str</span><span class=\"p\">,</span> <span class=\"n\">os</span><span class=\"o\">.</span><span class=\"n\">PathLike</span><span class=\"p\">]</span></span><span class=\"return-annotation\">) -> <span class=\"nb\">bool</span>:</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.host_shared_memory", "modulename": "sglang.srt.host_shared_memory", "kind": "module", "doc": "<p></p>\n"}, {"fullname": "sglang.srt.host_shared_memory.logger", "modulename": "sglang.srt.host_shared_memory", "qualname": "logger", "kind": "variable", "doc": "<p></p>\n", "default_value": "&lt;Logger sglang.srt.host_shared_memory (WARNING)&gt;"}, {"fullname": "sglang.srt.host_shared_memory.HostSharedMemoryManager", "modulename": "sglang.srt.host_shared_memory", "qualname": "HostSharedMemoryManager", "kind": "class", "doc": "<p></p>\n"}, {"fullname": "sglang.srt.host_shared_memory.HostSharedMemoryManager.__init__", "modulename": "sglang.srt.host_shared_memory", "qualname": "HostSharedMemoryManager.__init__", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">base_name</span><span class=\"p\">:</span> <span class=\"nb\">str</span></span>)</span>"}, {"fullname": "sglang.srt.host_shared_memory.HostSharedMemoryManager.malloc", "modulename": "sglang.srt.host_shared_memory", "qualname": "HostSharedMemoryManager.malloc", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"o\">*</span>, </span><span class=\"param\"><span class=\"n\">shape</span>, </span><span class=\"param\"><span class=\"n\">dtype</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.host_shared_memory.get_host_shared_memory_manager", "modulename": "sglang.srt.host_shared_memory", "qualname": "get_host_shared_memory_manager", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.host_shared_memory.set_host_shared_memory_manager", "modulename": "sglang.srt.host_shared_memory", "qualname": "set_host_shared_memory_manager", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">instance</span><span class=\"p\">:</span> <span class=\"n\">sglang</span><span class=\"o\">.</span><span class=\"n\">srt</span><span class=\"o\">.</span><span class=\"n\">host_shared_memory</span><span class=\"o\">.</span><span class=\"n\">HostSharedMemoryManager</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.jinja_template_utils", "modulename": "sglang.srt.jinja_template_utils", "kind": "module", "doc": "<p>Template utilities for Jinja template processing.</p>\n\n<p>This module provides utilities for analyzing and processing Jinja chat templates,\nincluding content format detection and message processing.</p>\n"}, {"fullname": "sglang.srt.jinja_template_utils.logger", "modulename": "sglang.srt.jinja_template_utils", "qualname": "logger", "kind": "variable", "doc": "<p></p>\n", "default_value": "&lt;Logger sglang.srt.jinja_template_utils (WARNING)&gt;"}, {"fullname": "sglang.srt.jinja_template_utils.detect_jinja_template_content_format", "modulename": "sglang.srt.jinja_template_utils", "qualname": "detect_jinja_template_content_format", "kind": "function", "doc": "<p>Detect whether a chat template expects 'string' or 'openai' content format.</p>\n\n<ul>\n<li>'string': content is a simple string (like DeepSeek templates)</li>\n<li>'openai': content is a list of structured dicts (like Llama4 templates)</li>\n</ul>\n\n<p>Detection logic:</p>\n\n<ul>\n<li>If template has loops like {%- for content in message['content'] -%} \u2192 'openai'</li>\n<li>Otherwise \u2192 'string'</li>\n</ul>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">chat_template</span><span class=\"p\">:</span> <span class=\"nb\">str</span></span><span class=\"return-annotation\">) -> <span class=\"nb\">str</span>:</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.jinja_template_utils.process_content_for_template_format", "modulename": "sglang.srt.jinja_template_utils", "qualname": "process_content_for_template_format", "kind": "function", "doc": "<p>Process message content based on detected template format.</p>\n\n<p>Args:\n    msg_dict: Message dictionary with content\n    content_format: 'string' or 'openai' (detected via AST analysis)\n    image_data: List to append extracted image URLs\n    video_data: List to append extracted video URLs\n    audio_data: List to append extracted audio URLs\n    modalities: List to append modalities</p>\n\n<p>Returns:\n    Processed message dictionary</p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">msg_dict</span><span class=\"p\">:</span> <span class=\"nb\">dict</span>,</span><span class=\"param\">\t<span class=\"n\">content_format</span><span class=\"p\">:</span> <span class=\"nb\">str</span>,</span><span class=\"param\">\t<span class=\"n\">image_data</span><span class=\"p\">:</span> <span class=\"nb\">list</span>,</span><span class=\"param\">\t<span class=\"n\">video_data</span><span class=\"p\">:</span> <span class=\"nb\">list</span>,</span><span class=\"param\">\t<span class=\"n\">audio_data</span><span class=\"p\">:</span> <span class=\"nb\">list</span>,</span><span class=\"param\">\t<span class=\"n\">modalities</span><span class=\"p\">:</span> <span class=\"nb\">list</span></span><span class=\"return-annotation\">) -> <span class=\"nb\">dict</span>:</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.model_loader", "modulename": "sglang.srt.model_loader", "kind": "module", "doc": "<p></p>\n"}, {"fullname": "sglang.srt.model_loader.get_model", "modulename": "sglang.srt.model_loader", "qualname": "get_model", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"o\">*</span>,</span><span class=\"param\">\t<span class=\"n\">model_config</span><span class=\"p\">:</span> <span class=\"n\">sglang</span><span class=\"o\">.</span><span class=\"n\">srt</span><span class=\"o\">.</span><span class=\"n\">configs</span><span class=\"o\">.</span><span class=\"n\">model_config</span><span class=\"o\">.</span><span class=\"n\">ModelConfig</span>,</span><span class=\"param\">\t<span class=\"n\">load_config</span><span class=\"p\">:</span> <span class=\"n\">sglang</span><span class=\"o\">.</span><span class=\"n\">srt</span><span class=\"o\">.</span><span class=\"n\">configs</span><span class=\"o\">.</span><span class=\"n\">load_config</span><span class=\"o\">.</span><span class=\"n\">LoadConfig</span>,</span><span class=\"param\">\t<span class=\"n\">device_config</span><span class=\"p\">:</span> <span class=\"n\">sglang</span><span class=\"o\">.</span><span class=\"n\">srt</span><span class=\"o\">.</span><span class=\"n\">configs</span><span class=\"o\">.</span><span class=\"n\">device_config</span><span class=\"o\">.</span><span class=\"n\">DeviceConfig</span></span><span class=\"return-annotation\">) -> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">nn</span><span class=\"o\">.</span><span class=\"n\">modules</span><span class=\"o\">.</span><span class=\"n\">module</span><span class=\"o\">.</span><span class=\"n\">Module</span>:</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.model_loader.get_model_loader", "modulename": "sglang.srt.model_loader", "qualname": "get_model_loader", "kind": "function", "doc": "<p>Get a model loader based on the load format.</p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">load_config</span><span class=\"p\">:</span> <span class=\"n\">sglang</span><span class=\"o\">.</span><span class=\"n\">srt</span><span class=\"o\">.</span><span class=\"n\">configs</span><span class=\"o\">.</span><span class=\"n\">load_config</span><span class=\"o\">.</span><span class=\"n\">LoadConfig</span></span><span class=\"return-annotation\">) -> <span class=\"n\">sglang</span><span class=\"o\">.</span><span class=\"n\">srt</span><span class=\"o\">.</span><span class=\"n\">model_loader</span><span class=\"o\">.</span><span class=\"n\">loader</span><span class=\"o\">.</span><span class=\"n\">BaseModelLoader</span>:</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.model_loader.BaseModelLoader", "modulename": "sglang.srt.model_loader", "qualname": "BaseModelLoader", "kind": "class", "doc": "<p>Base class for model loaders.</p>\n", "bases": "abc.ABC"}, {"fullname": "sglang.srt.model_loader.BaseModelLoader.load_config", "modulename": "sglang.srt.model_loader", "qualname": "BaseModelLoader.load_config", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "sglang.srt.model_loader.BaseModelLoader.download_model", "modulename": "sglang.srt.model_loader", "qualname": "BaseModelLoader.download_model", "kind": "function", "doc": "<p>Download a model so that it can be immediately loaded.</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">model_config</span><span class=\"p\">:</span> <span class=\"n\">sglang</span><span class=\"o\">.</span><span class=\"n\">srt</span><span class=\"o\">.</span><span class=\"n\">configs</span><span class=\"o\">.</span><span class=\"n\">model_config</span><span class=\"o\">.</span><span class=\"n\">ModelConfig</span></span><span class=\"return-annotation\">) -> <span class=\"kc\">None</span>:</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.model_loader.BaseModelLoader.load_model", "modulename": "sglang.srt.model_loader", "qualname": "BaseModelLoader.load_model", "kind": "function", "doc": "<p>Load a model with the given configurations.</p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"bp\">self</span>,</span><span class=\"param\">\t<span class=\"o\">*</span>,</span><span class=\"param\">\t<span class=\"n\">model_config</span><span class=\"p\">:</span> <span class=\"n\">sglang</span><span class=\"o\">.</span><span class=\"n\">srt</span><span class=\"o\">.</span><span class=\"n\">configs</span><span class=\"o\">.</span><span class=\"n\">model_config</span><span class=\"o\">.</span><span class=\"n\">ModelConfig</span>,</span><span class=\"param\">\t<span class=\"n\">device_config</span><span class=\"p\">:</span> <span class=\"n\">sglang</span><span class=\"o\">.</span><span class=\"n\">srt</span><span class=\"o\">.</span><span class=\"n\">configs</span><span class=\"o\">.</span><span class=\"n\">device_config</span><span class=\"o\">.</span><span class=\"n\">DeviceConfig</span></span><span class=\"return-annotation\">) -> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">nn</span><span class=\"o\">.</span><span class=\"n\">modules</span><span class=\"o\">.</span><span class=\"n\">module</span><span class=\"o\">.</span><span class=\"n\">Module</span>:</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.model_loader.get_architecture_class_name", "modulename": "sglang.srt.model_loader", "qualname": "get_architecture_class_name", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">model_config</span><span class=\"p\">:</span> <span class=\"n\">sglang</span><span class=\"o\">.</span><span class=\"n\">srt</span><span class=\"o\">.</span><span class=\"n\">configs</span><span class=\"o\">.</span><span class=\"n\">model_config</span><span class=\"o\">.</span><span class=\"n\">ModelConfig</span></span><span class=\"return-annotation\">) -> <span class=\"nb\">str</span>:</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.model_loader.get_model_architecture", "modulename": "sglang.srt.model_loader", "qualname": "get_model_architecture", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">model_config</span><span class=\"p\">:</span> <span class=\"n\">sglang</span><span class=\"o\">.</span><span class=\"n\">srt</span><span class=\"o\">.</span><span class=\"n\">configs</span><span class=\"o\">.</span><span class=\"n\">model_config</span><span class=\"o\">.</span><span class=\"n\">ModelConfig</span></span><span class=\"return-annotation\">) -> <span class=\"n\">Tuple</span><span class=\"p\">[</span><span class=\"n\">Type</span><span class=\"p\">[</span><span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">nn</span><span class=\"o\">.</span><span class=\"n\">modules</span><span class=\"o\">.</span><span class=\"n\">module</span><span class=\"o\">.</span><span class=\"n\">Module</span><span class=\"p\">],</span> <span class=\"nb\">str</span><span class=\"p\">]</span>:</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.model_parallel", "modulename": "sglang.srt.model_parallel", "kind": "module", "doc": "<p>Common utilities for torch model parallelism.</p>\n"}, {"fullname": "sglang.srt.model_parallel.ColwiseParallelSharded", "modulename": "sglang.srt.model_parallel", "qualname": "ColwiseParallelSharded", "kind": "class", "doc": "<p>A version of ColwiseParallel where the local weight has been already\nsharded.  This is used for the fused wqkv case, where during loading, we\nalready sharded wq, wk, wv before fusing them.</p>\n", "bases": "torch.distributed.tensor.parallel.style.ColwiseParallel"}, {"fullname": "sglang.srt.model_parallel.RowwiseParallelMaybeWait", "modulename": "sglang.srt.model_parallel", "qualname": "RowwiseParallelMaybeWait", "kind": "class", "doc": "<p>A version of RowwiseParallel that waits for the output (establish dependency\nbetween comm stream and compute stream in CUDA sense) before going into the\nnext op. This is needed to workaround the current interaction between\nAsyncCollectiveTensor and custom ops, such as <code>class RMSNorm(CustomOp)</code>.</p>\n", "bases": "torch.distributed.tensor.parallel.style.RowwiseParallel"}, {"fullname": "sglang.srt.model_parallel.tensor_parallel", "modulename": "sglang.srt.model_parallel", "qualname": "tensor_parallel", "kind": "function", "doc": "<p>Tensor parallelize the model across the given device mesh.\nArgs:\n    module (<code>torch.nn.Module</code>):\n        The module to tensor parallelize.\n    device_mesh (<code>torch.distributed.DeviceMesh</code>):\n        The device mesh to use for tensor parallelism.</p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">module</span><span class=\"p\">:</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">nn</span><span class=\"o\">.</span><span class=\"n\">modules</span><span class=\"o\">.</span><span class=\"n\">module</span><span class=\"o\">.</span><span class=\"n\">Module</span>,</span><span class=\"param\">\t<span class=\"n\">device_mesh</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">distributed</span><span class=\"o\">.</span><span class=\"n\">device_mesh</span><span class=\"o\">.</span><span class=\"n\">DeviceMesh</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.offloader", "modulename": "sglang.srt.offloader", "kind": "module", "doc": "<p></p>\n"}, {"fullname": "sglang.srt.offloader.logger", "modulename": "sglang.srt.offloader", "qualname": "logger", "kind": "variable", "doc": "<p></p>\n", "default_value": "&lt;Logger sglang.srt.offloader (WARNING)&gt;"}, {"fullname": "sglang.srt.offloader.BaseOffloader", "modulename": "sglang.srt.offloader", "qualname": "BaseOffloader", "kind": "class", "doc": "<p>Helper class that provides a standard way to create an ABC using\ninheritance.</p>\n", "bases": "abc.ABC"}, {"fullname": "sglang.srt.offloader.BaseOffloader.wrap_modules", "modulename": "sglang.srt.offloader", "qualname": "BaseOffloader.wrap_modules", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"bp\">self</span>,</span><span class=\"param\">\t<span class=\"n\">all_modules_generator</span><span class=\"p\">:</span> <span class=\"n\">Generator</span><span class=\"p\">[</span><span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">nn</span><span class=\"o\">.</span><span class=\"n\">modules</span><span class=\"o\">.</span><span class=\"n\">module</span><span class=\"o\">.</span><span class=\"n\">Module</span><span class=\"p\">,</span> <span class=\"n\">NoneType</span><span class=\"p\">,</span> <span class=\"n\">NoneType</span><span class=\"p\">]</span>,</span><span class=\"param\">\t<span class=\"n\">submodule_accessor</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"n\">Callable</span><span class=\"p\">[[</span><span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">nn</span><span class=\"o\">.</span><span class=\"n\">modules</span><span class=\"o\">.</span><span class=\"n\">module</span><span class=\"o\">.</span><span class=\"n\">Module</span><span class=\"p\">],</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">nn</span><span class=\"o\">.</span><span class=\"n\">modules</span><span class=\"o\">.</span><span class=\"n\">module</span><span class=\"o\">.</span><span class=\"n\">Module</span><span class=\"p\">]]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">whitelist_param_names_creator</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"n\">Callable</span><span class=\"p\">[[</span><span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">nn</span><span class=\"o\">.</span><span class=\"n\">modules</span><span class=\"o\">.</span><span class=\"n\">module</span><span class=\"o\">.</span><span class=\"n\">Module</span><span class=\"p\">],</span> <span class=\"n\">List</span><span class=\"p\">[</span><span class=\"nb\">str</span><span class=\"p\">]]]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.offloader.BaseOffloader.post_init", "modulename": "sglang.srt.offloader", "qualname": "BaseOffloader.post_init", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.offloader.NoopOffloader", "modulename": "sglang.srt.offloader", "qualname": "NoopOffloader", "kind": "class", "doc": "<p>Helper class that provides a standard way to create an ABC using\ninheritance.</p>\n", "bases": "BaseOffloader"}, {"fullname": "sglang.srt.offloader.get_offloader", "modulename": "sglang.srt.offloader", "qualname": "get_offloader", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.offloader.set_offloader", "modulename": "sglang.srt.offloader", "qualname": "set_offloader", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">instance</span><span class=\"p\">:</span> <span class=\"n\">sglang</span><span class=\"o\">.</span><span class=\"n\">srt</span><span class=\"o\">.</span><span class=\"n\">offloader</span><span class=\"o\">.</span><span class=\"n\">BaseOffloader</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.offloader.create_offloader_from_server_args", "modulename": "sglang.srt.offloader", "qualname": "create_offloader_from_server_args", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">server_args</span><span class=\"p\">:</span> <span class=\"n\">sglang</span><span class=\"o\">.</span><span class=\"n\">srt</span><span class=\"o\">.</span><span class=\"n\">server_args</span><span class=\"o\">.</span><span class=\"n\">ServerArgs</span>, </span><span class=\"param\"><span class=\"n\">dp_rank</span><span class=\"p\">:</span> <span class=\"nb\">int</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.offloader.OffloaderV1", "modulename": "sglang.srt.offloader", "qualname": "OffloaderV1", "kind": "class", "doc": "<p>Helper class that provides a standard way to create an ABC using\ninheritance.</p>\n", "bases": "BaseOffloader"}, {"fullname": "sglang.srt.offloader.OffloaderV1.__init__", "modulename": "sglang.srt.offloader", "qualname": "OffloaderV1.__init__", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">cpu_offload_max_bytes</span><span class=\"p\">:</span> <span class=\"nb\">int</span></span>)</span>"}, {"fullname": "sglang.srt.offloader.OffloaderV1.wrap_modules", "modulename": "sglang.srt.offloader", "qualname": "OffloaderV1.wrap_modules", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"bp\">self</span>,</span><span class=\"param\">\t<span class=\"n\">all_modules_generator</span><span class=\"p\">:</span> <span class=\"n\">Generator</span><span class=\"p\">[</span><span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">nn</span><span class=\"o\">.</span><span class=\"n\">modules</span><span class=\"o\">.</span><span class=\"n\">module</span><span class=\"o\">.</span><span class=\"n\">Module</span><span class=\"p\">,</span> <span class=\"n\">NoneType</span><span class=\"p\">,</span> <span class=\"n\">NoneType</span><span class=\"p\">]</span>,</span><span class=\"param\">\t<span class=\"n\">submodule_accessor</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"n\">Callable</span><span class=\"p\">[[</span><span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">nn</span><span class=\"o\">.</span><span class=\"n\">modules</span><span class=\"o\">.</span><span class=\"n\">module</span><span class=\"o\">.</span><span class=\"n\">Module</span><span class=\"p\">],</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">nn</span><span class=\"o\">.</span><span class=\"n\">modules</span><span class=\"o\">.</span><span class=\"n\">module</span><span class=\"o\">.</span><span class=\"n\">Module</span><span class=\"p\">]]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">whitelist_param_names_creator</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"n\">Callable</span><span class=\"p\">[[</span><span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">nn</span><span class=\"o\">.</span><span class=\"n\">modules</span><span class=\"o\">.</span><span class=\"n\">module</span><span class=\"o\">.</span><span class=\"n\">Module</span><span class=\"p\">],</span> <span class=\"n\">List</span><span class=\"p\">[</span><span class=\"nb\">str</span><span class=\"p\">]]]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.offloader.OffloaderV1.maybe_offload_to_cpu", "modulename": "sglang.srt.offloader", "qualname": "OffloaderV1.maybe_offload_to_cpu", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"bp\">self</span>,</span><span class=\"param\">\t<span class=\"n\">module</span><span class=\"p\">:</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">nn</span><span class=\"o\">.</span><span class=\"n\">modules</span><span class=\"o\">.</span><span class=\"n\">module</span><span class=\"o\">.</span><span class=\"n\">Module</span></span><span class=\"return-annotation\">) -> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">nn</span><span class=\"o\">.</span><span class=\"n\">modules</span><span class=\"o\">.</span><span class=\"n\">module</span><span class=\"o\">.</span><span class=\"n\">Module</span>:</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.offloader.OffloaderV2", "modulename": "sglang.srt.offloader", "qualname": "OffloaderV2", "kind": "class", "doc": "<p>Helper class that provides a standard way to create an ABC using\ninheritance.</p>\n", "bases": "BaseOffloader"}, {"fullname": "sglang.srt.offloader.OffloaderV2.__init__", "modulename": "sglang.srt.offloader", "qualname": "OffloaderV2.__init__", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">group_size</span><span class=\"p\">:</span> <span class=\"nb\">int</span>,</span><span class=\"param\">\t<span class=\"n\">num_in_group</span><span class=\"p\">:</span> <span class=\"nb\">int</span>,</span><span class=\"param\">\t<span class=\"n\">prefetch_step</span><span class=\"p\">:</span> <span class=\"nb\">int</span>,</span><span class=\"param\">\t<span class=\"n\">mode</span><span class=\"p\">:</span> <span class=\"nb\">str</span>,</span><span class=\"param\">\t<span class=\"n\">dp_rank</span><span class=\"p\">:</span> <span class=\"nb\">int</span>,</span><span class=\"param\">\t<span class=\"n\">dp_size</span><span class=\"p\">:</span> <span class=\"nb\">int</span></span>)</span>"}, {"fullname": "sglang.srt.offloader.OffloaderV2.group_size", "modulename": "sglang.srt.offloader", "qualname": "OffloaderV2.group_size", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "sglang.srt.offloader.OffloaderV2.num_in_group", "modulename": "sglang.srt.offloader", "qualname": "OffloaderV2.num_in_group", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "sglang.srt.offloader.OffloaderV2.prefetch_step", "modulename": "sglang.srt.offloader", "qualname": "OffloaderV2.prefetch_step", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "sglang.srt.offloader.OffloaderV2.mode", "modulename": "sglang.srt.offloader", "qualname": "OffloaderV2.mode", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "sglang.srt.offloader.OffloaderV2.offloaders", "modulename": "sglang.srt.offloader", "qualname": "OffloaderV2.offloaders", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "sglang.srt.offloader.OffloaderV2.wrap_modules", "modulename": "sglang.srt.offloader", "qualname": "OffloaderV2.wrap_modules", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"bp\">self</span>,</span><span class=\"param\">\t<span class=\"n\">all_modules_generator</span><span class=\"p\">:</span> <span class=\"n\">Generator</span><span class=\"p\">[</span><span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">nn</span><span class=\"o\">.</span><span class=\"n\">modules</span><span class=\"o\">.</span><span class=\"n\">module</span><span class=\"o\">.</span><span class=\"n\">Module</span><span class=\"p\">,</span> <span class=\"n\">NoneType</span><span class=\"p\">,</span> <span class=\"n\">NoneType</span><span class=\"p\">]</span>,</span><span class=\"param\">\t<span class=\"n\">submodule_accessor</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"n\">Callable</span><span class=\"p\">[[</span><span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">nn</span><span class=\"o\">.</span><span class=\"n\">modules</span><span class=\"o\">.</span><span class=\"n\">module</span><span class=\"o\">.</span><span class=\"n\">Module</span><span class=\"p\">],</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">nn</span><span class=\"o\">.</span><span class=\"n\">modules</span><span class=\"o\">.</span><span class=\"n\">module</span><span class=\"o\">.</span><span class=\"n\">Module</span><span class=\"p\">]]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">whitelist_param_names_creator</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"n\">Callable</span><span class=\"p\">[[</span><span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">nn</span><span class=\"o\">.</span><span class=\"n\">modules</span><span class=\"o\">.</span><span class=\"n\">module</span><span class=\"o\">.</span><span class=\"n\">Module</span><span class=\"p\">],</span> <span class=\"n\">List</span><span class=\"p\">[</span><span class=\"nb\">str</span><span class=\"p\">]]]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.offloader.OffloaderV2.post_init", "modulename": "sglang.srt.offloader", "qualname": "OffloaderV2.post_init", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.operations", "modulename": "sglang.srt.operations", "kind": "module", "doc": "<p></p>\n"}, {"fullname": "sglang.srt.operations.execute_operations", "modulename": "sglang.srt.operations", "qualname": "execute_operations", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">inputs</span>, </span><span class=\"param\"><span class=\"n\">operations</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.operations.execute_overlapped_operations", "modulename": "sglang.srt.operations", "qualname": "execute_overlapped_operations", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">inputs_arr</span><span class=\"p\">:</span> <span class=\"n\">Sequence</span>,</span><span class=\"param\">\t<span class=\"n\">operations_arr</span><span class=\"p\">:</span> <span class=\"n\">Sequence</span>,</span><span class=\"param\">\t<span class=\"n\">delta_stages</span><span class=\"p\">:</span> <span class=\"n\">Sequence</span><span class=\"p\">[</span><span class=\"nb\">int</span><span class=\"p\">]</span></span><span class=\"return-annotation\">) -> <span class=\"n\">Sequence</span>:</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.operations.YieldOperation", "modulename": "sglang.srt.operations", "qualname": "YieldOperation", "kind": "class", "doc": "<p></p>\n"}, {"fullname": "sglang.srt.operations.ExecutionOperation", "modulename": "sglang.srt.operations", "qualname": "ExecutionOperation", "kind": "class", "doc": "<p></p>\n"}, {"fullname": "sglang.srt.operations.ExecutionOperation.__init__", "modulename": "sglang.srt.operations", "qualname": "ExecutionOperation.__init__", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">debug_name</span><span class=\"p\">:</span> <span class=\"nb\">str</span>, </span><span class=\"param\"><span class=\"n\">fn</span><span class=\"p\">:</span> <span class=\"n\">Callable</span></span>)</span>"}, {"fullname": "sglang.srt.operations.ExecutionOperation.debug_name", "modulename": "sglang.srt.operations", "qualname": "ExecutionOperation.debug_name", "kind": "variable", "doc": "<p></p>\n", "annotation": ": str"}, {"fullname": "sglang.srt.operations.ExecutionOperation.fn", "modulename": "sglang.srt.operations", "qualname": "ExecutionOperation.fn", "kind": "variable", "doc": "<p></p>\n", "annotation": ": Callable"}, {"fullname": "sglang.srt.operations.Operation", "modulename": "sglang.srt.operations", "qualname": "Operation", "kind": "variable", "doc": "<p></p>\n", "default_value": "typing.Union[sglang.srt.operations.YieldOperation, sglang.srt.operations.ExecutionOperation, typing.Callable]"}, {"fullname": "sglang.srt.operations.Stage", "modulename": "sglang.srt.operations", "qualname": "Stage", "kind": "variable", "doc": "<p></p>\n", "default_value": "typing.List[sglang.srt.operations.ExecutionOperation]"}, {"fullname": "sglang.srt.operations_strategy", "modulename": "sglang.srt.operations_strategy", "kind": "module", "doc": "<p></p>\n"}, {"fullname": "sglang.srt.operations_strategy.OperationsStrategy", "modulename": "sglang.srt.operations_strategy", "qualname": "OperationsStrategy", "kind": "class", "doc": "<p></p>\n"}, {"fullname": "sglang.srt.operations_strategy.OperationsStrategy.__init__", "modulename": "sglang.srt.operations_strategy", "qualname": "OperationsStrategy.__init__", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">operations</span><span class=\"p\">:</span> <span class=\"n\">List</span><span class=\"p\">[</span><span class=\"n\">Union</span><span class=\"p\">[</span><span class=\"n\">sglang</span><span class=\"o\">.</span><span class=\"n\">srt</span><span class=\"o\">.</span><span class=\"n\">operations</span><span class=\"o\">.</span><span class=\"n\">YieldOperation</span><span class=\"p\">,</span> <span class=\"n\">sglang</span><span class=\"o\">.</span><span class=\"n\">srt</span><span class=\"o\">.</span><span class=\"n\">operations</span><span class=\"o\">.</span><span class=\"n\">ExecutionOperation</span><span class=\"p\">,</span> <span class=\"n\">Callable</span><span class=\"p\">]]</span>,</span><span class=\"param\">\t<span class=\"n\">deep_gemm_num_sms</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"nb\">int</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">tbo_delta_stages</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"nb\">int</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span></span>)</span>"}, {"fullname": "sglang.srt.operations_strategy.OperationsStrategy.operations", "modulename": "sglang.srt.operations_strategy", "qualname": "OperationsStrategy.operations", "kind": "variable", "doc": "<p></p>\n", "annotation": ": List[Union[sglang.srt.operations.YieldOperation, sglang.srt.operations.ExecutionOperation, Callable]]"}, {"fullname": "sglang.srt.operations_strategy.OperationsStrategy.deep_gemm_num_sms", "modulename": "sglang.srt.operations_strategy", "qualname": "OperationsStrategy.deep_gemm_num_sms", "kind": "variable", "doc": "<p></p>\n", "annotation": ": Optional[int]", "default_value": "None"}, {"fullname": "sglang.srt.operations_strategy.OperationsStrategy.tbo_delta_stages", "modulename": "sglang.srt.operations_strategy", "qualname": "OperationsStrategy.tbo_delta_stages", "kind": "variable", "doc": "<p></p>\n", "annotation": ": Optional[int]", "default_value": "None"}, {"fullname": "sglang.srt.operations_strategy.OperationsStrategy.concat", "modulename": "sglang.srt.operations_strategy", "qualname": "OperationsStrategy.concat", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"bp\">cls</span>,</span><span class=\"param\">\t<span class=\"n\">items</span><span class=\"p\">:</span> <span class=\"n\">List</span><span class=\"p\">[</span><span class=\"n\">sglang</span><span class=\"o\">.</span><span class=\"n\">srt</span><span class=\"o\">.</span><span class=\"n\">operations_strategy</span><span class=\"o\">.</span><span class=\"n\">OperationsStrategy</span><span class=\"p\">]</span></span><span class=\"return-annotation\">) -> <span class=\"n\">sglang</span><span class=\"o\">.</span><span class=\"n\">srt</span><span class=\"o\">.</span><span class=\"n\">operations_strategy</span><span class=\"o\">.</span><span class=\"n\">OperationsStrategy</span>:</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.operations_strategy.OperationsStrategy.init_new_tbo", "modulename": "sglang.srt.operations_strategy", "qualname": "OperationsStrategy.init_new_tbo", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">layers</span><span class=\"p\">:</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">nn</span><span class=\"o\">.</span><span class=\"n\">modules</span><span class=\"o\">.</span><span class=\"n\">container</span><span class=\"o\">.</span><span class=\"n\">ModuleList</span>,</span><span class=\"param\">\t<span class=\"n\">forward_mode</span><span class=\"p\">:</span> <span class=\"n\">sglang</span><span class=\"o\">.</span><span class=\"n\">srt</span><span class=\"o\">.</span><span class=\"n\">model_executor</span><span class=\"o\">.</span><span class=\"n\">forward_batch_info</span><span class=\"o\">.</span><span class=\"n\">ForwardMode</span></span><span class=\"return-annotation\">) -> <span class=\"n\">sglang</span><span class=\"o\">.</span><span class=\"n\">srt</span><span class=\"o\">.</span><span class=\"n\">operations_strategy</span><span class=\"o\">.</span><span class=\"n\">OperationsStrategy</span>:</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.patch_torch", "modulename": "sglang.srt.patch_torch", "kind": "module", "doc": "<p></p>\n"}, {"fullname": "sglang.srt.patch_torch.monkey_patch_torch_reductions", "modulename": "sglang.srt.patch_torch", "qualname": "monkey_patch_torch_reductions", "kind": "function", "doc": "<p>Monkey patching before Torch <a href=\"https://github.com/pytorch/pytorch/pull/149248\">https://github.com/pytorch/pytorch/pull/149248</a> is fixed</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.patch_torch.monkey_patch_torch_compile", "modulename": "sglang.srt.patch_torch", "qualname": "monkey_patch_torch_compile", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.poll_based_barrier", "modulename": "sglang.srt.poll_based_barrier", "kind": "module", "doc": "<p></p>\n"}, {"fullname": "sglang.srt.poll_based_barrier.PollBasedBarrier", "modulename": "sglang.srt.poll_based_barrier", "qualname": "PollBasedBarrier", "kind": "class", "doc": "<p></p>\n"}, {"fullname": "sglang.srt.poll_based_barrier.PollBasedBarrier.__init__", "modulename": "sglang.srt.poll_based_barrier", "qualname": "PollBasedBarrier.__init__", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">noop</span><span class=\"p\">:</span> <span class=\"nb\">bool</span> <span class=\"o\">=</span> <span class=\"kc\">False</span></span>)</span>"}, {"fullname": "sglang.srt.poll_based_barrier.PollBasedBarrier.local_arrive", "modulename": "sglang.srt.poll_based_barrier", "qualname": "PollBasedBarrier.local_arrive", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.poll_based_barrier.PollBasedBarrier.poll_global_arrived", "modulename": "sglang.srt.poll_based_barrier", "qualname": "PollBasedBarrier.poll_global_arrived", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span></span><span class=\"return-annotation\">) -> <span class=\"nb\">bool</span>:</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.reasoning_parser", "modulename": "sglang.srt.reasoning_parser", "kind": "module", "doc": "<p></p>\n"}, {"fullname": "sglang.srt.reasoning_parser.StreamingParseResult", "modulename": "sglang.srt.reasoning_parser", "qualname": "StreamingParseResult", "kind": "class", "doc": "<p>Result of streaming incremental parsing.</p>\n"}, {"fullname": "sglang.srt.reasoning_parser.StreamingParseResult.__init__", "modulename": "sglang.srt.reasoning_parser", "qualname": "StreamingParseResult.__init__", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">normal_text</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"nb\">str</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">reasoning_text</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"nb\">str</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span></span>)</span>"}, {"fullname": "sglang.srt.reasoning_parser.StreamingParseResult.normal_text", "modulename": "sglang.srt.reasoning_parser", "qualname": "StreamingParseResult.normal_text", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "sglang.srt.reasoning_parser.StreamingParseResult.reasoning_text", "modulename": "sglang.srt.reasoning_parser", "qualname": "StreamingParseResult.reasoning_text", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "sglang.srt.reasoning_parser.BaseReasoningFormatDetector", "modulename": "sglang.srt.reasoning_parser", "qualname": "BaseReasoningFormatDetector", "kind": "class", "doc": "<p>Base class providing two sets of interfaces: one-time and streaming incremental.</p>\n"}, {"fullname": "sglang.srt.reasoning_parser.BaseReasoningFormatDetector.__init__", "modulename": "sglang.srt.reasoning_parser", "qualname": "BaseReasoningFormatDetector.__init__", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">think_start_token</span><span class=\"p\">:</span> <span class=\"nb\">str</span>,</span><span class=\"param\">\t<span class=\"n\">think_end_token</span><span class=\"p\">:</span> <span class=\"nb\">str</span>,</span><span class=\"param\">\t<span class=\"n\">force_reasoning</span><span class=\"p\">:</span> <span class=\"nb\">bool</span> <span class=\"o\">=</span> <span class=\"kc\">False</span>,</span><span class=\"param\">\t<span class=\"n\">stream_reasoning</span><span class=\"p\">:</span> <span class=\"nb\">bool</span> <span class=\"o\">=</span> <span class=\"kc\">True</span></span>)</span>"}, {"fullname": "sglang.srt.reasoning_parser.BaseReasoningFormatDetector.think_start_token", "modulename": "sglang.srt.reasoning_parser", "qualname": "BaseReasoningFormatDetector.think_start_token", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "sglang.srt.reasoning_parser.BaseReasoningFormatDetector.think_end_token", "modulename": "sglang.srt.reasoning_parser", "qualname": "BaseReasoningFormatDetector.think_end_token", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "sglang.srt.reasoning_parser.BaseReasoningFormatDetector.stream_reasoning", "modulename": "sglang.srt.reasoning_parser", "qualname": "BaseReasoningFormatDetector.stream_reasoning", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "sglang.srt.reasoning_parser.BaseReasoningFormatDetector.stripped_think_start", "modulename": "sglang.srt.reasoning_parser", "qualname": "BaseReasoningFormatDetector.stripped_think_start", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "sglang.srt.reasoning_parser.BaseReasoningFormatDetector.detect_and_parse", "modulename": "sglang.srt.reasoning_parser", "qualname": "BaseReasoningFormatDetector.detect_and_parse", "kind": "function", "doc": "<p>One-time parsing: Detects and parses reasoning sections in the provided text.\nReturns both reasoning content and normal text separately.</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">text</span><span class=\"p\">:</span> <span class=\"nb\">str</span></span><span class=\"return-annotation\">) -> <span class=\"n\">sglang</span><span class=\"o\">.</span><span class=\"n\">srt</span><span class=\"o\">.</span><span class=\"n\">reasoning_parser</span><span class=\"o\">.</span><span class=\"n\">StreamingParseResult</span>:</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.reasoning_parser.BaseReasoningFormatDetector.parse_streaming_increment", "modulename": "sglang.srt.reasoning_parser", "qualname": "BaseReasoningFormatDetector.parse_streaming_increment", "kind": "function", "doc": "<p>Streaming incremental parsing for reasoning content.\nHandles partial reasoning tags and content.</p>\n\n<p>If stream_reasoning is False:\n    Accumulates reasoning content until the end tag is found\nIf stream_reasoning is True:\n    Streams reasoning content as it arrives</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">new_text</span><span class=\"p\">:</span> <span class=\"nb\">str</span></span><span class=\"return-annotation\">) -> <span class=\"n\">sglang</span><span class=\"o\">.</span><span class=\"n\">srt</span><span class=\"o\">.</span><span class=\"n\">reasoning_parser</span><span class=\"o\">.</span><span class=\"n\">StreamingParseResult</span>:</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.reasoning_parser.DeepSeekR1Detector", "modulename": "sglang.srt.reasoning_parser", "qualname": "DeepSeekR1Detector", "kind": "class", "doc": "<p>Detector for DeepSeek-R1 model.\nAssumes reasoning format:\n  (<think>)<em>(.</em>)</think>\nReturns all the text before the </think> tag as <code>reasoning_text</code>\nand the rest of the text as <code>normal_text</code>.</p>\n\n<p>Supported models:</p>\n\n<ul>\n<li>DeepSeek-R1: Always generates thinking content without <think> start tag</li>\n<li>DeepSeek-R1-0528: Generates thinking content with <think> start tag</li>\n</ul>\n\n<p>Format patterns:</p>\n\n<ul>\n<li>DeepSeek-R1: \"I need to think about this...</think>The answer is 42.\"</li>\n<li>DeepSeek-R1-0528: \"<think>I need to think about this...</think>The answer is 42.\"</li>\n</ul>\n\n<p>Args:\n    stream_reasoning (bool): If False, accumulates reasoning content until the end tag.\n        If True, streams reasoning content as it arrives.</p>\n", "bases": "BaseReasoningFormatDetector"}, {"fullname": "sglang.srt.reasoning_parser.DeepSeekR1Detector.__init__", "modulename": "sglang.srt.reasoning_parser", "qualname": "DeepSeekR1Detector.__init__", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">stream_reasoning</span><span class=\"p\">:</span> <span class=\"nb\">bool</span> <span class=\"o\">=</span> <span class=\"kc\">True</span>, </span><span class=\"param\"><span class=\"n\">force_reasoning</span><span class=\"p\">:</span> <span class=\"nb\">bool</span> <span class=\"o\">=</span> <span class=\"kc\">True</span></span>)</span>"}, {"fullname": "sglang.srt.reasoning_parser.Qwen3Detector", "modulename": "sglang.srt.reasoning_parser", "qualname": "Qwen3Detector", "kind": "class", "doc": "<p>Detector for Qwen3 models (e.g., Qwen/Qwen3-235B-A22B).\nAssumes reasoning format:\n  (<think>)<em>(.</em>)</think></p>\n\n<p>Qwen3 models released before 07/2025 supports switching between thinking mode and normal\nmode using <code>enable_thinking</code> parameter in the request parameter.</p>\n\n<ul>\n<li>enable_thinking=True: \"<think>reasoning content</think>The answer is 42.\"</li>\n<li>enable_thinking=False: \"The answer is 42.\" (no thinking tokens)</li>\n</ul>\n\n<p>Args:\n    stream_reasoning (bool): If False, accumulates reasoning content until the end tag.\n        If True, streams reasoning content as it arrives.</p>\n", "bases": "BaseReasoningFormatDetector"}, {"fullname": "sglang.srt.reasoning_parser.Qwen3Detector.__init__", "modulename": "sglang.srt.reasoning_parser", "qualname": "Qwen3Detector.__init__", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">stream_reasoning</span><span class=\"p\">:</span> <span class=\"nb\">bool</span> <span class=\"o\">=</span> <span class=\"kc\">True</span>, </span><span class=\"param\"><span class=\"n\">force_reasoning</span><span class=\"p\">:</span> <span class=\"nb\">bool</span> <span class=\"o\">=</span> <span class=\"kc\">False</span></span>)</span>"}, {"fullname": "sglang.srt.reasoning_parser.KimiDetector", "modulename": "sglang.srt.reasoning_parser", "qualname": "KimiDetector", "kind": "class", "doc": "<p>Detector for Kimi Thinking model.\nAssumes reasoning format:\n  \u25c1think\u25b7<em>(.</em>)\u25c1/think\u25b7\nReturns all the text before the \u25c1/think\u25b7 tag as <code>reasoning_text</code>\nand the rest of the text as <code>normal_text</code>.</p>\n", "bases": "BaseReasoningFormatDetector"}, {"fullname": "sglang.srt.reasoning_parser.KimiDetector.__init__", "modulename": "sglang.srt.reasoning_parser", "qualname": "KimiDetector.__init__", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">stream_reasoning</span><span class=\"p\">:</span> <span class=\"nb\">bool</span> <span class=\"o\">=</span> <span class=\"kc\">True</span>, </span><span class=\"param\"><span class=\"n\">force_reasoning</span><span class=\"p\">:</span> <span class=\"nb\">bool</span> <span class=\"o\">=</span> <span class=\"kc\">False</span></span>)</span>"}, {"fullname": "sglang.srt.reasoning_parser.GptOssDetector", "modulename": "sglang.srt.reasoning_parser", "qualname": "GptOssDetector", "kind": "class", "doc": "<p>Detector for T4-style reasoning format (GPT-OSS), using the HarmonyParser.</p>\n", "bases": "BaseReasoningFormatDetector"}, {"fullname": "sglang.srt.reasoning_parser.GptOssDetector.__init__", "modulename": "sglang.srt.reasoning_parser", "qualname": "GptOssDetector.__init__", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">stream_reasoning</span><span class=\"p\">:</span> <span class=\"nb\">bool</span> <span class=\"o\">=</span> <span class=\"kc\">True</span>, </span><span class=\"param\"><span class=\"n\">force_reasoning</span><span class=\"p\">:</span> <span class=\"nb\">bool</span> <span class=\"o\">=</span> <span class=\"kc\">True</span></span>)</span>"}, {"fullname": "sglang.srt.reasoning_parser.GptOssDetector.parser", "modulename": "sglang.srt.reasoning_parser", "qualname": "GptOssDetector.parser", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "sglang.srt.reasoning_parser.GptOssDetector.detect_and_parse", "modulename": "sglang.srt.reasoning_parser", "qualname": "GptOssDetector.detect_and_parse", "kind": "function", "doc": "<p>One-time parsing: Detects and parses reasoning sections in the provided text.\nReturns both reasoning content and normal text separately.</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">text</span><span class=\"p\">:</span> <span class=\"nb\">str</span></span><span class=\"return-annotation\">) -> <span class=\"n\">sglang</span><span class=\"o\">.</span><span class=\"n\">srt</span><span class=\"o\">.</span><span class=\"n\">reasoning_parser</span><span class=\"o\">.</span><span class=\"n\">StreamingParseResult</span>:</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.reasoning_parser.GptOssDetector.parse_streaming_increment", "modulename": "sglang.srt.reasoning_parser", "qualname": "GptOssDetector.parse_streaming_increment", "kind": "function", "doc": "<p>Streaming incremental parsing for reasoning content.\nHandles partial reasoning tags and content.</p>\n\n<p>If stream_reasoning is False:\n    Accumulates reasoning content until the end tag is found\nIf stream_reasoning is True:\n    Streams reasoning content as it arrives</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">new_text</span><span class=\"p\">:</span> <span class=\"nb\">str</span></span><span class=\"return-annotation\">) -> <span class=\"n\">sglang</span><span class=\"o\">.</span><span class=\"n\">srt</span><span class=\"o\">.</span><span class=\"n\">reasoning_parser</span><span class=\"o\">.</span><span class=\"n\">StreamingParseResult</span>:</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.reasoning_parser.ReasoningParser", "modulename": "sglang.srt.reasoning_parser", "qualname": "ReasoningParser", "kind": "class", "doc": "<p>Parser that handles both streaming and non-streaming scenarios for extracting\nreasoning content from model outputs.</p>\n\n<p>Args:\n    model_type (str): Type of model to parse reasoning from\n    stream_reasoning (bool): If False, accumulates reasoning content until complete.\n        If True, streams reasoning content as it arrives.</p>\n"}, {"fullname": "sglang.srt.reasoning_parser.ReasoningParser.__init__", "modulename": "sglang.srt.reasoning_parser", "qualname": "ReasoningParser.__init__", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">model_type</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"nb\">str</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">stream_reasoning</span><span class=\"p\">:</span> <span class=\"nb\">bool</span> <span class=\"o\">=</span> <span class=\"kc\">True</span>,</span><span class=\"param\">\t<span class=\"n\">force_reasoning</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"nb\">bool</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span></span>)</span>"}, {"fullname": "sglang.srt.reasoning_parser.ReasoningParser.DetectorMap", "modulename": "sglang.srt.reasoning_parser", "qualname": "ReasoningParser.DetectorMap", "kind": "variable", "doc": "<p></p>\n", "annotation": ": Dict[str, Type[sglang.srt.reasoning_parser.BaseReasoningFormatDetector]]", "default_value": "{&#x27;deepseek-r1&#x27;: &lt;class &#x27;sglang.srt.reasoning_parser.DeepSeekR1Detector&#x27;&gt;, &#x27;deepseek-v3&#x27;: &lt;class &#x27;sglang.srt.reasoning_parser.Qwen3Detector&#x27;&gt;, &#x27;glm45&#x27;: &lt;class &#x27;sglang.srt.reasoning_parser.Qwen3Detector&#x27;&gt;, &#x27;gpt-oss&#x27;: &lt;class &#x27;sglang.srt.reasoning_parser.GptOssDetector&#x27;&gt;, &#x27;kimi&#x27;: &lt;class &#x27;sglang.srt.reasoning_parser.KimiDetector&#x27;&gt;, &#x27;qwen3&#x27;: &lt;class &#x27;sglang.srt.reasoning_parser.Qwen3Detector&#x27;&gt;, &#x27;qwen3-thinking&#x27;: &lt;class &#x27;sglang.srt.reasoning_parser.Qwen3Detector&#x27;&gt;, &#x27;step3&#x27;: &lt;class &#x27;sglang.srt.reasoning_parser.DeepSeekR1Detector&#x27;&gt;}"}, {"fullname": "sglang.srt.reasoning_parser.ReasoningParser.detector", "modulename": "sglang.srt.reasoning_parser", "qualname": "ReasoningParser.detector", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "sglang.srt.reasoning_parser.ReasoningParser.parse_non_stream", "modulename": "sglang.srt.reasoning_parser", "qualname": "ReasoningParser.parse_non_stream", "kind": "function", "doc": "<p>Non-streaming call: one-time parsing</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">full_text</span><span class=\"p\">:</span> <span class=\"nb\">str</span></span><span class=\"return-annotation\">) -> <span class=\"n\">Tuple</span><span class=\"p\">[</span><span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"nb\">str</span><span class=\"p\">],</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"nb\">str</span><span class=\"p\">]]</span>:</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.reasoning_parser.ReasoningParser.parse_stream_chunk", "modulename": "sglang.srt.reasoning_parser", "qualname": "ReasoningParser.parse_stream_chunk", "kind": "function", "doc": "<p>Streaming call: incremental parsing</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">chunk_text</span><span class=\"p\">:</span> <span class=\"nb\">str</span></span><span class=\"return-annotation\">) -> <span class=\"n\">Tuple</span><span class=\"p\">[</span><span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"nb\">str</span><span class=\"p\">],</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"nb\">str</span><span class=\"p\">]]</span>:</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.server_args", "modulename": "sglang.srt.server_args", "kind": "module", "doc": "<p>The arguments of the server.</p>\n"}, {"fullname": "sglang.srt.server_args.logger", "modulename": "sglang.srt.server_args", "qualname": "logger", "kind": "variable", "doc": "<p></p>\n", "default_value": "&lt;Logger sglang.srt.server_args (WARNING)&gt;"}, {"fullname": "sglang.srt.server_args.ServerArgs", "modulename": "sglang.srt.server_args", "qualname": "ServerArgs", "kind": "class", "doc": "<p></p>\n"}, {"fullname": "sglang.srt.server_args.ServerArgs.__init__", "modulename": "sglang.srt.server_args", "qualname": "ServerArgs.__init__", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">model_path</span><span class=\"p\">:</span> <span class=\"nb\">str</span>,</span><span class=\"param\">\t<span class=\"n\">tokenizer_path</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"nb\">str</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">tokenizer_mode</span><span class=\"p\">:</span> <span class=\"nb\">str</span> <span class=\"o\">=</span> <span class=\"s1\">&#39;auto&#39;</span>,</span><span class=\"param\">\t<span class=\"n\">skip_tokenizer_init</span><span class=\"p\">:</span> <span class=\"nb\">bool</span> <span class=\"o\">=</span> <span class=\"kc\">False</span>,</span><span class=\"param\">\t<span class=\"n\">load_format</span><span class=\"p\">:</span> <span class=\"nb\">str</span> <span class=\"o\">=</span> <span class=\"s1\">&#39;auto&#39;</span>,</span><span class=\"param\">\t<span class=\"n\">model_loader_extra_config</span><span class=\"p\">:</span> <span class=\"nb\">str</span> <span class=\"o\">=</span> <span class=\"s1\">&#39;</span><span class=\"si\">{}</span><span class=\"s1\">&#39;</span>,</span><span class=\"param\">\t<span class=\"n\">trust_remote_code</span><span class=\"p\">:</span> <span class=\"nb\">bool</span> <span class=\"o\">=</span> <span class=\"kc\">False</span>,</span><span class=\"param\">\t<span class=\"n\">context_length</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"nb\">int</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">is_embedding</span><span class=\"p\">:</span> <span class=\"nb\">bool</span> <span class=\"o\">=</span> <span class=\"kc\">False</span>,</span><span class=\"param\">\t<span class=\"n\">enable_multimodal</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"nb\">bool</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">revision</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"nb\">str</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">model_impl</span><span class=\"p\">:</span> <span class=\"nb\">str</span> <span class=\"o\">=</span> <span class=\"s1\">&#39;auto&#39;</span>,</span><span class=\"param\">\t<span class=\"n\">host</span><span class=\"p\">:</span> <span class=\"nb\">str</span> <span class=\"o\">=</span> <span class=\"s1\">&#39;127.0.0.1&#39;</span>,</span><span class=\"param\">\t<span class=\"n\">port</span><span class=\"p\">:</span> <span class=\"nb\">int</span> <span class=\"o\">=</span> <span class=\"mi\">30000</span>,</span><span class=\"param\">\t<span class=\"n\">skip_server_warmup</span><span class=\"p\">:</span> <span class=\"nb\">bool</span> <span class=\"o\">=</span> <span class=\"kc\">False</span>,</span><span class=\"param\">\t<span class=\"n\">warmups</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"nb\">str</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">nccl_port</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"nb\">int</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">dtype</span><span class=\"p\">:</span> <span class=\"nb\">str</span> <span class=\"o\">=</span> <span class=\"s1\">&#39;auto&#39;</span>,</span><span class=\"param\">\t<span class=\"n\">quantization</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"nb\">str</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">quantization_param_path</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"nb\">str</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">kv_cache_dtype</span><span class=\"p\">:</span> <span class=\"nb\">str</span> <span class=\"o\">=</span> <span class=\"s1\">&#39;auto&#39;</span>,</span><span class=\"param\">\t<span class=\"n\">mem_fraction_static</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"nb\">float</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">max_running_requests</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"nb\">int</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">max_queued_requests</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"nb\">int</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"mi\">9223372036854775807</span>,</span><span class=\"param\">\t<span class=\"n\">max_total_tokens</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"nb\">int</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">chunked_prefill_size</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"nb\">int</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">max_prefill_tokens</span><span class=\"p\">:</span> <span class=\"nb\">int</span> <span class=\"o\">=</span> <span class=\"mi\">16384</span>,</span><span class=\"param\">\t<span class=\"n\">schedule_policy</span><span class=\"p\">:</span> <span class=\"nb\">str</span> <span class=\"o\">=</span> <span class=\"s1\">&#39;fcfs&#39;</span>,</span><span class=\"param\">\t<span class=\"n\">schedule_conservativeness</span><span class=\"p\">:</span> <span class=\"nb\">float</span> <span class=\"o\">=</span> <span class=\"mf\">1.0</span>,</span><span class=\"param\">\t<span class=\"n\">page_size</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"nb\">int</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">hybrid_kvcache_ratio</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"nb\">float</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">swa_full_tokens_ratio</span><span class=\"p\">:</span> <span class=\"nb\">float</span> <span class=\"o\">=</span> <span class=\"mf\">0.8</span>,</span><span class=\"param\">\t<span class=\"n\">disable_hybrid_swa_memory</span><span class=\"p\">:</span> <span class=\"nb\">bool</span> <span class=\"o\">=</span> <span class=\"kc\">False</span>,</span><span class=\"param\">\t<span class=\"n\">device</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"nb\">str</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">tp_size</span><span class=\"p\">:</span> <span class=\"nb\">int</span> <span class=\"o\">=</span> <span class=\"mi\">1</span>,</span><span class=\"param\">\t<span class=\"n\">pp_size</span><span class=\"p\">:</span> <span class=\"nb\">int</span> <span class=\"o\">=</span> <span class=\"mi\">1</span>,</span><span class=\"param\">\t<span class=\"n\">max_micro_batch_size</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"nb\">int</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">stream_interval</span><span class=\"p\">:</span> <span class=\"nb\">int</span> <span class=\"o\">=</span> <span class=\"mi\">1</span>,</span><span class=\"param\">\t<span class=\"n\">stream_output</span><span class=\"p\">:</span> <span class=\"nb\">bool</span> <span class=\"o\">=</span> <span class=\"kc\">False</span>,</span><span class=\"param\">\t<span class=\"n\">random_seed</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"nb\">int</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">constrained_json_whitespace_pattern</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"nb\">str</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">watchdog_timeout</span><span class=\"p\">:</span> <span class=\"nb\">float</span> <span class=\"o\">=</span> <span class=\"mi\">300</span>,</span><span class=\"param\">\t<span class=\"n\">dist_timeout</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"nb\">int</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">download_dir</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"nb\">str</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">base_gpu_id</span><span class=\"p\">:</span> <span class=\"nb\">int</span> <span class=\"o\">=</span> <span class=\"mi\">0</span>,</span><span class=\"param\">\t<span class=\"n\">gpu_id_step</span><span class=\"p\">:</span> <span class=\"nb\">int</span> <span class=\"o\">=</span> <span class=\"mi\">1</span>,</span><span class=\"param\">\t<span class=\"n\">sleep_on_idle</span><span class=\"p\">:</span> <span class=\"nb\">bool</span> <span class=\"o\">=</span> <span class=\"kc\">False</span>,</span><span class=\"param\">\t<span class=\"n\">log_level</span><span class=\"p\">:</span> <span class=\"nb\">str</span> <span class=\"o\">=</span> <span class=\"s1\">&#39;info&#39;</span>,</span><span class=\"param\">\t<span class=\"n\">log_level_http</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"nb\">str</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">log_requests</span><span class=\"p\">:</span> <span class=\"nb\">bool</span> <span class=\"o\">=</span> <span class=\"kc\">False</span>,</span><span class=\"param\">\t<span class=\"n\">log_requests_level</span><span class=\"p\">:</span> <span class=\"nb\">int</span> <span class=\"o\">=</span> <span class=\"mi\">2</span>,</span><span class=\"param\">\t<span class=\"n\">crash_dump_folder</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"nb\">str</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">show_time_cost</span><span class=\"p\">:</span> <span class=\"nb\">bool</span> <span class=\"o\">=</span> <span class=\"kc\">False</span>,</span><span class=\"param\">\t<span class=\"n\">enable_metrics</span><span class=\"p\">:</span> <span class=\"nb\">bool</span> <span class=\"o\">=</span> <span class=\"kc\">False</span>,</span><span class=\"param\">\t<span class=\"n\">enable_metrics_for_all_schedulers</span><span class=\"p\">:</span> <span class=\"nb\">bool</span> <span class=\"o\">=</span> <span class=\"kc\">False</span>,</span><span class=\"param\">\t<span class=\"n\">bucket_time_to_first_token</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"n\">List</span><span class=\"p\">[</span><span class=\"nb\">float</span><span class=\"p\">]]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">bucket_inter_token_latency</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"n\">List</span><span class=\"p\">[</span><span class=\"nb\">float</span><span class=\"p\">]]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">bucket_e2e_request_latency</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"n\">List</span><span class=\"p\">[</span><span class=\"nb\">float</span><span class=\"p\">]]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">collect_tokens_histogram</span><span class=\"p\">:</span> <span class=\"nb\">bool</span> <span class=\"o\">=</span> <span class=\"kc\">False</span>,</span><span class=\"param\">\t<span class=\"n\">decode_log_interval</span><span class=\"p\">:</span> <span class=\"nb\">int</span> <span class=\"o\">=</span> <span class=\"mi\">40</span>,</span><span class=\"param\">\t<span class=\"n\">enable_request_time_stats_logging</span><span class=\"p\">:</span> <span class=\"nb\">bool</span> <span class=\"o\">=</span> <span class=\"kc\">False</span>,</span><span class=\"param\">\t<span class=\"n\">kv_events_config</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"nb\">str</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">gc_warning_threshold_secs</span><span class=\"p\">:</span> <span class=\"nb\">float</span> <span class=\"o\">=</span> <span class=\"mf\">0.0</span>,</span><span class=\"param\">\t<span class=\"n\">api_key</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"nb\">str</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">served_model_name</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"nb\">str</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">weight_version</span><span class=\"p\">:</span> <span class=\"nb\">str</span> <span class=\"o\">=</span> <span class=\"s1\">&#39;default&#39;</span>,</span><span class=\"param\">\t<span class=\"n\">chat_template</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"nb\">str</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">completion_template</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"nb\">str</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">file_storage_path</span><span class=\"p\">:</span> <span class=\"nb\">str</span> <span class=\"o\">=</span> <span class=\"s1\">&#39;sglang_storage&#39;</span>,</span><span class=\"param\">\t<span class=\"n\">enable_cache_report</span><span class=\"p\">:</span> <span class=\"nb\">bool</span> <span class=\"o\">=</span> <span class=\"kc\">False</span>,</span><span class=\"param\">\t<span class=\"n\">reasoning_parser</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"nb\">str</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">tool_call_parser</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"nb\">str</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">tool_server</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"nb\">str</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">dp_size</span><span class=\"p\">:</span> <span class=\"nb\">int</span> <span class=\"o\">=</span> <span class=\"mi\">1</span>,</span><span class=\"param\">\t<span class=\"n\">load_balance_method</span><span class=\"p\">:</span> <span class=\"nb\">str</span> <span class=\"o\">=</span> <span class=\"s1\">&#39;round_robin&#39;</span>,</span><span class=\"param\">\t<span class=\"n\">dist_init_addr</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"nb\">str</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">nnodes</span><span class=\"p\">:</span> <span class=\"nb\">int</span> <span class=\"o\">=</span> <span class=\"mi\">1</span>,</span><span class=\"param\">\t<span class=\"n\">node_rank</span><span class=\"p\">:</span> <span class=\"nb\">int</span> <span class=\"o\">=</span> <span class=\"mi\">0</span>,</span><span class=\"param\">\t<span class=\"n\">json_model_override_args</span><span class=\"p\">:</span> <span class=\"nb\">str</span> <span class=\"o\">=</span> <span class=\"s1\">&#39;</span><span class=\"si\">{}</span><span class=\"s1\">&#39;</span>,</span><span class=\"param\">\t<span class=\"n\">preferred_sampling_params</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"nb\">str</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">enable_lora</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"nb\">bool</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">max_lora_rank</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"nb\">int</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">lora_target_modules</span><span class=\"p\">:</span> <span class=\"n\">Union</span><span class=\"p\">[</span><span class=\"nb\">set</span><span class=\"p\">[</span><span class=\"nb\">str</span><span class=\"p\">],</span> <span class=\"n\">List</span><span class=\"p\">[</span><span class=\"nb\">str</span><span class=\"p\">],</span> <span class=\"n\">NoneType</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">lora_paths</span><span class=\"p\">:</span> <span class=\"n\">Union</span><span class=\"p\">[</span><span class=\"nb\">dict</span><span class=\"p\">[</span><span class=\"nb\">str</span><span class=\"p\">,</span> <span class=\"nb\">str</span><span class=\"p\">],</span> <span class=\"n\">List</span><span class=\"p\">[</span><span class=\"nb\">dict</span><span class=\"p\">[</span><span class=\"nb\">str</span><span class=\"p\">,</span> <span class=\"nb\">str</span><span class=\"p\">]],</span> <span class=\"n\">List</span><span class=\"p\">[</span><span class=\"nb\">str</span><span class=\"p\">],</span> <span class=\"n\">List</span><span class=\"p\">[</span><span class=\"n\">sglang</span><span class=\"o\">.</span><span class=\"n\">srt</span><span class=\"o\">.</span><span class=\"n\">lora</span><span class=\"o\">.</span><span class=\"n\">lora_registry</span><span class=\"o\">.</span><span class=\"n\">LoRARef</span><span class=\"p\">],</span> <span class=\"n\">NoneType</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">max_loaded_loras</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"nb\">int</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">max_loras_per_batch</span><span class=\"p\">:</span> <span class=\"nb\">int</span> <span class=\"o\">=</span> <span class=\"mi\">8</span>,</span><span class=\"param\">\t<span class=\"n\">lora_backend</span><span class=\"p\">:</span> <span class=\"nb\">str</span> <span class=\"o\">=</span> <span class=\"s1\">&#39;triton&#39;</span>,</span><span class=\"param\">\t<span class=\"n\">attention_backend</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"nb\">str</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">decode_attention_backend</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"nb\">str</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">prefill_attention_backend</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"nb\">str</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">sampling_backend</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"nb\">str</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">grammar_backend</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"nb\">str</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">mm_attention_backend</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"nb\">str</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">speculative_algorithm</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"nb\">str</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">speculative_draft_model_path</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"nb\">str</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">speculative_num_steps</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"nb\">int</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">speculative_eagle_topk</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"nb\">int</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">speculative_num_draft_tokens</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"nb\">int</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">speculative_accept_threshold_single</span><span class=\"p\">:</span> <span class=\"nb\">float</span> <span class=\"o\">=</span> <span class=\"mf\">1.0</span>,</span><span class=\"param\">\t<span class=\"n\">speculative_accept_threshold_acc</span><span class=\"p\">:</span> <span class=\"nb\">float</span> <span class=\"o\">=</span> <span class=\"mf\">1.0</span>,</span><span class=\"param\">\t<span class=\"n\">speculative_token_map</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"nb\">str</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">ep_size</span><span class=\"p\">:</span> <span class=\"nb\">int</span> <span class=\"o\">=</span> <span class=\"mi\">1</span>,</span><span class=\"param\">\t<span class=\"n\">moe_a2a_backend</span><span class=\"p\">:</span> <span class=\"n\">Literal</span><span class=\"p\">[</span><span class=\"s1\">&#39;none&#39;</span><span class=\"p\">,</span> <span class=\"s1\">&#39;deepep&#39;</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"s1\">&#39;none&#39;</span>,</span><span class=\"param\">\t<span class=\"n\">moe_runner_backend</span><span class=\"p\">:</span> <span class=\"n\">Literal</span><span class=\"p\">[</span><span class=\"s1\">&#39;auto&#39;</span><span class=\"p\">,</span> <span class=\"s1\">&#39;triton&#39;</span><span class=\"p\">,</span> <span class=\"s1\">&#39;triton_kernel&#39;</span><span class=\"p\">,</span> <span class=\"s1\">&#39;flashinfer_trtllm&#39;</span><span class=\"p\">,</span> <span class=\"s1\">&#39;flashinfer_cutlass&#39;</span><span class=\"p\">,</span> <span class=\"s1\">&#39;flashinfer_mxfp4&#39;</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"s1\">&#39;auto&#39;</span>,</span><span class=\"param\">\t<span class=\"n\">flashinfer_mxfp4_moe_precision</span><span class=\"p\">:</span> <span class=\"n\">Literal</span><span class=\"p\">[</span><span class=\"s1\">&#39;default&#39;</span><span class=\"p\">,</span> <span class=\"s1\">&#39;bf16&#39;</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"s1\">&#39;default&#39;</span>,</span><span class=\"param\">\t<span class=\"n\">enable_flashinfer_allreduce_fusion</span><span class=\"p\">:</span> <span class=\"nb\">bool</span> <span class=\"o\">=</span> <span class=\"kc\">False</span>,</span><span class=\"param\">\t<span class=\"n\">deepep_mode</span><span class=\"p\">:</span> <span class=\"n\">Literal</span><span class=\"p\">[</span><span class=\"s1\">&#39;auto&#39;</span><span class=\"p\">,</span> <span class=\"s1\">&#39;normal&#39;</span><span class=\"p\">,</span> <span class=\"s1\">&#39;low_latency&#39;</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"s1\">&#39;auto&#39;</span>,</span><span class=\"param\">\t<span class=\"n\">ep_num_redundant_experts</span><span class=\"p\">:</span> <span class=\"nb\">int</span> <span class=\"o\">=</span> <span class=\"mi\">0</span>,</span><span class=\"param\">\t<span class=\"n\">ep_dispatch_algorithm</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"n\">Literal</span><span class=\"p\">[</span><span class=\"s1\">&#39;static&#39;</span><span class=\"p\">,</span> <span class=\"s1\">&#39;dynamic&#39;</span><span class=\"p\">,</span> <span class=\"s1\">&#39;fake&#39;</span><span class=\"p\">]]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">init_expert_location</span><span class=\"p\">:</span> <span class=\"nb\">str</span> <span class=\"o\">=</span> <span class=\"s1\">&#39;trivial&#39;</span>,</span><span class=\"param\">\t<span class=\"n\">enable_eplb</span><span class=\"p\">:</span> <span class=\"nb\">bool</span> <span class=\"o\">=</span> <span class=\"kc\">False</span>,</span><span class=\"param\">\t<span class=\"n\">eplb_algorithm</span><span class=\"p\">:</span> <span class=\"nb\">str</span> <span class=\"o\">=</span> <span class=\"s1\">&#39;auto&#39;</span>,</span><span class=\"param\">\t<span class=\"n\">eplb_rebalance_num_iterations</span><span class=\"p\">:</span> <span class=\"nb\">int</span> <span class=\"o\">=</span> <span class=\"mi\">1000</span>,</span><span class=\"param\">\t<span class=\"n\">eplb_rebalance_layers_per_chunk</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"nb\">int</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">expert_distribution_recorder_mode</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"n\">Literal</span><span class=\"p\">[</span><span class=\"s1\">&#39;stat&#39;</span><span class=\"p\">,</span> <span class=\"s1\">&#39;stat_approx&#39;</span><span class=\"p\">,</span> <span class=\"s1\">&#39;per_pass&#39;</span><span class=\"p\">,</span> <span class=\"s1\">&#39;per_token&#39;</span><span class=\"p\">]]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">expert_distribution_recorder_buffer_size</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"nb\">int</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">enable_expert_distribution_metrics</span><span class=\"p\">:</span> <span class=\"nb\">bool</span> <span class=\"o\">=</span> <span class=\"kc\">False</span>,</span><span class=\"param\">\t<span class=\"n\">deepep_config</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"nb\">str</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">moe_dense_tp_size</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"nb\">int</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">enable_hierarchical_cache</span><span class=\"p\">:</span> <span class=\"nb\">bool</span> <span class=\"o\">=</span> <span class=\"kc\">False</span>,</span><span class=\"param\">\t<span class=\"n\">hicache_ratio</span><span class=\"p\">:</span> <span class=\"nb\">float</span> <span class=\"o\">=</span> <span class=\"mf\">2.0</span>,</span><span class=\"param\">\t<span class=\"n\">hicache_size</span><span class=\"p\">:</span> <span class=\"nb\">int</span> <span class=\"o\">=</span> <span class=\"mi\">0</span>,</span><span class=\"param\">\t<span class=\"n\">hicache_write_policy</span><span class=\"p\">:</span> <span class=\"nb\">str</span> <span class=\"o\">=</span> <span class=\"s1\">&#39;write_through_selective&#39;</span>,</span><span class=\"param\">\t<span class=\"n\">hicache_io_backend</span><span class=\"p\">:</span> <span class=\"nb\">str</span> <span class=\"o\">=</span> <span class=\"s1\">&#39;kernel&#39;</span>,</span><span class=\"param\">\t<span class=\"n\">hicache_mem_layout</span><span class=\"p\">:</span> <span class=\"nb\">str</span> <span class=\"o\">=</span> <span class=\"s1\">&#39;layer_first&#39;</span>,</span><span class=\"param\">\t<span class=\"n\">hicache_storage_backend</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"nb\">str</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">hicache_storage_prefetch_policy</span><span class=\"p\">:</span> <span class=\"nb\">str</span> <span class=\"o\">=</span> <span class=\"s1\">&#39;best_effort&#39;</span>,</span><span class=\"param\">\t<span class=\"n\">hicache_storage_backend_extra_config</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"nb\">str</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">enable_double_sparsity</span><span class=\"p\">:</span> <span class=\"nb\">bool</span> <span class=\"o\">=</span> <span class=\"kc\">False</span>,</span><span class=\"param\">\t<span class=\"n\">ds_channel_config_path</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"nb\">str</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">ds_heavy_channel_num</span><span class=\"p\">:</span> <span class=\"nb\">int</span> <span class=\"o\">=</span> <span class=\"mi\">32</span>,</span><span class=\"param\">\t<span class=\"n\">ds_heavy_token_num</span><span class=\"p\">:</span> <span class=\"nb\">int</span> <span class=\"o\">=</span> <span class=\"mi\">256</span>,</span><span class=\"param\">\t<span class=\"n\">ds_heavy_channel_type</span><span class=\"p\">:</span> <span class=\"nb\">str</span> <span class=\"o\">=</span> <span class=\"s1\">&#39;qk&#39;</span>,</span><span class=\"param\">\t<span class=\"n\">ds_sparse_decode_threshold</span><span class=\"p\">:</span> <span class=\"nb\">int</span> <span class=\"o\">=</span> <span class=\"mi\">4096</span>,</span><span class=\"param\">\t<span class=\"n\">cpu_offload_gb</span><span class=\"p\">:</span> <span class=\"nb\">int</span> <span class=\"o\">=</span> <span class=\"mi\">0</span>,</span><span class=\"param\">\t<span class=\"n\">offload_group_size</span><span class=\"p\">:</span> <span class=\"nb\">int</span> <span class=\"o\">=</span> <span class=\"o\">-</span><span class=\"mi\">1</span>,</span><span class=\"param\">\t<span class=\"n\">offload_num_in_group</span><span class=\"p\">:</span> <span class=\"nb\">int</span> <span class=\"o\">=</span> <span class=\"mi\">1</span>,</span><span class=\"param\">\t<span class=\"n\">offload_prefetch_step</span><span class=\"p\">:</span> <span class=\"nb\">int</span> <span class=\"o\">=</span> <span class=\"mi\">1</span>,</span><span class=\"param\">\t<span class=\"n\">offload_mode</span><span class=\"p\">:</span> <span class=\"nb\">str</span> <span class=\"o\">=</span> <span class=\"s1\">&#39;cpu&#39;</span>,</span><span class=\"param\">\t<span class=\"n\">disable_radix_cache</span><span class=\"p\">:</span> <span class=\"nb\">bool</span> <span class=\"o\">=</span> <span class=\"kc\">False</span>,</span><span class=\"param\">\t<span class=\"n\">cuda_graph_max_bs</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"nb\">int</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">cuda_graph_bs</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"n\">List</span><span class=\"p\">[</span><span class=\"nb\">int</span><span class=\"p\">]]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">disable_cuda_graph</span><span class=\"p\">:</span> <span class=\"nb\">bool</span> <span class=\"o\">=</span> <span class=\"kc\">False</span>,</span><span class=\"param\">\t<span class=\"n\">disable_cuda_graph_padding</span><span class=\"p\">:</span> <span class=\"nb\">bool</span> <span class=\"o\">=</span> <span class=\"kc\">False</span>,</span><span class=\"param\">\t<span class=\"n\">enable_profile_cuda_graph</span><span class=\"p\">:</span> <span class=\"nb\">bool</span> <span class=\"o\">=</span> <span class=\"kc\">False</span>,</span><span class=\"param\">\t<span class=\"n\">enable_cudagraph_gc</span><span class=\"p\">:</span> <span class=\"nb\">bool</span> <span class=\"o\">=</span> <span class=\"kc\">False</span>,</span><span class=\"param\">\t<span class=\"n\">enable_nccl_nvls</span><span class=\"p\">:</span> <span class=\"nb\">bool</span> <span class=\"o\">=</span> <span class=\"kc\">False</span>,</span><span class=\"param\">\t<span class=\"n\">enable_symm_mem</span><span class=\"p\">:</span> <span class=\"nb\">bool</span> <span class=\"o\">=</span> <span class=\"kc\">False</span>,</span><span class=\"param\">\t<span class=\"n\">disable_flashinfer_cutlass_moe_fp4_allgather</span><span class=\"p\">:</span> <span class=\"nb\">bool</span> <span class=\"o\">=</span> <span class=\"kc\">False</span>,</span><span class=\"param\">\t<span class=\"n\">enable_tokenizer_batch_encode</span><span class=\"p\">:</span> <span class=\"nb\">bool</span> <span class=\"o\">=</span> <span class=\"kc\">False</span>,</span><span class=\"param\">\t<span class=\"n\">disable_outlines_disk_cache</span><span class=\"p\">:</span> <span class=\"nb\">bool</span> <span class=\"o\">=</span> <span class=\"kc\">False</span>,</span><span class=\"param\">\t<span class=\"n\">disable_custom_all_reduce</span><span class=\"p\">:</span> <span class=\"nb\">bool</span> <span class=\"o\">=</span> <span class=\"kc\">False</span>,</span><span class=\"param\">\t<span class=\"n\">enable_mscclpp</span><span class=\"p\">:</span> <span class=\"nb\">bool</span> <span class=\"o\">=</span> <span class=\"kc\">False</span>,</span><span class=\"param\">\t<span class=\"n\">disable_overlap_schedule</span><span class=\"p\">:</span> <span class=\"nb\">bool</span> <span class=\"o\">=</span> <span class=\"kc\">False</span>,</span><span class=\"param\">\t<span class=\"n\">enable_mixed_chunk</span><span class=\"p\">:</span> <span class=\"nb\">bool</span> <span class=\"o\">=</span> <span class=\"kc\">False</span>,</span><span class=\"param\">\t<span class=\"n\">enable_dp_attention</span><span class=\"p\">:</span> <span class=\"nb\">bool</span> <span class=\"o\">=</span> <span class=\"kc\">False</span>,</span><span class=\"param\">\t<span class=\"n\">enable_dp_lm_head</span><span class=\"p\">:</span> <span class=\"nb\">bool</span> <span class=\"o\">=</span> <span class=\"kc\">False</span>,</span><span class=\"param\">\t<span class=\"n\">enable_two_batch_overlap</span><span class=\"p\">:</span> <span class=\"nb\">bool</span> <span class=\"o\">=</span> <span class=\"kc\">False</span>,</span><span class=\"param\">\t<span class=\"n\">tbo_token_distribution_threshold</span><span class=\"p\">:</span> <span class=\"nb\">float</span> <span class=\"o\">=</span> <span class=\"mf\">0.48</span>,</span><span class=\"param\">\t<span class=\"n\">enable_torch_compile</span><span class=\"p\">:</span> <span class=\"nb\">bool</span> <span class=\"o\">=</span> <span class=\"kc\">False</span>,</span><span class=\"param\">\t<span class=\"n\">torch_compile_max_bs</span><span class=\"p\">:</span> <span class=\"nb\">int</span> <span class=\"o\">=</span> <span class=\"mi\">32</span>,</span><span class=\"param\">\t<span class=\"n\">torchao_config</span><span class=\"p\">:</span> <span class=\"nb\">str</span> <span class=\"o\">=</span> <span class=\"s1\">&#39;&#39;</span>,</span><span class=\"param\">\t<span class=\"n\">enable_nan_detection</span><span class=\"p\">:</span> <span class=\"nb\">bool</span> <span class=\"o\">=</span> <span class=\"kc\">False</span>,</span><span class=\"param\">\t<span class=\"n\">enable_p2p_check</span><span class=\"p\">:</span> <span class=\"nb\">bool</span> <span class=\"o\">=</span> <span class=\"kc\">False</span>,</span><span class=\"param\">\t<span class=\"n\">triton_attention_reduce_in_fp32</span><span class=\"p\">:</span> <span class=\"nb\">bool</span> <span class=\"o\">=</span> <span class=\"kc\">False</span>,</span><span class=\"param\">\t<span class=\"n\">triton_attention_num_kv_splits</span><span class=\"p\">:</span> <span class=\"nb\">int</span> <span class=\"o\">=</span> <span class=\"mi\">8</span>,</span><span class=\"param\">\t<span class=\"n\">num_continuous_decode_steps</span><span class=\"p\">:</span> <span class=\"nb\">int</span> <span class=\"o\">=</span> <span class=\"mi\">1</span>,</span><span class=\"param\">\t<span class=\"n\">delete_ckpt_after_loading</span><span class=\"p\">:</span> <span class=\"nb\">bool</span> <span class=\"o\">=</span> <span class=\"kc\">False</span>,</span><span class=\"param\">\t<span class=\"n\">enable_memory_saver</span><span class=\"p\">:</span> <span class=\"nb\">bool</span> <span class=\"o\">=</span> <span class=\"kc\">False</span>,</span><span class=\"param\">\t<span class=\"n\">allow_auto_truncate</span><span class=\"p\">:</span> <span class=\"nb\">bool</span> <span class=\"o\">=</span> <span class=\"kc\">False</span>,</span><span class=\"param\">\t<span class=\"n\">enable_custom_logit_processor</span><span class=\"p\">:</span> <span class=\"nb\">bool</span> <span class=\"o\">=</span> <span class=\"kc\">False</span>,</span><span class=\"param\">\t<span class=\"n\">flashinfer_mla_disable_ragged</span><span class=\"p\">:</span> <span class=\"nb\">bool</span> <span class=\"o\">=</span> <span class=\"kc\">False</span>,</span><span class=\"param\">\t<span class=\"n\">disable_shared_experts_fusion</span><span class=\"p\">:</span> <span class=\"nb\">bool</span> <span class=\"o\">=</span> <span class=\"kc\">False</span>,</span><span class=\"param\">\t<span class=\"n\">disable_chunked_prefix_cache</span><span class=\"p\">:</span> <span class=\"nb\">bool</span> <span class=\"o\">=</span> <span class=\"kc\">False</span>,</span><span class=\"param\">\t<span class=\"n\">disable_fast_image_processor</span><span class=\"p\">:</span> <span class=\"nb\">bool</span> <span class=\"o\">=</span> <span class=\"kc\">False</span>,</span><span class=\"param\">\t<span class=\"n\">enable_return_hidden_states</span><span class=\"p\">:</span> <span class=\"nb\">bool</span> <span class=\"o\">=</span> <span class=\"kc\">False</span>,</span><span class=\"param\">\t<span class=\"n\">scheduler_recv_interval</span><span class=\"p\">:</span> <span class=\"nb\">int</span> <span class=\"o\">=</span> <span class=\"mi\">1</span>,</span><span class=\"param\">\t<span class=\"n\">debug_tensor_dump_output_folder</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"nb\">str</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">debug_tensor_dump_input_file</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"nb\">str</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">debug_tensor_dump_inject</span><span class=\"p\">:</span> <span class=\"nb\">bool</span> <span class=\"o\">=</span> <span class=\"kc\">False</span>,</span><span class=\"param\">\t<span class=\"n\">debug_tensor_dump_prefill_only</span><span class=\"p\">:</span> <span class=\"nb\">bool</span> <span class=\"o\">=</span> <span class=\"kc\">False</span>,</span><span class=\"param\">\t<span class=\"n\">disaggregation_mode</span><span class=\"p\">:</span> <span class=\"nb\">str</span> <span class=\"o\">=</span> <span class=\"s1\">&#39;null&#39;</span>,</span><span class=\"param\">\t<span class=\"n\">disaggregation_transfer_backend</span><span class=\"p\">:</span> <span class=\"nb\">str</span> <span class=\"o\">=</span> <span class=\"s1\">&#39;mooncake&#39;</span>,</span><span class=\"param\">\t<span class=\"n\">disaggregation_bootstrap_port</span><span class=\"p\">:</span> <span class=\"nb\">int</span> <span class=\"o\">=</span> <span class=\"mi\">8998</span>,</span><span class=\"param\">\t<span class=\"n\">disaggregation_decode_tp</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"nb\">int</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">disaggregation_decode_dp</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"nb\">int</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">disaggregation_prefill_pp</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"nb\">int</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"mi\">1</span>,</span><span class=\"param\">\t<span class=\"n\">disaggregation_ib_device</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"nb\">str</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">num_reserved_decode_tokens</span><span class=\"p\">:</span> <span class=\"nb\">int</span> <span class=\"o\">=</span> <span class=\"mi\">512</span>,</span><span class=\"param\">\t<span class=\"n\">pdlb_url</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"nb\">str</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">custom_weight_loader</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"n\">List</span><span class=\"p\">[</span><span class=\"nb\">str</span><span class=\"p\">]]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">weight_loader_disable_mmap</span><span class=\"p\">:</span> <span class=\"nb\">bool</span> <span class=\"o\">=</span> <span class=\"kc\">False</span>,</span><span class=\"param\">\t<span class=\"n\">enable_pdmux</span><span class=\"p\">:</span> <span class=\"nb\">bool</span> <span class=\"o\">=</span> <span class=\"kc\">False</span>,</span><span class=\"param\">\t<span class=\"n\">sm_group_num</span><span class=\"p\">:</span> <span class=\"nb\">int</span> <span class=\"o\">=</span> <span class=\"mi\">3</span>,</span><span class=\"param\">\t<span class=\"n\">enable_ep_moe</span><span class=\"p\">:</span> <span class=\"nb\">bool</span> <span class=\"o\">=</span> <span class=\"kc\">False</span>,</span><span class=\"param\">\t<span class=\"n\">enable_deepep_moe</span><span class=\"p\">:</span> <span class=\"nb\">bool</span> <span class=\"o\">=</span> <span class=\"kc\">False</span>,</span><span class=\"param\">\t<span class=\"n\">enable_flashinfer_cutlass_moe</span><span class=\"p\">:</span> <span class=\"nb\">bool</span> <span class=\"o\">=</span> <span class=\"kc\">False</span>,</span><span class=\"param\">\t<span class=\"n\">enable_flashinfer_trtllm_moe</span><span class=\"p\">:</span> <span class=\"nb\">bool</span> <span class=\"o\">=</span> <span class=\"kc\">False</span>,</span><span class=\"param\">\t<span class=\"n\">enable_triton_kernel_moe</span><span class=\"p\">:</span> <span class=\"nb\">bool</span> <span class=\"o\">=</span> <span class=\"kc\">False</span>,</span><span class=\"param\">\t<span class=\"n\">enable_flashinfer_mxfp4_moe</span><span class=\"p\">:</span> <span class=\"nb\">bool</span> <span class=\"o\">=</span> <span class=\"kc\">False</span></span>)</span>"}, {"fullname": "sglang.srt.server_args.ServerArgs.model_path", "modulename": "sglang.srt.server_args", "qualname": "ServerArgs.model_path", "kind": "variable", "doc": "<p></p>\n", "annotation": ": str"}, {"fullname": "sglang.srt.server_args.ServerArgs.tokenizer_path", "modulename": "sglang.srt.server_args", "qualname": "ServerArgs.tokenizer_path", "kind": "variable", "doc": "<p></p>\n", "annotation": ": Optional[str]", "default_value": "None"}, {"fullname": "sglang.srt.server_args.ServerArgs.tokenizer_mode", "modulename": "sglang.srt.server_args", "qualname": "ServerArgs.tokenizer_mode", "kind": "variable", "doc": "<p></p>\n", "annotation": ": str", "default_value": "&#x27;auto&#x27;"}, {"fullname": "sglang.srt.server_args.ServerArgs.skip_tokenizer_init", "modulename": "sglang.srt.server_args", "qualname": "ServerArgs.skip_tokenizer_init", "kind": "variable", "doc": "<p></p>\n", "annotation": ": bool", "default_value": "False"}, {"fullname": "sglang.srt.server_args.ServerArgs.load_format", "modulename": "sglang.srt.server_args", "qualname": "ServerArgs.load_format", "kind": "variable", "doc": "<p></p>\n", "annotation": ": str", "default_value": "&#x27;auto&#x27;"}, {"fullname": "sglang.srt.server_args.ServerArgs.model_loader_extra_config", "modulename": "sglang.srt.server_args", "qualname": "ServerArgs.model_loader_extra_config", "kind": "variable", "doc": "<p></p>\n", "annotation": ": str", "default_value": "&#x27;{}&#x27;"}, {"fullname": "sglang.srt.server_args.ServerArgs.trust_remote_code", "modulename": "sglang.srt.server_args", "qualname": "ServerArgs.trust_remote_code", "kind": "variable", "doc": "<p></p>\n", "annotation": ": bool", "default_value": "False"}, {"fullname": "sglang.srt.server_args.ServerArgs.context_length", "modulename": "sglang.srt.server_args", "qualname": "ServerArgs.context_length", "kind": "variable", "doc": "<p></p>\n", "annotation": ": Optional[int]", "default_value": "None"}, {"fullname": "sglang.srt.server_args.ServerArgs.is_embedding", "modulename": "sglang.srt.server_args", "qualname": "ServerArgs.is_embedding", "kind": "variable", "doc": "<p></p>\n", "annotation": ": bool", "default_value": "False"}, {"fullname": "sglang.srt.server_args.ServerArgs.enable_multimodal", "modulename": "sglang.srt.server_args", "qualname": "ServerArgs.enable_multimodal", "kind": "variable", "doc": "<p></p>\n", "annotation": ": Optional[bool]", "default_value": "None"}, {"fullname": "sglang.srt.server_args.ServerArgs.revision", "modulename": "sglang.srt.server_args", "qualname": "ServerArgs.revision", "kind": "variable", "doc": "<p></p>\n", "annotation": ": Optional[str]", "default_value": "None"}, {"fullname": "sglang.srt.server_args.ServerArgs.model_impl", "modulename": "sglang.srt.server_args", "qualname": "ServerArgs.model_impl", "kind": "variable", "doc": "<p></p>\n", "annotation": ": str", "default_value": "&#x27;auto&#x27;"}, {"fullname": "sglang.srt.server_args.ServerArgs.host", "modulename": "sglang.srt.server_args", "qualname": "ServerArgs.host", "kind": "variable", "doc": "<p></p>\n", "annotation": ": str", "default_value": "&#x27;127.0.0.1&#x27;"}, {"fullname": "sglang.srt.server_args.ServerArgs.port", "modulename": "sglang.srt.server_args", "qualname": "ServerArgs.port", "kind": "variable", "doc": "<p></p>\n", "annotation": ": int", "default_value": "30000"}, {"fullname": "sglang.srt.server_args.ServerArgs.skip_server_warmup", "modulename": "sglang.srt.server_args", "qualname": "ServerArgs.skip_server_warmup", "kind": "variable", "doc": "<p></p>\n", "annotation": ": bool", "default_value": "False"}, {"fullname": "sglang.srt.server_args.ServerArgs.warmups", "modulename": "sglang.srt.server_args", "qualname": "ServerArgs.warmups", "kind": "variable", "doc": "<p></p>\n", "annotation": ": Optional[str]", "default_value": "None"}, {"fullname": "sglang.srt.server_args.ServerArgs.nccl_port", "modulename": "sglang.srt.server_args", "qualname": "ServerArgs.nccl_port", "kind": "variable", "doc": "<p></p>\n", "annotation": ": Optional[int]", "default_value": "None"}, {"fullname": "sglang.srt.server_args.ServerArgs.dtype", "modulename": "sglang.srt.server_args", "qualname": "ServerArgs.dtype", "kind": "variable", "doc": "<p></p>\n", "annotation": ": str", "default_value": "&#x27;auto&#x27;"}, {"fullname": "sglang.srt.server_args.ServerArgs.quantization", "modulename": "sglang.srt.server_args", "qualname": "ServerArgs.quantization", "kind": "variable", "doc": "<p></p>\n", "annotation": ": Optional[str]", "default_value": "None"}, {"fullname": "sglang.srt.server_args.ServerArgs.quantization_param_path", "modulename": "sglang.srt.server_args", "qualname": "ServerArgs.quantization_param_path", "kind": "variable", "doc": "<p></p>\n", "annotation": ": Optional[str]", "default_value": "None"}, {"fullname": "sglang.srt.server_args.ServerArgs.kv_cache_dtype", "modulename": "sglang.srt.server_args", "qualname": "ServerArgs.kv_cache_dtype", "kind": "variable", "doc": "<p></p>\n", "annotation": ": str", "default_value": "&#x27;auto&#x27;"}, {"fullname": "sglang.srt.server_args.ServerArgs.mem_fraction_static", "modulename": "sglang.srt.server_args", "qualname": "ServerArgs.mem_fraction_static", "kind": "variable", "doc": "<p></p>\n", "annotation": ": Optional[float]", "default_value": "None"}, {"fullname": "sglang.srt.server_args.ServerArgs.max_running_requests", "modulename": "sglang.srt.server_args", "qualname": "ServerArgs.max_running_requests", "kind": "variable", "doc": "<p></p>\n", "annotation": ": Optional[int]", "default_value": "None"}, {"fullname": "sglang.srt.server_args.ServerArgs.max_queued_requests", "modulename": "sglang.srt.server_args", "qualname": "ServerArgs.max_queued_requests", "kind": "variable", "doc": "<p></p>\n", "annotation": ": Optional[int]", "default_value": "9223372036854775807"}, {"fullname": "sglang.srt.server_args.ServerArgs.max_total_tokens", "modulename": "sglang.srt.server_args", "qualname": "ServerArgs.max_total_tokens", "kind": "variable", "doc": "<p></p>\n", "annotation": ": Optional[int]", "default_value": "None"}, {"fullname": "sglang.srt.server_args.ServerArgs.chunked_prefill_size", "modulename": "sglang.srt.server_args", "qualname": "ServerArgs.chunked_prefill_size", "kind": "variable", "doc": "<p></p>\n", "annotation": ": Optional[int]", "default_value": "None"}, {"fullname": "sglang.srt.server_args.ServerArgs.max_prefill_tokens", "modulename": "sglang.srt.server_args", "qualname": "ServerArgs.max_prefill_tokens", "kind": "variable", "doc": "<p></p>\n", "annotation": ": int", "default_value": "16384"}, {"fullname": "sglang.srt.server_args.ServerArgs.schedule_policy", "modulename": "sglang.srt.server_args", "qualname": "ServerArgs.schedule_policy", "kind": "variable", "doc": "<p></p>\n", "annotation": ": str", "default_value": "&#x27;fcfs&#x27;"}, {"fullname": "sglang.srt.server_args.ServerArgs.schedule_conservativeness", "modulename": "sglang.srt.server_args", "qualname": "ServerArgs.schedule_conservativeness", "kind": "variable", "doc": "<p></p>\n", "annotation": ": float", "default_value": "1.0"}, {"fullname": "sglang.srt.server_args.ServerArgs.page_size", "modulename": "sglang.srt.server_args", "qualname": "ServerArgs.page_size", "kind": "variable", "doc": "<p></p>\n", "annotation": ": Optional[int]", "default_value": "None"}, {"fullname": "sglang.srt.server_args.ServerArgs.hybrid_kvcache_ratio", "modulename": "sglang.srt.server_args", "qualname": "ServerArgs.hybrid_kvcache_ratio", "kind": "variable", "doc": "<p></p>\n", "annotation": ": Optional[float]", "default_value": "None"}, {"fullname": "sglang.srt.server_args.ServerArgs.swa_full_tokens_ratio", "modulename": "sglang.srt.server_args", "qualname": "ServerArgs.swa_full_tokens_ratio", "kind": "variable", "doc": "<p></p>\n", "annotation": ": float", "default_value": "0.8"}, {"fullname": "sglang.srt.server_args.ServerArgs.disable_hybrid_swa_memory", "modulename": "sglang.srt.server_args", "qualname": "ServerArgs.disable_hybrid_swa_memory", "kind": "variable", "doc": "<p></p>\n", "annotation": ": bool", "default_value": "False"}, {"fullname": "sglang.srt.server_args.ServerArgs.device", "modulename": "sglang.srt.server_args", "qualname": "ServerArgs.device", "kind": "variable", "doc": "<p></p>\n", "annotation": ": Optional[str]", "default_value": "None"}, {"fullname": "sglang.srt.server_args.ServerArgs.tp_size", "modulename": "sglang.srt.server_args", "qualname": "ServerArgs.tp_size", "kind": "variable", "doc": "<p></p>\n", "annotation": ": int", "default_value": "1"}, {"fullname": "sglang.srt.server_args.ServerArgs.pp_size", "modulename": "sglang.srt.server_args", "qualname": "ServerArgs.pp_size", "kind": "variable", "doc": "<p></p>\n", "annotation": ": int", "default_value": "1"}, {"fullname": "sglang.srt.server_args.ServerArgs.max_micro_batch_size", "modulename": "sglang.srt.server_args", "qualname": "ServerArgs.max_micro_batch_size", "kind": "variable", "doc": "<p></p>\n", "annotation": ": Optional[int]", "default_value": "None"}, {"fullname": "sglang.srt.server_args.ServerArgs.stream_interval", "modulename": "sglang.srt.server_args", "qualname": "ServerArgs.stream_interval", "kind": "variable", "doc": "<p></p>\n", "annotation": ": int", "default_value": "1"}, {"fullname": "sglang.srt.server_args.ServerArgs.stream_output", "modulename": "sglang.srt.server_args", "qualname": "ServerArgs.stream_output", "kind": "variable", "doc": "<p></p>\n", "annotation": ": bool", "default_value": "False"}, {"fullname": "sglang.srt.server_args.ServerArgs.random_seed", "modulename": "sglang.srt.server_args", "qualname": "ServerArgs.random_seed", "kind": "variable", "doc": "<p></p>\n", "annotation": ": Optional[int]", "default_value": "None"}, {"fullname": "sglang.srt.server_args.ServerArgs.constrained_json_whitespace_pattern", "modulename": "sglang.srt.server_args", "qualname": "ServerArgs.constrained_json_whitespace_pattern", "kind": "variable", "doc": "<p></p>\n", "annotation": ": Optional[str]", "default_value": "None"}, {"fullname": "sglang.srt.server_args.ServerArgs.watchdog_timeout", "modulename": "sglang.srt.server_args", "qualname": "ServerArgs.watchdog_timeout", "kind": "variable", "doc": "<p></p>\n", "annotation": ": float", "default_value": "300"}, {"fullname": "sglang.srt.server_args.ServerArgs.dist_timeout", "modulename": "sglang.srt.server_args", "qualname": "ServerArgs.dist_timeout", "kind": "variable", "doc": "<p></p>\n", "annotation": ": Optional[int]", "default_value": "None"}, {"fullname": "sglang.srt.server_args.ServerArgs.download_dir", "modulename": "sglang.srt.server_args", "qualname": "ServerArgs.download_dir", "kind": "variable", "doc": "<p></p>\n", "annotation": ": Optional[str]", "default_value": "None"}, {"fullname": "sglang.srt.server_args.ServerArgs.base_gpu_id", "modulename": "sglang.srt.server_args", "qualname": "ServerArgs.base_gpu_id", "kind": "variable", "doc": "<p></p>\n", "annotation": ": int", "default_value": "0"}, {"fullname": "sglang.srt.server_args.ServerArgs.gpu_id_step", "modulename": "sglang.srt.server_args", "qualname": "ServerArgs.gpu_id_step", "kind": "variable", "doc": "<p></p>\n", "annotation": ": int", "default_value": "1"}, {"fullname": "sglang.srt.server_args.ServerArgs.sleep_on_idle", "modulename": "sglang.srt.server_args", "qualname": "ServerArgs.sleep_on_idle", "kind": "variable", "doc": "<p></p>\n", "annotation": ": bool", "default_value": "False"}, {"fullname": "sglang.srt.server_args.ServerArgs.log_level", "modulename": "sglang.srt.server_args", "qualname": "ServerArgs.log_level", "kind": "variable", "doc": "<p></p>\n", "annotation": ": str", "default_value": "&#x27;info&#x27;"}, {"fullname": "sglang.srt.server_args.ServerArgs.log_level_http", "modulename": "sglang.srt.server_args", "qualname": "ServerArgs.log_level_http", "kind": "variable", "doc": "<p></p>\n", "annotation": ": Optional[str]", "default_value": "None"}, {"fullname": "sglang.srt.server_args.ServerArgs.log_requests", "modulename": "sglang.srt.server_args", "qualname": "ServerArgs.log_requests", "kind": "variable", "doc": "<p></p>\n", "annotation": ": bool", "default_value": "False"}, {"fullname": "sglang.srt.server_args.ServerArgs.log_requests_level", "modulename": "sglang.srt.server_args", "qualname": "ServerArgs.log_requests_level", "kind": "variable", "doc": "<p></p>\n", "annotation": ": int", "default_value": "2"}, {"fullname": "sglang.srt.server_args.ServerArgs.crash_dump_folder", "modulename": "sglang.srt.server_args", "qualname": "ServerArgs.crash_dump_folder", "kind": "variable", "doc": "<p></p>\n", "annotation": ": Optional[str]", "default_value": "None"}, {"fullname": "sglang.srt.server_args.ServerArgs.show_time_cost", "modulename": "sglang.srt.server_args", "qualname": "ServerArgs.show_time_cost", "kind": "variable", "doc": "<p></p>\n", "annotation": ": bool", "default_value": "False"}, {"fullname": "sglang.srt.server_args.ServerArgs.enable_metrics", "modulename": "sglang.srt.server_args", "qualname": "ServerArgs.enable_metrics", "kind": "variable", "doc": "<p></p>\n", "annotation": ": bool", "default_value": "False"}, {"fullname": "sglang.srt.server_args.ServerArgs.enable_metrics_for_all_schedulers", "modulename": "sglang.srt.server_args", "qualname": "ServerArgs.enable_metrics_for_all_schedulers", "kind": "variable", "doc": "<p></p>\n", "annotation": ": bool", "default_value": "False"}, {"fullname": "sglang.srt.server_args.ServerArgs.bucket_time_to_first_token", "modulename": "sglang.srt.server_args", "qualname": "ServerArgs.bucket_time_to_first_token", "kind": "variable", "doc": "<p></p>\n", "annotation": ": Optional[List[float]]", "default_value": "None"}, {"fullname": "sglang.srt.server_args.ServerArgs.bucket_inter_token_latency", "modulename": "sglang.srt.server_args", "qualname": "ServerArgs.bucket_inter_token_latency", "kind": "variable", "doc": "<p></p>\n", "annotation": ": Optional[List[float]]", "default_value": "None"}, {"fullname": "sglang.srt.server_args.ServerArgs.bucket_e2e_request_latency", "modulename": "sglang.srt.server_args", "qualname": "ServerArgs.bucket_e2e_request_latency", "kind": "variable", "doc": "<p></p>\n", "annotation": ": Optional[List[float]]", "default_value": "None"}, {"fullname": "sglang.srt.server_args.ServerArgs.collect_tokens_histogram", "modulename": "sglang.srt.server_args", "qualname": "ServerArgs.collect_tokens_histogram", "kind": "variable", "doc": "<p></p>\n", "annotation": ": bool", "default_value": "False"}, {"fullname": "sglang.srt.server_args.ServerArgs.decode_log_interval", "modulename": "sglang.srt.server_args", "qualname": "ServerArgs.decode_log_interval", "kind": "variable", "doc": "<p></p>\n", "annotation": ": int", "default_value": "40"}, {"fullname": "sglang.srt.server_args.ServerArgs.enable_request_time_stats_logging", "modulename": "sglang.srt.server_args", "qualname": "ServerArgs.enable_request_time_stats_logging", "kind": "variable", "doc": "<p></p>\n", "annotation": ": bool", "default_value": "False"}, {"fullname": "sglang.srt.server_args.ServerArgs.kv_events_config", "modulename": "sglang.srt.server_args", "qualname": "ServerArgs.kv_events_config", "kind": "variable", "doc": "<p></p>\n", "annotation": ": Optional[str]", "default_value": "None"}, {"fullname": "sglang.srt.server_args.ServerArgs.gc_warning_threshold_secs", "modulename": "sglang.srt.server_args", "qualname": "ServerArgs.gc_warning_threshold_secs", "kind": "variable", "doc": "<p></p>\n", "annotation": ": float", "default_value": "0.0"}, {"fullname": "sglang.srt.server_args.ServerArgs.api_key", "modulename": "sglang.srt.server_args", "qualname": "ServerArgs.api_key", "kind": "variable", "doc": "<p></p>\n", "annotation": ": Optional[str]", "default_value": "None"}, {"fullname": "sglang.srt.server_args.ServerArgs.served_model_name", "modulename": "sglang.srt.server_args", "qualname": "ServerArgs.served_model_name", "kind": "variable", "doc": "<p></p>\n", "annotation": ": Optional[str]", "default_value": "None"}, {"fullname": "sglang.srt.server_args.ServerArgs.weight_version", "modulename": "sglang.srt.server_args", "qualname": "ServerArgs.weight_version", "kind": "variable", "doc": "<p></p>\n", "annotation": ": str", "default_value": "&#x27;default&#x27;"}, {"fullname": "sglang.srt.server_args.ServerArgs.chat_template", "modulename": "sglang.srt.server_args", "qualname": "ServerArgs.chat_template", "kind": "variable", "doc": "<p></p>\n", "annotation": ": Optional[str]", "default_value": "None"}, {"fullname": "sglang.srt.server_args.ServerArgs.completion_template", "modulename": "sglang.srt.server_args", "qualname": "ServerArgs.completion_template", "kind": "variable", "doc": "<p></p>\n", "annotation": ": Optional[str]", "default_value": "None"}, {"fullname": "sglang.srt.server_args.ServerArgs.file_storage_path", "modulename": "sglang.srt.server_args", "qualname": "ServerArgs.file_storage_path", "kind": "variable", "doc": "<p></p>\n", "annotation": ": str", "default_value": "&#x27;sglang_storage&#x27;"}, {"fullname": "sglang.srt.server_args.ServerArgs.enable_cache_report", "modulename": "sglang.srt.server_args", "qualname": "ServerArgs.enable_cache_report", "kind": "variable", "doc": "<p></p>\n", "annotation": ": bool", "default_value": "False"}, {"fullname": "sglang.srt.server_args.ServerArgs.reasoning_parser", "modulename": "sglang.srt.server_args", "qualname": "ServerArgs.reasoning_parser", "kind": "variable", "doc": "<p></p>\n", "annotation": ": Optional[str]", "default_value": "None"}, {"fullname": "sglang.srt.server_args.ServerArgs.tool_call_parser", "modulename": "sglang.srt.server_args", "qualname": "ServerArgs.tool_call_parser", "kind": "variable", "doc": "<p></p>\n", "annotation": ": Optional[str]", "default_value": "None"}, {"fullname": "sglang.srt.server_args.ServerArgs.tool_server", "modulename": "sglang.srt.server_args", "qualname": "ServerArgs.tool_server", "kind": "variable", "doc": "<p></p>\n", "annotation": ": Optional[str]", "default_value": "None"}, {"fullname": "sglang.srt.server_args.ServerArgs.dp_size", "modulename": "sglang.srt.server_args", "qualname": "ServerArgs.dp_size", "kind": "variable", "doc": "<p></p>\n", "annotation": ": int", "default_value": "1"}, {"fullname": "sglang.srt.server_args.ServerArgs.load_balance_method", "modulename": "sglang.srt.server_args", "qualname": "ServerArgs.load_balance_method", "kind": "variable", "doc": "<p></p>\n", "annotation": ": str", "default_value": "&#x27;round_robin&#x27;"}, {"fullname": "sglang.srt.server_args.ServerArgs.dist_init_addr", "modulename": "sglang.srt.server_args", "qualname": "ServerArgs.dist_init_addr", "kind": "variable", "doc": "<p></p>\n", "annotation": ": Optional[str]", "default_value": "None"}, {"fullname": "sglang.srt.server_args.ServerArgs.nnodes", "modulename": "sglang.srt.server_args", "qualname": "ServerArgs.nnodes", "kind": "variable", "doc": "<p></p>\n", "annotation": ": int", "default_value": "1"}, {"fullname": "sglang.srt.server_args.ServerArgs.node_rank", "modulename": "sglang.srt.server_args", "qualname": "ServerArgs.node_rank", "kind": "variable", "doc": "<p></p>\n", "annotation": ": int", "default_value": "0"}, {"fullname": "sglang.srt.server_args.ServerArgs.json_model_override_args", "modulename": "sglang.srt.server_args", "qualname": "ServerArgs.json_model_override_args", "kind": "variable", "doc": "<p></p>\n", "annotation": ": str", "default_value": "&#x27;{}&#x27;"}, {"fullname": "sglang.srt.server_args.ServerArgs.preferred_sampling_params", "modulename": "sglang.srt.server_args", "qualname": "ServerArgs.preferred_sampling_params", "kind": "variable", "doc": "<p></p>\n", "annotation": ": Optional[str]", "default_value": "None"}, {"fullname": "sglang.srt.server_args.ServerArgs.enable_lora", "modulename": "sglang.srt.server_args", "qualname": "ServerArgs.enable_lora", "kind": "variable", "doc": "<p></p>\n", "annotation": ": Optional[bool]", "default_value": "None"}, {"fullname": "sglang.srt.server_args.ServerArgs.max_lora_rank", "modulename": "sglang.srt.server_args", "qualname": "ServerArgs.max_lora_rank", "kind": "variable", "doc": "<p></p>\n", "annotation": ": Optional[int]", "default_value": "None"}, {"fullname": "sglang.srt.server_args.ServerArgs.lora_target_modules", "modulename": "sglang.srt.server_args", "qualname": "ServerArgs.lora_target_modules", "kind": "variable", "doc": "<p></p>\n", "annotation": ": Union[set[str], List[str], NoneType]", "default_value": "None"}, {"fullname": "sglang.srt.server_args.ServerArgs.lora_paths", "modulename": "sglang.srt.server_args", "qualname": "ServerArgs.lora_paths", "kind": "variable", "doc": "<p></p>\n", "annotation": ": Union[dict[str, str], List[dict[str, str]], List[str], List[sglang.srt.lora.lora_registry.LoRARef], NoneType]", "default_value": "None"}, {"fullname": "sglang.srt.server_args.ServerArgs.max_loaded_loras", "modulename": "sglang.srt.server_args", "qualname": "ServerArgs.max_loaded_loras", "kind": "variable", "doc": "<p></p>\n", "annotation": ": Optional[int]", "default_value": "None"}, {"fullname": "sglang.srt.server_args.ServerArgs.max_loras_per_batch", "modulename": "sglang.srt.server_args", "qualname": "ServerArgs.max_loras_per_batch", "kind": "variable", "doc": "<p></p>\n", "annotation": ": int", "default_value": "8"}, {"fullname": "sglang.srt.server_args.ServerArgs.lora_backend", "modulename": "sglang.srt.server_args", "qualname": "ServerArgs.lora_backend", "kind": "variable", "doc": "<p></p>\n", "annotation": ": str", "default_value": "&#x27;triton&#x27;"}, {"fullname": "sglang.srt.server_args.ServerArgs.attention_backend", "modulename": "sglang.srt.server_args", "qualname": "ServerArgs.attention_backend", "kind": "variable", "doc": "<p></p>\n", "annotation": ": Optional[str]", "default_value": "None"}, {"fullname": "sglang.srt.server_args.ServerArgs.decode_attention_backend", "modulename": "sglang.srt.server_args", "qualname": "ServerArgs.decode_attention_backend", "kind": "variable", "doc": "<p></p>\n", "annotation": ": Optional[str]", "default_value": "None"}, {"fullname": "sglang.srt.server_args.ServerArgs.prefill_attention_backend", "modulename": "sglang.srt.server_args", "qualname": "ServerArgs.prefill_attention_backend", "kind": "variable", "doc": "<p></p>\n", "annotation": ": Optional[str]", "default_value": "None"}, {"fullname": "sglang.srt.server_args.ServerArgs.sampling_backend", "modulename": "sglang.srt.server_args", "qualname": "ServerArgs.sampling_backend", "kind": "variable", "doc": "<p></p>\n", "annotation": ": Optional[str]", "default_value": "None"}, {"fullname": "sglang.srt.server_args.ServerArgs.grammar_backend", "modulename": "sglang.srt.server_args", "qualname": "ServerArgs.grammar_backend", "kind": "variable", "doc": "<p></p>\n", "annotation": ": Optional[str]", "default_value": "None"}, {"fullname": "sglang.srt.server_args.ServerArgs.mm_attention_backend", "modulename": "sglang.srt.server_args", "qualname": "ServerArgs.mm_attention_backend", "kind": "variable", "doc": "<p></p>\n", "annotation": ": Optional[str]", "default_value": "None"}, {"fullname": "sglang.srt.server_args.ServerArgs.speculative_algorithm", "modulename": "sglang.srt.server_args", "qualname": "ServerArgs.speculative_algorithm", "kind": "variable", "doc": "<p></p>\n", "annotation": ": Optional[str]", "default_value": "None"}, {"fullname": "sglang.srt.server_args.ServerArgs.speculative_draft_model_path", "modulename": "sglang.srt.server_args", "qualname": "ServerArgs.speculative_draft_model_path", "kind": "variable", "doc": "<p></p>\n", "annotation": ": Optional[str]", "default_value": "None"}, {"fullname": "sglang.srt.server_args.ServerArgs.speculative_num_steps", "modulename": "sglang.srt.server_args", "qualname": "ServerArgs.speculative_num_steps", "kind": "variable", "doc": "<p></p>\n", "annotation": ": Optional[int]", "default_value": "None"}, {"fullname": "sglang.srt.server_args.ServerArgs.speculative_eagle_topk", "modulename": "sglang.srt.server_args", "qualname": "ServerArgs.speculative_eagle_topk", "kind": "variable", "doc": "<p></p>\n", "annotation": ": Optional[int]", "default_value": "None"}, {"fullname": "sglang.srt.server_args.ServerArgs.speculative_num_draft_tokens", "modulename": "sglang.srt.server_args", "qualname": "ServerArgs.speculative_num_draft_tokens", "kind": "variable", "doc": "<p></p>\n", "annotation": ": Optional[int]", "default_value": "None"}, {"fullname": "sglang.srt.server_args.ServerArgs.speculative_accept_threshold_single", "modulename": "sglang.srt.server_args", "qualname": "ServerArgs.speculative_accept_threshold_single", "kind": "variable", "doc": "<p></p>\n", "annotation": ": float", "default_value": "1.0"}, {"fullname": "sglang.srt.server_args.ServerArgs.speculative_accept_threshold_acc", "modulename": "sglang.srt.server_args", "qualname": "ServerArgs.speculative_accept_threshold_acc", "kind": "variable", "doc": "<p></p>\n", "annotation": ": float", "default_value": "1.0"}, {"fullname": "sglang.srt.server_args.ServerArgs.speculative_token_map", "modulename": "sglang.srt.server_args", "qualname": "ServerArgs.speculative_token_map", "kind": "variable", "doc": "<p></p>\n", "annotation": ": Optional[str]", "default_value": "None"}, {"fullname": "sglang.srt.server_args.ServerArgs.ep_size", "modulename": "sglang.srt.server_args", "qualname": "ServerArgs.ep_size", "kind": "variable", "doc": "<p></p>\n", "annotation": ": int", "default_value": "1"}, {"fullname": "sglang.srt.server_args.ServerArgs.moe_a2a_backend", "modulename": "sglang.srt.server_args", "qualname": "ServerArgs.moe_a2a_backend", "kind": "variable", "doc": "<p></p>\n", "annotation": ": Literal[&#x27;none&#x27;, &#x27;deepep&#x27;]", "default_value": "&#x27;none&#x27;"}, {"fullname": "sglang.srt.server_args.ServerArgs.moe_runner_backend", "modulename": "sglang.srt.server_args", "qualname": "ServerArgs.moe_runner_backend", "kind": "variable", "doc": "<p></p>\n", "annotation": ": Literal[&#x27;auto&#x27;, &#x27;triton&#x27;, &#x27;triton_kernel&#x27;, &#x27;flashinfer_trtllm&#x27;, &#x27;flashinfer_cutlass&#x27;, &#x27;flashinfer_mxfp4&#x27;]", "default_value": "&#x27;auto&#x27;"}, {"fullname": "sglang.srt.server_args.ServerArgs.flashinfer_mxfp4_moe_precision", "modulename": "sglang.srt.server_args", "qualname": "ServerArgs.flashinfer_mxfp4_moe_precision", "kind": "variable", "doc": "<p></p>\n", "annotation": ": Literal[&#x27;default&#x27;, &#x27;bf16&#x27;]", "default_value": "&#x27;default&#x27;"}, {"fullname": "sglang.srt.server_args.ServerArgs.enable_flashinfer_allreduce_fusion", "modulename": "sglang.srt.server_args", "qualname": "ServerArgs.enable_flashinfer_allreduce_fusion", "kind": "variable", "doc": "<p></p>\n", "annotation": ": bool", "default_value": "False"}, {"fullname": "sglang.srt.server_args.ServerArgs.deepep_mode", "modulename": "sglang.srt.server_args", "qualname": "ServerArgs.deepep_mode", "kind": "variable", "doc": "<p></p>\n", "annotation": ": Literal[&#x27;auto&#x27;, &#x27;normal&#x27;, &#x27;low_latency&#x27;]", "default_value": "&#x27;auto&#x27;"}, {"fullname": "sglang.srt.server_args.ServerArgs.ep_num_redundant_experts", "modulename": "sglang.srt.server_args", "qualname": "ServerArgs.ep_num_redundant_experts", "kind": "variable", "doc": "<p></p>\n", "annotation": ": int", "default_value": "0"}, {"fullname": "sglang.srt.server_args.ServerArgs.ep_dispatch_algorithm", "modulename": "sglang.srt.server_args", "qualname": "ServerArgs.ep_dispatch_algorithm", "kind": "variable", "doc": "<p></p>\n", "annotation": ": Optional[Literal[&#x27;static&#x27;, &#x27;dynamic&#x27;, &#x27;fake&#x27;]]", "default_value": "None"}, {"fullname": "sglang.srt.server_args.ServerArgs.init_expert_location", "modulename": "sglang.srt.server_args", "qualname": "ServerArgs.init_expert_location", "kind": "variable", "doc": "<p></p>\n", "annotation": ": str", "default_value": "&#x27;trivial&#x27;"}, {"fullname": "sglang.srt.server_args.ServerArgs.enable_eplb", "modulename": "sglang.srt.server_args", "qualname": "ServerArgs.enable_eplb", "kind": "variable", "doc": "<p></p>\n", "annotation": ": bool", "default_value": "False"}, {"fullname": "sglang.srt.server_args.ServerArgs.eplb_algorithm", "modulename": "sglang.srt.server_args", "qualname": "ServerArgs.eplb_algorithm", "kind": "variable", "doc": "<p></p>\n", "annotation": ": str", "default_value": "&#x27;auto&#x27;"}, {"fullname": "sglang.srt.server_args.ServerArgs.eplb_rebalance_num_iterations", "modulename": "sglang.srt.server_args", "qualname": "ServerArgs.eplb_rebalance_num_iterations", "kind": "variable", "doc": "<p></p>\n", "annotation": ": int", "default_value": "1000"}, {"fullname": "sglang.srt.server_args.ServerArgs.eplb_rebalance_layers_per_chunk", "modulename": "sglang.srt.server_args", "qualname": "ServerArgs.eplb_rebalance_layers_per_chunk", "kind": "variable", "doc": "<p></p>\n", "annotation": ": Optional[int]", "default_value": "None"}, {"fullname": "sglang.srt.server_args.ServerArgs.expert_distribution_recorder_mode", "modulename": "sglang.srt.server_args", "qualname": "ServerArgs.expert_distribution_recorder_mode", "kind": "variable", "doc": "<p></p>\n", "annotation": ": Optional[Literal[&#x27;stat&#x27;, &#x27;stat_approx&#x27;, &#x27;per_pass&#x27;, &#x27;per_token&#x27;]]", "default_value": "None"}, {"fullname": "sglang.srt.server_args.ServerArgs.expert_distribution_recorder_buffer_size", "modulename": "sglang.srt.server_args", "qualname": "ServerArgs.expert_distribution_recorder_buffer_size", "kind": "variable", "doc": "<p></p>\n", "annotation": ": Optional[int]", "default_value": "None"}, {"fullname": "sglang.srt.server_args.ServerArgs.enable_expert_distribution_metrics", "modulename": "sglang.srt.server_args", "qualname": "ServerArgs.enable_expert_distribution_metrics", "kind": "variable", "doc": "<p></p>\n", "annotation": ": bool", "default_value": "False"}, {"fullname": "sglang.srt.server_args.ServerArgs.deepep_config", "modulename": "sglang.srt.server_args", "qualname": "ServerArgs.deepep_config", "kind": "variable", "doc": "<p></p>\n", "annotation": ": Optional[str]", "default_value": "None"}, {"fullname": "sglang.srt.server_args.ServerArgs.moe_dense_tp_size", "modulename": "sglang.srt.server_args", "qualname": "ServerArgs.moe_dense_tp_size", "kind": "variable", "doc": "<p></p>\n", "annotation": ": Optional[int]", "default_value": "None"}, {"fullname": "sglang.srt.server_args.ServerArgs.enable_hierarchical_cache", "modulename": "sglang.srt.server_args", "qualname": "ServerArgs.enable_hierarchical_cache", "kind": "variable", "doc": "<p></p>\n", "annotation": ": bool", "default_value": "False"}, {"fullname": "sglang.srt.server_args.ServerArgs.hicache_ratio", "modulename": "sglang.srt.server_args", "qualname": "ServerArgs.hicache_ratio", "kind": "variable", "doc": "<p></p>\n", "annotation": ": float", "default_value": "2.0"}, {"fullname": "sglang.srt.server_args.ServerArgs.hicache_size", "modulename": "sglang.srt.server_args", "qualname": "ServerArgs.hicache_size", "kind": "variable", "doc": "<p></p>\n", "annotation": ": int", "default_value": "0"}, {"fullname": "sglang.srt.server_args.ServerArgs.hicache_write_policy", "modulename": "sglang.srt.server_args", "qualname": "ServerArgs.hicache_write_policy", "kind": "variable", "doc": "<p></p>\n", "annotation": ": str", "default_value": "&#x27;write_through_selective&#x27;"}, {"fullname": "sglang.srt.server_args.ServerArgs.hicache_io_backend", "modulename": "sglang.srt.server_args", "qualname": "ServerArgs.hicache_io_backend", "kind": "variable", "doc": "<p></p>\n", "annotation": ": str", "default_value": "&#x27;kernel&#x27;"}, {"fullname": "sglang.srt.server_args.ServerArgs.hicache_mem_layout", "modulename": "sglang.srt.server_args", "qualname": "ServerArgs.hicache_mem_layout", "kind": "variable", "doc": "<p></p>\n", "annotation": ": str", "default_value": "&#x27;layer_first&#x27;"}, {"fullname": "sglang.srt.server_args.ServerArgs.hicache_storage_backend", "modulename": "sglang.srt.server_args", "qualname": "ServerArgs.hicache_storage_backend", "kind": "variable", "doc": "<p></p>\n", "annotation": ": Optional[str]", "default_value": "None"}, {"fullname": "sglang.srt.server_args.ServerArgs.hicache_storage_prefetch_policy", "modulename": "sglang.srt.server_args", "qualname": "ServerArgs.hicache_storage_prefetch_policy", "kind": "variable", "doc": "<p></p>\n", "annotation": ": str", "default_value": "&#x27;best_effort&#x27;"}, {"fullname": "sglang.srt.server_args.ServerArgs.hicache_storage_backend_extra_config", "modulename": "sglang.srt.server_args", "qualname": "ServerArgs.hicache_storage_backend_extra_config", "kind": "variable", "doc": "<p></p>\n", "annotation": ": Optional[str]", "default_value": "None"}, {"fullname": "sglang.srt.server_args.ServerArgs.enable_double_sparsity", "modulename": "sglang.srt.server_args", "qualname": "ServerArgs.enable_double_sparsity", "kind": "variable", "doc": "<p></p>\n", "annotation": ": bool", "default_value": "False"}, {"fullname": "sglang.srt.server_args.ServerArgs.ds_channel_config_path", "modulename": "sglang.srt.server_args", "qualname": "ServerArgs.ds_channel_config_path", "kind": "variable", "doc": "<p></p>\n", "annotation": ": Optional[str]", "default_value": "None"}, {"fullname": "sglang.srt.server_args.ServerArgs.ds_heavy_channel_num", "modulename": "sglang.srt.server_args", "qualname": "ServerArgs.ds_heavy_channel_num", "kind": "variable", "doc": "<p></p>\n", "annotation": ": int", "default_value": "32"}, {"fullname": "sglang.srt.server_args.ServerArgs.ds_heavy_token_num", "modulename": "sglang.srt.server_args", "qualname": "ServerArgs.ds_heavy_token_num", "kind": "variable", "doc": "<p></p>\n", "annotation": ": int", "default_value": "256"}, {"fullname": "sglang.srt.server_args.ServerArgs.ds_heavy_channel_type", "modulename": "sglang.srt.server_args", "qualname": "ServerArgs.ds_heavy_channel_type", "kind": "variable", "doc": "<p></p>\n", "annotation": ": str", "default_value": "&#x27;qk&#x27;"}, {"fullname": "sglang.srt.server_args.ServerArgs.ds_sparse_decode_threshold", "modulename": "sglang.srt.server_args", "qualname": "ServerArgs.ds_sparse_decode_threshold", "kind": "variable", "doc": "<p></p>\n", "annotation": ": int", "default_value": "4096"}, {"fullname": "sglang.srt.server_args.ServerArgs.cpu_offload_gb", "modulename": "sglang.srt.server_args", "qualname": "ServerArgs.cpu_offload_gb", "kind": "variable", "doc": "<p></p>\n", "annotation": ": int", "default_value": "0"}, {"fullname": "sglang.srt.server_args.ServerArgs.offload_group_size", "modulename": "sglang.srt.server_args", "qualname": "ServerArgs.offload_group_size", "kind": "variable", "doc": "<p></p>\n", "annotation": ": int", "default_value": "-1"}, {"fullname": "sglang.srt.server_args.ServerArgs.offload_num_in_group", "modulename": "sglang.srt.server_args", "qualname": "ServerArgs.offload_num_in_group", "kind": "variable", "doc": "<p></p>\n", "annotation": ": int", "default_value": "1"}, {"fullname": "sglang.srt.server_args.ServerArgs.offload_prefetch_step", "modulename": "sglang.srt.server_args", "qualname": "ServerArgs.offload_prefetch_step", "kind": "variable", "doc": "<p></p>\n", "annotation": ": int", "default_value": "1"}, {"fullname": "sglang.srt.server_args.ServerArgs.offload_mode", "modulename": "sglang.srt.server_args", "qualname": "ServerArgs.offload_mode", "kind": "variable", "doc": "<p></p>\n", "annotation": ": str", "default_value": "&#x27;cpu&#x27;"}, {"fullname": "sglang.srt.server_args.ServerArgs.disable_radix_cache", "modulename": "sglang.srt.server_args", "qualname": "ServerArgs.disable_radix_cache", "kind": "variable", "doc": "<p></p>\n", "annotation": ": bool", "default_value": "False"}, {"fullname": "sglang.srt.server_args.ServerArgs.cuda_graph_max_bs", "modulename": "sglang.srt.server_args", "qualname": "ServerArgs.cuda_graph_max_bs", "kind": "variable", "doc": "<p></p>\n", "annotation": ": Optional[int]", "default_value": "None"}, {"fullname": "sglang.srt.server_args.ServerArgs.cuda_graph_bs", "modulename": "sglang.srt.server_args", "qualname": "ServerArgs.cuda_graph_bs", "kind": "variable", "doc": "<p></p>\n", "annotation": ": Optional[List[int]]", "default_value": "None"}, {"fullname": "sglang.srt.server_args.ServerArgs.disable_cuda_graph", "modulename": "sglang.srt.server_args", "qualname": "ServerArgs.disable_cuda_graph", "kind": "variable", "doc": "<p></p>\n", "annotation": ": bool", "default_value": "False"}, {"fullname": "sglang.srt.server_args.ServerArgs.disable_cuda_graph_padding", "modulename": "sglang.srt.server_args", "qualname": "ServerArgs.disable_cuda_graph_padding", "kind": "variable", "doc": "<p></p>\n", "annotation": ": bool", "default_value": "False"}, {"fullname": "sglang.srt.server_args.ServerArgs.enable_profile_cuda_graph", "modulename": "sglang.srt.server_args", "qualname": "ServerArgs.enable_profile_cuda_graph", "kind": "variable", "doc": "<p></p>\n", "annotation": ": bool", "default_value": "False"}, {"fullname": "sglang.srt.server_args.ServerArgs.enable_cudagraph_gc", "modulename": "sglang.srt.server_args", "qualname": "ServerArgs.enable_cudagraph_gc", "kind": "variable", "doc": "<p></p>\n", "annotation": ": bool", "default_value": "False"}, {"fullname": "sglang.srt.server_args.ServerArgs.enable_nccl_nvls", "modulename": "sglang.srt.server_args", "qualname": "ServerArgs.enable_nccl_nvls", "kind": "variable", "doc": "<p></p>\n", "annotation": ": bool", "default_value": "False"}, {"fullname": "sglang.srt.server_args.ServerArgs.enable_symm_mem", "modulename": "sglang.srt.server_args", "qualname": "ServerArgs.enable_symm_mem", "kind": "variable", "doc": "<p></p>\n", "annotation": ": bool", "default_value": "False"}, {"fullname": "sglang.srt.server_args.ServerArgs.disable_flashinfer_cutlass_moe_fp4_allgather", "modulename": "sglang.srt.server_args", "qualname": "ServerArgs.disable_flashinfer_cutlass_moe_fp4_allgather", "kind": "variable", "doc": "<p></p>\n", "annotation": ": bool", "default_value": "False"}, {"fullname": "sglang.srt.server_args.ServerArgs.enable_tokenizer_batch_encode", "modulename": "sglang.srt.server_args", "qualname": "ServerArgs.enable_tokenizer_batch_encode", "kind": "variable", "doc": "<p></p>\n", "annotation": ": bool", "default_value": "False"}, {"fullname": "sglang.srt.server_args.ServerArgs.disable_outlines_disk_cache", "modulename": "sglang.srt.server_args", "qualname": "ServerArgs.disable_outlines_disk_cache", "kind": "variable", "doc": "<p></p>\n", "annotation": ": bool", "default_value": "False"}, {"fullname": "sglang.srt.server_args.ServerArgs.disable_custom_all_reduce", "modulename": "sglang.srt.server_args", "qualname": "ServerArgs.disable_custom_all_reduce", "kind": "variable", "doc": "<p></p>\n", "annotation": ": bool", "default_value": "False"}, {"fullname": "sglang.srt.server_args.ServerArgs.enable_mscclpp", "modulename": "sglang.srt.server_args", "qualname": "ServerArgs.enable_mscclpp", "kind": "variable", "doc": "<p></p>\n", "annotation": ": bool", "default_value": "False"}, {"fullname": "sglang.srt.server_args.ServerArgs.disable_overlap_schedule", "modulename": "sglang.srt.server_args", "qualname": "ServerArgs.disable_overlap_schedule", "kind": "variable", "doc": "<p></p>\n", "annotation": ": bool", "default_value": "False"}, {"fullname": "sglang.srt.server_args.ServerArgs.enable_mixed_chunk", "modulename": "sglang.srt.server_args", "qualname": "ServerArgs.enable_mixed_chunk", "kind": "variable", "doc": "<p></p>\n", "annotation": ": bool", "default_value": "False"}, {"fullname": "sglang.srt.server_args.ServerArgs.enable_dp_attention", "modulename": "sglang.srt.server_args", "qualname": "ServerArgs.enable_dp_attention", "kind": "variable", "doc": "<p></p>\n", "annotation": ": bool", "default_value": "False"}, {"fullname": "sglang.srt.server_args.ServerArgs.enable_dp_lm_head", "modulename": "sglang.srt.server_args", "qualname": "ServerArgs.enable_dp_lm_head", "kind": "variable", "doc": "<p></p>\n", "annotation": ": bool", "default_value": "False"}, {"fullname": "sglang.srt.server_args.ServerArgs.enable_two_batch_overlap", "modulename": "sglang.srt.server_args", "qualname": "ServerArgs.enable_two_batch_overlap", "kind": "variable", "doc": "<p></p>\n", "annotation": ": bool", "default_value": "False"}, {"fullname": "sglang.srt.server_args.ServerArgs.tbo_token_distribution_threshold", "modulename": "sglang.srt.server_args", "qualname": "ServerArgs.tbo_token_distribution_threshold", "kind": "variable", "doc": "<p></p>\n", "annotation": ": float", "default_value": "0.48"}, {"fullname": "sglang.srt.server_args.ServerArgs.enable_torch_compile", "modulename": "sglang.srt.server_args", "qualname": "ServerArgs.enable_torch_compile", "kind": "variable", "doc": "<p></p>\n", "annotation": ": bool", "default_value": "False"}, {"fullname": "sglang.srt.server_args.ServerArgs.torch_compile_max_bs", "modulename": "sglang.srt.server_args", "qualname": "ServerArgs.torch_compile_max_bs", "kind": "variable", "doc": "<p></p>\n", "annotation": ": int", "default_value": "32"}, {"fullname": "sglang.srt.server_args.ServerArgs.torchao_config", "modulename": "sglang.srt.server_args", "qualname": "ServerArgs.torchao_config", "kind": "variable", "doc": "<p></p>\n", "annotation": ": str", "default_value": "&#x27;&#x27;"}, {"fullname": "sglang.srt.server_args.ServerArgs.enable_nan_detection", "modulename": "sglang.srt.server_args", "qualname": "ServerArgs.enable_nan_detection", "kind": "variable", "doc": "<p></p>\n", "annotation": ": bool", "default_value": "False"}, {"fullname": "sglang.srt.server_args.ServerArgs.enable_p2p_check", "modulename": "sglang.srt.server_args", "qualname": "ServerArgs.enable_p2p_check", "kind": "variable", "doc": "<p></p>\n", "annotation": ": bool", "default_value": "False"}, {"fullname": "sglang.srt.server_args.ServerArgs.triton_attention_reduce_in_fp32", "modulename": "sglang.srt.server_args", "qualname": "ServerArgs.triton_attention_reduce_in_fp32", "kind": "variable", "doc": "<p></p>\n", "annotation": ": bool", "default_value": "False"}, {"fullname": "sglang.srt.server_args.ServerArgs.triton_attention_num_kv_splits", "modulename": "sglang.srt.server_args", "qualname": "ServerArgs.triton_attention_num_kv_splits", "kind": "variable", "doc": "<p></p>\n", "annotation": ": int", "default_value": "8"}, {"fullname": "sglang.srt.server_args.ServerArgs.num_continuous_decode_steps", "modulename": "sglang.srt.server_args", "qualname": "ServerArgs.num_continuous_decode_steps", "kind": "variable", "doc": "<p></p>\n", "annotation": ": int", "default_value": "1"}, {"fullname": "sglang.srt.server_args.ServerArgs.delete_ckpt_after_loading", "modulename": "sglang.srt.server_args", "qualname": "ServerArgs.delete_ckpt_after_loading", "kind": "variable", "doc": "<p></p>\n", "annotation": ": bool", "default_value": "False"}, {"fullname": "sglang.srt.server_args.ServerArgs.enable_memory_saver", "modulename": "sglang.srt.server_args", "qualname": "ServerArgs.enable_memory_saver", "kind": "variable", "doc": "<p></p>\n", "annotation": ": bool", "default_value": "False"}, {"fullname": "sglang.srt.server_args.ServerArgs.allow_auto_truncate", "modulename": "sglang.srt.server_args", "qualname": "ServerArgs.allow_auto_truncate", "kind": "variable", "doc": "<p></p>\n", "annotation": ": bool", "default_value": "False"}, {"fullname": "sglang.srt.server_args.ServerArgs.enable_custom_logit_processor", "modulename": "sglang.srt.server_args", "qualname": "ServerArgs.enable_custom_logit_processor", "kind": "variable", "doc": "<p></p>\n", "annotation": ": bool", "default_value": "False"}, {"fullname": "sglang.srt.server_args.ServerArgs.flashinfer_mla_disable_ragged", "modulename": "sglang.srt.server_args", "qualname": "ServerArgs.flashinfer_mla_disable_ragged", "kind": "variable", "doc": "<p></p>\n", "annotation": ": bool", "default_value": "False"}, {"fullname": "sglang.srt.server_args.ServerArgs.disable_shared_experts_fusion", "modulename": "sglang.srt.server_args", "qualname": "ServerArgs.disable_shared_experts_fusion", "kind": "variable", "doc": "<p></p>\n", "annotation": ": bool", "default_value": "False"}, {"fullname": "sglang.srt.server_args.ServerArgs.disable_chunked_prefix_cache", "modulename": "sglang.srt.server_args", "qualname": "ServerArgs.disable_chunked_prefix_cache", "kind": "variable", "doc": "<p></p>\n", "annotation": ": bool", "default_value": "False"}, {"fullname": "sglang.srt.server_args.ServerArgs.disable_fast_image_processor", "modulename": "sglang.srt.server_args", "qualname": "ServerArgs.disable_fast_image_processor", "kind": "variable", "doc": "<p></p>\n", "annotation": ": bool", "default_value": "False"}, {"fullname": "sglang.srt.server_args.ServerArgs.enable_return_hidden_states", "modulename": "sglang.srt.server_args", "qualname": "ServerArgs.enable_return_hidden_states", "kind": "variable", "doc": "<p></p>\n", "annotation": ": bool", "default_value": "False"}, {"fullname": "sglang.srt.server_args.ServerArgs.scheduler_recv_interval", "modulename": "sglang.srt.server_args", "qualname": "ServerArgs.scheduler_recv_interval", "kind": "variable", "doc": "<p></p>\n", "annotation": ": int", "default_value": "1"}, {"fullname": "sglang.srt.server_args.ServerArgs.debug_tensor_dump_output_folder", "modulename": "sglang.srt.server_args", "qualname": "ServerArgs.debug_tensor_dump_output_folder", "kind": "variable", "doc": "<p></p>\n", "annotation": ": Optional[str]", "default_value": "None"}, {"fullname": "sglang.srt.server_args.ServerArgs.debug_tensor_dump_input_file", "modulename": "sglang.srt.server_args", "qualname": "ServerArgs.debug_tensor_dump_input_file", "kind": "variable", "doc": "<p></p>\n", "annotation": ": Optional[str]", "default_value": "None"}, {"fullname": "sglang.srt.server_args.ServerArgs.debug_tensor_dump_inject", "modulename": "sglang.srt.server_args", "qualname": "ServerArgs.debug_tensor_dump_inject", "kind": "variable", "doc": "<p></p>\n", "annotation": ": bool", "default_value": "False"}, {"fullname": "sglang.srt.server_args.ServerArgs.debug_tensor_dump_prefill_only", "modulename": "sglang.srt.server_args", "qualname": "ServerArgs.debug_tensor_dump_prefill_only", "kind": "variable", "doc": "<p></p>\n", "annotation": ": bool", "default_value": "False"}, {"fullname": "sglang.srt.server_args.ServerArgs.disaggregation_mode", "modulename": "sglang.srt.server_args", "qualname": "ServerArgs.disaggregation_mode", "kind": "variable", "doc": "<p></p>\n", "annotation": ": str", "default_value": "&#x27;null&#x27;"}, {"fullname": "sglang.srt.server_args.ServerArgs.disaggregation_transfer_backend", "modulename": "sglang.srt.server_args", "qualname": "ServerArgs.disaggregation_transfer_backend", "kind": "variable", "doc": "<p></p>\n", "annotation": ": str", "default_value": "&#x27;mooncake&#x27;"}, {"fullname": "sglang.srt.server_args.ServerArgs.disaggregation_bootstrap_port", "modulename": "sglang.srt.server_args", "qualname": "ServerArgs.disaggregation_bootstrap_port", "kind": "variable", "doc": "<p></p>\n", "annotation": ": int", "default_value": "8998"}, {"fullname": "sglang.srt.server_args.ServerArgs.disaggregation_decode_tp", "modulename": "sglang.srt.server_args", "qualname": "ServerArgs.disaggregation_decode_tp", "kind": "variable", "doc": "<p></p>\n", "annotation": ": Optional[int]", "default_value": "None"}, {"fullname": "sglang.srt.server_args.ServerArgs.disaggregation_decode_dp", "modulename": "sglang.srt.server_args", "qualname": "ServerArgs.disaggregation_decode_dp", "kind": "variable", "doc": "<p></p>\n", "annotation": ": Optional[int]", "default_value": "None"}, {"fullname": "sglang.srt.server_args.ServerArgs.disaggregation_prefill_pp", "modulename": "sglang.srt.server_args", "qualname": "ServerArgs.disaggregation_prefill_pp", "kind": "variable", "doc": "<p></p>\n", "annotation": ": Optional[int]", "default_value": "1"}, {"fullname": "sglang.srt.server_args.ServerArgs.disaggregation_ib_device", "modulename": "sglang.srt.server_args", "qualname": "ServerArgs.disaggregation_ib_device", "kind": "variable", "doc": "<p></p>\n", "annotation": ": Optional[str]", "default_value": "None"}, {"fullname": "sglang.srt.server_args.ServerArgs.num_reserved_decode_tokens", "modulename": "sglang.srt.server_args", "qualname": "ServerArgs.num_reserved_decode_tokens", "kind": "variable", "doc": "<p></p>\n", "annotation": ": int", "default_value": "512"}, {"fullname": "sglang.srt.server_args.ServerArgs.pdlb_url", "modulename": "sglang.srt.server_args", "qualname": "ServerArgs.pdlb_url", "kind": "variable", "doc": "<p></p>\n", "annotation": ": Optional[str]", "default_value": "None"}, {"fullname": "sglang.srt.server_args.ServerArgs.custom_weight_loader", "modulename": "sglang.srt.server_args", "qualname": "ServerArgs.custom_weight_loader", "kind": "variable", "doc": "<p></p>\n", "annotation": ": Optional[List[str]]", "default_value": "None"}, {"fullname": "sglang.srt.server_args.ServerArgs.weight_loader_disable_mmap", "modulename": "sglang.srt.server_args", "qualname": "ServerArgs.weight_loader_disable_mmap", "kind": "variable", "doc": "<p></p>\n", "annotation": ": bool", "default_value": "False"}, {"fullname": "sglang.srt.server_args.ServerArgs.enable_pdmux", "modulename": "sglang.srt.server_args", "qualname": "ServerArgs.enable_pdmux", "kind": "variable", "doc": "<p></p>\n", "annotation": ": bool", "default_value": "False"}, {"fullname": "sglang.srt.server_args.ServerArgs.sm_group_num", "modulename": "sglang.srt.server_args", "qualname": "ServerArgs.sm_group_num", "kind": "variable", "doc": "<p></p>\n", "annotation": ": int", "default_value": "3"}, {"fullname": "sglang.srt.server_args.ServerArgs.enable_ep_moe", "modulename": "sglang.srt.server_args", "qualname": "ServerArgs.enable_ep_moe", "kind": "variable", "doc": "<p></p>\n", "annotation": ": bool", "default_value": "False"}, {"fullname": "sglang.srt.server_args.ServerArgs.enable_deepep_moe", "modulename": "sglang.srt.server_args", "qualname": "ServerArgs.enable_deepep_moe", "kind": "variable", "doc": "<p></p>\n", "annotation": ": bool", "default_value": "False"}, {"fullname": "sglang.srt.server_args.ServerArgs.enable_flashinfer_cutlass_moe", "modulename": "sglang.srt.server_args", "qualname": "ServerArgs.enable_flashinfer_cutlass_moe", "kind": "variable", "doc": "<p></p>\n", "annotation": ": bool", "default_value": "False"}, {"fullname": "sglang.srt.server_args.ServerArgs.enable_flashinfer_trtllm_moe", "modulename": "sglang.srt.server_args", "qualname": "ServerArgs.enable_flashinfer_trtllm_moe", "kind": "variable", "doc": "<p></p>\n", "annotation": ": bool", "default_value": "False"}, {"fullname": "sglang.srt.server_args.ServerArgs.enable_triton_kernel_moe", "modulename": "sglang.srt.server_args", "qualname": "ServerArgs.enable_triton_kernel_moe", "kind": "variable", "doc": "<p></p>\n", "annotation": ": bool", "default_value": "False"}, {"fullname": "sglang.srt.server_args.ServerArgs.enable_flashinfer_mxfp4_moe", "modulename": "sglang.srt.server_args", "qualname": "ServerArgs.enable_flashinfer_mxfp4_moe", "kind": "variable", "doc": "<p></p>\n", "annotation": ": bool", "default_value": "False"}, {"fullname": "sglang.srt.server_args.ServerArgs.add_cli_args", "modulename": "sglang.srt.server_args", "qualname": "ServerArgs.add_cli_args", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">parser</span><span class=\"p\">:</span> <span class=\"n\">argparse</span><span class=\"o\">.</span><span class=\"n\">ArgumentParser</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.server_args.ServerArgs.from_cli_args", "modulename": "sglang.srt.server_args", "qualname": "ServerArgs.from_cli_args", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">cls</span>, </span><span class=\"param\"><span class=\"n\">args</span><span class=\"p\">:</span> <span class=\"n\">argparse</span><span class=\"o\">.</span><span class=\"n\">Namespace</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.server_args.ServerArgs.url", "modulename": "sglang.srt.server_args", "qualname": "ServerArgs.url", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.server_args.ServerArgs.get_hf_config", "modulename": "sglang.srt.server_args", "qualname": "ServerArgs.get_hf_config", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.server_args.ServerArgs.check_server_args", "modulename": "sglang.srt.server_args", "qualname": "ServerArgs.check_server_args", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.server_args.ServerArgs.check_lora_server_args", "modulename": "sglang.srt.server_args", "qualname": "ServerArgs.check_lora_server_args", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.server_args.ServerArgs.validate_disagg_tp_size", "modulename": "sglang.srt.server_args", "qualname": "ServerArgs.validate_disagg_tp_size", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">prefill_tp</span><span class=\"p\">:</span> <span class=\"nb\">int</span>, </span><span class=\"param\"><span class=\"n\">decode_tp</span><span class=\"p\">:</span> <span class=\"nb\">int</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.server_args.ServerArgs.model_specific_adjustments", "modulename": "sglang.srt.server_args", "qualname": "ServerArgs.model_specific_adjustments", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.server_args.ServerArgs.adjust_mem_fraction_for_vlm", "modulename": "sglang.srt.server_args", "qualname": "ServerArgs.adjust_mem_fraction_for_vlm", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">model_config</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.server_args.prepare_server_args", "modulename": "sglang.srt.server_args", "qualname": "prepare_server_args", "kind": "function", "doc": "<p>Prepare the server arguments from the command line arguments.</p>\n\n<p>Args:\n    args: The command line arguments. Typically, it should be <code>sys.argv[1:]</code>\n        to ensure compatibility with <code>parse_args</code> when no arguments are passed.</p>\n\n<p>Returns:\n    The server arguments.</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">argv</span><span class=\"p\">:</span> <span class=\"n\">List</span><span class=\"p\">[</span><span class=\"nb\">str</span><span class=\"p\">]</span></span><span class=\"return-annotation\">) -> <span class=\"n\">sglang</span><span class=\"o\">.</span><span class=\"n\">srt</span><span class=\"o\">.</span><span class=\"n\">server_args</span><span class=\"o\">.</span><span class=\"n\">ServerArgs</span>:</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.server_args.ZMQ_TCP_PORT_DELTA", "modulename": "sglang.srt.server_args", "qualname": "ZMQ_TCP_PORT_DELTA", "kind": "variable", "doc": "<p></p>\n", "default_value": "233"}, {"fullname": "sglang.srt.server_args.PortArgs", "modulename": "sglang.srt.server_args", "qualname": "PortArgs", "kind": "class", "doc": "<p></p>\n"}, {"fullname": "sglang.srt.server_args.PortArgs.__init__", "modulename": "sglang.srt.server_args", "qualname": "PortArgs.__init__", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">tokenizer_ipc_name</span><span class=\"p\">:</span> <span class=\"nb\">str</span>,</span><span class=\"param\">\t<span class=\"n\">scheduler_input_ipc_name</span><span class=\"p\">:</span> <span class=\"nb\">str</span>,</span><span class=\"param\">\t<span class=\"n\">detokenizer_ipc_name</span><span class=\"p\">:</span> <span class=\"nb\">str</span>,</span><span class=\"param\">\t<span class=\"n\">nccl_port</span><span class=\"p\">:</span> <span class=\"nb\">int</span>,</span><span class=\"param\">\t<span class=\"n\">rpc_ipc_name</span><span class=\"p\">:</span> <span class=\"nb\">str</span>,</span><span class=\"param\">\t<span class=\"n\">metrics_ipc_name</span><span class=\"p\">:</span> <span class=\"nb\">str</span></span>)</span>"}, {"fullname": "sglang.srt.server_args.PortArgs.tokenizer_ipc_name", "modulename": "sglang.srt.server_args", "qualname": "PortArgs.tokenizer_ipc_name", "kind": "variable", "doc": "<p></p>\n", "annotation": ": str"}, {"fullname": "sglang.srt.server_args.PortArgs.scheduler_input_ipc_name", "modulename": "sglang.srt.server_args", "qualname": "PortArgs.scheduler_input_ipc_name", "kind": "variable", "doc": "<p></p>\n", "annotation": ": str"}, {"fullname": "sglang.srt.server_args.PortArgs.detokenizer_ipc_name", "modulename": "sglang.srt.server_args", "qualname": "PortArgs.detokenizer_ipc_name", "kind": "variable", "doc": "<p></p>\n", "annotation": ": str"}, {"fullname": "sglang.srt.server_args.PortArgs.nccl_port", "modulename": "sglang.srt.server_args", "qualname": "PortArgs.nccl_port", "kind": "variable", "doc": "<p></p>\n", "annotation": ": int"}, {"fullname": "sglang.srt.server_args.PortArgs.rpc_ipc_name", "modulename": "sglang.srt.server_args", "qualname": "PortArgs.rpc_ipc_name", "kind": "variable", "doc": "<p></p>\n", "annotation": ": str"}, {"fullname": "sglang.srt.server_args.PortArgs.metrics_ipc_name", "modulename": "sglang.srt.server_args", "qualname": "PortArgs.metrics_ipc_name", "kind": "variable", "doc": "<p></p>\n", "annotation": ": str"}, {"fullname": "sglang.srt.server_args.PortArgs.init_new", "modulename": "sglang.srt.server_args", "qualname": "PortArgs.init_new", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">server_args</span>,</span><span class=\"param\">\t<span class=\"n\">dp_rank</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"nb\">int</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span></span><span class=\"return-annotation\">) -> <span class=\"n\">sglang</span><span class=\"o\">.</span><span class=\"n\">srt</span><span class=\"o\">.</span><span class=\"n\">server_args</span><span class=\"o\">.</span><span class=\"n\">PortArgs</span>:</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.server_args.LoRAPathAction", "modulename": "sglang.srt.server_args", "qualname": "LoRAPathAction", "kind": "class", "doc": "<p>Information about how to convert command line strings to Python objects.</p>\n\n<p>Action objects are used by an ArgumentParser to represent the information\nneeded to parse a single argument from one or more strings from the\ncommand line. The keyword arguments to the Action constructor are also\nall attributes of Action instances.</p>\n\n<p>Keyword Arguments:</p>\n\n<pre><code>- option_strings -- A list of command-line option strings which\n    should be associated with this action.\n\n- dest -- The name of the attribute to hold the created object(s)\n\n- nargs -- The number of command-line arguments that should be\n    consumed. By default, one argument will be consumed and a single\n    value will be produced.  Other values include:\n        - N (an integer) consumes N arguments (and produces a list)\n        - '?' consumes zero or one arguments\n        - '*' consumes zero or more arguments (and produces a list)\n        - '+' consumes one or more arguments (and produces a list)\n    Note that the difference between the default and nargs=1 is that\n    with the default, a single value will be produced, while with\n    nargs=1, a list containing a single value will be produced.\n\n- const -- The value to be produced if the option is specified and the\n    option uses an action that takes no values.\n\n- default -- The value to be produced if the option is not specified.\n\n- type -- A callable that accepts a single string argument, and\n    returns the converted value.  The standard Python types str, int,\n    float, and complex are useful examples of such callables.  If None,\n    str is used.\n\n- choices -- A container of values that should be allowed. If not None,\n    after a command-line argument has been converted to the appropriate\n    type, an exception will be raised if it is not a member of this\n    collection.\n\n- required -- True if the action must always be specified at the\n    command line. This is only meaningful for optional command-line\n    arguments.\n\n- help -- The help string describing the argument.\n\n- metavar -- The name to be used for the option's argument with the\n    help string. If None, the 'dest' value will be used as the name.\n</code></pre>\n", "bases": "argparse.Action"}, {"fullname": "sglang.srt.server_args.DeprecatedAction", "modulename": "sglang.srt.server_args", "qualname": "DeprecatedAction", "kind": "class", "doc": "<p>Information about how to convert command line strings to Python objects.</p>\n\n<p>Action objects are used by an ArgumentParser to represent the information\nneeded to parse a single argument from one or more strings from the\ncommand line. The keyword arguments to the Action constructor are also\nall attributes of Action instances.</p>\n\n<p>Keyword Arguments:</p>\n\n<pre><code>- option_strings -- A list of command-line option strings which\n    should be associated with this action.\n\n- dest -- The name of the attribute to hold the created object(s)\n\n- nargs -- The number of command-line arguments that should be\n    consumed. By default, one argument will be consumed and a single\n    value will be produced.  Other values include:\n        - N (an integer) consumes N arguments (and produces a list)\n        - '?' consumes zero or one arguments\n        - '*' consumes zero or more arguments (and produces a list)\n        - '+' consumes one or more arguments (and produces a list)\n    Note that the difference between the default and nargs=1 is that\n    with the default, a single value will be produced, while with\n    nargs=1, a list containing a single value will be produced.\n\n- const -- The value to be produced if the option is specified and the\n    option uses an action that takes no values.\n\n- default -- The value to be produced if the option is not specified.\n\n- type -- A callable that accepts a single string argument, and\n    returns the converted value.  The standard Python types str, int,\n    float, and complex are useful examples of such callables.  If None,\n    str is used.\n\n- choices -- A container of values that should be allowed. If not None,\n    after a command-line argument has been converted to the appropriate\n    type, an exception will be raised if it is not a member of this\n    collection.\n\n- required -- True if the action must always be specified at the\n    command line. This is only meaningful for optional command-line\n    arguments.\n\n- help -- The help string describing the argument.\n\n- metavar -- The name to be used for the option's argument with the\n    help string. If None, the 'dest' value will be used as the name.\n</code></pre>\n", "bases": "argparse.Action"}, {"fullname": "sglang.srt.server_args.DeprecatedAction.__init__", "modulename": "sglang.srt.server_args", "qualname": "DeprecatedAction.__init__", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">option_strings</span>, </span><span class=\"param\"><span class=\"n\">dest</span>, </span><span class=\"param\"><span class=\"n\">nargs</span><span class=\"o\">=</span><span class=\"mi\">0</span>, </span><span class=\"param\"><span class=\"o\">**</span><span class=\"n\">kwargs</span></span>)</span>"}, {"fullname": "sglang.srt.server_args.print_deprecated_warning", "modulename": "sglang.srt.server_args", "qualname": "print_deprecated_warning", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">message</span><span class=\"p\">:</span> <span class=\"nb\">str</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.server_args.auto_choose_speculative_params", "modulename": "sglang.srt.server_args", "qualname": "auto_choose_speculative_params", "kind": "function", "doc": "<p>Automatically choose the parameters for speculative decoding.</p>\n\n<p>You can tune them on your own models and prompts with scripts/playground/bench_speculative.py</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span><span class=\"p\">:</span> <span class=\"n\">sglang</span><span class=\"o\">.</span><span class=\"n\">srt</span><span class=\"o\">.</span><span class=\"n\">server_args</span><span class=\"o\">.</span><span class=\"n\">ServerArgs</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.torch_memory_saver_adapter", "modulename": "sglang.srt.torch_memory_saver_adapter", "kind": "module", "doc": "<p></p>\n"}, {"fullname": "sglang.srt.torch_memory_saver_adapter.logger", "modulename": "sglang.srt.torch_memory_saver_adapter", "qualname": "logger", "kind": "variable", "doc": "<p></p>\n", "default_value": "&lt;Logger sglang.srt.torch_memory_saver_adapter (WARNING)&gt;"}, {"fullname": "sglang.srt.torch_memory_saver_adapter.TorchMemorySaverAdapter", "modulename": "sglang.srt.torch_memory_saver_adapter", "qualname": "TorchMemorySaverAdapter", "kind": "class", "doc": "<p>Helper class that provides a standard way to create an ABC using\ninheritance.</p>\n", "bases": "abc.ABC"}, {"fullname": "sglang.srt.torch_memory_saver_adapter.TorchMemorySaverAdapter.create", "modulename": "sglang.srt.torch_memory_saver_adapter", "qualname": "TorchMemorySaverAdapter.create", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">enable</span><span class=\"p\">:</span> <span class=\"nb\">bool</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.torch_memory_saver_adapter.TorchMemorySaverAdapter.check_validity", "modulename": "sglang.srt.torch_memory_saver_adapter", "qualname": "TorchMemorySaverAdapter.check_validity", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">caller_name</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.torch_memory_saver_adapter.TorchMemorySaverAdapter.configure_subprocess", "modulename": "sglang.srt.torch_memory_saver_adapter", "qualname": "TorchMemorySaverAdapter.configure_subprocess", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.torch_memory_saver_adapter.TorchMemorySaverAdapter.region", "modulename": "sglang.srt.torch_memory_saver_adapter", "qualname": "TorchMemorySaverAdapter.region", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">tag</span><span class=\"p\">:</span> <span class=\"nb\">str</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.torch_memory_saver_adapter.TorchMemorySaverAdapter.pause", "modulename": "sglang.srt.torch_memory_saver_adapter", "qualname": "TorchMemorySaverAdapter.pause", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">tag</span><span class=\"p\">:</span> <span class=\"nb\">str</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.torch_memory_saver_adapter.TorchMemorySaverAdapter.resume", "modulename": "sglang.srt.torch_memory_saver_adapter", "qualname": "TorchMemorySaverAdapter.resume", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">tag</span><span class=\"p\">:</span> <span class=\"nb\">str</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.torch_memory_saver_adapter.TorchMemorySaverAdapter.enabled", "modulename": "sglang.srt.torch_memory_saver_adapter", "qualname": "TorchMemorySaverAdapter.enabled", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "sglang.srt.two_batch_overlap", "modulename": "sglang.srt.two_batch_overlap", "kind": "module", "doc": "<p></p>\n"}, {"fullname": "sglang.srt.two_batch_overlap.logger", "modulename": "sglang.srt.two_batch_overlap", "qualname": "logger", "kind": "variable", "doc": "<p></p>\n", "default_value": "&lt;Logger sglang.srt.two_batch_overlap (WARNING)&gt;"}, {"fullname": "sglang.srt.two_batch_overlap.get_token_num_per_seq", "modulename": "sglang.srt.two_batch_overlap", "qualname": "get_token_num_per_seq", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">forward_mode</span><span class=\"p\">:</span> <span class=\"n\">sglang</span><span class=\"o\">.</span><span class=\"n\">srt</span><span class=\"o\">.</span><span class=\"n\">model_executor</span><span class=\"o\">.</span><span class=\"n\">forward_batch_info</span><span class=\"o\">.</span><span class=\"n\">ForwardMode</span>,</span><span class=\"param\">\t<span class=\"n\">spec_info</span><span class=\"p\">:</span> <span class=\"n\">Union</span><span class=\"p\">[</span><span class=\"n\">sglang</span><span class=\"o\">.</span><span class=\"n\">srt</span><span class=\"o\">.</span><span class=\"n\">speculative</span><span class=\"o\">.</span><span class=\"n\">eagle_utils</span><span class=\"o\">.</span><span class=\"n\">EagleDraftInput</span><span class=\"p\">,</span> <span class=\"n\">sglang</span><span class=\"o\">.</span><span class=\"n\">srt</span><span class=\"o\">.</span><span class=\"n\">speculative</span><span class=\"o\">.</span><span class=\"n\">eagle_utils</span><span class=\"o\">.</span><span class=\"n\">EagleVerifyInput</span><span class=\"p\">,</span> <span class=\"n\">NoneType</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.two_batch_overlap.compute_split_seq_index", "modulename": "sglang.srt.two_batch_overlap", "qualname": "compute_split_seq_index", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">forward_mode</span><span class=\"p\">:</span> <span class=\"n\">sglang</span><span class=\"o\">.</span><span class=\"n\">srt</span><span class=\"o\">.</span><span class=\"n\">model_executor</span><span class=\"o\">.</span><span class=\"n\">forward_batch_info</span><span class=\"o\">.</span><span class=\"n\">ForwardMode</span>,</span><span class=\"param\">\t<span class=\"n\">num_tokens</span><span class=\"p\">:</span> <span class=\"nb\">int</span>,</span><span class=\"param\">\t<span class=\"n\">extend_lens</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"n\">Sequence</span><span class=\"p\">[</span><span class=\"nb\">int</span><span class=\"p\">]]</span>,</span><span class=\"param\">\t<span class=\"n\">token_num_per_seq</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"nb\">int</span><span class=\"p\">]</span></span><span class=\"return-annotation\">) -> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"nb\">int</span><span class=\"p\">]</span>:</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.two_batch_overlap.split_spec_info", "modulename": "sglang.srt.two_batch_overlap", "qualname": "split_spec_info", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">spec_info</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"n\">sglang</span><span class=\"o\">.</span><span class=\"n\">srt</span><span class=\"o\">.</span><span class=\"n\">speculative</span><span class=\"o\">.</span><span class=\"n\">eagle_utils</span><span class=\"o\">.</span><span class=\"n\">EagleVerifyInput</span><span class=\"p\">]</span>,</span><span class=\"param\">\t<span class=\"n\">start_seq_index</span><span class=\"p\">:</span> <span class=\"nb\">int</span>,</span><span class=\"param\">\t<span class=\"n\">end_seq_index</span><span class=\"p\">:</span> <span class=\"nb\">int</span>,</span><span class=\"param\">\t<span class=\"n\">start_token_index</span><span class=\"p\">:</span> <span class=\"nb\">int</span>,</span><span class=\"param\">\t<span class=\"n\">end_token_index</span><span class=\"p\">:</span> <span class=\"nb\">int</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.two_batch_overlap.compute_split_token_index", "modulename": "sglang.srt.two_batch_overlap", "qualname": "compute_split_token_index", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">split_seq_index</span><span class=\"p\">:</span> <span class=\"nb\">int</span>,</span><span class=\"param\">\t<span class=\"n\">forward_mode</span><span class=\"p\">:</span> <span class=\"n\">sglang</span><span class=\"o\">.</span><span class=\"n\">srt</span><span class=\"o\">.</span><span class=\"n\">model_executor</span><span class=\"o\">.</span><span class=\"n\">forward_batch_info</span><span class=\"o\">.</span><span class=\"n\">ForwardMode</span>,</span><span class=\"param\">\t<span class=\"n\">extend_seq_lens</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"n\">Sequence</span><span class=\"p\">[</span><span class=\"nb\">int</span><span class=\"p\">]]</span>,</span><span class=\"param\">\t<span class=\"n\">token_num_per_seq</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"nb\">int</span><span class=\"p\">]</span></span><span class=\"return-annotation\">) -> <span class=\"nb\">int</span>:</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.two_batch_overlap.compute_split_indices_for_cuda_graph_replay", "modulename": "sglang.srt.two_batch_overlap", "qualname": "compute_split_indices_for_cuda_graph_replay", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">forward_mode</span><span class=\"p\">:</span> <span class=\"n\">sglang</span><span class=\"o\">.</span><span class=\"n\">srt</span><span class=\"o\">.</span><span class=\"n\">model_executor</span><span class=\"o\">.</span><span class=\"n\">forward_batch_info</span><span class=\"o\">.</span><span class=\"n\">ForwardMode</span>,</span><span class=\"param\">\t<span class=\"n\">cuda_graph_num_tokens</span><span class=\"p\">:</span> <span class=\"nb\">int</span>,</span><span class=\"param\">\t<span class=\"n\">spec_info</span><span class=\"p\">:</span> <span class=\"n\">Union</span><span class=\"p\">[</span><span class=\"n\">sglang</span><span class=\"o\">.</span><span class=\"n\">srt</span><span class=\"o\">.</span><span class=\"n\">speculative</span><span class=\"o\">.</span><span class=\"n\">eagle_utils</span><span class=\"o\">.</span><span class=\"n\">EagleDraftInput</span><span class=\"p\">,</span> <span class=\"n\">sglang</span><span class=\"o\">.</span><span class=\"n\">srt</span><span class=\"o\">.</span><span class=\"n\">speculative</span><span class=\"o\">.</span><span class=\"n\">eagle_utils</span><span class=\"o\">.</span><span class=\"n\">EagleVerifyInput</span><span class=\"p\">,</span> <span class=\"n\">NoneType</span><span class=\"p\">]</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.two_batch_overlap.TboCudaGraphRunnerPlugin", "modulename": "sglang.srt.two_batch_overlap", "qualname": "TboCudaGraphRunnerPlugin", "kind": "class", "doc": "<p></p>\n"}, {"fullname": "sglang.srt.two_batch_overlap.TboCudaGraphRunnerPlugin.capture_one_batch_size", "modulename": "sglang.srt.two_batch_overlap", "qualname": "TboCudaGraphRunnerPlugin.capture_one_batch_size", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"bp\">self</span>,</span><span class=\"param\">\t<span class=\"n\">batch</span><span class=\"p\">:</span> <span class=\"n\">sglang</span><span class=\"o\">.</span><span class=\"n\">srt</span><span class=\"o\">.</span><span class=\"n\">model_executor</span><span class=\"o\">.</span><span class=\"n\">forward_batch_info</span><span class=\"o\">.</span><span class=\"n\">ForwardBatch</span>,</span><span class=\"param\">\t<span class=\"n\">num_tokens</span><span class=\"p\">:</span> <span class=\"nb\">int</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.two_batch_overlap.TboCudaGraphRunnerPlugin.replay_prepare", "modulename": "sglang.srt.two_batch_overlap", "qualname": "TboCudaGraphRunnerPlugin.replay_prepare", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"bp\">self</span>,</span><span class=\"param\">\t<span class=\"n\">forward_mode</span><span class=\"p\">:</span> <span class=\"n\">sglang</span><span class=\"o\">.</span><span class=\"n\">srt</span><span class=\"o\">.</span><span class=\"n\">model_executor</span><span class=\"o\">.</span><span class=\"n\">forward_batch_info</span><span class=\"o\">.</span><span class=\"n\">ForwardMode</span>,</span><span class=\"param\">\t<span class=\"n\">bs</span><span class=\"p\">:</span> <span class=\"nb\">int</span>,</span><span class=\"param\">\t<span class=\"n\">num_token_non_padded</span><span class=\"p\">:</span> <span class=\"nb\">int</span>,</span><span class=\"param\">\t<span class=\"n\">spec_info</span><span class=\"p\">:</span> <span class=\"n\">Union</span><span class=\"p\">[</span><span class=\"n\">sglang</span><span class=\"o\">.</span><span class=\"n\">srt</span><span class=\"o\">.</span><span class=\"n\">speculative</span><span class=\"o\">.</span><span class=\"n\">eagle_utils</span><span class=\"o\">.</span><span class=\"n\">EagleDraftInput</span><span class=\"p\">,</span> <span class=\"n\">sglang</span><span class=\"o\">.</span><span class=\"n\">srt</span><span class=\"o\">.</span><span class=\"n\">speculative</span><span class=\"o\">.</span><span class=\"n\">eagle_utils</span><span class=\"o\">.</span><span class=\"n\">EagleVerifyInput</span><span class=\"p\">,</span> <span class=\"n\">NoneType</span><span class=\"p\">]</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.two_batch_overlap.TboDPAttentionPreparer", "modulename": "sglang.srt.two_batch_overlap", "qualname": "TboDPAttentionPreparer", "kind": "class", "doc": "<p></p>\n"}, {"fullname": "sglang.srt.two_batch_overlap.TboDPAttentionPreparer.prepare_all_gather", "modulename": "sglang.srt.two_batch_overlap", "qualname": "TboDPAttentionPreparer.prepare_all_gather", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">local_batch</span><span class=\"p\">:</span> <span class=\"n\">sglang</span><span class=\"o\">.</span><span class=\"n\">srt</span><span class=\"o\">.</span><span class=\"n\">managers</span><span class=\"o\">.</span><span class=\"n\">schedule_batch</span><span class=\"o\">.</span><span class=\"n\">ScheduleBatch</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.two_batch_overlap.TboDPAttentionPreparer.compute_output", "modulename": "sglang.srt.two_batch_overlap", "qualname": "TboDPAttentionPreparer.compute_output", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">partial_global_info</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.two_batch_overlap.TboForwardBatchPreparer", "modulename": "sglang.srt.two_batch_overlap", "qualname": "TboForwardBatchPreparer", "kind": "class", "doc": "<p></p>\n"}, {"fullname": "sglang.srt.two_batch_overlap.TboForwardBatchPreparer.prepare", "modulename": "sglang.srt.two_batch_overlap", "qualname": "TboForwardBatchPreparer.prepare", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"bp\">cls</span>,</span><span class=\"param\">\t<span class=\"n\">batch</span><span class=\"p\">:</span> <span class=\"n\">sglang</span><span class=\"o\">.</span><span class=\"n\">srt</span><span class=\"o\">.</span><span class=\"n\">model_executor</span><span class=\"o\">.</span><span class=\"n\">forward_batch_info</span><span class=\"o\">.</span><span class=\"n\">ForwardBatch</span>,</span><span class=\"param\">\t<span class=\"n\">is_draft_worker</span><span class=\"p\">:</span> <span class=\"nb\">bool</span> <span class=\"o\">=</span> <span class=\"kc\">False</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.two_batch_overlap.TboForwardBatchPreparer.prepare_raw", "modulename": "sglang.srt.two_batch_overlap", "qualname": "TboForwardBatchPreparer.prepare_raw", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"bp\">cls</span>,</span><span class=\"param\">\t<span class=\"n\">batch</span><span class=\"p\">:</span> <span class=\"n\">sglang</span><span class=\"o\">.</span><span class=\"n\">srt</span><span class=\"o\">.</span><span class=\"n\">model_executor</span><span class=\"o\">.</span><span class=\"n\">forward_batch_info</span><span class=\"o\">.</span><span class=\"n\">ForwardBatch</span>,</span><span class=\"param\">\t<span class=\"n\">tbo_children_num_token_non_padded</span><span class=\"p\">:</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">Tensor</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.two_batch_overlap.TboForwardBatchPreparer.derive_fields_related_to_seq_len_for_two_chunk", "modulename": "sglang.srt.two_batch_overlap", "qualname": "TboForwardBatchPreparer.derive_fields_related_to_seq_len_for_two_chunk", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"bp\">cls</span>,</span><span class=\"param\">\t<span class=\"n\">batch</span><span class=\"p\">:</span> <span class=\"n\">sglang</span><span class=\"o\">.</span><span class=\"n\">srt</span><span class=\"o\">.</span><span class=\"n\">model_executor</span><span class=\"o\">.</span><span class=\"n\">forward_batch_info</span><span class=\"o\">.</span><span class=\"n\">ForwardBatch</span>,</span><span class=\"param\">\t<span class=\"o\">*</span>,</span><span class=\"param\">\t<span class=\"n\">child_a</span><span class=\"p\">:</span> <span class=\"n\">sglang</span><span class=\"o\">.</span><span class=\"n\">srt</span><span class=\"o\">.</span><span class=\"n\">model_executor</span><span class=\"o\">.</span><span class=\"n\">forward_batch_info</span><span class=\"o\">.</span><span class=\"n\">ForwardBatch</span>,</span><span class=\"param\">\t<span class=\"n\">child_b</span><span class=\"p\">:</span> <span class=\"n\">sglang</span><span class=\"o\">.</span><span class=\"n\">srt</span><span class=\"o\">.</span><span class=\"n\">model_executor</span><span class=\"o\">.</span><span class=\"n\">forward_batch_info</span><span class=\"o\">.</span><span class=\"n\">ForwardBatch</span>,</span><span class=\"param\">\t<span class=\"n\">tbo_split_seq_index</span><span class=\"p\">:</span> <span class=\"nb\">int</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.two_batch_overlap.TboForwardBatchPreparer.filter_batch", "modulename": "sglang.srt.two_batch_overlap", "qualname": "TboForwardBatchPreparer.filter_batch", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"bp\">cls</span>,</span><span class=\"param\">\t<span class=\"n\">batch</span><span class=\"p\">:</span> <span class=\"n\">sglang</span><span class=\"o\">.</span><span class=\"n\">srt</span><span class=\"o\">.</span><span class=\"n\">model_executor</span><span class=\"o\">.</span><span class=\"n\">forward_batch_info</span><span class=\"o\">.</span><span class=\"n\">ForwardBatch</span>,</span><span class=\"param\">\t<span class=\"o\">*</span>,</span><span class=\"param\">\t<span class=\"n\">start_token_index</span><span class=\"p\">:</span> <span class=\"nb\">int</span>,</span><span class=\"param\">\t<span class=\"n\">end_token_index</span><span class=\"p\">:</span> <span class=\"nb\">int</span>,</span><span class=\"param\">\t<span class=\"n\">start_seq_index</span><span class=\"p\">:</span> <span class=\"nb\">int</span>,</span><span class=\"param\">\t<span class=\"n\">end_seq_index</span><span class=\"p\">:</span> <span class=\"nb\">int</span>,</span><span class=\"param\">\t<span class=\"n\">output_attn_backend</span><span class=\"p\">:</span> <span class=\"n\">sglang</span><span class=\"o\">.</span><span class=\"n\">srt</span><span class=\"o\">.</span><span class=\"n\">layers</span><span class=\"o\">.</span><span class=\"n\">attention</span><span class=\"o\">.</span><span class=\"n\">base_attn_backend</span><span class=\"o\">.</span><span class=\"n\">AttentionBackend</span>,</span><span class=\"param\">\t<span class=\"n\">out_num_token_non_padded</span><span class=\"p\">:</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">Tensor</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.two_batch_overlap.TboForwardBatchPreparer.compute_tbo_children_num_token_non_padded", "modulename": "sglang.srt.two_batch_overlap", "qualname": "TboForwardBatchPreparer.compute_tbo_children_num_token_non_padded", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"bp\">cls</span>,</span><span class=\"param\">\t<span class=\"n\">batch</span><span class=\"p\">:</span> <span class=\"n\">sglang</span><span class=\"o\">.</span><span class=\"n\">srt</span><span class=\"o\">.</span><span class=\"n\">model_executor</span><span class=\"o\">.</span><span class=\"n\">forward_batch_info</span><span class=\"o\">.</span><span class=\"n\">ForwardBatch</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.two_batch_overlap.TboForwardBatchPreparer.compute_tbo_children_num_token_non_padded_raw", "modulename": "sglang.srt.two_batch_overlap", "qualname": "TboForwardBatchPreparer.compute_tbo_children_num_token_non_padded_raw", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">cls</span>, </span><span class=\"param\"><span class=\"n\">tbo_split_token_index</span><span class=\"p\">:</span> <span class=\"nb\">int</span>, </span><span class=\"param\"><span class=\"n\">num_token_non_padded</span><span class=\"p\">:</span> <span class=\"nb\">int</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.two_batch_overlap.model_forward_maybe_tbo", "modulename": "sglang.srt.two_batch_overlap", "qualname": "model_forward_maybe_tbo", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">layers</span>,</span><span class=\"param\">\t<span class=\"n\">enable_tbo</span><span class=\"p\">:</span> <span class=\"nb\">bool</span>,</span><span class=\"param\">\t<span class=\"n\">positions</span><span class=\"p\">:</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">Tensor</span>,</span><span class=\"param\">\t<span class=\"n\">forward_batch</span><span class=\"p\">:</span> <span class=\"n\">sglang</span><span class=\"o\">.</span><span class=\"n\">srt</span><span class=\"o\">.</span><span class=\"n\">model_executor</span><span class=\"o\">.</span><span class=\"n\">forward_batch_info</span><span class=\"o\">.</span><span class=\"n\">ForwardBatch</span>,</span><span class=\"param\">\t<span class=\"n\">hidden_states</span><span class=\"p\">:</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">Tensor</span>,</span><span class=\"param\">\t<span class=\"n\">input_data_scatter_mode</span><span class=\"p\">:</span> <span class=\"n\">sglang</span><span class=\"o\">.</span><span class=\"n\">srt</span><span class=\"o\">.</span><span class=\"n\">layers</span><span class=\"o\">.</span><span class=\"n\">communicator</span><span class=\"o\">.</span><span class=\"n\">ScatterMode</span>,</span><span class=\"param\">\t<span class=\"n\">residual</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">Tensor</span><span class=\"p\">]</span>,</span><span class=\"param\">\t<span class=\"n\">zero_allocator</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"n\">sglang</span><span class=\"o\">.</span><span class=\"n\">srt</span><span class=\"o\">.</span><span class=\"n\">utils</span><span class=\"o\">.</span><span class=\"n\">BumpAllocator</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.two_batch_overlap.MaybeTboDeepEPDispatcher", "modulename": "sglang.srt.two_batch_overlap", "qualname": "MaybeTboDeepEPDispatcher", "kind": "class", "doc": "<p></p>\n"}, {"fullname": "sglang.srt.two_batch_overlap.MaybeTboDeepEPDispatcher.__init__", "modulename": "sglang.srt.two_batch_overlap", "qualname": "MaybeTboDeepEPDispatcher.__init__", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"o\">**</span><span class=\"n\">kwargs</span></span>)</span>"}, {"fullname": "sglang.srt.two_batch_overlap.MaybeTboDeepEPDispatcher.dispatch", "modulename": "sglang.srt.two_batch_overlap", "qualname": "MaybeTboDeepEPDispatcher.dispatch", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"bp\">self</span>,</span><span class=\"param\">\t<span class=\"o\">**</span><span class=\"n\">kwargs</span></span><span class=\"return-annotation\">) -> <span class=\"n\">sglang</span><span class=\"o\">.</span><span class=\"n\">srt</span><span class=\"o\">.</span><span class=\"n\">layers</span><span class=\"o\">.</span><span class=\"n\">moe</span><span class=\"o\">.</span><span class=\"n\">token_dispatcher</span><span class=\"o\">.</span><span class=\"n\">base_dispatcher</span><span class=\"o\">.</span><span class=\"n\">DispatchOutput</span>:</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.two_batch_overlap.MaybeTboDeepEPDispatcher.dispatch_a", "modulename": "sglang.srt.two_batch_overlap", "qualname": "MaybeTboDeepEPDispatcher.dispatch_a", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"o\">**</span><span class=\"n\">kwargs</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.two_batch_overlap.MaybeTboDeepEPDispatcher.dispatch_b", "modulename": "sglang.srt.two_batch_overlap", "qualname": "MaybeTboDeepEPDispatcher.dispatch_b", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"o\">**</span><span class=\"n\">kwargs</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.two_batch_overlap.MaybeTboDeepEPDispatcher.combine", "modulename": "sglang.srt.two_batch_overlap", "qualname": "MaybeTboDeepEPDispatcher.combine", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"o\">**</span><span class=\"n\">kwargs</span></span><span class=\"return-annotation\">) -> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">Tensor</span>:</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.two_batch_overlap.MaybeTboDeepEPDispatcher.combine_a", "modulename": "sglang.srt.two_batch_overlap", "qualname": "MaybeTboDeepEPDispatcher.combine_a", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"o\">**</span><span class=\"n\">kwargs</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.two_batch_overlap.MaybeTboDeepEPDispatcher.combine_b", "modulename": "sglang.srt.two_batch_overlap", "qualname": "MaybeTboDeepEPDispatcher.combine_b", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"o\">**</span><span class=\"n\">kwargs</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.utils", "modulename": "sglang.srt.utils", "kind": "module", "doc": "<p>Common utilities.</p>\n"}, {"fullname": "sglang.srt.utils.logger", "modulename": "sglang.srt.utils", "qualname": "logger", "kind": "variable", "doc": "<p></p>\n", "default_value": "&lt;Logger sglang.srt.utils (WARNING)&gt;"}, {"fullname": "sglang.srt.utils.show_time_cost", "modulename": "sglang.srt.utils", "qualname": "show_time_cost", "kind": "variable", "doc": "<p></p>\n", "default_value": "False"}, {"fullname": "sglang.srt.utils.time_infos", "modulename": "sglang.srt.utils", "qualname": "time_infos", "kind": "variable", "doc": "<p></p>\n", "default_value": "{}"}, {"fullname": "sglang.srt.utils.HIP_FP8_E4M3_FNUZ_MAX", "modulename": "sglang.srt.utils", "qualname": "HIP_FP8_E4M3_FNUZ_MAX", "kind": "variable", "doc": "<p></p>\n", "default_value": "224.0"}, {"fullname": "sglang.srt.utils.is_hip", "modulename": "sglang.srt.utils", "qualname": "is_hip", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"return-annotation\">) -> <span class=\"nb\">bool</span>:</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.utils.FP8_E4M3_MIN", "modulename": "sglang.srt.utils", "qualname": "FP8_E4M3_MIN", "kind": "variable", "doc": "<p></p>\n", "default_value": "-448.0"}, {"fullname": "sglang.srt.utils.is_cuda", "modulename": "sglang.srt.utils", "qualname": "is_cuda", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.utils.is_cuda_alike", "modulename": "sglang.srt.utils", "qualname": "is_cuda_alike", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.utils.is_hpu", "modulename": "sglang.srt.utils", "qualname": "is_hpu", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"return-annotation\">) -> <span class=\"nb\">bool</span>:</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.utils.is_xpu", "modulename": "sglang.srt.utils", "qualname": "is_xpu", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"return-annotation\">) -> <span class=\"nb\">bool</span>:</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.utils.is_npu", "modulename": "sglang.srt.utils", "qualname": "is_npu", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"return-annotation\">) -> <span class=\"nb\">bool</span>:</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.utils.is_host_cpu_x86", "modulename": "sglang.srt.utils", "qualname": "is_host_cpu_x86", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"return-annotation\">) -> <span class=\"nb\">bool</span>:</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.utils.is_cpu", "modulename": "sglang.srt.utils", "qualname": "is_cpu", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"return-annotation\">) -> <span class=\"nb\">bool</span>:</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.utils.get_cuda_version", "modulename": "sglang.srt.utils", "qualname": "get_cuda_version", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.utils.is_ampere_with_cuda_12_3", "modulename": "sglang.srt.utils", "qualname": "is_ampere_with_cuda_12_3", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.utils.is_hopper_with_cuda_12_3", "modulename": "sglang.srt.utils", "qualname": "is_hopper_with_cuda_12_3", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.utils.is_blackwell", "modulename": "sglang.srt.utils", "qualname": "is_blackwell", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.utils.is_sm100_supported", "modulename": "sglang.srt.utils", "qualname": "is_sm100_supported", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">device</span><span class=\"o\">=</span><span class=\"kc\">None</span></span><span class=\"return-annotation\">) -> <span class=\"nb\">bool</span>:</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.utils.is_sm90_supported", "modulename": "sglang.srt.utils", "qualname": "is_sm90_supported", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">device</span><span class=\"o\">=</span><span class=\"kc\">None</span></span><span class=\"return-annotation\">) -> <span class=\"nb\">bool</span>:</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.utils.get_bool_env_var", "modulename": "sglang.srt.utils", "qualname": "get_bool_env_var", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">name</span><span class=\"p\">:</span> <span class=\"nb\">str</span>, </span><span class=\"param\"><span class=\"n\">default</span><span class=\"p\">:</span> <span class=\"nb\">str</span> <span class=\"o\">=</span> <span class=\"s1\">&#39;false&#39;</span></span><span class=\"return-annotation\">) -> <span class=\"nb\">bool</span>:</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.utils.get_int_env_var", "modulename": "sglang.srt.utils", "qualname": "get_int_env_var", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">name</span><span class=\"p\">:</span> <span class=\"nb\">str</span>, </span><span class=\"param\"><span class=\"n\">default</span><span class=\"p\">:</span> <span class=\"nb\">int</span> <span class=\"o\">=</span> <span class=\"mi\">0</span></span><span class=\"return-annotation\">) -> <span class=\"nb\">int</span>:</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.utils.support_triton", "modulename": "sglang.srt.utils", "qualname": "support_triton", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">backend</span><span class=\"p\">:</span> <span class=\"nb\">str</span></span><span class=\"return-annotation\">) -> <span class=\"nb\">bool</span>:</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.utils.cpu_has_amx_support", "modulename": "sglang.srt.utils", "qualname": "cpu_has_amx_support", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.utils.use_intel_amx_backend", "modulename": "sglang.srt.utils", "qualname": "use_intel_amx_backend", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">layer</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.utils.is_flashinfer_available", "modulename": "sglang.srt.utils", "qualname": "is_flashinfer_available", "kind": "function", "doc": "<p>Check whether flashinfer is available.\nAs of Oct. 6, 2024, it is only available on NVIDIA GPUs.</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.utils.random_uuid", "modulename": "sglang.srt.utils", "qualname": "random_uuid", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"return-annotation\">) -> <span class=\"nb\">str</span>:</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.utils.DynamicGradMode", "modulename": "sglang.srt.utils", "qualname": "DynamicGradMode", "kind": "class", "doc": "<p>A combination of torch.no_grad and torch.inference_mode,\nwith their behavior controlled by an environment variable. Just refer to them.</p>\n", "bases": "torch.utils._contextlib._DecoratorContextManager"}, {"fullname": "sglang.srt.utils.DynamicGradMode.__init__", "modulename": "sglang.srt.utils", "qualname": "DynamicGradMode.__init__", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">mode</span><span class=\"o\">=</span><span class=\"kc\">True</span></span>)</span>"}, {"fullname": "sglang.srt.utils.DynamicGradMode.set_inference_mode", "modulename": "sglang.srt.utils", "qualname": "DynamicGradMode.set_inference_mode", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">mode</span><span class=\"p\">:</span> <span class=\"nb\">bool</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.utils.DynamicGradMode.clone", "modulename": "sglang.srt.utils", "qualname": "DynamicGradMode.clone", "kind": "function", "doc": "<p>Create a copy of this class</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span></span><span class=\"return-annotation\">) -> <span class=\"n\">sglang</span><span class=\"o\">.</span><span class=\"n\">srt</span><span class=\"o\">.</span><span class=\"n\">utils</span><span class=\"o\">.</span><span class=\"n\">DynamicGradMode</span>:</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.utils.enable_show_time_cost", "modulename": "sglang.srt.utils", "qualname": "enable_show_time_cost", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.utils.TimeInfo", "modulename": "sglang.srt.utils", "qualname": "TimeInfo", "kind": "class", "doc": "<p></p>\n"}, {"fullname": "sglang.srt.utils.TimeInfo.__init__", "modulename": "sglang.srt.utils", "qualname": "TimeInfo.__init__", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">name</span>, </span><span class=\"param\"><span class=\"n\">interval</span><span class=\"o\">=</span><span class=\"mf\">0.1</span>, </span><span class=\"param\"><span class=\"n\">color</span><span class=\"o\">=</span><span class=\"mi\">0</span>, </span><span class=\"param\"><span class=\"n\">indent</span><span class=\"o\">=</span><span class=\"mi\">0</span></span>)</span>"}, {"fullname": "sglang.srt.utils.TimeInfo.name", "modulename": "sglang.srt.utils", "qualname": "TimeInfo.name", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "sglang.srt.utils.TimeInfo.interval", "modulename": "sglang.srt.utils", "qualname": "TimeInfo.interval", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "sglang.srt.utils.TimeInfo.color", "modulename": "sglang.srt.utils", "qualname": "TimeInfo.color", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "sglang.srt.utils.TimeInfo.indent", "modulename": "sglang.srt.utils", "qualname": "TimeInfo.indent", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "sglang.srt.utils.TimeInfo.acc_time", "modulename": "sglang.srt.utils", "qualname": "TimeInfo.acc_time", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "sglang.srt.utils.TimeInfo.last_acc_time", "modulename": "sglang.srt.utils", "qualname": "TimeInfo.last_acc_time", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "sglang.srt.utils.TimeInfo.check", "modulename": "sglang.srt.utils", "qualname": "TimeInfo.check", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.utils.TimeInfo.pretty_print", "modulename": "sglang.srt.utils", "qualname": "TimeInfo.pretty_print", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.utils.mark_start", "modulename": "sglang.srt.utils", "qualname": "mark_start", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">name</span>, </span><span class=\"param\"><span class=\"n\">interval</span><span class=\"o\">=</span><span class=\"mf\">0.1</span>, </span><span class=\"param\"><span class=\"n\">color</span><span class=\"o\">=</span><span class=\"mi\">0</span>, </span><span class=\"param\"><span class=\"n\">indent</span><span class=\"o\">=</span><span class=\"mi\">0</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.utils.mark_end", "modulename": "sglang.srt.utils", "qualname": "mark_end", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">name</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.utils.calculate_time", "modulename": "sglang.srt.utils", "qualname": "calculate_time", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">show</span><span class=\"o\">=</span><span class=\"kc\">False</span>, </span><span class=\"param\"><span class=\"n\">min_cost_ms</span><span class=\"o\">=</span><span class=\"mf\">0.0</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.utils.get_available_gpu_memory", "modulename": "sglang.srt.utils", "qualname": "get_available_gpu_memory", "kind": "function", "doc": "<p>Get available memory for cuda:gpu_id device.\nWhen distributed is True, the available memory is the minimum available memory of all GPUs.</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">device</span>, </span><span class=\"param\"><span class=\"n\">gpu_id</span>, </span><span class=\"param\"><span class=\"n\">distributed</span><span class=\"o\">=</span><span class=\"kc\">False</span>, </span><span class=\"param\"><span class=\"n\">empty_cache</span><span class=\"o\">=</span><span class=\"kc\">True</span>, </span><span class=\"param\"><span class=\"n\">cpu_group</span><span class=\"o\">=</span><span class=\"kc\">None</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.utils.is_pin_memory_available", "modulename": "sglang.srt.utils", "qualname": "is_pin_memory_available", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"return-annotation\">) -> <span class=\"nb\">bool</span>:</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.utils.LayerFn", "modulename": "sglang.srt.utils", "qualname": "LayerFn", "kind": "class", "doc": "<p>Base class for protocol classes.</p>\n\n<p>Protocol classes are defined as::</p>\n\n<pre><code>class Proto(Protocol):\n    def meth(self) -&gt; int:\n        ...\n</code></pre>\n\n<p>Such classes are primarily used with static type checkers that recognize\nstructural subtyping (static duck-typing).</p>\n\n<p>For example::</p>\n\n<pre><code>class C:\n    def meth(self) -&gt; int:\n        return 0\n\ndef func(x: Proto) -&gt; int:\n    return x.meth()\n\nfunc(C())  # Passes static type check\n</code></pre>\n\n<p>See PEP 544 for details. Protocol classes decorated with\n@typing.runtime_checkable act as simple-minded runtime protocols that check\nonly the presence of given attributes, ignoring their type signatures.\nProtocol classes can be generic, they are defined as::</p>\n\n<pre><code>class GenProto[T](Protocol):\n    def meth(self) -&gt; T:\n        ...\n</code></pre>\n", "bases": "typing.Protocol"}, {"fullname": "sglang.srt.utils.LayerFn.__init__", "modulename": "sglang.srt.utils", "qualname": "LayerFn.__init__", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"o\">*</span><span class=\"n\">args</span>, </span><span class=\"param\"><span class=\"o\">**</span><span class=\"n\">kwargs</span></span>)</span>"}, {"fullname": "sglang.srt.utils.make_layers", "modulename": "sglang.srt.utils", "qualname": "make_layers", "kind": "function", "doc": "<p>Make a list of layers with the given layer function</p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">num_hidden_layers</span><span class=\"p\">:</span> <span class=\"nb\">int</span>,</span><span class=\"param\">\t<span class=\"n\">layer_fn</span><span class=\"p\">:</span> <span class=\"n\">sglang</span><span class=\"o\">.</span><span class=\"n\">srt</span><span class=\"o\">.</span><span class=\"n\">utils</span><span class=\"o\">.</span><span class=\"n\">LayerFn</span>,</span><span class=\"param\">\t<span class=\"n\">pp_rank</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"nb\">int</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">pp_size</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"nb\">int</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">prefix</span><span class=\"p\">:</span> <span class=\"nb\">str</span> <span class=\"o\">=</span> <span class=\"s1\">&#39;&#39;</span>,</span><span class=\"param\">\t<span class=\"n\">return_tuple</span><span class=\"p\">:</span> <span class=\"nb\">bool</span> <span class=\"o\">=</span> <span class=\"kc\">False</span>,</span><span class=\"param\">\t<span class=\"n\">offloader_kwargs</span><span class=\"p\">:</span> <span class=\"n\">Dict</span><span class=\"p\">[</span><span class=\"nb\">str</span><span class=\"p\">,</span> <span class=\"n\">Any</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"p\">{}</span></span><span class=\"return-annotation\">) -> <span class=\"n\">Tuple</span><span class=\"p\">[</span><span class=\"nb\">int</span><span class=\"p\">,</span> <span class=\"nb\">int</span><span class=\"p\">,</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">nn</span><span class=\"o\">.</span><span class=\"n\">modules</span><span class=\"o\">.</span><span class=\"n\">container</span><span class=\"o\">.</span><span class=\"n\">ModuleList</span><span class=\"p\">]</span>:</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.utils.set_random_seed", "modulename": "sglang.srt.utils", "qualname": "set_random_seed", "kind": "function", "doc": "<p>Set the random seed for all libraries.</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">seed</span><span class=\"p\">:</span> <span class=\"nb\">int</span></span><span class=\"return-annotation\">) -> <span class=\"kc\">None</span>:</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.utils.find_process_using_port", "modulename": "sglang.srt.utils", "qualname": "find_process_using_port", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">port</span><span class=\"p\">:</span> <span class=\"nb\">int</span></span><span class=\"return-annotation\">) -> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"n\">psutil</span><span class=\"o\">.</span><span class=\"n\">Process</span><span class=\"p\">]</span>:</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.utils.wait_port_available", "modulename": "sglang.srt.utils", "qualname": "wait_port_available", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">port</span><span class=\"p\">:</span> <span class=\"nb\">int</span>,</span><span class=\"param\">\t<span class=\"n\">port_name</span><span class=\"p\">:</span> <span class=\"nb\">str</span>,</span><span class=\"param\">\t<span class=\"n\">timeout_s</span><span class=\"p\">:</span> <span class=\"nb\">int</span> <span class=\"o\">=</span> <span class=\"mi\">30</span>,</span><span class=\"param\">\t<span class=\"n\">raise_exception</span><span class=\"p\">:</span> <span class=\"nb\">bool</span> <span class=\"o\">=</span> <span class=\"kc\">True</span></span><span class=\"return-annotation\">) -> <span class=\"nb\">bool</span>:</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.utils.is_port_available", "modulename": "sglang.srt.utils", "qualname": "is_port_available", "kind": "function", "doc": "<p>Return whether a port is available.</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">port</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.utils.get_free_port", "modulename": "sglang.srt.utils", "qualname": "get_free_port", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.utils.decode_video_base64", "modulename": "sglang.srt.utils", "qualname": "decode_video_base64", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">video_base64</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.utils.load_audio", "modulename": "sglang.srt.utils", "qualname": "load_audio", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">audio_file</span><span class=\"p\">:</span> <span class=\"nb\">str</span>,</span><span class=\"param\">\t<span class=\"n\">sr</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"nb\">int</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">mono</span><span class=\"p\">:</span> <span class=\"nb\">bool</span> <span class=\"o\">=</span> <span class=\"kc\">True</span></span><span class=\"return-annotation\">) -> <span class=\"n\">numpy</span><span class=\"o\">.</span><span class=\"n\">ndarray</span>:</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.utils.ImageData", "modulename": "sglang.srt.utils", "qualname": "ImageData", "kind": "class", "doc": "<p></p>\n"}, {"fullname": "sglang.srt.utils.ImageData.__init__", "modulename": "sglang.srt.utils", "qualname": "ImageData.__init__", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">url</span><span class=\"p\">:</span> <span class=\"nb\">str</span>, </span><span class=\"param\"><span class=\"n\">detail</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"n\">Literal</span><span class=\"p\">[</span><span class=\"s1\">&#39;auto&#39;</span><span class=\"p\">,</span> <span class=\"s1\">&#39;low&#39;</span><span class=\"p\">,</span> <span class=\"s1\">&#39;high&#39;</span><span class=\"p\">]]</span> <span class=\"o\">=</span> <span class=\"s1\">&#39;auto&#39;</span></span>)</span>"}, {"fullname": "sglang.srt.utils.ImageData.url", "modulename": "sglang.srt.utils", "qualname": "ImageData.url", "kind": "variable", "doc": "<p></p>\n", "annotation": ": str"}, {"fullname": "sglang.srt.utils.ImageData.detail", "modulename": "sglang.srt.utils", "qualname": "ImageData.detail", "kind": "variable", "doc": "<p></p>\n", "annotation": ": Optional[Literal[&#x27;auto&#x27;, &#x27;low&#x27;, &#x27;high&#x27;]]", "default_value": "&#x27;auto&#x27;"}, {"fullname": "sglang.srt.utils.load_image", "modulename": "sglang.srt.utils", "qualname": "load_image", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">image_file</span><span class=\"p\">:</span> <span class=\"n\">Union</span><span class=\"p\">[</span><span class=\"n\">PIL</span><span class=\"o\">.</span><span class=\"n\">Image</span><span class=\"o\">.</span><span class=\"n\">Image</span><span class=\"p\">,</span> <span class=\"nb\">str</span><span class=\"p\">,</span> <span class=\"n\">sglang</span><span class=\"o\">.</span><span class=\"n\">srt</span><span class=\"o\">.</span><span class=\"n\">utils</span><span class=\"o\">.</span><span class=\"n\">ImageData</span><span class=\"p\">,</span> <span class=\"nb\">bytes</span><span class=\"p\">]</span></span><span class=\"return-annotation\">) -> <span class=\"nb\">tuple</span><span class=\"p\">[</span><span class=\"n\">PIL</span><span class=\"o\">.</span><span class=\"n\">Image</span><span class=\"o\">.</span><span class=\"n\">Image</span><span class=\"p\">,</span> <span class=\"nb\">tuple</span><span class=\"p\">[</span><span class=\"nb\">int</span><span class=\"p\">,</span> <span class=\"nb\">int</span><span class=\"p\">]]</span>:</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.utils.load_video", "modulename": "sglang.srt.utils", "qualname": "load_video", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">video_file</span><span class=\"p\">:</span> <span class=\"n\">Union</span><span class=\"p\">[</span><span class=\"nb\">str</span><span class=\"p\">,</span> <span class=\"nb\">bytes</span><span class=\"p\">]</span>, </span><span class=\"param\"><span class=\"n\">use_gpu</span><span class=\"p\">:</span> <span class=\"nb\">bool</span> <span class=\"o\">=</span> <span class=\"kc\">True</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.utils.suppress_other_loggers", "modulename": "sglang.srt.utils", "qualname": "suppress_other_loggers", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.utils.assert_pkg_version", "modulename": "sglang.srt.utils", "qualname": "assert_pkg_version", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">pkg</span><span class=\"p\">:</span> <span class=\"nb\">str</span>, </span><span class=\"param\"><span class=\"n\">min_version</span><span class=\"p\">:</span> <span class=\"nb\">str</span>, </span><span class=\"param\"><span class=\"n\">message</span><span class=\"p\">:</span> <span class=\"nb\">str</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.utils.kill_process_tree", "modulename": "sglang.srt.utils", "qualname": "kill_process_tree", "kind": "function", "doc": "<p>Kill the process and all its child processes.</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">parent_pid</span>, </span><span class=\"param\"><span class=\"n\">include_parent</span><span class=\"p\">:</span> <span class=\"nb\">bool</span> <span class=\"o\">=</span> <span class=\"kc\">True</span>, </span><span class=\"param\"><span class=\"n\">skip_pid</span><span class=\"p\">:</span> <span class=\"nb\">int</span> <span class=\"o\">=</span> <span class=\"kc\">None</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.utils.monkey_patch_p2p_access_check", "modulename": "sglang.srt.utils", "qualname": "monkey_patch_p2p_access_check", "kind": "function", "doc": "<p>Monkey patch the slow p2p access check.\nNOTE: We assume the p2p access is always allowed, which can be wrong for some setups.</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.utils.monkey_patch_vllm_gguf_config", "modulename": "sglang.srt.utils", "qualname": "monkey_patch_vllm_gguf_config", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.utils.set_ulimit", "modulename": "sglang.srt.utils", "qualname": "set_ulimit", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">target_soft_limit</span><span class=\"o\">=</span><span class=\"mi\">65535</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.utils.add_api_key_middleware", "modulename": "sglang.srt.utils", "qualname": "add_api_key_middleware", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">app</span>, </span><span class=\"param\"><span class=\"n\">api_key</span><span class=\"p\">:</span> <span class=\"nb\">str</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.utils.prepare_model_and_tokenizer", "modulename": "sglang.srt.utils", "qualname": "prepare_model_and_tokenizer", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">model_path</span><span class=\"p\">:</span> <span class=\"nb\">str</span>, </span><span class=\"param\"><span class=\"n\">tokenizer_path</span><span class=\"p\">:</span> <span class=\"nb\">str</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.utils.configure_logger", "modulename": "sglang.srt.utils", "qualname": "configure_logger", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">server_args</span>, </span><span class=\"param\"><span class=\"n\">prefix</span><span class=\"p\">:</span> <span class=\"nb\">str</span> <span class=\"o\">=</span> <span class=\"s1\">&#39;&#39;</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.utils.replace_submodule", "modulename": "sglang.srt.utils", "qualname": "replace_submodule", "kind": "function", "doc": "<p>Replace a submodule in a model with a new module.</p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">model</span><span class=\"p\">:</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">nn</span><span class=\"o\">.</span><span class=\"n\">modules</span><span class=\"o\">.</span><span class=\"n\">module</span><span class=\"o\">.</span><span class=\"n\">Module</span>,</span><span class=\"param\">\t<span class=\"n\">module_name</span><span class=\"p\">:</span> <span class=\"nb\">str</span>,</span><span class=\"param\">\t<span class=\"n\">new_module</span><span class=\"p\">:</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">nn</span><span class=\"o\">.</span><span class=\"n\">modules</span><span class=\"o\">.</span><span class=\"n\">module</span><span class=\"o\">.</span><span class=\"n\">Module</span></span><span class=\"return-annotation\">) -> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">nn</span><span class=\"o\">.</span><span class=\"n\">modules</span><span class=\"o\">.</span><span class=\"n\">module</span><span class=\"o\">.</span><span class=\"n\">Module</span>:</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.utils.set_weight_attrs", "modulename": "sglang.srt.utils", "qualname": "set_weight_attrs", "kind": "function", "doc": "<p>Set attributes on a weight tensor.</p>\n\n<p>This method is used to set attributes on a weight tensor. This method\nwill not overwrite existing attributes.</p>\n\n<p>Args:\n    weight: The weight tensor.\n    weight_attrs: A dictionary of attributes to set on the weight tensor.</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">weight</span><span class=\"p\">:</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">Tensor</span>, </span><span class=\"param\"><span class=\"n\">weight_attrs</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"n\">Dict</span><span class=\"p\">[</span><span class=\"nb\">str</span><span class=\"p\">,</span> <span class=\"n\">Any</span><span class=\"p\">]]</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.utils.broadcast_pyobj", "modulename": "sglang.srt.utils", "qualname": "broadcast_pyobj", "kind": "function", "doc": "<p>Broadcast inputs from src rank to all other ranks with torch.dist backend.\nThe <code>rank</code> here refer to the source rank on global process group (regardless\nof dist_group argument).</p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">data</span><span class=\"p\">:</span> <span class=\"n\">List</span><span class=\"p\">[</span><span class=\"n\">Any</span><span class=\"p\">]</span>,</span><span class=\"param\">\t<span class=\"n\">rank</span><span class=\"p\">:</span> <span class=\"nb\">int</span>,</span><span class=\"param\">\t<span class=\"n\">dist_group</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">distributed</span><span class=\"o\">.</span><span class=\"n\">distributed_c10d</span><span class=\"o\">.</span><span class=\"n\">ProcessGroup</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">src</span><span class=\"p\">:</span> <span class=\"nb\">int</span> <span class=\"o\">=</span> <span class=\"mi\">0</span>,</span><span class=\"param\">\t<span class=\"n\">force_cpu_device</span><span class=\"p\">:</span> <span class=\"nb\">bool</span> <span class=\"o\">=</span> <span class=\"kc\">True</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.utils.point_to_point_pyobj", "modulename": "sglang.srt.utils", "qualname": "point_to_point_pyobj", "kind": "function", "doc": "<p>Send data from src to dst in group using DeviceToDevice communication.</p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">data</span><span class=\"p\">:</span> <span class=\"n\">List</span><span class=\"p\">[</span><span class=\"n\">Any</span><span class=\"p\">]</span>,</span><span class=\"param\">\t<span class=\"n\">rank</span><span class=\"p\">:</span> <span class=\"nb\">int</span>,</span><span class=\"param\">\t<span class=\"n\">group</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">distributed</span><span class=\"o\">.</span><span class=\"n\">distributed_c10d</span><span class=\"o\">.</span><span class=\"n\">ProcessGroup</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">src</span><span class=\"p\">:</span> <span class=\"nb\">int</span> <span class=\"o\">=</span> <span class=\"mi\">0</span>,</span><span class=\"param\">\t<span class=\"n\">dst</span><span class=\"p\">:</span> <span class=\"nb\">int</span> <span class=\"o\">=</span> <span class=\"mi\">1</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.utils.step_counter", "modulename": "sglang.srt.utils", "qualname": "step_counter", "kind": "variable", "doc": "<p></p>\n", "default_value": "0"}, {"fullname": "sglang.srt.utils.pytorch_profile", "modulename": "sglang.srt.utils", "qualname": "pytorch_profile", "kind": "function", "doc": "<p>Args:\n    name (string): the name of recorded function.\n    func: the function to be profiled.\n    args: the arguments of the profiled function.\n    data_size (int): some measurement of the computation complexity.\n        Usually, it could be the batch size.</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">name</span>, </span><span class=\"param\"><span class=\"n\">func</span>, </span><span class=\"param\"><span class=\"o\">*</span><span class=\"n\">args</span>, </span><span class=\"param\"><span class=\"n\">data_size</span><span class=\"o\">=-</span><span class=\"mi\">1</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.utils.get_zmq_socket", "modulename": "sglang.srt.utils", "qualname": "get_zmq_socket", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">context</span><span class=\"p\">:</span> <span class=\"n\">zmq</span><span class=\"o\">.</span><span class=\"n\">sugar</span><span class=\"o\">.</span><span class=\"n\">context</span><span class=\"o\">.</span><span class=\"n\">Context</span>,</span><span class=\"param\">\t<span class=\"n\">socket_type</span><span class=\"p\">:</span> <span class=\"n\">zmq</span><span class=\"o\">.</span><span class=\"n\">constants</span><span class=\"o\">.</span><span class=\"n\">SocketType</span>,</span><span class=\"param\">\t<span class=\"n\">endpoint</span><span class=\"p\">:</span> <span class=\"nb\">str</span>,</span><span class=\"param\">\t<span class=\"n\">bind</span><span class=\"p\">:</span> <span class=\"nb\">bool</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.utils.dump_to_file", "modulename": "sglang.srt.utils", "qualname": "dump_to_file", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">dirpath</span>, </span><span class=\"param\"><span class=\"n\">name</span>, </span><span class=\"param\"><span class=\"n\">value</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.utils.is_triton_3", "modulename": "sglang.srt.utils", "qualname": "is_triton_3", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.utils.maybe_torch_compile", "modulename": "sglang.srt.utils", "qualname": "maybe_torch_compile", "kind": "function", "doc": "<p>torch.compile does not work for triton 2.2.0, which is needed in xlm1's jax.\nTherefore, we disable it here.</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"o\">*</span><span class=\"n\">args</span>, </span><span class=\"param\"><span class=\"o\">**</span><span class=\"n\">kwargs</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.utils.delete_directory", "modulename": "sglang.srt.utils", "qualname": "delete_directory", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">dirpath</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.utils.prometheus_multiproc_dir", "modulename": "sglang.srt.utils", "qualname": "prometheus_multiproc_dir", "kind": "variable", "doc": "<p></p>\n", "annotation": ": tempfile.TemporaryDirectory"}, {"fullname": "sglang.srt.utils.set_prometheus_multiproc_dir", "modulename": "sglang.srt.utils", "qualname": "set_prometheus_multiproc_dir", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.utils.add_prometheus_middleware", "modulename": "sglang.srt.utils", "qualname": "add_prometheus_middleware", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">app</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.utils.bind_port", "modulename": "sglang.srt.utils", "qualname": "bind_port", "kind": "function", "doc": "<p>Bind to a specific port, assuming it's available.</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">port</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.utils.get_amdgpu_memory_capacity", "modulename": "sglang.srt.utils", "qualname": "get_amdgpu_memory_capacity", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.utils.get_device_sm", "modulename": "sglang.srt.utils", "qualname": "get_device_sm", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.utils.get_nvgpu_memory_capacity", "modulename": "sglang.srt.utils", "qualname": "get_nvgpu_memory_capacity", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.utils.get_hpu_memory_capacity", "modulename": "sglang.srt.utils", "qualname": "get_hpu_memory_capacity", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.utils.get_npu_memory_capacity", "modulename": "sglang.srt.utils", "qualname": "get_npu_memory_capacity", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.utils.get_device_memory_capacity", "modulename": "sglang.srt.utils", "qualname": "get_device_memory_capacity", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">device</span><span class=\"p\">:</span> <span class=\"nb\">str</span> <span class=\"o\">=</span> <span class=\"kc\">None</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.utils.init_custom_process_group", "modulename": "sglang.srt.utils", "qualname": "init_custom_process_group", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">backend</span><span class=\"o\">=</span><span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">init_method</span><span class=\"o\">=</span><span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">timeout</span><span class=\"o\">=</span><span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">world_size</span><span class=\"o\">=-</span><span class=\"mi\">1</span>,</span><span class=\"param\">\t<span class=\"n\">rank</span><span class=\"o\">=-</span><span class=\"mi\">1</span>,</span><span class=\"param\">\t<span class=\"n\">store</span><span class=\"o\">=</span><span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">group_name</span><span class=\"o\">=</span><span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">pg_options</span><span class=\"o\">=</span><span class=\"kc\">None</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.utils.crash_on_warnings", "modulename": "sglang.srt.utils", "qualname": "crash_on_warnings", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.utils.print_warning_once", "modulename": "sglang.srt.utils", "qualname": "print_warning_once", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">msg</span><span class=\"p\">:</span> <span class=\"nb\">str</span></span><span class=\"return-annotation\">) -> <span class=\"kc\">None</span>:</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.utils.print_info_once", "modulename": "sglang.srt.utils", "qualname": "print_info_once", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">msg</span><span class=\"p\">:</span> <span class=\"nb\">str</span></span><span class=\"return-annotation\">) -> <span class=\"kc\">None</span>:</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.utils.get_device_name", "modulename": "sglang.srt.utils", "qualname": "get_device_name", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">device_id</span><span class=\"p\">:</span> <span class=\"nb\">int</span> <span class=\"o\">=</span> <span class=\"mi\">0</span></span><span class=\"return-annotation\">) -> <span class=\"nb\">str</span>:</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.utils.is_habana_available", "modulename": "sglang.srt.utils", "qualname": "is_habana_available", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"return-annotation\">) -> <span class=\"nb\">bool</span>:</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.utils.get_device", "modulename": "sglang.srt.utils", "qualname": "get_device", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">device_id</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"nb\">int</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span></span><span class=\"return-annotation\">) -> <span class=\"nb\">str</span>:</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.utils.get_device_count", "modulename": "sglang.srt.utils", "qualname": "get_device_count", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"return-annotation\">) -> <span class=\"nb\">int</span>:</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.utils.get_device_core_count", "modulename": "sglang.srt.utils", "qualname": "get_device_core_count", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">device_id</span><span class=\"p\">:</span> <span class=\"nb\">int</span> <span class=\"o\">=</span> <span class=\"mi\">0</span></span><span class=\"return-annotation\">) -> <span class=\"nb\">int</span>:</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.utils.get_device_capability", "modulename": "sglang.srt.utils", "qualname": "get_device_capability", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">device_id</span><span class=\"p\">:</span> <span class=\"nb\">int</span> <span class=\"o\">=</span> <span class=\"mi\">0</span></span><span class=\"return-annotation\">) -> <span class=\"n\">Tuple</span><span class=\"p\">[</span><span class=\"nb\">int</span><span class=\"p\">,</span> <span class=\"nb\">int</span><span class=\"p\">]</span>:</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.utils.get_npu_compiler_config", "modulename": "sglang.srt.utils", "qualname": "get_npu_compiler_config", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.utils.get_compiler_backend", "modulename": "sglang.srt.utils", "qualname": "get_compiler_backend", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"return-annotation\">) -> <span class=\"nb\">str</span>:</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.utils.sglang_lib", "modulename": "sglang.srt.utils", "qualname": "sglang_lib", "kind": "variable", "doc": "<p></p>\n", "default_value": "Library(kind=FRAGMENT, ns=sglang, dispatch_key=)&gt;"}, {"fullname": "sglang.srt.utils.supports_custom_op", "modulename": "sglang.srt.utils", "qualname": "supports_custom_op", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"return-annotation\">) -> <span class=\"nb\">bool</span>:</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.utils.direct_register_custom_op", "modulename": "sglang.srt.utils", "qualname": "direct_register_custom_op", "kind": "function", "doc": "<p><code>torch.library.custom_op</code> can have significant overhead because it\nneeds to consider complicated dispatching logic. This function\ndirectly registers a custom op and dispatches it to the CUDA backend.\nSee <a href=\"https://gist.github.com/youkaichao/ecbea9ec9fc79a45d2adce1784d7a9a5\">https://gist.github.com/youkaichao/ecbea9ec9fc79a45d2adce1784d7a9a5</a>\nfor more details.</p>\n\n<p>By default, the custom op is registered to the vLLM library. If you\nwant to register it to a different library, you can pass the library\nobject to the <code>target_lib</code> argument.</p>\n\n<p>IMPORTANT: the lifetime of the operator is tied to the lifetime of the\nlibrary object. If you want to bind the operator to a different library,\nmake sure the library object is alive when the operator is used.</p>\n\n<p>Note: This function will silently skip registration if the operator\nwith the same name is already registered to avoid RuntimeError in\nmulti-engine scenarios (e.g., VERL framework).</p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">op_name</span><span class=\"p\">:</span> <span class=\"nb\">str</span>,</span><span class=\"param\">\t<span class=\"n\">op_func</span><span class=\"p\">:</span> <span class=\"n\">Callable</span>,</span><span class=\"param\">\t<span class=\"n\">mutates_args</span><span class=\"p\">:</span> <span class=\"n\">List</span><span class=\"p\">[</span><span class=\"nb\">str</span><span class=\"p\">]</span>,</span><span class=\"param\">\t<span class=\"n\">fake_impl</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"n\">Callable</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">target_lib</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">library</span><span class=\"o\">.</span><span class=\"n\">Library</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.utils.set_gpu_proc_affinity", "modulename": "sglang.srt.utils", "qualname": "set_gpu_proc_affinity", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">tp_size</span><span class=\"p\">:</span> <span class=\"nb\">int</span>, </span><span class=\"param\"><span class=\"n\">nnodes</span><span class=\"p\">:</span> <span class=\"nb\">int</span>, </span><span class=\"param\"><span class=\"n\">gpu_id</span><span class=\"p\">:</span> <span class=\"nb\">int</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.utils.disable_request_logging", "modulename": "sglang.srt.utils", "qualname": "disable_request_logging", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"return-annotation\">) -> <span class=\"nb\">bool</span>:</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.utils.dataclass_to_string_truncated", "modulename": "sglang.srt.utils", "qualname": "dataclass_to_string_truncated", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">data</span>, </span><span class=\"param\"><span class=\"n\">max_length</span><span class=\"o\">=</span><span class=\"mi\">2048</span>, </span><span class=\"param\"><span class=\"n\">skip_names</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"n\">Set</span><span class=\"p\">[</span><span class=\"nb\">str</span><span class=\"p\">]]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.utils.permute_weight", "modulename": "sglang.srt.utils", "qualname": "permute_weight", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">x</span><span class=\"p\">:</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">Tensor</span></span><span class=\"return-annotation\">) -> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">Tensor</span>:</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.utils.MultiprocessingSerializer", "modulename": "sglang.srt.utils", "qualname": "MultiprocessingSerializer", "kind": "class", "doc": "<p></p>\n"}, {"fullname": "sglang.srt.utils.MultiprocessingSerializer.serialize", "modulename": "sglang.srt.utils", "qualname": "MultiprocessingSerializer.serialize", "kind": "function", "doc": "<p>Serialize a Python object using ForkingPickler.</p>\n\n<p>Args:\n    obj: The object to serialize.\n    output_str (bool): If True, return a base64-encoded string instead of raw bytes.</p>\n\n<p>Returns:\n    bytes or str: The serialized object.</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">obj</span>, </span><span class=\"param\"><span class=\"n\">output_str</span><span class=\"p\">:</span> <span class=\"nb\">bool</span> <span class=\"o\">=</span> <span class=\"kc\">False</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.utils.MultiprocessingSerializer.deserialize", "modulename": "sglang.srt.utils", "qualname": "MultiprocessingSerializer.deserialize", "kind": "function", "doc": "<p>Deserialize a previously serialized object.</p>\n\n<p>Args:\n    data (bytes or str): The serialized data, optionally base64-encoded.</p>\n\n<p>Returns:\n    The deserialized Python object.</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">data</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.utils.debug_timing", "modulename": "sglang.srt.utils", "qualname": "debug_timing", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">func</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.utils.nullable_str", "modulename": "sglang.srt.utils", "qualname": "nullable_str", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">val</span><span class=\"p\">:</span> <span class=\"nb\">str</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.utils.pyspy_dump_schedulers", "modulename": "sglang.srt.utils", "qualname": "pyspy_dump_schedulers", "kind": "function", "doc": "<p>py-spy dump on all scheduler in a local node.</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.utils.kill_itself_when_parent_died", "modulename": "sglang.srt.utils", "qualname": "kill_itself_when_parent_died", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.utils.set_uvicorn_logging_configs", "modulename": "sglang.srt.utils", "qualname": "set_uvicorn_logging_configs", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.utils.get_ip", "modulename": "sglang.srt.utils", "qualname": "get_ip", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"return-annotation\">) -> <span class=\"nb\">str</span>:</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.utils.get_open_port", "modulename": "sglang.srt.utils", "qualname": "get_open_port", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"return-annotation\">) -> <span class=\"nb\">int</span>:</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.utils.is_valid_ipv6_address", "modulename": "sglang.srt.utils", "qualname": "is_valid_ipv6_address", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">address</span><span class=\"p\">:</span> <span class=\"nb\">str</span></span><span class=\"return-annotation\">) -> <span class=\"nb\">bool</span>:</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.utils.maybe_wrap_ipv6_address", "modulename": "sglang.srt.utils", "qualname": "maybe_wrap_ipv6_address", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">address</span><span class=\"p\">:</span> <span class=\"nb\">str</span></span><span class=\"return-annotation\">) -> <span class=\"nb\">str</span>:</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.utils.format_tcp_address", "modulename": "sglang.srt.utils", "qualname": "format_tcp_address", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">ip</span><span class=\"p\">:</span> <span class=\"nb\">str</span>, </span><span class=\"param\"><span class=\"n\">port</span><span class=\"p\">:</span> <span class=\"nb\">int</span></span><span class=\"return-annotation\">) -> <span class=\"nb\">str</span>:</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.utils.configure_ipv6", "modulename": "sglang.srt.utils", "qualname": "configure_ipv6", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">dist_init_addr</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.utils.launch_dummy_health_check_server", "modulename": "sglang.srt.utils", "qualname": "launch_dummy_health_check_server", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">host</span>, </span><span class=\"param\"><span class=\"n\">port</span>, </span><span class=\"param\"><span class=\"n\">enable_metrics</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.utils.create_checksum", "modulename": "sglang.srt.utils", "qualname": "create_checksum", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">directory</span><span class=\"p\">:</span> <span class=\"nb\">str</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.utils.set_cuda_arch", "modulename": "sglang.srt.utils", "qualname": "set_cuda_arch", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.utils.next_power_of_2", "modulename": "sglang.srt.utils", "qualname": "next_power_of_2", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">n</span><span class=\"p\">:</span> <span class=\"nb\">int</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.utils.round_up", "modulename": "sglang.srt.utils", "qualname": "round_up", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">x</span><span class=\"p\">:</span> <span class=\"nb\">int</span>, </span><span class=\"param\"><span class=\"n\">y</span><span class=\"p\">:</span> <span class=\"nb\">int</span></span><span class=\"return-annotation\">) -> <span class=\"nb\">int</span>:</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.utils.EmptyContextManager", "modulename": "sglang.srt.utils", "qualname": "EmptyContextManager", "kind": "class", "doc": "<p></p>\n"}, {"fullname": "sglang.srt.utils.empty_context", "modulename": "sglang.srt.utils", "qualname": "empty_context", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"o\">*</span><span class=\"n\">args</span>, </span><span class=\"param\"><span class=\"o\">**</span><span class=\"n\">kwargs</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.utils.add_prefix", "modulename": "sglang.srt.utils", "qualname": "add_prefix", "kind": "function", "doc": "<p>Add a weight path prefix to a module name.</p>\n\n<p>Args:\n    name: base module name.\n    prefix: weight prefix str to added to the front of <code>name</code> concatenated with <code>.</code>.</p>\n\n<p>Returns:\n    The string <code>prefix.name</code> if prefix is non-empty, otherwise just <code>name</code>.</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">name</span><span class=\"p\">:</span> <span class=\"nb\">str</span>, </span><span class=\"param\"><span class=\"n\">prefix</span><span class=\"p\">:</span> <span class=\"nb\">str</span></span><span class=\"return-annotation\">) -> <span class=\"nb\">str</span>:</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.utils.is_remote_url", "modulename": "sglang.srt.utils", "qualname": "is_remote_url", "kind": "function", "doc": "<p>Check if the URL is a remote URL of the format:\n<connector_type>://<host>:<port>/<model_name></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">url</span><span class=\"p\">:</span> <span class=\"n\">Union</span><span class=\"p\">[</span><span class=\"nb\">str</span><span class=\"p\">,</span> <span class=\"n\">pathlib</span><span class=\"o\">.</span><span class=\"n\">Path</span><span class=\"p\">]</span></span><span class=\"return-annotation\">) -> <span class=\"nb\">bool</span>:</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.utils.parse_connector_type", "modulename": "sglang.srt.utils", "qualname": "parse_connector_type", "kind": "function", "doc": "<p>Parse the connector type from the URL of the format:\n<connector_type>://<path></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">url</span><span class=\"p\">:</span> <span class=\"nb\">str</span></span><span class=\"return-annotation\">) -> <span class=\"nb\">str</span>:</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.utils.retry", "modulename": "sglang.srt.utils", "qualname": "retry", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">fn</span>,</span><span class=\"param\">\t<span class=\"n\">max_retry</span><span class=\"p\">:</span> <span class=\"nb\">int</span>,</span><span class=\"param\">\t<span class=\"n\">initial_delay</span><span class=\"p\">:</span> <span class=\"nb\">float</span> <span class=\"o\">=</span> <span class=\"mf\">2.0</span>,</span><span class=\"param\">\t<span class=\"n\">max_delay</span><span class=\"p\">:</span> <span class=\"nb\">float</span> <span class=\"o\">=</span> <span class=\"mf\">60.0</span>,</span><span class=\"param\">\t<span class=\"n\">should_retry</span><span class=\"p\">:</span> <span class=\"n\">Callable</span><span class=\"p\">[[</span><span class=\"n\">Any</span><span class=\"p\">],</span> <span class=\"nb\">bool</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"o\">&lt;</span><span class=\"n\">function</span> <span class=\"o\">&lt;</span><span class=\"k\">lambda</span><span class=\"o\">&gt;&gt;</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.utils.flatten_nested_list", "modulename": "sglang.srt.utils", "qualname": "flatten_nested_list", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">nested_list</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.utils.is_non_idle_and_non_empty", "modulename": "sglang.srt.utils", "qualname": "is_non_idle_and_non_empty", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">forward_mode</span>, </span><span class=\"param\"><span class=\"n\">hidden_states</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.utils.fast_topk", "modulename": "sglang.srt.utils", "qualname": "fast_topk", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">values</span>, </span><span class=\"param\"><span class=\"n\">topk</span>, </span><span class=\"param\"><span class=\"n\">dim</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.utils.bind_or_assign", "modulename": "sglang.srt.utils", "qualname": "bind_or_assign", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">target</span>, </span><span class=\"param\"><span class=\"n\">source</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.utils.get_local_ip_auto", "modulename": "sglang.srt.utils", "qualname": "get_local_ip_auto", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"return-annotation\">) -> <span class=\"nb\">str</span>:</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.utils.get_local_ip_by_nic", "modulename": "sglang.srt.utils", "qualname": "get_local_ip_by_nic", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">interface</span><span class=\"p\">:</span> <span class=\"nb\">str</span></span><span class=\"return-annotation\">) -> <span class=\"nb\">str</span>:</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.utils.get_local_ip_by_remote", "modulename": "sglang.srt.utils", "qualname": "get_local_ip_by_remote", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"return-annotation\">) -> <span class=\"nb\">str</span>:</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.utils.is_page_size_one", "modulename": "sglang.srt.utils", "qualname": "is_page_size_one", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">server_args</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.utils.is_no_spec_infer_or_topk_one", "modulename": "sglang.srt.utils", "qualname": "is_no_spec_infer_or_topk_one", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">server_args</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.utils.is_fa3_default_architecture", "modulename": "sglang.srt.utils", "qualname": "is_fa3_default_architecture", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">hf_config</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.utils.BumpAllocator", "modulename": "sglang.srt.utils", "qualname": "BumpAllocator", "kind": "class", "doc": "<p></p>\n"}, {"fullname": "sglang.srt.utils.BumpAllocator.__init__", "modulename": "sglang.srt.utils", "qualname": "BumpAllocator.__init__", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">buffer_size</span><span class=\"p\">:</span> <span class=\"nb\">int</span>, </span><span class=\"param\"><span class=\"n\">dtype</span>, </span><span class=\"param\"><span class=\"n\">device</span></span>)</span>"}, {"fullname": "sglang.srt.utils.BumpAllocator.allocate", "modulename": "sglang.srt.utils", "qualname": "BumpAllocator.allocate", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">size</span><span class=\"p\">:</span> <span class=\"nb\">int</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.utils.log_info_on_rank0", "modulename": "sglang.srt.utils", "qualname": "log_info_on_rank0", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">logger</span>, </span><span class=\"param\"><span class=\"n\">msg</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.utils.load_json_config", "modulename": "sglang.srt.utils", "qualname": "load_json_config", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">data</span><span class=\"p\">:</span> <span class=\"nb\">str</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.utils.dispose_tensor", "modulename": "sglang.srt.utils", "qualname": "dispose_tensor", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">x</span><span class=\"p\">:</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">Tensor</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.utils.Withable", "modulename": "sglang.srt.utils", "qualname": "Withable", "kind": "class", "doc": "<p>Abstract base class for generic types.</p>\n\n<p>On Python 3.12 and newer, generic classes implicitly inherit from\nGeneric when they declare a parameter list after the class's name::</p>\n\n<pre><code>class Mapping[KT, VT]:\n    def __getitem__(self, key: KT) -&gt; VT:\n        ...\n    # Etc.\n</code></pre>\n\n<p>On older versions of Python, however, generic classes have to\nexplicitly inherit from Generic.</p>\n\n<p>After a class has been declared to be generic, it can then be used as\nfollows::</p>\n\n<pre><code>def lookup_name[KT, VT](mapping: Mapping[KT, VT], key: KT, default: VT) -&gt; VT:\n    try:\n        return mapping[key]\n    except KeyError:\n        return default\n</code></pre>\n", "bases": "typing.Generic[~T]"}, {"fullname": "sglang.srt.utils.Withable.value", "modulename": "sglang.srt.utils", "qualname": "Withable.value", "kind": "variable", "doc": "<p></p>\n", "annotation": ": ~T"}, {"fullname": "sglang.srt.utils.Withable.with_value", "modulename": "sglang.srt.utils", "qualname": "Withable.with_value", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">new_value</span><span class=\"p\">:</span> <span class=\"o\">~</span><span class=\"n\">T</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.utils.require_mlp_tp_gather", "modulename": "sglang.srt.utils", "qualname": "require_mlp_tp_gather", "kind": "function", "doc": "<p>Check if the input of MLP is obtained by all-gather rather than all-reduce. This only happens when each MLP TP group contains multiple attention DP groups.</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">server_args</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.utils.require_attn_tp_gather", "modulename": "sglang.srt.utils", "qualname": "require_attn_tp_gather", "kind": "function", "doc": "<p>Check if the input of attention is scattered.</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">server_args</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.utils.require_gathered_buffer", "modulename": "sglang.srt.utils", "qualname": "require_gathered_buffer", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">server_args</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.utils.require_mlp_sync", "modulename": "sglang.srt.utils", "qualname": "require_mlp_sync", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">server_args</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.utils.find_local_repo_dir", "modulename": "sglang.srt.utils", "qualname": "find_local_repo_dir", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">repo_id</span><span class=\"p\">:</span> <span class=\"nb\">str</span>, </span><span class=\"param\"><span class=\"n\">revision</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"nb\">str</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span></span><span class=\"return-annotation\">) -> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"nb\">str</span><span class=\"p\">]</span>:</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.utils.read_system_prompt_from_file", "modulename": "sglang.srt.utils", "qualname": "read_system_prompt_from_file", "kind": "function", "doc": "<p>Read system prompt from a file in the HuggingFace cache directory.</p>\n\n<p>Args:\n    model_name: The model name to construct the file path</p>\n\n<p>Returns:\n    The system prompt content from the file, or empty string if file not found</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">model_name</span><span class=\"p\">:</span> <span class=\"nb\">str</span></span><span class=\"return-annotation\">) -> <span class=\"nb\">str</span>:</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.utils.prepack_weight_if_needed", "modulename": "sglang.srt.utils", "qualname": "prepack_weight_if_needed", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">weight</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.utils.dim_is_supported", "modulename": "sglang.srt.utils", "qualname": "dim_is_supported", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">weight</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.utils.PackWeightMethod", "modulename": "sglang.srt.utils", "qualname": "PackWeightMethod", "kind": "class", "doc": "<p></p>\n"}, {"fullname": "sglang.srt.utils.PackWeightMethod.__init__", "modulename": "sglang.srt.utils", "qualname": "PackWeightMethod.__init__", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">weight_names</span>, </span><span class=\"param\"><span class=\"n\">transpose_dims</span><span class=\"o\">=</span><span class=\"kc\">None</span></span>)</span>"}, {"fullname": "sglang.srt.utils.PackWeightMethod.weight_names", "modulename": "sglang.srt.utils", "qualname": "PackWeightMethod.weight_names", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "sglang.srt.utils.PackWeightMethod.transpose_dims", "modulename": "sglang.srt.utils", "qualname": "PackWeightMethod.transpose_dims", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "sglang.srt.utils.PackWeightMethod.process_weights_after_loading", "modulename": "sglang.srt.utils", "qualname": "PackWeightMethod.process_weights_after_loading", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">module</span></span><span class=\"return-annotation\">) -> <span class=\"kc\">None</span>:</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.utils.LazyValue", "modulename": "sglang.srt.utils", "qualname": "LazyValue", "kind": "class", "doc": "<p></p>\n"}, {"fullname": "sglang.srt.utils.LazyValue.__init__", "modulename": "sglang.srt.utils", "qualname": "LazyValue.__init__", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">creator</span><span class=\"p\">:</span> <span class=\"n\">Callable</span></span>)</span>"}, {"fullname": "sglang.srt.utils.LazyValue.value", "modulename": "sglang.srt.utils", "qualname": "LazyValue.value", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "sglang.srt.utils.dynamic_import", "modulename": "sglang.srt.utils", "qualname": "dynamic_import", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">func_path</span><span class=\"p\">:</span> <span class=\"nb\">str</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.utils.gc_object_counts", "modulename": "sglang.srt.utils", "qualname": "gc_object_counts", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.utils.configure_gc_warning", "modulename": "sglang.srt.utils", "qualname": "configure_gc_warning", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">warn_threshold_secs</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.utils.freeze_gc", "modulename": "sglang.srt.utils", "qualname": "freeze_gc", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">context</span><span class=\"p\">:</span> <span class=\"nb\">str</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.utils.configure_gc_logger", "modulename": "sglang.srt.utils", "qualname": "configure_gc_logger", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.utils.align", "modulename": "sglang.srt.utils", "qualname": "align", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">x</span><span class=\"p\">:</span> <span class=\"nb\">int</span>, </span><span class=\"param\"><span class=\"n\">y</span><span class=\"p\">:</span> <span class=\"nb\">int</span></span><span class=\"return-annotation\">) -> <span class=\"nb\">int</span>:</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.utils.ceil_div", "modulename": "sglang.srt.utils", "qualname": "ceil_div", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">x</span><span class=\"p\">:</span> <span class=\"nb\">int</span>, </span><span class=\"param\"><span class=\"n\">y</span><span class=\"p\">:</span> <span class=\"nb\">int</span></span><span class=\"return-annotation\">) -> <span class=\"nb\">int</span>:</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.utils.parse_lscpu_topology", "modulename": "sglang.srt.utils", "qualname": "parse_lscpu_topology", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.utils.get_physical_cpus_by_numa", "modulename": "sglang.srt.utils", "qualname": "get_physical_cpus_by_numa", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.utils.get_cpu_ids_by_node", "modulename": "sglang.srt.utils", "qualname": "get_cpu_ids_by_node", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.utils.is_shm_available", "modulename": "sglang.srt.utils", "qualname": "is_shm_available", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">dtype</span>, </span><span class=\"param\"><span class=\"n\">world_size</span>, </span><span class=\"param\"><span class=\"n\">local_size</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.utils.lru_cache_frozenset", "modulename": "sglang.srt.utils", "qualname": "lru_cache_frozenset", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">maxsize</span><span class=\"o\">=</span><span class=\"mi\">128</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.utils.apply_module_patch", "modulename": "sglang.srt.utils", "qualname": "apply_module_patch", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">target_module</span>, </span><span class=\"param\"><span class=\"n\">target_function</span>, </span><span class=\"param\"><span class=\"n\">wrappers</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.utils.parse_module_path", "modulename": "sglang.srt.utils", "qualname": "parse_module_path", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">module_path</span>, </span><span class=\"param\"><span class=\"n\">function_name</span>, </span><span class=\"param\"><span class=\"n\">create_dummy</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.utils.mxfp_supported", "modulename": "sglang.srt.utils", "qualname": "mxfp_supported", "kind": "function", "doc": "<p>Returns whether the current platform supports MX types.</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.utils.SUPPORTED_LORA_TARGET_MODULES", "modulename": "sglang.srt.utils", "qualname": "SUPPORTED_LORA_TARGET_MODULES", "kind": "variable", "doc": "<p></p>\n", "default_value": "[&#x27;q_proj&#x27;, &#x27;k_proj&#x27;, &#x27;v_proj&#x27;, &#x27;o_proj&#x27;, &#x27;gate_proj&#x27;, &#x27;up_proj&#x27;, &#x27;down_proj&#x27;, &#x27;qkv_proj&#x27;, &#x27;gate_up_proj&#x27;]"}, {"fullname": "sglang.srt.utils.LORA_TARGET_ALL_MODULES", "modulename": "sglang.srt.utils", "qualname": "LORA_TARGET_ALL_MODULES", "kind": "variable", "doc": "<p></p>\n", "default_value": "&#x27;all&#x27;"}, {"fullname": "sglang.srt.utils.ConcurrentCounter", "modulename": "sglang.srt.utils", "qualname": "ConcurrentCounter", "kind": "class", "doc": "<p>An asynchronous counter for managing concurrent tasks that need\ncoordinated increments, decrements, and waiting until the count reaches zero.</p>\n\n<p>This class is useful for scenarios like tracking the number of in-flight tasks\nand waiting for them to complete.</p>\n"}, {"fullname": "sglang.srt.utils.ConcurrentCounter.__init__", "modulename": "sglang.srt.utils", "qualname": "ConcurrentCounter.__init__", "kind": "function", "doc": "<p>Initialize the counter with an optional initial value.</p>\n\n<p>Args:\n    initial (int): The initial value of the counter. Default is 0.</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">initial</span><span class=\"p\">:</span> <span class=\"nb\">int</span> <span class=\"o\">=</span> <span class=\"mi\">0</span></span>)</span>"}, {"fullname": "sglang.srt.utils.ConcurrentCounter.value", "modulename": "sglang.srt.utils", "qualname": "ConcurrentCounter.value", "kind": "function", "doc": "<p>Return the current value of the counter.</p>\n\n<p>Note:\n    This method is not synchronized. It may return a stale value\n    if other coroutines are concurrently modifying the counter.</p>\n\n<p>Returns:\n    int: The current counter value.</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span></span><span class=\"return-annotation\">) -> <span class=\"nb\">int</span>:</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.utils.ConcurrentCounter.increment", "modulename": "sglang.srt.utils", "qualname": "ConcurrentCounter.increment", "kind": "function", "doc": "<p>Atomically increment the counter by a given amount and notify all waiters.</p>\n\n<p>Args:\n    n (int): The amount to increment the counter by. Default is 1.\n    notify_all (bool): Whether to notify all waiters after incrementing. Default is True.</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">n</span><span class=\"p\">:</span> <span class=\"nb\">int</span> <span class=\"o\">=</span> <span class=\"mi\">1</span>, </span><span class=\"param\"><span class=\"n\">notify_all</span><span class=\"p\">:</span> <span class=\"nb\">bool</span> <span class=\"o\">=</span> <span class=\"kc\">True</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "async def"}, {"fullname": "sglang.srt.utils.ConcurrentCounter.decrement", "modulename": "sglang.srt.utils", "qualname": "ConcurrentCounter.decrement", "kind": "function", "doc": "<p>Atomically decrement the counter by a given amount and notify all waiters.</p>\n\n<p>Args:\n    n (int): The amount to decrement the counter by. Default is 1.\n    notify_all (bool): Whether to notify all waiters after decrementing. Default is True.</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">n</span><span class=\"p\">:</span> <span class=\"nb\">int</span> <span class=\"o\">=</span> <span class=\"mi\">1</span>, </span><span class=\"param\"><span class=\"n\">notify_all</span><span class=\"p\">:</span> <span class=\"nb\">bool</span> <span class=\"o\">=</span> <span class=\"kc\">True</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "async def"}, {"fullname": "sglang.srt.utils.ConcurrentCounter.wait_for", "modulename": "sglang.srt.utils", "qualname": "ConcurrentCounter.wait_for", "kind": "function", "doc": "<p>Asynchronously wait until the counter satisfies a given condition.</p>\n\n<p>This suspends the calling coroutine without blocking the thread, allowing\nother tasks to run while waiting. When the condition is met, the coroutine resumes.</p>\n\n<p>Args:\n    condition (Callable[[int], bool]): A function that takes the current counter value\n        and returns True when the condition is satisfied.</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">condition</span><span class=\"p\">:</span> <span class=\"n\">Callable</span><span class=\"p\">[[</span><span class=\"nb\">int</span><span class=\"p\">],</span> <span class=\"nb\">bool</span><span class=\"p\">]</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "async def"}, {"fullname": "sglang.srt.utils.ConcurrentCounter.wait_for_zero", "modulename": "sglang.srt.utils", "qualname": "ConcurrentCounter.wait_for_zero", "kind": "function", "doc": "<p>Asynchronously wait until the counter reaches zero.</p>\n\n<p>This suspends the calling coroutine without blocking the thread, allowing\nother tasks to run while waiting. When the counter becomes zero, the coroutine resumes.</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "async def"}, {"fullname": "sglang.srt.utils.is_triton_kernels_available", "modulename": "sglang.srt.utils", "qualname": "is_triton_kernels_available", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"return-annotation\">) -> <span class=\"nb\">bool</span>:</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.utils.check_cuda_result", "modulename": "sglang.srt.utils", "qualname": "check_cuda_result", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">raw_output</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.warmup", "modulename": "sglang.srt.warmup", "kind": "module", "doc": "<p></p>\n"}, {"fullname": "sglang.srt.warmup.logger", "modulename": "sglang.srt.warmup", "qualname": "logger", "kind": "variable", "doc": "<p></p>\n", "default_value": "&lt;Logger /root/sglang/python/sglang/srt/warmup.py (WARNING)&gt;"}, {"fullname": "sglang.srt.warmup.warmup", "modulename": "sglang.srt.warmup", "qualname": "warmup", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">name</span><span class=\"p\">:</span> <span class=\"nb\">str</span></span><span class=\"return-annotation\">) -> <span class=\"o\">&lt;</span><span class=\"n\">built</span><span class=\"o\">-</span><span class=\"ow\">in</span> <span class=\"n\">function</span> <span class=\"nb\">callable</span><span class=\"o\">&gt;</span>:</span></span>", "funcdef": "def"}, {"fullname": "sglang.srt.warmup.execute_warmups", "modulename": "sglang.srt.warmup", "qualname": "execute_warmups", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">disaggregation_mode</span><span class=\"p\">:</span> <span class=\"nb\">str</span>,</span><span class=\"param\">\t<span class=\"n\">warmup_names</span><span class=\"p\">:</span> <span class=\"n\">List</span><span class=\"p\">[</span><span class=\"nb\">str</span><span class=\"p\">]</span>,</span><span class=\"param\">\t<span class=\"n\">tokenizer_manager</span><span class=\"p\">:</span> <span class=\"n\">sglang</span><span class=\"o\">.</span><span class=\"n\">srt</span><span class=\"o\">.</span><span class=\"n\">managers</span><span class=\"o\">.</span><span class=\"n\">tokenizer_manager</span><span class=\"o\">.</span><span class=\"n\">TokenizerManager</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "async def"}, {"fullname": "sglang.srt.warmup.voice_chat", "modulename": "sglang.srt.warmup", "qualname": "voice_chat", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">disaggregation_mode</span><span class=\"p\">:</span> <span class=\"nb\">str</span>,</span><span class=\"param\">\t<span class=\"n\">tokenizer_manager</span><span class=\"p\">:</span> <span class=\"n\">sglang</span><span class=\"o\">.</span><span class=\"n\">srt</span><span class=\"o\">.</span><span class=\"n\">managers</span><span class=\"o\">.</span><span class=\"n\">tokenizer_manager</span><span class=\"o\">.</span><span class=\"n\">TokenizerManager</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "async def"}];

    // mirrored in build-search-index.js (part 1)
    // Also split on html tags. this is a cheap heuristic, but good enough.
    elasticlunr.tokenizer.setSeperator(/[\s\-.;&_'"=,()]+|<[^>]*>/);

    let searchIndex;
    if (docs._isPrebuiltIndex) {
        console.info("using precompiled search index");
        searchIndex = elasticlunr.Index.load(docs);
    } else {
        console.time("building search index");
        // mirrored in build-search-index.js (part 2)
        searchIndex = elasticlunr(function () {
            this.pipeline.remove(elasticlunr.stemmer);
            this.pipeline.remove(elasticlunr.stopWordFilter);
            this.addField("qualname");
            this.addField("fullname");
            this.addField("annotation");
            this.addField("default_value");
            this.addField("signature");
            this.addField("bases");
            this.addField("doc");
            this.setRef("fullname");
        });
        for (let doc of docs) {
            searchIndex.addDoc(doc);
        }
        console.timeEnd("building search index");
    }

    return (term) => searchIndex.search(term, {
        fields: {
            qualname: {boost: 4},
            fullname: {boost: 2},
            annotation: {boost: 2},
            default_value: {boost: 2},
            signature: {boost: 2},
            bases: {boost: 2},
            doc: {boost: 1},
        },
        expand: true
    });
})();