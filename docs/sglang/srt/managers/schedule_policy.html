<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1">
<meta name="generator" content="pdoc3 0.11.6">
<title>sglang.srt.managers.schedule_policy API documentation</title>
<meta name="description" content="">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/13.0.0/sanitize.min.css" integrity="sha512-y1dtMcuvtTMJc1yPgEqF0ZjQbhnc/bFhyvIyVNb9Zk5mIGtqVaAB1Ttl28su8AvFMOY0EwRbAe+HCLqj6W7/KA==" crossorigin>
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/13.0.0/typography.min.css" integrity="sha512-Y1DYSb995BAfxobCkKepB1BqJJTPrOp3zPL74AWFugHHmmdcvO+C48WLrUOlhGMc0QG7AE3f7gmvvcrmX2fDoA==" crossorigin>
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/styles/default.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:1.5em;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:2em 0 .50em 0}h3{font-size:1.4em;margin:1.6em 0 .7em 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .2s ease-in-out}a:visited{color:#503}a:hover{color:#b62}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900;font-weight:bold}pre code{font-size:.8em;line-height:1.4em;padding:1em;display:block}code{background:#f3f3f3;font-family:"DejaVu Sans Mono",monospace;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source > summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible;min-width:max-content}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em 1em;margin:1em 0}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul ul{padding-left:1em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/highlight.min.js" integrity="sha512-D9gUyxqja7hBtkWpPWGt9wfbfaMGVt9gnyCvYa+jojwwPHLCzUm5i8rpk7vD7wNee9bA35eYIjobYPaQuKS1MQ==" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => {
hljs.configure({languages: ['bash', 'css', 'diff', 'graphql', 'ini', 'javascript', 'json', 'plaintext', 'python', 'python-repl', 'rust', 'shell', 'sql', 'typescript', 'xml', 'yaml']});
hljs.highlightAll();
/* Collapse source docstrings */
setTimeout(() => {
[...document.querySelectorAll('.hljs.language-python > .hljs-string')]
.filter(el => el.innerHTML.length > 200 && ['"""', "'''"].includes(el.innerHTML.substring(0, 3)))
.forEach(el => {
let d = document.createElement('details');
d.classList.add('hljs-string');
d.innerHTML = '<summary>"""</summary>' + el.innerHTML.substring(3);
el.replaceWith(d);
});
}, 100);
})</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>sglang.srt.managers.schedule_policy</code></h1>
</header>
<section id="section-intro">
</section>
<section>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="sglang.srt.managers.schedule_policy.AddReqResult"><code class="flex name class">
<span>class <span class="ident">AddReqResult</span></span>
<span>(</span><span>*args, **kwds)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class AddReqResult(Enum):
    CONTINUE = auto()  # Continue to add requests
    NO_TOKEN = auto()  # No token left
    OTHER = auto()  # Other reasons to stop adding requests</code></pre>
</details>
<div class="desc"><p>Create a collection of name/value pairs.</p>
<p>Example enumeration:</p>
<pre><code class="language-python-repl">&gt;&gt;&gt; class Color(Enum):
...     RED = 1
...     BLUE = 2
...     GREEN = 3
</code></pre>
<p>Access them by:</p>
<ul>
<li>attribute access:</li>
</ul>
<blockquote>
<blockquote>
<blockquote>
<p>Color.RED
<Color.RED: 1></p>
</blockquote>
</blockquote>
</blockquote>
<ul>
<li>value lookup:</li>
</ul>
<blockquote>
<blockquote>
<blockquote>
<p>Color(1)
<Color.RED: 1></p>
</blockquote>
</blockquote>
</blockquote>
<ul>
<li>name lookup:</li>
</ul>
<blockquote>
<blockquote>
<blockquote>
<p>Color['RED']
<Color.RED: 1></p>
</blockquote>
</blockquote>
</blockquote>
<p>Enumerations can be iterated over, and know how many members they have:</p>
<pre><code class="language-python-repl">&gt;&gt;&gt; len(Color)
3
</code></pre>
<pre><code class="language-python-repl">&gt;&gt;&gt; list(Color)
[&lt;Color.RED: 1&gt;, &lt;Color.BLUE: 2&gt;, &lt;Color.GREEN: 3&gt;]
</code></pre>
<p>Methods can be added to enumerations, and members can have their own
attributes &ndash; see the documentation for details.</p></div>
<h3>Ancestors</h3>
<ul class="hlist">
<li>enum.Enum</li>
</ul>
<h3>Class variables</h3>
<dl>
<dt id="sglang.srt.managers.schedule_policy.AddReqResult.CONTINUE"><code class="name">var <span class="ident">CONTINUE</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="sglang.srt.managers.schedule_policy.AddReqResult.NO_TOKEN"><code class="name">var <span class="ident">NO_TOKEN</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="sglang.srt.managers.schedule_policy.AddReqResult.OTHER"><code class="name">var <span class="ident">OTHER</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
</dl>
</dd>
<dt id="sglang.srt.managers.schedule_policy.CacheAgnosticPolicy"><code class="flex name class">
<span>class <span class="ident">CacheAgnosticPolicy</span></span>
<span>(</span><span>*args, **kwds)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class CacheAgnosticPolicy(Enum):
    &#34;&#34;&#34;Scheduling policies that are not aware of the tree cache.&#34;&#34;&#34;

    FCFS = &#34;fcfs&#34;  # first come first serve
    LOF = &#34;lof&#34;  # longest output first
    RANDOM = &#34;random&#34;</code></pre>
</details>
<div class="desc"><p>Scheduling policies that are not aware of the tree cache.</p></div>
<h3>Ancestors</h3>
<ul class="hlist">
<li>enum.Enum</li>
</ul>
<h3>Class variables</h3>
<dl>
<dt id="sglang.srt.managers.schedule_policy.CacheAgnosticPolicy.FCFS"><code class="name">var <span class="ident">FCFS</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="sglang.srt.managers.schedule_policy.CacheAgnosticPolicy.LOF"><code class="name">var <span class="ident">LOF</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="sglang.srt.managers.schedule_policy.CacheAgnosticPolicy.RANDOM"><code class="name">var <span class="ident">RANDOM</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
</dl>
</dd>
<dt id="sglang.srt.managers.schedule_policy.CacheAwarePolicy"><code class="flex name class">
<span>class <span class="ident">CacheAwarePolicy</span></span>
<span>(</span><span>*args, **kwds)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class CacheAwarePolicy(Enum):
    &#34;&#34;&#34;Scheduling policies that are aware of the tree cache.&#34;&#34;&#34;

    LPM = &#34;lpm&#34;  # longest prefix match
    DFS_WEIGHT = &#34;dfs-weight&#34;  # depth-first search weighting</code></pre>
</details>
<div class="desc"><p>Scheduling policies that are aware of the tree cache.</p></div>
<h3>Ancestors</h3>
<ul class="hlist">
<li>enum.Enum</li>
</ul>
<h3>Class variables</h3>
<dl>
<dt id="sglang.srt.managers.schedule_policy.CacheAwarePolicy.DFS_WEIGHT"><code class="name">var <span class="ident">DFS_WEIGHT</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="sglang.srt.managers.schedule_policy.CacheAwarePolicy.LPM"><code class="name">var <span class="ident">LPM</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
</dl>
</dd>
<dt id="sglang.srt.managers.schedule_policy.PrefillAdder"><code class="flex name class">
<span>class <span class="ident">PrefillAdder</span></span>
<span>(</span><span>page_size: int,<br>tree_cache: BasePrefixCache,<br>token_to_kv_pool_allocator: BaseTokenToKVPoolAllocator,<br>running_batch: ScheduleBatch,<br>new_token_ratio: float,<br>rem_input_tokens: int,<br>rem_chunk_tokens: Optional[int],<br>mixed_with_decode_tokens: int = 0)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class PrefillAdder:
    def __init__(
        self,
        page_size: int,
        tree_cache: BasePrefixCache,
        token_to_kv_pool_allocator: BaseTokenToKVPoolAllocator,
        running_batch: ScheduleBatch,
        new_token_ratio: float,
        rem_input_tokens: int,
        rem_chunk_tokens: Optional[int],
        mixed_with_decode_tokens: int = 0,
    ):
        self.page_size = page_size
        self.tree_cache = tree_cache
        self.token_to_kv_pool_allocator = token_to_kv_pool_allocator
        self.running_batch = running_batch
        self.new_token_ratio = new_token_ratio
        self.rem_input_tokens = rem_input_tokens - mixed_with_decode_tokens
        self.rem_chunk_tokens = rem_chunk_tokens
        if self.rem_chunk_tokens is not None:
            self.rem_chunk_tokens -= mixed_with_decode_tokens

        self.rem_total_token_offset = mixed_with_decode_tokens
        self.cur_rem_token_offset = mixed_with_decode_tokens

        self.req_states = None
        self.can_run_list = []
        self.new_chunked_req = None
        self.log_hit_tokens = 0
        # TODO(lsyin): report the real input tokens excluding page alignment
        self.log_input_tokens = 0

        if running_batch is not None:
            self.rem_total_token_offset += sum(
                [
                    min(
                        (r.sampling_params.max_new_tokens - len(r.output_ids)),
                        CLIP_MAX_NEW_TOKENS,
                    )
                    * self.new_token_ratio
                    for r in running_batch.reqs
                ]
            )

        self.is_hybrid = isinstance(
            self.token_to_kv_pool_allocator, SWATokenToKVPoolAllocator
        )

    @property
    def rem_total_tokens(self):
        if self.is_hybrid:
            available_and_evictable = min(
                self.token_to_kv_pool_allocator.full_available_size()
                + self.tree_cache.full_evictable_size(),
                self.token_to_kv_pool_allocator.swa_available_size()
                + self.tree_cache.swa_evictable_size(),
            )
        else:
            available_and_evictable = (
                self.token_to_kv_pool_allocator.available_size()
                + self.tree_cache.evictable_size()
            )

        return available_and_evictable - self.rem_total_token_offset

    @property
    def cur_rem_tokens(self):
        if self.is_hybrid:
            available_and_evictable = min(
                self.token_to_kv_pool_allocator.full_available_size()
                + self.tree_cache.full_evictable_size(),
                self.token_to_kv_pool_allocator.swa_available_size()
                + self.tree_cache.swa_evictable_size(),
            )
        else:
            available_and_evictable = (
                self.token_to_kv_pool_allocator.available_size()
                + self.tree_cache.evictable_size()
            )

        return available_and_evictable - self.cur_rem_token_offset

    def ceil_paged_tokens(self, tokens: int) -&gt; int:
        return -(-tokens // self.page_size) * self.page_size

    def budget_state(self):
        if self.rem_total_tokens &lt;= 0 or self.cur_rem_tokens &lt;= 0:
            return AddReqResult.NO_TOKEN

        if self.rem_input_tokens &lt;= 0 or (
            self.rem_chunk_tokens is not None and self.rem_chunk_tokens &lt;= 0
        ):
            return AddReqResult.OTHER

        return AddReqResult.CONTINUE

    def _update_prefill_budget(
        self, prefix_len: int, extend_input_len: int, max_new_tokens: int
    ):
        # TODO(lsyin): check this workaround logic, which only ensures the prefill will not out of memory, and may be too conservative
        extend_input_len = self.ceil_paged_tokens(extend_input_len)

        self.rem_total_token_offset += extend_input_len + max_new_tokens
        self.cur_rem_token_offset += extend_input_len
        self.rem_input_tokens -= extend_input_len
        if self.rem_chunk_tokens is not None:
            self.rem_chunk_tokens -= extend_input_len

        self.log_hit_tokens += prefix_len
        self.log_input_tokens += extend_input_len

    def add_chunked_req(self, req: Req):
        truncated = req.extend_input_len &gt; self.rem_chunk_tokens
        req.extend_input_len = min(req.extend_input_len, self.rem_chunk_tokens)
        req.fill_ids = req.fill_ids[: len(req.prefix_indices) + req.extend_input_len]
        self.can_run_list.append(req)
        self._update_prefill_budget(
            0,
            req.extend_input_len,
            (
                min(req.sampling_params.max_new_tokens, CLIP_MAX_NEW_TOKENS)
                if not truncated
                else 0
            ),
        )

        # Return if chunked prefill not finished
        return req if truncated else None

    @contextmanager
    def _lock_node(self, last_node: TreeNode):
        if self.is_hybrid:
            try:
                swa_uuid_for_lock = self.tree_cache.inc_lock_ref(last_node)
                yield None
            finally:
                self.tree_cache.dec_lock_ref(last_node, swa_uuid_for_lock)
        else:
            try:
                self.tree_cache.inc_lock_ref(last_node)
                yield None
            finally:
                self.tree_cache.dec_lock_ref(last_node)

    def add_one_req_ignore_eos(self, req: Req, has_chunked_req: bool):
        # Early exit if no enough tokens for the input tokens
        if self.ceil_paged_tokens(req.extend_input_len) &gt; min(
            self.cur_rem_tokens, self.rem_total_tokens
        ):
            return AddReqResult.NO_TOKEN

        def add_req_state(r, insert_sort=False):
            new_token_ratio = (
                1.0 if r.sampling_params.ignore_eos else self.new_token_ratio
            )
            tokens_left = r.sampling_params.max_new_tokens * new_token_ratio - len(
                r.output_ids
            )
            tokens_occupied = len(r.origin_input_ids) + len(r.output_ids)

            if tokens_left &lt;= 0:
                return

            if not insert_sort:
                self.req_states.append((tokens_left, tokens_occupied))
            else:
                i = 0
                for i in range(len(self.req_states)):
                    if tokens_left &lt;= self.req_states[i][0]:
                        break
                self.req_states.insert(i, (tokens_left, tokens_occupied))

        if self.req_states is None:
            self.req_states = []
            add_req_state(req)
            if self.running_batch is not None:
                for r in self.running_batch.reqs:
                    add_req_state(r)
            for r in self.can_run_list:
                add_req_state(r)
            self.req_states.sort(key=lambda x: x[0])
        else:
            add_req_state(req, insert_sort=True)

        if not self.is_hybrid:
            # Skip this logic for swa. The SWA has different memory management, and
            # this mechanism is underestimating the memory usage.
            cur_rem_tokens = self.cur_rem_tokens - self.ceil_paged_tokens(
                req.extend_input_len
            )
            tokens_freed = 0
            for i, (tokens_left, tokens_occupied) in enumerate(self.req_states):
                # tokens_left gives a reservative calculation as the last token is not stored
                bs = len(self.req_states) - i
                min_free_tokens = cur_rem_tokens + tokens_freed - tokens_left * bs
                # reserve tokens for corner cases
                if min_free_tokens &lt;= IGNORE_EOS_RESERVE_TOKENS * bs:
                    return AddReqResult.NO_TOKEN
                tokens_freed += tokens_occupied

        if (
            self.rem_chunk_tokens is None  # chunked prefill is disabled
            or req.extend_input_len &lt;= self.rem_chunk_tokens  # it is the last chunk
        ):
            # Non-chunked prefill
            self.can_run_list.append(req)
            self._update_prefill_budget(
                0,
                req.extend_input_len,
                min(req.sampling_params.max_new_tokens, CLIP_MAX_NEW_TOKENS),
            )
        else:
            if self.rem_chunk_tokens == 0:
                return AddReqResult.OTHER

            # Chunked prefill
            trunc_len = self.rem_chunk_tokens

            req.extend_input_len = trunc_len
            req.fill_ids = req.fill_ids[:trunc_len]
            self.can_run_list.append(req)
            self.new_chunked_req = req
            self._update_prefill_budget(0, trunc_len, 0)

        return self.budget_state()

    def add_one_req(self, req: Req, has_chunked_req: bool):
        if req.sampling_params.ignore_eos and getattr(self.tree_cache, &#34;disable&#34;, True):
            return self.add_one_req_ignore_eos(req, has_chunked_req)

        total_tokens = req.extend_input_len + min(
            req.sampling_params.max_new_tokens, CLIP_MAX_NEW_TOKENS
        )

        # adjusting the input_tokens based on host_hit_length and page_size
        real_input_tokens = req.extend_input_len - req.host_hit_length
        real_input_tokens = self.ceil_paged_tokens(real_input_tokens)
        prefix_len = len(req.prefix_indices)

        if total_tokens &gt;= self.rem_total_tokens:
            return AddReqResult.NO_TOKEN

        if real_input_tokens &gt;= self.rem_input_tokens and len(self.can_run_list) != 0:
            return AddReqResult.OTHER

        with self._lock_node(req.last_node):
            # self.rem_total_tokens may decrease after the lock acquisition
            if total_tokens &gt;= self.rem_total_tokens:
                return AddReqResult.NO_TOKEN

            if req.host_hit_length &gt; 0:
                new_indices, req.last_node = self.tree_cache.init_load_back(
                    req.last_host_node, req.host_hit_length
                )
                req.prefix_indices = torch.cat([req.prefix_indices, new_indices])
                req.extend_input_len = len(req.fill_ids) - len(req.prefix_indices)
                prefix_len = len(req.prefix_indices)

            input_tokens = self.ceil_paged_tokens(req.extend_input_len)

            if input_tokens &gt;= self.rem_input_tokens and len(self.can_run_list) != 0:
                return AddReqResult.OTHER

            if self.rem_chunk_tokens is None or input_tokens &lt;= self.rem_chunk_tokens:
                # Non-chunked prefill
                self.can_run_list.append(req)
                if self.is_hybrid:
                    swa_uuid_for_lock = self.tree_cache.inc_lock_ref(req.last_node)
                    req.swa_uuid_for_lock = swa_uuid_for_lock
                else:
                    self.tree_cache.inc_lock_ref(req.last_node)
                self._update_prefill_budget(
                    prefix_len,
                    input_tokens,
                    min(
                        req.sampling_params.max_new_tokens,
                        CLIP_MAX_NEW_TOKENS,
                    ),
                )
            else:
                # Make sure at least one page is available
                trunc_len = self.rem_chunk_tokens - self.page_size + 1
                if trunc_len &lt;= 0:
                    return AddReqResult.OTHER

                # Chunked prefill
                req.extend_input_len = trunc_len
                req.fill_ids = req.fill_ids[: len(req.prefix_indices) + trunc_len]

                self.can_run_list.append(req)
                self.new_chunked_req = req
                if self.is_hybrid:
                    swa_uuid_for_lock = self.tree_cache.inc_lock_ref(req.last_node)
                    req.swa_uuid_for_lock = swa_uuid_for_lock
                else:
                    self.tree_cache.inc_lock_ref(req.last_node)
                self._update_prefill_budget(prefix_len, trunc_len, 0)

        return self.budget_state()</code></pre>
</details>
<div class="desc"></div>
<h3>Instance variables</h3>
<dl>
<dt id="sglang.srt.managers.schedule_policy.PrefillAdder.cur_rem_tokens"><code class="name">prop <span class="ident">cur_rem_tokens</span></code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@property
def cur_rem_tokens(self):
    if self.is_hybrid:
        available_and_evictable = min(
            self.token_to_kv_pool_allocator.full_available_size()
            + self.tree_cache.full_evictable_size(),
            self.token_to_kv_pool_allocator.swa_available_size()
            + self.tree_cache.swa_evictable_size(),
        )
    else:
        available_and_evictable = (
            self.token_to_kv_pool_allocator.available_size()
            + self.tree_cache.evictable_size()
        )

    return available_and_evictable - self.cur_rem_token_offset</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="sglang.srt.managers.schedule_policy.PrefillAdder.rem_total_tokens"><code class="name">prop <span class="ident">rem_total_tokens</span></code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@property
def rem_total_tokens(self):
    if self.is_hybrid:
        available_and_evictable = min(
            self.token_to_kv_pool_allocator.full_available_size()
            + self.tree_cache.full_evictable_size(),
            self.token_to_kv_pool_allocator.swa_available_size()
            + self.tree_cache.swa_evictable_size(),
        )
    else:
        available_and_evictable = (
            self.token_to_kv_pool_allocator.available_size()
            + self.tree_cache.evictable_size()
        )

    return available_and_evictable - self.rem_total_token_offset</code></pre>
</details>
<div class="desc"></div>
</dd>
</dl>
<h3>Methods</h3>
<dl>
<dt id="sglang.srt.managers.schedule_policy.PrefillAdder.add_chunked_req"><code class="name flex">
<span>def <span class="ident">add_chunked_req</span></span>(<span>self, req: Req)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def add_chunked_req(self, req: Req):
    truncated = req.extend_input_len &gt; self.rem_chunk_tokens
    req.extend_input_len = min(req.extend_input_len, self.rem_chunk_tokens)
    req.fill_ids = req.fill_ids[: len(req.prefix_indices) + req.extend_input_len]
    self.can_run_list.append(req)
    self._update_prefill_budget(
        0,
        req.extend_input_len,
        (
            min(req.sampling_params.max_new_tokens, CLIP_MAX_NEW_TOKENS)
            if not truncated
            else 0
        ),
    )

    # Return if chunked prefill not finished
    return req if truncated else None</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="sglang.srt.managers.schedule_policy.PrefillAdder.add_one_req"><code class="name flex">
<span>def <span class="ident">add_one_req</span></span>(<span>self, req: Req, has_chunked_req: bool)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def add_one_req(self, req: Req, has_chunked_req: bool):
    if req.sampling_params.ignore_eos and getattr(self.tree_cache, &#34;disable&#34;, True):
        return self.add_one_req_ignore_eos(req, has_chunked_req)

    total_tokens = req.extend_input_len + min(
        req.sampling_params.max_new_tokens, CLIP_MAX_NEW_TOKENS
    )

    # adjusting the input_tokens based on host_hit_length and page_size
    real_input_tokens = req.extend_input_len - req.host_hit_length
    real_input_tokens = self.ceil_paged_tokens(real_input_tokens)
    prefix_len = len(req.prefix_indices)

    if total_tokens &gt;= self.rem_total_tokens:
        return AddReqResult.NO_TOKEN

    if real_input_tokens &gt;= self.rem_input_tokens and len(self.can_run_list) != 0:
        return AddReqResult.OTHER

    with self._lock_node(req.last_node):
        # self.rem_total_tokens may decrease after the lock acquisition
        if total_tokens &gt;= self.rem_total_tokens:
            return AddReqResult.NO_TOKEN

        if req.host_hit_length &gt; 0:
            new_indices, req.last_node = self.tree_cache.init_load_back(
                req.last_host_node, req.host_hit_length
            )
            req.prefix_indices = torch.cat([req.prefix_indices, new_indices])
            req.extend_input_len = len(req.fill_ids) - len(req.prefix_indices)
            prefix_len = len(req.prefix_indices)

        input_tokens = self.ceil_paged_tokens(req.extend_input_len)

        if input_tokens &gt;= self.rem_input_tokens and len(self.can_run_list) != 0:
            return AddReqResult.OTHER

        if self.rem_chunk_tokens is None or input_tokens &lt;= self.rem_chunk_tokens:
            # Non-chunked prefill
            self.can_run_list.append(req)
            if self.is_hybrid:
                swa_uuid_for_lock = self.tree_cache.inc_lock_ref(req.last_node)
                req.swa_uuid_for_lock = swa_uuid_for_lock
            else:
                self.tree_cache.inc_lock_ref(req.last_node)
            self._update_prefill_budget(
                prefix_len,
                input_tokens,
                min(
                    req.sampling_params.max_new_tokens,
                    CLIP_MAX_NEW_TOKENS,
                ),
            )
        else:
            # Make sure at least one page is available
            trunc_len = self.rem_chunk_tokens - self.page_size + 1
            if trunc_len &lt;= 0:
                return AddReqResult.OTHER

            # Chunked prefill
            req.extend_input_len = trunc_len
            req.fill_ids = req.fill_ids[: len(req.prefix_indices) + trunc_len]

            self.can_run_list.append(req)
            self.new_chunked_req = req
            if self.is_hybrid:
                swa_uuid_for_lock = self.tree_cache.inc_lock_ref(req.last_node)
                req.swa_uuid_for_lock = swa_uuid_for_lock
            else:
                self.tree_cache.inc_lock_ref(req.last_node)
            self._update_prefill_budget(prefix_len, trunc_len, 0)

    return self.budget_state()</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="sglang.srt.managers.schedule_policy.PrefillAdder.add_one_req_ignore_eos"><code class="name flex">
<span>def <span class="ident">add_one_req_ignore_eos</span></span>(<span>self, req: Req, has_chunked_req: bool)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def add_one_req_ignore_eos(self, req: Req, has_chunked_req: bool):
    # Early exit if no enough tokens for the input tokens
    if self.ceil_paged_tokens(req.extend_input_len) &gt; min(
        self.cur_rem_tokens, self.rem_total_tokens
    ):
        return AddReqResult.NO_TOKEN

    def add_req_state(r, insert_sort=False):
        new_token_ratio = (
            1.0 if r.sampling_params.ignore_eos else self.new_token_ratio
        )
        tokens_left = r.sampling_params.max_new_tokens * new_token_ratio - len(
            r.output_ids
        )
        tokens_occupied = len(r.origin_input_ids) + len(r.output_ids)

        if tokens_left &lt;= 0:
            return

        if not insert_sort:
            self.req_states.append((tokens_left, tokens_occupied))
        else:
            i = 0
            for i in range(len(self.req_states)):
                if tokens_left &lt;= self.req_states[i][0]:
                    break
            self.req_states.insert(i, (tokens_left, tokens_occupied))

    if self.req_states is None:
        self.req_states = []
        add_req_state(req)
        if self.running_batch is not None:
            for r in self.running_batch.reqs:
                add_req_state(r)
        for r in self.can_run_list:
            add_req_state(r)
        self.req_states.sort(key=lambda x: x[0])
    else:
        add_req_state(req, insert_sort=True)

    if not self.is_hybrid:
        # Skip this logic for swa. The SWA has different memory management, and
        # this mechanism is underestimating the memory usage.
        cur_rem_tokens = self.cur_rem_tokens - self.ceil_paged_tokens(
            req.extend_input_len
        )
        tokens_freed = 0
        for i, (tokens_left, tokens_occupied) in enumerate(self.req_states):
            # tokens_left gives a reservative calculation as the last token is not stored
            bs = len(self.req_states) - i
            min_free_tokens = cur_rem_tokens + tokens_freed - tokens_left * bs
            # reserve tokens for corner cases
            if min_free_tokens &lt;= IGNORE_EOS_RESERVE_TOKENS * bs:
                return AddReqResult.NO_TOKEN
            tokens_freed += tokens_occupied

    if (
        self.rem_chunk_tokens is None  # chunked prefill is disabled
        or req.extend_input_len &lt;= self.rem_chunk_tokens  # it is the last chunk
    ):
        # Non-chunked prefill
        self.can_run_list.append(req)
        self._update_prefill_budget(
            0,
            req.extend_input_len,
            min(req.sampling_params.max_new_tokens, CLIP_MAX_NEW_TOKENS),
        )
    else:
        if self.rem_chunk_tokens == 0:
            return AddReqResult.OTHER

        # Chunked prefill
        trunc_len = self.rem_chunk_tokens

        req.extend_input_len = trunc_len
        req.fill_ids = req.fill_ids[:trunc_len]
        self.can_run_list.append(req)
        self.new_chunked_req = req
        self._update_prefill_budget(0, trunc_len, 0)

    return self.budget_state()</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="sglang.srt.managers.schedule_policy.PrefillAdder.budget_state"><code class="name flex">
<span>def <span class="ident">budget_state</span></span>(<span>self)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def budget_state(self):
    if self.rem_total_tokens &lt;= 0 or self.cur_rem_tokens &lt;= 0:
        return AddReqResult.NO_TOKEN

    if self.rem_input_tokens &lt;= 0 or (
        self.rem_chunk_tokens is not None and self.rem_chunk_tokens &lt;= 0
    ):
        return AddReqResult.OTHER

    return AddReqResult.CONTINUE</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="sglang.srt.managers.schedule_policy.PrefillAdder.ceil_paged_tokens"><code class="name flex">
<span>def <span class="ident">ceil_paged_tokens</span></span>(<span>self, tokens: int) ‑> int</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def ceil_paged_tokens(self, tokens: int) -&gt; int:
    return -(-tokens // self.page_size) * self.page_size</code></pre>
</details>
<div class="desc"></div>
</dd>
</dl>
</dd>
<dt id="sglang.srt.managers.schedule_policy.SchedulePolicy"><code class="flex name class">
<span>class <span class="ident">SchedulePolicy</span></span>
<span>(</span><span>policy: str, tree_cache: BasePrefixCache, enable_hierarchical_cache: bool)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class SchedulePolicy:
    Policy = Union[CacheAwarePolicy, CacheAgnosticPolicy]

    def __init__(
        self,
        policy: str,
        tree_cache: BasePrefixCache,
        enable_hierarchical_cache: bool,
    ):
        self.policy = self._validate_and_adjust_policy(policy, tree_cache)
        self.tree_cache = tree_cache
        self.enable_hierarchical_cache = enable_hierarchical_cache

        # It is used to find the matching prefix for in-batch prefix caching.
        self.waiting_queue_radix_tree = RadixCache(
            req_to_token_pool=None,
            token_to_kv_pool_allocator=None,
            page_size=1,
            disable=False,
        )

    def calc_priority(self, waiting_queue: List[Req]) -&gt; bool:
        if self.policy == CacheAgnosticPolicy.FCFS:
            # A shortcut for FCFS
            return False

        policy = self._determine_active_policy(waiting_queue)

        prefix_computed = False
        if isinstance(policy, CacheAwarePolicy):
            prefix_computed = True
            temporary_deprioritized = self._compute_prefix_matches(
                waiting_queue, policy
            )
            if policy == CacheAwarePolicy.LPM:
                SchedulePolicy._sort_by_longest_prefix(
                    waiting_queue, temporary_deprioritized
                )
            elif policy == CacheAwarePolicy.DFS_WEIGHT:
                SchedulePolicy._sort_by_dfs_weight(waiting_queue, self.tree_cache)
            else:
                raise ValueError(f&#34;Unknown CacheAware Policy: {policy=}&#34;)
        else:
            if policy == CacheAgnosticPolicy.FCFS:
                pass
            elif policy == CacheAgnosticPolicy.LOF:
                SchedulePolicy._sort_by_longest_output(waiting_queue)
            elif policy == CacheAgnosticPolicy.RANDOM:
                SchedulePolicy._sort_randomly(waiting_queue)
            else:
                raise ValueError(f&#34;Unknown CacheAgnostic Policy: {policy=}&#34;)

        return prefix_computed

    def _determine_active_policy(self, waiting_queue: List[Req]) -&gt; Policy:
        if self.policy == CacheAwarePolicy.LPM and len(waiting_queue) &gt; 128:
            # Turn off the expensive prefix matching and sorting when the #queue is large.
            return CacheAgnosticPolicy.FCFS
        return self.policy

    def _validate_and_adjust_policy(
        self, policy: str, tree_cache: BasePrefixCache
    ) -&gt; Policy:
        &#34;&#34;&#34;
        Validates the policy and adjusts it if necessary based on tree cache settings.
        &#34;&#34;&#34;
        try:
            policy_enum = CacheAwarePolicy(policy)
            if getattr(tree_cache, &#34;disable&#34;, True):
                # If tree_cache is disabled, using CacheAgnosticPolicy policy
                return CacheAgnosticPolicy.FCFS
            return policy_enum
        except ValueError:
            try:
                return CacheAgnosticPolicy(policy)
            except ValueError:
                raise ValueError(f&#34;Unknown schedule_policy: {policy=}&#34;)

    def _compute_prefix_matches(
        self, waiting_queue: List[Req], policy: CacheAwarePolicy
    ) -&gt; Set[int]:
        &#34;&#34;&#34;
        Computes and caches the matching prefixes for requests in the waiting queue,
            and handles in-batch prefix caching logic.
        &#34;&#34;&#34;
        temporary_deprioritized: Set[int] = set()
        self.waiting_queue_radix_tree.reset()

        for r in waiting_queue:
            prefix_ids = r.adjust_max_prefix_ids()

            # NOTE: the prefix_indices must always be aligned with last_node
            r.prefix_indices, r.last_node, r.last_host_node, r.host_hit_length = (
                self.tree_cache.match_prefix(rid=r.rid, key=prefix_ids)
            )

            # NOTE(sang): This logic is for in-batch prefix caching;
            # If there are more than 1 request that have small matching prefix from
            # existing cache, but all those requests share the same prefix, we prefer
            # to schedule only one of them so that we can increase the cache hit rate.
            # We prefer to set IN_BATCH_PREFIX_CACHING_CHECK_THRESHOLD &gt; 0 because too small
            # threshold means we cannot use in-batch prefix caching for short prefixes.
            # It is kind of common when the engine is long running (e.g., imagine the prefix &#34;the&#34;).
            if len(r.prefix_indices) &lt;= IN_BATCH_PREFIX_CACHING_CHECK_THRESHOLD:
                in_batch_matching_prefixes, _, _, _ = (
                    self.waiting_queue_radix_tree.match_prefix(
                        rid=r.rid, key=prefix_ids
                    )
                )
                if (
                    len(in_batch_matching_prefixes)
                    &gt;= IN_BATCH_PREFIX_CACHING_DEPRIORITIZE_THRESHOLD
                ):
                    temporary_deprioritized.add(r.rid)
                else:
                    # Insert with a dummy key
                    self.waiting_queue_radix_tree.insert(
                        prefix_ids, torch.empty(len(prefix_ids), dtype=torch.bool)
                    )
        return temporary_deprioritized

    @staticmethod
    def _sort_by_longest_prefix(
        waiting_queue: List[Req], temporary_deprioritized: Set[int]
    ) -&gt; None:
        &#34;&#34;&#34;Sorts the waiting queue based on the longest prefix match.&#34;&#34;&#34;
        waiting_queue.sort(
            key=lambda r: (
                -len(r.prefix_indices)
                if r.rid not in temporary_deprioritized
                else float(&#34;inf&#34;)
            )
        )

    @staticmethod
    def _sort_by_dfs_weight(
        waiting_queue: List[Req], tree_cache: BasePrefixCache
    ) -&gt; None:
        &#34;&#34;&#34;Sorts the waiting queue based on a depth-first search weighting.&#34;&#34;&#34;
        last_node_to_reqs = defaultdict(list)
        for req in waiting_queue:
            last_node_to_reqs[req.last_node].append(req)

        node_to_weight = defaultdict(int)
        for node in last_node_to_reqs:
            node_to_weight[node] = len(last_node_to_reqs[node])
        SchedulePolicy._calc_weight(tree_cache.root_node, node_to_weight)

        waiting_queue.clear()
        SchedulePolicy._get_dfs_priority(
            tree_cache.root_node,
            node_to_weight,
            last_node_to_reqs,
            waiting_queue,
        )

    @staticmethod
    def _sort_by_longest_output(waiting_queue: List[Req]) -&gt; None:
        &#34;&#34;&#34;Sorts the waiting queue based on the longest output (max_new_tokens).&#34;&#34;&#34;
        waiting_queue.sort(key=lambda x: -x.sampling_params.max_new_tokens)

    @staticmethod
    def _sort_randomly(waiting_queue: List[Req]) -&gt; None:
        &#34;&#34;&#34;Shuffles the waiting queue randomly.&#34;&#34;&#34;
        random.shuffle(waiting_queue)

    @staticmethod
    def _calc_weight(cur_node: TreeNode, node_to_weight: Dict[TreeNode, int]) -&gt; None:
        for child in cur_node.children.values():
            SchedulePolicy._calc_weight(child, node_to_weight)
            node_to_weight[cur_node] += node_to_weight[child]

    @staticmethod
    def _get_dfs_priority(
        cur_node: TreeNode,
        node_to_priority: Dict[TreeNode, int],
        last_node_to_reqs: Dict[TreeNode, List[Req]],
        q: List,
    ) -&gt; None:
        childs = [child for child in cur_node.children.values()]
        childs.sort(key=lambda x: -node_to_priority[x])
        for child in childs:
            SchedulePolicy._get_dfs_priority(
                child, node_to_priority, last_node_to_reqs, q
            )
        q.extend(last_node_to_reqs[cur_node])</code></pre>
</details>
<div class="desc"></div>
<h3>Class variables</h3>
<dl>
<dt id="sglang.srt.managers.schedule_policy.SchedulePolicy.Policy"><code class="name">var <span class="ident">Policy</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
</dl>
<h3>Methods</h3>
<dl>
<dt id="sglang.srt.managers.schedule_policy.SchedulePolicy.calc_priority"><code class="name flex">
<span>def <span class="ident">calc_priority</span></span>(<span>self, waiting_queue: List[Req]) ‑> bool</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def calc_priority(self, waiting_queue: List[Req]) -&gt; bool:
    if self.policy == CacheAgnosticPolicy.FCFS:
        # A shortcut for FCFS
        return False

    policy = self._determine_active_policy(waiting_queue)

    prefix_computed = False
    if isinstance(policy, CacheAwarePolicy):
        prefix_computed = True
        temporary_deprioritized = self._compute_prefix_matches(
            waiting_queue, policy
        )
        if policy == CacheAwarePolicy.LPM:
            SchedulePolicy._sort_by_longest_prefix(
                waiting_queue, temporary_deprioritized
            )
        elif policy == CacheAwarePolicy.DFS_WEIGHT:
            SchedulePolicy._sort_by_dfs_weight(waiting_queue, self.tree_cache)
        else:
            raise ValueError(f&#34;Unknown CacheAware Policy: {policy=}&#34;)
    else:
        if policy == CacheAgnosticPolicy.FCFS:
            pass
        elif policy == CacheAgnosticPolicy.LOF:
            SchedulePolicy._sort_by_longest_output(waiting_queue)
        elif policy == CacheAgnosticPolicy.RANDOM:
            SchedulePolicy._sort_randomly(waiting_queue)
        else:
            raise ValueError(f&#34;Unknown CacheAgnostic Policy: {policy=}&#34;)

    return prefix_computed</code></pre>
</details>
<div class="desc"></div>
</dd>
</dl>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="sglang.srt.managers" href="index.html">sglang.srt.managers</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="sglang.srt.managers.schedule_policy.AddReqResult" href="#sglang.srt.managers.schedule_policy.AddReqResult">AddReqResult</a></code></h4>
<ul class="">
<li><code><a title="sglang.srt.managers.schedule_policy.AddReqResult.CONTINUE" href="#sglang.srt.managers.schedule_policy.AddReqResult.CONTINUE">CONTINUE</a></code></li>
<li><code><a title="sglang.srt.managers.schedule_policy.AddReqResult.NO_TOKEN" href="#sglang.srt.managers.schedule_policy.AddReqResult.NO_TOKEN">NO_TOKEN</a></code></li>
<li><code><a title="sglang.srt.managers.schedule_policy.AddReqResult.OTHER" href="#sglang.srt.managers.schedule_policy.AddReqResult.OTHER">OTHER</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="sglang.srt.managers.schedule_policy.CacheAgnosticPolicy" href="#sglang.srt.managers.schedule_policy.CacheAgnosticPolicy">CacheAgnosticPolicy</a></code></h4>
<ul class="">
<li><code><a title="sglang.srt.managers.schedule_policy.CacheAgnosticPolicy.FCFS" href="#sglang.srt.managers.schedule_policy.CacheAgnosticPolicy.FCFS">FCFS</a></code></li>
<li><code><a title="sglang.srt.managers.schedule_policy.CacheAgnosticPolicy.LOF" href="#sglang.srt.managers.schedule_policy.CacheAgnosticPolicy.LOF">LOF</a></code></li>
<li><code><a title="sglang.srt.managers.schedule_policy.CacheAgnosticPolicy.RANDOM" href="#sglang.srt.managers.schedule_policy.CacheAgnosticPolicy.RANDOM">RANDOM</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="sglang.srt.managers.schedule_policy.CacheAwarePolicy" href="#sglang.srt.managers.schedule_policy.CacheAwarePolicy">CacheAwarePolicy</a></code></h4>
<ul class="">
<li><code><a title="sglang.srt.managers.schedule_policy.CacheAwarePolicy.DFS_WEIGHT" href="#sglang.srt.managers.schedule_policy.CacheAwarePolicy.DFS_WEIGHT">DFS_WEIGHT</a></code></li>
<li><code><a title="sglang.srt.managers.schedule_policy.CacheAwarePolicy.LPM" href="#sglang.srt.managers.schedule_policy.CacheAwarePolicy.LPM">LPM</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="sglang.srt.managers.schedule_policy.PrefillAdder" href="#sglang.srt.managers.schedule_policy.PrefillAdder">PrefillAdder</a></code></h4>
<ul class="">
<li><code><a title="sglang.srt.managers.schedule_policy.PrefillAdder.add_chunked_req" href="#sglang.srt.managers.schedule_policy.PrefillAdder.add_chunked_req">add_chunked_req</a></code></li>
<li><code><a title="sglang.srt.managers.schedule_policy.PrefillAdder.add_one_req" href="#sglang.srt.managers.schedule_policy.PrefillAdder.add_one_req">add_one_req</a></code></li>
<li><code><a title="sglang.srt.managers.schedule_policy.PrefillAdder.add_one_req_ignore_eos" href="#sglang.srt.managers.schedule_policy.PrefillAdder.add_one_req_ignore_eos">add_one_req_ignore_eos</a></code></li>
<li><code><a title="sglang.srt.managers.schedule_policy.PrefillAdder.budget_state" href="#sglang.srt.managers.schedule_policy.PrefillAdder.budget_state">budget_state</a></code></li>
<li><code><a title="sglang.srt.managers.schedule_policy.PrefillAdder.ceil_paged_tokens" href="#sglang.srt.managers.schedule_policy.PrefillAdder.ceil_paged_tokens">ceil_paged_tokens</a></code></li>
<li><code><a title="sglang.srt.managers.schedule_policy.PrefillAdder.cur_rem_tokens" href="#sglang.srt.managers.schedule_policy.PrefillAdder.cur_rem_tokens">cur_rem_tokens</a></code></li>
<li><code><a title="sglang.srt.managers.schedule_policy.PrefillAdder.rem_total_tokens" href="#sglang.srt.managers.schedule_policy.PrefillAdder.rem_total_tokens">rem_total_tokens</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="sglang.srt.managers.schedule_policy.SchedulePolicy" href="#sglang.srt.managers.schedule_policy.SchedulePolicy">SchedulePolicy</a></code></h4>
<ul class="">
<li><code><a title="sglang.srt.managers.schedule_policy.SchedulePolicy.Policy" href="#sglang.srt.managers.schedule_policy.SchedulePolicy.Policy">Policy</a></code></li>
<li><code><a title="sglang.srt.managers.schedule_policy.SchedulePolicy.calc_priority" href="#sglang.srt.managers.schedule_policy.SchedulePolicy.calc_priority">calc_priority</a></code></li>
</ul>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc" title="pdoc: Python API documentation generator"><cite>pdoc</cite> 0.11.6</a>.</p>
</footer>
</body>
</html>
