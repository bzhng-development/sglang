<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1">
<meta name="generator" content="pdoc3 0.11.6">
<title>sglang.srt.mem_cache.storage.hf3fs.mini_3fs_metadata_server API documentation</title>
<meta name="description" content="">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/13.0.0/sanitize.min.css" integrity="sha512-y1dtMcuvtTMJc1yPgEqF0ZjQbhnc/bFhyvIyVNb9Zk5mIGtqVaAB1Ttl28su8AvFMOY0EwRbAe+HCLqj6W7/KA==" crossorigin>
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/13.0.0/typography.min.css" integrity="sha512-Y1DYSb995BAfxobCkKepB1BqJJTPrOp3zPL74AWFugHHmmdcvO+C48WLrUOlhGMc0QG7AE3f7gmvvcrmX2fDoA==" crossorigin>
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/styles/default.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:1.5em;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:2em 0 .50em 0}h3{font-size:1.4em;margin:1.6em 0 .7em 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .2s ease-in-out}a:visited{color:#503}a:hover{color:#b62}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900;font-weight:bold}pre code{font-size:.8em;line-height:1.4em;padding:1em;display:block}code{background:#f3f3f3;font-family:"DejaVu Sans Mono",monospace;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source > summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible;min-width:max-content}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em 1em;margin:1em 0}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul ul{padding-left:1em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/highlight.min.js" integrity="sha512-D9gUyxqja7hBtkWpPWGt9wfbfaMGVt9gnyCvYa+jojwwPHLCzUm5i8rpk7vD7wNee9bA35eYIjobYPaQuKS1MQ==" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => {
hljs.configure({languages: ['bash', 'css', 'diff', 'graphql', 'ini', 'javascript', 'json', 'plaintext', 'python', 'python-repl', 'rust', 'shell', 'sql', 'typescript', 'xml', 'yaml']});
hljs.highlightAll();
/* Collapse source docstrings */
setTimeout(() => {
[...document.querySelectorAll('.hljs.language-python > .hljs-string')]
.filter(el => el.innerHTML.length > 200 && ['"""', "'''"].includes(el.innerHTML.substring(0, 3)))
.forEach(el => {
let d = document.createElement('details');
d.classList.add('hljs-string');
d.innerHTML = '<summary>"""</summary>' + el.innerHTML.substring(3);
el.replaceWith(d);
});
}, 100);
})</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>sglang.srt.mem_cache.storage.hf3fs.mini_3fs_metadata_server</code></h1>
</header>
<section id="section-intro">
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-functions">Functions</h2>
<dl>
<dt id="sglang.srt.mem_cache.storage.hf3fs.mini_3fs_metadata_server.run_metadata_server"><code class="name flex">
<span>def <span class="ident">run_metadata_server</span></span>(<span>host: str = '0.0.0.0',<br>port: int = 18000,<br>persistence_path: str | None = None,<br>save_interval: int = 60)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def run_metadata_server(
    host: str = &#34;0.0.0.0&#34;,
    port: int = 18000,
    persistence_path: Optional[str] = None,
    save_interval: int = 60,
):
    &#34;&#34;&#34;Run the HF3FS metadata server.&#34;&#34;&#34;
    global server
    server = Hf3fsMetadataServer(
        persistence_path=persistence_path, save_interval=save_interval
    )

    server.run(host=host, port=port)</code></pre>
</details>
<div class="desc"><p>Run the HF3FS metadata server.</p></div>
</dd>
</dl>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="sglang.srt.mem_cache.storage.hf3fs.mini_3fs_metadata_server.GlobalMetadataState"><code class="flex name class">
<span>class <span class="ident">GlobalMetadataState</span></span>
<span>(</span><span>persistence_path: str | None, save_interval: int)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class GlobalMetadataState:
    &#34;&#34;&#34;Manages the state for all ranks and persistence.&#34;&#34;&#34;

    def __init__(self, persistence_path: Optional[str], save_interval: int):
        self.global_lock = threading.RLock()
        self.ranks: Dict[int, RankMetadata] = {}
        self.persistence_path = Path(persistence_path) if persistence_path else None
        self.save_interval = save_interval
        self.save_timer: Optional[threading.Timer] = None
        self.is_shutting_down = False

    def load_from_disk(self):
        if not self.persistence_path or not self.persistence_path.exists():
            logging.info(&#34;Persistence file not found. Starting with a clean state.&#34;)
            return

        logging.info(f&#34;Loading state from {self.persistence_path}&#34;)
        try:
            with open(self.persistence_path, &#34;r&#34;) as f:
                persisted_data = json.load(f)

            with self.global_lock:
                for rank_id_str, data in persisted_data.items():
                    rank_id = int(rank_id_str)
                    num_pages = data[&#34;num_pages&#34;]
                    rank_meta = RankMetadata(num_pages)
                    rank_meta.free_pages = data[&#34;free_pages&#34;]
                    rank_meta.key_to_index = dict(data[&#34;key_to_index&#34;])
                    self.ranks[rank_id] = rank_meta
                logging.info(
                    f&#34;Successfully loaded metadata for {len(self.ranks)} ranks.&#34;
                )
        except (json.JSONDecodeError, KeyError, TypeError) as e:
            logging.error(
                f&#34;Failed to load or parse persistence file: {e}. Starting fresh.&#34;,
                exc_info=True,
            )
            self.ranks.clear()

    def save_to_disk(self):
        if not self.persistence_path:
            return

        logging.info(&#34;Persisting metadata to disk...&#34;)
        with self.global_lock:
            serializable_state = {}
            for rank_id, rank_meta in self.ranks.items():
                with rank_meta.lock:
                    serializable_state[rank_id] = {
                        &#34;num_pages&#34;: rank_meta.num_pages,
                        &#34;free_pages&#34;: rank_meta.free_pages,
                        &#34;key_to_index&#34;: list(rank_meta.key_to_index.items()),
                    }

        try:
            temp_path = self.persistence_path.with_suffix(&#34;.tmp&#34;)
            with open(temp_path, &#34;w&#34;) as f:
                json.dump(serializable_state, f, indent=4)
            temp_path.rename(self.persistence_path)
            logging.info(f&#34;Metadata successfully persisted to {self.persistence_path}&#34;)
        except Exception as e:
            logging.error(f&#34;Failed to save metadata to disk: {e}&#34;, exc_info=True)

    def schedule_save(self):
        if self.is_shutting_down or not self.persistence_path:
            return
        self.save_to_disk()
        self.save_timer = threading.Timer(self.save_interval, self.schedule_save)
        self.save_timer.start()

    def shutdown(self):
        logging.info(&#34;Shutting down metadata server...&#34;)
        self.is_shutting_down = True
        if self.save_timer:
            self.save_timer.cancel()
        self.save_to_disk()
        logging.info(&#34;Shutdown complete.&#34;)</code></pre>
</details>
<div class="desc"><p>Manages the state for all ranks and persistence.</p></div>
<h3>Methods</h3>
<dl>
<dt id="sglang.srt.mem_cache.storage.hf3fs.mini_3fs_metadata_server.GlobalMetadataState.load_from_disk"><code class="name flex">
<span>def <span class="ident">load_from_disk</span></span>(<span>self)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def load_from_disk(self):
    if not self.persistence_path or not self.persistence_path.exists():
        logging.info(&#34;Persistence file not found. Starting with a clean state.&#34;)
        return

    logging.info(f&#34;Loading state from {self.persistence_path}&#34;)
    try:
        with open(self.persistence_path, &#34;r&#34;) as f:
            persisted_data = json.load(f)

        with self.global_lock:
            for rank_id_str, data in persisted_data.items():
                rank_id = int(rank_id_str)
                num_pages = data[&#34;num_pages&#34;]
                rank_meta = RankMetadata(num_pages)
                rank_meta.free_pages = data[&#34;free_pages&#34;]
                rank_meta.key_to_index = dict(data[&#34;key_to_index&#34;])
                self.ranks[rank_id] = rank_meta
            logging.info(
                f&#34;Successfully loaded metadata for {len(self.ranks)} ranks.&#34;
            )
    except (json.JSONDecodeError, KeyError, TypeError) as e:
        logging.error(
            f&#34;Failed to load or parse persistence file: {e}. Starting fresh.&#34;,
            exc_info=True,
        )
        self.ranks.clear()</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="sglang.srt.mem_cache.storage.hf3fs.mini_3fs_metadata_server.GlobalMetadataState.save_to_disk"><code class="name flex">
<span>def <span class="ident">save_to_disk</span></span>(<span>self)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def save_to_disk(self):
    if not self.persistence_path:
        return

    logging.info(&#34;Persisting metadata to disk...&#34;)
    with self.global_lock:
        serializable_state = {}
        for rank_id, rank_meta in self.ranks.items():
            with rank_meta.lock:
                serializable_state[rank_id] = {
                    &#34;num_pages&#34;: rank_meta.num_pages,
                    &#34;free_pages&#34;: rank_meta.free_pages,
                    &#34;key_to_index&#34;: list(rank_meta.key_to_index.items()),
                }

    try:
        temp_path = self.persistence_path.with_suffix(&#34;.tmp&#34;)
        with open(temp_path, &#34;w&#34;) as f:
            json.dump(serializable_state, f, indent=4)
        temp_path.rename(self.persistence_path)
        logging.info(f&#34;Metadata successfully persisted to {self.persistence_path}&#34;)
    except Exception as e:
        logging.error(f&#34;Failed to save metadata to disk: {e}&#34;, exc_info=True)</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="sglang.srt.mem_cache.storage.hf3fs.mini_3fs_metadata_server.GlobalMetadataState.schedule_save"><code class="name flex">
<span>def <span class="ident">schedule_save</span></span>(<span>self)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def schedule_save(self):
    if self.is_shutting_down or not self.persistence_path:
        return
    self.save_to_disk()
    self.save_timer = threading.Timer(self.save_interval, self.schedule_save)
    self.save_timer.start()</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="sglang.srt.mem_cache.storage.hf3fs.mini_3fs_metadata_server.GlobalMetadataState.shutdown"><code class="name flex">
<span>def <span class="ident">shutdown</span></span>(<span>self)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def shutdown(self):
    logging.info(&#34;Shutting down metadata server...&#34;)
    self.is_shutting_down = True
    if self.save_timer:
        self.save_timer.cancel()
    self.save_to_disk()
    logging.info(&#34;Shutdown complete.&#34;)</code></pre>
</details>
<div class="desc"></div>
</dd>
</dl>
</dd>
<dt id="sglang.srt.mem_cache.storage.hf3fs.mini_3fs_metadata_server.Hf3fsGlobalMetadataClient"><code class="flex name class">
<span>class <span class="ident">Hf3fsGlobalMetadataClient</span></span>
<span>(</span><span>base_url: str, max_retries: int = 3)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class Hf3fsGlobalMetadataClient(Hf3fsMetadataInterface):
    &#34;&#34;&#34;Global http metadata client for HF3FS.&#34;&#34;&#34;

    def __init__(self, base_url: str, max_retries: int = 3):
        self.base_url = base_url.rstrip(&#34;/&#34;)
        self._session = requests.Session()

        retry_strategy = Retry(
            total=max_retries,
            backoff_factor=0.3,
            status_forcelist=[500, 502, 503, 504],
            allowed_methods=[&#34;GET&#34;, &#34;POST&#34;],
        )
        adapter = HTTPAdapter(max_retries=retry_strategy)
        self._session.mount(&#34;http://&#34;, adapter)

    def _post(self, endpoint: str, json_data: dict) -&gt; dict:
        try:
            response = self._session.post(f&#34;{self.base_url}/{endpoint}&#34;, json=json_data)
            response.raise_for_status()
            return response.json()
        except requests.exceptions.RequestException as e:
            logging.error(f&#34;Failed to POST to {endpoint} after retries: {e}&#34;)
            raise RuntimeError(f&#34;Failed to connect to metadata server: {e}&#34;) from e

    def initialize(self, rank: int, num_pages: int) -&gt; None:
        self._post(f&#34;{rank}/initialize&#34;, {&#34;num_pages&#34;: num_pages})

    def reserve_and_allocate_page_indices(
        self, rank: int, keys: List[Tuple[str, str]]
    ) -&gt; List[Tuple[bool, int]]:
        response = self._post(
            f&#34;{rank}/reserve_and_allocate_page_indices&#34;, {&#34;keys&#34;: keys}
        )
        return [tuple(item) for item in response.get(&#34;indices&#34;)]

    def confirm_write(
        self,
        rank: int,
        written_keys_to_confirm: List[Tuple[str, int]],
        pages_to_release: List[int],
    ) -&gt; None:
        self._post(
            f&#34;{rank}/confirm_write&#34;,
            {
                &#34;written_keys_to_confirm&#34;: written_keys_to_confirm,
                &#34;pages_to_release&#34;: pages_to_release,
            },
        )

    def delete_keys(self, rank: int, keys: List[str]) -&gt; None:
        self._post(f&#34;{rank}/delete_keys&#34;, {&#34;keys&#34;: keys})

    def exists(self, rank: int, keys: List[str]) -&gt; List[bool]:
        response = self._post(f&#34;{rank}/exists&#34;, {&#34;keys&#34;: keys})
        return response.get(&#34;exists&#34;, [])

    def clear(self, rank: int) -&gt; None:
        self._post(f&#34;{rank}/clear&#34;, {})

    def get_page_indices(self, rank: int, keys: List[str]) -&gt; List[Optional[int]]:
        response = self._post(f&#34;{rank}/get_page_indices&#34;, {&#34;keys&#34;: keys})
        return response.get(&#34;indices&#34;)</code></pre>
</details>
<div class="desc"><p>Global http metadata client for HF3FS.</p></div>
<h3>Ancestors</h3>
<ul class="hlist">
<li><a title="sglang.srt.mem_cache.storage.hf3fs.storage_hf3fs.Hf3fsMetadataInterface" href="storage_hf3fs.html#sglang.srt.mem_cache.storage.hf3fs.storage_hf3fs.Hf3fsMetadataInterface">Hf3fsMetadataInterface</a></li>
<li>abc.ABC</li>
</ul>
<h3>Inherited members</h3>
<ul class="hlist">
<li><code><b><a title="sglang.srt.mem_cache.storage.hf3fs.storage_hf3fs.Hf3fsMetadataInterface" href="storage_hf3fs.html#sglang.srt.mem_cache.storage.hf3fs.storage_hf3fs.Hf3fsMetadataInterface">Hf3fsMetadataInterface</a></b></code>:
<ul class="hlist">
<li><code><a title="sglang.srt.mem_cache.storage.hf3fs.storage_hf3fs.Hf3fsMetadataInterface.clear" href="storage_hf3fs.html#sglang.srt.mem_cache.storage.hf3fs.storage_hf3fs.Hf3fsMetadataInterface.clear">clear</a></code></li>
<li><code><a title="sglang.srt.mem_cache.storage.hf3fs.storage_hf3fs.Hf3fsMetadataInterface.confirm_write" href="storage_hf3fs.html#sglang.srt.mem_cache.storage.hf3fs.storage_hf3fs.Hf3fsMetadataInterface.confirm_write">confirm_write</a></code></li>
<li><code><a title="sglang.srt.mem_cache.storage.hf3fs.storage_hf3fs.Hf3fsMetadataInterface.delete_keys" href="storage_hf3fs.html#sglang.srt.mem_cache.storage.hf3fs.storage_hf3fs.Hf3fsMetadataInterface.delete_keys">delete_keys</a></code></li>
<li><code><a title="sglang.srt.mem_cache.storage.hf3fs.storage_hf3fs.Hf3fsMetadataInterface.exists" href="storage_hf3fs.html#sglang.srt.mem_cache.storage.hf3fs.storage_hf3fs.Hf3fsMetadataInterface.exists">exists</a></code></li>
<li><code><a title="sglang.srt.mem_cache.storage.hf3fs.storage_hf3fs.Hf3fsMetadataInterface.get_page_indices" href="storage_hf3fs.html#sglang.srt.mem_cache.storage.hf3fs.storage_hf3fs.Hf3fsMetadataInterface.get_page_indices">get_page_indices</a></code></li>
<li><code><a title="sglang.srt.mem_cache.storage.hf3fs.storage_hf3fs.Hf3fsMetadataInterface.initialize" href="storage_hf3fs.html#sglang.srt.mem_cache.storage.hf3fs.storage_hf3fs.Hf3fsMetadataInterface.initialize">initialize</a></code></li>
<li><code><a title="sglang.srt.mem_cache.storage.hf3fs.storage_hf3fs.Hf3fsMetadataInterface.reserve_and_allocate_page_indices" href="storage_hf3fs.html#sglang.srt.mem_cache.storage.hf3fs.storage_hf3fs.Hf3fsMetadataInterface.reserve_and_allocate_page_indices">reserve_and_allocate_page_indices</a></code></li>
</ul>
</li>
</ul>
</dd>
<dt id="sglang.srt.mem_cache.storage.hf3fs.mini_3fs_metadata_server.Hf3fsLocalMetadataClient"><code class="flex name class">
<span>class <span class="ident">Hf3fsLocalMetadataClient</span></span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class Hf3fsLocalMetadataClient(Hf3fsMetadataInterface):
    &#34;&#34;&#34;Local metadata client that directly operates on single RankMetadata in memory without metadata server.&#34;&#34;&#34;

    def __init__(self):
        self.rank_metadata = None

    def initialize(self, rank: int, num_pages: int) -&gt; None:
        self.rank_metadata = RankMetadata(num_pages)

    def reserve_and_allocate_page_indices(
        self, rank: int, keys: List[Tuple[str, str]]
    ) -&gt; List[Tuple[bool, int]]:
        &#34;&#34;&#34;Reserve and allocate page indices for keys.&#34;&#34;&#34;
        return self.rank_metadata.reserve_and_allocate_page_indices(keys)

    def confirm_write(
        self,
        rank: int,
        written_keys_to_confirm: List[Tuple[str, int]],
        pages_to_release: List[int],
    ) -&gt; None:
        &#34;&#34;&#34;Confirm write operations.&#34;&#34;&#34;
        self.rank_metadata.confirm_write(written_keys_to_confirm, pages_to_release)

    def delete_keys(self, rank: int, keys: List[str]) -&gt; None:
        &#34;&#34;&#34;Delete keys.&#34;&#34;&#34;
        self.rank_metadata.delete_keys(keys)

    def exists(self, rank: int, keys: List[str]) -&gt; List[bool]:
        &#34;&#34;&#34;Check if keys exist.&#34;&#34;&#34;
        return self.rank_metadata.exists_keys(keys)

    def clear(self, rank: int) -&gt; None:
        &#34;&#34;&#34;Clear all metadata for rank.&#34;&#34;&#34;
        self.rank_metadata.clear_all()

    def get_page_indices(self, rank: int, keys: List[str]) -&gt; List[Optional[int]]:
        &#34;&#34;&#34;Get page indices for keys.&#34;&#34;&#34;
        return self.rank_metadata.get_page_indices(keys)</code></pre>
</details>
<div class="desc"><p>Local metadata client that directly operates on single RankMetadata in memory without metadata server.</p></div>
<h3>Ancestors</h3>
<ul class="hlist">
<li><a title="sglang.srt.mem_cache.storage.hf3fs.storage_hf3fs.Hf3fsMetadataInterface" href="storage_hf3fs.html#sglang.srt.mem_cache.storage.hf3fs.storage_hf3fs.Hf3fsMetadataInterface">Hf3fsMetadataInterface</a></li>
<li>abc.ABC</li>
</ul>
<h3>Methods</h3>
<dl>
<dt id="sglang.srt.mem_cache.storage.hf3fs.mini_3fs_metadata_server.Hf3fsLocalMetadataClient.clear"><code class="name flex">
<span>def <span class="ident">clear</span></span>(<span>self, rank: int) ‑> None</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def clear(self, rank: int) -&gt; None:
    &#34;&#34;&#34;Clear all metadata for rank.&#34;&#34;&#34;
    self.rank_metadata.clear_all()</code></pre>
</details>
<div class="desc"><p>Clear all metadata for rank.</p></div>
</dd>
<dt id="sglang.srt.mem_cache.storage.hf3fs.mini_3fs_metadata_server.Hf3fsLocalMetadataClient.confirm_write"><code class="name flex">
<span>def <span class="ident">confirm_write</span></span>(<span>self,<br>rank: int,<br>written_keys_to_confirm: List[Tuple[str, int]],<br>pages_to_release: List[int]) ‑> None</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def confirm_write(
    self,
    rank: int,
    written_keys_to_confirm: List[Tuple[str, int]],
    pages_to_release: List[int],
) -&gt; None:
    &#34;&#34;&#34;Confirm write operations.&#34;&#34;&#34;
    self.rank_metadata.confirm_write(written_keys_to_confirm, pages_to_release)</code></pre>
</details>
<div class="desc"><p>Confirm write operations.</p></div>
</dd>
<dt id="sglang.srt.mem_cache.storage.hf3fs.mini_3fs_metadata_server.Hf3fsLocalMetadataClient.delete_keys"><code class="name flex">
<span>def <span class="ident">delete_keys</span></span>(<span>self, rank: int, keys: List[str]) ‑> None</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def delete_keys(self, rank: int, keys: List[str]) -&gt; None:
    &#34;&#34;&#34;Delete keys.&#34;&#34;&#34;
    self.rank_metadata.delete_keys(keys)</code></pre>
</details>
<div class="desc"><p>Delete keys.</p></div>
</dd>
<dt id="sglang.srt.mem_cache.storage.hf3fs.mini_3fs_metadata_server.Hf3fsLocalMetadataClient.exists"><code class="name flex">
<span>def <span class="ident">exists</span></span>(<span>self, rank: int, keys: List[str]) ‑> List[bool]</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def exists(self, rank: int, keys: List[str]) -&gt; List[bool]:
    &#34;&#34;&#34;Check if keys exist.&#34;&#34;&#34;
    return self.rank_metadata.exists_keys(keys)</code></pre>
</details>
<div class="desc"><p>Check if keys exist.</p></div>
</dd>
<dt id="sglang.srt.mem_cache.storage.hf3fs.mini_3fs_metadata_server.Hf3fsLocalMetadataClient.get_page_indices"><code class="name flex">
<span>def <span class="ident">get_page_indices</span></span>(<span>self, rank: int, keys: List[str]) ‑> List[int | None]</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_page_indices(self, rank: int, keys: List[str]) -&gt; List[Optional[int]]:
    &#34;&#34;&#34;Get page indices for keys.&#34;&#34;&#34;
    return self.rank_metadata.get_page_indices(keys)</code></pre>
</details>
<div class="desc"><p>Get page indices for keys.</p></div>
</dd>
<dt id="sglang.srt.mem_cache.storage.hf3fs.mini_3fs_metadata_server.Hf3fsLocalMetadataClient.reserve_and_allocate_page_indices"><code class="name flex">
<span>def <span class="ident">reserve_and_allocate_page_indices</span></span>(<span>self, rank: int, keys: List[Tuple[str, str]]) ‑> List[Tuple[bool, int]]</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def reserve_and_allocate_page_indices(
    self, rank: int, keys: List[Tuple[str, str]]
) -&gt; List[Tuple[bool, int]]:
    &#34;&#34;&#34;Reserve and allocate page indices for keys.&#34;&#34;&#34;
    return self.rank_metadata.reserve_and_allocate_page_indices(keys)</code></pre>
</details>
<div class="desc"><p>Reserve and allocate page indices for keys.</p></div>
</dd>
</dl>
<h3>Inherited members</h3>
<ul class="hlist">
<li><code><b><a title="sglang.srt.mem_cache.storage.hf3fs.storage_hf3fs.Hf3fsMetadataInterface" href="storage_hf3fs.html#sglang.srt.mem_cache.storage.hf3fs.storage_hf3fs.Hf3fsMetadataInterface">Hf3fsMetadataInterface</a></b></code>:
<ul class="hlist">
<li><code><a title="sglang.srt.mem_cache.storage.hf3fs.storage_hf3fs.Hf3fsMetadataInterface.initialize" href="storage_hf3fs.html#sglang.srt.mem_cache.storage.hf3fs.storage_hf3fs.Hf3fsMetadataInterface.initialize">initialize</a></code></li>
</ul>
</li>
</ul>
</dd>
<dt id="sglang.srt.mem_cache.storage.hf3fs.mini_3fs_metadata_server.Hf3fsMetadataServer"><code class="flex name class">
<span>class <span class="ident">Hf3fsMetadataServer</span></span>
<span>(</span><span>persistence_path: str | None = None, save_interval: int = 60)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class Hf3fsMetadataServer:
    &#34;&#34;&#34;HF3FS Metadata Server that manages metadata for multiple ranks.&#34;&#34;&#34;

    def __init__(self, persistence_path: Optional[str] = None, save_interval: int = 60):
        self.state = GlobalMetadataState(persistence_path, save_interval)
        self.app = FastAPI()
        self._setup_routes()

    def _setup_routes(self):
        &#34;&#34;&#34;Setup FastAPI routes.&#34;&#34;&#34;
        self.app.post(&#34;/{rank}/initialize&#34;)(self.initialize)
        self.app.post(&#34;/{rank}/exists&#34;)(self.exists)
        self.app.post(&#34;/{rank}/reserve_and_allocate_page_indices&#34;)(
            self.reserve_and_allocate_page_indices
        )
        self.app.post(&#34;/{rank}/confirm_write&#34;)(self.confirm_write)
        self.app.post(&#34;/{rank}/delete_keys&#34;)(self.delete_keys)
        self.app.post(&#34;/{rank}/clear&#34;)(self.clear)
        self.app.post(&#34;/{rank}/get_page_indices&#34;)(self.get_page_indices)

    def get_rank_metadata(self, rank: int) -&gt; RankMetadata:
        &#34;&#34;&#34;Get rank metadata with proper error handling.&#34;&#34;&#34;
        with self.state.global_lock:
            if rank not in self.state.ranks:
                raise HTTPException(
                    status_code=404,
                    detail=f&#34;Rank {rank} not initialized. Please call /{{rank}}/initialize first.&#34;,
                )
            return self.state.ranks[rank]

    async def initialize(self, rank: int, request: Request):
        &#34;&#34;&#34;Initialize a rank with specified number of pages.&#34;&#34;&#34;
        data = await request.json()
        num_pages = data[&#34;num_pages&#34;]
        with self.state.global_lock:
            if rank in self.state.ranks:
                logging.info(
                    f&#34;Rank {rank} already exists. Initialization request ignored.&#34;
                )
                if self.state.ranks[rank].num_pages != num_pages:
                    logging.warning(
                        f&#34;Rank {rank} initialized with different num_pages. Existing: {self.state.ranks[rank].num_pages}, New: {num_pages}&#34;
                    )
            else:
                logging.info(f&#34;Initializing new Rank {rank} with {num_pages} pages.&#34;)
                self.state.ranks[rank] = RankMetadata(num_pages)
        return {&#34;message&#34;: f&#34;Rank {rank} is ready.&#34;}

    async def exists(self, rank: int, request: Request):
        &#34;&#34;&#34;Check if keys exist in metadata.&#34;&#34;&#34;
        data = await request.json()
        keys = data[&#34;keys&#34;]
        metadata = self.get_rank_metadata(rank)
        results = metadata.exists_keys(keys)
        return {&#34;exists&#34;: results}

    async def reserve_and_allocate_page_indices(self, rank: int, request: Request):
        &#34;&#34;&#34;Reserve and allocate page indices for keys.&#34;&#34;&#34;
        data = await request.json()
        metadata = self.get_rank_metadata(rank)
        keys = data[&#34;keys&#34;]
        results = metadata.reserve_and_allocate_page_indices(keys)
        return {&#34;indices&#34;: results}

    async def confirm_write(self, rank: int, request: Request):
        &#34;&#34;&#34;Confirm write operations and release pages.&#34;&#34;&#34;
        data = await request.json()
        metadata = self.get_rank_metadata(rank)
        success_written_keys = data.get(&#34;written_keys_to_confirm&#34;, [])
        released_pages = data.get(&#34;pages_to_release&#34;, [])

        metadata.confirm_write(success_written_keys, released_pages)

        return {
            &#34;message&#34;: f&#34;Rank {rank}: Write confirmed for {len(success_written_keys)} keys. {len(released_pages)} pages released.&#34;
        }

    async def delete_keys(self, rank: int, request: Request):
        &#34;&#34;&#34;Delete keys from metadata.&#34;&#34;&#34;
        data = await request.json()
        metadata = self.get_rank_metadata(rank)
        count = metadata.delete_keys(data[&#34;keys&#34;])
        return {&#34;message&#34;: f&#34;Rank {rank}: {count} keys deleted.&#34;}

    async def clear(self, rank: int):
        &#34;&#34;&#34;Clear all metadata for a rank.&#34;&#34;&#34;
        metadata = self.get_rank_metadata(rank)
        metadata.clear_all()
        return {&#34;message&#34;: f&#34;Rank {rank}: Metadata cleared.&#34;}

    async def get_page_indices(self, rank: int, request: Request):
        &#34;&#34;&#34;Get page indices for keys.&#34;&#34;&#34;
        data = await request.json()
        metadata = self.get_rank_metadata(rank)
        keys = data[&#34;keys&#34;]
        results = metadata.get_page_indices(keys)
        return {&#34;indices&#34;: results}

    def run(self, host: str = &#34;0.0.0.0&#34;, port: int = 18000):
        &#34;&#34;&#34;Run the metadata server.&#34;&#34;&#34;
        self.state.load_from_disk()
        if self.state.persistence_path:
            self.state.schedule_save()
            atexit.register(self.state.shutdown)

        import uvicorn

        logging.info(f&#34;Starting metadata server on http://{host}:{port}&#34;)
        if self.state.persistence_path:
            logging.info(
                f&#34;Persistence is ENABLED. Saving to &#39;{self.state.persistence_path}&#39; every {self.state.save_interval} seconds.&#34;
            )
        else:
            logging.info(&#34;Persistence is DISABLED.&#34;)

        uvicorn.run(self.app, host=host, port=port)</code></pre>
</details>
<div class="desc"><p>HF3FS Metadata Server that manages metadata for multiple ranks.</p></div>
<h3>Methods</h3>
<dl>
<dt id="sglang.srt.mem_cache.storage.hf3fs.mini_3fs_metadata_server.Hf3fsMetadataServer.clear"><code class="name flex">
<span>async def <span class="ident">clear</span></span>(<span>self, rank: int)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">async def clear(self, rank: int):
    &#34;&#34;&#34;Clear all metadata for a rank.&#34;&#34;&#34;
    metadata = self.get_rank_metadata(rank)
    metadata.clear_all()
    return {&#34;message&#34;: f&#34;Rank {rank}: Metadata cleared.&#34;}</code></pre>
</details>
<div class="desc"><p>Clear all metadata for a rank.</p></div>
</dd>
<dt id="sglang.srt.mem_cache.storage.hf3fs.mini_3fs_metadata_server.Hf3fsMetadataServer.confirm_write"><code class="name flex">
<span>async def <span class="ident">confirm_write</span></span>(<span>self, rank: int, request: starlette.requests.Request)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">async def confirm_write(self, rank: int, request: Request):
    &#34;&#34;&#34;Confirm write operations and release pages.&#34;&#34;&#34;
    data = await request.json()
    metadata = self.get_rank_metadata(rank)
    success_written_keys = data.get(&#34;written_keys_to_confirm&#34;, [])
    released_pages = data.get(&#34;pages_to_release&#34;, [])

    metadata.confirm_write(success_written_keys, released_pages)

    return {
        &#34;message&#34;: f&#34;Rank {rank}: Write confirmed for {len(success_written_keys)} keys. {len(released_pages)} pages released.&#34;
    }</code></pre>
</details>
<div class="desc"><p>Confirm write operations and release pages.</p></div>
</dd>
<dt id="sglang.srt.mem_cache.storage.hf3fs.mini_3fs_metadata_server.Hf3fsMetadataServer.delete_keys"><code class="name flex">
<span>async def <span class="ident">delete_keys</span></span>(<span>self, rank: int, request: starlette.requests.Request)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">async def delete_keys(self, rank: int, request: Request):
    &#34;&#34;&#34;Delete keys from metadata.&#34;&#34;&#34;
    data = await request.json()
    metadata = self.get_rank_metadata(rank)
    count = metadata.delete_keys(data[&#34;keys&#34;])
    return {&#34;message&#34;: f&#34;Rank {rank}: {count} keys deleted.&#34;}</code></pre>
</details>
<div class="desc"><p>Delete keys from metadata.</p></div>
</dd>
<dt id="sglang.srt.mem_cache.storage.hf3fs.mini_3fs_metadata_server.Hf3fsMetadataServer.exists"><code class="name flex">
<span>async def <span class="ident">exists</span></span>(<span>self, rank: int, request: starlette.requests.Request)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">async def exists(self, rank: int, request: Request):
    &#34;&#34;&#34;Check if keys exist in metadata.&#34;&#34;&#34;
    data = await request.json()
    keys = data[&#34;keys&#34;]
    metadata = self.get_rank_metadata(rank)
    results = metadata.exists_keys(keys)
    return {&#34;exists&#34;: results}</code></pre>
</details>
<div class="desc"><p>Check if keys exist in metadata.</p></div>
</dd>
<dt id="sglang.srt.mem_cache.storage.hf3fs.mini_3fs_metadata_server.Hf3fsMetadataServer.get_page_indices"><code class="name flex">
<span>async def <span class="ident">get_page_indices</span></span>(<span>self, rank: int, request: starlette.requests.Request)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">async def get_page_indices(self, rank: int, request: Request):
    &#34;&#34;&#34;Get page indices for keys.&#34;&#34;&#34;
    data = await request.json()
    metadata = self.get_rank_metadata(rank)
    keys = data[&#34;keys&#34;]
    results = metadata.get_page_indices(keys)
    return {&#34;indices&#34;: results}</code></pre>
</details>
<div class="desc"><p>Get page indices for keys.</p></div>
</dd>
<dt id="sglang.srt.mem_cache.storage.hf3fs.mini_3fs_metadata_server.Hf3fsMetadataServer.get_rank_metadata"><code class="name flex">
<span>def <span class="ident">get_rank_metadata</span></span>(<span>self, rank: int) ‑> <a title="sglang.srt.mem_cache.storage.hf3fs.mini_3fs_metadata_server.RankMetadata" href="#sglang.srt.mem_cache.storage.hf3fs.mini_3fs_metadata_server.RankMetadata">RankMetadata</a></span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_rank_metadata(self, rank: int) -&gt; RankMetadata:
    &#34;&#34;&#34;Get rank metadata with proper error handling.&#34;&#34;&#34;
    with self.state.global_lock:
        if rank not in self.state.ranks:
            raise HTTPException(
                status_code=404,
                detail=f&#34;Rank {rank} not initialized. Please call /{{rank}}/initialize first.&#34;,
            )
        return self.state.ranks[rank]</code></pre>
</details>
<div class="desc"><p>Get rank metadata with proper error handling.</p></div>
</dd>
<dt id="sglang.srt.mem_cache.storage.hf3fs.mini_3fs_metadata_server.Hf3fsMetadataServer.initialize"><code class="name flex">
<span>async def <span class="ident">initialize</span></span>(<span>self, rank: int, request: starlette.requests.Request)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">async def initialize(self, rank: int, request: Request):
    &#34;&#34;&#34;Initialize a rank with specified number of pages.&#34;&#34;&#34;
    data = await request.json()
    num_pages = data[&#34;num_pages&#34;]
    with self.state.global_lock:
        if rank in self.state.ranks:
            logging.info(
                f&#34;Rank {rank} already exists. Initialization request ignored.&#34;
            )
            if self.state.ranks[rank].num_pages != num_pages:
                logging.warning(
                    f&#34;Rank {rank} initialized with different num_pages. Existing: {self.state.ranks[rank].num_pages}, New: {num_pages}&#34;
                )
        else:
            logging.info(f&#34;Initializing new Rank {rank} with {num_pages} pages.&#34;)
            self.state.ranks[rank] = RankMetadata(num_pages)
    return {&#34;message&#34;: f&#34;Rank {rank} is ready.&#34;}</code></pre>
</details>
<div class="desc"><p>Initialize a rank with specified number of pages.</p></div>
</dd>
<dt id="sglang.srt.mem_cache.storage.hf3fs.mini_3fs_metadata_server.Hf3fsMetadataServer.reserve_and_allocate_page_indices"><code class="name flex">
<span>async def <span class="ident">reserve_and_allocate_page_indices</span></span>(<span>self, rank: int, request: starlette.requests.Request)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">async def reserve_and_allocate_page_indices(self, rank: int, request: Request):
    &#34;&#34;&#34;Reserve and allocate page indices for keys.&#34;&#34;&#34;
    data = await request.json()
    metadata = self.get_rank_metadata(rank)
    keys = data[&#34;keys&#34;]
    results = metadata.reserve_and_allocate_page_indices(keys)
    return {&#34;indices&#34;: results}</code></pre>
</details>
<div class="desc"><p>Reserve and allocate page indices for keys.</p></div>
</dd>
<dt id="sglang.srt.mem_cache.storage.hf3fs.mini_3fs_metadata_server.Hf3fsMetadataServer.run"><code class="name flex">
<span>def <span class="ident">run</span></span>(<span>self, host: str = '0.0.0.0', port: int = 18000)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def run(self, host: str = &#34;0.0.0.0&#34;, port: int = 18000):
    &#34;&#34;&#34;Run the metadata server.&#34;&#34;&#34;
    self.state.load_from_disk()
    if self.state.persistence_path:
        self.state.schedule_save()
        atexit.register(self.state.shutdown)

    import uvicorn

    logging.info(f&#34;Starting metadata server on http://{host}:{port}&#34;)
    if self.state.persistence_path:
        logging.info(
            f&#34;Persistence is ENABLED. Saving to &#39;{self.state.persistence_path}&#39; every {self.state.save_interval} seconds.&#34;
        )
    else:
        logging.info(&#34;Persistence is DISABLED.&#34;)

    uvicorn.run(self.app, host=host, port=port)</code></pre>
</details>
<div class="desc"><p>Run the metadata server.</p></div>
</dd>
</dl>
</dd>
<dt id="sglang.srt.mem_cache.storage.hf3fs.mini_3fs_metadata_server.RankMetadata"><code class="flex name class">
<span>class <span class="ident">RankMetadata</span></span>
<span>(</span><span>num_pages: int)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class RankMetadata:
    &#34;&#34;&#34;Holds all metadata for a single rank.&#34;&#34;&#34;

    def __init__(self, num_pages: int):
        self.lock = threading.RLock()
        self.num_pages = num_pages
        self.free_pages: List[int] = list(range(num_pages))
        self.key_to_index: Dict[str, int] = {}
        # Todo: Support multi files for HF3FS

    def exists_keys(self, keys: List[str]) -&gt; List[bool]:
        &#34;&#34;&#34;Check if keys exist in metadata.&#34;&#34;&#34;
        with self.lock:
            return [key in self.key_to_index for key in keys]

    def reserve_and_allocate_page_indices(
        self, keys: List[Tuple[str, str]]
    ) -&gt; List[Tuple[bool, int]]:
        &#34;&#34;&#34;Reserve and allocate page indices for keys.&#34;&#34;&#34;
        with self.lock:
            results = [None] * len(keys)
            new_keys_to_process = []

            for i, (key, prefix_key) in enumerate(keys):
                if key in self.key_to_index:
                    results[i] = (True, self.key_to_index[key])
                else:
                    new_keys_to_process.append((i, key, prefix_key))

            # Todo: Implementing data eviction logic after HiCache supports prefix information pass-through
            for i, key, prefix_key in new_keys_to_process:
                if len(self.free_pages) &gt; 0:
                    page_idx = self.free_pages.pop()
                    results[i] = (False, page_idx)
                else:
                    results[i] = (False, -1)

            return results

    def confirm_write(
        self,
        written_keys_to_confirm: List[Tuple[str, int]],
        pages_to_release: List[int],
    ) -&gt; None:
        &#34;&#34;&#34;Confirm write operations and release pages.&#34;&#34;&#34;
        with self.lock:
            for key, page_index in written_keys_to_confirm:
                self.key_to_index[key] = page_index

            for page_index in pages_to_release:
                if page_index not in self.free_pages:
                    self.free_pages.append(page_index)

    def delete_keys(self, keys: List[str]) -&gt; int:
        &#34;&#34;&#34;Delete keys and return count of deleted keys.&#34;&#34;&#34;
        with self.lock:
            count = 0
            for key in keys:
                if key in self.key_to_index:
                    page_index = self.key_to_index.pop(key)
                    if page_index not in self.free_pages:
                        self.free_pages.append(page_index)
                    count += 1
            return count

    def clear_all(self) -&gt; None:
        &#34;&#34;&#34;Clear all metadata.&#34;&#34;&#34;
        with self.lock:
            self.free_pages = list(range(self.num_pages))
            self.key_to_index.clear()

    def get_page_indices(self, keys: List[str]) -&gt; List[Optional[int]]:
        &#34;&#34;&#34;Get page indices for keys.&#34;&#34;&#34;
        with self.lock:
            return [self.key_to_index.get(key) for key in keys]</code></pre>
</details>
<div class="desc"><p>Holds all metadata for a single rank.</p></div>
<h3>Methods</h3>
<dl>
<dt id="sglang.srt.mem_cache.storage.hf3fs.mini_3fs_metadata_server.RankMetadata.clear_all"><code class="name flex">
<span>def <span class="ident">clear_all</span></span>(<span>self) ‑> None</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def clear_all(self) -&gt; None:
    &#34;&#34;&#34;Clear all metadata.&#34;&#34;&#34;
    with self.lock:
        self.free_pages = list(range(self.num_pages))
        self.key_to_index.clear()</code></pre>
</details>
<div class="desc"><p>Clear all metadata.</p></div>
</dd>
<dt id="sglang.srt.mem_cache.storage.hf3fs.mini_3fs_metadata_server.RankMetadata.confirm_write"><code class="name flex">
<span>def <span class="ident">confirm_write</span></span>(<span>self,<br>written_keys_to_confirm: List[Tuple[str, int]],<br>pages_to_release: List[int]) ‑> None</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def confirm_write(
    self,
    written_keys_to_confirm: List[Tuple[str, int]],
    pages_to_release: List[int],
) -&gt; None:
    &#34;&#34;&#34;Confirm write operations and release pages.&#34;&#34;&#34;
    with self.lock:
        for key, page_index in written_keys_to_confirm:
            self.key_to_index[key] = page_index

        for page_index in pages_to_release:
            if page_index not in self.free_pages:
                self.free_pages.append(page_index)</code></pre>
</details>
<div class="desc"><p>Confirm write operations and release pages.</p></div>
</dd>
<dt id="sglang.srt.mem_cache.storage.hf3fs.mini_3fs_metadata_server.RankMetadata.delete_keys"><code class="name flex">
<span>def <span class="ident">delete_keys</span></span>(<span>self, keys: List[str]) ‑> int</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def delete_keys(self, keys: List[str]) -&gt; int:
    &#34;&#34;&#34;Delete keys and return count of deleted keys.&#34;&#34;&#34;
    with self.lock:
        count = 0
        for key in keys:
            if key in self.key_to_index:
                page_index = self.key_to_index.pop(key)
                if page_index not in self.free_pages:
                    self.free_pages.append(page_index)
                count += 1
        return count</code></pre>
</details>
<div class="desc"><p>Delete keys and return count of deleted keys.</p></div>
</dd>
<dt id="sglang.srt.mem_cache.storage.hf3fs.mini_3fs_metadata_server.RankMetadata.exists_keys"><code class="name flex">
<span>def <span class="ident">exists_keys</span></span>(<span>self, keys: List[str]) ‑> List[bool]</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def exists_keys(self, keys: List[str]) -&gt; List[bool]:
    &#34;&#34;&#34;Check if keys exist in metadata.&#34;&#34;&#34;
    with self.lock:
        return [key in self.key_to_index for key in keys]</code></pre>
</details>
<div class="desc"><p>Check if keys exist in metadata.</p></div>
</dd>
<dt id="sglang.srt.mem_cache.storage.hf3fs.mini_3fs_metadata_server.RankMetadata.get_page_indices"><code class="name flex">
<span>def <span class="ident">get_page_indices</span></span>(<span>self, keys: List[str]) ‑> List[int | None]</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_page_indices(self, keys: List[str]) -&gt; List[Optional[int]]:
    &#34;&#34;&#34;Get page indices for keys.&#34;&#34;&#34;
    with self.lock:
        return [self.key_to_index.get(key) for key in keys]</code></pre>
</details>
<div class="desc"><p>Get page indices for keys.</p></div>
</dd>
<dt id="sglang.srt.mem_cache.storage.hf3fs.mini_3fs_metadata_server.RankMetadata.reserve_and_allocate_page_indices"><code class="name flex">
<span>def <span class="ident">reserve_and_allocate_page_indices</span></span>(<span>self, keys: List[Tuple[str, str]]) ‑> List[Tuple[bool, int]]</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def reserve_and_allocate_page_indices(
    self, keys: List[Tuple[str, str]]
) -&gt; List[Tuple[bool, int]]:
    &#34;&#34;&#34;Reserve and allocate page indices for keys.&#34;&#34;&#34;
    with self.lock:
        results = [None] * len(keys)
        new_keys_to_process = []

        for i, (key, prefix_key) in enumerate(keys):
            if key in self.key_to_index:
                results[i] = (True, self.key_to_index[key])
            else:
                new_keys_to_process.append((i, key, prefix_key))

        # Todo: Implementing data eviction logic after HiCache supports prefix information pass-through
        for i, key, prefix_key in new_keys_to_process:
            if len(self.free_pages) &gt; 0:
                page_idx = self.free_pages.pop()
                results[i] = (False, page_idx)
            else:
                results[i] = (False, -1)

        return results</code></pre>
</details>
<div class="desc"><p>Reserve and allocate page indices for keys.</p></div>
</dd>
</dl>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="sglang.srt.mem_cache.storage.hf3fs" href="index.html">sglang.srt.mem_cache.storage.hf3fs</a></code></li>
</ul>
</li>
<li><h3><a href="#header-functions">Functions</a></h3>
<ul class="">
<li><code><a title="sglang.srt.mem_cache.storage.hf3fs.mini_3fs_metadata_server.run_metadata_server" href="#sglang.srt.mem_cache.storage.hf3fs.mini_3fs_metadata_server.run_metadata_server">run_metadata_server</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="sglang.srt.mem_cache.storage.hf3fs.mini_3fs_metadata_server.GlobalMetadataState" href="#sglang.srt.mem_cache.storage.hf3fs.mini_3fs_metadata_server.GlobalMetadataState">GlobalMetadataState</a></code></h4>
<ul class="">
<li><code><a title="sglang.srt.mem_cache.storage.hf3fs.mini_3fs_metadata_server.GlobalMetadataState.load_from_disk" href="#sglang.srt.mem_cache.storage.hf3fs.mini_3fs_metadata_server.GlobalMetadataState.load_from_disk">load_from_disk</a></code></li>
<li><code><a title="sglang.srt.mem_cache.storage.hf3fs.mini_3fs_metadata_server.GlobalMetadataState.save_to_disk" href="#sglang.srt.mem_cache.storage.hf3fs.mini_3fs_metadata_server.GlobalMetadataState.save_to_disk">save_to_disk</a></code></li>
<li><code><a title="sglang.srt.mem_cache.storage.hf3fs.mini_3fs_metadata_server.GlobalMetadataState.schedule_save" href="#sglang.srt.mem_cache.storage.hf3fs.mini_3fs_metadata_server.GlobalMetadataState.schedule_save">schedule_save</a></code></li>
<li><code><a title="sglang.srt.mem_cache.storage.hf3fs.mini_3fs_metadata_server.GlobalMetadataState.shutdown" href="#sglang.srt.mem_cache.storage.hf3fs.mini_3fs_metadata_server.GlobalMetadataState.shutdown">shutdown</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="sglang.srt.mem_cache.storage.hf3fs.mini_3fs_metadata_server.Hf3fsGlobalMetadataClient" href="#sglang.srt.mem_cache.storage.hf3fs.mini_3fs_metadata_server.Hf3fsGlobalMetadataClient">Hf3fsGlobalMetadataClient</a></code></h4>
</li>
<li>
<h4><code><a title="sglang.srt.mem_cache.storage.hf3fs.mini_3fs_metadata_server.Hf3fsLocalMetadataClient" href="#sglang.srt.mem_cache.storage.hf3fs.mini_3fs_metadata_server.Hf3fsLocalMetadataClient">Hf3fsLocalMetadataClient</a></code></h4>
<ul class="">
<li><code><a title="sglang.srt.mem_cache.storage.hf3fs.mini_3fs_metadata_server.Hf3fsLocalMetadataClient.clear" href="#sglang.srt.mem_cache.storage.hf3fs.mini_3fs_metadata_server.Hf3fsLocalMetadataClient.clear">clear</a></code></li>
<li><code><a title="sglang.srt.mem_cache.storage.hf3fs.mini_3fs_metadata_server.Hf3fsLocalMetadataClient.confirm_write" href="#sglang.srt.mem_cache.storage.hf3fs.mini_3fs_metadata_server.Hf3fsLocalMetadataClient.confirm_write">confirm_write</a></code></li>
<li><code><a title="sglang.srt.mem_cache.storage.hf3fs.mini_3fs_metadata_server.Hf3fsLocalMetadataClient.delete_keys" href="#sglang.srt.mem_cache.storage.hf3fs.mini_3fs_metadata_server.Hf3fsLocalMetadataClient.delete_keys">delete_keys</a></code></li>
<li><code><a title="sglang.srt.mem_cache.storage.hf3fs.mini_3fs_metadata_server.Hf3fsLocalMetadataClient.exists" href="#sglang.srt.mem_cache.storage.hf3fs.mini_3fs_metadata_server.Hf3fsLocalMetadataClient.exists">exists</a></code></li>
<li><code><a title="sglang.srt.mem_cache.storage.hf3fs.mini_3fs_metadata_server.Hf3fsLocalMetadataClient.get_page_indices" href="#sglang.srt.mem_cache.storage.hf3fs.mini_3fs_metadata_server.Hf3fsLocalMetadataClient.get_page_indices">get_page_indices</a></code></li>
<li><code><a title="sglang.srt.mem_cache.storage.hf3fs.mini_3fs_metadata_server.Hf3fsLocalMetadataClient.reserve_and_allocate_page_indices" href="#sglang.srt.mem_cache.storage.hf3fs.mini_3fs_metadata_server.Hf3fsLocalMetadataClient.reserve_and_allocate_page_indices">reserve_and_allocate_page_indices</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="sglang.srt.mem_cache.storage.hf3fs.mini_3fs_metadata_server.Hf3fsMetadataServer" href="#sglang.srt.mem_cache.storage.hf3fs.mini_3fs_metadata_server.Hf3fsMetadataServer">Hf3fsMetadataServer</a></code></h4>
<ul class="">
<li><code><a title="sglang.srt.mem_cache.storage.hf3fs.mini_3fs_metadata_server.Hf3fsMetadataServer.clear" href="#sglang.srt.mem_cache.storage.hf3fs.mini_3fs_metadata_server.Hf3fsMetadataServer.clear">clear</a></code></li>
<li><code><a title="sglang.srt.mem_cache.storage.hf3fs.mini_3fs_metadata_server.Hf3fsMetadataServer.confirm_write" href="#sglang.srt.mem_cache.storage.hf3fs.mini_3fs_metadata_server.Hf3fsMetadataServer.confirm_write">confirm_write</a></code></li>
<li><code><a title="sglang.srt.mem_cache.storage.hf3fs.mini_3fs_metadata_server.Hf3fsMetadataServer.delete_keys" href="#sglang.srt.mem_cache.storage.hf3fs.mini_3fs_metadata_server.Hf3fsMetadataServer.delete_keys">delete_keys</a></code></li>
<li><code><a title="sglang.srt.mem_cache.storage.hf3fs.mini_3fs_metadata_server.Hf3fsMetadataServer.exists" href="#sglang.srt.mem_cache.storage.hf3fs.mini_3fs_metadata_server.Hf3fsMetadataServer.exists">exists</a></code></li>
<li><code><a title="sglang.srt.mem_cache.storage.hf3fs.mini_3fs_metadata_server.Hf3fsMetadataServer.get_page_indices" href="#sglang.srt.mem_cache.storage.hf3fs.mini_3fs_metadata_server.Hf3fsMetadataServer.get_page_indices">get_page_indices</a></code></li>
<li><code><a title="sglang.srt.mem_cache.storage.hf3fs.mini_3fs_metadata_server.Hf3fsMetadataServer.get_rank_metadata" href="#sglang.srt.mem_cache.storage.hf3fs.mini_3fs_metadata_server.Hf3fsMetadataServer.get_rank_metadata">get_rank_metadata</a></code></li>
<li><code><a title="sglang.srt.mem_cache.storage.hf3fs.mini_3fs_metadata_server.Hf3fsMetadataServer.initialize" href="#sglang.srt.mem_cache.storage.hf3fs.mini_3fs_metadata_server.Hf3fsMetadataServer.initialize">initialize</a></code></li>
<li><code><a title="sglang.srt.mem_cache.storage.hf3fs.mini_3fs_metadata_server.Hf3fsMetadataServer.reserve_and_allocate_page_indices" href="#sglang.srt.mem_cache.storage.hf3fs.mini_3fs_metadata_server.Hf3fsMetadataServer.reserve_and_allocate_page_indices">reserve_and_allocate_page_indices</a></code></li>
<li><code><a title="sglang.srt.mem_cache.storage.hf3fs.mini_3fs_metadata_server.Hf3fsMetadataServer.run" href="#sglang.srt.mem_cache.storage.hf3fs.mini_3fs_metadata_server.Hf3fsMetadataServer.run">run</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="sglang.srt.mem_cache.storage.hf3fs.mini_3fs_metadata_server.RankMetadata" href="#sglang.srt.mem_cache.storage.hf3fs.mini_3fs_metadata_server.RankMetadata">RankMetadata</a></code></h4>
<ul class="">
<li><code><a title="sglang.srt.mem_cache.storage.hf3fs.mini_3fs_metadata_server.RankMetadata.clear_all" href="#sglang.srt.mem_cache.storage.hf3fs.mini_3fs_metadata_server.RankMetadata.clear_all">clear_all</a></code></li>
<li><code><a title="sglang.srt.mem_cache.storage.hf3fs.mini_3fs_metadata_server.RankMetadata.confirm_write" href="#sglang.srt.mem_cache.storage.hf3fs.mini_3fs_metadata_server.RankMetadata.confirm_write">confirm_write</a></code></li>
<li><code><a title="sglang.srt.mem_cache.storage.hf3fs.mini_3fs_metadata_server.RankMetadata.delete_keys" href="#sglang.srt.mem_cache.storage.hf3fs.mini_3fs_metadata_server.RankMetadata.delete_keys">delete_keys</a></code></li>
<li><code><a title="sglang.srt.mem_cache.storage.hf3fs.mini_3fs_metadata_server.RankMetadata.exists_keys" href="#sglang.srt.mem_cache.storage.hf3fs.mini_3fs_metadata_server.RankMetadata.exists_keys">exists_keys</a></code></li>
<li><code><a title="sglang.srt.mem_cache.storage.hf3fs.mini_3fs_metadata_server.RankMetadata.get_page_indices" href="#sglang.srt.mem_cache.storage.hf3fs.mini_3fs_metadata_server.RankMetadata.get_page_indices">get_page_indices</a></code></li>
<li><code><a title="sglang.srt.mem_cache.storage.hf3fs.mini_3fs_metadata_server.RankMetadata.reserve_and_allocate_page_indices" href="#sglang.srt.mem_cache.storage.hf3fs.mini_3fs_metadata_server.RankMetadata.reserve_and_allocate_page_indices">reserve_and_allocate_page_indices</a></code></li>
</ul>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc" title="pdoc: Python API documentation generator"><cite>pdoc</cite> 0.11.6</a>.</p>
</footer>
</body>
</html>
