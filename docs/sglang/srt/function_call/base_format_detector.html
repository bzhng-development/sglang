<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1">
<meta name="generator" content="pdoc3 0.11.6">
<title>sglang.srt.function_call.base_format_detector API documentation</title>
<meta name="description" content="">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/13.0.0/sanitize.min.css" integrity="sha512-y1dtMcuvtTMJc1yPgEqF0ZjQbhnc/bFhyvIyVNb9Zk5mIGtqVaAB1Ttl28su8AvFMOY0EwRbAe+HCLqj6W7/KA==" crossorigin>
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/13.0.0/typography.min.css" integrity="sha512-Y1DYSb995BAfxobCkKepB1BqJJTPrOp3zPL74AWFugHHmmdcvO+C48WLrUOlhGMc0QG7AE3f7gmvvcrmX2fDoA==" crossorigin>
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/styles/default.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:1.5em;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:2em 0 .50em 0}h3{font-size:1.4em;margin:1.6em 0 .7em 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .2s ease-in-out}a:visited{color:#503}a:hover{color:#b62}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900;font-weight:bold}pre code{font-size:.8em;line-height:1.4em;padding:1em;display:block}code{background:#f3f3f3;font-family:"DejaVu Sans Mono",monospace;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source > summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible;min-width:max-content}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em 1em;margin:1em 0}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul ul{padding-left:1em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/highlight.min.js" integrity="sha512-D9gUyxqja7hBtkWpPWGt9wfbfaMGVt9gnyCvYa+jojwwPHLCzUm5i8rpk7vD7wNee9bA35eYIjobYPaQuKS1MQ==" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => {
hljs.configure({languages: ['bash', 'css', 'diff', 'graphql', 'ini', 'javascript', 'json', 'plaintext', 'python', 'python-repl', 'rust', 'shell', 'sql', 'typescript', 'xml', 'yaml']});
hljs.highlightAll();
/* Collapse source docstrings */
setTimeout(() => {
[...document.querySelectorAll('.hljs.language-python > .hljs-string')]
.filter(el => el.innerHTML.length > 200 && ['"""', "'''"].includes(el.innerHTML.substring(0, 3)))
.forEach(el => {
let d = document.createElement('details');
d.classList.add('hljs-string');
d.innerHTML = '<summary>"""</summary>' + el.innerHTML.substring(3);
el.replaceWith(d);
});
}, 100);
})</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>sglang.srt.function_call.base_format_detector</code></h1>
</header>
<section id="section-intro">
</section>
<section>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="sglang.srt.function_call.base_format_detector.BaseFormatDetector"><code class="flex name class">
<span>class <span class="ident">BaseFormatDetector</span></span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class BaseFormatDetector(ABC):
    &#34;&#34;&#34;Base class providing two sets of interfaces: one-time and streaming incremental.&#34;&#34;&#34;

    def __init__(self):
        # Streaming state management
        # Buffer for accumulating incomplete patterns that arrive across multiple streaming chunks
        self._buffer = &#34;&#34;
        # Stores complete tool call info (name and arguments) for each tool being parsed.
        # Used by serving layer for completion handling when streaming ends.
        # Format: [{&#34;name&#34;: str, &#34;arguments&#34;: dict}, ...]
        self.prev_tool_call_arr: List[Dict] = []
        # Index of currently streaming tool call. Starts at -1 (no active tool),
        # increments as each tool completes. Tracks which tool&#39;s arguments are streaming.
        self.current_tool_id: int = -1
        # Flag for whether current tool&#39;s name has been sent to client.
        # Tool names sent first with empty parameters, then arguments stream incrementally.
        self.current_tool_name_sent: bool = False
        # Tracks raw JSON string content streamed to client for each tool&#39;s arguments.
        # Critical for serving layer to calculate remaining content when streaming ends.
        # Each index corresponds to a tool_id. Example: [&#39;{&#34;location&#34;: &#34;San Francisco&#34;&#39;, &#39;{&#34;temp&#34;: 72&#39;]
        self.streamed_args_for_tool: List[str] = []

        # Token configuration (override in subclasses)
        self.bot_token = &#34;&#34;
        self.eot_token = &#34;&#34;
        self.tool_call_separator = &#34;, &#34;

    def _get_tool_indices(self, tools: List[Tool]) -&gt; Dict[str, int]:
        &#34;&#34;&#34;
        Get a mapping of tool names to their indices in the tools list.

        This utility method creates a dictionary mapping function names to their
        indices in the tools list, which is commonly needed for tool validation
        and ToolCallItem creation.

        Args:
            tools: List of available tools

        Returns:
            Dictionary mapping tool names to their indices
        &#34;&#34;&#34;
        return {
            tool.function.name: i for i, tool in enumerate(tools) if tool.function.name
        }

    def parse_base_json(self, action: Any, tools: List[Tool]) -&gt; List[ToolCallItem]:
        tool_indices = self._get_tool_indices(tools)
        if not isinstance(action, list):
            action = [action]

        results = []
        for act in action:
            name = act.get(&#34;name&#34;)
            if name and name in tool_indices:
                results.append(
                    ToolCallItem(
                        tool_index=-1,  # Caller should update this based on the actual tools array called
                        name=name,
                        parameters=json.dumps(
                            act.get(&#34;parameters&#34;) or act.get(&#34;arguments&#34;, {}),
                            ensure_ascii=False,
                        ),
                    )
                )
            else:
                logger.warning(f&#34;Model attempted to call undefined function: {name}&#34;)

        return results

    @abstractmethod
    def detect_and_parse(self, text: str, tools: List[Tool]) -&gt; StreamingParseResult:
        &#34;&#34;&#34;
        Parses the text in one go. Returns success=True if the format matches, otherwise False.
        Note that leftover_text here represents &#34;content that this parser will not consume further&#34;.
        &#34;&#34;&#34;
        action = json.loads(text)
        return StreamingParseResult(calls=self.parse_base_json(action, tools))

    def _ends_with_partial_token(self, buffer: str, bot_token: str) -&gt; int:
        &#34;&#34;&#34;
        Check if buffer ends with a partial bot_token.
        Return the length of the partial bot_token.

        For some format, the bot_token is not a token in model&#39;s vocabulary, such as
        `[TOOL_CALLS] [` in Mistral.
        &#34;&#34;&#34;
        for i in range(1, min(len(buffer) + 1, len(bot_token))):
            if bot_token.startswith(buffer[-i:]):
                return i
        return 0

    def parse_streaming_increment(
        self, new_text: str, tools: List[Tool]
    ) -&gt; StreamingParseResult:
        &#34;&#34;&#34;
        Streaming incremental parsing with tool validation.

        This base implementation works best with formats where:
        1. bot_token is followed immediately by JSON (e.g., bot_token + JSON_array)
        2. JSON can be parsed incrementally using partial_json_loads
        3. Multiple tool calls are separated by &#34;; &#34; or &#34;, &#34;

        Examples of incompatible formats (need custom implementation, may reuse some logic from this class):
        - Each tool call is wrapped in a separate block: See Qwen25Detector
        - Multiple separate blocks: [TOOL_CALLS] [...] \n [TOOL_CALLS] [...]
        - Tool call is Pythonic style

        For incompatible formats, detectors should override this method with custom logic.
        &#34;&#34;&#34;
        # Append new text to buffer
        self._buffer += new_text
        current_text = self._buffer

        # The current_text has tool_call if it is the start of a new tool call sequence
        # or it is the start of a new tool call after a tool call separator, when there is a previous tool call
        if not (
            self.has_tool_call(current_text)
            or (
                self.current_tool_id &gt; 0
                and current_text.startswith(self.tool_call_separator)
            )
        ):
            # Only clear buffer if we&#39;re sure no tool call is starting
            if not self._ends_with_partial_token(self._buffer, self.bot_token):
                normal_text = self._buffer
                self._buffer = &#34;&#34;
                if self.eot_token in normal_text:
                    normal_text = normal_text.replace(self.eot_token, &#34;&#34;)
                return StreamingParseResult(normal_text=normal_text)
            else:
                # Might be partial bot_token, keep buffering
                return StreamingParseResult()

        # Build tool indices if not already built
        if not hasattr(self, &#34;_tool_indices&#34;):
            self._tool_indices = self._get_tool_indices(tools)

        flags = Allow.ALL if self.current_tool_name_sent else Allow.ALL &amp; ~Allow.STR

        try:
            try:
                if current_text.startswith(self.bot_token):
                    start_idx = len(self.bot_token)
                elif self.current_tool_id &gt; 0 and current_text.startswith(
                    self.tool_call_separator + self.bot_token
                ):
                    start_idx = len(self.tool_call_separator + self.bot_token)
                elif self.current_tool_id &gt; 0 and current_text.startswith(
                    self.tool_call_separator
                ):
                    start_idx = len(self.tool_call_separator)
                else:
                    start_idx = 0

                if start_idx &gt;= len(current_text):
                    return StreamingParseResult()

                (obj, end_idx) = _partial_json_loads(current_text[start_idx:], flags)

                is_current_complete = _is_complete_json(
                    current_text[start_idx : start_idx + end_idx]
                )

                # Validate tool name if present
                if &#34;name&#34; in obj and obj[&#34;name&#34;] not in self._tool_indices:
                    # Invalid tool name - reset state
                    self._buffer = &#34;&#34;
                    self.current_tool_id = -1
                    self.current_tool_name_sent = False
                    if self.streamed_args_for_tool:
                        self.streamed_args_for_tool.pop()
                    return StreamingParseResult()

                # Handle parameters/arguments consistency
                # NOTE: we assume here that the obj is always partial of a single tool call
                if &#34;parameters&#34; in obj:
                    assert (
                        &#34;arguments&#34; not in obj
                    ), &#34;model generated both parameters and arguments&#34;
                    obj[&#34;arguments&#34;] = obj[&#34;parameters&#34;]

                current_tool_call = obj

            except MalformedJSON:
                return StreamingParseResult()

            if not current_tool_call:
                return StreamingParseResult()

            # Case 1: Handle tool name streaming
            # This happens when we encounter a tool but haven&#39;t sent its name yet
            if not self.current_tool_name_sent:
                function_name = current_tool_call.get(&#34;name&#34;)

                if function_name and function_name in self._tool_indices:
                    # If this is a new tool (current_tool_id was -1), initialize it
                    if self.current_tool_id == -1:
                        self.current_tool_id = 0
                        self.streamed_args_for_tool.append(&#34;&#34;)
                    # If this is a subsequent tool, ensure streamed_args_for_tool is large enough
                    elif self.current_tool_id &gt;= len(self.streamed_args_for_tool):
                        while len(self.streamed_args_for_tool) &lt;= self.current_tool_id:
                            self.streamed_args_for_tool.append(&#34;&#34;)

                    # Send the tool name with empty parameters
                    res = StreamingParseResult(
                        calls=[
                            ToolCallItem(
                                tool_index=self.current_tool_id,
                                name=function_name,
                                parameters=&#34;&#34;,
                            )
                        ],
                    )
                    self.current_tool_name_sent = True
                else:
                    res = StreamingParseResult()

            # Case 2: Handle streaming arguments
            # This happens when we&#39;ve already sent the tool name and now need to stream arguments incrementally
            else:
                cur_arguments = current_tool_call.get(&#34;arguments&#34;)
                res = StreamingParseResult()

                if cur_arguments:
                    # Calculate how much of the arguments we&#39;ve already streamed
                    sent = len(self.streamed_args_for_tool[self.current_tool_id])
                    cur_args_json = json.dumps(cur_arguments)
                    prev_arguments = None
                    if self.current_tool_id &lt; len(self.prev_tool_call_arr):
                        prev_arguments = self.prev_tool_call_arr[
                            self.current_tool_id
                        ].get(&#34;arguments&#34;)

                    argument_diff = None

                    # If the current tool&#39;s JSON is complete, send all remaining arguments
                    if is_current_complete:
                        argument_diff = cur_args_json[sent:]
                        completing_tool_id = (
                            self.current_tool_id
                        )  # Save the ID of the tool that&#39;s completing

                        # Only remove the processed portion, keep unprocessed content
                        self._buffer = current_text[start_idx + end_idx :]

                        if self.current_tool_id &lt; len(self.prev_tool_call_arr):
                            self.prev_tool_call_arr[self.current_tool_id].clear()
                        self.current_tool_name_sent = False
                        self.streamed_args_for_tool[self.current_tool_id] = &#34;&#34;
                        self.current_tool_id += 1

                    # If the tool is still being parsed, send incremental changes
                    elif prev_arguments:
                        prev_args_json = json.dumps(prev_arguments)
                        if cur_args_json != prev_args_json:
                            prefix = _find_common_prefix(prev_args_json, cur_args_json)
                            argument_diff = prefix[sent:]

                    # Send the argument diff if there&#39;s something new
                    if argument_diff is not None:
                        # Use the correct tool_index: completing_tool_id for completed tools, current_tool_id for ongoing
                        tool_index_to_use = (
                            completing_tool_id
                            if is_current_complete
                            else self.current_tool_id
                        )
                        res = StreamingParseResult(
                            calls=[
                                ToolCallItem(
                                    tool_index=tool_index_to_use,
                                    parameters=argument_diff,
                                )
                            ],
                        )
                        if not is_current_complete:
                            self.streamed_args_for_tool[
                                self.current_tool_id
                            ] += argument_diff

            # Update prev_tool_call_arr with current state
            if self.current_tool_id &gt;= 0:
                # Ensure prev_tool_call_arr is large enough
                while len(self.prev_tool_call_arr) &lt;= self.current_tool_id:
                    self.prev_tool_call_arr.append({})
                self.prev_tool_call_arr[self.current_tool_id] = current_tool_call

            return res

        except Exception as e:
            logger.error(f&#34;Error in parse_streaming_increment: {e}&#34;)
            return StreamingParseResult()

    @abstractmethod
    def has_tool_call(self, text: str) -&gt; bool:
        &#34;&#34;&#34;
        Check if the given text contains function call markers specific to this format.
        &#34;&#34;&#34;
        raise NotImplementedError()

    def supports_structural_tag(self) -&gt; bool:
        &#34;&#34;&#34;Return True if this detector supports structural tag format.&#34;&#34;&#34;
        return True

    @abstractmethod
    def structure_info(self) -&gt; _GetInfoFunc:
        &#34;&#34;&#34;
        Return a function that creates StructureInfo for constrained generation.

        The returned function takes a tool name and returns a StructureInfo object
        containing the begin/end patterns and trigger tokens needed for constrained
        generation of function calls in this format.

        Returns:
            A function that takes a tool name (str) and returns StructureInfo
        &#34;&#34;&#34;
        raise NotImplementedError()

    @abstractmethod
    def build_ebnf(self, tools: List[Tool]) -&gt; str:
        &#34;&#34;&#34;
        Build an EBNF grammar for constrained generation of function calls.

        This method generates an Extended Backus-Naur Form (EBNF) grammar that
        constrains the model&#39;s output to valid function calls in this format.
        The grammar should include all available tools and their parameter schemas.

        Args:
            tools: List of available tools/functions that can be called

        Returns:
            A string containing the EBNF grammar for this function call format

        The EBNF grammar should:
            - Define the overall structure of function calls in this format
            - Include all tool names from the provided tools list
            - Define valid JSON structures for function arguments
            - Handle multiple function calls if the format supports them

        Note:
            Most implementations use EBNFComposer.build_ebnf() utility with
            format-specific parameters rather than writing EBNF from scratch.
        &#34;&#34;&#34;
        raise NotImplementedError()</code></pre>
</details>
<div class="desc"><p>Base class providing two sets of interfaces: one-time and streaming incremental.</p></div>
<h3>Ancestors</h3>
<ul class="hlist">
<li>abc.ABC</li>
</ul>
<h3>Subclasses</h3>
<ul class="hlist">
<li><a title="sglang.srt.function_call.deepseekv31_detector.DeepSeekV31Detector" href="deepseekv31_detector.html#sglang.srt.function_call.deepseekv31_detector.DeepSeekV31Detector">DeepSeekV31Detector</a></li>
<li><a title="sglang.srt.function_call.deepseekv3_detector.DeepSeekV3Detector" href="deepseekv3_detector.html#sglang.srt.function_call.deepseekv3_detector.DeepSeekV3Detector">DeepSeekV3Detector</a></li>
<li><a title="sglang.srt.function_call.glm4_moe_detector.Glm4MoeDetector" href="glm4_moe_detector.html#sglang.srt.function_call.glm4_moe_detector.Glm4MoeDetector">Glm4MoeDetector</a></li>
<li><a title="sglang.srt.function_call.gpt_oss_detector.GptOssDetector" href="gpt_oss_detector.html#sglang.srt.function_call.gpt_oss_detector.GptOssDetector">GptOssDetector</a></li>
<li><a title="sglang.srt.function_call.kimik2_detector.KimiK2Detector" href="kimik2_detector.html#sglang.srt.function_call.kimik2_detector.KimiK2Detector">KimiK2Detector</a></li>
<li><a title="sglang.srt.function_call.llama32_detector.Llama32Detector" href="llama32_detector.html#sglang.srt.function_call.llama32_detector.Llama32Detector">Llama32Detector</a></li>
<li><a title="sglang.srt.function_call.mistral_detector.MistralDetector" href="mistral_detector.html#sglang.srt.function_call.mistral_detector.MistralDetector">MistralDetector</a></li>
<li><a title="sglang.srt.function_call.pythonic_detector.PythonicDetector" href="pythonic_detector.html#sglang.srt.function_call.pythonic_detector.PythonicDetector">PythonicDetector</a></li>
<li><a title="sglang.srt.function_call.qwen25_detector.Qwen25Detector" href="qwen25_detector.html#sglang.srt.function_call.qwen25_detector.Qwen25Detector">Qwen25Detector</a></li>
<li><a title="sglang.srt.function_call.qwen3_coder_detector.Qwen3CoderDetector" href="qwen3_coder_detector.html#sglang.srt.function_call.qwen3_coder_detector.Qwen3CoderDetector">Qwen3CoderDetector</a></li>
<li><a title="sglang.srt.function_call.step3_detector.Step3Detector" href="step3_detector.html#sglang.srt.function_call.step3_detector.Step3Detector">Step3Detector</a></li>
</ul>
<h3>Methods</h3>
<dl>
<dt id="sglang.srt.function_call.base_format_detector.BaseFormatDetector.build_ebnf"><code class="name flex">
<span>def <span class="ident">build_ebnf</span></span>(<span>self,<br>tools: List[<a title="sglang.srt.entrypoints.openai.protocol.Tool" href="../entrypoints/openai/protocol.html#sglang.srt.entrypoints.openai.protocol.Tool">Tool</a>]) ‑> str</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@abstractmethod
def build_ebnf(self, tools: List[Tool]) -&gt; str:
    &#34;&#34;&#34;
    Build an EBNF grammar for constrained generation of function calls.

    This method generates an Extended Backus-Naur Form (EBNF) grammar that
    constrains the model&#39;s output to valid function calls in this format.
    The grammar should include all available tools and their parameter schemas.

    Args:
        tools: List of available tools/functions that can be called

    Returns:
        A string containing the EBNF grammar for this function call format

    The EBNF grammar should:
        - Define the overall structure of function calls in this format
        - Include all tool names from the provided tools list
        - Define valid JSON structures for function arguments
        - Handle multiple function calls if the format supports them

    Note:
        Most implementations use EBNFComposer.build_ebnf() utility with
        format-specific parameters rather than writing EBNF from scratch.
    &#34;&#34;&#34;
    raise NotImplementedError()</code></pre>
</details>
<div class="desc"><p>Build an EBNF grammar for constrained generation of function calls.</p>
<p>This method generates an Extended Backus-Naur Form (EBNF) grammar that
constrains the model's output to valid function calls in this format.
The grammar should include all available tools and their parameter schemas.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>tools</code></strong></dt>
<dd>List of available tools/functions that can be called</dd>
</dl>
<h2 id="returns">Returns</h2>
<p>A string containing the EBNF grammar for this function call format
The EBNF grammar should:
- Define the overall structure of function calls in this format
- Include all tool names from the provided tools list
- Define valid JSON structures for function arguments
- Handle multiple function calls if the format supports them</p>
<h2 id="note">Note</h2>
<p>Most implementations use EBNFComposer.build_ebnf() utility with
format-specific parameters rather than writing EBNF from scratch.</p></div>
</dd>
<dt id="sglang.srt.function_call.base_format_detector.BaseFormatDetector.detect_and_parse"><code class="name flex">
<span>def <span class="ident">detect_and_parse</span></span>(<span>self,<br>text: str,<br>tools: List[<a title="sglang.srt.entrypoints.openai.protocol.Tool" href="../entrypoints/openai/protocol.html#sglang.srt.entrypoints.openai.protocol.Tool">Tool</a>]) ‑> <a title="sglang.srt.function_call.core_types.StreamingParseResult" href="core_types.html#sglang.srt.function_call.core_types.StreamingParseResult">StreamingParseResult</a></span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@abstractmethod
def detect_and_parse(self, text: str, tools: List[Tool]) -&gt; StreamingParseResult:
    &#34;&#34;&#34;
    Parses the text in one go. Returns success=True if the format matches, otherwise False.
    Note that leftover_text here represents &#34;content that this parser will not consume further&#34;.
    &#34;&#34;&#34;
    action = json.loads(text)
    return StreamingParseResult(calls=self.parse_base_json(action, tools))</code></pre>
</details>
<div class="desc"><p>Parses the text in one go. Returns success=True if the format matches, otherwise False.
Note that leftover_text here represents "content that this parser will not consume further".</p></div>
</dd>
<dt id="sglang.srt.function_call.base_format_detector.BaseFormatDetector.has_tool_call"><code class="name flex">
<span>def <span class="ident">has_tool_call</span></span>(<span>self, text: str) ‑> bool</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@abstractmethod
def has_tool_call(self, text: str) -&gt; bool:
    &#34;&#34;&#34;
    Check if the given text contains function call markers specific to this format.
    &#34;&#34;&#34;
    raise NotImplementedError()</code></pre>
</details>
<div class="desc"><p>Check if the given text contains function call markers specific to this format.</p></div>
</dd>
<dt id="sglang.srt.function_call.base_format_detector.BaseFormatDetector.parse_base_json"><code class="name flex">
<span>def <span class="ident">parse_base_json</span></span>(<span>self,<br>action: Any,<br>tools: List[<a title="sglang.srt.entrypoints.openai.protocol.Tool" href="../entrypoints/openai/protocol.html#sglang.srt.entrypoints.openai.protocol.Tool">Tool</a>]) ‑> List[<a title="sglang.srt.function_call.core_types.ToolCallItem" href="core_types.html#sglang.srt.function_call.core_types.ToolCallItem">ToolCallItem</a>]</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def parse_base_json(self, action: Any, tools: List[Tool]) -&gt; List[ToolCallItem]:
    tool_indices = self._get_tool_indices(tools)
    if not isinstance(action, list):
        action = [action]

    results = []
    for act in action:
        name = act.get(&#34;name&#34;)
        if name and name in tool_indices:
            results.append(
                ToolCallItem(
                    tool_index=-1,  # Caller should update this based on the actual tools array called
                    name=name,
                    parameters=json.dumps(
                        act.get(&#34;parameters&#34;) or act.get(&#34;arguments&#34;, {}),
                        ensure_ascii=False,
                    ),
                )
            )
        else:
            logger.warning(f&#34;Model attempted to call undefined function: {name}&#34;)

    return results</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="sglang.srt.function_call.base_format_detector.BaseFormatDetector.parse_streaming_increment"><code class="name flex">
<span>def <span class="ident">parse_streaming_increment</span></span>(<span>self,<br>new_text: str,<br>tools: List[<a title="sglang.srt.entrypoints.openai.protocol.Tool" href="../entrypoints/openai/protocol.html#sglang.srt.entrypoints.openai.protocol.Tool">Tool</a>]) ‑> <a title="sglang.srt.function_call.core_types.StreamingParseResult" href="core_types.html#sglang.srt.function_call.core_types.StreamingParseResult">StreamingParseResult</a></span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def parse_streaming_increment(
    self, new_text: str, tools: List[Tool]
) -&gt; StreamingParseResult:
    &#34;&#34;&#34;
    Streaming incremental parsing with tool validation.

    This base implementation works best with formats where:
    1. bot_token is followed immediately by JSON (e.g., bot_token + JSON_array)
    2. JSON can be parsed incrementally using partial_json_loads
    3. Multiple tool calls are separated by &#34;; &#34; or &#34;, &#34;

    Examples of incompatible formats (need custom implementation, may reuse some logic from this class):
    - Each tool call is wrapped in a separate block: See Qwen25Detector
    - Multiple separate blocks: [TOOL_CALLS] [...] \n [TOOL_CALLS] [...]
    - Tool call is Pythonic style

    For incompatible formats, detectors should override this method with custom logic.
    &#34;&#34;&#34;
    # Append new text to buffer
    self._buffer += new_text
    current_text = self._buffer

    # The current_text has tool_call if it is the start of a new tool call sequence
    # or it is the start of a new tool call after a tool call separator, when there is a previous tool call
    if not (
        self.has_tool_call(current_text)
        or (
            self.current_tool_id &gt; 0
            and current_text.startswith(self.tool_call_separator)
        )
    ):
        # Only clear buffer if we&#39;re sure no tool call is starting
        if not self._ends_with_partial_token(self._buffer, self.bot_token):
            normal_text = self._buffer
            self._buffer = &#34;&#34;
            if self.eot_token in normal_text:
                normal_text = normal_text.replace(self.eot_token, &#34;&#34;)
            return StreamingParseResult(normal_text=normal_text)
        else:
            # Might be partial bot_token, keep buffering
            return StreamingParseResult()

    # Build tool indices if not already built
    if not hasattr(self, &#34;_tool_indices&#34;):
        self._tool_indices = self._get_tool_indices(tools)

    flags = Allow.ALL if self.current_tool_name_sent else Allow.ALL &amp; ~Allow.STR

    try:
        try:
            if current_text.startswith(self.bot_token):
                start_idx = len(self.bot_token)
            elif self.current_tool_id &gt; 0 and current_text.startswith(
                self.tool_call_separator + self.bot_token
            ):
                start_idx = len(self.tool_call_separator + self.bot_token)
            elif self.current_tool_id &gt; 0 and current_text.startswith(
                self.tool_call_separator
            ):
                start_idx = len(self.tool_call_separator)
            else:
                start_idx = 0

            if start_idx &gt;= len(current_text):
                return StreamingParseResult()

            (obj, end_idx) = _partial_json_loads(current_text[start_idx:], flags)

            is_current_complete = _is_complete_json(
                current_text[start_idx : start_idx + end_idx]
            )

            # Validate tool name if present
            if &#34;name&#34; in obj and obj[&#34;name&#34;] not in self._tool_indices:
                # Invalid tool name - reset state
                self._buffer = &#34;&#34;
                self.current_tool_id = -1
                self.current_tool_name_sent = False
                if self.streamed_args_for_tool:
                    self.streamed_args_for_tool.pop()
                return StreamingParseResult()

            # Handle parameters/arguments consistency
            # NOTE: we assume here that the obj is always partial of a single tool call
            if &#34;parameters&#34; in obj:
                assert (
                    &#34;arguments&#34; not in obj
                ), &#34;model generated both parameters and arguments&#34;
                obj[&#34;arguments&#34;] = obj[&#34;parameters&#34;]

            current_tool_call = obj

        except MalformedJSON:
            return StreamingParseResult()

        if not current_tool_call:
            return StreamingParseResult()

        # Case 1: Handle tool name streaming
        # This happens when we encounter a tool but haven&#39;t sent its name yet
        if not self.current_tool_name_sent:
            function_name = current_tool_call.get(&#34;name&#34;)

            if function_name and function_name in self._tool_indices:
                # If this is a new tool (current_tool_id was -1), initialize it
                if self.current_tool_id == -1:
                    self.current_tool_id = 0
                    self.streamed_args_for_tool.append(&#34;&#34;)
                # If this is a subsequent tool, ensure streamed_args_for_tool is large enough
                elif self.current_tool_id &gt;= len(self.streamed_args_for_tool):
                    while len(self.streamed_args_for_tool) &lt;= self.current_tool_id:
                        self.streamed_args_for_tool.append(&#34;&#34;)

                # Send the tool name with empty parameters
                res = StreamingParseResult(
                    calls=[
                        ToolCallItem(
                            tool_index=self.current_tool_id,
                            name=function_name,
                            parameters=&#34;&#34;,
                        )
                    ],
                )
                self.current_tool_name_sent = True
            else:
                res = StreamingParseResult()

        # Case 2: Handle streaming arguments
        # This happens when we&#39;ve already sent the tool name and now need to stream arguments incrementally
        else:
            cur_arguments = current_tool_call.get(&#34;arguments&#34;)
            res = StreamingParseResult()

            if cur_arguments:
                # Calculate how much of the arguments we&#39;ve already streamed
                sent = len(self.streamed_args_for_tool[self.current_tool_id])
                cur_args_json = json.dumps(cur_arguments)
                prev_arguments = None
                if self.current_tool_id &lt; len(self.prev_tool_call_arr):
                    prev_arguments = self.prev_tool_call_arr[
                        self.current_tool_id
                    ].get(&#34;arguments&#34;)

                argument_diff = None

                # If the current tool&#39;s JSON is complete, send all remaining arguments
                if is_current_complete:
                    argument_diff = cur_args_json[sent:]
                    completing_tool_id = (
                        self.current_tool_id
                    )  # Save the ID of the tool that&#39;s completing

                    # Only remove the processed portion, keep unprocessed content
                    self._buffer = current_text[start_idx + end_idx :]

                    if self.current_tool_id &lt; len(self.prev_tool_call_arr):
                        self.prev_tool_call_arr[self.current_tool_id].clear()
                    self.current_tool_name_sent = False
                    self.streamed_args_for_tool[self.current_tool_id] = &#34;&#34;
                    self.current_tool_id += 1

                # If the tool is still being parsed, send incremental changes
                elif prev_arguments:
                    prev_args_json = json.dumps(prev_arguments)
                    if cur_args_json != prev_args_json:
                        prefix = _find_common_prefix(prev_args_json, cur_args_json)
                        argument_diff = prefix[sent:]

                # Send the argument diff if there&#39;s something new
                if argument_diff is not None:
                    # Use the correct tool_index: completing_tool_id for completed tools, current_tool_id for ongoing
                    tool_index_to_use = (
                        completing_tool_id
                        if is_current_complete
                        else self.current_tool_id
                    )
                    res = StreamingParseResult(
                        calls=[
                            ToolCallItem(
                                tool_index=tool_index_to_use,
                                parameters=argument_diff,
                            )
                        ],
                    )
                    if not is_current_complete:
                        self.streamed_args_for_tool[
                            self.current_tool_id
                        ] += argument_diff

        # Update prev_tool_call_arr with current state
        if self.current_tool_id &gt;= 0:
            # Ensure prev_tool_call_arr is large enough
            while len(self.prev_tool_call_arr) &lt;= self.current_tool_id:
                self.prev_tool_call_arr.append({})
            self.prev_tool_call_arr[self.current_tool_id] = current_tool_call

        return res

    except Exception as e:
        logger.error(f&#34;Error in parse_streaming_increment: {e}&#34;)
        return StreamingParseResult()</code></pre>
</details>
<div class="desc"><p>Streaming incremental parsing with tool validation.</p>
<pre><code>   This base implementation works best with formats where:
   1. bot_token is followed immediately by JSON (e.g., bot_token + JSON_array)
   2. JSON can be parsed incrementally using partial_json_loads
   3. Multiple tool calls are separated by "; " or ", "

   Examples of incompatible formats (need custom implementation, may reuse some logic from this class):
   - Each tool call is wrapped in a separate block: See Qwen25Detector
   - Multiple separate blocks: [TOOL_CALLS] [...]
</code></pre>
<p>[TOOL_CALLS] [&hellip;]
- Tool call is Pythonic style</p>
<pre><code>   For incompatible formats, detectors should override this method with custom logic.
</code></pre></div>
</dd>
<dt id="sglang.srt.function_call.base_format_detector.BaseFormatDetector.structure_info"><code class="name flex">
<span>def <span class="ident">structure_info</span></span>(<span>self) ‑> Callable[[str], <a title="sglang.srt.function_call.core_types.StructureInfo" href="core_types.html#sglang.srt.function_call.core_types.StructureInfo">StructureInfo</a>]</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@abstractmethod
def structure_info(self) -&gt; _GetInfoFunc:
    &#34;&#34;&#34;
    Return a function that creates StructureInfo for constrained generation.

    The returned function takes a tool name and returns a StructureInfo object
    containing the begin/end patterns and trigger tokens needed for constrained
    generation of function calls in this format.

    Returns:
        A function that takes a tool name (str) and returns StructureInfo
    &#34;&#34;&#34;
    raise NotImplementedError()</code></pre>
</details>
<div class="desc"><p>Return a function that creates StructureInfo for constrained generation.</p>
<p>The returned function takes a tool name and returns a StructureInfo object
containing the begin/end patterns and trigger tokens needed for constrained
generation of function calls in this format.</p>
<h2 id="returns">Returns</h2>
<p>A function that takes a tool name (str) and returns StructureInfo</p></div>
</dd>
<dt id="sglang.srt.function_call.base_format_detector.BaseFormatDetector.supports_structural_tag"><code class="name flex">
<span>def <span class="ident">supports_structural_tag</span></span>(<span>self) ‑> bool</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def supports_structural_tag(self) -&gt; bool:
    &#34;&#34;&#34;Return True if this detector supports structural tag format.&#34;&#34;&#34;
    return True</code></pre>
</details>
<div class="desc"><p>Return True if this detector supports structural tag format.</p></div>
</dd>
</dl>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="sglang.srt.function_call" href="index.html">sglang.srt.function_call</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="sglang.srt.function_call.base_format_detector.BaseFormatDetector" href="#sglang.srt.function_call.base_format_detector.BaseFormatDetector">BaseFormatDetector</a></code></h4>
<ul class="">
<li><code><a title="sglang.srt.function_call.base_format_detector.BaseFormatDetector.build_ebnf" href="#sglang.srt.function_call.base_format_detector.BaseFormatDetector.build_ebnf">build_ebnf</a></code></li>
<li><code><a title="sglang.srt.function_call.base_format_detector.BaseFormatDetector.detect_and_parse" href="#sglang.srt.function_call.base_format_detector.BaseFormatDetector.detect_and_parse">detect_and_parse</a></code></li>
<li><code><a title="sglang.srt.function_call.base_format_detector.BaseFormatDetector.has_tool_call" href="#sglang.srt.function_call.base_format_detector.BaseFormatDetector.has_tool_call">has_tool_call</a></code></li>
<li><code><a title="sglang.srt.function_call.base_format_detector.BaseFormatDetector.parse_base_json" href="#sglang.srt.function_call.base_format_detector.BaseFormatDetector.parse_base_json">parse_base_json</a></code></li>
<li><code><a title="sglang.srt.function_call.base_format_detector.BaseFormatDetector.parse_streaming_increment" href="#sglang.srt.function_call.base_format_detector.BaseFormatDetector.parse_streaming_increment">parse_streaming_increment</a></code></li>
<li><code><a title="sglang.srt.function_call.base_format_detector.BaseFormatDetector.structure_info" href="#sglang.srt.function_call.base_format_detector.BaseFormatDetector.structure_info">structure_info</a></code></li>
<li><code><a title="sglang.srt.function_call.base_format_detector.BaseFormatDetector.supports_structural_tag" href="#sglang.srt.function_call.base_format_detector.BaseFormatDetector.supports_structural_tag">supports_structural_tag</a></code></li>
</ul>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc" title="pdoc: Python API documentation generator"><cite>pdoc</cite> 0.11.6</a>.</p>
</footer>
</body>
</html>
