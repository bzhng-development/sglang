================================================================================
FUNCTION INDEX: SGLang Complete Codebase
================================================================================
Total Functions: 6263
Documented: 1008


============================================================
FILE: python/sglang/bench_offline_throughput.py
Functions: 5
============================================================

MODULE FUNCTIONS:
----------------------------------------
  L 197: def throughput_test_once(backend_name: str,
        backend,
        reqs: List[DatasetRow],
        ignore_eos: bool,
        extra_request_body: Dict,
        profile: bool)

  L 278: def monitor_trace_file(known_files, directory, interval)

  L 310: def throughput_test(server_args: ServerArgs, bench_args: BenchArgs)


CLASS: BenchArgs
----------------------------------------
  L  65: add_cli_args(parser: argparse.ArgumentParser)

  L 192: from_cli_args(cls, args: argparse.Namespace)


============================================================
FILE: python/sglang/bench_one_batch.py
Functions: 13
============================================================

MODULE FUNCTIONS:
----------------------------------------
  L 150: def load_model(server_args, port_args, tp_rank)

  L 180: def prepare_inputs_for_correctness_test(bench_args, tokenizer, custom_prompts)

  L 216: def prepare_extend_inputs_for_correctness_test(bench_args,
        input_ids,
        reqs,
        model_runner)

  L 230: def prepare_synthetic_inputs_for_latency_test(batch_size,
        input_len,
        custom_inputs)

  L 261: def extend(reqs, model_runner)
         @torch.no_grad

  L 281: def decode(input_token_ids, batch, model_runner)
         @torch.no_grad

  L 332: def correctness_test(server_args, port_args, bench_args, tp_rank)

  L 380: def synchronize(device)

  L 384: def latency_test_run_once(run_name,
        model_runner,
        rank_print,
        reqs,
        batch_size,
        input_len,
        output_len,
        device,
        log_decode_step,
        profile,
        profile_record_shapes,
        profile_filename_prefix)

  L 507: def latency_test(server_args, port_args, bench_args, tp_rank)

  L 607: def main(server_args, bench_args)


CLASS: BenchArgs
----------------------------------------
  L 100: add_cli_args(parser: argparse.ArgumentParser)

  L 142: from_cli_args(cls, args: argparse.Namespace)


============================================================
FILE: python/sglang/bench_one_batch_server.py
Functions: 8
============================================================

MODULE FUNCTIONS:
----------------------------------------
  L  96: def launch_server_internal(server_args)

  L 105: def launch_server_process(server_args: ServerArgs)

  L 126: def run_one_case(url: str,
        batch_size: int,
        input_len: int,
        output_len: int,
        temperature: float,
        return_logprob: bool,
        stream_interval: int,
        input_len_step_percentage: float,
        run_name: str,
        result_filename: str,
        tokenizer,
        profile: bool,
        profile_steps: int,
        profile_by_stage: bool)

  L 255: def get_report_summary(result: List[Tuple],
        server_args: ServerArgs,
        bench_args: BenchArgs)

  L 320: def run_benchmark(server_args: ServerArgs, bench_args: BenchArgs)

  L 418: def main()


CLASS: BenchArgs
----------------------------------------
  L  52: add_cli_args(parser: argparse.ArgumentParser)

  L  88: from_cli_args(cls, args: argparse.Namespace)


============================================================
FILE: python/sglang/bench_serving.py
Functions: 32
============================================================

MODULE FUNCTIONS:
----------------------------------------
  L  98: def remove_prefix(text: str, prefix: str)
         ‚Üí str

  L 102: def remove_suffix(text: str, suffix: str)
         ‚Üí str

  L 106: def get_auth_headers()
         ‚Üí Dict[str, str]

  L 116: async def async_request_trt_llm(request_func_input: RequestFuncInput,
        pbar: Optional[tqdm])
         ‚Üí RequestFuncOutput

  L 185: async def async_request_openai_completions(request_func_input: RequestFuncInput,
        pbar: Optional[tqdm])
         ‚Üí RequestFuncOutput

  L 270: async def async_request_openai_chat_completions(request_func_input: RequestFuncInput,
        pbar: Optional[tqdm])
         ‚Üí RequestFuncOutput
         üìù Makes a request to the OpenAI Chat Completions API.
            Handles both streaming and non-streaming responses, including support
            for image data in messages. Calculates and returns various performance
            metrics.
            Args:
            request_func_input: Input parameters for the request.
            pbar: Optional tqdm progress bar to update.
            Returns:
            RequestFuncOutput: Output of the request, including generated text,
            latency, TTFT, ITL, and success status.

  L 405: async def async_request_truss(request_func_input: RequestFuncInput,
        pbar: Optional[tqdm])
         ‚Üí RequestFuncOutput

  L 483: async def async_request_sglang_generate(request_func_input: RequestFuncInput,
        pbar: Optional[tqdm])
         ‚Üí RequestFuncOutput

  L 580: async def async_request_gserver(request_func_input: RequestFuncInput,
        pbar: Optional[tqdm])
         ‚Üí RequestFuncOutput

  L 587: async def async_request_profile(api_url: str)
         ‚Üí RequestFuncOutput

  L 605: def get_model(pretrained_model_name_or_path: str)
         ‚Üí str

  L 620: def get_tokenizer(pretrained_model_name_or_path: str)
         ‚Üí Union[PreTrainedTokenizer, PreTrainedTokenizerFast]

  L 643: def get_dataset(args, tokenizer)

  L 755: def download_and_cache_file(url: str, filename: Optional[str])
         üìù Read and cache a file from a url.

  L 789: def is_file_valid_json(path)

  L 813: def sample_mmmu_requests(num_requests: int,
        tokenizer: PreTrainedTokenizerBase,
        fixed_output_len: Optional[int],
        apply_chat_template: bool,
        random_sample: bool)
         ‚Üí List[DatasetRow]
         üìù Sample requests from the MMMU dataset using HuggingFace datasets.
            Args:
            num_requests: Number of requests to sample.
            tokenizer: Tokenizer to use for token counting.
            fixed_output_len: If provided, use this fixed output length for all requests.
            apply_chat_template: Whether to apply the chat template to the prompt.
            random_sample: Whether to randomly sample or take the first N.
            Returns:
            List of tuples (prompt, prompt_token_len, output_token_len).

  L 944: def sample_sharegpt_requests(dataset_path: str,
        num_requests: int,
        tokenizer: PreTrainedTokenizerBase,
        fixed_output_len: Optional[int],
        context_len: Optional[int],
        prompt_suffix: Optional[str],
        apply_chat_template)
         ‚Üí List[DatasetRow]

  L1030: def sample_random_requests(input_len: int,
        output_len: int,
        num_prompts: int,
        range_ratio: float,
        tokenizer: PreTrainedTokenizerBase,
        dataset_path: str,
        random_sample: bool,
        return_text: bool)
         ‚Üí List[DatasetRow]

  L1133: def parse_random_image_resolution(image_resolution: str)
         ‚Üí Tuple[int, int]
         üìù Parse image resolution into (width, height).
            Supports presets '1080p', '720p', '360p' and custom 'heightxwidth' format
            (e.g., '1080x1920' means height=1080, width=1920).

  L1163: def sample_random_image_requests(num_requests: int,
        num_images: int,
        input_len: int,
        output_len: int,
        range_ratio: float,
        tokenizer: PreTrainedTokenizerBase,
        apply_chat_template: bool,
        image_resolution: str)
         ‚Üí List[DatasetRow]
         üìù Generate requests with random images.
            - Each request includes ``num_images`` random images.
            - Supported resolutions: 4k (3840x2160), 1080p (1920x1080), 720p (1280x720), 360p (640x360),
            or custom 'heightxwidth' (e.g., 1080x1920).
            - Text lengths follow the 'random' dataset sampling rule. ``prompt_len``
            only counts text tokens and excludes image data.

  L1259: def gen_prompt(tokenizer, token_num)
         üìù Generate a random prompt of specified token length using tokenizer vocabulary.

  L1266: def get_gen_prefix_cache_path(args, tokenizer)
         üìù Create cache directory under ~/.cache/sglang/benchmark

  L1279: def sample_generated_shared_prefix_requests(num_groups: int,
        prompts_per_group: int,
        system_prompt_len: int,
        question_len: int,
        output_len: int,
        tokenizer: PreTrainedTokenizerBase,
        args: argparse.Namespace)
         ‚Üí List[DatasetRow]
         üìù Generate benchmark requests with shared system prompts using random tokens and caching.

  L1359: async def get_request(input_requests: List[DatasetRow], request_rate: float)
         ‚Üí AsyncGenerator[DatasetRow, None]

  L1377: def calculate_metrics(input_requests: List[DatasetRow],
        outputs: List[RequestFuncOutput],
        dur_s: float,
        tokenizer: PreTrainedTokenizerBase,
        backend: str)
         ‚Üí Tuple[BenchmarkMetrics, List[int]]

  L1456: async def benchmark(backend: str,
        api_url: str,
        base_url: str,
        model_id: str,
        tokenizer: PreTrainedTokenizerBase,
        input_requests: List[DatasetRow],
        request_rate: float,
        max_concurrency: Optional[int],
        disable_tqdm: bool,
        lora_names: List[str],
        extra_request_body: Dict[str,
        Any],
        profile: bool,
        pd_separated: bool,
        flush_cache: bool,
        warmup_requests: int)

  L1756: def check_chat_template(model_path)

  L1765: def set_global_args(args_: argparse.Namespace)
         üìù Set the global args.

  L1771: def run_benchmark(args_: argparse.Namespace)

  L1926: def set_ulimit(target_soft_limit)


CLASS: LoRAPathAction
----------------------------------------
  L1938: __call__(self, parser, namespace, values, option_string)


CLASS: RequestFuncOutput
----------------------------------------
  L  92: init_new(request_func_input: RequestFuncInput)


============================================================
FILE: python/sglang/check_env.py
Functions: 6
============================================================

MODULE FUNCTIONS:
----------------------------------------
  L  15: def is_cuda_v2()

  L  54: def get_package_versions(packages)
         üìù Get versions of specified packages.

  L  69: def get_cuda_info()
         üìù Get CUDA-related information if available.

  L 233: def get_gpu_topology()
         üìù Get GPU topology information.

  L 265: def get_hypervisor_vendor()

  L 276: def check_env()
         üìù Check and print environment information.


============================================================
FILE: python/sglang/compile_deep_gemm.py
Functions: 7
============================================================

MODULE FUNCTIONS:
----------------------------------------
  L  56: async def warm_up_compile(disaggregation_mode: str,
        tokenizer_manager: TokenizerManager)
         @warmup('compile-deep-gemm')

  L  75: def launch_server_internal(server_args)

  L  84: def launch_server_process_and_send_one_request(server_args: ServerArgs,
        compile_args: CompileArgs)

  L 138: def refine_server_args(server_args: ServerArgs, compile_args: CompileArgs)

  L 149: def run_compile(server_args: ServerArgs, compile_args: CompileArgs)


CLASS: CompileArgs
----------------------------------------
  L  43: add_cli_args(parser: argparse.ArgumentParser)

  L  47: from_cli_args(cls, args: argparse.Namespace)


============================================================
FILE: python/sglang/eval/llama3_eval.py
Functions: 9
============================================================

MODULE FUNCTIONS:
----------------------------------------
  L  39: async def fetch_responses(client,
        prompt,
        semaphore,
        index,
        provider,
        model_size,
        output_dir,
        max_tokens)

  L  87: def get_client(provider)

  L 103: async def benchmark(args)

  L 144: def get_mmlu_answer(response)

  L 150: def get_mmlu_cot_answer(response)

  L 172: def get_answer_gsm8k(response)

  L 190: def get_dataset_from_task(task, response_path, model_size)

  L 221: def analyze(task, response_path, model_size)


CLASS: CustomAsyncHTTPXClient
----------------------------------------
  L  80: send(self, request: httpx.Request)
         ‚Üí httpx.Response


============================================================
FILE: python/sglang/eval/loogle_eval.py
Functions: 5
============================================================

MODULE FUNCTIONS:
----------------------------------------
  L  15: def get_client(api_url: str)
         ‚Üí openai.AsyncOpenAI

  L  21: def get_dataset()

  L  25: async def fetch_response(client: openai.AsyncOpenAI,
        context: str,
        question: str,
        semaphore: asyncio.Semaphore,
        index: int,
        model: str,
        output_dir: Path)

  L  66: async def benchmark(args)

  L  98: def analyse(args)


============================================================
FILE: python/sglang/global_config.py
Functions: 1
============================================================


CLASS: GlobalConfig
----------------------------------------
  L  14: __init__(self)


============================================================
FILE: python/sglang/lang/api.py
Functions: 22
============================================================

MODULE FUNCTIONS:
----------------------------------------
  L  23: def function(func: Optional[Callable], num_api_spec_tokens: Optional[int])

  L  35: def Runtime()

  L  42: def Engine()

  L  49: def set_default_backend(backend: BaseBackend)

  L  53: def flush_cache(backend: Optional[BaseBackend])

  L  64: def get_server_info(backend: Optional[BaseBackend])

  L  75: def gen(name: Optional[str],
        max_tokens: Optional[int],
        min_tokens: Optional[int],
        n: Optional[int],
        stop: Optional[Union[str,
        List[str]]],
        stop_token_ids: Optional[List[int]],
        temperature: Optional[float],
        top_p: Optional[float],
        top_k: Optional[int],
        min_p: Optional[float],
        frequency_penalty: Optional[float],
        presence_penalty: Optional[float],
        ignore_eos: Optional[bool],
        return_logprob: Optional[bool],
        logprob_start_len: Optional[int],
        top_logprobs_num: Optional[int],
        return_text_in_logprobs: Optional[bool],
        dtype: Optional[Union[type,
        str]],
        choices: Optional[List[str]],
        choices_method: Optional[ChoicesSamplingMethod],
        regex: Optional[str],
        json_schema: Optional[str])
         üìù Call the model to generate. See the meaning of the arguments in docs/backend/sampling_params.md

  L 140: def gen_int(name: Optional[str],
        max_tokens: Optional[int],
        n: Optional[int],
        stop: Optional[Union[str,
        List[str]]],
        stop_token_ids: Optional[List[int]],
        temperature: Optional[float],
        top_p: Optional[float],
        top_k: Optional[int],
        min_p: Optional[float],
        frequency_penalty: Optional[float],
        presence_penalty: Optional[float],
        ignore_eos: Optional[bool],
        return_logprob: Optional[bool],
        logprob_start_len: Optional[int],
        top_logprobs_num: Optional[int],
        return_text_in_logprobs: Optional[bool])

  L 181: def gen_string(name: Optional[str],
        max_tokens: Optional[int],
        n: Optional[int],
        stop: Optional[Union[str,
        List[str]]],
        stop_token_ids: Optional[List[int]],
        temperature: Optional[float],
        top_p: Optional[float],
        top_k: Optional[int],
        min_p: Optional[float],
        frequency_penalty: Optional[float],
        presence_penalty: Optional[float],
        ignore_eos: Optional[bool],
        return_logprob: Optional[bool],
        logprob_start_len: Optional[int],
        top_logprobs_num: Optional[int],
        return_text_in_logprobs: Optional[bool])

  L 222: def image(expr: SglExpr)

  L 226: def video(path: str, num_frames: int)

  L 230: def select(name: Optional[str],
        choices: Optional[List[str]],
        temperature: float,
        choices_method: ChoicesSamplingMethod)

  L 247: def system(expr: Optional[SglExpr])

  L 251: def user(expr: Optional[SglExpr])

  L 255: def assistant(expr: Optional[SglExpr])

  L 259: def system_begin()

  L 263: def system_end()

  L 267: def user_begin()

  L 271: def user_end()

  L 275: def assistant_begin()

  L 279: def assistant_end()

  L 283: def separate_reasoning(expr: Optional[SglExpr], model_type: Optional[str])


============================================================
FILE: python/sglang/lang/backend/anthropic.py
Functions: 4
============================================================


CLASS: Anthropic
----------------------------------------
  L  13: __init__(self, model_name)

  L  23: get_chat_template(self)

  L  26: generate(self, s: StreamExecutor, sampling_params: SglSamplingParams)

  L  51: generate_stream(self, s: StreamExecutor, sampling_params: SglSamplingParams)


============================================================
FILE: python/sglang/lang/backend/base_backend.py
Functions: 18
============================================================


CLASS: BaseBackend
----------------------------------------
  L  10: __init__(self)
         ‚Üí None

  L  14: get_model_name(self)

  L  17: get_chat_template(self)

  L  20: cache_prefix(self, prefix_str: str)

  L  23: uncache_prefix(self, rid: str)

  L  26: end_request(self, rid: Union[str, List[str]])

  L  29: begin_program(self, s: StreamExecutor)

  L  32: end_program(self, s: Union[StreamExecutor, List[StreamExecutor]])

  L  35: commit_lazy_operations(self, s: StreamExecutor)

  L  38: fork_program(self, src: StreamExecutor, dst: List[StreamExecutor], position_ids_offset: Optional[List[int]])

  L  46: fill_image(self, s: StreamExecutor)

  L  49: generate(self, s: StreamExecutor, sampling_params: SglSamplingParams)

  L  56: generate_stream(self, s: StreamExecutor, sampling_params: SglSamplingParams)

  L  63: select(self, s: StreamExecutor, choices: List[str], temperature: float, choices_method: Optional[ChoicesSamplingMethod])
         ‚Üí ChoicesDecision

  L  72: concatenate_and_append(self, src_rids: List[str], dst_rid: str)

  L  75: shutdown(self)

  L  78: flush_cache(self)

  L  81: get_server_info(self)


============================================================
FILE: python/sglang/lang/backend/litellm.py
Functions: 4
============================================================


CLASS: LiteLLM
----------------------------------------
  L  16: __init__(self, model_name, chat_template, api_key, organization: Optional[str], base_url: Optional[str], timeout: Optional[float], max_retries: Optional[int], default_headers: Optional[Mapping[str, str]])

  L  47: get_chat_template(self)

  L  50: generate(self, s: StreamExecutor, sampling_params: SglSamplingParams)

  L  70: generate_stream(self, s: StreamExecutor, sampling_params: SglSamplingParams)


============================================================
FILE: python/sglang/lang/backend/openai.py
Functions: 12
============================================================

MODULE FUNCTIONS:
----------------------------------------
  L  25: def create_logit_bias_int(tokenizer)
         üìù Get logit bias for integer numbers.

  L 383: def openai_completion(client, token_usage, is_chat, retries, prompt)
         ‚Üí Union[str, List[str]]

  L 425: def openai_completion_stream(client, token_usage, is_chat, retries, prompt)


CLASS: OpenAI
----------------------------------------
  L  57: __init__(self, model_name: str, is_chat_model: Optional[bool], chat_template: Optional[ChatTemplate], is_azure: bool)

  L 106: get_chat_template(self)

  L 140: generate(self, s: StreamExecutor, sampling_params: SglSamplingParams, spec_var_name: str)

  L 224: spec_fill(self, value: str)

  L 228: spec_pattern_match(self, comp)

  L 248: role_end_generate(self, s: StreamExecutor)

  L 283: generate_stream(self, s: StreamExecutor, sampling_params: SglSamplingParams)

  L 312: select(self, s: StreamExecutor, choices: List[str], temperature: float, choices_method: ChoicesSamplingMethod)
         ‚Üí ChoicesDecision
         üìù Note: `choices_method` is not used by the OpenAI backend.


CLASS: TokenUsage
----------------------------------------
  L  52: reset(self)


============================================================
FILE: python/sglang/lang/backend/runtime_endpoint.py
Functions: 26
============================================================

MODULE FUNCTIONS:
----------------------------------------
  L 350: def compute_normalized_prompt_logprobs(input_logprobs)


CLASS: Runtime
----------------------------------------
  L 365: __init__(self, log_level: str)
         üìù See the arguments in server_args.py::ServerArgs

  L 419: shutdown(self)

  L 426: start_profile(self)

  L 429: stop_profile(self)

  L 432: cache_prefix(self, prefix: str)

  L 435: get_tokenizer(self)

  L 445: async_generate(self, prompt: str, sampling_params: Optional[Dict])

  L 483: generate(self, prompt: Union[str, List[str]], sampling_params: Optional[Dict], return_logprob: Optional[Union[List[bool], bool]], logprob_start_len: Optional[Union[List[int], int]], top_logprobs_num: Optional[Union[List[int], int]], lora_path: Optional[List[Optional[str]]])

  L 507: encode(self, prompt: Union[str, List[str], List[Dict], List[List[Dict]]])

  L 515: get_server_info(self)

  L 526: __del__(self)


CLASS: RuntimeEndpoint
----------------------------------------
  L  26: __init__(self, base_url: str, api_key: Optional[str], verify: Optional[str], chat_template_name: Optional[str])

  L  55: get_model_name(self)

  L  58: flush_cache(self)

  L  67: get_server_info(self)

  L  76: get_chat_template(self)

  L  79: cache_prefix(self, prefix_str: str)

  L  88: start_profile(self)

  L  96: stop_profile(self)

  L 104: commit_lazy_operations(self, s: StreamExecutor)

  L 115: fill_image(self, s: StreamExecutor)

  L 158: generate(self, s: StreamExecutor, sampling_params: SglSamplingParams)

  L 197: generate_stream(self, s: StreamExecutor, sampling_params: SglSamplingParams)

  L 247: select(self, s: StreamExecutor, choices: List[str], temperature: float, choices_method: ChoicesSamplingMethod)
         ‚Üí ChoicesDecision

  L 316: concatenate_and_append(self, src_rids: List[str], dst_rid: str)


============================================================
FILE: python/sglang/lang/backend/vertexai.py
Functions: 6
============================================================


CLASS: VertexAI
----------------------------------------
  L  21: __init__(self, model_name, safety_settings)

  L  35: get_chat_template(self)

  L  38: generate(self, s: StreamExecutor, sampling_params: SglSamplingParams)

  L  62: generate_stream(self, s: StreamExecutor, sampling_params: SglSamplingParams)

  L  85: text_to_vertexai_input(self, text, images)

  L  99: messages_to_vertexai_input(self, messages)


============================================================
FILE: python/sglang/lang/chat_template.py
Functions: 22
============================================================

MODULE FUNCTIONS:
----------------------------------------
  L  61: def register_chat_template(template)

  L  65: def register_chat_template_matching_function(func)

  L  69: def get_chat_template(name)

  L  73: def get_chat_template_by_model_path(model_path)

  L 526: def match_deepseek(model_path: str)
         @register_chat_template_matching_function

  L 534: def match_deepseek_janus_pro(model_path: str)
         @register_chat_template_matching_function

  L 540: def match_dbrx(model_path: str)
         @register_chat_template_matching_function

  L 548: def match_vicuna(model_path: str)
         @register_chat_template_matching_function

  L 554: def match_llama2_chat(model_path: str)
         @register_chat_template_matching_function

  L 564: def match_mistral(model_path: str)
         @register_chat_template_matching_function

  L 570: def match_llama3_instruct(model_path: str)
         @register_chat_template_matching_function

  L 576: def match_chat_ml(model_path: str)
         @register_chat_template_matching_function

  L 596: def match_chat_yi(model_path: str)
         @register_chat_template_matching_function

  L 606: def match_gemma_it(model_path: str)
         @register_chat_template_matching_function

  L 612: def match_openbmb_minicpm(model_path: str)
         @register_chat_template_matching_function

  L 620: def match_c4ai_command_r(model_path: str)
         @register_chat_template_matching_function

  L 626: def match_granite_instruct(model_path: str)
         @register_chat_template_matching_function

  L 632: def match_gemma3_instruct(model_path: str)
         @register_chat_template_matching_function

  L 638: def match_internvl_chat(model_path: str)
         @register_chat_template_matching_function

  L 644: def match_interns1_chat(model_path: str)
         @register_chat_template_matching_function


CLASS: ChatTemplate
----------------------------------------
  L  22: get_prefix_and_suffix(self, role: str, hist_messages: List[Dict])
         ‚Üí Tuple[str, str]

  L  43: get_prompt(self, messages: List[Dict])
         ‚Üí str


============================================================
FILE: python/sglang/lang/choices.py
Functions: 6
============================================================


CLASS: ChoicesSamplingMethod
----------------------------------------
  L  17: requires_unconditional_logprobs(self)
         ‚Üí bool

  L  21: __call__(self)
         ‚Üí ChoicesDecision


CLASS: GreedyTokenSelection
----------------------------------------
  L  58: __call__(self)
         ‚Üí ChoicesDecision
         üìù Select the option based on greedy logprob selection. For overlapping options
            where one option is a subset of a longer option, extend the shorter option using
            its average logprob for comparison against the longer option.


CLASS: TokenLengthNormalized
----------------------------------------
  L  34: __call__(self)
         ‚Üí ChoicesDecision
         üìù Select the option with the highest token length normalized prompt logprob.


CLASS: UnconditionalLikelihoodNormalized
----------------------------------------
  L 113: requires_unconditional_logprobs(self)
         ‚Üí bool

  L 116: __call__(self)
         ‚Üí ChoicesDecision
         üìù Select the option with the highest average token logprob once normalized by
            the unconditional token logprobs.
            The first unconditional token logprob is assumed to be None. If so, it is
            replaced with 0 for the purposes of normalization.


============================================================
FILE: python/sglang/lang/compiler.py
Functions: 11
============================================================

MODULE FUNCTIONS:
----------------------------------------
  L  11: def compile_func(function, backend)


CLASS: CompGraphNode
----------------------------------------
  L 214: __init__(self, expr: SglExpr, prev_node, next_nodes, source_node)

  L 222: add_next_node(self, other)

  L 225: __repr__(self)


CLASS: CompiledFunction
----------------------------------------
  L  18: __init__(self, tracer, function)

  L  26: build_graph(self, tracer)

  L  66: topological_sort(self)

  L  83: print_graph(self)

  L  89: run_internal(self, backend, kwargs, default_sampling_para)

  L 119: run(self)

  L 150: run_batch(self, batch_kwargs)


============================================================
FILE: python/sglang/lang/interpreter.py
Functions: 43
============================================================

MODULE FUNCTIONS:
----------------------------------------
  L  42: def run_internal(state, program, func_args, func_kwargs, sync)

  L  57: def run_program(program,
        backend,
        func_args,
        func_kwargs,
        default_sampling_para,
        stream,
        sync,
        use_thread)

  L  93: def run_program_batch(program,
        backend,
        batch_arguments,
        default_sampling_para,
        num_threads,
        progress_bar,
        generator_style)

  L 242: def cache_program(program, backend)


CLASS: ProgramState
----------------------------------------
  L 830: __init__(self, stream_executor: StreamExecutor)

  L 848: system(self, expr: Optional[SglExpr])

  L 851: user(self, expr: Optional[SglExpr])

  L 854: assistant(self, expr: Optional[SglExpr])

  L 858: var_scope(self, name: str)

  L 863: fork(self, size: int, position_ids_offset: Optional[List[int]])

  L 874: copy(self, position_ids_offset: Optional[List[int]])

  L 881: text(self)

  L 884: messages(self)

  L 887: sync(self)

  L 890: error(self)

  L 893: text_iter(self, var_name: Optional[str])

  L 931: text_async_iter(self, var_name: Optional[str], return_meta_data: bool)

  L 976: get_var(self, name)

  L 979: set_var(self, name, value)

  L 982: get_meta_info(self, name)

  L 985: __iadd__(self, other)

  L 991: __getitem__(self, name)

  L 994: __setitem__(self, name, value)

  L 997: __contains__(self, name)

  L1000: __del__(self)

  L1003: __repr__(self)
         ‚Üí str


CLASS: ProgramStateGroup
----------------------------------------
  L1008: __init__(self, states: List[ProgramState], src_state: Optional[ProgramState])

  L1014: join(self, mode: str)

  L1040: __getitem__(self, i: int)

  L1043: __setitem__(self, i: int, value)

  L1046: __iadd__(self, other)


CLASS: StreamExecutor
----------------------------------------
  L 253: __init__(self, backend, arguments, default_sampling_para, chat_template, stream, num_api_spec_tokens, use_thread)

  L 318: submit(self, expr: SglExpr)

  L 326: sync(self)

  L 330: get_var(self, name)

  L 335: set_var(self, name, value)

  L 338: get_meta_info(self, name, timeout)

  L 346: fork(self, size: int, position_ids_offset: Optional[List[int]])

  L 380: text(self)

  L 384: messages(self)

  L 388: error(self)

  L 392: end(self)

  L 823: __del__(self)


============================================================
FILE: python/sglang/lang/ir.py
Functions: 59
============================================================


CLASS: SglArgument
----------------------------------------
  L 401: __init__(self, name: str, value: str)

  L 406: __repr__(self)

  L 409: __len__(self)

  L 412: __getitem__(self, i)

  L 415: __int__(self)

  L 418: __bool__(self)

  L 421: __format__(self)


CLASS: SglCommitLazy
----------------------------------------
  L 604: __init__(self)

  L 607: __repr__(self)


CLASS: SglConcateAndAppend
----------------------------------------
  L 595: __init__(self, states)

  L 599: __repr__(self)


CLASS: SglConstantText
----------------------------------------
  L 499: __init__(self, value: str)

  L 503: __repr__(self)


CLASS: SglExpr
----------------------------------------
  L 324: __init__(self)

  L 330: __add__(self, other)

  L 337: __radd__(self, other)

  L 344: concatenate_ir(self, a, b)

  L 355: print_graph_dfs(self)


CLASS: SglExprList
----------------------------------------
  L 392: __init__(self, expr_list: List[SglExpr])

  L 396: __repr__(self)


CLASS: SglFork
----------------------------------------
  L 545: __init__(self, number: int, position_ids_offset)

  L 550: __repr__(self)


CLASS: SglFunction
----------------------------------------
  L 139: __init__(self, func, num_api_spec_tokens, bind_arguments)

  L 151: bind(self)

  L 157: run(self)

  L 216: run_batch(self, batch_kwargs)

  L 293: trace(self)

  L 299: cache(self, backend)

  L 305: compile(self)

  L 310: __call__(self)


CLASS: SglGen
----------------------------------------
  L 446: __init__(self, name: Optional[str], max_new_tokens: Optional[int], min_new_tokens: Optional[int], n: Optional[int], stop: Optional[Union[str, List[str]]], stop_token_ids: Optional[List[int]], temperature: Optional[float], top_p: Optional[float], top_k: Optional[int], min_p: Optional[float], frequency_penalty: Optional[float], presence_penalty: Optional[float], ignore_eos: Optional[bool], return_logprob: Optional[bool], logprob_start_len: Optional[int], top_logprobs_num: Optional[int], return_text_in_logprobs: Optional[bool], dtype: Optional[type], regex: Optional[str], json_schema: Optional[str])
         üìù Call the model to generate. See the meaning of the arguments in docs/backend/sampling_params.md

  L 494: __repr__(self)


CLASS: SglGetForkItem
----------------------------------------
  L 558: __init__(self, index: int)

  L 562: __repr__(self)


CLASS: SglImage
----------------------------------------
  L 429: __init__(self, path: str)

  L 432: __repr__(self)
         ‚Üí str


CLASS: SglRoleBegin
----------------------------------------
  L 508: __init__(self, role: str)

  L 512: __repr__(self)


CLASS: SglRoleEnd
----------------------------------------
  L 517: __init__(self, role: str)

  L 521: __repr__(self)


CLASS: SglSamplingParams
----------------------------------------
  L  41: clone(self)

  L  62: to_openai_kwargs(self)

  L  77: to_vertexai_kwargs(self)

  L  91: to_anthropic_kwargs(self)

  L 107: to_litellm_kwargs(self)

  L 119: to_srt_kwargs(self)


CLASS: SglSelect
----------------------------------------
  L 527: __init__(self, name: str, choices: List[str], temperature: float, choices_method: ChoicesSamplingMethod)

  L 540: __repr__(self)


CLASS: SglSeparateReasoning
----------------------------------------
  L 612: __init__(self, model_type: str, expr: SglExpr)

  L 620: process_name_for_reasoning(self, name)

  L 634: __repr__(self)


CLASS: SglVarScopeBegin
----------------------------------------
  L 577: __init__(self, name: str)

  L 581: __repr__(self)


CLASS: SglVarScopeEnd
----------------------------------------
  L 586: __init__(self, name: str)

  L 590: __repr__(self)


CLASS: SglVariable
----------------------------------------
  L 567: __init__(self, name: str, source)

  L 572: __repr__(self)


CLASS: SglVideo
----------------------------------------
  L 437: __init__(self, path: str, num_frames: int)

  L 441: __repr__(self)
         ‚Üí str


============================================================
FILE: python/sglang/lang/tracer.py
Functions: 13
============================================================

MODULE FUNCTIONS:
----------------------------------------
  L  29: def extract_prefix_by_tracing(program, backend)

  L  54: def trace_program(program, arguments, backend)


CLASS: TracerProgramState
----------------------------------------
  L  76: __init__(self, backend, arguments, only_trace_prefix)

  L 108: fork(self, size: int, position_ids_offset: Optional[List[int]])

  L 175: __iadd__(self, other)

  L 232: get_var(self, name)

  L 240: flatten_nodes(self)

  L 253: __del__(self)


CLASS: TracingScope
----------------------------------------
  L 260: __init__(self, tracer_state: TracerProgramState)

  L 264: __enter__(self)

  L 268: __exit__(self, exc_type, exc_value, traceback)

  L 272: get_current_scope()

  L 275: add_child_state(self, state: TracerProgramState)


============================================================
FILE: python/sglang/profiler.py
Functions: 1
============================================================

MODULE FUNCTIONS:
----------------------------------------
  L  72: def run_profile(url: Optional[str],
        num_steps: int,
        activities: List[str],
        output_dir: Optional[str],
        profile_name: Optional[str],
        profile_by_stage: bool)


============================================================
FILE: python/sglang/srt/_custom_ops.py
Functions: 26
============================================================

MODULE FUNCTIONS:
----------------------------------------
  L  35: def init_custom_ar(ipc_tensors: List[torch.Tensor],
        rank_data: torch.Tensor,
        rank: int,
        full_nvlink: bool)
         ‚Üí int

  L  43: def all_reduce(fa: int,
        inp: torch.Tensor,
        out: torch.Tensor,
        reg_buffer: int,
        reg_buffer_sz_bytes: int)
         ‚Üí None

  L  52: def dispose(fa: int)
         ‚Üí None

  L  55: def meta_size()
         ‚Üí int

  L  58: def register_buffer(fa: int, ipc_tensors: List[int])
         ‚Üí None

  L  61: def get_graph_buffer_ipc_meta(fa: int)
         ‚Üí Tuple[List[int], List[int]]

  L  64: def register_graph_buffers(fa: int,
        handles: List[List[int]],
        offsets: List[List[int]])
         ‚Üí None

  L  72: def init_custom_ar(meta: torch.Tensor,
        rank_data: torch.Tensor,
        handles: List[str],
        offsets: List[int],
        rank: int,
        full_nvlink: bool)
         ‚Üí int

  L  84: def all_reduce_reg(fa: int, inp: torch.Tensor, out: torch.Tensor)
         ‚Üí None

  L  87: def all_reduce_unreg(fa: int,
        inp: torch.Tensor,
        reg_buffer: torch.Tensor,
        out: torch.Tensor)
         ‚Üí None

  L  92: def dispose(fa: int)
         ‚Üí None

  L  95: def meta_size()
         ‚Üí int

  L  98: def register_buffer(fa: int,
        t: torch.Tensor,
        handles: List[str],
        offsets: List[int])
         ‚Üí None

  L 103: def get_graph_buffer_ipc_meta(fa: int)
         ‚Üí Tuple[torch.Tensor, List[int]]

  L 106: def register_graph_buffers(fa: int,
        handles: List[str],
        offsets: List[List[int]])
         ‚Üí None

  L 111: def allocate_meta_buffer(size: int)
         ‚Üí torch.Tensor

  L 114: def get_meta_buffer_ipc_handle(inp: torch.Tensor)
         ‚Üí torch.Tensor

  L 119: def init_custom_qr(rank: int, world_size: int, qr_max_size: Optional[int])
         ‚Üí int

  L 124: def qr_get_handle(fa: int)
         ‚Üí torch.Tensor

  L 127: def qr_open_handles(fa: int, handles: list[torch.Tensor])
         ‚Üí None

  L 130: def qr_all_reduce(fa: int,
        inp: torch.Tensor,
        out: torch.Tensor,
        quant_level: int,
        cast_bf2half: bool)
         ‚Üí None

  L 139: def qr_destroy(fa: int)
         ‚Üí None

  L 142: def qr_max_size()
         ‚Üí int

  L 146: def mscclpp_generate_unique_id()
         ‚Üí bytes

  L 150: def mscclpp_init_context(unique_id: bytes,
        rank: int,
        world_size: int,
        scratch: torch.Tensor,
        put_buffer: torch.Tensor,
        nranks_per_node: int,
        rank_to_node: List[int],
        rank_to_ib: List[int],
        context_selection: int)
         ‚Üí int

  L 174: def mscclpp_allreduce(context: int,
        inp: torch.Tensor,
        out: torch.Tensor,
        nthreads: int,
        nblocks: int)
         ‚Üí None


============================================================
FILE: python/sglang/srt/aio_rwlock.py
Functions: 13
============================================================


CLASS: RWLock
----------------------------------------
  L   5: __init__(self)

  L  22: reader_lock(self)
         üìù A context manager for acquiring a shared (reader) lock.
            Example:
            async with rwlock.reader_lock:
            # read-only access

  L  33: writer_lock(self)
         üìù A context manager for acquiring an exclusive (writer) lock.
            Example:
            async with rwlock.writer_lock:
            # exclusive access

  L  43: acquire_reader(self)

  L  51: release_reader(self)

  L  59: acquire_writer(self)

  L  72: release_writer(self)


CLASS: _ReaderLock
----------------------------------------
  L  80: __init__(self, rwlock: RWLock)

  L  83: __aenter__(self)

  L  87: __aexit__(self, exc_type, exc_val, exc_tb)


CLASS: _WriterLock
----------------------------------------
  L  92: __init__(self, rwlock: RWLock)

  L  95: __aenter__(self)

  L  99: __aexit__(self, exc_type, exc_val, exc_tb)


============================================================
FILE: python/sglang/srt/bench_utils.py
Functions: 3
============================================================

MODULE FUNCTIONS:
----------------------------------------
  L  45: def bench_kineto(fn,
        kernel_names,
        num_tests: int,
        suppress_kineto_output: bool,
        trace_path: str,
        flush_l2: bool,
        with_multiple_kernels: bool)


CLASS: suppress_stdout_stderr
----------------------------------------
  L  10: __enter__(self)

  L  30: __exit__(self)


============================================================
FILE: python/sglang/srt/code_completion_parser.py
Functions: 5
============================================================

MODULE FUNCTIONS:
----------------------------------------
  L  58: def register_completion_template(template: CompletionTemplate, override: bool)
         üìù Register a new completion template.

  L  68: def completion_template_exists(template_name: str)
         ‚Üí bool

  L  72: def is_completion_template_defined()
         ‚Üí bool

  L  77: def generate_completion_prompt_from_request(request: CompletionRequest)
         ‚Üí str

  L  87: def generate_completion_prompt(prompt: str, suffix: str, template_name: str)
         ‚Üí str


============================================================
FILE: python/sglang/srt/configs/chatglm.py
Functions: 1
============================================================


CLASS: ChatGLMConfig
----------------------------------------
  L  19: __init__(self, num_layers, padded_vocab_size, hidden_size, ffn_hidden_size, kv_channels, num_attention_heads, seq_length, hidden_dropout, attention_dropout, layernorm_epsilon, rmsnorm, apply_residual_connection_post_layernorm, post_layer_norm, add_bias_linear, add_qkv_bias, interleaved_qkv, bias_dropout_fusion, multi_query_attention, multi_query_group_num, apply_query_key_layer_scaling, attention_softmax_in_fp32, fp32_residual_connection, quantization_bit, pre_seq_len, prefix_projection)


============================================================
FILE: python/sglang/srt/configs/dbrx.py
Functions: 5
============================================================


CLASS: DbrxAttentionConfig
----------------------------------------
  L  34: __init__(self, attn_pdrop: float, clip_qkv: Optional[float], kv_n_heads: int, rope_theta: float)

  L  55: from_pretrained(cls, pretrained_model_name_or_path: str)
         ‚Üí 'PretrainedConfig'


CLASS: DbrxConfig
----------------------------------------
  L 229: __init__(self, d_model: int, n_heads: int, n_layers: int, max_seq_len: int, vocab_size: int, resid_pdrop: float, emb_pdrop: float, attn_config: Optional[DbrxAttentionConfig], ffn_config: Optional[DbrxFFNConfig], use_cache: bool, initializer_range: float, output_router_logits: bool, router_aux_loss_coef: float)


CLASS: DbrxFFNConfig
----------------------------------------
  L 106: __init__(self, ffn_act_fn: Optional[dict], ffn_hidden_size: int, moe_num_experts: int, moe_top_k: int, moe_jitter_eps: Optional[float], moe_loss_weight: float, moe_normalize_expert_weights: Optional[float], uniform_expert_assignment: bool)

  L 137: from_pretrained(cls, pretrained_model_name_or_path: str)
         ‚Üí 'PretrainedConfig'


============================================================
FILE: python/sglang/srt/configs/deepseekvl2.py
Functions: 24
============================================================

MODULE FUNCTIONS:
----------------------------------------
  L  16: def select_best_resolution(image_size, candidate_resolutions)


CLASS: DeepseekV2Config
----------------------------------------
  L 555: __init__(self, vocab_size, hidden_size, intermediate_size, moe_intermediate_size, num_hidden_layers, num_attention_heads, num_key_value_heads, n_shared_experts, n_routed_experts, ep_size, routed_scaling_factor, kv_lora_rank, q_lora_rank, qk_rope_head_dim, v_head_dim, qk_nope_head_dim, topk_method, n_group, topk_group, num_experts_per_tok, moe_layer_freq, first_k_dense_replace, norm_topk_prob, scoring_func, aux_loss_alpha, seq_aux, hidden_act, max_position_embeddings, initializer_range, rms_norm_eps, use_cache, pad_token_id, bos_token_id, eos_token_id, pretraining_tp, tie_word_embeddings, rope_theta, rope_scaling, attention_bias, attention_dropout, use_mla)


CLASS: DeepseekVL2Config
----------------------------------------
  L 661: __init__(self, tile_tag: str, global_view_pos: str, candidate_resolutions: Tuple[Tuple[int, int]])


CLASS: DeepseekVL2MlpProjectorConfig
----------------------------------------
  L 530: __init__(self, projector_type: str, input_dim: int, n_embed: int, depth: int, mlp_ratio: int, downsample_ratio: int)


CLASS: DeepseekVL2VisionEncoderConfig
----------------------------------------
  L 488: __init__(self, model_name: str, image_size: int, patch_size: int, width: int, layers: int, heads: int, mlp_ratio: int, global_pool: str, ignore_head: bool, class_token: bool, num_classes: int, use_checkpoint: bool)


CLASS: DeepseekVLV2Processor
----------------------------------------
  L 112: __init__(self, tokenizer: LlamaTokenizerFast, candidate_resolutions: Tuple[Tuple[int, int]], patch_size: int, downsample_ratio: int, image_mean: Tuple[float, float, float], image_std: Tuple[float, float, float], normalize: bool, image_token: str, pad_token: str, add_special_token: bool, sft_format: str, mask_prompt: bool, ignore_id: int)

  L 180: format_messages_v2(self, messages, pil_images, max_req_input_len)
         üìù play the role of format_messages_v2 and get_images_info in the last version

  L 222: bos_id(self)

  L 226: eos_id(self)

  L 230: pad_id(self)

  L 233: encode(self, text: str, bos: bool, eos: bool)

  L 243: decode(self, t: List[int])
         ‚Üí str

  L 246: process_one(self, prompt: str, conversations: List[Dict[str, str]], images: List[Image.Image], apply_sft_format: bool, inference_mode: bool, system_prompt: str, max_req_input_len: int)
         üìù Args:
            prompt (str): the formatted prompt;
            conversations (List[Dict]): conversations with a list of messages;
            images (List[ImageType]): the list of images;
            apply_sft_format (bool): if prompt is not None, then apply the SFT format to prompt;
            if conversations is not None, then it will always apply the SFT format to conversations;
            inference_mode (bool): if True, then remove the last eos token;
            system_prompt (str): the system prompt;
            **kwargs:
            Returns:
            outputs (BaseProcessorOutput): the output of the processor,
            - input_ids (torch.LongTensor): [N + image tokens]
            - target_ids (torch.LongTensor): [N + image tokens]
            - images (torch.FloatTensor): [n_images, 3, H, W]
            - image_id (int): the id of the image token
            - num_image_tokens (List[int]): the number of image tokens

  L 334: __call__(self)

  L 358: find_all_indices(self, messages, target_value)

  L 365: tokenize_with_images(self, conversation: str, images: List[Image.Image], bos: bool, eos: bool, cropping: bool, max_req_input_len: int)
         üìù Tokenize text with <image> tags.


CLASS: DictOutput
----------------------------------------
  L  45: items(self)

  L  48: keys(self)

  L  51: __getitem__(self, item)

  L  54: __contains__(self, key)

  L  57: __setitem__(self, key, value)


CLASS: ImageTransform
----------------------------------------
  L  76: __init__(self, mean: Optional[Tuple[float, float, float]], std: Optional[Tuple[float, float, float]], normalize: bool)

  L 103: __call__(self, pil_img: Image.Image)


CLASS: VLChatProcessorOutput
----------------------------------------
  L  71: __len__(self)


============================================================
FILE: python/sglang/srt/configs/device_config.py
Functions: 1
============================================================


CLASS: DeviceConfig
----------------------------------------
  L  12: __init__(self, device: str)
         ‚Üí None


============================================================
FILE: python/sglang/srt/configs/exaone.py
Functions: 1
============================================================


CLASS: ExaoneConfig
----------------------------------------
  L 143: __init__(self, vocab_size, max_position_embeddings, hidden_size, num_layers, num_attention_heads, num_key_value_heads, intermediate_size, activation_function, rope_theta, rope_scaling, embed_dropout, attention_dropout, layer_norm_epsilon, initializer_range, use_cache, bos_token_id, eos_token_id, tie_word_embeddings)


============================================================
FILE: python/sglang/srt/configs/internvl.py
Functions: 16
============================================================


CLASS: InternLM2Config
----------------------------------------
  L  78: __init__(self, vocab_size, hidden_size, intermediate_size, num_hidden_layers, num_attention_heads, num_key_value_heads, hidden_act, max_position_embeddings, initializer_range, rms_norm_eps, use_cache, pad_token_id, bos_token_id, eos_token_id, tie_word_embeddings, bias, rope_theta, rope_scaling, attn_implementation)


CLASS: InternLM2Tokenizer
----------------------------------------
  L 494: __init__(self, vocab_file, unk_token, bos_token, eos_token, pad_token, sp_model_kwargs: Optional[Dict[str, Any]], add_bos_token, add_eos_token, decode_with_prefix_space, clean_up_tokenization_spaces)

  L 527: no_prefix_space_tokens(self)

  L 536: vocab_size(self)
         üìù Returns vocab size

  L 541: bos_token_id(self)
         ‚Üí Optional[int]

  L 545: eos_token_id(self)
         ‚Üí Optional[int]

  L 548: get_vocab(self)
         üìù Returns vocab as a dict

  L 573: convert_tokens_to_string(self, tokens)
         üìù Converts a sequence of tokens (string) in a single string.

  L 594: save_vocabulary(self, save_directory, filename_prefix: Optional[str])
         ‚Üí Tuple[str]
         üìù Save the vocabulary and special tokens file to a directory.
            Args:
            save_directory (`str`):
            The directory in which to save the vocabulary.
            Returns:
            `Tuple(str)`: Paths to the files saved.

  L 627: build_inputs_with_special_tokens(self, token_ids_0, token_ids_1)

  L 643: get_special_tokens_mask(self, token_ids_0: List[int], token_ids_1: Optional[List[int]], already_has_special_tokens: bool)
         ‚Üí List[int]
         üìù Retrieve sequence ids from a token list that has no special tokens added. This method is called when adding
            special tokens using the tokenizer `prepare_for_model` method.
            Args:
            token_ids_0 (`List[int]`):
            List of IDs.
            token_ids_1 (`List[int]`, *optional*):
            Optional second list of IDs for sequence pairs.
            already_has_special_tokens (`bool`, *optional*, defaults to `False`):
            Whether or not the token list is already formatted with special tokens for the model.
            Returns:
            `List[int]`: A list of integers in the range [0, 1]: 1 for a special token, 0 for a sequence token.

  L 675: create_token_type_ids_from_sequences(self, token_ids_0: List[int], token_ids_1: Optional[List[int]])
         ‚Üí List[int]
         üìù Create a mask from the two sequences passed to be used in a sequence-pair classification task. T5 does not make
            use of token type ids, therefore a list of zeros is returned.
            Args:
            token_ids_0 (`List[int]`):
            List of IDs.
            token_ids_1 (`List[int]`, *optional*):
            Optional second list of IDs for sequence pairs.
            Returns:
            `List[int]`: List of zeros.


CLASS: InternVLChatConfig
----------------------------------------
  L 279: __init__(self, vision_config, llm_config, use_backbone_lora, use_llm_lora, pad2square, select_layer, force_image_size, downsample_ratio, template, dynamic_image_size, use_thumbnail, ps_version, min_dynamic_patch, max_dynamic_patch)

  L 345: to_dict(self)
         üìù Serializes this instance to a Python dictionary. Override the default [`~PretrainedConfig.to_dict`].
            Returns:
            `Dict[str, any]`: Dictionary of all the attributes that make up this configuration instance,


CLASS: InternVisionConfig
----------------------------------------
  L 210: __init__(self, num_channels, patch_size, image_size, qkv_bias, hidden_size, num_attention_heads, intermediate_size, qk_normalization, num_hidden_layers, use_flash_attn, hidden_act, layer_norm_eps, dropout, drop_path_rate, attention_dropout, initializer_range, initializer_factor)

  L 252: from_pretrained(cls, pretrained_model_name_or_path: Union[str, os.PathLike])
         ‚Üí 'PretrainedConfig'


============================================================
FILE: python/sglang/srt/configs/janus_pro.py
Functions: 30
============================================================


CLASS: AlignerConfig
----------------------------------------
  L  85: __init__(self)


CLASS: DictOutput
----------------------------------------
  L 287: items(self)

  L 290: keys(self)

  L 293: __getitem__(self, item)

  L 296: __contains__(self, key)

  L 299: __setitem__(self, key, value)


CLASS: DictToObject
----------------------------------------
  L  26: __init__(self, dictionary)


CLASS: GenAlignerConfig
----------------------------------------
  L  55: __init__(self)


CLASS: GenHeadConfig
----------------------------------------
  L  70: __init__(self)


CLASS: GenVisionConfig
----------------------------------------
  L 100: __init__(self)


CLASS: MultiModalityConfig
----------------------------------------
  L 135: __init__(self)


CLASS: VLChatProcessor
----------------------------------------
  L 332: __init__(self, image_processor: VLMImageProcessor, tokenizer: LlamaTokenizerFast, image_tag: str, image_start_tag: str, image_end_tag: str, pad_tag: str, num_image_tokens: int, add_special_token: bool, sft_format: str, mask_prompt: bool, ignore_id: int)

  L 374: image_token(self)

  L 378: image_id(self)
         ‚Üí int

  L 383: image_start_id(self)

  L 388: image_end_id(self)

  L 393: image_start_token(self)

  L 397: image_end_token(self)

  L 401: pad_id(self)

  L 405: add_image_token(self, image_indices: List[int], input_ids: torch.LongTensor)
         üìù Args:
            image_indices (List[int]): [index_0, index_1, ..., index_j]
            input_ids (torch.LongTensor): [N]
            Returns:
            input_ids (torch.LongTensor): [N + image tokens]
            num_image_tokens (torch.IntTensor): [n_images]

  L 450: process_one(self, prompt: str, images: List[Image])
         üìù Args:
            prompt (str): the formatted prompt;
            images (List[ImageType]): the list of images;
            **kwargs:
            Returns:
            outputs (BaseProcessorOutput): the output of the processor,
            - input_ids (torch.LongTensor): [N + image tokens]
            - target_ids (torch.LongTensor): [N + image tokens]
            - images (torch.FloatTensor): [n_images, 3, H, W]
            - image_id (int): the id of the image token
            - num_image_tokens (List[int]): the number of image tokens

  L 497: __call__(self)
         üìù Args:
            prompt (str): the formatted prompt;
            conversations (List[Dict]): conversations with a list of messages;
            images (List[ImageType]): the list of images;
            force_batchify (bool): force batchify the inputs;
            **kwargs:
            Returns:
            outputs (BaseProcessorOutput): the output of the processor,
            - input_ids (torch.LongTensor): [N + image tokens]
            - images (torch.FloatTensor): [n_images, 3, H, W]
            - image_id (int): the id of the image token
            - num_image_tokens (List[int]): the number of image tokens

  L 532: batchify(self, prepare_list: List[VLChatProcessorOutput])
         ‚Üí BatchedVLChatProcessorOutput
         üìù Preprocesses the inputs for multimodal inference.
            Args:
            prepare_list (List[VLChatProcessorOutput]): A list of VLChatProcessorOutput.
            Returns:
            BatchedVLChatProcessorOutput: A dictionary of the inputs to use for multimodal inference.


CLASS: VLChatProcessorOutput
----------------------------------------
  L 310: __len__(self)


CLASS: VLMImageProcessor
----------------------------------------
  L 162: __init__(self, image_size: int, min_size: int, image_mean: Union[Tuple[float, float, float], List[float]], image_std: Union[Tuple[float, float, float], List[float]], rescale_factor: float, do_normalize: bool)

  L 194: resize(self, pil_img: Image)
         ‚Üí np.ndarray
         üìù Args:
            pil_img (PIL.Image): [H, W, 3] in PIL.Image in RGB
            Returns:
            x (np.ndarray): [3, self.image_size, self.image_size]

  L 249: preprocess(self, images, return_tensors: str)
         ‚Üí BatchFeature

  L 282: default_shape(self)


CLASS: VLMImageProcessorConfig
----------------------------------------
  L 605: __init__(self, image_size: int, min_size: int, image_mean: Union[Tuple[float, float, float], List[float]], image_std: Union[Tuple[float, float, float], List[float]], rescale_factor: float, do_normalize: bool)


CLASS: VisionConfig
----------------------------------------
  L  40: __init__(self)


============================================================
FILE: python/sglang/srt/configs/kimi_vl.py
Functions: 1
============================================================


CLASS: KimiVLConfig
----------------------------------------
  L  14: __init__(self, vision_config: Optional[Union[dict, MoonViTConfig]], text_config: Optional[Union[dict, DeepseekV2Config]], ignore_index: int, media_placeholder_token_id: int, pad_token_id: int)


============================================================
FILE: python/sglang/srt/configs/kimi_vl_moonvit.py
Functions: 1
============================================================


CLASS: MoonViTConfig
----------------------------------------
  L   9: __init__(self, patch_size: int, init_pos_emb_height: int, init_pos_emb_width: int, num_attention_heads: int, num_hidden_layers: int, hidden_size: int, intermediate_size: int, merge_kernel_size: tuple[int, int])


============================================================
FILE: python/sglang/srt/configs/load_config.py
Functions: 1
============================================================


CLASS: LoadConfig
----------------------------------------
  L  57: __post_init__(self)


============================================================
FILE: python/sglang/srt/configs/longcat_flash.py
Functions: 1
============================================================


CLASS: LongcatFlashConfig
----------------------------------------
  L  13: __init__(self, vocab_size, hidden_size, intermediate_size, ffn_hidden_size, expert_ffn_hidden_size, num_layers, num_hidden_layers, num_attention_heads, ep_size, kv_lora_rank, q_lora_rank, qk_rope_head_dim, qk_nope_head_dim, v_head_dim, n_routed_experts, moe_topk, norm_topk_prob, max_position_embeddings, rms_norm_eps, use_cache, pad_token_id, bos_token_id, eos_token_id, pretraining_tp, tie_word_embeddings, rope_theta, rope_scaling, attention_bias, attention_dropout, mla_scale_q_lora, mla_scale_kv_lora, torch_dtype, params_dtype, rounter_params_dtype, router_bias, topk_method, routed_scaling_factor, zero_expert_num, zero_expert_type, nextn_use_scmoe, num_nextn_predict_layers)


============================================================
FILE: python/sglang/srt/configs/model_config.py
Functions: 18
============================================================

MODULE FUNCTIONS:
----------------------------------------
  L 659: def is_generation_model(model_architectures: List[str], is_embedding: bool)

  L 717: def is_multimodal_model(model_architectures: List[str])

  L 727: def is_multimodal_gen_model(model_architectures: List[str])

  L 731: def is_image_gen_model(model_architectures: List[str])

  L 735: def is_audio_model(model_architectures: List[str])

  L 739: def is_encoder_decoder_model(model_architectures: List[str])

  L 743: def is_multimodal_chunked_prefill_supported(model_architectures: List[str])
         üìù Check if chunked prefill is supported for a MultiModal model.

  L 758: def yarn_get_mscale(scale: float, mscale: float)
         ‚Üí float

  L 764: def is_hybrid_model(model_architectures: List[str],
        hybrid_kvcache_ratio: Optional[float],
        context_length: Optional[int],
        attention_chunk_size: Optional[int])

  L 782: def get_hybrid_layer_ids(model_architectures: List[str], num_hidden_layers: int)


CLASS: ModelConfig
----------------------------------------
  L  52: __init__(self, model_path: str, trust_remote_code: bool, revision: Optional[str], context_length: Optional[int], model_override_args: str, is_embedding: Optional[bool], enable_multimodal: Optional[bool], dtype: str, quantization: Optional[str], override_config_file: Optional[str], is_draft_model: bool, hybrid_kvcache_ratio: Optional[float], model_impl: Union[str, ModelImpl])
         ‚Üí None

  L 305: from_server_args(server_args: ServerArgs, model_path: str)

  L 321: get_total_num_attention_heads(self)
         ‚Üí int

  L 324: get_num_attention_heads(self, tensor_parallel_size)
         ‚Üí int

  L 329: get_total_num_kv_heads(self)
         ‚Üí int
         üìù Returns the total number of KV heads.

  L 392: get_num_kv_heads(self, tensor_parallel_size)
         ‚Üí int
         üìù Returns the number of KV heads per GPU.

  L 545: get_hf_eos_token_id(self)
         ‚Üí Optional[Set[int]]

  L 565: maybe_pull_model_tokenizer_from_remote(self)
         ‚Üí None
         üìù Pull the model config files to a temporary
            directory in case of remote.
            Args:
            model: The model name or path.


============================================================
FILE: python/sglang/srt/configs/step3_vl.py
Functions: 3
============================================================


CLASS: Step3TextConfig
----------------------------------------
  L  40: __init__(self, hidden_size: int, intermediate_size: int, num_attention_heads: int, num_attention_groups: int, num_hidden_layers: int, max_seq_len: int, vocab_size: int, rms_norm_eps: float, moe_intermediate_size: int, moe_num_experts: int, moe_top_k: int, rope_theta: float, rope_scaling: Optional[dict[str, Any]], max_position_embedding: int, share_expert_dim: int, share_q_dim: int, head_dim: int, norm_expert_weight: bool, moe_layers_enum: tuple[int])
         ‚Üí None


CLASS: Step3VLConfig
----------------------------------------
  L 146: __init__(self, vision_config: Optional[Union[dict, Step3VisionEncoderConfig]], text_config: Optional[Union[dict, Step3TextConfig]], understand_projector_stride: int, projector_bias: bool, image_token_id: int)
         ‚Üí None


CLASS: Step3VisionEncoderConfig
----------------------------------------
  L   9: __init__(self, hidden_size, intermediate_size, output_hidden_size, num_hidden_layers, num_attention_heads, num_channels, image_size, patch_size, hidden_act, layer_norm_eps)


============================================================
FILE: python/sglang/srt/configs/update_config.py
Functions: 5
============================================================

MODULE FUNCTIONS:
----------------------------------------
  L  13: def may_get_weight_block_size(model_config, load_config)

  L  29: def get_moe_padding_size(weight_block_size)

  L  44: def get_num_heads_padding_size(tp_size, weight_block_size)

  L  51: def update_intermediate_size(model_config, attr_name, intermediate_padding_size)

  L  74: def adjust_config_with_unaligned_cpu_tp(model_config: ModelConfig,
        load_config: LoadConfig,
        tp_size: int)
         ‚Üí ModelConfig


============================================================
FILE: python/sglang/srt/configs/utils.py
Functions: 2
============================================================

MODULE FUNCTIONS:
----------------------------------------
  L  12: def register_image_processor(config: Type[PretrainedConfig],
        image_processor: Type[BaseImageProcessor])
         üìù register customized hf image processor while removing hf impl

  L  21: def register_processor(config: Type[PretrainedConfig],
        processor: Type[ProcessorMixin])
         üìù register customized hf processor while removing hf impl


============================================================
FILE: python/sglang/srt/connector/__init__.py
Functions: 2
============================================================

MODULE FUNCTIONS:
----------------------------------------
  L  23: def create_remote_connector(url)
         ‚Üí BaseConnector

  L  33: def get_connector_type(client: BaseConnector)
         ‚Üí ConnectorType


============================================================
FILE: python/sglang/srt/connector/base_connector.py
Functions: 14
============================================================


CLASS: BaseConnector
----------------------------------------
  L  23: __init__(self, url: str)

  L  31: get_local_dir(self)

  L  35: weight_iterator(self, rank: int)
         ‚Üí Generator[Tuple[str, torch.Tensor], None, None]

  L  41: pull_files(self, allow_pattern: Optional[List[str]], ignore_pattern: Optional[List[str]])
         ‚Üí None

  L  48: close(self)

  L  56: __enter__(self)

  L  59: __exit__(self, exc_type, exc_value, traceback)

  L  62: __del__(self)


CLASS: BaseFileConnector
----------------------------------------
  L 110: glob(self, allow_pattern: str)
         ‚Üí List[str]


CLASS: BaseKVConnector
----------------------------------------
  L  78: get(self, key: str)
         ‚Üí Optional[torch.Tensor]

  L  82: getstr(self, key: str)
         ‚Üí Optional[str]

  L  86: set(self, key: str, obj: torch.Tensor)
         ‚Üí None

  L  90: setstr(self, key: str, obj: str)
         ‚Üí None

  L  94: list(self, prefix: str)
         ‚Üí List[str]


============================================================
FILE: python/sglang/srt/connector/redis.py
Functions: 9
============================================================


CLASS: RedisConnector
----------------------------------------
  L  18: __init__(self, url: str)

  L  28: get(self, key: str)
         ‚Üí Optional[torch.Tensor]

  L  37: getstr(self, key: str)
         ‚Üí Optional[str]

  L  45: set(self, key: str, tensor: torch.Tensor)
         ‚Üí None

  L  49: setstr(self, key: str, obj: str)
         ‚Üí None

  L  52: list(self, prefix: str)
         ‚Üí List[str]

  L  67: weight_iterator(self, rank: int)
         ‚Üí Generator[Tuple[str, bytes], None, None]

  L  76: pull_files(self, allow_pattern: Optional[List[str]], ignore_pattern: Optional[List[str]])
         ‚Üí None

  L  83: close(self)


============================================================
FILE: python/sglang/srt/connector/s3.py
Functions: 6
============================================================

MODULE FUNCTIONS:
----------------------------------------
  L  29: def list_files(s3,
        path: str,
        allow_pattern: Optional[list[str]],
        ignore_pattern: Optional[list[str]])
         ‚Üí tuple[str, str, list[str]]
         üìù List files from S3 path and filter by pattern.
            Args:
            s3: S3 client to use.
            path: The S3 path to list from.
            allow_pattern: A list of patterns of which files to pull.
            ignore_pattern: A list of patterns of which files not to pull.
            Returns:
            tuple[str, str, list[str]]: A tuple where:
            - The first element is the bucket name
            - The second element is string represent the bucket
            and the prefix as a dir like string
            - The third element is a list of files allowed or
            disallowed by pattern


CLASS: S3Connector
----------------------------------------
  L  71: __init__(self, url: str)
         ‚Üí None

  L  77: glob(self, allow_pattern: Optional[list[str]])
         ‚Üí list[str]

  L  83: pull_files(self, allow_pattern: Optional[list[str]], ignore_pattern: Optional[list[str]])
         ‚Üí None
         üìù Pull files from S3 storage into the temporary directory.
            Args:
            s3_model_path: The S3 path of the model.
            allow_pattern: A list of patterns of which files to pull.
            ignore_pattern: A list of patterns of which files not to pull.

  L 109: weight_iterator(self, rank: int)
         ‚Üí Generator[Tuple[str, torch.Tensor], None, None]

  L 120: close(self)


============================================================
FILE: python/sglang/srt/connector/serde/__init__.py
Functions: 1
============================================================

MODULE FUNCTIONS:
----------------------------------------
  L  12: def create_serde(serde_type: str)
         ‚Üí Tuple[Serializer, Deserializer]


============================================================
FILE: python/sglang/srt/connector/serde/safe_serde.py
Functions: 5
============================================================


CLASS: SafeDeserializer
----------------------------------------
  L  22: __init__(self)

  L  26: from_bytes_normal(self, b: Union[bytearray, bytes])
         ‚Üí torch.Tensor

  L  29: from_bytes(self, b: Union[bytearray, bytes])
         ‚Üí torch.Tensor


CLASS: SafeSerializer
----------------------------------------
  L  13: __init__(self)

  L  16: to_bytes(self, t: torch.Tensor)
         ‚Üí bytes


============================================================
FILE: python/sglang/srt/connector/serde/serde.py
Functions: 3
============================================================


CLASS: Deserializer
----------------------------------------
  L  29: __init__(self, dtype)

  L  33: from_bytes(self, bs: bytes)
         ‚Üí torch.Tensor
         üìù Deserialize a pytorch tensor from bytes.
            Input:
            bytes: a stream of bytes
            Output:
            torch.Tensor: the deserialized pytorch tensor


CLASS: Serializer
----------------------------------------
  L  12: to_bytes(self, t: torch.Tensor)
         ‚Üí bytes
         üìù Serialize a pytorch tensor to bytes. The serialized bytes should contain
            both the data and the metadata (shape, dtype, etc.) of the tensor.
            Input:
            t: the input pytorch tensor, can be on any device, in any shape,
            with any dtype
            Returns:
            bytes: the serialized bytes


============================================================
FILE: python/sglang/srt/connector/utils.py
Functions: 2
============================================================

MODULE FUNCTIONS:
----------------------------------------
  L  11: def parse_model_name(url: str)
         ‚Üí str
         üìù Parse the model name from the url.
            Only used for db connector

  L  20: def pull_files_from_db(connector: BaseConnector,
        model_name: str,
        allow_pattern: Optional[list[str]],
        ignore_pattern: Optional[list[str]])
         ‚Üí None


============================================================
FILE: python/sglang/srt/constrained/base_grammar_backend.py
Functions: 24
============================================================

MODULE FUNCTIONS:
----------------------------------------
  L 170: def create_grammar_backend(server_args: ServerArgs,
        tokenizer,
        vocab_size: int,
        eos_token_ids: Optional[set])
         ‚Üí Optional[BaseGrammarBackend]


CLASS: BaseGrammarBackend
----------------------------------------
  L 112: __init__(self)

  L 119: dispatch_fallback(self, key_type: str, key_string: str)
         ‚Üí Optional[BaseGrammarObject]
         üìù This function should not be reached in any case.

  L 127: dispatch_json(self, key_string: str)
         ‚Üí Optional[BaseGrammarObject]

  L 130: dispatch_regex(self, key_string: str)
         ‚Üí Optional[BaseGrammarObject]

  L 133: dispatch_ebnf(self, key_string: str)
         ‚Üí Optional[BaseGrammarObject]

  L 136: dispatch_structural_tag(self, key_string: str)
         ‚Üí Optional[BaseGrammarObject]

  L 154: get_cached_or_future_value(self, key: Tuple[str, str])
         ‚Üí Optional[BaseGrammarObject]

  L 163: set_cache(self, key: Tuple[str, str], value: BaseGrammarObject)

  L 166: reset(self)


CLASS: BaseGrammarObject
----------------------------------------
  L  31: __init__(self)

  L  34: accept_token(self, token: int)
         ‚Üí None
         üìù Accept a token in the grammar.

  L  40: rollback(self, k: int)

  L  43: is_terminated(self)

  L  46: allocate_vocab_mask(self, vocab_size: int, batch_size: int, device)
         ‚Üí torch.Tensor

  L  51: fill_vocab_mask(self, vocab_mask: torch.Tensor, idx: int)
         ‚Üí None

  L  55: move_vocab_mask(vocab_mask: torch.Tensor, device)
         ‚Üí torch.Tensor

  L  59: apply_vocab_mask(logits: torch.Tensor, vocab_mask: torch.Tensor)
         ‚Üí None

  L  62: copy(self)
         ‚Üí 'BaseGrammarObject'

  L  66: finished(self)

  L  70: finished(self, finished)

  L  73: try_jump_forward(self, tokenizer)
         ‚Üí Optional[Tuple[List[int], str]]
         üìù Try to jump forward in the grammar.
            Returns:
            A jump forward helper which may be used in `jump_forward_str_state`.
            None if the jump forward is not possible.

  L  83: jump_forward_str_state(self, helper: Tuple[List[int], str])
         ‚Üí Tuple[str, int]
         üìù Jump forward for the grammar.
            Returns:
            A tuple of the jump forward string and the next state of the grammar
            (which can be used in `jump_and_retokenize` if needed).

  L  93: jump_and_retokenize(self, old_output_ids: List[int], new_output_ids: List[int], next_state: int)
         ‚Üí None
         üìù Jump forward occurs, and update the grammar state if needed.


============================================================
FILE: python/sglang/srt/constrained/llguidance_backend.py
Functions: 15
============================================================


CLASS: GuidanceBackend
----------------------------------------
  L 111: __init__(self, tokenizer, whitespace_pattern: Optional[str], n_vocab: Optional[int])

  L 133: dispatch_json(self, key_string: str)
         ‚Üí Optional[GuidanceGrammar]

  L 146: dispatch_regex(self, key_string: str)
         ‚Üí Optional[GuidanceGrammar]

  L 150: dispatch_ebnf(self, key_string: str)
         ‚Üí Optional[GuidanceGrammar]

  L 158: dispatch_structural_tag(self, key_string: str)
         ‚Üí Optional[GuidanceGrammar]


CLASS: GuidanceGrammar
----------------------------------------
  L  41: __init__(self, llguidance_tokenizer: LLTokenizer, serialized_grammar: str)

  L  54: accept_token(self, token: int)

  L  59: fill_vocab_mask(self, vocab_mask: torch.Tensor, idx: int)
         ‚Üí None

  L  65: allocate_vocab_mask(self, vocab_size: int, batch_size: int, device)
         ‚Üí torch.Tensor

  L  80: move_vocab_mask(vocab_mask: torch.Tensor, device)
         ‚Üí torch.Tensor

  L  84: apply_vocab_mask(logits: torch.Tensor, vocab_mask: torch.Tensor)
         ‚Üí None

  L  87: copy(self)

  L  93: try_jump_forward(self, tokenizer)
         ‚Üí Optional[Tuple[List[int], str]]

  L 100: jump_forward_str_state(self, helper: Tuple[List[int], str])
         ‚Üí Tuple[str, int]

  L 103: jump_and_retokenize(self, old_output_ids: List[int], new_output_ids: List[int], next_state: int)


============================================================
FILE: python/sglang/srt/constrained/outlines_backend.py
Functions: 16
============================================================

MODULE FUNCTIONS:
----------------------------------------
  L 182: def build_regex_from_object(object: Union[str,
        BaseModel,
        Dict],
        whitespace_pattern: Optional[str])


CLASS: OutlinesGrammar
----------------------------------------
  L  43: __init__(self, guide: RegexGuide, jump_forward_map: Union[OutlinesJumpForwardMap, None])
         ‚Üí None

  L  54: accept_token(self, token: int)

  L  57: allocate_vocab_mask(self, vocab_size: int, batch_size: int, device)
         ‚Üí torch.Tensor

  L  63: move_vocab_mask(vocab_mask: torch.Tensor, device)
         ‚Üí torch.Tensor

  L  66: fill_vocab_mask(self, vocab_mask: torch.Tensor, idx: int)
         ‚Üí None

  L  75: apply_vocab_mask(logits: torch.Tensor, vocab_mask: torch.Tensor)

  L  78: copy(self)

  L  81: try_jump_forward(self, tokenizer)
         ‚Üí Optional[Tuple]

  L 105: jump_forward_str_state(self, helper: Tuple[List[int], str])
         ‚Üí Tuple[str, int]

  L 109: jump_and_retokenize(self, old_output_ids: List[int], new_output_ids: List[int], next_state: int)


CLASS: OutlinesGrammarBackend
----------------------------------------
  L 116: __init__(self, tokenizer, whitespace_pattern: bool)

  L 161: dispatch_ebnf(self, key_string: str)

  L 164: dispatch_structural_tag(self, key_string: str)

  L 167: dispatch_json(self, key_string: str)

  L 178: dispatch_regex(self, key_string: str)


============================================================
FILE: python/sglang/srt/constrained/outlines_jump_forward.py
Functions: 7
============================================================

MODULE FUNCTIONS:
----------------------------------------
  L  54: def disk_cache(expire: Optional[float], typed, ignore)

  L  62: def init_state_to_jump_forward(regex_string)
         @disk_cache()

  L 181: def test_main(regex_string)


CLASS: OutlinesJumpForwardMap
----------------------------------------
  L 143: __init__(self, regex_string)

  L 146: jump_forward_symbol(self, state)

  L 159: jump_forward_byte(self, state)

  L 174: is_jump_forward_symbol_state(self, state)


============================================================
FILE: python/sglang/srt/constrained/reasoner_grammar_backend.py
Functions: 13
============================================================


CLASS: ReasonerGrammarBackend
----------------------------------------
  L  79: __init__(self, grammar_backend: BaseGrammarBackend, think_end_id)


CLASS: ReasonerGrammarObject
----------------------------------------
  L  24: __init__(self, grammar: BaseGrammarObject, think_end_id)

  L  30: accept_token(self, token: int)

  L  37: allocate_vocab_mask(self, vocab_size: int, batch_size: int, device)
         ‚Üí torch.Tensor

  L  42: fill_vocab_mask(self, vocab_mask: torch.Tensor, idx: int)
         ‚Üí None

  L  46: move_vocab_mask(self, vocab_mask: torch.Tensor, device)
         ‚Üí torch.Tensor

  L  50: apply_vocab_mask(self)

  L  53: copy(self)
         ‚Üí BaseGrammarObject

  L  57: finished(self)

  L  61: finished(self, finished)

  L  64: try_jump_forward(self, tokenizer)

  L  67: jump_forward_str_state(self, helper)

  L  70: jump_and_retokenize(self, old_output_ids: List[int], new_output_ids: List[int], next_state: int)


============================================================
FILE: python/sglang/srt/constrained/triton_ops/bitmask_ops.py
Functions: 2
============================================================

MODULE FUNCTIONS:
----------------------------------------
  L  14: def apply_token_bitmask_inplace_kernel(logits_ptr,
        bitmask_ptr,
        indices_ptr,
        num_rows,
        vocab_size,
        logits_strides,
        bitmask_strides,
        NUM_SMS: tl.constexpr,
        BLOCK_SIZE: tl.constexpr)
         üìù Apply a bitmask to logits in-place using Triton. The bitmask is a 01 bitwise compressed tensor,
            where 0 means the token is masked and 1 means the token is not masked. After applying the bitmask,
            the masked logits will be set to -inf.
            Parameters
            ----------
            logits_ptr : tl.tensor
            Pointer to the logits tensor to apply the bitmask to.
            bitmask_ptr : tl.tensor
            Pointer to the bitmask tensor to apply.
            indices_ptr : Optional[tl.tensor]
            Optional pointer to indices tensor specifying which rows to apply the mask to.
            num_rows : int
            Number of rows to process. If indices_ptr is provided, this is the number of unique indices.
            vocab_size : int
            Size of the vocabulary dimension. If the logits does not have a vocab padding, this is the
            same as the logits's second dimension. Otherwise, this is the actual size of the vocabulary.
            logits_strides : int
            Stride between rows in the logits tensor.
            bitmask_strides : int
            Stride between rows in the bitmask tensor.
            NUM_SMS : int
            Number of streaming multiprocessors to use.
            BLOCK_SIZE : int
            Size of processing blocks.
         @triton.jit

  L  84: def apply_token_bitmask_inplace_triton(logits: torch.Tensor,
        bitmask: torch.Tensor,
        indices: Optional[Union[List[int],
        torch.Tensor]])


============================================================
FILE: python/sglang/srt/constrained/xgrammar_backend.py
Functions: 19
============================================================


CLASS: XGrammarGrammar
----------------------------------------
  L  52: __init__(self, matcher: GrammarMatcher, vocab_size: int, ctx: CompiledGrammar, override_stop_tokens: Optional[Union[List[int], int]], key_string: Optional[str])
         ‚Üí None

  L  68: accept_token(self, token: int)

  L  81: rollback(self, k: int)

  L  85: is_terminated(self)

  L  88: allocate_vocab_mask(self, vocab_size: int, batch_size: int, device)
         ‚Üí torch.Tensor

  L  93: fill_vocab_mask(self, vocab_mask: torch.Tensor, idx: int)
         ‚Üí None

  L  97: move_vocab_mask(vocab_mask: torch.Tensor, device)
         ‚Üí torch.Tensor

  L 100: apply_vocab_mask(self, logits: torch.Tensor, vocab_mask: torch.Tensor)
         ‚Üí None

  L 111: copy(self)

  L 125: try_jump_forward(self, tokenizer)
         ‚Üí Optional[Tuple[List[int], str]]

  L 131: jump_forward_str_state(self, helper: Tuple[List[int], str])
         ‚Üí Tuple[str, int]

  L 135: jump_and_retokenize(self, old_output_ids: List[int], new_output_ids: List[int], next_state: int)

  L 152: __repr__(self)


CLASS: XGrammarGrammarBackend
----------------------------------------
  L 157: __init__(self, tokenizer, vocab_size: int, model_eos_token_ids: Optional[List[int]])

  L 190: dispatch_json(self, key_string: str)
         ‚Üí Optional[XGrammarGrammar]

  L 203: dispatch_ebnf(self, key_string: str)
         ‚Üí Optional[XGrammarGrammar]

  L 211: dispatch_regex(self, key_string: str)
         ‚Üí Optional[XGrammarGrammar]

  L 219: dispatch_structural_tag(self, key_string: str)
         ‚Üí Optional[XGrammarGrammar]

  L 238: reset(self)


============================================================
FILE: python/sglang/srt/conversation.py
Functions: 25
============================================================

MODULE FUNCTIONS:
----------------------------------------
  L 465: def register_conv_template(template: Conversation, override: bool)
         üìù Register a new conversation template.

  L 475: def register_conv_template_matching_function(func)

  L 479: def get_conv_template_by_model_path(model_path)

  L 487: def chat_template_exists(template_name: str)
         ‚Üí bool

  L 491: def generate_embedding_convs(texts: List[str],
        images: List[str],
        template_name: str)
         ‚Üí List[Conversation]

  L 559: def generate_chat_conv(request: ChatCompletionRequest, template_name: str)
         ‚Üí Conversation

  L 974: def get_model_type(model_path: str)
         ‚Üí Optional[str]

  L 987: def match_internvl(model_path: str)
         @register_conv_template_matching_function

  L 995: def match_deepseek_janus_pro(model_path: str)
         @register_conv_template_matching_function

  L1003: def match_vicuna(model_path: str)
         @register_conv_template_matching_function

  L1009: def match_deepseek_vl(model_path: str)
         @register_conv_template_matching_function

  L1017: def match_qwen_chat_ml(model_path: str)
         @register_conv_template_matching_function

  L1027: def match_minicpm(model_path: str)
         @register_conv_template_matching_function

  L1036: def match_phi_4_mm(model_path: str)
         @register_conv_template_matching_function


CLASS: Conversation
----------------------------------------
  L 105: get_prompt(self)
         ‚Üí str
         üìù Get the prompt for generation.

  L 380: set_system_message(self, system_message: str)
         üìù Set the system message.

  L 384: append_message(self, role: str, message: str)
         üìù Append a new message.

  L 388: append_image(self, image: str, detail: Literal['auto', 'low', 'high'])
         üìù Append a new image.

  L 392: append_video(self, video: str)
         üìù Append a new video.

  L 396: append_audio(self, audio: str)
         üìù Append a new audio.

  L 400: update_last_message(self, message: str)
         üìù Update the last output.
            The last message is typically set to be None when constructing the prompt,
            so we need to update it in-place after getting the response from a model.

  L 408: to_gradio_chatbot(self)
         üìù Convert the conversation to gradio chatbot format.

  L 418: to_openai_api_messages(self)
         üìù Convert the conversation to OpenAI chat completion format.

  L 433: copy(self)

  L 450: dict(self)


============================================================
FILE: python/sglang/srt/custom_op.py
Functions: 12
============================================================


CLASS: CustomOp
----------------------------------------
  L  13: __init__(self)

  L  21: enter_torch_compile(self, num_tokens: int)

  L  48: leave_torch_compile(self)

  L  58: forward(self)

  L  61: forward_native(self)

  L  64: forward_cuda(self)

  L  67: forward_npu(self)

  L  70: forward_hip(self)

  L  73: forward_xpu(self)

  L  76: forward_hpu(self)

  L  79: forward_cpu(self)

  L  82: dispatch_forward(self)


============================================================
FILE: python/sglang/srt/debug_utils/dump_comparator.py
Functions: 3
============================================================

MODULE FUNCTIONS:
----------------------------------------
  L  12: def main(args)

  L  53: def read_meta(directory)

  L  78: def check_tensor_pair(path_baseline, path_target)


============================================================
FILE: python/sglang/srt/debug_utils/dumper.py
Functions: 4
============================================================

MODULE FUNCTIONS:
----------------------------------------
  L  89: def get_truncated_value(value)


CLASS: _Dumper
----------------------------------------
  L  27: __init__(self)

  L  38: on_forward_pass_start(self)

  L  44: dump(self, name, value)


============================================================
FILE: python/sglang/srt/debug_utils/text_comparator.py
Functions: 1
============================================================

MODULE FUNCTIONS:
----------------------------------------
  L  15: def main(args)


============================================================
FILE: python/sglang/srt/disaggregation/ascend/conn.py
Functions: 3
============================================================


CLASS: AscendKVManager
----------------------------------------
  L  22: init_engine(self)

  L  31: register_buffer_to_engine(self)

  L  38: send_kvcache(self, mooncake_session_id: str, prefill_kv_indices: npt.NDArray[np.int32], dst_kv_ptrs: list[int], dst_kv_indices: npt.NDArray[np.int32], executor: concurrent.futures.ThreadPoolExecutor)


============================================================
FILE: python/sglang/srt/disaggregation/ascend/transfer_engine.py
Functions: 3
============================================================


CLASS: AscendTransferEngine
----------------------------------------
  L  13: __init__(self, hostname: str, npu_id: int, disaggregation_mode: DisaggregationMode)

  L  39: initialize(self)
         ‚Üí None
         üìù Initialize the ascend transfer instance.

  L  51: batch_register(self, ptrs: List[int], lengths: List[int])


============================================================
FILE: python/sglang/srt/disaggregation/base/conn.py
Functions: 11
============================================================


CLASS: BaseKVBootstrapServer
----------------------------------------
  L 134: __init__(self, port: int)


CLASS: BaseKVManager
----------------------------------------
  L  50: __init__(self, args: KVArgs, disaggregation_mode: DisaggregationMode, server_args: ServerArgs, is_mla_backend: Optional[bool])


CLASS: BaseKVReceiver
----------------------------------------
  L 103: __init__(self, mgr: BaseKVManager, bootstrap_addr: str, bootstrap_room: Optional[int])

  L 111: init(self, kv_indices: npt.NDArray[np.int32], aux_index: Optional[int])
         üìù Notify the prefill server about the kv indices and aux index

  L 118: poll(self)
         ‚Üí KVPoll
         üìù Check the status of the kv cache transfer

  L 125: failure_exception(self)
         üìù Raise an exception if the kv cache transfer fails


CLASS: BaseKVSender
----------------------------------------
  L  62: __init__(self, mgr: BaseKVManager, bootstrap_addr: str, bootstrap_room: int, dest_tp_ranks: List[int], pp_rank: int)

  L  72: init(self, num_kv_indices: int, aux_index: Optional[int])
         üìù Notify the decoder server about the kv indices length and aux index

  L  79: send(self, kv_indices: npt.NDArray[np.int32])
         üìù Send the kv cache at the given kv indices to the decoder server

  L  86: poll(self)
         ‚Üí KVPoll
         üìù Check the status of the kv cache transfer

  L  93: failure_exception(self)
         üìù Raise an exception if the kv cache transfer fails


============================================================
FILE: python/sglang/srt/disaggregation/common/conn.py
Functions: 7
============================================================


CLASS: CommonKVBootstrapServer
----------------------------------------
  L 311: __init__(self, port: int)

  L 326: run(self)

  L 425: close(self)
         üìù Shutdown

  L 435: poll(self)
         ‚Üí KVPoll


CLASS: CommonKVManager
----------------------------------------
  L  39: __init__(self, args: KVArgs, disaggregation_mode: DisaggregationMode, server_args: ServerArgs, is_mla_backend: Optional[bool])


CLASS: CommonKVReceiver
----------------------------------------
  L 123: __init__(self, mgr: BaseKVManager, bootstrap_addr: str, bootstrap_room: Optional[int], data_parallel_rank: Optional[int])

  L 306: failure_exception(self)


============================================================
FILE: python/sglang/srt/disaggregation/common/utils.py
Functions: 4
============================================================

MODULE FUNCTIONS:
----------------------------------------
  L  28: def group_concurrent_contiguous(src_indices: npt.NDArray[np.int32],
        dst_indices: npt.NDArray[np.int32])
         ‚Üí Tuple[List[npt.NDArray[np.int32]], List[npt.NDArray[np.int32]]]
         üìù Vectorised NumPy implementation.


CLASS: FastQueue
----------------------------------------
  L  10: __init__(self)

  L  14: put(self, item)

  L  20: get(self)


============================================================
FILE: python/sglang/srt/disaggregation/decode.py
Functions: 21
============================================================


CLASS: DecodePreallocQueue
----------------------------------------
  L 139: __init__(self, req_to_token_pool: ReqToTokenPool, token_to_kv_pool_allocator: BaseTokenToKVPoolAllocator, draft_token_to_kv_pool: Optional[KVCache], req_to_metadata_buffer_idx_allocator: ReqToMetadataIdxAllocator, metadata_buffers: MetadataBuffers, scheduler: Scheduler, transfer_queue: DecodeTransferQueue, tree_cache: BasePrefixCache, gloo_group: ProcessGroup, tp_rank: int, tp_size: int, dp_size: int, gpu_id: int, bootstrap_port: int, max_total_num_tokens: int, prefill_pp_size: int, num_reserved_decode_tokens: int, transfer_backend: TransferBackend)

  L 230: add(self, req: Req, is_retracted: bool)
         ‚Üí None
         üìù Add a request to the pending queue.

  L 267: extend(self, reqs: List[Req], is_retracted: bool)
         ‚Üí None
         üìù Add a request to the pending queue.

  L 272: resume_retracted_reqs(self)
         ‚Üí List[Req]

  L 342: pop_preallocated(self)
         ‚Üí List[DecodeRequest]
         üìù Pop the preallocated requests from the pending queue (FIFO).

  L 432: num_tokens_pre_allocated(self)


CLASS: DecodeReqToTokenPool
----------------------------------------
  L  77: __init__(self, size: int, max_context_len: int, device: str, enable_memory_saver: bool, pre_alloc_size: int)

  L 102: write(self, indices, values)

  L 105: available_size(self)

  L 108: alloc(self, need_size: int)
         ‚Üí List[int]

  L 116: free(self, free_index: Union[int, List[int]])

  L 122: clear(self)


CLASS: DecodeTransferQueue
----------------------------------------
  L 548: __init__(self, gloo_group: ProcessGroup, req_to_metadata_buffer_idx_allocator: ReqToMetadataIdxAllocator, tp_rank: int, metadata_buffers: MetadataBuffers, scheduler: Scheduler, tree_cache: BasePrefixCache)

  L 566: add(self, decode_req: DecodeRequest)
         ‚Üí None

  L 569: extend(self, decode_reqs: List[DecodeRequest])
         ‚Üí None

  L 572: pop_transferred(self)
         ‚Üí List[Req]


CLASS: SchedulerDisaggregationDecodeMixin
----------------------------------------
  L 675: event_loop_normal_disagg_decode(self: Scheduler)
         üìù A normal scheduler loop for decode worker in disaggregation mode.

  L 716: event_loop_overlap_disagg_decode(self: Scheduler)

  L 799: get_next_disagg_decode_batch_to_run(self: Scheduler)
         ‚Üí Optional[Tuple[ScheduleBatch, bool]]
         üìù Create fake completed prefill if possible and merge with running batch

  L 831: get_new_prebuilt_batch(self: Scheduler)
         ‚Üí Optional[ScheduleBatch]
         üìù Create a schedulebatch for fake completed prefill

  L 879: process_decode_queue(self: Scheduler)


============================================================
FILE: python/sglang/srt/disaggregation/decode_schedule_batch_mixin.py
Functions: 2
============================================================


CLASS: ScheduleBatchDisaggregationDecodeMixin
----------------------------------------
  L  23: prepare_for_prebuilt_extend(self: ScheduleBatch)
         üìù Prepare a prebuilt extend by populate metadata
            Adapted from .prepare_for_extend().

  L 102: process_prebuilt_extend(self: ScheduleBatch, server_args: ServerArgs, model_config: ModelConfig)
         üìù Assign the buffered last input id to schedule batch


============================================================
FILE: python/sglang/srt/disaggregation/fake/conn.py
Functions: 9
============================================================


CLASS: FakeKVReceiver
----------------------------------------
  L  60: __init__(self, mgr: BaseKVManager, bootstrap_addr: str, bootstrap_room: Optional[int], data_parallel_rank: Optional[int])

  L  69: poll(self)
         ‚Üí KVPoll

  L  78: init(self, kv_indices: list[int], aux_index: Optional[int])

  L  84: failure_exception(self)


CLASS: FakeKVSender
----------------------------------------
  L  19: __init__(self, mgr: BaseKVManager, bootstrap_addr: str, bootstrap_room: int, dest_tp_ranks: List[int], pp_rank: int)

  L  29: poll(self)
         ‚Üí KVPoll

  L  38: init(self, kv_indices: list[int], aux_index: Optional[int])

  L  48: send(self, kv_indices: npt.NDArray[np.int32])

  L  55: failure_exception(self)


============================================================
FILE: python/sglang/srt/disaggregation/kv_events.py
Functions: 12
============================================================


CLASS: EventPublisher
----------------------------------------
  L  93: __init__(self, attn_dp_rank: int)

  L  97: publish(self, events: EventBatch)
         ‚Üí None
         üìù Emit events in order.
            Implementations should guarantee at-least-once delivery and
            monotonic ordering (e.g., via sequence numbers).

  L 105: shutdown(self)
         ‚Üí None
         üìù Shutdown the publisher.


CLASS: EventPublisherFactory
----------------------------------------
  L 394: register_publisher(cls, name: str, ctor: Callable[..., EventPublisher])
         ‚Üí None

  L 400: create(cls, config: Optional[str], attn_dp_rank: int)
         ‚Üí EventPublisher
         üìù Create publisher from a config mapping.


CLASS: KVEventsConfig
----------------------------------------
  L 382: from_cli(cls, cli_value: str)
         ‚Üí 'KVEventsConfig'
         üìù Parse the CLI value for the event publisher config.


CLASS: NullEventPublisher
----------------------------------------
  L 112: publish(self, events)
         ‚Üí None

  L 115: shutdown(self)
         ‚Üí None


CLASS: ZmqEventPublisher
----------------------------------------
  L 146: __init__(self, attn_dp_rank: int, endpoint: str, replay_endpoint: Optional[str], buffer_steps: int, hwm: int, max_queue_size: int, topic: str)
         ‚Üí None

  L 188: publish(self, events: EventBatch)
         ‚Üí None

  L 195: shutdown(self)
         ‚Üí None
         üìù Stop the publisher thread and clean up resources.

  L 314: offset_endpoint_port(endpoint: Optional[str], data_parallel_rank: int)
         ‚Üí Optional[str]
         üìù Helper function to offset the port in an endpoint by
            the data parallel rank.
            Args:
            endpoint: The endpoint string
            (e.g., "tcp://*:5557" or "inproc://cache")
            data_parallel_rank: The data parallel rank to offset by
            Returns:
            The endpoint with the port offset by data_parallel_rank
            or suffix appended


============================================================
FILE: python/sglang/srt/disaggregation/launch_lb.py
Functions: 3
============================================================

MODULE FUNCTIONS:
----------------------------------------
  L  99: def main()


CLASS: LBArgs
----------------------------------------
  L  18: add_cli_args(parser: argparse.ArgumentParser)

  L  72: from_cli_args(cls, args: argparse.Namespace)
         ‚Üí 'LBArgs'


============================================================
FILE: python/sglang/srt/disaggregation/mini_lb.py
Functions: 18
============================================================

MODULE FUNCTIONS:
----------------------------------------
  L  28: def setup_logger()

  L 185: async def health_check()
         @app.get('/health')

  L 190: async def health_check()
         @app.get('/health_generate')

  L 206: async def flush_cache()
         @app.post('/flush_cache')

  L 222: async def get_server_info()
         @app.get('/get_server_info')

  L 265: async def get_model_info()
         @app.get('/get_model_info')

  L 301: async def handle_generate_request(request_data: dict)
         @app.post('/generate')

  L 371: async def handle_chat_completion_request(request_data: dict)
         @app.post('/v1/chat/completions')

  L 376: async def handle_completion_request(request_data: dict)
         @app.post('/v1/completions')

  L 394: async def get_models()
         @app.get('/v1/models')

  L 410: async def register(obj: PDRegistryRequest)
         @app.post('/register')

  L 435: def run(prefill_configs, decode_addrs, host, port, timeout)


CLASS: MiniLoadBalancer
----------------------------------------
  L  54: __init__(self, prefill_configs: List[PrefillConfig], decode_servers: List[str], timeout: int)

  L  65: add_prefill_server(self, new_prefill_config: PrefillConfig)

  L  69: add_decode_server(self, new_decode_server: str)

  L  72: select_pair(self)

  L  81: generate(self, modified_request, prefill_server, decode_server, endpoint)
         ‚Üí ORJSONResponse

  L 119: generate_stream(self, modified_request, prefill_server, decode_server, endpoint)


============================================================
FILE: python/sglang/srt/disaggregation/mooncake/conn.py
Functions: 40
============================================================


CLASS: AuxDataCodec
----------------------------------------
  L 146: serialize_data_from_buffer(src_addr, data_length)
         üìù Serialize data from memory buffer to bytes

  L 152: deserialize_data_to_buffer(kv_args, buffer_index, aux_index, data)
         üìù Deserialize bytes into target memory buffer


CLASS: KVArgsRegisterInfo
----------------------------------------
  L 128: from_zmq(cls, msg: List[bytes])


CLASS: KVTransferError
----------------------------------------
  L  61: __init__(self, bootstrap_room: int, failure_reason: str)

  L  66: __str__(self)


CLASS: MooncakeKVBootstrapServer
----------------------------------------
  L1548: __init__(self, port: int)

  L1565: run(self)

  L1686: close(self)
         üìù Shutdown

  L1696: poll(self)
         ‚Üí KVPoll


CLASS: MooncakeKVManager
----------------------------------------
  L 165: __init__(self, args: KVArgs, disaggregation_mode: DisaggregationMode, server_args: ServerArgs, is_mla_backend: Optional[bool])

  L 277: init_engine(self)

  L 284: register_buffer_to_engine(self)

  L 314: send_kvcache(self, mooncake_session_id: str, prefill_kv_indices: npt.NDArray[np.int32], dst_kv_ptrs: list[int], dst_kv_indices: npt.NDArray[np.int32], executor: concurrent.futures.ThreadPoolExecutor)

  L 419: send_kvcache_slice(self, mooncake_session_id: str, prefill_kv_indices: npt.NDArray[np.int64], dst_kv_ptrs: list[int], dst_kv_indices: npt.NDArray[np.int64], dst_tp_rank: int, dst_attn_tp_size: int, dst_kv_item_len: int, executor: concurrent.futures.ThreadPoolExecutor)
         üìù Sends KV cache slices from this Prefill rank to a target Decode rank,
            supporting generic M-to-N TP size configurations.
            NOTE: This implementation calls the transfer engine for each token slot within
            each page to ensure correctness for any page_size and head-slicing configuration.
            This may introduce performance overhead (increased TTFT) for long sequences.

  L 583: send_aux(self, req: TransferInfo, prefill_aux_index: int, dst_aux_ptrs: list[int])

  L 605: send_aux_tcp(self, req: TransferInfo, prefill_aux_index: int, dst_aux_ptrs: list[int])

  L 630: send_aux_data_to_endpoint(self, remote: str, dst_port: int, room: int, buffer_index: int, aux_index: int, data: bytes)

  L 654: sync_status_to_decode_endpoint(self, remote: str, dst_port: int, room: int, status: int, prefill_rank: int)

  L 667: transfer_worker(self, queue: FastQueue, executor: concurrent.futures.ThreadPoolExecutor)

  L 805: start_prefill_thread(self)

  L 864: start_decode_thread(self)

  L 955: add_transfer_request(self, bootstrap_room: int, kv_indices: npt.NDArray[np.int32], index_slice: slice, is_last: bool, aux_index: Optional[int])

  L 998: check_status(self, bootstrap_room: int)

  L1001: update_status(self, bootstrap_room: int, status: KVPoll)

  L1013: record_failure(self, bootstrap_room: int, failure_reason: str)

  L1017: get_session_id(self)


CLASS: MooncakeKVReceiver
----------------------------------------
  L1207: __init__(self, mgr: MooncakeKVManager, bootstrap_addr: str, bootstrap_room: Optional[int], data_parallel_rank: Optional[int])

  L1470: init(self, kv_indices: npt.NDArray[np.int32], aux_index: Optional[int])

  L1489: poll(self)
         ‚Üí KVPoll

  L1515: clear(self)
         ‚Üí None

  L1525: failure_exception(self)

  L1538: abort(self)


CLASS: MooncakeKVSender
----------------------------------------
  L1103: __init__(self, mgr: MooncakeKVManager, bootstrap_addr: str, bootstrap_room: int, dest_tp_ranks: List[int], pp_rank: int)

  L1121: init(self, num_kv_indices: int, aux_index: Optional[int])

  L1125: send(self, kv_indices: npt.NDArray[np.int32])

  L1149: poll(self)
         ‚Üí KVPoll

  L1175: clear(self)
         ‚Üí None

  L1179: failure_exception(self)

  L1192: abort(self)


CLASS: TransferInfo
----------------------------------------
  L  93: from_zmq(cls, msg: List[bytes])


============================================================
FILE: python/sglang/srt/disaggregation/mooncake/transfer_engine.py
Functions: 9
============================================================


CLASS: MooncakeTransferEngine
----------------------------------------
  L  11: __init__(self, hostname: str, gpu_id: int, ib_device: Optional[str])

  L  34: register(self, ptr, length)

  L  44: deregister(self, ptr)

  L  54: batch_register(self, ptrs: List[int], lengths: List[int])
         ‚Üí int
         üìù Batch register multiple memory regions.

  L  71: batch_deregister(self, ptrs: List[int])
         ‚Üí int
         üìù Batch deregister multiple memory regions.

  L  83: initialize(self, hostname: str, device_name: Optional[str])
         ‚Üí None
         üìù Initialize the mooncake instance.

  L 108: transfer_sync(self, session_id: str, buffer: int, peer_buffer_address: int, length: int)
         ‚Üí int
         üìù Synchronously transfer data to the specified address.

  L 133: batch_transfer_sync(self, session_id: str, buffers: List[int], peer_buffer_addresses: List[int], lengths: List[int])
         ‚Üí int
         üìù Synchronously transfer data to the specified addresses in batches.

  L 163: get_session_id(self)


============================================================
FILE: python/sglang/srt/disaggregation/nixl/conn.py
Functions: 22
============================================================


CLASS: KVArgsRegisterInfo
----------------------------------------
  L  83: from_zmq(cls, msg: List[bytes])


CLASS: NixlKVManager
----------------------------------------
  L 114: __init__(self, args: KVArgs, disaggregation_mode: DisaggregationMode, server_args: ServerArgs, is_mla_backend: Optional[bool])

  L 151: check_status(self, bootstrap_room: int)

  L 154: update_status(self, bootstrap_room: int, status: KVPoll)

  L 163: register_buffer_to_engine(self)

  L 191: send_kvcache(self, peer_name: str, prefill_kv_indices: npt.NDArray[np.int32], dst_kv_ptrs: list[int], dst_kv_indices: npt.NDArray[np.int32], dst_gpu_id: int, notif: str)

  L 242: send_aux(self, peer_name: str, prefill_aux_index: int, dst_aux_ptrs: list[int], dst_aux_index: int, notif: str)

  L 275: add_transfer_request(self, bootstrap_room: int, kv_indices: npt.NDArray[np.int32], index_slice: slice, is_last: bool, chunk_id: int, aux_index: Optional[int])

  L 323: update_transfer_status(self)

  L 342: check_transfer_done(self, room: int)


CLASS: NixlKVReceiver
----------------------------------------
  L 452: __init__(self, mgr: NixlKVManager, bootstrap_addr: str, bootstrap_room: Optional[int], data_parallel_rank: Optional[int])

  L 463: init(self, kv_indices: npt.NDArray[np.int32], aux_index: Optional[int])

  L 489: poll(self)
         ‚Üí KVPoll

  L 527: failure_exception(self)


CLASS: NixlKVSender
----------------------------------------
  L 392: __init__(self, mgr: NixlKVManager, bootstrap_addr: str, bootstrap_room: int, dest_tp_ranks: List[int], pp_rank: int)

  L 411: init(self, num_kv_indices: int, aux_index: Optional[int])

  L 415: send(self, kv_indices: npt.NDArray[np.int32])

  L 437: poll(self)
         ‚Üí KVPoll

  L 447: failure_exception(self)


CLASS: TransferInfo
----------------------------------------
  L  53: is_dummy(self)

  L  57: from_zmq(cls, msg: List[bytes])


CLASS: TransferStatus
----------------------------------------
  L 107: is_done(self)


============================================================
FILE: python/sglang/srt/disaggregation/prefill.py
Functions: 14
============================================================


CLASS: PrefillBootstrapQueue
----------------------------------------
  L  68: __init__(self, token_to_kv_pool: KVCache, draft_token_to_kv_pool: Optional[KVCache], req_to_metadata_buffer_idx_allocator: ReqToMetadataIdxAllocator, metadata_buffers: MetadataBuffers, tp_rank: int, tp_size: int, gpu_id: int, bootstrap_port: int, gloo_group: ProcessGroup, max_total_num_tokens: int, decode_tp_size: int, decode_dp_size: int, scheduler: Scheduler, pp_rank: int, pp_size: int, transfer_backend: TransferBackend)

  L 152: add(self, req: Req, num_kv_heads: int)
         ‚Üí None

  L 173: extend(self, reqs: List[Req], num_kv_heads: int)
         ‚Üí None

  L 192: pop_bootstrapped(self, return_failed_reqs: bool, rids_to_check: Optional[List[str]])
         ‚Üí List[Req]
         üìù pop the reqs which has finished bootstrapping
            return_failed_reqs: For PP, on rank 0, also return the failed reqs to notify the next rank
            rids_to_check: For PP, on rank > 0, check the rids from the previous rank has consensus with the current rank.


CLASS: SchedulerDisaggregationPrefillMixin
----------------------------------------
  L 276: event_loop_normal_disagg_prefill(self: Scheduler)
         ‚Üí None
         üìù A normal scheduler loop for prefill worker in disaggregation mode.

  L 308: event_loop_overlap_disagg_prefill(self: Scheduler)
         ‚Üí None

  L 355: process_batch_result_disagg_prefill(self: Scheduler, batch: ScheduleBatch, result: GenerationBatchResult, launch_done: Optional[threading.Event])
         ‚Üí None
         üìù Transfer kv for prefill completed requests and add it into disagg_prefill_inflight_queue
            Adapted from process_batch_result_prefill

  L 478: process_disagg_prefill_inflight_queue(self: Scheduler, rids_to_check: Optional[List[str]])
         ‚Üí List[Req]
         üìù Poll the requests in the middle of transfer. If done, return the request.
            rids_to_check: For PP, on rank > 0, check the rids from the previous rank has consensus with the current rank.

  L 547: get_transferred_rids(self: Scheduler)
         ‚Üí List[str]
         üìù Used by PP, get the transferred rids but **do not pop**

  L 564: process_prefill_chunk(self: Scheduler)
         ‚Üí None

  L 583: send_kv_chunk(self: Scheduler, req: Req, last_chunk: bool, end_idx: Optional[int])
         ‚Üí None
         üìù Send a prefilled chunk to the decode server

  L 622: event_loop_pp_disagg_prefill(self: Scheduler)
         üìù An event loop for the prefill server in pipeline parallelism.
            Rules:
            1. Each stage runs in the same order and is notified by the previous stage.
            2. Each send/recv operation is blocking and matched by the neighboring stage.
            Regular Schedule:
            ====================================================================
            Stage i                   | Stage i+1
            send ith req              | recv ith req
            send ith proxy            | recv ith proxy
            send prev (i+1)th carry   | recv prev (i+1)th carry
            ====================================================================
            Prefill Server Schedule:
            ====================================================================
            Stage i                        | Stage i+1
            send ith req                   | recv ith req
            send ith bootstrap req         | recv ith bootstrap req
            send ith transferred req       | recv ith transferred req
            send ith proxy                 | recv ith proxy
            send prev (i+1)th carry        | recv prev (i+1)th carry
            send prev (i+1)th release req  | recv prev (i+1)th release req
            ====================================================================
            There are two additional elements compared to the regular schedule:
            1. Bootstrap Requests:
            a. Instead of polling the status on the current workers, we should wait for the previous stage to notify to avoid desynchronization.
            b. The first stage polls the status and propagates the bootstrapped requests down to all other stages.
            c. If the first stage polls successfully, by nature, other ranks are also successful because they performed a handshake together.
            2. Transferred Requests + Release Requests:
            a. The first stage polls the transfer finished requests, performs an intersection with the next stage's finished requests, and propagates down to the last stage.
            b. The last stage receives the requests that have finished transfer on all stages (consensus), then sends them to the first stage to release the memory.
            c. The first stage receives the release requests, releases the memory, and then propagates the release requests down to the last stage.

  L 837: send_pyobj_to_next_stage(self, data)

  L 848: recv_pyobj_from_prev_stage(self)


============================================================
FILE: python/sglang/srt/disaggregation/utils.py
Functions: 16
============================================================

MODULE FUNCTIONS:
----------------------------------------
  L  43: def poll_and_all_reduce(pollers, gloo_group)

  L 220: def get_kv_class(transfer_backend: TransferBackend, class_type: KVClassType)

  L 293: def kv_to_page_indices(kv_indices: np.ndarray, page_size: int)

  L 303: def kv_to_page_num(num_kv_indices: int, page_size: int)

  L 332: def register_disaggregation_server(mode: str,
        server_port: int,
        bootstrap_port: int,
        pdlb_url: str)

  L 356: def is_mla_backend(target_kv_pool)
         ‚Üí bool

  L 362: def prepare_abort(req: Req, error_message: str, status_code)


CLASS: MetadataBuffers
----------------------------------------
  L  88: __init__(self, size: int, hidden_size: int, dtype: torch.dtype, max_top_logprobs_num: int, custom_mem_pool: torch.cuda.MemPool)

  L 131: get_buf_infos(self)

  L 158: get_buf(self, idx: int)

  L 168: set_buf(self, req: Req)


CLASS: PDRegistryRequest
----------------------------------------
  L 321: __post_init__(self)


CLASS: ReqToMetadataIdxAllocator
----------------------------------------
  L  67: __init__(self, size: int)

  L  74: available_size(self)

  L  77: alloc(self)
         ‚Üí Optional[int]

  L  83: free(self, free_index: int)


============================================================
FILE: python/sglang/srt/distributed/communication_op.py
Functions: 4
============================================================

MODULE FUNCTIONS:
----------------------------------------
  L  11: def tensor_model_parallel_all_reduce(input_: torch.Tensor)
         ‚Üí torch.Tensor
         üìù All-reduce the input tensor across model parallel group.

  L  16: def tensor_model_parallel_all_gather(input_: torch.Tensor, dim: int)
         ‚Üí torch.Tensor
         üìù All-gather the input tensor across model parallel group.

  L  23: def tensor_model_parallel_gather(input_: torch.Tensor, dst: int, dim: int)
         ‚Üí Optional[torch.Tensor]
         üìù Gather the input tensor across model parallel group.

  L  30: def broadcast_tensor_dict(tensor_dict: Optional[Dict[Any,
        Union[torch.Tensor,
        Any]]],
        src: int)


============================================================
FILE: python/sglang/srt/distributed/device_communicators/cuda_wrapper.py
Functions: 13
============================================================

MODULE FUNCTIONS:
----------------------------------------
  L  37: def find_loaded_library(lib_name)
         ‚Üí Optional[str]
         üìù According to according to https://man7.org/linux/man-pages/man5/proc_pid_maps.5.html,
            the file `/proc/self/maps` contains the memory maps of the process, which includes the
            shared libraries loaded by the process. We can use this file to find the path of the
            a loaded library.


CLASS: CudaRTLibrary
----------------------------------------
  L 114: __init__(self, so_file: Optional[str])

  L 133: CUDART_CHECK(self, result: cudaError_t)
         ‚Üí None

  L 138: cudaGetErrorString(self, error: cudaError_t)
         ‚Üí str

  L 141: cudaSetDevice(self, device: int)
         ‚Üí None

  L 144: cudaDeviceSynchronize(self)
         ‚Üí None

  L 147: cudaDeviceReset(self)
         ‚Üí None

  L 150: cudaMalloc(self, size: int)
         ‚Üí ctypes.c_void_p

  L 155: cudaFree(self, devPtr: ctypes.c_void_p)
         ‚Üí None

  L 158: cudaMemset(self, devPtr: ctypes.c_void_p, value: int, count: int)
         ‚Üí None

  L 161: cudaMemcpy(self, dst: ctypes.c_void_p, src: ctypes.c_void_p, count: int)
         ‚Üí None

  L 168: cudaIpcGetMemHandle(self, devPtr: ctypes.c_void_p)
         ‚Üí cudaIpcMemHandle_t

  L 175: cudaIpcOpenMemHandle(self, handle: cudaIpcMemHandle_t)
         ‚Üí ctypes.c_void_p


============================================================
FILE: python/sglang/srt/distributed/device_communicators/custom_all_reduce.py
Functions: 13
============================================================


CLASS: CustomAllreduce
----------------------------------------
  L  66: __init__(self, group: ProcessGroup, device: Union[int, str, torch.device], max_size)
         ‚Üí None
         üìù Args:
            group: the process group to work on. If None, it will use the
            default process group.
            device: the device to bind the CustomAllreduce to. If None,
            it will be bind to f"cuda:{local_rank}".
            It is the caller's responsibility to make sure each communicator
            is bind to a unique device, and all communicators in this group
            are in the same node.

  L 215: create_shared_buffer(size_in_bytes: int, group: Optional[ProcessGroup])
         ‚Üí List[int]
         üìù Creates a shared buffer and returns a list of pointers
            representing the buffer on all processes in the group.

  L 240: free_shared_buffer(pointers: List[int], group: Optional[ProcessGroup])
         ‚Üí None

  L 248: capture(self)
         üìù The main responsibility of this context manager is the
            `register_graph_buffers` call at the end of the context.
            It records all the buffer addresses used in the CUDA graph.

  L 296: register_buffer(self, inp: torch.Tensor)

  L 300: register_graph_buffers(self)

  L 326: should_custom_ar(self, inp: torch.Tensor)

  L 351: all_reduce_reg(self, inp: torch.Tensor, out: torch.Tensor)

  L 358: all_reduce_unreg(self, inp: torch.Tensor, out: torch.Tensor)

  L 364: all_reduce(self, inp: torch.Tensor)
         üìù Performs an out-of-place all reduce.
            If registered is True, this assumes inp's pointer is already
            IPC-registered. Otherwise, inp is first copied into a pre-registered
            buffer.

  L 387: custom_all_reduce(self, input: torch.Tensor)
         ‚Üí Optional[torch.Tensor]
         üìù The main allreduce API that provides support for cuda graph.

  L 412: close(self)

  L 420: __del__(self)


============================================================
FILE: python/sglang/srt/distributed/device_communicators/custom_all_reduce_utils.py
Functions: 8
============================================================

MODULE FUNCTIONS:
----------------------------------------
  L  50: def update_environment_variables(envs: Dict[str, str])

  L  62: def producer(batch_src: Sequence[int],
        producer_queue,
        consumer_queue,
        result_queue,
        cuda_visible_devices: Optional[str])

  L  96: def consumer(batch_tgt: Sequence[int],
        producer_queue,
        consumer_queue,
        result_queue,
        cuda_visible_devices: Optional[str])

  L 137: def can_actually_p2p(batch_src: Sequence[int], batch_tgt: Sequence[int])
         ‚Üí Sequence[bool]
         üìù Usually, checking if P2P access is enabled can be done by
            `torch.cuda.can_device_access_peer(src, tgt)`. However, sometimes
            the driver might be broken, and `torch.cuda.can_device_access_peer(src, tgt)`
            returns `True` even if P2P access is not actually possible.
            See https://github.com/vllm-project/vllm/issues/2728 and
            https://forums.developer.nvidia.com/t/direct-gpu-gpu-communication-does-not-seem-to-work-properly/283264/10
            Therefore, we have to perform a real P2P access to check if it is actually
            possible.
            Note on p2p and cuda IPC:
            Usually, one process uses one GPU:
            GPU src --> cuda context src --> tensor src --> process src
            We need to combine p2p and cuda IPC, so that:
            GPU src --> cuda context src --> tensor src --> process src
            |shared|
            GPU tgt --> cuda context tgt --> tensor tgt --> process tgt
            That is to say, process src creates a tensor in GPU src, passes IPC handle to
            process tgt, and process tgt accesses the tensor in GPU tgt. Any operation on the
            tensor in process tgt will be reflected in the tensor in process src, because
            they are the same memory segment.
            It is important to note that process tgt accesses the tensor in GPU tgt, not
            GPU src. That's why we need p2p access.
            The most time-consuming part is the process creation. To avoid creating
            processes for every pair of GPUs, we use batched testing. We create two
            processes for testing all pairs of GPUs in batch. The trick is to reset
            the device after each test (which is not available in PyTorch).

  L 237: def gpu_p2p_access_check(src: int, tgt: int)
         ‚Üí bool
         üìù Check if GPU src can access GPU tgt.

  L 312: def with_nvml_context(fn: Callable[_P, _R])
         ‚Üí Callable[_P, _R]

  L 332: def is_full_nvlink(physical_device_ids: List[int], world_size: int)
         ‚Üí bool
         @with_nvml_context

  L 373: def is_weak_contiguous(inp: torch.Tensor)


============================================================
FILE: python/sglang/srt/distributed/device_communicators/hpu_communicator.py
Functions: 3
============================================================


CLASS: HpuCommunicator
----------------------------------------
  L  15: __init__(self, group: ProcessGroup)

  L  23: all_reduce(self, x: torch.Tensor)
         ‚Üí torch.Tensor

  L  31: all_gather(self, x: torch.Tensor, dim: int)
         ‚Üí torch.Tensor


============================================================
FILE: python/sglang/srt/distributed/device_communicators/npu_communicator.py
Functions: 3
============================================================


CLASS: NpuCommunicator
----------------------------------------
  L  10: __init__(self, group: ProcessGroup)

  L  18: all_reduce(self, x: torch.Tensor)
         ‚Üí torch.Tensor

  L  22: all_gather(self, x: torch.Tensor, dim: int)
         ‚Üí torch.Tensor


============================================================
FILE: python/sglang/srt/distributed/device_communicators/pymscclpp.py
Functions: 8
============================================================

MODULE FUNCTIONS:
----------------------------------------
  L  39: def mscclpp_is_weak_contiguous(inp: torch.Tensor)

  L  46: def mscclpp_convert_to_bytes(size_str)
         üìù Converts a human-readable size string (e.g., "1MB", "2.5kb", "3 GB")
            into the equivalent number of bytes using binary units.
            Args:
            size_str (str): A string representing size with unit (KB, MB, GB).
            Returns:
            int: Number of bytes.

  L  87: def mscclpp_bench_time(func, test_niter: int, warmup_niter: int)


CLASS: PyMscclppCommunicator
----------------------------------------
  L 111: __init__(self, group: ProcessGroup, device: Union[int, str, torch.device], max_bytes)
         ‚Üí None
         üìù Args:
            group: the process group to work on. If None, it will use the
            default process group.
            device: the device to bind the CustomAllreduce to. If None,
            it will be bind to f"cuda:{local_rank}".
            It is the caller's responsibility to make sure each communicator
            is bind to a unique device, and all communicators in this group
            are in the same node.

  L 243: pre_tune_config(self, dtype)
         ‚Üí bool

  L 273: should_mscclpp_allreduce(self, inp: torch.Tensor, op: ReduceOp)
         ‚Üí bool

  L 289: all_reduce(self, tensor: torch.Tensor, op: ReduceOp)

  L 302: change_state(self, enable: Optional[bool])


============================================================
FILE: python/sglang/srt/distributed/device_communicators/pynccl.py
Functions: 12
============================================================


CLASS: PyNcclCommunicator
----------------------------------------
  L  28: __init__(self, group: Union[ProcessGroup, StatelessProcessGroup], device: Union[int, str, torch.device], library_path: Optional[str])
         üìù Args:
            group: the process group to work on. If None, it will use the
            default process group.
            device: the device to bind the PyNcclCommunicator to. If None,
            it will be bind to f"cuda:{local_rank}".
            library_path: the path to the NCCL library. If None, it will
            use the default library path.
            It is the caller's responsibility to make sure each communicator
            is bind to a unique device.

  L 126: all_reduce(self, tensor: torch.Tensor, op: ReduceOp, stream)

  L 150: all_gather(self, output_tensor: torch.Tensor, input_tensor: torch.Tensor, stream, sizes: Optional[list[int]])

  L 196: reduce_scatter(self, output_tensor: torch.Tensor, input_tensor: torch.Tensor, op: ReduceOp, stream, sizes: Optional[list[int]])

  L 245: send(self, tensor: torch.Tensor, dst: int, stream)

  L 263: recv(self, tensor: torch.Tensor, src: int, stream)

  L 281: broadcast(self, tensor: torch.Tensor, src: int, stream)

  L 307: register_comm_window_raw(self, ptr: int, size: int)

  L 310: deregister_comm_window(self, window)

  L 313: group_start(self)

  L 316: group_end(self)

  L 320: change_state(self, enable: Optional[bool], stream: Optional[torch.cuda.Stream])
         üìù A context manager to change the state of the communicator.


============================================================
FILE: python/sglang/srt/distributed/device_communicators/pynccl_allocator.py
Functions: 7
============================================================

MODULE FUNCTIONS:
----------------------------------------
  L  34: def is_symmetric_memory_enabled()

  L  38: def set_graph_pool_id(graph_pool_id)

  L  43: def get_nccl_mem_pool()


CLASS: use_symmetric_memory
----------------------------------------
  L  67: __init__(self, group_coordinator: GroupCoordinator)

  L  81: __enter__(self)

  L 104: tag(self, tensor: torch.Tensor)

  L 109: __exit__(self, exc_type, exc_val, exc_tb)


============================================================
FILE: python/sglang/srt/distributed/device_communicators/pynccl_wrapper.py
Functions: 22
============================================================

MODULE FUNCTIONS:
----------------------------------------
  L  37: def find_nccl_library()
         ‚Üí str
         üìù We either use the library file specified by the `SGLANG_NCCL_SO_PATH`
            environment variable, or we find the library file brought by PyTorch.
            After importing `torch`, `libnccl.so.2` or `librccl.so.1` can be
            found by `ctypes` automatically.


CLASS: NCCLLibrary
----------------------------------------
  L 332: __init__(self, so_file: Optional[str])

  L 368: ncclGetErrorString(self, result: ncclResult_t)
         ‚Üí str

  L 371: NCCL_CHECK(self, result: ncclResult_t)
         ‚Üí None

  L 376: ncclGetRawVersion(self)
         ‚Üí int

  L 382: ncclGetVersion(self)
         ‚Üí str

  L 390: ncclGetUniqueId(self)
         ‚Üí ncclUniqueId

  L 395: ncclCommInitRank(self, world_size: int, unique_id: ncclUniqueId, rank: int)
         ‚Üí ncclComm_t

  L 406: ncclAllReduce(self, sendbuff: buffer_type, recvbuff: buffer_type, count: int, datatype: int, op: int, comm: ncclComm_t, stream: cudaStream_t)
         ‚Üí None

  L 427: ncclReduce(self, sendbuff: buffer_type, recvbuff: buffer_type, count: int, datatype: int, op: int, root: int, comm: ncclComm_t, stream: cudaStream_t)
         ‚Üí None

  L 449: ncclReduceScatter(self, sendbuff: buffer_type, recvbuff: buffer_type, count: int, datatype: int, op: int, comm: ncclComm_t, stream: cudaStream_t)
         ‚Üí None

  L 470: ncclAllGather(self, sendbuff: buffer_type, recvbuff: buffer_type, count: int, datatype: int, comm: ncclComm_t, stream: cudaStream_t)
         ‚Üí None

  L 489: ncclSend(self, sendbuff: buffer_type, count: int, datatype: int, dest: int, comm: ncclComm_t, stream: cudaStream_t)
         ‚Üí None

  L 502: ncclRecv(self, recvbuff: buffer_type, count: int, datatype: int, src: int, comm: ncclComm_t, stream: cudaStream_t)
         ‚Üí None

  L 515: ncclBroadcast(self, sendbuff: buffer_type, recvbuff: buffer_type, count: int, datatype: int, root: int, comm: ncclComm_t, stream: cudaStream_t)
         ‚Üí None

  L 531: ncclCommDestroy(self, comm: ncclComm_t)
         ‚Üí None

  L 534: ncclCommWindowRegister(self, comm: ncclComm_t, buff: buffer_type, size: int, win_flags: int)
         ‚Üí ncclWindow_t

  L 545: ncclCommWindowDeregister(self, comm: ncclComm_t, window: ncclWindow_t)
         ‚Üí None

  L 548: ncclGroupStart(self)
         ‚Üí None

  L 551: ncclGroupEnd(self)
         ‚Üí None


CLASS: ncclDataTypeEnum
----------------------------------------
  L 102: from_torch(cls, dtype: torch.dtype)
         ‚Üí int


CLASS: ncclRedOpTypeEnum
----------------------------------------
  L 134: from_torch(cls, op: ReduceOp)
         ‚Üí int


============================================================
FILE: python/sglang/srt/distributed/device_communicators/quick_all_reduce.py
Functions: 8
============================================================

MODULE FUNCTIONS:
----------------------------------------
  L  34: def qr_rocm_arch_available()


CLASS: QuickAllReduce
----------------------------------------
  L  73: __init__(self, group: ProcessGroup, device: Union[int, str, torch.device])
         ‚Üí None
         üìù Custom allreduce provides non-destructive acceleration and is
            available for CUDA and ROCm MI300 series.
            Custom quick allreduce leverages quantization for further
            acceleration on ROCm. It currently supports Q8, Q6, and Q4
            quantization formats and FP(float16, bfloat16).
            Quick allreduce is designed as a complement to custom allreduce.
            Its initialization requires even stricter conditions.
            Only the ROCm MI300 series is supported for quick allreduce at
            this time.
            Args:
            group: the process group to work on. If None, it will use the
            default process group.
            device: the device to bind the CustomAllreduce to. If None,
            it will be bind to f"cuda:{local_rank}".
            It is the caller's responsibility to make sure each communicator
            is bind to a unique device, and all communicators in this group
            are in the same node.

  L 175: init_quick_all_reduce(self)

  L 219: create_shared_buffer(self)
         üìù Creates a shared buffer for quickreduce.
            Has to be called after init_custom_qr

  L 230: should_quick_allreduce(self, inp: torch.Tensor)
         üìù Check if quickreduce is available

  L 254: quick_all_reduce(self, inp: torch.Tensor)
         üìù Performs an out-of-place custom quick all reduce.

  L 265: close(self)

  L 272: __del__(self)


============================================================
FILE: python/sglang/srt/distributed/device_communicators/shm_broadcast.py
Functions: 15
============================================================


CLASS: MessageQueue
----------------------------------------
  L 176: __init__(self, n_reader, n_local_reader, local_reader_ranks: Optional[List[int]], max_chunk_bytes: int, max_chunks: int, connect_ip: Optional[str])

  L 257: export_handle(self)
         ‚Üí Handle

  L 261: create_from_handle(handle: Handle, rank)
         ‚Üí 'MessageQueue'

  L 304: wait_until_ready(self)
         üìù This is a collective operation. All processes (including the
            readers and the writer) should call this function.

  L 338: acquire_write(self)

  L 391: acquire_read(self)

  L 434: enqueue(self, obj)

  L 449: dequeue(self)

  L 468: broadcast_object(self, obj)

  L 476: create_from_process_group(pg: ProcessGroup, max_chunk_bytes, max_chunks, writer_rank)
         ‚Üí 'MessageQueue'


CLASS: ShmRingBuffer
----------------------------------------
  L  36: __init__(self, n_reader: int, max_chunk_bytes: int, max_chunks: int, name: Optional[str])
         üìù A shared memory ring buffer implementation for broadcast communication.
            Essentially, it is a queue where only one will `enqueue` and multiple
            will `dequeue`. The max size of each item, together with the max number
            of items that can be stored in the buffer are known in advance.
            In this case, we don't need to synchronize the access to
            the buffer.
            Buffer memory layout:
            data                                 metadata
            |                                      |
            | (current_idx)                        | (current_idx)
            v                                      v
            +-------------------------------+----------------------------------------+
            | chunk0 | chunk1 | ... | chunk | metadata0 | metadata1 | ... | metadata |
            +-------------------------------+----------------------------------------+
            | max_chunks x max_chunk_bytes  | max_chunks x (1 + n_reader) bytes      |
            metadata memory layout: each byte is a flag, the first byte is the written
            flag, and the rest are reader flags. The flags are set to 0 by default.
            +--------------+--------------+--------------+-----+--------------+
            | written_flag | reader0_flag | reader1_flag | ... | readerN_flag |
            +--------------+--------------+--------------+-----+--------------+
            The state of metadata is as follows:
            (case 1) 0???...???: the block is not written yet, cannot read, can write
            (case 2) 1000...000: the block is just written, can read, cannot write
            (case 3) 1???...???: the block is written and read by some readers, can read if not read, cannot write
            (case 4) 1111...111: the block is written and read by all readers, cannot read, can write
            State transition for readers:
            When a reader finds a block that it can read (case 2 or 3), it can yield the block for caller to read.
            Only after the caller finishes reading the block, the reader can mark the block as read.
            Readers only mark the block as read (from 0 to 1), the writer marks the block as ready to read (from 1 to 0).
            State transition for writer:
            When the writer writes to a block (case 1 or 4), it first resets the written flag to 0, converting either case
            to case 1. Then it can yield the block for caller to write. After the caller finishes writing the block, the writer
            can reset the reader flags to 0, and mark the block as written (from 0 to 1).
            NOTE: the order is important here, first reset the reader flags (so that we are still in case 1), then mark the block as written. The state transition is atomic. If we do it in the reverse order, it will go through case 3 and then back to case 2, and readers might read the intermediate case 3, which is not correct.
            During creation, `name` is None and the buffer is created. We can pass the
            created object to other processes by pickling it. The other processes will
            get the name of the shared memory and open it, so that they can access the
            same shared memory buffer.

  L 132: __reduce__(self)

  L 143: __del__(self)

  L 150: get_data(self, current_idx: int)

  L 157: get_metadata(self, current_idx: int)


============================================================
FILE: python/sglang/srt/distributed/device_communicators/xpu_communicator.py
Functions: 3
============================================================


CLASS: XpuCommunicator
----------------------------------------
  L  12: __init__(self, group: ProcessGroup)

  L  20: all_reduce(self, x: torch.Tensor)
         ‚Üí torch.Tensor

  L  24: gather(self, input_: torch.Tensor, rank_in_group: int, dst: int, dim: int)


============================================================
FILE: python/sglang/srt/distributed/naive_distributed.py
Functions: 8
============================================================

MODULE FUNCTIONS:
----------------------------------------
  L 104: def get_naive_distributed()

  L 109: def set_naive_distributed(instance: NaiveDistributed)


CLASS: NaiveDistributed
----------------------------------------
  L  14: __init__(self, rank: int, world_size: int, rendezvous: str)

  L  25: get_rank(self)

  L  28: get_world_size(self)

  L  31: scatter(self, tensor: torch.Tensor, scatter_list: List[torch.Tensor], src: int)

  L  69: all_gather_object(self, obj: Any)
         ‚Üí List[Any]

  L  95: barrier(self)


============================================================
FILE: python/sglang/srt/distributed/parallel_state.py
Functions: 63
============================================================

MODULE FUNCTIONS:
----------------------------------------
  L 117: def inplace_all_reduce(tensor: torch.Tensor, group_name: str)
         ‚Üí None

  L 124: def inplace_all_reduce_fake(tensor: torch.Tensor, group_name: str)
         ‚Üí None

  L 134: def outplace_all_reduce(tensor: torch.Tensor,
        group_name: str,
        outplace_all_reduce_method: str)
         ‚Üí torch.Tensor

  L 143: def outplace_all_reduce_fake(tensor: torch.Tensor,
        group_name: str,
        outplace_all_reduce_method: str)
         ‚Üí torch.Tensor

  L 155: def reg_all_gather_into_tensor(output: torch.Tensor,
        input: torch.Tensor,
        group_name: str)
         ‚Üí None

  L 164: def reg_all_gather_into_tensor_fake(output: torch.Tensor,
        input: torch.Tensor,
        group_name: str)
         ‚Üí None

  L1187: def get_world_group()
         ‚Üí GroupCoordinator

  L1192: def init_world_group(ranks: List[int], local_rank: int, backend: str)
         ‚Üí GroupCoordinator

  L1209: def init_model_parallel_group(group_ranks: List[List[int]],
        local_rank: int,
        backend: str,
        use_custom_allreduce: Optional[bool],
        use_message_queue_broadcaster: bool,
        group_name: Optional[str],
        use_mscclpp_allreduce: Optional[bool])
         ‚Üí GroupCoordinator

  L1245: def set_pdmux_status(enable_prefill_multiplexing: bool)

  L1250: def get_tp_group()
         ‚Üí GroupCoordinator

  L1264: def get_moe_ep_group()
         ‚Üí GroupCoordinator

  L1269: def get_moe_tp_group()
         ‚Üí GroupCoordinator

  L1280: def get_pp_group()
         ‚Üí GroupCoordinator

  L1290: def graph_capture()
         üìù `graph_capture` is a context manager which should surround the code that
            is capturing the CUDA graph. Its main purpose is to ensure that the
            some operations will be run after the graph is captured, before the graph
            is replayed. It returns a `GraphCaptureContext` object which contains the
            necessary data for the graph capture. Currently, it only contains the
            stream that the graph capture is running on. This stream is set to the
            current CUDA stream when the context manager is entered and reset to the
            default stream when the context manager is exited. This is to ensure that
            the graph capture is running on a separate stream from the default stream,
            in order to explicitly distinguish the kernels to capture
            from other kernels possibly launched on background in the default stream.
         @contextmanager

  L1316: def set_custom_all_reduce(enable: bool)

  L1321: def set_mscclpp_all_reduce(enable: bool)

  L1326: def init_distributed_environment(world_size: int,
        rank: int,
        distributed_init_method: str,
        local_rank: int,
        backend: str,
        timeout: Optional[int])

  L1381: def initialize_model_parallel(tensor_model_parallel_size: int,
        expert_model_parallel_size: int,
        pipeline_model_parallel_size: int,
        backend: Optional[str],
        duplicate_tp_group: bool)
         ‚Üí None
         üìù Initialize model parallel groups.
            Arguments:
            tensor_model_parallel_size: number of GPUs used for tensor model
            parallelism.
            pipeline_model_parallel_size: number of GPUs used for pipeline model
            parallelism.
            Let's say we have a total of 8 GPUs denoted by g0 ... g7 and we
            use 2 GPUs to parallelize the model tensor, and 4 GPUs to parallelize
            the model pipeline. The present function will
            create 4 tensor model-parallel groups and 2 pipeline model-parallel groups:
            4 tensor model-parallel groups:
            [g0, g1], [g2, g3], [g4, g5], [g6, g7]
            2 pipeline model-parallel groups:
            [g0, g2, g4, g6], [g1, g3, g5, g7]
            Note that for efficiency, the caller should make sure adjacent ranks
            are on the same DGX box. For example if we are using 2 DGX-1 boxes
            with a total of 16 GPUs, rank 0 to 7 belong to the first box and
            ranks 8 to 15 belong to the second box.

  L1518: def ensure_model_parallel_initialized(tensor_model_parallel_size: int,
        expert_model_parallel_size: int,
        pipeline_model_parallel_size: int,
        backend: Optional[str])
         ‚Üí None
         üìù Helper to initialize model parallel groups if they are not initialized,
            or ensure tensor-parallel and pipeline-parallel sizes are equal to expected
            values if the model parallel groups are initialized.

  L1551: def model_parallel_is_initialized()
         üìù Check if tensor and pipeline parallel groups are initialized.

  L1560: def patch_tensor_parallel_group(tp_group: GroupCoordinator)
         üìù Patch the tp group temporarily until this function ends.
            This method is for draft workers of speculative decoding to run draft model
            with different tp degree from that of target model workers.
            Args:
            tp_group (GroupCoordinator): the tp group coordinator
         @contextmanager

  L1584: def get_tensor_model_parallel_world_size()
         üìù Return world size for the tensor model parallel group.

  L1589: def get_tensor_model_parallel_rank()
         üìù Return my rank for the tensor model parallel group.

  L1594: def get_moe_expert_parallel_world_size()
         üìù Return world size for the moe expert parallel group.

  L1599: def get_moe_expert_parallel_rank()
         üìù Return my rank for the moe expert parallel group.

  L1604: def get_moe_tensor_parallel_world_size()
         üìù Return world size for the moe tensor parallel group.

  L1609: def get_moe_tensor_parallel_rank()
         üìù Return my rank for the moe tensor parallel group.

  L1614: def destroy_model_parallel()
         üìù Set the groups to none and destroy them.

  L1627: def destroy_distributed_environment()

  L1636: def cleanup_dist_env_and_memory(shutdown_ray: bool)

  L1661: def in_the_same_node_as(pg: ProcessGroup, source_rank: int)
         ‚Üí List[bool]
         üìù This is a collective operation that returns if each rank is in the same node
            as the source rank. It tests if processes are attached to the same
            memory system (shared access to shared memory).

  L1732: def monkey_patch_vllm_parallel_state(reverse: bool)


CLASS: GroupCoordinator
----------------------------------------
  L 214: __init__(self, group_ranks: List[List[int]], local_rank: int, torch_distributed_backend: Union[str, Backend], use_pynccl: bool, use_pymscclpp: bool, use_custom_allreduce: bool, use_hpu_communicator: bool, use_xpu_communicator: bool, use_npu_communicator: bool, use_message_queue_broadcaster: bool, group_name: Optional[str])

  L 367: __repr__(self)

  L 375: first_rank(self)
         üìù Return the global rank of the first process in the group

  L 380: last_rank(self)
         üìù Return the global rank of the last process in the group

  L 385: is_first_rank(self)
         üìù Return whether the caller is the first process in the group

  L 390: is_last_rank(self)
         üìù Return whether the caller is the last process in the group

  L 395: next_rank(self)
         üìù Return the global rank of the process that follows the caller

  L 402: prev_rank(self)
         üìù Return the global rank of the process that precedes the caller

  L 409: graph_capture(self, graph_capture_context: Optional[GraphCaptureContext])

  L 469: all_reduce(self, input_: torch.Tensor)
         ‚Üí torch.Tensor
         üìù User-facing all-reduce function before we actually call the
            all-reduce operation.
            We need this because Dynamo does not support passing an arbitrary
            object (`self` in this case) to a custom op. We need to pass the
            group name as a string, and then look up the group coordinator from
            the group name, dispatch the all-reduce operation to the group
            coordinator.
            In addition, PyTorch custom ops do not support mutation or returning
            a new tensor in the same op. So we need to figure out if the op is
            in-place or out-of-place ahead of time.

  L 576: reduce_scatter_tensor(self, output: torch.Tensor, input: torch.Tensor)
         ‚Üí None

  L 585: reduce_scatter(self, output: torch.Tensor, input_list: List[torch.Tensor])
         ‚Üí None

  L 594: reduce_scatterv(self, input_: torch.Tensor, output: Optional[torch.Tensor], sizes: Optional[List[int]])
         ‚Üí torch.Tensor

  L 636: all_gather_into_tensor(self, output: torch.Tensor, input: torch.Tensor)

  L 644: all_gather(self, input_: torch.Tensor, dim: int, output_tensor_list: Optional[List[torch.Tensor]])
         ‚Üí torch.Tensor

  L 717: all_gatherv(self, input_: Union[torch.Tensor, List[torch.Tensor]], sizes: Optional[List[int]])
         ‚Üí Union[torch.Tensor, List[torch.Tensor]]
         üìù Supports varying sizes per rank and input tensor list.
            `sizes`: a list of len(world_size) with the number of items per rank to gather.

  L 765: gather(self, input_: torch.Tensor, dst: int, dim: int)
         ‚Üí Optional[torch.Tensor]
         üìù NOTE: We assume that the input tensor is on the same device across
            all the ranks.
            NOTE: `dst` is the local rank of the destination rank.

  L 800: broadcast(self, input_: torch.Tensor, src: int)
         üìù Broadcast the input tensor.
            NOTE: `src` is the local rank of the source rank.

  L 815: broadcast_object(self, obj: Optional[Any], src: int)
         üìù Broadcast the input object.
            NOTE: `src` is the local rank of the source rank.

  L 839: broadcast_object_list(self, obj_list: List[Any], src: int, group: Optional[ProcessGroup])
         üìù Broadcast the input object list.
            NOTE: `src` is the local rank of the source rank.

  L 856: all_gather_object(self, obj: Any)
         ‚Üí List[Any]

  L 861: send_object(self, obj: Any, dst: int)
         ‚Üí None
         üìù Send the input object list to the destination rank.

  L 895: recv_object(self, src: int)
         ‚Üí Any
         üìù Receive the input object list from the source rank.

  L 933: broadcast_tensor_dict(self, tensor_dict: Optional[Dict[str, Union[torch.Tensor, Any]]], src: int, group: Optional[ProcessGroup], metadata_group: Optional[ProcessGroup])
         ‚Üí Optional[Dict[str, Union[torch.Tensor, Any]]]
         üìù Broadcast the input tensor dictionary.
            NOTE: `src` is the local rank of the source rank.

  L1015: send_tensor_dict(self, tensor_dict: Dict[str, Union[torch.Tensor, Any]], dst: Optional[int], all_gather_group: Optional['GroupCoordinator'])
         ‚Üí Optional[Dict[str, Union[torch.Tensor, Any]]]
         üìù Send the input tensor dictionary.
            NOTE: `dst` is the local rank of the source rank.

  L1070: recv_tensor_dict(self, src: Optional[int], all_gather_group: Optional['GroupCoordinator'])
         ‚Üí Optional[Dict[str, Union[torch.Tensor, Any]]]
         üìù Recv the input tensor dictionary.
            NOTE: `src` is the local rank of the source rank.

  L1132: barrier(self)
         üìù Barrier synchronization among the group.
            NOTE: don't use `device_group` here! `barrier` in NCCL is
            terrible because it is internally a broadcast operation with
            secretly created GPU tensors. It is easy to mess up the current
            device. Use the CPU group instead.

  L1141: send(self, tensor: torch.Tensor, dst: Optional[int])
         ‚Üí None
         üìù Sends a tensor to the destination rank in a non-blocking way

  L1153: recv(self, size: torch.Size, dtype: torch.dtype, src: Optional[int])
         ‚Üí torch.Tensor
         üìù Receives a tensor from the source rank.

  L1169: destroy(self)


============================================================
FILE: python/sglang/srt/distributed/utils.py
Functions: 12
============================================================

MODULE FUNCTIONS:
----------------------------------------
  L  21: def ensure_divisibility(numerator, denominator)
         üìù Ensure that numerator is divisible by the denominator.

  L  28: def divide(numerator, denominator)
         üìù Ensure that numerator is divisible by the denominator and return
            the division value.

  L  35: def split_tensor_along_last_dim(tensor: torch.Tensor,
        num_partitions: int,
        contiguous_split_chunks: bool)
         ‚Üí Sequence[torch.Tensor]
         üìù Split a tensor along its last dimension.
            Arguments:
            tensor: input tensor.
            num_partitions: number of partitions to split the tensor
            contiguous_split_chunks: If True, make each chunk contiguous
            in memory.
            Returns:
            A list of Tensors

  L  63: def get_pp_indices(num_hidden_layers: int, pp_rank: int, pp_size: int)
         ‚Üí Tuple[int, int]
         üìù Try to evenly distribute layers across partitions.
            If the number of layers is not divisible by the number of partitions,
            the last partition will have the remaining layers.


CLASS: StatelessProcessGroup
----------------------------------------
  L 118: __post_init__(self)

  L 124: send_obj(self, obj: Any, dst: int)
         üìù Send an object to a destination rank.

  L 132: expire_data(self)
         üìù Expire data that is older than `data_expiration_seconds` seconds.

  L 143: recv_obj(self, src: int)
         ‚Üí Any
         üìù Receive an object from a source rank.

  L 151: broadcast_obj(self, obj: Optional[Any], src: int)
         ‚Üí Any
         üìù Broadcast an object from a source rank to all other ranks.
            It does not clean up after all ranks have received the object.
            Use it for limited times, e.g., for initialization.

  L 169: all_gather_obj(self, obj: Any)
         ‚Üí list[Any]
         üìù All gather an object from all ranks.

  L 181: barrier(self)
         üìù A barrier to synchronize all ranks.

  L 190: create(host: str, port: int, rank: int, world_size: int, data_expiration_seconds: int)
         ‚Üí 'StatelessProcessGroup'
         üìù A replacement for `torch.distributed.init_process_group` that does not
            pollute the global state.
            If we have process A and process B called `torch.distributed.init_process_group`
            to form a group, and then we want to form another group with process A, B, C,
            D, it is not possible in PyTorch, because process A and process B have already
            formed a group, and process C and process D cannot join that group. This
            function is a workaround for this issue.
            `torch.distributed.init_process_group` is a global call, while this function
            is a stateless call. It will return a `StatelessProcessGroup` object that can be
            used for exchanging metadata. With this function, process A and process B
            can call `StatelessProcessGroup.create` to form a group, and then process A, B,
            C, and D can call `StatelessProcessGroup.create` to form another group.


============================================================
FILE: python/sglang/srt/entrypoints/EngineBase.py
Functions: 8
============================================================


CLASS: EngineBase
----------------------------------------
  L  14: generate(self, prompt: Optional[Union[List[str], str]], sampling_params: Optional[Union[List[Dict], Dict]], input_ids: Optional[Union[List[List[int]], List[int]]], image_data: Optional[Union[List[str], str]], return_logprob: Optional[Union[List[bool], bool]], logprob_start_len: Optional[Union[List[int], int]], top_logprobs_num: Optional[Union[List[int], int]], token_ids_logprob: Optional[Union[List[List[int]], List[int]]], lora_path: Optional[Union[List[Optional[str]], Optional[str]]], custom_logit_processor: Optional[Union[List[str], str]], return_hidden_states: Optional[bool], stream: Optional[bool], bootstrap_host: Optional[Union[List[str], str]], bootstrap_port: Optional[Union[List[int], int]], bootstrap_room: Optional[Union[List[int], int]], data_parallel_rank: Optional[int])
         ‚Üí Union[Dict, Iterator[Dict]]
         üìù Generate outputs based on given inputs.

  L  37: flush_cache(self)
         üìù Flush the cache of the engine.

  L  42: update_weights_from_tensor(self, named_tensors: List[Tuple[str, torch.Tensor]], load_format: Optional[str], flush_cache: bool)
         üìù Update model weights with in-memory tensor data.

  L  51: load_lora_adapter(self, lora_name: str, lora_path: str)
         üìù Load a new LoRA adapter without re-launching the engine.

  L  55: unload_lora_adapter(self, lora_name: str)
         üìù Unload a LoRA adapter without re-launching the engine.

  L  60: release_memory_occupation(self)
         üìù Release GPU memory occupation temporarily.

  L  65: resume_memory_occupation(self)
         üìù Resume GPU memory occupation which is previously released.

  L  70: shutdown(self)
         üìù Shutdown the engine and clean up resources.


============================================================
FILE: python/sglang/srt/entrypoints/context.py
Functions: 23
============================================================


CLASS: ConversationContext
----------------------------------------
  L  28: append_output(self, output)
         ‚Üí None

  L  32: call_tool(self)
         ‚Üí list[Message]

  L  36: need_builtin_tool_call(self)
         ‚Üí bool

  L  40: render_for_completion(self)
         ‚Üí list[int]


CLASS: HarmonyContext
----------------------------------------
  L  64: __init__(self, messages: list, tool_sessions: dict[str, Union['ClientSession', Tool]])

  L  82: append_output(self, output)
         ‚Üí None

  L 114: messages(self)
         ‚Üí list

  L 117: need_builtin_tool_call(self)
         ‚Üí bool

  L 126: call_tool(self)
         ‚Üí list[Message]

  L 142: render_for_completion(self)
         ‚Üí list[int]

  L 145: call_search_tool(self, tool_session: Union['ClientSession', Tool], last_msg: Message)
         ‚Üí list[Message]

  L 158: call_python_tool(self, tool_session: Union['ClientSession', Tool], last_msg: Message)
         ‚Üí list[Message]


CLASS: SimpleContext
----------------------------------------
  L  46: __init__(self)

  L  49: append_output(self, output)
         ‚Üí None

  L  52: need_builtin_tool_call(self)
         ‚Üí bool

  L  55: call_tool(self)
         ‚Üí list[Message]

  L  58: render_for_completion(self)
         ‚Üí list[int]


CLASS: StreamingHarmonyContext
----------------------------------------
  L 184: __init__(self)

  L 193: messages(self)
         ‚Üí list

  L 196: append_output(self, output)
         ‚Üí None

  L 226: is_expecting_start(self)
         ‚Üí bool

  L 229: is_assistant_action_turn(self)
         ‚Üí bool

  L 232: render_for_completion(self)
         ‚Üí list[int]


============================================================
FILE: python/sglang/srt/entrypoints/engine.py
Functions: 31
============================================================


CLASS: Engine
----------------------------------------
  L 103: __init__(self)
         üìù The arguments of this function is the same as `sglang/srt/server_args.py::ServerArgs`.
            Please refer to `ServerArgs` for the documentation.

  L 140: generate(self, prompt: Optional[Union[List[str], str]], sampling_params: Optional[Union[List[Dict], Dict]], input_ids: Optional[Union[List[List[int]], List[int]]], image_data: Optional[MultimodalDataInputFormat], audio_data: Optional[MultimodalDataInputFormat], video_data: Optional[MultimodalDataInputFormat], return_logprob: Optional[Union[List[bool], bool]], logprob_start_len: Optional[Union[List[int], int]], top_logprobs_num: Optional[Union[List[int], int]], token_ids_logprob: Optional[Union[List[List[int]], List[int]]], lora_path: Optional[List[Optional[str]]], custom_logit_processor: Optional[Union[List[str], str]], return_hidden_states: bool, stream: bool, bootstrap_host: Optional[Union[List[str], str]], bootstrap_port: Optional[Union[List[int], int]], bootstrap_room: Optional[Union[List[int], int]], data_parallel_rank: Optional[int])
         ‚Üí Union[Dict, Iterator[Dict]]
         üìù The arguments of this function is the same as `sglang/srt/managers/io_struct.py::GenerateReqInput`.
            Please refer to `GenerateReqInput` for the documentation.

  L 221: async_generate(self, prompt: Optional[Union[List[str], str]], sampling_params: Optional[Union[List[Dict], Dict]], input_ids: Optional[Union[List[List[int]], List[int]]], image_data: Optional[MultimodalDataInputFormat], audio_data: Optional[MultimodalDataInputFormat], video_data: Optional[MultimodalDataInputFormat], return_logprob: Optional[Union[List[bool], bool]], logprob_start_len: Optional[Union[List[int], int]], top_logprobs_num: Optional[Union[List[int], int]], token_ids_logprob: Optional[Union[List[List[int]], List[int]]], lora_path: Optional[List[Optional[str]]], custom_logit_processor: Optional[Union[List[str], str]], return_hidden_states: bool, stream: bool, bootstrap_host: Optional[Union[List[str], str]], bootstrap_port: Optional[Union[List[int], int]], bootstrap_room: Optional[Union[List[int], int]], data_parallel_rank: Optional[int])
         ‚Üí Union[Dict, AsyncIterator[Dict]]
         üìù The arguments of this function is the same as `sglang/srt/managers/io_struct.py::GenerateReqInput`.
            Please refer to `GenerateReqInput` for the documentation.

  L 293: encode(self, prompt: Union[str, List[str], List[Dict], List[List[Dict]]], image_data: Optional[MultimodalDataInputFormat], audio_data: Optional[MultimodalDataInputFormat], video_data: Optional[MultimodalDataInputFormat])
         ‚Üí Dict
         üìù The arguments of this function is the same as `sglang/srt/managers/io_struct.py::EmbeddingReqInput`.
            Please refer to `EmbeddingReqInput` for the documentation.

  L 315: async_encode(self, prompt: Union[str, List[str], List[Dict], List[List[Dict]]], image_data: Optional[MultimodalDataInputFormat], audio_data: Optional[MultimodalDataInputFormat], video_data: Optional[MultimodalDataInputFormat])
         ‚Üí Dict
         üìù Asynchronous version of encode method.
            The arguments of this function is the same as `sglang/srt/managers/io_struct.py::EmbeddingReqInput`.
            Please refer to `EmbeddingReqInput` for the documentation.

  L 337: rerank(self, prompt: Union[List[List[str]]])
         ‚Üí Dict
         üìù The arguments of this function is the same as `sglang/srt/managers/io_struct.py::EmbeddingReqInput`.
            Please refer to `EmbeddingReqInput` for the documentation.

  L 351: shutdown(self)
         üìù Shutdown the engine

  L 355: __enter__(self)

  L 358: __exit__(self, exc_type, exc_value, traceback)

  L 362: flush_cache(self)

  L 366: start_profile(self)

  L 370: stop_profile(self)

  L 374: start_expert_distribution_record(self)

  L 380: stop_expert_distribution_record(self)

  L 386: dump_expert_distribution_record(self)

  L 392: get_server_info(self)

  L 404: init_weights_update_group(self, master_address: str, master_port: int, rank_offset: int, world_size: int, group_name: str, backend: str)
         üìù Initialize parameter update group.

  L 427: update_weights_from_distributed(self, names: list[str], dtypes: list[str], shapes: list[list[int]], group_name: str, flush_cache: bool)
         üìù Update weights from distributed source.

  L 448: update_weights_from_tensor(self, named_tensors: List[Tuple[str, torch.Tensor]], load_format: Optional[str], flush_cache: bool)
         üìù Update weights from distributed source. If there are going to be more updates, set `flush_cache` to be false
            to avoid duplicated cache cleaning operation.

  L 474: update_weights_from_disk(self, model_path: str, load_format: Optional[str])
         üìù Update the weights from disk inplace without re-launching the engine.
            This method allows updating the model weights from disk without restarting
            the engine. It can be used to load a different model or update weights with
            new training.

  L 495: get_weights_by_name(self, name: str, truncate_size: int)
         üìù Get weights by parameter name.

  L 503: load_lora_adapter(self, lora_name: str, lora_path: str, pinned: bool)
         üìù Load a new LoRA adapter without re-launching the engine.

  L 517: unload_lora_adapter(self, lora_name: str)
         üìù Unload a LoRA adapter without re-launching the engine.

  L 527: release_memory_occupation(self, tags: Optional[List[str]])

  L 534: resume_memory_occupation(self, tags: Optional[List[str]])

  L 541: freeze_gc(self)
         üìù To maintain a high performance server with low latency, we want to reduce the
            stalls caused by the garbage collector scanning through a large number of objects.
            It is usually helpful to start the server and warm it up with real requests to
            initialize many of the long-lived objects that do not need to be garbage collected.
            After sufficient warmup, we can call this function to freeze the garbage collector
            so that all objects created before this point are considered out of scope for garbage
            collection.

  L 561: collective_rpc(self, method: str)

  L 568: save_remote_model(self)

  L 571: save_sharded_model(self)

  L 574: score(self, query: Optional[Union[str, List[int]]], items: Optional[Union[str, List[str], List[List[int]]]], label_token_ids: Optional[List[int]], apply_softmax: bool, item_first: bool)
         ‚Üí List[List[float]]
         üìù Score the probability of specified token IDs appearing after the given (query + item) pair. For example:
            query = "<|user|>Is the following city the capital of France? "
            items = ["Paris <|assistant|>", "London <|assistant|>", "Berlin <|assistant|>"]
            label_token_ids = [2332, 1223] # Token IDs for "Yes" and "No"
            item_first = False
            This would pass the following prompts to the model:
            "<|user|>Is the following city the capital of France? Paris <|assistant|>"
            "<|user|>Is the following city the capital of France? London <|assistant|>"
            "<|user|>Is the following city the capital of France? Berlin <|assistant|>"
            The api would then return the probabilities of the model producing "Yes" and "No" as the next token.
            The output would look like:
            [[0.9, 0.1], [0.2, 0.8], [0.1, 0.9]]
            Args:
            query: The query text or pre-tokenized query token IDs. Must be provided.
            items: The item text(s) or pre-tokenized item token IDs. Must be provided.
            label_token_ids: List of token IDs to compute probabilities for. If None, no token probabilities will be computed.
            apply_softmax: Whether to normalize probabilities using softmax.
            item_first: If True, prepend items to query. Otherwise append items to query.
            Returns:
            List of dictionaries mapping token IDs to their probabilities for each item.
            Each dictionary in the list corresponds to one item input.
            Raises:
            ValueError: If query is not provided, or if items is not provided,
            or if token IDs are out of vocabulary, or if logprobs are not available for the specified tokens.

  L 625: async_score(self, query: Optional[Union[str, List[int]]], items: Optional[Union[str, List[str], List[List[int]]]], label_token_ids: Optional[List[int]], apply_softmax: bool, item_first: bool)
         ‚Üí List[List[float]]
         üìù Asynchronous version of score method.
            See score() for detailed documentation.


============================================================
FILE: python/sglang/srt/entrypoints/harmony_utils.py
Functions: 13
============================================================

MODULE FUNCTIONS:
----------------------------------------
  L  54: def get_encoding()

  L  61: def get_system_message(model_identity: Optional[str],
        reasoning_effort: Optional[Literal['high',
        'medium',
        'low']],
        start_date: Optional[str],
        browser_description: Optional[str],
        python_description: Optional[str])
         ‚Üí Message

  L  86: def get_developer_message(instructions: Optional[str],
        tools: Optional[list[Tool]])
         ‚Üí Message

  L 118: def get_user_message(content: str)
         ‚Üí Message

  L 122: def parse_response_input(response_msg: ResponseInputOutputItem,
        prev_responses: list[Union[ResponseOutputItem,
        ResponseReasoningItem]])
         ‚Üí Message

  L 174: def parse_response_output(output: ResponseOutputItem)
         ‚Üí Message

  L 190: def parse_chat_input(chat_msg)
         ‚Üí Message

  L 202: def render_for_completion(messages: list[Message])
         ‚Üí list[int]

  L 210: def get_stop_tokens_for_assistant_actions()
         ‚Üí list[int]

  L 214: def get_streamable_parser_for_assistant()
         ‚Üí StreamableParser

  L 218: def parse_output_message(message: Message)

  L 324: def parse_remaining_state(parser: StreamableParser)

  L 368: def parse_output_into_messages(token_ids: Iterable[int])


============================================================
FILE: python/sglang/srt/entrypoints/http_server.py
Functions: 56
============================================================

MODULE FUNCTIONS:
----------------------------------------
  L 128: def set_global_state(global_state: _GlobalState)

  L 134: async def lifespan(fast_api_app: FastAPI)
         @asynccontextmanager

  L 212: async def validation_exception_handler(request: Request, exc: HTTPException)
         üìù Enrich HTTP exception with status code and other details
         @app.exception_handler(HTTPException)

  L 225: async def validation_exception_handler(request: Request,
        exc: RequestValidationError)
         üìù Override FastAPI's default 422 validation error with 400
         @app.exception_handler(RequestValidationError)

  L 247: async def validate_json_request(raw_request: Request)
         üìù Validate that the request content-type is application/json.

  L 268: async def health_generate(request: Request)
         ‚Üí Response
         üìù Check the health of the inference server by sending a special request to generate one token.
            If the server is running something, this request will be ignored, so it creates zero overhead.
            If the server is not running anything, this request will be run, so we know whether the server is healthy.
         @app.get('/health')
         @app.get('/health_generate')

  L 339: async def get_model_info()
         üìù Get the model information.
         @app.get('/get_model_info')

  L 352: async def get_weight_version()
         üìù Get the current weight version.
         @app.get('/get_weight_version')

  L 360: async def get_server_info()
         @app.get('/get_server_info')

  L 374: async def get_load()
         @app.get('/get_load')

  L 381: async def set_internal_state(obj: SetInternalStateReq, request: Request)
         @app.api_route('/set_internal_state', methods=['POST', 'PUT'])

  L 388: async def generate_request(obj: GenerateReqInput, request: Request)
         üìù Handle a generate request.
         @app.api_route('/generate', methods=['POST', 'PUT'])

  L 425: async def generate_from_file_request(file: UploadFile, request: Request)
         üìù Handle a generate request, this is purely to work with input_embeds.
         @app.api_route('/generate_from_file', methods=['POST'])

  L 449: async def encode_request(obj: EmbeddingReqInput, request: Request)
         üìù Handle an embedding request.
         @app.api_route('/encode', methods=['POST', 'PUT'])

  L 461: async def classify_request(obj: EmbeddingReqInput, request: Request)
         üìù Handle a reward model request. Now the arguments and return values are the same as embedding models.
         @app.api_route('/classify', methods=['POST', 'PUT'])

  L 473: async def flush_cache()
         üìù Flush the radix cache.
         @app.api_route('/flush_cache', methods=['GET', 'POST'])

  L 484: async def clear_hicache_storage_backend()
         üìù Clear the hierarchical cache storage backend.
         @app.api_route('/clear_hicache_storage_backend', methods=['GET', 'POST'])

  L 494: async def start_profile_async(obj: Optional[ProfileReqInput])
         üìù Start profiling.
         @app.api_route('/start_profile', methods=['GET', 'POST'])

  L 515: async def stop_profile_async()
         üìù Stop profiling.
         @app.api_route('/stop_profile', methods=['GET', 'POST'])

  L 525: async def freeze_gc_async()
         üìù See engine.freeze_gc for more details.
         @app.api_route('/freeze_gc', methods=['GET', 'POST'])

  L 537: async def start_expert_distribution_record_async()
         üìù Start recording the expert distribution. Clear the previous record if any.
         @app.api_route('/start_expert_distribution_record', methods=['GET', 'POST'])

  L 547: async def stop_expert_distribution_record_async()
         üìù Stop recording the expert distribution.
         @app.api_route('/stop_expert_distribution_record', methods=['GET', 'POST'])

  L 557: async def dump_expert_distribution_record_async()
         üìù Dump expert distribution record.
         @app.api_route('/dump_expert_distribution_record', methods=['GET', 'POST'])

  L 567: async def update_weights_from_disk(obj: UpdateWeightFromDiskReqInput,
        request: Request)
         üìù Update the weights from disk inplace without re-launching the server.
         @app.post('/update_weights_from_disk')

  L 596: async def init_weights_update_group(obj: InitWeightsUpdateGroupReqInput,
        request: Request)
         üìù Initialize the parameter update group.
         @app.post('/init_weights_update_group')

  L 611: async def update_weights_from_tensor(obj: UpdateWeightsFromTensorReqInput,
        request: Request)
         üìù Update the weights from tensor inplace without re-launching the server.
            Notes:
            1. Ensure that the model is on the correct device (e.g., GPU) before calling this endpoint. If the model is moved to the CPU unexpectedly, it may cause performance issues or runtime errors.
            2. HTTP will transmit only the metadata of the tensor, while the tensor itself will be directly copied to the model.
            3. Any binary data in the named tensors should be base64 encoded.
         @app.post('/update_weights_from_tensor')

  L 637: async def update_weights_from_distributed(obj: UpdateWeightsFromDistributedReqInput,
        request: Request)
         üìù Update model parameter from distributed online.
         @app.post('/update_weights_from_distributed')

  L 660: async def update_weight_version(obj: UpdateWeightVersionReqInput,
        request: Request)
         üìù Update the weight version. This operation requires no active requests.
         @app.post('/update_weight_version')

  L 690: async def get_weights_by_name(obj: GetWeightsByNameReqInput, request: Request)
         üìù Get model parameter by name.
         @app.api_route('/get_weights_by_name', methods=['GET', 'POST'])

  L 703: async def release_memory_occupation(obj: ReleaseMemoryOccupationReqInput,
        request: Request)
         üìù Release GPU memory occupation temporarily.
         @app.api_route('/release_memory_occupation', methods=['GET', 'POST'])

  L 714: async def resume_memory_occupation(obj: ResumeMemoryOccupationReqInput,
        request: Request)
         üìù Resume GPU memory occupation.
         @app.api_route('/resume_memory_occupation', methods=['GET', 'POST'])

  L 725: async def slow_down(obj: SlowDownReqInput, request: Request)
         üìù Slow down the system deliberately. Only for testing. Example scenario:
            when we want to test performance of D in large-scale PD disaggregation and have no enough nodes for P,
            we can use this to slow down D to let it have enough running sequences, and then disable slowdown
            to let it run in full batch size.
         @app.api_route('/slow_down', methods=['GET', 'POST'])

  L 738: async def load_lora_adapter(obj: LoadLoRAAdapterReqInput, request: Request)
         üìù Load a new LoRA adapter without re-launching the server.
         @app.api_route('/load_lora_adapter', methods=['POST'])

  L 755: async def unload_lora_adapter(obj: UnloadLoRAAdapterReqInput, request: Request)
         üìù Load a new LoRA adapter without re-launching the server.
         @app.api_route('/unload_lora_adapter', methods=['POST'])

  L 772: async def open_session(obj: OpenSessionReqInput, request: Request)
         üìù Open a session, and return its unique session id.
         @app.api_route('/open_session', methods=['GET', 'POST'])

  L 786: async def close_session(obj: CloseSessionReqInput, request: Request)
         üìù Close the session.
         @app.api_route('/close_session', methods=['GET', 'POST'])

  L 796: async def configure_logging(obj: ConfigureLoggingReq, request: Request)
         üìù Configure the request logging options.
         @app.api_route('/configure_logging', methods=['GET', 'POST'])

  L 803: async def abort_request(obj: AbortReq, request: Request)
         üìù Abort a request.
         @app.post('/abort_request')

  L 815: async def parse_function_call_request(obj: ParseFunctionCallReq,
        request: Request)
         üìù A native API endpoint to parse function calls from a text.
         @app.post('/parse_function_call')

  L 837: async def separate_reasoning_request(obj: SeparateReasoningReqInput,
        request: Request)
         üìù A native API endpoint to separate reasoning from a text.
         @app.post('/separate_reasoning')

  L 857: async def pause_generation(request: Request)
         üìù Pause generation.
         @app.post('/pause_generation')

  L 867: async def continue_generation(request: Request)
         üìù Continue generation.
         @app.post('/continue_generation')

  L 880: async def openai_v1_completions(request: CompletionRequest,
        raw_request: Request)
         üìù OpenAI-compatible text completion endpoint.
         @app.post('/v1/completions', dependencies=[Depends(validate_json_request)])

  L 888: async def openai_v1_chat_completions(request: ChatCompletionRequest,
        raw_request: Request)
         üìù OpenAI-compatible chat completion endpoint.
         @app.post('/v1/chat/completions', dependencies=[Depends(validate_json_request)])

  L 902: async def openai_v1_embeddings(request: EmbeddingRequest, raw_request: Request)
         üìù OpenAI-compatible embeddings endpoint.
         @app.post('/v1/embeddings', response_class=ORJSONResponse, dependencies=[Depends(validate_json_request)])

  L 910: async def available_models()
         üìù Show available models. OpenAI-compatible endpoint.
         @app.get('/v1/models', response_class=ORJSONResponse)

  L 926: async def retrieve_model(model: str)
         üìù Retrieves a model instance, providing basic information about the model.
         @app.get('/v1/models/{model:path}', response_class=ORJSONResponse)

  L 951: async def v1_score_request(request: ScoringRequest, raw_request: Request)
         üìù Endpoint for the decoder-only scoring API. See Engine.score() for detailed documentation.
         @app.post('/v1/score', dependencies=[Depends(validate_json_request)])

  L 959: async def v1_responses_request(request: dict, raw_request: Request)
         üìù Endpoint for the responses API with reasoning support.
         @app.post('/v1/responses', dependencies=[Depends(validate_json_request)])

  L 979: async def v1_retrieve_responses(response_id: str, raw_request: Request)
         üìù Retrieve a response by ID.
         @app.get('/v1/responses/{response_id}')

  L 987: async def v1_cancel_responses(response_id: str, raw_request: Request)
         üìù Cancel a background response.
         @app.post('/v1/responses/{response_id}/cancel')

  L 997: async def v1_rerank_request(request: V1RerankReqInput, raw_request: Request)
         üìù Endpoint for reranking documents based on query relevance.
         @app.api_route('/v1/rerank', methods=['POST', 'PUT'], dependencies=[Depends(validate_json_request)])

  L1006: async def sagemaker_health()
         ‚Üí Response
         üìù Check the health of the http server.
         @app.get('/ping')

  L1012: async def sagemaker_chat_completions(request: ChatCompletionRequest,
        raw_request: Request)
         üìù OpenAI-compatible chat completion endpoint.
         @app.post('/invocations')

  L1023: async def vertex_generate(vertex_req: VertexGenerateReqInput,
        raw_request: Request)
         @app.post(os.environ.get('AIP_PREDICT_ROUTE', '/vertex_generate'))

  L1061: def launch_server(server_args: ServerArgs,
        pipe_finish_writer: Optional[multiprocessing.connection.Connection],
        launch_callback: Optional[Callable[[],
        None]])
         üìù Launch SRT (SGLang Runtime) Server.
            The SRT server consists of an HTTP server and an SRT engine.
            - HTTP server: A FastAPI server that routes requests to the engine.
            - The engine consists of three components:
            1. TokenizerManager: Tokenizes the requests and sends them to the scheduler.
            2. Scheduler (subprocess): Receives requests from the Tokenizer Manager, schedules batches, forwards them, and sends the output tokens to the Detokenizer Manager.
            3. DetokenizerManager (subprocess): Detokenizes the output tokens and sends the result back to the Tokenizer Manager.
            Note:
            1. The HTTP server, Engine, and TokenizerManager both run in the main process.
            2. Inter-process communication is done through IPC (each process uses a different port) via the ZMQ library.


============================================================
FILE: python/sglang/srt/entrypoints/http_server_engine.py
Functions: 8
============================================================

MODULE FUNCTIONS:
----------------------------------------
  L  20: def launch_server_process(server_args: ServerArgs)
         ‚Üí multiprocessing.Process


CLASS: HttpServerEngineAdapter
----------------------------------------
  L  58: __init__(self)

  L  78: update_weights_from_tensor(self, named_tensors: List[Tuple[str, torch.Tensor]], load_format: Optional[str], flush_cache: bool)
         üìù Update model weights from tensor data. The HTTP server will only post meta data, and the real weights will be copied directly from GPUs.
            Note: The model should be on GPUs rather than CPU for this functionality to work properly.
            If you encounter issues, ensure your model is loaded on GPU devices rather than CPU.

  L 102: shutdown(self)

  L 105: generate(self, prompt, sampling_params, input_ids, image_data, return_logprob, logprob_start_len, top_logprobs_num, token_ids_logprob, lora_path, custom_logit_processor)

  L 135: release_memory_occupation(self)

  L 138: resume_memory_occupation(self)

  L 141: flush_cache(self)


============================================================
FILE: python/sglang/srt/entrypoints/openai/protocol.py
Functions: 6
============================================================


CLASS: ChatCompletionRequest
----------------------------------------
  L 455: set_tool_choice_default(cls, values)

  L 465: normalize_reasoning_inputs(cls, values: Dict)

  L 493: set_json_schema(cls, values)


CLASS: CompletionRequest
----------------------------------------
  L 234: validate_max_tokens_positive(cls, v)


CLASS: ResponsesRequest
----------------------------------------
  L 790: to_sampling_params(self, default_max_tokens: int, default_params: Optional[Dict])
         ‚Üí Dict[str, Any]
         üìù Convert to sampling parameters for generation.


CLASS: ResponsesResponse
----------------------------------------
  L 861: from_request(cls, request: ResponsesRequest, sampling_params: Any, model_name: str, created_time: int, output: List[Union[ResponseOutputItem, ResponseReasoningItem, ResponseFunctionToolCall]], status: str, usage: Optional[UsageInfo])
         ‚Üí 'ResponsesResponse'
         üìù Create a response from a request.


============================================================
FILE: python/sglang/srt/entrypoints/openai/serving_base.py
Functions: 4
============================================================


CLASS: OpenAIServingBase
----------------------------------------
  L  21: __init__(self, tokenizer_manager: TokenizerManager)

  L  24: handle_request(self, request: OpenAIServingRequest, raw_request: Request)
         ‚Üí Union[Any, StreamingResponse, ErrorResponse]
         üìù Handle the specific request type with common pattern

  L 120: create_error_response(self, message: str, err_type: str, status_code: int, param: Optional[str])
         ‚Üí ORJSONResponse
         üìù Create an error response

  L 138: create_streaming_error_response(self, message: str, err_type: str, status_code: int)
         ‚Üí str
         üìù Create a streaming error response


============================================================
FILE: python/sglang/srt/entrypoints/openai/serving_chat.py
Functions: 1
============================================================


CLASS: OpenAIServingChat
----------------------------------------
  L  49: __init__(self, tokenizer_manager: TokenizerManager, template_manager: TemplateManager)


============================================================
FILE: python/sglang/srt/entrypoints/openai/serving_completions.py
Functions: 1
============================================================


CLASS: OpenAIServingCompletion
----------------------------------------
  L  34: __init__(self, tokenizer_manager: TokenizerManager, template_manager: TemplateManager)


============================================================
FILE: python/sglang/srt/entrypoints/openai/serving_embedding.py
Functions: 1
============================================================


CLASS: OpenAIServingEmbedding
----------------------------------------
  L  24: __init__(self, tokenizer_manager: TokenizerManager, template_manager: TemplateManager)


============================================================
FILE: python/sglang/srt/entrypoints/openai/serving_responses.py
Functions: 6
============================================================


CLASS: OpenAIServingResponses
----------------------------------------
  L  68: __init__(self, tokenizer_manager: TokenizerManager, template_manager: TemplateManager)
         ‚Üí None

  L 126: create_responses(self, request: ResponsesRequest, raw_request: Optional[Request])
         ‚Üí Union[AsyncGenerator[str, None], ResponsesResponse, ORJSONResponse]

  L 389: responses_full_generator(self, request: ResponsesRequest, sampling_params: Any, result_generator: AsyncIterator[Any], context: ConversationContext, model_name: str, tokenizer: Any, request_metadata: RequestResponseMetadata, created_time: Optional[int])
         ‚Üí Union[ResponsesResponse, ORJSONResponse]

  L 708: retrieve_responses(self, response_id: str)
         ‚Üí Union[ResponsesResponse, ORJSONResponse]

  L 722: cancel_responses(self, response_id: str)
         ‚Üí Union[ResponsesResponse, ORJSONResponse]

  L 771: responses_stream_generator(self, request: ResponsesRequest, sampling_params: Any, result_generator: AsyncIterator[StreamingHarmonyContext], context: StreamingHarmonyContext, model_name: str, tokenizer: Any, request_metadata: RequestResponseMetadata, created_time: Optional[int])
         ‚Üí AsyncGenerator[str, None]


============================================================
FILE: python/sglang/srt/entrypoints/openai/tool_server.py
Functions: 15
============================================================

MODULE FUNCTIONS:
----------------------------------------
  L  20: async def list_server_and_tools(server_url: str)

  L  30: def trim_schema(schema: dict)
         ‚Üí dict

  L  55: def post_process_tools_description(list_tools_result: 'ListToolsResult')
         ‚Üí 'ListToolsResult'


CLASS: DemoToolServer
----------------------------------------
  L 145: __init__(self)

  L 160: has_tool(self, tool_name: str)

  L 163: get_tool_description(self, tool_name: str)

  L 174: get_tool_session(self, tool_name: str)


CLASS: MCPToolServer
----------------------------------------
  L  89: __init__(self)

  L  92: add_tool_server(self, server_url: str)

  L 124: has_tool(self, tool_name: str)

  L 127: get_tool_description(self, tool_name: str)

  L 131: get_tool_session(self, tool_name: str)


CLASS: ToolServer
----------------------------------------
  L  76: has_tool(self, tool_name: str)

  L  80: get_tool_description(self, tool_name: str)

  L  84: get_tool_session(self, tool_name: str)
         ‚Üí AbstractAsyncContextManager[Any]


============================================================
FILE: python/sglang/srt/entrypoints/openai/usage_processor.py
Functions: 3
============================================================


CLASS: UsageProcessor
----------------------------------------
  L  18: calculate_response_usage(responses: List[Dict[str, Any]], n_choices: int, enable_cache_report: bool)
         ‚Üí UsageInfo

  L  44: calculate_streaming_usage(prompt_tokens: Mapping[int, int], completion_tokens: Mapping[int, int], cached_tokens: Mapping[int, int], n_choices: int, enable_cache_report: bool)
         ‚Üí UsageInfo

  L  70: calculate_token_usage(prompt_tokens: int, completion_tokens: int, cached_tokens: Optional[Dict[str, int]])
         ‚Üí UsageInfo
         üìù Calculate token usage information


============================================================
FILE: python/sglang/srt/entrypoints/openai/utils.py
Functions: 2
============================================================

MODULE FUNCTIONS:
----------------------------------------
  L  13: def to_openai_style_logprobs(input_token_logprobs,
        output_token_logprobs,
        input_top_logprobs,
        output_top_logprobs)

  L  50: def process_hidden_states_from_ret(ret_item: Dict[str,
        Any],
        request: Union[ChatCompletionRequest,
        CompletionRequest])
         ‚Üí Optional[List]
         üìù Process hidden states from a ret item in non-streaming response.
            Args:
            ret_item: Response item containing meta_info
            request: The original request object
            Returns:
            Processed hidden states for the last token, or None


============================================================
FILE: python/sglang/srt/entrypoints/tool.py
Functions: 7
============================================================


CLASS: HarmonyBrowserTool
----------------------------------------
  L  25: __init__(self)

  L  45: get_result(self, context: 'ConversationContext')
         ‚Üí Any

  L  56: tool_config(self)
         ‚Üí Any


CLASS: HarmonyPythonTool
----------------------------------------
  L  62: __init__(self)

  L  75: get_result(self, context: 'ConversationContext')
         ‚Üí Any

  L  86: tool_config(self)
         ‚Üí Any


CLASS: Tool
----------------------------------------
  L  19: get_result(self, context: 'ConversationContext')
         ‚Üí Any


============================================================
FILE: python/sglang/srt/eplb/eplb_algorithms/__init__.py
Functions: 2
============================================================

MODULE FUNCTIONS:
----------------------------------------
  L  17: def rebalance_experts(tokens_per_expert: torch.Tensor,
        num_physical_experts: int,
        num_local_physical_experts: int,
        num_groups: Optional[int],
        num_nodes: int,
        algorithm: EplbAlgorithm)

  L  51: def compute_algorithm(raw_algorithm: str,
        num_groups: Optional[int],
        num_nodes: int)
         ‚Üí EplbAlgorithm


============================================================
FILE: python/sglang/srt/eplb/eplb_algorithms/deepseek.py
Functions: 4
============================================================

MODULE FUNCTIONS:
----------------------------------------
  L   9: def balanced_packing(weight: torch.Tensor, num_packs: int)
         ‚Üí Tuple[torch.Tensor, torch.Tensor]
         üìù Pack n weighted objects to m packs, such that each bin contains exactly n/m objects and the weights of all packs
            are as balanced as possible.
            Parameters:
            weight: [X, n], the weight of each item
            num_packs: number of packs
            Returns:
            pack_index: [X, n], the pack index of each item
            rank_in_pack: [X, n], the rank of the item in the pack

  L  54: def replicate_experts(weight: torch.Tensor, num_phy: int)
         ‚Üí Tuple[torch.Tensor, torch.Tensor, torch.Tensor]
         üìù Replicate `num_log` experts to `num_phy` replicas, such that the maximum load of all replicas is minimized.
            Parameters:
            weight: [X, num_log]
            num_phy: total number of experts after replication
            Returns:
            phy2log: [X, num_phy], logical expert id of each physical expert
            rank: [X, num_phy], the replica rank
            logcnt: [X, num_log], number of replicas for each logical expert

  L  85: def rebalance_experts_hierarchical(weight: torch.Tensor,
        num_physical_experts: int,
        num_groups: int,
        num_nodes: int,
        num_gpus: int)
         üìù Parameters:
            weight: [num_moe_layers, num_logical_experts]
            num_physical_experts: number of physical experts after replication
            num_groups: number of expert groups
            num_nodes: number of server nodes, where the intra-node network (e.g, NVLink) is faster
            num_gpus: number of GPUs, must be a multiple of `num_nodes`
            Returns:
            physical_to_logical_map: [num_moe_layers, num_physical_experts]
            logical_to_physical_map: [num_moe_layers, num_logical_experts, X]
            logical_count: [num_moe_layers, num_logical_experts]

  L 170: def rebalance_experts(weight: torch.Tensor,
        num_replicas: int,
        num_groups: int,
        num_nodes: int,
        num_gpus: int,
        enable_hierarchical: bool)
         ‚Üí Tuple[torch.Tensor, torch.Tensor, torch.Tensor]
         üìù Entry point for expert-parallelism load balancer.
            Parameters:
            weight: [layers, num_logical_experts], the load statistics for all logical experts
            num_replicas: number of physical experts, must be a multiple of `num_gpus`
            num_groups: number of expert groups
            num_nodes: number of server nodes, where the intra-node network (e.g, NVLink) is faster
            num_gpus: number of GPUs, must be a multiple of `num_nodes`
            Returns:
            physical_to_logical_map: [layers, num_replicas], the expert index of each replica
            logical_to_physical_map: [layers, num_logical_experts, X], the replica indices for each expert
            expert_count: [layers, num_logical_experts], number of physical replicas for each logical expert


============================================================
FILE: python/sglang/srt/eplb/eplb_algorithms/deepseek_vec.py
Functions: 5
============================================================

MODULE FUNCTIONS:
----------------------------------------
  L   7: def pack_groups(tokens_per_group: torch.Tensor, num_nodes: int)
         ‚Üí torch.Tensor

  L  35: def make_redundant_experts_chunkwise(tokens_per_expert: torch.Tensor,
        num_physical_experts: int,
        num_local_physical_experts: int,
        num_physical_experts_per_chunk: int)
         ‚Üí Tuple[torch.Tensor, torch.Tensor, torch.Tensor]

  L 184: def decode_rebalance_experts(tokens_per_expert: torch.Tensor,
        num_physical_experts: int,
        num_local_physical_experts: int)

  L 197: def prefill_rebalance_experts(tokens_per_expert: torch.Tensor,
        num_physical_experts: int,
        num_local_physical_experts: int,
        num_groups: int,
        num_nodes: int)

  L 255: def rebalance_experts(tokens_per_expert: torch.Tensor,
        num_physical_experts: int,
        num_local_physical_experts: int,
        num_groups: Optional[int],
        num_nodes: int,
        enable_hierarchical: bool)


============================================================
FILE: python/sglang/srt/eplb/eplb_manager.py
Functions: 3
============================================================


CLASS: EPLBManager
----------------------------------------
  L  17: __init__(self, model_runner: 'ModelRunner')

  L  41: on_forward_pass_end(self)

  L  52: rebalance(self)


============================================================
FILE: python/sglang/srt/eplb/eplb_simulator/reader.py
Functions: 1
============================================================

MODULE FUNCTIONS:
----------------------------------------
  L  16: def read_mode_per_pass(dir_data: Path)
         üìù Read data from ExpertDistributionRecorder when recorded with mode `per_pass`


============================================================
FILE: python/sglang/srt/eplb/expert_distribution.py
Functions: 91
============================================================

MODULE FUNCTIONS:
----------------------------------------
  L 266: def get_global_expert_distribution_recorder()

  L 270: def set_global_expert_distribution_recorder(value)

  L 925: def compute_gpu_physical_count(physical_count_of_whatever: torch.Tensor,
        num_gpu: int)
         üìù output: gpu_physical_count_of_batch (..., num_layer, num_gpu)

  L 938: def compute_utilization_rate(gpu_physical_count_of_batch: torch.Tensor)
         üìù output: utilization_rate (..., num_layer)


CLASS: ExpertDistributionRecorder
----------------------------------------
  L  44: init_new(server_args: ServerArgs, expert_location_metadata: 'ExpertLocationMetadata', rank: int)

  L  62: with_current_layer(self, layer_idx)

  L  66: with_debug_name(self, debug_name)

  L  70: disable_this_region(self)

  L  74: with_forward_pass(self, forward_pass_id: int, forward_batch: ForwardBatch)

  L  77: on_select_experts(self, topk_ids: torch.Tensor)

  L  80: on_deepep_dispatch_normal(self, local_physical_count_of_layer: List[int], num_tokens_per_rank, num_tokens_per_rdma_rank, num_tokens_per_expert)

  L  89: on_deepep_dispatch_low_latency(self, local_physical_count_of_layer: torch.Tensor)

  L  94: start_record(self)

  L  97: stop_record(self)

  L 100: dump_record(self, output_mode: _OutputMode)

  L 104: recording(self)


CLASS: _Accumulator
----------------------------------------
  L 562: init_new(server_args: ServerArgs, expert_location_metadata: 'ExpertLocationMetadata', rank: int)
         ‚Üí '_Accumulator'

  L 572: get_class(server_args: ServerArgs)
         ‚Üí Type['_Accumulator']

  L 580: __init__(self, server_args: ServerArgs, expert_location_metadata: 'ExpertLocationMetadata', rank: int)

  L 590: get_single_pass_gatherer_keys(self)

  L 593: get_single_pass_gatherer_key(self, debug_name: Optional[str])

  L 596: append(self, forward_pass_id: int, gatherer_key: str, single_pass_data: Dict)

  L 604: reset(self)

  L 607: dump(self, output_mode: _OutputMode)


CLASS: _Buffer
----------------------------------------
  L 839: init_new(item_shape: Tuple, buffer_size: int, dtype, device)

  L 845: append(self, value: torch.Tensor)

  L 848: get_all(self)
         ‚Üí torch.Tensor

  L 851: reset(self)


CLASS: _CircularBuffer
----------------------------------------
  L 856: __init__(self, item_shape: Tuple, buffer_size: int, dtype, device)

  L 862: append(self, value: torch.Tensor)

  L 866: get_all(self)
         ‚Üí torch.Tensor

  L 869: reset(self)


CLASS: _DeepepLowLatencySinglePassGatherer
----------------------------------------
  L 528: __init__(self)

  L 531: on_deepep_dispatch_low_latency(self, layer_idx: int, local_physical_count_of_layer: torch.Tensor)


CLASS: _DeepepNormalSinglePassGatherer
----------------------------------------
  L 495: __init__(self)

  L 503: on_deepep_dispatch_normal(self, layer_idx: int, local_physical_count_of_layer: List[int], num_tokens_per_rank, num_tokens_per_rdma_rank, num_tokens_per_expert)

  L 514: collect(self)
         ‚Üí Dict


CLASS: _DequeCollection
----------------------------------------
  L 669: __init__(self, maxlens: List[int])

  L 672: append(self, value)

  L 676: clear(self)

  L 680: mean(self)
         ‚Üí Dict[int, float]


CLASS: _DetailAccumulator
----------------------------------------
  L 685: __init__(self)

  L 689: get_single_pass_gatherer_keys(self)

  L 694: get_single_pass_gatherer_key(self, debug_name: Optional[str])

  L 699: append(self, forward_pass_id: int, gatherer_key: str, single_pass_data: Dict)

  L 725: reset(self)

  L 729: dump(self, output_mode: _OutputMode)


CLASS: _DetailSinglePassGatherer
----------------------------------------
  L 346: __init__(self, server_args: ServerArgs, expert_location_metadata: 'ExpertLocationMetadata', rank: int)

  L 370: on_forward_pass_start(self, forward_batch: ForwardBatch)

  L 381: on_select_experts(self, layer_idx: int, topk_ids: torch.Tensor)

  L 386: on_deepep_dispatch_normal(self, layer_idx: int, local_physical_count_of_layer: List[int], num_tokens_per_rank, num_tokens_per_rdma_rank, num_tokens_per_expert)

  L 403: reset(self)

  L 408: collect(self)
         ‚Üí Dict


CLASS: _ExpertDistributionRecorderReal
----------------------------------------
  L 118: __init__(self, server_args: ServerArgs, expert_location_metadata: 'ExpertLocationMetadata', rank: int)

  L 146: with_current_layer(self, layer_idx)

  L 149: with_debug_name(self, debug_name)

  L 153: with_forward_pass(self, forward_pass_id: int, forward_batch: ForwardBatch)

  L 162: disable_this_region(self)
         üìù Context manager to temporarily disable recording.

  L 185: on_select_experts(self, topk_ids: torch.Tensor)

  L 188: on_deepep_dispatch_normal(self, local_physical_count_of_layer: List[int], num_tokens_per_rank, num_tokens_per_rdma_rank, num_tokens_per_expert)

  L 203: on_deepep_dispatch_low_latency(self, local_physical_count_of_layer: torch.Tensor)

  L 233: start_record(self)
         üìù Start recording the expert distribution.

  L 242: stop_record(self)
         üìù Stop recording the expert distribution.

  L 250: dump_record(self, output_mode: _OutputMode)
         üìù Dump the expert distribution record and reset the recorder after dumping.

  L 257: recording(self)


CLASS: _InfiniteBuffer
----------------------------------------
  L 874: __init__(self, item_shape: Tuple, dtype, device)

  L 879: append(self, value: torch.Tensor)

  L 894: get_all(self)
         ‚Üí torch.Tensor

  L 897: reset(self)


CLASS: _LayerBasedCpuSinglePassGatherer
----------------------------------------
  L 418: __init__(self)

  L 431: reset(self)


CLASS: _LayerBasedGpuSinglePassGatherer
----------------------------------------
  L 447: __init__(self)

  L 463: reset(self)

  L 466: collect(self)
         ‚Üí Dict


CLASS: _SelectExpertsSinglePassGatherer
----------------------------------------
  L 482: __init__(self)

  L 486: on_select_experts(self, layer_idx: int, topk_ids: torch.Tensor)


CLASS: _SinglePassGatherer
----------------------------------------
  L 280: init_new(server_args: ServerArgs, expert_location_metadata: 'ExpertLocationMetadata', rank: int)
         ‚Üí '_SinglePassGatherer'

  L 310: __init__(self, expert_location_metadata: 'ExpertLocationMetadata', rank: int)

  L 314: on_forward_pass_start(self, forward_batch: ForwardBatch)

  L 317: on_select_experts(self, layer_idx: int, topk_ids: torch.Tensor)

  L 320: on_deepep_dispatch_normal(self, layer_idx: int, local_physical_count_of_layer: List[int], num_tokens_per_rank, num_tokens_per_rdma_rank, num_tokens_per_expert)

  L 330: on_deepep_dispatch_low_latency(self, layer_idx: int, local_physical_count_of_layer: torch.Tensor)

  L 335: reset(self)

  L 338: collect(self)
         ‚Üí Dict


CLASS: _StatAccumulator
----------------------------------------
  L 742: __init__(self)

  L 756: append(self, forward_pass_id: int, gatherer_key: str, single_pass_data: Dict)

  L 768: reset(self)

  L 772: dump(self, output_mode: _OutputMode)


CLASS: _UtilizationRateAccumulatorMixin
----------------------------------------
  L 612: __init__(self)

  L 622: append(self, forward_pass_id: int, gatherer_key: str, single_pass_data: Dict)

  L 634: reset(self)


============================================================
FILE: python/sglang/srt/eplb/expert_location.py
Functions: 16
============================================================

MODULE FUNCTIONS:
----------------------------------------
  L 289: def get_global_expert_location_metadata()

  L 293: def set_global_expert_location_metadata(value)

  L 337: def compute_logical_to_rank_dispatch_physical_map(logical_to_all_physical_map: torch.Tensor,
        num_gpus: int,
        num_physical_experts: int,
        ep_rank: int,
        seed: int)

  L 431: def compute_initial_expert_location_metadata(server_args: ServerArgs,
        model_config: ModelConfig)
         ‚Üí Optional[ExpertLocationMetadata]


CLASS: ExpertLocationMetadata
----------------------------------------
  L  46: num_layers(self)
         ‚Üí int

  L  50: num_physical_experts(self)
         ‚Üí int

  L  54: num_local_physical_experts(self)
         ‚Üí int

  L  60: num_logical_experts(self)
         ‚Üí int

  L  64: ep_size(self)

  L  68: __post_init__(self)

  L  83: init_trivial(server_args: ServerArgs, model_config: ModelConfig)
         üìù Trivial location - logical expert i corresponds to physical expert i

  L 107: init_by_mapping(server_args: ServerArgs, model_config: ModelConfig, physical_to_logical_map)

  L 135: init_by_eplb(server_args: ServerArgs, model_config: ModelConfig, logical_count: torch.Tensor)

  L 242: update(self, other: 'ExpertLocationMetadata', update_layer_ids: List[int])

  L 273: logical_to_all_physical(self, layer_id: int, logical_expert_id: int)
         ‚Üí List[int]


CLASS: ModelConfigForExpertLocation
----------------------------------------
  L 421: from_model_config(model_config: ModelConfig)


============================================================
FILE: python/sglang/srt/eplb/expert_location_dispatch.py
Functions: 3
============================================================

MODULE FUNCTIONS:
----------------------------------------
  L  64: def transform_select_experts_inputs(router_logits: torch.Tensor,
        correction_bias: Optional[torch.Tensor],
        info: Optional[ExpertLocationDispatchInfo])

  L  76: def topk_ids_logical_to_physical(topk_ids: torch.Tensor,
        info: Optional[ExpertLocationDispatchInfo])
         ‚Üí torch.Tensor


CLASS: ExpertLocationDispatchInfo
----------------------------------------
  L  36: init_new(cls, layer_id: int)


============================================================
FILE: python/sglang/srt/eplb/expert_location_updater.py
Functions: 7
============================================================

MODULE FUNCTIONS:
----------------------------------------
  L 160: def create_temp_buffers(sample_tensors)

  L 164: def update_expert_weights_single_layer(routed_experts_weights: List[torch.Tensor],
        temp_buffers: List[torch.Tensor],
        old_physical_to_logical_map: List[int],
        new_physical_to_logical_map: List[int],
        num_local_physical_experts: int,
        num_gpu_per_node: int,
        rank: int,
        world_size: Optional[int],
        debug: bool,
        log_metrics: bool)


CLASS: ExpertLocationUpdater
----------------------------------------
  L  37: __init__(self)

  L  40: update(self, routed_experts_weights_of_layer: Dict[int, List[torch.Tensor]], new_expert_location_metadata: ExpertLocationMetadata, update_layer_ids: List[int], nnodes: int, rank: int)


CLASS: _ChunkUtils
----------------------------------------
  L 474: __init__(self)

  L 478: chunk_value_from_element_value(self, element_value)

  L 486: element_values_from_chunk_value(self, chunk_value)
         ‚Üí List


============================================================
FILE: python/sglang/srt/function_call/base_format_detector.py
Functions: 8
============================================================


CLASS: BaseFormatDetector
----------------------------------------
  L  27: __init__(self)

  L  69: parse_base_json(self, action: Any, tools: List[Tool])
         ‚Üí List[ToolCallItem]

  L  94: detect_and_parse(self, text: str, tools: List[Tool])
         ‚Üí StreamingParseResult
         üìù Parses the text in one go. Returns success=True if the format matches, otherwise False.
            Note that leftover_text here represents "content that this parser will not consume further".

  L 115: parse_streaming_increment(self, new_text: str, tools: List[Tool])
         ‚Üí StreamingParseResult
         üìù Streaming incremental parsing with tool validation.
            This base implementation works best with formats where:
            1. bot_token is followed immediately by JSON (e.g., bot_token + JSON_array)
            2. JSON can be parsed incrementally using partial_json_loads
            3. Multiple tool calls are separated by "; " or ", "
            Examples of incompatible formats (need custom implementation, may reuse some logic from this class):
            - Each tool call is wrapped in a separate block: See Qwen25Detector
            - Multiple separate blocks: [TOOL_CALLS] [...]
            [TOOL_CALLS] [...]
            - Tool call is Pythonic style
            For incompatible formats, detectors should override this method with custom logic.

  L 318: has_tool_call(self, text: str)
         ‚Üí bool
         üìù Check if the given text contains function call markers specific to this format.

  L 324: supports_structural_tag(self)
         ‚Üí bool
         üìù Return True if this detector supports structural tag format.

  L 329: structure_info(self)
         ‚Üí _GetInfoFunc
         üìù Return a function that creates StructureInfo for constrained generation.
            The returned function takes a tool name and returns a StructureInfo object
            containing the begin/end patterns and trigger tokens needed for constrained
            generation of function calls in this format.
            Returns:
            A function that takes a tool name (str) and returns StructureInfo

  L 343: build_ebnf(self, tools: List[Tool])
         ‚Üí str
         üìù Build an EBNF grammar for constrained generation of function calls.
            This method generates an Extended Backus-Naur Form (EBNF) grammar that
            constrains the model's output to valid function calls in this format.
            The grammar should include all available tools and their parameter schemas.
            Args:
            tools: List of available tools/functions that can be called
            Returns:
            A string containing the EBNF grammar for this function call format
            The EBNF grammar should:
            - Define the overall structure of function calls in this format
            - Include all tool names from the provided tools list
            - Define valid JSON structures for function arguments
            - Handle multiple function calls if the format supports them
            Note:
            Most implementations use EBNFComposer.build_ebnf() utility with
            format-specific parameters rather than writing EBNF from scratch.


============================================================
FILE: python/sglang/srt/function_call/deepseekv31_detector.py
Functions: 6
============================================================


CLASS: DeepSeekV31Detector
----------------------------------------
  L  46: __init__(self)

  L  57: has_tool_call(self, text: str)
         ‚Üí bool
         üìù Check if the text contains a deepseek format tool call.

  L  61: detect_and_parse(self, text: str, tools: List[Tool])
         ‚Üí StreamingParseResult
         üìù One-time parsing: Detects and parses tool calls in the provided text.
            :param text: The complete text to parse.
            :param tools: List of available tools.
            :return: ParseResult indicating success or failure, consumed text, leftover text, and parsed calls.

  L  91: parse_streaming_increment(self, new_text: str, tools: List[Tool])
         ‚Üí StreamingParseResult
         üìù Streaming incremental parsing tool calls for DeepSeekV3 format.

  L 207: structure_info(self)
         ‚Üí _GetInfoFunc

  L 214: build_ebnf(self, tools: List[Tool])


============================================================
FILE: python/sglang/srt/function_call/deepseekv3_detector.py
Functions: 6
============================================================


CLASS: DeepSeekV3Detector
----------------------------------------
  L  46: __init__(self)

  L  55: has_tool_call(self, text: str)
         ‚Üí bool
         üìù Check if the text contains a deepseek format tool call.

  L  59: detect_and_parse(self, text: str, tools: List[Tool])
         ‚Üí StreamingParseResult
         üìù One-time parsing: Detects and parses tool calls in the provided text.
            :param text: The complete text to parse.
            :param tools: List of available tools.
            :return: ParseResult indicating success or failure, consumed text, leftover text, and parsed calls.

  L  89: parse_streaming_increment(self, new_text: str, tools: List[Tool])
         ‚Üí StreamingParseResult
         üìù Streaming incremental parsing tool calls for DeepSeekV3 format.

  L 205: structure_info(self)
         ‚Üí _GetInfoFunc

  L 212: build_ebnf(self, tools: List[Tool])


============================================================
FILE: python/sglang/srt/function_call/ebnf_composer.py
Functions: 3
============================================================


CLASS: EBNFComposer
----------------------------------------
  L  92: get_value_rule(prop: dict, function_format: Literal['pythonic', 'json', 'xml'])
         ‚Üí str

  L 132: get_type_mapping(function_format: str)
         ‚Üí Dict[str, str]
         üìù Get the complete type mapping for a given format.

  L 155: build_ebnf(tools, function_format: Literal['pythonic', 'json', 'xml'], sequence_start_token: Optional[str], sequence_end_token: Optional[str], individual_call_start_token: Optional[str], individual_call_end_token: Optional[str], tool_call_separator: Optional[str], call_rule_fmt: Optional[str], key_value_rule_fmt: Optional[str], key_value_separator: str)
         üìù Generalized EBNF builder for all detectors.
            Args:
            tools: List of Tool objects to generate EBNF grammar for
            function_format: The format of function calls, either "pythonic" or "json"
            sequence_start_token: Token that wraps the entire sequence of tool calls (start)
            sequence_end_token: Token that wraps the entire sequence of tool calls (end)
            individual_call_start_token: Token that wraps each individual tool call (start)
            individual_call_end_token: Token that wraps each individual tool call (end)
            tool_call_separator: The separator between multiple tool calls
            call_rule_fmt: Optional custom format string for call_{name} rule. It should define each function call's format, with
            the placeholders {name} for the function name and {arguments_rule} for the arguments rule. If None, a default
            format based on function_format will be used.
            key_value_rule_fmt: Optional custom format string for key-value pairs. It should define how each parameter is formatted,
            with placeholders {key} for the parameter name and {valrule} for the value rule. If None, a default format
            based on function_format will be used.


============================================================
FILE: python/sglang/srt/function_call/function_call_parser.py
Functions: 7
============================================================


CLASS: FunctionCallParser
----------------------------------------
  L  50: __init__(self, tools: List[Tool], tool_call_parser: str)

  L  61: has_tool_call(self, text: str)
         ‚Üí bool
         üìù Check if the given text contains a tool call in the format supported by this parser.
            This delegates to the detector's implementation.
            Args:
            text: The text to check for tool calls
            Returns:
            True if the text contains a tool call, False otherwise

  L  74: parse_non_stream(self, full_text: str)
         ‚Üí Tuple[str, list[ToolCallItem]]
         üìù One-time parsing of the full text to extract tool calls.
            Args:
            full_text: The complete text to parse
            Returns:
            A tuple containing:
            - The remaining text after parsing that was not consumed by the detector (can be treated as normal text)
            - A list of tool calls parsed from the text

  L  93: parse_stream_chunk(self, chunk_text: str)
         ‚Üí Tuple[str, list[ToolCallItem]]
         üìù Streaming incremental parsing of chunks of text as they arrive.
            Args:
            chunk_text: The new chunk of text to parse
            Returns:
            A tuple containing:
            - The normal text that should be displayed to the user
            - A list of tool calls parsed from the chunk

  L 117: get_structure_tag(self)
         ‚Üí StructuralTagResponseFormat
         üìù Generate a structural tag response format for all available tools.
            This creates the necessary structural tags that guide the model's output format.

  L 151: get_structure_constraint(self, tool_choice: Union[ToolChoice, Literal['auto', 'required']])
         ‚Üí Optional[Tuple[str, Any]]
         üìù Returns the appropriate structure constraint for tool calls based on the tool_choice.
            The constraint is used to guide the model's output format.
            Args:
            tool_choice: The tool choice setting from the request
            Returns:
            A tuple of (constraint_type, constraint_value) to be added to sampling parameters,
            or None if no constraint applies.

  L 178: get_ebnf(self, tool_choice: Union[ToolChoice, Literal['required']])
         ‚Üí Optional[str]
         üìù Get the EBNF grammar for the specified tool choice.
            Args:
            tool_choice: The tool choice specification
            Returns:
            EBNF grammar string, or None if no valid tools found
            Note:
            If a specific function is requested but not found in available tools,
            logs a warning and falls back to using all available tools for backward compatibility.


============================================================
FILE: python/sglang/srt/function_call/glm4_moe_detector.py
Functions: 9
============================================================

MODULE FUNCTIONS:
----------------------------------------
  L  19: def get_argument_type(func_name: str, arg_key: str, defined_tools: list)

  L  29: def parse_arguments(json_value)


CLASS: Glm4MoeDetector
----------------------------------------
  L  47: __init__(self)

  L  55: has_tool_call(self, text: str)
         ‚Üí bool
         üìù Check if the text contains a glm-4.5 format tool call.

  L  59: detect_and_parse(self, text: str, tools: List[Tool])
         ‚Üí StreamingParseResult
         üìù One-time parsing: Detects and parses tool calls in the provided text.
            :param text: The complete text to parse.
            :param tools: List of available tools.
            :return: ParseResult indicating success or failure, consumed text, leftover text, and parsed calls.

  L 101: parse_streaming_increment(self, new_text: str, tools: List[Tool])
         ‚Üí StreamingParseResult
         üìù Streaming incremental parsing tool calls for GLM-4.5 format.

  L 148: supports_structural_tag(self)
         ‚Üí bool

  L 151: structure_info(self)
         ‚Üí _GetInfoFunc

  L 154: build_ebnf(self, tools: List[Tool])


============================================================
FILE: python/sglang/srt/function_call/gpt_oss_detector.py
Functions: 6
============================================================


CLASS: GptOssDetector
----------------------------------------
  L  26: __init__(self)

  L  38: has_tool_call(self, text: str)
         ‚Üí bool
         üìù Check if text contains TypeScript-style function call markers.

  L  42: detect_and_parse(self, text: str, tools: List[Tool])
         ‚Üí StreamingParseResult
         üìù Parse TypeScript-style function calls from complete text.

  L  75: parse_streaming_increment(self, new_text: str, tools: List[Tool])
         ‚Üí StreamingParseResult
         üìù Parse incremental streaming text for TypeScript-style function calls.

  L 215: structure_info(self)
         ‚Üí _GetInfoFunc

  L 218: build_ebnf(self, tools: List[Tool])
         ‚Üí str


============================================================
FILE: python/sglang/srt/function_call/kimik2_detector.py
Functions: 6
============================================================


CLASS: KimiK2Detector
----------------------------------------
  L  34: __init__(self)

  L  53: has_tool_call(self, text: str)
         ‚Üí bool
         üìù Check if the text contains a KimiK2 format tool call.

  L  57: detect_and_parse(self, text: str, tools: List[Tool])
         ‚Üí StreamingParseResult
         üìù One-time parsing: Detects and parses tool calls in the provided text.
            :param text: The complete text to parse.
            :param tools: List of available tools.
            :return: ParseResult indicating success or failure, consumed text, leftover text, and parsed calls.

  L 100: parse_streaming_increment(self, new_text: str, tools: List[Tool])
         ‚Üí StreamingParseResult
         üìù Streaming incremental parsing tool calls for KimiK2 format.

  L 217: structure_info(self)
         ‚Üí _GetInfoFunc
         üìù Return function that creates StructureInfo for guided generation.

  L 229: build_ebnf(self, tools: List[Tool])
         ‚Üí str
         üìù Build EBNF grammar for KimiK2 tool call format.
            NOTE: The call_rule_fmt uses [0-9]+ for the function index to allow the grammar
            to accept any numeric index (0, 1, 2, etc.) for proper sequential indexing in
            multiple function call scenarios, while still maintaining the correct KimiK2
            format structure for constrained generation.


============================================================
FILE: python/sglang/srt/function_call/llama32_detector.py
Functions: 5
============================================================


CLASS: Llama32Detector
----------------------------------------
  L  27: __init__(self)

  L  36: has_tool_call(self, text: str)
         ‚Üí bool
         üìù Check if the text contains a Llama 3.2 format tool call.

  L  42: detect_and_parse(self, text: str, tools: List[Tool])
         ‚Üí StreamingParseResult
         üìù Parse function calls from text, handling multiple JSON objects.

  L  84: structure_info(self)
         ‚Üí _GetInfoFunc

  L  91: build_ebnf(self, tools: List[Tool])


============================================================
FILE: python/sglang/srt/function_call/mistral_detector.py
Functions: 5
============================================================


CLASS: MistralDetector
----------------------------------------
  L  33: __init__(self)
         üìù Initializes the detector with necessary state variables.

  L  43: has_tool_call(self, text: str)
         ‚Üí bool
         üìù Check if the text contains a Mistral format tool call.

  L  47: detect_and_parse(self, text: str, tools: List[Tool])
         ‚Üí StreamingParseResult
         üìù One-time parsing: Detects and parses tool calls in the provided text.
            :param text: The complete text to parse.
            :param tools: List of available tools.
            :return: ParseResult indicating success or failure, consumed text, leftover text, and parsed calls.

  L 125: structure_info(self)
         ‚Üí _GetInfoFunc

  L 132: build_ebnf(self, tools: List[Tool])


============================================================
FILE: python/sglang/srt/function_call/pythonic_detector.py
Functions: 7
============================================================


CLASS: PythonicDetector
----------------------------------------
  L  34: __init__(self)

  L  49: has_tool_call(self, text: str)
         ‚Üí bool

  L  52: detect_and_parse(self, text: str, tools: List[Tool])
         ‚Üí StreamingParseResult

  L 157: parse_streaming_increment(self, new_text: str, tools: List[Tool])
         ‚Üí StreamingParseResult
         üìù Streaming incremental parsing for pythonic tool calls.
            Buffers input until a complete pythonic tool call (from [ to ]) is found,
            then parses and emits any detected calls.

  L 218: supports_structural_tag(self)
         ‚Üí bool

  L 221: structure_info(self)
         ‚Üí _GetInfoFunc

  L 224: build_ebnf(self, tools: List[Tool])
         ‚Üí Optional[str]


============================================================
FILE: python/sglang/srt/function_call/qwen25_detector.py
Functions: 6
============================================================


CLASS: Qwen25Detector
----------------------------------------
  L  34: __init__(self)
         üìù Initializes the detector with necessary state variables.

  L  44: has_tool_call(self, text: str)
         ‚Üí bool
         üìù Check if the text contains a Qwen 2.5 format tool call.

  L  48: detect_and_parse(self, text: str, tools: List[Tool])
         ‚Üí StreamingParseResult
         üìù One-time parsing: Detects and parses tool calls in the provided text.
            :param text: The complete text to parse.
            :param tools: List of available tools.
            :return: ParseResult indicating success or failure, consumed text, leftover text, and parsed calls.

  L  76: parse_streaming_increment(self, new_text: str, tools: List[Tool])
         ‚Üí StreamingParseResult
         üìù Streaming incremental parsing for Qwen 2.5 tool calls.
            Uses base class implementation with buffering to handle partial end tokens.

  L 116: structure_info(self)
         ‚Üí _GetInfoFunc

  L 123: build_ebnf(self, tools: List[Tool])


============================================================
FILE: python/sglang/srt/function_call/qwen3_coder_detector.py
Functions: 7
============================================================


CLASS: Qwen3CoderDetector
----------------------------------------
  L  44: __init__(self)

  L  69: has_tool_call(self, text: str)
         ‚Üí bool

  L  72: detect_and_parse(self, text: str, tools: List[Tool])
         ‚Üí StreamingParseResult

  L  76: parse_streaming_increment(self, new_text: str, tools: List[Tool])
         ‚Üí StreamingParseResult

  L 346: supports_structural_tag(self)
         ‚Üí bool

  L 349: structure_info(self)
         ‚Üí _GetInfoFunc

  L 352: build_ebnf(self, tools: List[Tool])


============================================================
FILE: python/sglang/srt/function_call/step3_detector.py
Functions: 9
============================================================

MODULE FUNCTIONS:
----------------------------------------
  L  19: def get_argument_type(func_name: str, arg_key: str, defined_tools: List[Tool])
         ‚Üí str
         üìù Get the expected type for a function argument from tool schema.

  L  32: def parse_arguments(value: str)
         ‚Üí tuple[Any, bool]
         üìù Parse a string value to appropriate type. Returns (parsed_value, success).


CLASS: Step3Detector
----------------------------------------
  L  62: __init__(self)

  L  86: has_tool_call(self, text: str)
         ‚Üí bool
         üìù Check if the text contains a Step3 format tool call.

  L 121: detect_and_parse(self, text: str, tools: List[Tool])
         ‚Üí StreamingParseResult
         üìù One-time parsing: Detects and parses tool calls in the provided text.

  L 170: parse_streaming_increment(self, new_text: str, tools: List[Tool])
         ‚Üí StreamingParseResult
         üìù Streaming incremental parsing for Step3 format.

  L 403: supports_structural_tag(self)
         ‚Üí bool
         üìù Return True if this detector supports structural tag format.

  L 407: structure_info(self)
         ‚Üí _GetInfoFunc

  L 410: build_ebnf(self, tools: List[Tool])
         ‚Üí str
         üìù Build EBNF grammar for Step3 tool call format.


============================================================
FILE: python/sglang/srt/harmony_parser.py
Functions: 9
============================================================

MODULE FUNCTIONS:
----------------------------------------
  L  24: def prefix_hold(text: str, tokens: List[str])
         ‚Üí Tuple[str, str]
         üìù Holds back the longest suffix of `text` that could be a prefix of any token.
            Returns (emit_now, keep_for_later).

  L  46: def iter_tokens(text: str, start_pos: int)
         ‚Üí Iterator[Token]
         üìù Iterate over structural tokens in left-to-right order.


CLASS: CanonicalStrategy
----------------------------------------
  L 126: __init__(self)

  L 137: parse(self, text: str)
         ‚Üí Tuple[List[Event], str]


CLASS: HarmonyParser
----------------------------------------
  L 504: __init__(self)

  L 514: parse(self, chunk: str)
         ‚Üí List[Event]


CLASS: TextStrategy
----------------------------------------
  L 422: __init__(self)

  L 438: set_buffer_context(self, buffer: str)

  L 441: parse(self, text: str)
         ‚Üí Tuple[List[Event], str]


============================================================
FILE: python/sglang/srt/hf_transformers_utils.py
Functions: 11
============================================================

MODULE FUNCTIONS:
----------------------------------------
  L  68: def download_from_hf(model_path: str,
        allow_patterns: Optional[Union[str,
        list]])

  L  81: def get_hf_text_config(config: PretrainedConfig)
         üìù Get the "sub" config relevant to llm for multi modal models.
            No op for pure text models.

  L 119: def get_config(model: str,
        trust_remote_code: bool,
        revision: Optional[str],
        model_override_args: Optional[dict])
         @lru_cache_frozenset(maxsize=32)

  L 196: def get_generation_config(model: str,
        trust_remote_code: bool,
        revision: Optional[str])
         @lru_cache_frozenset(maxsize=32)

  L 211: def get_sparse_attention_config(model: str,
        sparse_attention_config_filename: str)
         ‚Üí Dict[str, Any]

  L 243: def get_context_length(config)
         üìù Get the context length of a model from a huggingface model configs.

  L 267: def get_tokenizer(tokenizer_name: str)
         ‚Üí Union[PreTrainedTokenizer, PreTrainedTokenizerFast]
         üìù Gets a tokenizer for the given model name via Huggingface.

  L 348: def get_tokenizer_from_processor(processor)

  L 354: def get_processor(tokenizer_name: str)

  L 420: def attach_additional_stop_token_ids(tokenizer)

  L 430: def check_gguf_file(model: Union[str, os.PathLike])
         ‚Üí bool
         üìù Check if the file is a GGUF model.


============================================================
FILE: python/sglang/srt/host_shared_memory.py
Functions: 4
============================================================

MODULE FUNCTIONS:
----------------------------------------
  L  75: def get_host_shared_memory_manager()

  L  80: def set_host_shared_memory_manager(instance: HostSharedMemoryManager)


CLASS: HostSharedMemoryManager
----------------------------------------
  L  18: __init__(self, base_name: str)

  L  23: malloc(self)


============================================================
FILE: python/sglang/srt/jinja_template_utils.py
Functions: 2
============================================================

MODULE FUNCTIONS:
----------------------------------------
  L  81: def detect_jinja_template_content_format(chat_template: str)
         ‚Üí str
         üìù Detect whether a chat template expects 'string' or 'openai' content format.
            - 'string': content is a simple string (like DeepSeek templates)
            - 'openai': content is a list of structured dicts (like Llama4 templates)
            Detection logic:
            - If template has loops like {%- for content in message['content'] -%} ‚Üí 'openai'
            - Otherwise ‚Üí 'string'

  L 117: def process_content_for_template_format(msg_dict: dict,
        content_format: str,
        image_data: list,
        video_data: list,
        audio_data: list,
        modalities: list)
         ‚Üí dict
         üìù Process message content based on detected template format.
            Args:
            msg_dict: Message dictionary with content
            content_format: 'string' or 'openai' (detected via AST analysis)
            image_data: List to append extracted image URLs
            video_data: List to append extracted video URLs
            audio_data: List to append extracted audio URLs
            modalities: List to append modalities
            Returns:
            Processed message dictionary


============================================================
FILE: python/sglang/srt/layers/activation.py
Functions: 20
============================================================

MODULE FUNCTIONS:
----------------------------------------
  L 203: def get_act_fn(act_fn_name: str,
        quant_config: Optional[QuantizationConfig],
        intermediate_size: Optional[int],
        input_is_parallel: bool,
        params_dtype: Optional[torch.dtype])
         ‚Üí nn.Module
         üìù Get an activation function by name.

  L 228: def get_cross_encoder_activation_function(config: PretrainedConfig)


CLASS: GeluAndMul
----------------------------------------
  L  86: __init__(self, approximate)

  L  90: forward_native(self, x: torch.Tensor)
         ‚Üí torch.Tensor

  L  94: forward_cuda(self, x: torch.Tensor)
         ‚Üí torch.Tensor

  L 106: forward_npu(self, x: torch.Tensor)
         ‚Üí torch.Tensor


CLASS: NewGELU
----------------------------------------
  L 117: forward_native(self, x: torch.Tensor)
         ‚Üí torch.Tensor

  L 121: forward_cuda(self, x: torch.Tensor)
         ‚Üí torch.Tensor


CLASS: QuickGELU
----------------------------------------
  L 138: forward_native(self, x: torch.Tensor)
         ‚Üí torch.Tensor

  L 141: forward_cuda(self, x: torch.Tensor)
         ‚Üí torch.Tensor

  L 144: forward_hip(self, x: torch.Tensor)
         ‚Üí torch.Tensor

  L 149: forward_npu(self, x: torch.Tensor)
         ‚Üí torch.Tensor


CLASS: ReLU2
----------------------------------------
  L 132: forward(self, x: torch.Tensor)
         ‚Üí torch.Tensor


CLASS: ScaledActivation
----------------------------------------
  L 159: __init__(self, act_module: nn.Module, intermediate_size: int, input_is_parallel: bool, params_dtype: Optional[torch.dtype])

  L 181: forward(self, x: torch.Tensor)
         ‚Üí torch.Tensor

  L 184: weight_loader(self, param: nn.Parameter, loaded_weight: torch.Tensor)


CLASS: SiluAndMul
----------------------------------------
  L  60: forward_native(self, x: torch.Tensor)
         ‚Üí torch.Tensor

  L  64: forward_cuda(self, x: torch.Tensor)
         ‚Üí torch.Tensor

  L  71: forward_cpu(self, x: torch.Tensor)
         ‚Üí torch.Tensor

  L  80: forward_npu(self, x: torch.Tensor)
         ‚Üí torch.Tensor


============================================================
FILE: python/sglang/srt/layers/amx_utils.py
Functions: 4
============================================================

MODULE FUNCTIONS:
----------------------------------------
  L  10: def amx_process_weight_after_loading(weight)

  L  22: def dim_is_supported(weight)


CLASS: PackWeightMethod
----------------------------------------
  L  79: __init__(self, weight_names, transpose_dims)

  L  83: process_weights_after_loading(self, module)
         ‚Üí None


============================================================
FILE: python/sglang/srt/layers/attention/aiter_backend.py
Functions: 20
============================================================


CLASS: AiterAttnBackend
----------------------------------------
  L  65: __init__(self, model_runner: ModelRunner, skip_prefill: bool, kv_indptr_buf: Optional[torch.Tensor])

  L 157: init_forward_metadata(self, forward_batch: ForwardBatch)
         üìù Init auxiliary variables for triton attention backend.

  L 341: init_cuda_graph_state(self, max_bs: int, max_num_tokens: int, kv_indices_buf: Optional[torch.Tensor])

  L 364: init_forward_metadata_capture_cuda_graph(self, bs: int, num_tokens: int, req_pool_indices: torch.Tensor, seq_lens: torch.Tensor, encoder_lens: Optional[torch.Tensor], forward_mode: ForwardMode, spec_info: Optional[SpecInfo])

  L 499: init_forward_metadata_replay_cuda_graph(self, bs: int, req_pool_indices: torch.Tensor, seq_lens: torch.Tensor, seq_lens_sum: int, encoder_lens: Optional[torch.Tensor], forward_mode: ForwardMode, spec_info: Optional[SpecInfo], seq_lens_cpu: Optional[torch.Tensor])

  L 572: get_cuda_graph_seq_len_fill_value(self)

  L 575: forward_extend(self, q: torch.Tensor, k: torch.Tensor, v: torch.Tensor, layer: RadixAttention, forward_batch: ForwardBatch, save_kv_cache)

  L 761: forward_decode(self, q: torch.Tensor, k: torch.Tensor, v: torch.Tensor, layer: RadixAttention, forward_batch: ForwardBatch, save_kv_cache)


CLASS: AiterIndicesUpdaterPrefill
----------------------------------------
  L 830: __init__(self, model_runner: ModelRunner, attn_backend: AttentionBackend)

  L 855: update(self, req_pool_indices: torch.Tensor, seq_lens: torch.Tensor, seq_lens_sum: int, prefix_lens: torch.Tensor, encoder_lens: Optional[torch.Tensor], spec_info: Optional[SpecInfo])

  L 867: update_single_wrapper(self, req_pool_indices: torch.Tensor, seq_lens: torch.Tensor, seq_lens_sum: int, prefix_lens: torch.Tensor, encoder_lens: Optional[torch.Tensor], spec_info: Optional[SpecInfo])


CLASS: AiterMlaIndicesUpdaterPrefill
----------------------------------------
  L 935: __init__(self, model_runner: ModelRunner, attn_backend: AttentionBackend)

  L 950: update(self, req_pool_indices: torch.Tensor, kv_lens: torch.Tensor, kv_lens_sum: int, extend_lens: torch.Tensor, max_q_len: int, max_kv_len: int, spec_info: Optional[SpecInfo])

  L 963: update_single_wrapper(self, req_pool_indices: torch.Tensor, kv_lens: torch.Tensor, kv_lens_sum: int, extend_lens: torch.Tensor, max_q_len: int, max_kv_len: int, spec_info: Optional[SpecInfo])


CLASS: AiterMultiStepDraftBackend
----------------------------------------
  L1022: __init__(self, model_runner: ModelRunner, topk: int, speculative_num_steps: int)

  L1061: common_template(self, forward_batch: ForwardBatch, kv_indices_buffer: torch.Tensor, call_fn: int)

  L1093: init_forward_metadata(self, forward_batch: ForwardBatch)

  L1114: init_cuda_graph_state(self, max_bs: int, max_num_tokens: int)

  L1125: init_forward_metadata_capture_cuda_graph(self, forward_batch: ForwardBatch)

  L1139: init_forward_metadata_replay_cuda_graph(self, forward_batch: ForwardBatch, bs: int)


============================================================
FILE: python/sglang/srt/layers/attention/ascend_backend.py
Functions: 10
============================================================


CLASS: AscendAttnBackend
----------------------------------------
  L  40: gen_attention_mask(self, max_seq_len: int, dtype)

  L  58: __init__(self, model_runner: ModelRunner)

  L  84: init_forward_metadata(self, forward_batch: ForwardBatch)
         üìù Init the metadata for a forward pass.

  L 105: init_cuda_graph_state(self, max_bs: int, max_num_tokens: int)

  L 114: init_forward_metadata_capture_cuda_graph(self, bs: int, num_tokens: int, req_pool_indices: torch.Tensor, seq_lens: torch.Tensor, encoder_lens: Optional[torch.Tensor], forward_mode: ForwardMode, spec_info: Optional[Union[EagleDraftInput, EagleVerifyInput]])

  L 134: init_forward_metadata_replay_cuda_graph(self, bs: int, req_pool_indices: torch.Tensor, seq_lens: torch.Tensor, seq_lens_sum: int, encoder_lens: Optional[torch.Tensor], forward_mode: ForwardMode, spec_info: Optional[Union[EagleDraftInput, EagleVerifyInput]], seq_lens_cpu: Optional[torch.Tensor])

  L 160: get_cuda_graph_seq_len_fill_value(self)

  L 163: forward_extend(self, q, k, v, layer: RadixAttention, forward_batch: ForwardBatch, save_kv_cache: bool)

  L 291: forward_decode_graph(self, q: torch.Tensor, k: torch.Tensor, v: torch.Tensor, layer: RadixAttention, forward_batch: ForwardBatch, save_kv_cache: bool, q_rope: Optional[torch.Tensor], k_rope: Optional[torch.Tensor])

  L 421: forward_decode(self, q: torch.Tensor, k: torch.Tensor, v: torch.Tensor, layer: RadixAttention, forward_batch: ForwardBatch, save_kv_cache: bool, q_rope: Optional[torch.Tensor], k_rope: Optional[torch.Tensor])


============================================================
FILE: python/sglang/srt/layers/attention/base_attn_backend.py
Functions: 9
============================================================


CLASS: AttentionBackend
----------------------------------------
  L  18: init_forward_metadata(self, forward_batch: ForwardBatch)
         üìù Init the metadata for a forward pass.

  L  22: init_cuda_graph_state(self, max_bs: int, max_num_tokens: int)
         üìù Init the global shared states for cuda graph.

  L  26: init_forward_metadata_capture_cuda_graph(self, bs: int, num_tokens: int, req_pool_indices: torch.Tensor, seq_lens: torch.Tensor, encoder_lens: Optional[torch.Tensor], forward_mode: ForwardMode, spec_info: Optional[Union[EagleDraftInput, EagleVerifyInput]])
         üìù Init the metadata for a forward pass for capturing a cuda graph.

  L  39: init_forward_metadata_replay_cuda_graph(self, bs: int, req_pool_indices: torch.Tensor, seq_lens: torch.Tensor, seq_lens_sum: int, encoder_lens: Optional[torch.Tensor], forward_mode: ForwardMode, spec_info: Optional[Union[EagleDraftInput, EagleVerifyInput]], seq_lens_cpu: Optional[torch.Tensor])
         üìù Init the metadata for a forward pass for replaying a cuda graph.

  L  53: get_cuda_graph_seq_len_fill_value(self)
         üìù Get the fill value for padded seq lens. Typically, it is 0 or 1.

  L  57: forward(self, q: torch.Tensor, k: torch.Tensor, v: torch.Tensor, layer: RadixAttention, forward_batch: ForwardBatch, save_kv_cache: bool)
         üìù Run forward on an attention layer.

  L  91: forward_decode(self, q: torch.Tensor, k: torch.Tensor, v: torch.Tensor, layer: RadixAttention, forward_batch: ForwardBatch, save_kv_cache: bool)
         üìù Run a forward for decode.

  L 103: forward_extend(self, q: torch.Tensor, k: torch.Tensor, v: torch.Tensor, layer: RadixAttention, forward_batch: ForwardBatch, save_kv_cache: bool)
         üìù Run a forward for extend.

  L 115: support_triton(self)
         üìù Check if the current backend supports triton.


============================================================
FILE: python/sglang/srt/layers/attention/cutlass_mla_backend.py
Functions: 8
============================================================


CLASS: CutlassMLABackend
----------------------------------------
  L  51: __init__(self, model_runner: ModelRunner, skip_prefill: bool, kv_indptr_buf: Optional[torch.Tensor], kv_last_page_len_buf: Optional[torch.Tensor])

  L  82: init_forward_metadata(self, forward_batch: ForwardBatch)

  L 122: init_cuda_graph_state(self, max_bs: int, max_num_tokens: int, block_kv_indices: Optional[torch.Tensor])

  L 146: init_forward_metadata_capture_cuda_graph(self, bs: int, num_tokens: int, req_pool_indices: torch.Tensor, seq_lens: torch.Tensor, encoder_lens: Optional[torch.Tensor], forward_mode: ForwardMode, spec_info: Optional[SpecInfo])

  L 185: init_forward_metadata_replay_cuda_graph(self, bs: int, req_pool_indices: torch.Tensor, seq_lens: torch.Tensor, seq_lens_sum: int, encoder_lens: Optional[torch.Tensor], forward_mode: ForwardMode, spec_info: Optional[SpecInfo], seq_lens_cpu: Optional[torch.Tensor])

  L 223: get_cuda_graph_seq_len_fill_value(self)

  L 226: forward_decode(self, q: torch.Tensor, k: torch.Tensor, v: torch.Tensor, layer: RadixAttention, forward_batch: ForwardBatch, save_kv_cache: bool, q_rope: Optional[torch.Tensor], k_rope: Optional[torch.Tensor])


CLASS: CutlassMLADecodeMetadata
----------------------------------------
  L  39: __init__(self, workspace: Optional[torch.Tensor], block_kv_indices: Optional[torch.Tensor])


============================================================
FILE: python/sglang/srt/layers/attention/double_sparsity_backend.py
Functions: 4
============================================================


CLASS: DoubleSparseAttnBackend
----------------------------------------
  L  17: __init__(self, model_runner: ModelRunner)

  L  52: init_forward_metadata(self, forward_batch: ForwardBatch)
         üìù Init auxiliary variables for triton attention backend.

  L 113: forward_extend(self, q, k, v, layer: RadixAttention, forward_batch: ForwardBatch, save_kv_cache)

  L 167: forward_decode(self, q, k, v, layer: RadixAttention, forward_batch: ForwardBatch, save_kv_cache)


============================================================
FILE: python/sglang/srt/layers/attention/dual_chunk_flashattention_backend.py
Functions: 9
============================================================


CLASS: DualChunkFlashAttentionBackend
----------------------------------------
  L 102: __init__(self, model_runner: 'ModelRunner')
         ‚Üí None

  L 160: get_sparse_attention_config(self, layer_idx)
         ‚Üí List[Dict[str, Any]]

  L 168: init_forward_metadata(self, forward_batch: ForwardBatch)
         üìù Initialize forward metadata hence all layers in the forward pass can reuse it.

  L 296: forward_extend(self, q: torch.Tensor, k: torch.Tensor, v: torch.Tensor, layer: 'RadixAttention', forward_batch: ForwardBatch, save_kv_cache)

  L 409: forward_decode(self, q: torch.Tensor, k: torch.Tensor, v: torch.Tensor, layer: 'RadixAttention', forward_batch: ForwardBatch, save_kv_cache)
         ‚Üí torch.Tensor

  L 486: init_cuda_graph_state(self, max_bs: int, max_num_tokens: int)
         üìù Initialize CUDA graph state for the attention backend.
            Args:
            max_bs (int): Maximum batch size to support in CUDA graphs
            This creates fixed-size tensors that will be reused during CUDA graph replay
            to avoid memory allocations.

  L 532: init_forward_metadata_capture_cuda_graph(self, bs: int, num_tokens: int, req_pool_indices: torch.Tensor, seq_lens: torch.Tensor, encoder_lens: Optional[torch.Tensor], forward_mode: ForwardMode, spec_info: Optional[None])

  L 580: init_forward_metadata_replay_cuda_graph(self, bs: int, req_pool_indices: torch.Tensor, seq_lens: torch.Tensor, seq_lens_sum: int, encoder_lens: Optional[torch.Tensor], forward_mode: ForwardMode, spec_info: Optional[None], seq_lens_cpu: Optional[torch.Tensor], out_cache_loc: torch.Tensor)
         üìù Initialize forward metadata for replaying CUDA graph.

  L 670: get_cuda_graph_seq_len_fill_value(self)
         üìù Get the fill value for sequence length in CUDA graph.


============================================================
FILE: python/sglang/srt/layers/attention/flashattention_backend.py
Functions: 18
============================================================

MODULE FUNCTIONS:
----------------------------------------
  L 127: def make_local_attention_virtual_batches(attn_chunk_size: int,
        query_start_loc_np: np.ndarray,
        seq_lens_np: np.ndarray,
        block_table: torch.Tensor,
        page_size: int)
         ‚Üí tuple[np.ndarray, np.ndarray, np.ndarray, torch.Tensor]
         üìù Take in `query_start_loc_np` and `seq_lens_np` and break the sequences into
            local attention blocks, where each block is passed to the attention kernel
            as an independent local ("virtual") batch item.
            Args:
            attn_chunk_size: Size of local attention chunks
            query_start_loc_np: Cumulative sum of query lengths (numpy array)
            seq_lens_np: Sequence lengths (numpy array)
            block_table: Block table for KV cache
            page_size: Size of each page in the KV cache
            Returns:
            seqlens_q_local: Query sequence lengths for local attention
            cu_seqlens_q_local: Cumulative sum of query sequence lengths for local attention
            seqlens_k_local: Key sequence lengths for local attention
            block_table_local: Block table for local attention

  L 272: def cdiv(a: int, b: int)
         ‚Üí int
         üìù Ceiling division.

  L 279: def merge_state_v2_wrapper(o, s_a, o_exp, s_b)
         @torch._dynamo.disable()

  L2237: def prepare_swa_spec_page_table_triton(page_table_dst: torch.Tensor,
        page_table_a: torch.Tensor,
        page_table_b: torch.Tensor,
        seq_len_a: torch.Tensor,
        seq_len_b: torch.Tensor,
        speculative_num_draft_tokens: int)

  L2347: def normal_decode_set_metadata(cache_seqlens_int32: torch.Tensor,
        cu_seqlens_k: torch.Tensor,
        page_table: torch.Tensor,
        req_to_token: torch.Tensor,
        req_pool_indices: torch.Tensor,
        strided_indices: torch.Tensor,
        max_seq_pages: torch.Tensor,
        seq_lens: torch.Tensor,
        seq_len_delta: int,
        page_size: int)


CLASS: FlashAttentionBackend
----------------------------------------
  L 301: __init__(self, model_runner: ModelRunner, skip_prefill: bool, speculative_step_id, topk, speculative_num_steps)

  L 355: init_forward_metadata(self, forward_batch: ForwardBatch)
         üìù Initialize forward metadata hence all layers in the forward pass can reuse it.

  L 639: forward_extend(self, q: torch.Tensor, k: torch.Tensor, v: torch.Tensor, layer: RadixAttention, forward_batch: ForwardBatch, save_kv_cache, q_rope: Optional[torch.Tensor], k_rope: Optional[torch.Tensor], sinks: Optional[torch.Tensor])

  L 929: forward_decode(self, q: torch.Tensor, k: torch.Tensor, v: torch.Tensor, layer: RadixAttention, forward_batch: ForwardBatch, save_kv_cache, q_rope: Optional[torch.Tensor], k_rope: Optional[torch.Tensor], sinks: Optional[torch.Tensor])
         ‚Üí torch.Tensor

  L1188: init_cuda_graph_state(self, max_bs: int, max_num_tokens: int)
         üìù Initialize CUDA graph state for the attention backend.
            Args:
            max_bs (int): Maximum batch size to support in CUDA graphs
            This creates fixed-size tensors that will be reused during CUDA graph replay
            to avoid memory allocations.

  L1448: init_forward_metadata_capture_cuda_graph(self, bs: int, num_tokens: int, req_pool_indices: torch.Tensor, seq_lens: torch.Tensor, encoder_lens: Optional[torch.Tensor], forward_mode: ForwardMode, spec_info: Optional[Union[EagleDraftInput, EagleVerifyInput]])
         üìù Initialize forward metadata for capturing CUDA graph.

  L1683: init_forward_metadata_replay_cuda_graph(self, bs: int, req_pool_indices: torch.Tensor, seq_lens: torch.Tensor, seq_lens_sum: int, encoder_lens: Optional[torch.Tensor], forward_mode: ForwardMode, spec_info: Optional[Union[EagleDraftInput, EagleVerifyInput]], seq_lens_cpu: Optional[torch.Tensor], out_cache_loc: Optional[torch.Tensor])
         üìù Initialize forward metadata for replaying CUDA graph.

  L1939: get_cuda_graph_seq_len_fill_value(self)
         üìù Get the fill value for sequence length in CUDA graph.


CLASS: FlashAttentionMultiStepBackend
----------------------------------------
  L2279: __init__(self, model_runner: ModelRunner, topk: int, speculative_num_steps: int)

  L2296: init_forward_metadata(self, forward_batch: ForwardBatch)

  L2300: init_cuda_graph_state(self, max_bs: int, max_num_tokens: int)

  L2304: init_forward_metadata_capture_cuda_graph(self, forward_batch: ForwardBatch)

  L2322: init_forward_metadata_replay_cuda_graph(self, forward_batch: ForwardBatch, bs: int)


============================================================
FILE: python/sglang/srt/layers/attention/flashinfer_backend.py
Functions: 28
============================================================

MODULE FUNCTIONS:
----------------------------------------
  L1230: def should_use_tensor_core(kv_cache_dtype: torch.dtype,
        num_attention_heads: int,
        num_kv_heads: int)
         ‚Üí bool
         üìù Determine whether to use tensor cores for attention computation.
            Args:
            kv_cache_dtype: Data type of the KV cache
            num_attention_heads: Number of attention heads
            num_kv_heads: Number of key/value heads
            Returns:
            bool: Whether to use tensor cores

  L1284: def fast_decode_plan(self,
        indptr: torch.Tensor,
        indices: torch.Tensor,
        last_page_len: torch.Tensor,
        num_qo_heads: int,
        num_kv_heads: int,
        head_dim: int,
        page_size: int,
        pos_encoding_mode: str,
        window_left: int,
        logits_soft_cap: Optional[float],
        q_data_type: Optional[Union[str,
        torch.dtype]],
        kv_data_type: Optional[Union[str,
        torch.dtype]],
        data_type: Optional[Union[str,
        torch.dtype]],
        sm_scale: Optional[float],
        rope_scale: Optional[float],
        rope_theta: Optional[float],
        non_blocking: bool)
         ‚Üí None
         üìù A faster version of BatchDecodeWithPagedKVCacheWrapper::plan used for FlashInferMultiStepDraftBackend.
            Modifications:
            - Remove unnecessary device-to-device copy for the cuda graph buffers.
            - Remove unnecessary host-to-device copy for the metadata buffers.


CLASS: FlashInferAttnBackend
----------------------------------------
  L  80: __init__(self, model_runner: ModelRunner, skip_prefill: bool, kv_indptr_buf: Optional[torch.Tensor], kv_last_page_len_buf: Optional[torch.Tensor])

  L 211: init_forward_metadata(self, forward_batch: ForwardBatch)

  L 278: init_cuda_graph_state(self, max_bs: int, max_num_tokens: int, kv_indices_buf: Optional[torch.Tensor])

  L 312: init_forward_metadata_capture_cuda_graph(self, bs: int, num_tokens: int, req_pool_indices: torch.Tensor, seq_lens: torch.Tensor, encoder_lens: Optional[torch.Tensor], forward_mode: ForwardMode, spec_info: Optional[Union[EagleDraftInput, EagleVerifyInput]])

  L 417: init_forward_metadata_replay_cuda_graph(self, bs: int, req_pool_indices: torch.Tensor, seq_lens: torch.Tensor, seq_lens_sum: int, encoder_lens: Optional[torch.Tensor], forward_mode: ForwardMode, spec_info: Optional[Union[EagleDraftInput, EagleVerifyInput]], seq_lens_cpu: Optional[torch.Tensor])

  L 465: get_cuda_graph_seq_len_fill_value(self)

  L 468: forward_extend(self, q: torch.Tensor, k: torch.Tensor, v: torch.Tensor, layer: RadixAttention, forward_batch: ForwardBatch, save_kv_cache)

  L 552: forward_decode(self, q: torch.Tensor, k: torch.Tensor, v: torch.Tensor, layer: RadixAttention, forward_batch: ForwardBatch, save_kv_cache)


CLASS: FlashInferIndicesUpdaterDecode
----------------------------------------
  L 602: __init__(self, model_runner: ModelRunner, attn_backend: FlashInferAttnBackend)

  L 631: update(self, req_pool_indices: torch.Tensor, seq_lens: torch.Tensor, seq_lens_cpu: Optional[torch.Tensor], seq_lens_sum: int, decode_wrappers: List[BatchDecodeWithPagedKVCacheWrapper], encoder_lens: Optional[torch.Tensor], spec_info: Optional[Union[EagleDraftInput, EagleVerifyInput]])

  L 644: update_single_wrapper(self, req_pool_indices: torch.Tensor, seq_lens: torch.Tensor, seq_lens_cpu: Optional[torch.Tensor], seq_lens_sum: int, decode_wrappers: List[BatchDecodeWithPagedKVCacheWrapper], encoder_lens: Optional[torch.Tensor], spec_info: Optional[Union[EagleDraftInput, EagleVerifyInput]])

  L 666: update_sliding_window(self, req_pool_indices: torch.Tensor, seq_lens: torch.Tensor, seq_lens_cpu: Optional[torch.Tensor], seq_lens_sum: int, decode_wrappers: List[BatchDecodeWithPagedKVCacheWrapper], encoder_lens: Optional[torch.Tensor], spec_info: Optional[Union[EagleDraftInput, EagleVerifyInput]])

  L 714: update_cross_attention(self, req_pool_indices: torch.Tensor, seq_lens: torch.Tensor, seq_lens_cpu: Optional[torch.Tensor], seq_lens_sum: int, decode_wrappers: List[BatchDecodeWithPagedKVCacheWrapper], encoder_lens: Optional[torch.Tensor], spec_info: Optional[Union[EagleDraftInput, EagleVerifyInput]])

  L 746: call_begin_forward(self, wrapper: BatchDecodeWithPagedKVCacheWrapper, req_pool_indices: torch.Tensor, paged_kernel_lens: torch.Tensor, paged_kernel_lens_sum: int, kv_indptr: torch.Tensor, kv_start_idx: torch.Tensor, spec_info: Optional[Union[EagleDraftInput, EagleVerifyInput]], seq_lens_cpu: Optional[torch.Tensor], use_sliding_window_kv_pool: bool)


CLASS: FlashInferIndicesUpdaterPrefill
----------------------------------------
  L 818: __init__(self, model_runner: ModelRunner, attn_backend: FlashInferAttnBackend)

  L 849: update(self, req_pool_indices: torch.Tensor, seq_lens: torch.Tensor, seq_lens_cpu: Optional[torch.Tensor], seq_lens_sum: int, prefix_lens: torch.Tensor, prefill_wrappers: List[BatchPrefillWithPagedKVCacheWrapper], use_ragged: bool, encoder_lens: Optional[torch.Tensor], spec_info: Optional[Union[EagleDraftInput, EagleVerifyInput]])

  L 864: update_single_wrapper(self, req_pool_indices: torch.Tensor, seq_lens: torch.Tensor, seq_lens_cpu: Optional[torch.Tensor], seq_lens_sum: int, prefix_lens: torch.Tensor, prefill_wrappers: List[BatchPrefillWithPagedKVCacheWrapper], use_ragged: bool, encoder_lens: Optional[torch.Tensor], spec_info: Optional[Union[EagleDraftInput, EagleVerifyInput]])

  L 900: update_sliding_window(self, req_pool_indices: torch.Tensor, seq_lens: torch.Tensor, seq_lens_cpu: Optional[torch.Tensor], seq_lens_sum: int, prefix_lens: torch.Tensor, prefill_wrappers: List[BatchPrefillWithPagedKVCacheWrapper], use_ragged: bool, encoder_lens: Optional[torch.Tensor], spec_info: Optional[Union[EagleDraftInput, EagleVerifyInput]])

  L 946: update_cross_attention(self, req_pool_indices: torch.Tensor, seq_lens: torch.Tensor, seq_lens_cpu: Optional[torch.Tensor], seq_lens_sum: int, prefix_lens: torch.Tensor, prefill_wrappers: List[BatchPrefillWithPagedKVCacheWrapper], use_ragged: bool, encoder_lens: Optional[torch.Tensor], spec_info: Optional[Union[EagleDraftInput, EagleVerifyInput]])

  L 985: call_begin_forward(self, wrapper_ragged: BatchPrefillWithRaggedKVCacheWrapper, wrapper_paged: BatchPrefillWithPagedKVCacheWrapper, req_pool_indices: torch.Tensor, paged_kernel_lens: torch.Tensor, paged_kernel_lens_sum: int, seq_lens: torch.Tensor, prefix_lens: torch.Tensor, kv_start_idx: torch.Tensor, kv_indptr: torch.Tensor, qo_indptr: torch.Tensor, use_ragged: bool, spec_info: Optional[Union[EagleDraftInput, EagleVerifyInput]], use_sliding_window_kv_pool: bool)


CLASS: FlashInferMultiStepDraftBackend
----------------------------------------
  L1079: __init__(self, model_runner: ModelRunner, topk: int, speculative_num_steps: int)

  L1120: common_template(self, forward_batch: ForwardBatch, kv_indices_buffer: torch.Tensor, call_fn: Callable)

  L1165: init_forward_metadata(self, forward_batch: ForwardBatch)

  L1186: init_cuda_graph_state(self, max_bs: int, max_num_tokens: int)

  L1198: init_forward_metadata_capture_cuda_graph(self, forward_batch: ForwardBatch)

  L1212: init_forward_metadata_replay_cuda_graph(self, forward_batch: ForwardBatch, bs: int)


============================================================
FILE: python/sglang/srt/layers/attention/flashinfer_mla_backend.py
Functions: 26
============================================================

MODULE FUNCTIONS:
----------------------------------------
  L1038: def fast_mla_decode_plan(self,
        qo_indptr_cpu: torch.Tensor,
        kv_indptr_cpu: torch.Tensor,
        kv_indices: torch.Tensor,
        kv_len_arr_cpu: torch.Tensor,
        num_heads: int,
        head_dim_ckv: int,
        head_dim_kpe: int,
        page_size: int,
        causal: bool,
        sm_scale: float,
        q_data_type: torch.dtype,
        kv_data_type: torch.dtype)
         ‚Üí None
         üìù A faster version of BatchMLAPagedAttentionWrapper::plan,
            for skipping the stream synchronization in original plan function during
            cuda graph replaying.


CLASS: FlashInferMLAAttnBackend
----------------------------------------
  L 179: __init__(self, model_runner: ModelRunner, skip_prefill: bool, kv_indptr_buf: Optional[torch.Tensor], q_indptr_decode_buf: Optional[torch.Tensor])

  L 271: init_forward_metadata(self, forward_batch: ForwardBatch)

  L 323: init_cuda_graph_state(self, max_bs: int, max_num_tokens: int, kv_indices_buf: Optional[torch.Tensor])

  L 354: init_forward_metadata_capture_cuda_graph(self, bs: int, num_tokens: int, req_pool_indices: torch.Tensor, seq_lens: torch.Tensor, encoder_lens: Optional[torch.Tensor], forward_mode: ForwardMode, spec_info: Optional[SpecInfo])

  L 434: init_forward_metadata_replay_cuda_graph(self, bs: int, req_pool_indices: torch.Tensor, seq_lens: torch.Tensor, seq_lens_sum: int, encoder_lens: Optional[torch.Tensor], forward_mode: ForwardMode, spec_info: Optional[SpecInfo], seq_lens_cpu: Optional[torch.Tensor])

  L 491: get_cuda_graph_seq_len_fill_value(self)

  L 494: init_mha_chunk_metadata(self, forward_batch: ForwardBatch)
         üìù Init the metadata for a forward pass.

  L 498: forward_extend(self, q: torch.Tensor, k: torch.Tensor, v: torch.Tensor, layer: RadixAttention, forward_batch: ForwardBatch, save_kv_cache: bool, q_rope: Optional[torch.Tensor], k_rope: Optional[torch.Tensor])

  L 576: forward_decode(self, q: torch.Tensor, k: torch.Tensor, v: torch.Tensor, layer: RadixAttention, forward_batch: ForwardBatch, save_kv_cache: bool, q_rope: Optional[torch.Tensor], k_rope: Optional[torch.Tensor])


CLASS: FlashInferMLAIndicesUpdaterDecode
----------------------------------------
  L 638: __init__(self, model_runner: ModelRunner, attn_backend: AttentionBackend)

  L 655: update(self, req_pool_indices: torch.Tensor, seq_lens: torch.Tensor, seq_lens_sum: int, decode_wrapper: BatchMLAPagedAttentionWrapper, init_metadata_replay: bool, spec_info: Optional[Union[EagleDraftInput, EagleVerifyInput]])

  L 678: call_begin_forward(self, wrapper: BatchMLAPagedAttentionWrapper, req_pool_indices: torch.Tensor, paged_kernel_lens: torch.Tensor, paged_kernel_lens_sum: int, q_indptr: torch.Tensor, kv_indptr: torch.Tensor, init_metadata_replay: bool, spec_info: Optional[Union[EagleDraftInput, EagleVerifyInput]])


CLASS: FlashInferMLAIndicesUpdaterPrefill
----------------------------------------
  L 747: __init__(self, model_runner: ModelRunner, attn_backend: AttentionBackend)

  L 767: update(self, req_pool_indices: torch.Tnesor, seq_lens: torch.Tensor, seq_lens_sum: int, prefix_lens: torch.Tensor, prefill_wrapper_paged: BatchMLAPagedAttentionWrapper, use_ragged: bool, spec_info: Optional[Union[EagleDraftInput, EagleVerifyInput]])

  L 798: call_begin_forward(self, wrapper_ragged: BatchPrefillWithRaggedKVCacheWrapper, wrapper_paged: BatchMLAPagedAttentionWrapper, req_pool_indices: torch.Tensor, paged_kernel_lens: torch.Tensor, paged_kernel_lens_sum: int, seq_lens: torch.Tensor, prefix_lens: torch.Tensor, kv_indptr: torch.Tensor, qo_indptr: torch.Tensor, use_ragged: bool, spec_info: Optional[Union[EagleDraftInput, EagleVerifyInput]])


CLASS: FlashInferMLAMultiStepDraftBackend
----------------------------------------
  L 887: __init__(self, model_runner: ModelRunner, topk: int, speculative_num_steps: int)

  L 933: common_template(self, forward_batch: ForwardBatch, kv_indices_buffer: torch.Tensor, call_fn: Callable)

  L 971: init_forward_metadata(self, forward_batch: ForwardBatch)

  L 994: init_cuda_graph_state(self, max_bs: int, max_num_tokens: int)

  L1006: init_forward_metadata_capture_cuda_graph(self, forward_batch: ForwardBatch)

  L1020: init_forward_metadata_replay_cuda_graph(self, forward_batch: ForwardBatch, bs: int)


CLASS: FlashInferMhaChunkKVRunner
----------------------------------------
  L  68: __init__(self, model_runner: ModelRunner, attn_backend: 'FlashInferMlaAttnBackend')

  L  89: update_prefix_chunks(self, num_prefix_chunks: int)

  L  96: update_wrapper(self, forward_batch: ForwardBatch)

  L 142: forward(self, q: torch.Tensor, k: torch.Tensor, v: torch.Tensor, layer: RadixAttention, forward_batch: ForwardBatch)


============================================================
FILE: python/sglang/srt/layers/attention/flashmla_backend.py
Functions: 15
============================================================


CLASS: FlashMLABackend
----------------------------------------
  L  51: __init__(self, model_runner: ModelRunner, skip_prefill: bool, kv_indptr_buf: Optional[torch.Tensor], kv_last_page_len_buf: Optional[torch.Tensor])

  L  81: init_forward_metadata(self, forward_batch: ForwardBatch)

  L 148: init_cuda_graph_state(self, max_bs: int, max_num_tokens: int, block_kv_indices: Optional[torch.Tensor])

  L 182: init_forward_metadata_capture_cuda_graph(self, bs: int, num_tokens: int, req_pool_indices: torch.Tensor, seq_lens: torch.Tensor, encoder_lens: Optional[torch.Tensor], forward_mode: ForwardMode, spec_info: Optional[SpecInfo])

  L 252: init_forward_metadata_replay_cuda_graph(self, bs: int, req_pool_indices: torch.Tensor, seq_lens: torch.Tensor, seq_lens_sum: int, encoder_lens: Optional[torch.Tensor], forward_mode: ForwardMode, spec_info: Optional[SpecInfo], seq_lens_cpu: Optional[torch.Tensor])

  L 327: get_cuda_graph_seq_len_fill_value(self)

  L 330: forward_decode(self, q: torch.Tensor, k: torch.Tensor, v: torch.Tensor, layer: RadixAttention, forward_batch: ForwardBatch, save_kv_cache: bool)

  L 387: forward_extend(self, q: torch.Tensor, k: torch.Tensor, v: torch.Tensor, layer: RadixAttention, forward_batch: ForwardBatch, save_kv_cache: bool)


CLASS: FlashMLADecodeMetadata
----------------------------------------
  L  37: __init__(self, flashmla_metadata: Optional[Tuple[torch.Tensor, torch.Tensor]], num_splits: Optional[torch.Tensor], block_kv_indices: Optional[torch.Tensor])


CLASS: FlashMLAMultiStepDraftBackend
----------------------------------------
  L 456: __init__(self, model_runner: ModelRunner, topk: int, speculative_num_steps: int)

  L 489: common_template(self, forward_batch: ForwardBatch, call_fn: Callable)

  L 499: init_forward_metadata(self, forward_batch: ForwardBatch)

  L 506: init_cuda_graph_state(self, max_bs: int, max_num_tokens: int)

  L 512: init_forward_metadata_capture_cuda_graph(self, forward_batch: ForwardBatch)

  L 526: init_forward_metadata_replay_cuda_graph(self, forward_batch: ForwardBatch, bs: int)


============================================================
FILE: python/sglang/srt/layers/attention/hybrid_attn_backend.py
Functions: 8
============================================================


CLASS: HybridAttnBackend
----------------------------------------
  L  15: __init__(self, model_runner: ModelRunner, prefill_backend: AttentionBackend, decode_backend: AttentionBackend)

  L  25: init_forward_metadata(self, forward_batch: ForwardBatch)

  L  31: init_cuda_graph_state(self, max_bs: int, max_num_tokens: int)

  L  38: init_forward_metadata_capture_cuda_graph(self, bs: int, num_tokens: int, req_pool_indices: torch.Tensor, seq_lens: torch.Tensor, encoder_lens: Optional[torch.Tensor], forward_mode: ForwardMode, spec_info: Optional[Union[EagleDraftInput, EagleVerifyInput]])

  L  69: init_forward_metadata_replay_cuda_graph(self, bs: int, req_pool_indices: torch.Tensor, seq_lens: torch.Tensor, seq_lens_sum: int, encoder_lens: Optional[torch.Tensor], forward_mode: ForwardMode, spec_info: Optional[Union[EagleDraftInput, EagleVerifyInput]], seq_lens_cpu: Optional[torch.Tensor])

  L 103: get_cuda_graph_seq_len_fill_value(self)

  L 106: forward_decode(self, q: torch.Tensor, k: torch.Tensor, v: torch.Tensor, layer: RadixAttention, forward_batch: ForwardBatch, save_kv_cache: bool)

  L 120: forward_extend(self, q: torch.Tensor, k: torch.Tensor, v: torch.Tensor, layer: RadixAttention, forward_batch: ForwardBatch, save_kv_cache: bool)


============================================================
FILE: python/sglang/srt/layers/attention/intel_amx_backend.py
Functions: 5
============================================================


CLASS: IntelAMXAttnBackend
----------------------------------------
  L  16: __init__(self, model_runner: ModelRunner)

  L  32: init_forward_metadata(self, forward_batch: ForwardBatch)
         üìù Init the metadata for a forward pass.

  L  52: forward_extend(self, q, k, v, layer: RadixAttention, forward_batch: ForwardBatch, save_kv_cache)

  L  91: forward_decode(self, q: torch.Tensor, k: torch.Tensor, v: torch.Tensor, layer: RadixAttention, forward_batch: ForwardBatch, save_kv_cache)

  L 127: support_triton(self)


============================================================
FILE: python/sglang/srt/layers/attention/merge_state.py
Functions: 1
============================================================

MODULE FUNCTIONS:
----------------------------------------
  L  26: def merge_state(prefix_output: torch.Tensor,
        prefix_lse: torch.Tensor,
        suffix_output: torch.Tensor,
        suffix_lse: torch.Tensor,
        output: Optional[torch.Tensor],
        output_lse: Optional[torch.Tensor])
         ‚Üí Tuple[torch.Tensor, Optional[torch.Tensor]]


============================================================
FILE: python/sglang/srt/layers/attention/tbo_backend.py
Functions: 9
============================================================


CLASS: TboAttnBackend
----------------------------------------
  L  14: __init__(self, primary: AttentionBackend, children: List[AttentionBackend])

  L  20: init_new(cls, creator: Callable[[], AttentionBackend])

  L  26: init_forward_metadata(self, forward_batch: 'ForwardBatch')

  L  35: init_cuda_graph_state(self, max_bs: int, max_num_tokens: int)

  L  41: init_forward_metadata_capture_cuda_graph(self, bs: int, num_tokens: int, req_pool_indices: torch.Tensor, seq_lens: torch.Tensor, encoder_lens: Optional[torch.Tensor], forward_mode: 'ForwardMode', spec_info: Optional[Union[EagleDraftInput, EagleVerifyInput]])

  L  72: init_forward_metadata_replay_cuda_graph(self, bs: int, req_pool_indices: torch.Tensor, seq_lens: torch.Tensor, seq_lens_sum: int, encoder_lens: Optional[torch.Tensor], forward_mode: 'ForwardMode', spec_info: Optional[Union[EagleDraftInput, EagleVerifyInput]], seq_lens_cpu: Optional[torch.Tensor])

  L 176: get_cuda_graph_seq_len_fill_value(self)

  L 182: forward_extend(self)

  L 185: forward_decode(self)


============================================================
FILE: python/sglang/srt/layers/attention/torch_native_backend.py
Functions: 5
============================================================


CLASS: TorchNativeAttnBackend
----------------------------------------
  L  18: __init__(self, model_runner: ModelRunner)

  L  23: init_forward_metadata(self, forward_batch: ForwardBatch)
         üìù Init the metadata for a forward pass.

  L 182: forward_extend(self, q, k, v, layer: RadixAttention, forward_batch: ForwardBatch, save_kv_cache)

  L 226: forward_decode(self, q, k, v, layer: RadixAttention, forward_batch: ForwardBatch, save_kv_cache)

  L 269: support_triton(self)


============================================================
FILE: python/sglang/srt/layers/attention/triton_backend.py
Functions: 19
============================================================

MODULE FUNCTIONS:
----------------------------------------
  L  23: def logit_capping_mod(logit_capping_method, logit_cap)

  L 965: def get_num_kv_splits_triton(num_kv_splits_ptr,
        seq_lens_ptr,
        num_seq,
        num_group,
        num_head,
        num_kv_head,
        max_kv_splits,
        device_core_count,
        MAX_NUM_SEQ: tl.constexpr)
         @triton.jit

  L1016: def update_sliding_window_buffer(window_kv_indptr,
        req_to_token,
        sliding_window_size,
        seq_lens,
        req_pool_indices,
        bs,
        device,
        token_to_kv_pool_allocator)

  L1056: def update_sliding_window_buffer_cuda_graph(window_kv_indptr,
        window_kv_indices,
        req_to_token,
        sliding_window_size,
        seq_lens,
        req_pool_indices,
        bs,
        token_to_kv_pool_allocator)


CLASS: TritonAttnBackend
----------------------------------------
  L  50: __init__(self, model_runner: ModelRunner, skip_prefill: bool, kv_indptr_buf: Optional[torch.Tensor])

  L 131: get_num_kv_splits(self, num_kv_splits: torch.Tensor, seq_lens: torch.Tensor)

  L 167: init_forward_metadata(self, forward_batch: ForwardBatch)
         üìù Init auxiliary variables for triton attention backend.

  L 369: init_cuda_graph_state(self, max_bs: int, max_num_tokens: int, kv_indices_buf: Optional[torch.Tensor])

  L 427: init_forward_metadata_capture_cuda_graph(self, bs: int, num_tokens: int, req_pool_indices: torch.Tensor, seq_lens: torch.Tensor, encoder_lens: Optional[torch.Tensor], forward_mode: ForwardMode, spec_info: Optional[Union[EagleDraftInput, EagleVerifyInput]])

  L 583: init_forward_metadata_replay_cuda_graph(self, bs: int, req_pool_indices: torch.Tensor, seq_lens: torch.Tensor, seq_lens_sum: int, encoder_lens: Optional[torch.Tensor], forward_mode: ForwardMode, spec_info: Optional[Union[EagleDraftInput, EagleVerifyInput]], seq_lens_cpu: Optional[torch.Tensor])

  L 705: get_cuda_graph_seq_len_fill_value(self)

  L 708: forward_extend(self, q: torch.Tensor, k: torch.Tensor, v: torch.Tensor, layer: RadixAttention, forward_batch: ForwardBatch, save_kv_cache, sinks)

  L 771: forward_decode(self, q: torch.Tensor, k: torch.Tensor, v: torch.Tensor, layer: RadixAttention, forward_batch: ForwardBatch, save_kv_cache, sinks)


CLASS: TritonMultiStepDraftBackend
----------------------------------------
  L 830: __init__(self, model_runner: ModelRunner, topk: int, speculative_num_steps: int)

  L 868: common_template(self, forward_batch: ForwardBatch, kv_indices_buffer: torch.Tensor, call_fn: int)

  L 900: init_forward_metadata(self, forward_batch: ForwardBatch)

  L 921: init_cuda_graph_state(self, max_bs: int, max_num_tokens: int)

  L 932: init_forward_metadata_capture_cuda_graph(self, forward_batch: ForwardBatch)

  L 946: init_forward_metadata_replay_cuda_graph(self, forward_batch: ForwardBatch, bs: int)


============================================================
FILE: python/sglang/srt/layers/attention/triton_ops/decode_attention.py
Functions: 4
============================================================

MODULE FUNCTIONS:
----------------------------------------
  L  39: def tanh(x)
         @triton.jit

  L 633: def decode_attention_fwd_normal(q,
        k_buffer,
        v_buffer,
        o,
        kv_indptr,
        kv_indices,
        attn_logits,
        attn_lse,
        num_kv_splits,
        max_kv_splits,
        sm_scale,
        logit_cap,
        sinks,
        xai_temperature_len)

  L 676: def decode_attention_fwd_grouped(q,
        k_buffer,
        v_buffer,
        o,
        kv_indptr,
        kv_indices,
        attn_logits,
        attn_lse,
        num_kv_splits,
        max_kv_splits,
        sm_scale,
        logit_cap,
        sinks,
        xai_temperature_len)

  L 719: def decode_attention_fwd(q,
        k_buffer,
        v_buffer,
        o,
        kv_indptr,
        kv_indices,
        attn_logits,
        attn_lse,
        num_kv_splits,
        max_kv_splits,
        sm_scale,
        logit_cap,
        sinks,
        xai_temperature_len)


============================================================
FILE: python/sglang/srt/layers/attention/triton_ops/double_sparsity_attention.py
Functions: 9
============================================================

MODULE FUNCTIONS:
----------------------------------------
  L  23: def tanh(x)
         @triton.jit

  L 192: def flash_decode_stage1(q,
        k,
        v,
        Req_to_tokens,
        B_req_idx,
        B_Seqlen,
        max_len_in_batch,
        mid_out,
        mid_out_logsumexp,
        block_seq)
         @torch.no_grad()

  L 255: def flash_decode_stage2(mid_out, mid_out_logexpsum, B_Seqlen, O, block_seq)
         @torch.no_grad()

  L 284: def flash_decode_attention_fwd(q,
        k_buffer,
        v_buffer,
        o,
        req_to_token,
        b_req_idx,
        b_start_loc,
        b_seq_len,
        attn_logits,
        max_len_in_batch,
        sm_scale,
        logit_cap)

  L 561: def sparse_flash_decode_stage1(q_label,
        k_label_buffer,
        att_out,
        Req_to_tokens,
        B_Seqlen,
        max_len_in_batch,
        sm_scale,
        logit_cap)

  L 613: def sparse_flash_decode_stage2(q,
        k,
        v,
        Req_to_tokens,
        Topk_token_indices,
        heavy_token_num,
        mid_out,
        mid_out_logsumexp,
        block_seq,
        sm_scale)
         @torch.no_grad()

  L 674: def sparse_flash_decode_stage3(Seqlen, mid_out, mid_out_logexpsum, O, block_seq)
         @torch.no_grad()

  L 700: def flash_decode_sparse_attention_fwd(q,
        k_buffer,
        v_buffer,
        o,
        q_label,
        k_label_buffer,
        req_to_token,
        b_seq_len,
        max_len_in_batch,
        sm_scale,
        logit_cap,
        heavy_token_num,
        att_out_approx,
        mid_out,
        mid_o_logexpsum,
        BLOCK_SEQ)

  L 994: def extend_attention_fwd(q_extend,
        k_extend,
        v_extend,
        o_extend,
        k_buffer,
        v_buffer,
        req_to_tokens,
        b_req_idx,
        b_seq_len,
        b_seq_len_extend,
        b_start_loc_extend,
        max_len_extend,
        sm_scale,
        logit_cap)
         üìù q_extend, k_extend, v_extend, o_extend: contiguous tensors
            k_buffer, v_buffer: (prefix + extend) tensors in mem_manager


============================================================
FILE: python/sglang/srt/layers/attention/triton_ops/extend_attention.py
Functions: 3
============================================================

MODULE FUNCTIONS:
----------------------------------------
  L  36: def tanh(x)
         @triton.jit

  L 372: def extend_attention_fwd(q_extend,
        k_extend,
        v_extend,
        o_extend,
        k_buffer,
        v_buffer,
        qo_indptr,
        kv_indptr,
        kv_indices,
        custom_mask,
        is_causal,
        mask_indptr,
        max_len_extend,
        sm_scale,
        logit_cap,
        skip_prefix_custom_mask,
        sliding_window_size,
        sinks,
        window_kv_offsets,
        xai_temperature_len)
         üìù q_extend, k_extend, v_extend, o_extend: contiguous tensors
            k_buffer, v_buffer: (prefix + extend) tensors in mem_manager

  L 516: def redundant_attention(q_extend,
        o_extend,
        k_buffer,
        v_buffer,
        b_req_idx,
        b_start_loc,
        b_seq_len,
        b_seq_len_prefix,
        max_len_in_batch)


============================================================
FILE: python/sglang/srt/layers/attention/triton_ops/merge_state.py
Functions: 2
============================================================

MODULE FUNCTIONS:
----------------------------------------
  L   9: def merge_state_kernel(output,
        output_lse,
        prefix_output,
        prefix_lse,
        suffix_output,
        suffix_lse,
        HEAD_SIZE: tl.constexpr,
        PADDED_HEAD_SIZE: tl.constexpr,
        OUTPUT_LSE: tl.constexpr)
         @triton.jit

  L  66: def merge_state_triton(prefix_output: torch.Tensor,
        prefix_lse: torch.Tensor,
        suffix_output: torch.Tensor,
        suffix_lse: torch.Tensor,
        output: Optional[torch.Tensor],
        output_lse: Optional[torch.Tensor])
         ‚Üí Tuple[torch.Tensor, Optional[torch.Tensor]]


============================================================
FILE: python/sglang/srt/layers/attention/triton_ops/prefill_attention.py
Functions: 1
============================================================

MODULE FUNCTIONS:
----------------------------------------
  L 170: def context_attention_fwd(q,
        k,
        v,
        o,
        b_start_loc,
        b_seq_len,
        max_input_len,
        is_causal)
         üìù q, k, v: [b * s, head, head_dim]
            b_start_loc: [b]
            b_seq_len: [b]
            out: [b * s, head, head_dim]


============================================================
FILE: python/sglang/srt/layers/attention/triton_ops/rocm_mla_decode_rope.py
Functions: 3
============================================================

MODULE FUNCTIONS:
----------------------------------------
  L  31: def is_hip()

  L  39: def tanh(x)
         @triton.jit

  L 402: def decode_attention_fwd_grouped_rope(q,
        k_buffer,
        v_buffer,
        o,
        kv_indptr,
        kv_indices,
        k_pe_tokens,
        kv_lora_rank,
        rotary_dim,
        cos_sin_cache,
        positions,
        attn_logits,
        num_kv_splits,
        sm_scale,
        logit_cap,
        use_rope,
        is_neox_style)


============================================================
FILE: python/sglang/srt/layers/attention/trtllm_mha_backend.py
Functions: 13
============================================================


CLASS: TRTLLMHAAttnBackend
----------------------------------------
  L  58: __init__(self, model_runner: ModelRunner, skip_prefill: bool, kv_indptr_buf: Optional[torch.Tensor], kv_last_page_len_buf: Optional[torch.Tensor], speculative_step_id: int)

  L 111: init_cuda_graph_state(self, max_bs: int, max_num_tokens: int, kv_indices_buf: Optional[torch.Tensor])
         üìù Initialize CUDA graph state for TRTLLM MHA.

  L 196: init_forward_metadata_capture_cuda_graph(self, bs: int, num_tokens: int, req_pool_indices: torch.Tensor, seq_lens: torch.Tensor, encoder_lens: Optional[torch.Tensor], forward_mode: ForwardMode, spec_info: Optional[SpecInfo])
         üìù Initialize metadata for CUDA graph capture.

  L 309: init_forward_metadata_replay_cuda_graph(self, bs: int, req_pool_indices: torch.Tensor, seq_lens: torch.Tensor, seq_lens_sum: int, encoder_lens: Optional[torch.Tensor], forward_mode: ForwardMode, spec_info: Optional[SpecInfo], seq_lens_cpu: Optional[torch.Tensor])
         üìù Replay CUDA graph with new inputs.

  L 411: get_cuda_graph_seq_len_fill_value(self)
         ‚Üí int
         üìù Get the fill value for sequence lengths in CUDA graph.

  L 415: init_forward_metadata(self, forward_batch: ForwardBatch)
         üìù Initialize the metadata for a forward pass.

  L 517: forward_decode(self, q: torch.Tensor, k: torch.Tensor, v: torch.Tensor, layer: RadixAttention, forward_batch: ForwardBatch, save_kv_cache: bool)
         ‚Üí torch.Tensor
         üìù Run forward for decode using TRTLLM MHA kernel.

  L 576: forward_extend(self, q: torch.Tensor, k: torch.Tensor, v: torch.Tensor, layer: RadixAttention, forward_batch: ForwardBatch, save_kv_cache)


CLASS: TRTLLMHAAttnMultiStepDraftBackend
----------------------------------------
  L 638: __init__(self, model_runner: ModelRunner, topk: int, speculative_num_steps: int)

  L 651: init_forward_metadata(self, forward_batch: ForwardBatch)

  L 655: init_cuda_graph_state(self, max_bs: int, max_num_tokens: int)

  L 659: init_forward_metadata_capture_cuda_graph(self, forward_batch: ForwardBatch)

  L 677: init_forward_metadata_replay_cuda_graph(self, forward_batch: ForwardBatch, bs: int)


============================================================
FILE: python/sglang/srt/layers/attention/trtllm_mla_backend.py
Functions: 9
============================================================


CLASS: TRTLLMMLABackend
----------------------------------------
  L  60: __init__(self, model_runner: ModelRunner, skip_prefill: bool, kv_indptr_buf: Optional[torch.Tensor], q_indptr_decode_buf: Optional[torch.Tensor])

  L 167: init_cuda_graph_state(self, max_bs: int, max_num_tokens: int, kv_indices_buf: Optional[torch.Tensor])
         üìù Initialize CUDA graph state for TRTLLM MLA.

  L 186: init_forward_metadata_capture_cuda_graph(self, bs: int, num_tokens: int, req_pool_indices: torch.Tensor, seq_lens: torch.Tensor, encoder_lens: Optional[torch.Tensor], forward_mode: ForwardMode, spec_info: Optional[SpecInfo])
         üìù Initialize metadata for CUDA graph capture.

  L 240: init_forward_metadata_replay_cuda_graph(self, bs: int, req_pool_indices: torch.Tensor, seq_lens: torch.Tensor, seq_lens_sum: int, encoder_lens: Optional[torch.Tensor], forward_mode: ForwardMode, spec_info: Optional[SpecInfo], seq_lens_cpu: Optional[torch.Tensor])
         üìù Replay CUDA graph with new inputs.

  L 287: get_cuda_graph_seq_len_fill_value(self)
         ‚Üí int
         üìù Get the fill value for sequence lengths in CUDA graph.

  L 291: init_forward_metadata(self, forward_batch: ForwardBatch)
         üìù Initialize the metadata for a forward pass.

  L 320: quantize_and_rope_for_fp8(self, q_nope: torch.Tensor, q_rope: torch.Tensor, k_nope: torch.Tensor, k_rope: torch.Tensor, forward_batch: ForwardBatch, cos_sin_cache: torch.Tensor, is_neox: bool)
         ‚Üí tuple[torch.Tensor, torch.Tensor, torch.Tensor]
         üìù Quantize and apply RoPE for FP8 attention path.
            This function handles the FP8 quantization and RoPE application for MLA attention.
            It takes separate query/key nope and rope components, applies RoPE to the rope parts,
            quantizes all components to FP8, and merges the query components into a single tensor.
            Args:
            q_nope: Query no-position-encoding component [seq_len, num_heads, kv_lora_rank]
            - expected dtype: torch.bfloat16
            q_rope: Query RoPE component [seq_len, num_heads, qk_rope_head_dim]
            - expected dtype: torch.bfloat16
            k_nope: Key no-position-encoding component [seq_len, num_heads, kv_lora_rank]
            - expected dtype: torch.bfloat16
            k_rope: Key RoPE component [seq_len, num_heads, qk_rope_head_dim]
            - expected dtype: torch.bfloat16
            forward_batch: Forward batch containing position information
            cos_sin_cache: Precomputed cosine/sine cache for RoPE
            - expected dtype: matches q_/k_ input dtype (torch.bfloat16)
            is_neox: Whether to use NeoX-style RoPE (interleaved) or GPT-style (half rotation)
            Returns:
            tuple: (merged_q_out, k_nope_out, k_rope_out) quantized to FP8
            - merged_q_out: [seq_len, num_heads, kv_lora_rank + qk_rope_head_dim], dtype=torch.float8_e4m3fn
            - k_nope_out:   [seq_len, num_heads, kv_lora_rank], dtype=torch.float8_e4m3fn
            - k_rope_out:   [seq_len, num_heads, qk_rope_head_dim], dtype=torch.float8_e4m3fn

  L 398: forward_decode(self, q: torch.Tensor, k: torch.Tensor, v: torch.Tensor, layer: RadixAttention, forward_batch: ForwardBatch, save_kv_cache: bool, q_rope: Optional[torch.Tensor], k_rope: Optional[torch.Tensor], cos_sin_cache: Optional[torch.Tensor], is_neox: Optional[bool])
         ‚Üí torch.Tensor
         üìù Run forward for decode using TRTLLM MLA kernel.


CLASS: TRTLLMMLAMultiStepDraftBackend
----------------------------------------
  L 503: __init__(self, model_runner: 'ModelRunner', topk: int, speculative_num_steps: int)


============================================================
FILE: python/sglang/srt/layers/attention/utils.py
Functions: 2
============================================================

MODULE FUNCTIONS:
----------------------------------------
  L  11: def create_flashinfer_kv_indices_triton(req_to_token_ptr,
        req_pool_indices_ptr,
        page_kernel_lens_ptr,
        kv_indptr,
        kv_start_idx,
        kv_indices_ptr,
        req_to_token_ptr_stride: tl.constexpr)
         @triton.jit

  L  50: def create_flashmla_kv_indices_triton(req_to_token_ptr,
        req_pool_indices_ptr,
        page_kernel_lens_ptr,
        kv_start_idx,
        kv_indices_ptr,
        req_to_token_ptr_stride: tl.constexpr,
        kv_indices_ptr_stride: tl.constexpr,
        NUM_PAGE_PER_BLOCK: tl.constexpr,
        PAGED_SIZE: tl.constexpr)
         @triton.jit


============================================================
FILE: python/sglang/srt/layers/attention/vision.py
Functions: 12
============================================================


CLASS: SingletonCache
----------------------------------------
  L  55: set_data(self, value: Any)
         ‚Üí None

  L  58: get_data(self)
         ‚Üí Optional[Any]

  L  61: empty(self)
         ‚Üí bool


CLASS: VisionAttention
----------------------------------------
  L 354: __init__(self, embed_dim: int, num_heads: int, projection_size: int, use_qkv_parallel: bool, qkv_backend: Optional[str], quant_config: Optional[QuantizationConfig], dropout: float, softmax_in_single_precision: bool, flatten_batch: bool, prefix: str, proj_bias: bool, num_dummy_heads: int, qkv_bias: bool, qk_normalization: bool, layer_norm_eps: float, customized_position_embedding_applier: Callable[[torch.Tensor, torch.Tensor, Any, Any], Tuple[torch.Tensor, torch.Tensor]])

  L 509: forward(self, x: torch.Tensor, cu_seqlens: Optional[torch.Tensor], position_embeddings: Optional[Tuple[torch.Tensor, torch.Tensor]], attention_mask: Optional[torch.Tensor])
         ‚Üí torch.Tensor
         üìù Args:
            x: [b, s, embed_dim]
            cu_seqlens: [b]
            Returns:
            [s, b, head * head_size]


CLASS: VisionFlash3Attention
----------------------------------------
  L 284: __init__(self)

  L 292: forward(self, q: torch.Tensor, k: torch.Tensor, v: torch.Tensor, cu_seqlens: Optional[Union[SingletonCache, torch.Tensor]], bsz: int, seq_len: int)
         ‚Üí torch.Tensor
         üìù Args:
            cu_seqlens: [b]
            Returns:
            [b * s, h, head_size]


CLASS: VisionSdpaAttention
----------------------------------------
  L  88: __init__(self, head_dim: int, num_heads: int, num_kv_heads: int, dropout: float, flatten_batch: bool, softmax_in_single_precision: bool)

  L 141: generate_patch_attention_mask(self, s: int, cu_seqlens: Optional[torch.Tensor], flatten_batch: bool)
         ‚Üí Optional[torch.Tensor]
         üìù Creates a non-causal 4D mask of shape `(b, 1, s, s)` or `(1, 1, s, s)`.
            Args:
            s: sequence length
            cu_seqlens: cumulative sequence lengths tensor. If not, returns an empty mask
            flatten_batch: whether to flatten batch dimension
            Returns:
            attention mask tensor or None

  L 163: forward(self, q: torch.Tensor, k: torch.Tensor, v: torch.Tensor, bsz: int, cu_seqlens: Optional[torch.Tensor], attention_mask: Optional[torch.Tensor])
         ‚Üí torch.Tensor
         üìù Args:
            cu_seqlens: [b]
            Returns:
            [b * s, h, head_size]


CLASS: VisionTritonAttention
----------------------------------------
  L 240: __init__(self)

  L 246: forward(self, q: torch.Tensor, k: torch.Tensor, v: torch.Tensor, cu_seqlens: Optional[torch.Tensor], bsz: int, seq_len: int)
         ‚Üí torch.Tensor
         üìù Args:
            cu_seqlens: [b]
            Returns:
            [b * s, h, head_size]


============================================================
FILE: python/sglang/srt/layers/attention/vision_utils.py
Functions: 2
============================================================

MODULE FUNCTIONS:
----------------------------------------
  L   8: def update_vit_attn_dummy_heads_config(config)
         üìù Update HF config to ensure vision attention num_attention_heads is divisible by tp_size

  L  26: def pad_vit_attn_dummy_heads(config, name: str, loaded_weight: torch.Tensor)
         üìù Pad attention qkv weights for dummy heads


============================================================
FILE: python/sglang/srt/layers/attention/wave_backend.py
Functions: 10
============================================================

MODULE FUNCTIONS:
----------------------------------------
  L  26: def get_num_kv_splits_triton(num_kv_splits_ptr,
        seq_lens_ptr,
        num_seq,
        num_group,
        num_head,
        num_kv_head,
        max_kv_splits,
        device_core_count,
        MAX_NUM_SEQ: tl.constexpr)
         @triton.jit


CLASS: WaveAttnBackend
----------------------------------------
  L  91: __init__(self, model_runner: ModelRunner, skip_prefill: bool, kv_indptr_buf: Optional[torch.Tensor])

  L 162: get_num_kv_splits(self, num_kv_splits: torch.Tensor, seq_lens: torch.Tensor)

  L 195: init_forward_metadata(self, forward_batch: ForwardBatch)
         üìù Init auxiliary variables for wave attention backend.

  L 344: init_cuda_graph_state(self, max_bs: int, max_num_tokens: int, kv_indices_buf: Optional[torch.Tensor])

  L 388: init_forward_metadata_capture_cuda_graph(self, bs: int, num_tokens: int, req_pool_indices: torch.Tensor, seq_lens: torch.Tensor, encoder_lens: Optional[torch.Tensor], forward_mode: ForwardMode, spec_info: Optional[Union[EagleDraftInput, EagleVerifyInput]])

  L 472: init_forward_metadata_replay_cuda_graph(self, bs: int, req_pool_indices: torch.Tensor, seq_lens: torch.Tensor, seq_lens_sum: int, encoder_lens: Optional[torch.Tensor], forward_mode: ForwardMode, spec_info: Optional[Union[EagleDraftInput, EagleVerifyInput]], seq_lens_cpu: Optional[torch.Tensor])

  L 540: get_cuda_graph_seq_len_fill_value(self)

  L 543: forward_extend(self, q: torch.Tensor, k: torch.Tensor, v: torch.Tensor, layer: RadixAttention, forward_batch: ForwardBatch, save_kv_cache)

  L 589: forward_decode(self, q: torch.Tensor, k: torch.Tensor, v: torch.Tensor, layer: RadixAttention, forward_batch: ForwardBatch, save_kv_cache)


============================================================
FILE: python/sglang/srt/layers/attention/wave_ops/decode_attention.py
Functions: 4
============================================================

MODULE FUNCTIONS:
----------------------------------------
  L  27: def get_wave_kernel(shape: paged_decode_attention_shape,
        max_kv_splits,
        input_dtype,
        output_dtype,
        logit_cap)
         @functools.lru_cache(maxsize=4096)

  L  92: def decode_attention_intermediate_arrays_shapes(num_seqs,
        head_size_kv,
        num_query_heads,
        max_kv_splits)

  L 107: def decode_attention_wave(q,
        k_buffer,
        v_buffer,
        o,
        b_req_idx,
        req_to_token,
        attn_logits,
        attn_logits_max,
        num_kv_splits,
        max_kv_splits,
        sm_scale,
        logit_cap)

  L 159: def decode_attention_fwd(q,
        k_buffer,
        v_buffer,
        o,
        b_req_idx,
        req_to_token,
        attn_logits,
        attn_logits_max,
        num_kv_splits,
        max_kv_splits,
        sm_scale,
        logit_cap)


============================================================
FILE: python/sglang/srt/layers/attention/wave_ops/extend_attention.py
Functions: 2
============================================================

MODULE FUNCTIONS:
----------------------------------------
  L  23: def get_wave_kernel(shape: AttentionShape,
        q_shape: tuple[int],
        k_shape: tuple[int],
        v_shape: tuple[int],
        k_cache_shape: tuple[int],
        v_cache_shape: tuple[int],
        o_shape: tuple[int],
        input_dtype: torch.dtype,
        output_dtype: torch.dtype,
        size_dtype: torch.dtype,
        is_causal: bool,
        logit_cap: float,
        layer_scaling: float)
         @functools.lru_cache

  L  83: def extend_attention_wave(q_extend,
        k_extend,
        v_extend,
        k_buffer,
        v_buffer,
        qo_indptr,
        kv_indptr,
        kv_indices,
        custom_mask,
        mask_indptr,
        max_seq_len,
        output,
        is_causal,
        layer_scaling,
        logit_cap)


============================================================
FILE: python/sglang/srt/layers/attention/wave_ops/prefill_attention.py
Functions: 1
============================================================

MODULE FUNCTIONS:
----------------------------------------
  L  22: def prefill_attention_wave(q,
        k,
        v,
        o,
        b_start_loc,
        b_seq_len,
        max_seq_len,
        is_causal)


============================================================
FILE: python/sglang/srt/layers/communicator.py
Functions: 16
============================================================

MODULE FUNCTIONS:
----------------------------------------
  L 155: def enable_moe_dense_fully_dp()


CLASS: CommunicateContext
----------------------------------------
  L 315: is_same_group_size(self, a: ScatterMode, b: ScatterMode)

  L 319: init_new(cls)


CLASS: CommunicateSimpleFn
----------------------------------------
  L 341: get_fn(input_mode: ScatterMode, output_mode: ScatterMode, context: CommunicateContext)


CLASS: CommunicateSummableTensorPairFn
----------------------------------------
  L 527: execute(cls, hidden_states_input_mode, residual_input_mode, output_mode, context)

  L 543: get_fn(hidden_states_input_mode: ScatterMode, residual_input_mode: ScatterMode, output_mode: ScatterMode, context: CommunicateContext)


CLASS: CommunicateWithAllReduceAndLayerNormFn
----------------------------------------
  L 388: get_fn(hidden_states_input_mode: ScatterMode, residual_input_mode: ScatterMode, hidden_states_output_mode: ScatterMode, residual_output_mode: ScatterMode, context: CommunicateContext)


CLASS: LayerCommunicator
----------------------------------------
  L 160: __init__(self, layer_scatter_modes: LayerScatterModes, input_layernorm: torch.nn.Module, post_attention_layernorm: torch.nn.Module, allow_reduce_scatter: bool, is_last_layer: bool)

  L 199: prepare_attn(self, hidden_states: torch.Tensor, residual: torch.Tensor, forward_batch: ForwardBatch)

  L 235: prepare_mlp(self, hidden_states: torch.Tensor, residual: torch.Tensor, forward_batch: ForwardBatch)

  L 249: postprocess_layer(self, hidden_states: torch.Tensor, residual: torch.Tensor, forward_batch: ForwardBatch)

  L 263: should_use_reduce_scatter(self, forward_batch: ForwardBatch)

  L 271: should_fuse_mlp_allreduce_with_next_layer(self, forward_batch: ForwardBatch)
         ‚Üí bool


CLASS: LayerScatterModes
----------------------------------------
  L  99: init_new(cls)


CLASS: ScatterMode
----------------------------------------
  L  67: model_input_output()
         üìù The scatter mode for model forward pass input and output data


CLASS: _LayerModeComputationContext
----------------------------------------
  L  79: previous_layer(self)


============================================================
FILE: python/sglang/srt/layers/dp_attention.py
Functions: 40
============================================================

MODULE FUNCTIONS:
----------------------------------------
  L 123: def set_dp_buffer_len(global_dp_buffer_len: int,
        local_dp_buffer_len: int,
        global_num_tokens: Optional[List[int]])

  L 133: def get_global_dp_buffer()
         ‚Üí torch.Tensor

  L 137: def get_local_dp_buffer()
         ‚Üí torch.Tensor

  L 141: def get_global_dp_buffer_len()
         ‚Üí int

  L 145: def get_local_dp_buffer_len()
         ‚Üí int

  L 149: def get_dp_global_num_tokens()
         ‚Üí List[int]

  L 153: def compute_dp_attention_world_info(enable_dp_attention,
        tp_rank,
        tp_size,
        dp_size)

  L 164: def compute_dp_attention_local_info(enable_dp_attention,
        tp_rank,
        tp_size,
        dp_size,
        moe_dense_tp_size)

  L 181: def initialize_dp_attention(server_args: ServerArgs, model_config: ModelConfig)

  L 241: def is_dp_attention_enabled()
         ‚Üí bool

  L 245: def get_attention_tp_group()
         ‚Üí GroupCoordinator

  L 250: def get_attention_tp_rank()
         ‚Üí int

  L 255: def get_attention_tp_size()
         ‚Üí int

  L 260: def get_attention_dp_rank()
         ‚Üí int

  L 265: def get_attention_dp_size()
         ‚Üí int

  L 270: def get_local_attention_dp_rank()
         ‚Üí int

  L 275: def get_local_attention_dp_size()
         ‚Üí int

  L 281: def disable_dp_size()
         üìù Patch the tp group temporarily until this function ends.
            This method is for draft workers of speculative decoding to run draft model
            with different tp degree from that of target model workers.
            Args:
            tp_group (GroupCoordinator): the tp group coordinator
         @contextmanager

  L 301: def get_dp_local_info(forward_batch: ForwardBatch)
         ‚Üí Tuple[torch.Tensor, torch.Tensor]

  L 320: def memcpy_triton_kernel(dst_ptr,
        src_ptr,
        offset_ptr,
        sz_ptr,
        offset_src: tl.constexpr,
        chunk_size,
        BLOCK_SIZE: tl.constexpr)
         @triton.jit

  L 345: def prod(x)

  L 349: def memcpy_triton(dst, src, dim, offset, sz, offset_src)

  L 431: def dp_gather_partial(global_tokens: torch.Tensor,
        local_tokens: torch.Tensor,
        forward_batch: ForwardBatch)

  L 439: def dp_gather_replicate(global_tokens: torch.Tensor,
        local_tokens: torch.Tensor,
        forward_batch: ForwardBatch)

  L 447: def dp_scatter(local_tokens: torch.Tensor,
        global_tokens: torch.Tensor,
        forward_batch: ForwardBatch)

  L 469: def dp_reduce_scatter_tensor(output: torch.Tensor, input: torch.Tensor)

  L 480: def attn_tp_reduce_scatter_tensor(output: torch.Tensor, input: torch.Tensor)

  L 484: def attn_tp_all_gather_into_tensor(output: torch.Tensor, input: torch.Tensor)

  L 488: def attn_tp_all_gather(output_list: List[torch.Tensor], input: torch.Tensor)


CLASS: DpPaddingMode
----------------------------------------
  L  47: is_max_len(self)

  L  50: is_sum_len(self)

  L  54: get_dp_padding_mode(cls, global_num_tokens: List[int])
         ‚Üí DpPaddingMode

  L  64: get_default_mode_in_cuda_graph(cls)
         ‚Üí DpPaddingMode


CLASS: _DpGatheredBufferWrapper
----------------------------------------
  L  78: set_metadata(cls, hidden_size: int, dtype: torch.dtype, device: torch.device)

  L  84: set_dp_buffer_len(cls, global_dp_buffer_len: int, local_dp_buffer_len: int, global_num_tokens: Optional[List[int]])

  L  95: get_global_dp_buffer(cls)
         ‚Üí torch.Tensor

  L 103: get_local_dp_buffer(cls)
         ‚Üí torch.Tensor

  L 111: get_global_dp_buffer_len(cls)
         ‚Üí int

  L 115: get_local_dp_buffer_len(cls)
         ‚Üí int

  L 119: get_dp_global_num_tokens(cls)
         ‚Üí List[int]


============================================================
FILE: python/sglang/srt/layers/elementwise.py
Functions: 23
============================================================

MODULE FUNCTIONS:
----------------------------------------
  L  37: def fused_softcap_kernel(output_ptr,
        input_ptr,
        n_ele,
        softcap_const: tl.constexpr,
        BLOCK_SIZE: tl.constexpr)
         @triton.jit

  L  61: def fused_softcap(x, softcap_const, autotune)

  L 138: def fused_dual_residual_rmsnorm_kernel(output_ptr,
        mid_ptr,
        activ_ptr,
        residual_ptr,
        weight1_ptr,
        weight2_ptr,
        eps: tl.constexpr,
        hidden_dim: tl.constexpr,
        BLOCK_SIZE: tl.constexpr)
         @triton.jit

  L 188: def fused_dual_residual_rmsnorm(x, residual, weight1, weight2, eps, autotune)

  L 222: def fused_rmsnorm_kernel(output_ptr,
        activ_ptr,
        weight_ptr,
        eps: tl.constexpr,
        hidden_dim: tl.constexpr,
        BLOCK_SIZE: tl.constexpr)
         @triton.jit

  L 252: def fused_rmsnorm(x, weight, eps, autotune, inplace)

  L 329: def experts_combine_kernel(out_hidden_states,
        moe_hidden_states,
        mlp_hidden_states,
        combine_k: tl.constexpr,
        hidden_dim: tl.constexpr,
        BLOCK_SIZE: tl.constexpr)
         @triton.jit

  L 359: def experts_combine_triton(moe_hidden_states, mlp_hidden_states, output_buffer)

  L 399: def gelu_and_mul_kernel(out_hidden_states_ptr,
        out_scales_ptr,
        hidden_states_ptr,
        quant_max: tl.constexpr,
        static_scale: tl.constexpr,
        hidden_dim: tl.constexpr,
        BLOCK_SIZE: tl.constexpr)
         @triton.jit

  L 436: def gelu_and_mul_triton(hidden_states, scales, quantize, out)

  L 493: def silu_and_mul_kernel(out_hidden_states_ptr,
        out_scales_ptr,
        hidden_states_ptr,
        quant_max: tl.constexpr,
        static_scale: tl.constexpr,
        hidden_dim: tl.constexpr,
        BLOCK_SIZE: tl.constexpr)
         @triton.jit

  L 530: def silu_and_mul_triton(hidden_states, scales, quantize, out)


CLASS: FusedDualResidualRMSNorm
----------------------------------------
  L 279: __init__(self, rmsnorm1, rmsnorm2)
         ‚Üí None

  L 286: __call__(self)

  L 289: forward(self, x: torch.Tensor, residual: torch.Tensor)
         ‚Üí Tuple[torch.Tensor, torch.Tensor]

  L 297: forward_cuda(self, x: torch.Tensor, residual: torch.Tensor, autotune)
         ‚Üí Tuple[torch.Tensor, torch.Tensor]

  L 309: forward_flashinfer(self, x: torch.Tensor, residual: torch.Tensor)
         ‚Üí Tuple[torch.Tensor, torch.Tensor]

  L 318: forward_native(self, x: torch.Tensor, residual: torch.Tensor)
         ‚Üí Tuple[torch.Tensor, torch.Tensor]


CLASS: Softcap
----------------------------------------
  L  76: __init__(self, softcap_const: float)

  L  79: __call__(self)

  L  82: forward(self, x: torch.Tensor)
         ‚Üí torch.Tensor

  L  88: forward_native(self, x: torch.Tensor)
         ‚Üí torch.Tensor

  L  91: forward_cuda(self, x: torch.Tensor, autotune)
         ‚Üí torch.Tensor


============================================================
FILE: python/sglang/srt/layers/flashinfer_comm_fusion.py
Functions: 7
============================================================

MODULE FUNCTIONS:
----------------------------------------
  L  98: def ensure_workspace_initialized(max_token_num: int,
        hidden_dim: int,
        use_fp32_lamport: bool)
         üìù Ensure workspace is initialized

  L 126: def flashinfer_allreduce_residual_rmsnorm(input_tensor: torch.Tensor,
        residual: torch.Tensor,
        weight: torch.Tensor,
        eps: float,
        max_token_num: int,
        use_oneshot: Optional[bool],
        trigger_completion_at_end: bool,
        fp32_acc: bool)
         ‚Üí Tuple[torch.Tensor, torch.Tensor]
         üìù Use FlashInfer's fused allreduce + residual + RMS norm operation
            Args:
            input_tensor: Input tensor that needs allreduce
            residual: Residual tensor
            weight: RMS norm weight
            eps: RMS norm epsilon
            max_token_num: Maximum token number
            use_oneshot: Whether to use oneshot mode
            trigger_completion_at_end: Whether to trigger completion at end
            fp32_acc: Whether to use fp32 precision
            Returns:
            Tuple[torch.Tensor, torch.Tensor]: (norm_output, residual_output)

  L 203: def fake_flashinfer_allreduce_residual_rmsnorm(input_tensor: torch.Tensor,
        residual: torch.Tensor,
        weight: torch.Tensor,
        eps: float,
        max_token_num: int,
        use_oneshot: Optional[bool],
        trigger_completion_at_end: bool,
        fp32_acc: bool)
         ‚Üí Tuple[torch.Tensor, torch.Tensor]

  L 227: def cleanup_flashinfer_workspace()


CLASS: FlashInferWorkspaceManager
----------------------------------------
  L  32: __init__(self)

  L  39: initialize(self, world_size: int, rank: int, max_token_num: int, hidden_dim: int, group, use_fp32_lamport: bool)
         üìù Initialize workspace

  L  80: cleanup(self)
         üìù Clean up workspace


============================================================
FILE: python/sglang/srt/layers/layernorm.py
Functions: 17
============================================================


CLASS: Gemma3RMSNorm
----------------------------------------
  L 288: __init__(self, dim: int, eps: float)

  L 297: forward_native(self, x)

  L 304: forward_cuda(self, x)

  L 307: forward_npu(self, x)

  L 311: extra_repr(self)


CLASS: GemmaRMSNorm
----------------------------------------
  L 226: __init__(self, hidden_size: int, eps: float)
         ‚Üí None

  L 239: forward_native(self, x: torch.Tensor, residual: Optional[torch.Tensor])
         ‚Üí Union[torch.Tensor, Tuple[torch.Tensor, torch.Tensor]]

  L 256: forward_cuda(self, x: torch.Tensor, residual: Optional[torch.Tensor])
         ‚Üí Union[torch.Tensor, Tuple[torch.Tensor, torch.Tensor]]

  L 269: forward_npu(self, x: torch.Tensor, residual: Optional[torch.Tensor])
         ‚Üí Union[torch.Tensor, Tuple[torch.Tensor, torch.Tensor]]


CLASS: RMSNorm
----------------------------------------
  L  61: __init__(self, hidden_size: int, eps: float, var_hidden_size: Optional[int])
         ‚Üí None

  L  77: forward_cuda(self, x: torch.Tensor, residual: Optional[torch.Tensor])
         ‚Üí Union[torch.Tensor, Tuple[torch.Tensor, torch.Tensor]]

  L  90: forward_npu(self, x: torch.Tensor, residual: Optional[torch.Tensor])
         ‚Üí Union[torch.Tensor, Tuple[torch.Tensor, torch.Tensor]]

  L 102: forward_aiter(self, x: torch.Tensor, residual: Optional[torch.Tensor])
         ‚Üí Union[torch.Tensor, Tuple[torch.Tensor, torch.Tensor]]

  L 121: forward_hip(self, x: torch.Tensor, residual: Optional[torch.Tensor])
         ‚Üí Union[torch.Tensor, Tuple[torch.Tensor, torch.Tensor]]

  L 136: forward_native(self, x: torch.Tensor, residual: Optional[torch.Tensor])
         ‚Üí Union[torch.Tensor, Tuple[torch.Tensor, torch.Tensor]]

  L 175: forward_cpu(self, x: torch.Tensor, residual: Optional[torch.Tensor])
         ‚Üí Union[torch.Tensor, Tuple[torch.Tensor, torch.Tensor]]

  L 192: forward_with_allreduce_fusion(self, x: torch.Tensor, residual: Optional[torch.Tensor])
         ‚Üí Union[torch.Tensor, Tuple[torch.Tensor, torch.Tensor]]
         üìù Forward method with allreduce fusion, prioritizing flashinfer fused operations


============================================================
FILE: python/sglang/srt/layers/linear.py
Functions: 26
============================================================

MODULE FUNCTIONS:
----------------------------------------
  L  67: def adjust_marlin_shard(param, shard_size, shard_offset)

  L  75: def adjust_bitsandbytes_4bit_shard(param: Parameter,
        shard_offsets: Dict[str,
        Tuple[int,
        int]],
        loaded_shard_id: str)
         ‚Üí Tuple[int, int]
         üìù Adjust the quantization offsets and sizes for BitsAndBytes sharding.

  L  90: def adjust_scalar_to_fused_array(param, loaded_weight, shard_id)
         üìù For fused modules (QKV and MLP) we have an array of length
            N that holds 1 scale for each "logical" matrix. So the param
            is an array of length N. The loaded_weight corresponds to
            one of the shards on disk. Here, we slice the param based on
            the shard_id for loading.

  L 113: def adjust_shard_offsets(shard_offsets, loaded_weight, dim)


CLASS: ColumnParallelLinear
----------------------------------------
  L 281: __init__(self, input_size: int, output_size: int, bias: bool, gather_output: bool, skip_bias_add: bool, params_dtype: Optional[torch.dtype], quant_config: Optional[QuantizationConfig], output_sizes: Optional[List[int]], prefix: str, tp_rank: Optional[int], tp_size: Optional[int], use_presharded_weights: bool)

  L 348: weight_loader(self, param: Parameter, loaded_weight: torch.Tensor)

  L 398: weight_loader_v2(self, param: Parameter, loaded_weight: torch.Tensor)

  L 416: forward(self, input_)

  L 430: extra_repr(self)
         ‚Üí str


CLASS: LinearBase
----------------------------------------
  L 139: __init__(self, input_size: int, output_size: int, skip_bias_add: bool, params_dtype: Optional[torch.dtype], quant_config: Optional[QuantizationConfig], prefix: str)

  L 162: forward(self, x: torch.Tensor)
         ‚Üí torch.Tensor


CLASS: MergedColumnParallelLinear
----------------------------------------
  L 462: __init__(self, input_size: int, output_sizes: List[int], bias: bool, gather_output: bool, skip_bias_add: bool, params_dtype: Optional[torch.dtype], quant_config: Optional[QuantizationConfig], prefix: str, tp_rank: Optional[int], tp_size: Optional[int], use_presharded_weights: bool)

  L 499: weight_loader(self, param: Parameter, loaded_weight: torch.Tensor, loaded_shard_id: Optional[int])

  L 694: weight_loader_v2(self, param: BasevLLMParameter, loaded_weight: torch.Tensor, loaded_shard_id: Optional[int])


CLASS: QKVParallelLinear
----------------------------------------
  L 774: __init__(self, hidden_size: int, head_size: int, total_num_heads: int, total_num_kv_heads: Optional[int], bias: bool, skip_bias_add: bool, params_dtype: Optional[torch.dtype], quant_config: Optional[QuantizationConfig], prefix: str, tp_rank: Optional[int], tp_size: Optional[int], load_presharded_attn: bool)

  L 897: weight_loader_v2(self, param: BasevLLMParameter, loaded_weight: torch.Tensor, loaded_shard_id: Optional[str])

  L 935: weight_loader(self, param: Parameter, loaded_weight: torch.Tensor, loaded_shard_id: Optional[str])


CLASS: ReplicatedLinear
----------------------------------------
  L 180: __init__(self, input_size: int, output_size: int, bias: bool, skip_bias_add: bool, params_dtype: Optional[torch.dtype], quant_config: Optional[QuantizationConfig], prefix: str)

  L 225: weight_loader(self, param: Parameter, loaded_weight: torch.Tensor)

  L 243: forward(self, x: torch.Tensor)
         ‚Üí Tuple[torch.Tensor, Optional[torch.Tensor]]

  L 250: extra_repr(self)
         ‚Üí str


CLASS: RowParallelLinear
----------------------------------------
  L1174: __init__(self, input_size: int, output_size: int, bias: bool, input_is_parallel: bool, skip_bias_add: bool, params_dtype: Optional[torch.dtype], reduce_results: bool, quant_config: Optional[QuantizationConfig], prefix: str, tp_rank: Optional[int], tp_size: Optional[int], use_presharded_weights: bool)

  L1232: weight_loader(self, param: Parameter, loaded_weight: torch.Tensor)

  L1284: weight_loader_v2(self, param: BasevLLMParameter, loaded_weight: torch.Tensor)

  L1305: forward(self, input_, skip_all_reduce)

  L1332: extra_repr(self)
         ‚Üí str


============================================================
FILE: python/sglang/srt/layers/logits_processor.py
Functions: 9
============================================================

MODULE FUNCTIONS:
----------------------------------------
  L 607: def fused_softcap_kernel(full_logits_ptr,
        softcapping_value,
        n_elements,
        BLOCK_SIZE: tl.constexpr)
         @triton.jit

  L 634: def fused_softcap(full_logits, final_logit_softcapping)


CLASS: LogitsMetadata
----------------------------------------
  L 123: from_forward_batch(cls, forward_batch: ForwardBatch)

  L 173: compute_dp_attention_metadata(self)


CLASS: LogitsProcessor
----------------------------------------
  L 202: __init__(self, config, skip_all_gather: bool, logit_scale: Optional[float])

  L 235: forward(self, input_ids, hidden_states, lm_head: VocabParallelEmbedding, logits_metadata: Union[LogitsMetadata, ForwardBatch], aux_hidden_states: Optional[torch.Tensor])
         ‚Üí LogitsProcessorOutput

  L 525: get_top_logprobs(all_logprobs: torch.Tensor, logits_metadata: LogitsMetadata)

  L 554: get_token_ids_logprobs(all_logprobs: torch.Tensor, logits_metadata: LogitsMetadata)

  L 577: compute_temp_top_p_normalized_logprobs(last_logits: torch.Tensor, logits_metadata: LogitsMetadata)
         ‚Üí torch.Tensor
         üìù compute logprobs for the output token from the given logits.
            Returns:
            torch.Tensor: logprobs from logits


============================================================
FILE: python/sglang/srt/layers/moe/cutlass_moe.py
Functions: 2
============================================================

MODULE FUNCTIONS:
----------------------------------------
  L  21: def cutlass_fused_experts_fp8(a: torch.Tensor,
        w1_q: torch.Tensor,
        w2_q: torch.Tensor,
        w1_scale: torch.Tensor,
        w2_scale: torch.Tensor,
        topk_weights: torch.Tensor,
        topk_ids: torch.Tensor,
        a1_strides: torch.Tensor,
        c1_strides: torch.Tensor,
        a2_strides: torch.Tensor,
        c2_strides: torch.Tensor,
        workspace: torch.Tensor,
        a_ptrs: torch.Tensor,
        b_ptrs: torch.Tensor,
        out_ptrs: torch.Tensor,
        a_scales_ptrs: torch.Tensor,
        b_scales_ptrs: torch.Tensor,
        expert_offsets: torch.Tensor,
        problem_sizes1: torch.Tensor,
        problem_sizes2: torch.Tensor,
        use_fp8_blockscale: bool)
         ‚Üí torch.Tensor
         üìù Performs Fused MoE computation using CUTLASS-like kernels with FP8 weights and activations.
            This function implements a Mixture of Experts (MoE) layer with a SwiGLU/SiLU
            activation, leveraging custom kernels likely derived from CUTLASS principles
            for grouped matrix multiplication (`fp8_blockwise_scaled_grouped_mm`) and
            data preparation (`prepare_moe_input`, `silu_and_mul`).
            It handles per-token routing, quantizes input activations to FP8 with
            per-token scales, performs the expert computations using FP8 GEMMs with
            pre-quantized FP8 weights (per-block scales), applies the SiLU activation,
            and combines the results weighted by the router scores.
            Args:
            a (torch.Tensor): Input activations. Shape: `(m, k)`, where `m` is the total
            number of tokens and `k` is the hidden size. Expected dtype: `torch.half`
            or `torch.bfloat16`.
            w1_q (torch.Tensor): Pre-quantized FP8 weight tensor for the first GEMM
            (up-projection part of SwiGLU). Expected shape: `(E, k, n*2)`, where
            `E` is the number of experts, `k` is the hidden size, and `n*2` is the
            intermediate size (`I`). Expected dtype: `torch.float8_e4m3fn`.
            Note: This shape implies weights are stored as (num_experts, hidden_size, intermediate_size).
            w2_q (torch.Tensor): Pre-quantized FP8 weight tensor for the second GEMM
            (down-projection). Expected shape: `(E, n, k)`, where `n` is half the
            intermediate size (`I // 2`). Expected dtype: `torch.float8_e4m3fn`.
            Note: This shape implies weights are stored as (num_experts, intermediate_size // 2, hidden_size).
            w1_scale (torch.Tensor): Scales corresponding to `w1_q` (per-block scales).
            Shape: `(E, num_blocks_n, num_blocks_k)`. Dtype: `torch.float32`.
            w2_scale (torch.Tensor): Scales corresponding to `w2_q` (per-block scales).
            Shape: `(E, num_blocks_k, num_blocks_n)`. Dtype: `torch.float32`.
            topk_weights (torch.Tensor): Router weights for the selected top-k experts
            for each token. Shape: `(m, topk)`. Dtype should ideally match `a`.
            topk_ids (torch.Tensor): Indices of the selected top-k experts for each token.
            Shape: `(m, topk)`. Dtype: `torch.int32`.
            a1_strides (torch.Tensor): Stride information for the first GEMM's 'a' input.
            Passed directly to the underlying kernel. Expected shape `(E,)`, dtype `torch.int64`.
            Note: Its exact usage within `fp8_blockwise_scaled_grouped_mm` needs clarification
            as it's passed as both a_stride and b_stride in the first call.
            c1_strides (torch.Tensor): Stride information for the first GEMM's 'c' output.
            Passed directly to the underlying kernel. Expected shape `(E,)`, dtype `torch.int64`.
            a2_strides (torch.Tensor): Stride information for the second GEMM's 'a' input.
            Passed directly to the underlying kernel. Expected shape `(E,)`, dtype `torch.int64`.
            Note: Its exact usage within `fp8_blockwise_scaled_grouped_mm` needs clarification
            as it's passed as both a_stride and b_stride in the second call.
            c2_strides (torch.Tensor): Stride information for the second GEMM's 'c' output.
            Passed directly to the underlying kernel. Expected shape `(E,)`, dtype `torch.int64`.
            workspace (torch.Tensor): Reusable workspace for the underlying kernel.
            a_ptrs (torch.Tensor): Pointers container for calculating offsets of the input activations for each expert.
            b_ptrs (torch.Tensor): Pointers container for calculating offsets of the input weights for each expert.
            out_ptrs (torch.Tensor): Pointers container for calculating offsets of the output activations for each expert.
            a_scales_ptrs (torch.Tensor): Pointers container for calculating offsets of the input scales for each expert.
            b_scales_ptrs (torch.Tensor): Pointers container for calculating offsets of the input scales for each expert.
            use_fp8_blockscale (bool, optional): Flag indicating usage of FP8 with
            block scaling. Currently, only `True` is supported. Defaults to `True`.
            Returns:
            torch.Tensor: The computed MoE layer output. Shape: `(m, k)`, dtype matches `a`.
            Raises:
            AssertionError: If input shapes, dtypes, or flags are inconsistent or unsupported.
            NotImplementedError: If CUDA is not available or `sgl_kernel` is not properly installed.

  L 214: def cutlass_moe_fp4(a: torch.Tensor,
        a1_gscale: torch.Tensor,
        w1_fp4: torch.Tensor,
        w1_blockscale: torch.Tensor,
        w1_alphas: torch.Tensor,
        a2_gscale: torch.Tensor,
        w2_fp4: torch.Tensor,
        w2_blockscale: torch.Tensor,
        w2_alphas: torch.Tensor,
        topk_weights: torch.Tensor,
        topk_ids: torch.Tensor,
        params: CutlassMoEParams,
        apply_router_weight_on_input: bool)
         üìù MoE implementation for FP4 Inputs
            # Gemm 1
            a: Input tensor: [m, k] (half/bfloat16)
            a1_gscale: Activation scale per expert: [e]  (float32)
            w1(gate up) (not an argument to cutlass_moe_fp4): [e, 2 * n, k]
            w1_fp4: [e, 2 * n, k // 2], dtype: torch.uint8 (stacked fp4: E2M1)
            (Note: `n` is the up projection output dim, `k` is the input dim in
            full precision)
            w1_blockscale: [e, 2 * n, k // block_size] (float8_e4m3)
            (Block size = 16 for NVFP4)
            # Gemm 2
            a2_gscale: Activation scale per expert: [e]
            w2(down projection) (not an argument to cutlass_moe_fp4): [e, k, n]
            w2_fp4: [e, k, n // 2], dtype: torch.uint8 (stacked E2M1)
            w2_blockscale: [e, k, n // block_size], dtype: float8_e4m3
            Strides for activations, weights and output in logical number of elements.
            The activations & output stride is the number of elements to the next row.
            The weights stride is the number of elements to the next row per expert.
            For example, if the weight is [e, n, k], then the b_stride is a tensor of
            shape [e] with each element being k. Similarly for activations, if the
            shape is [m, k], then the a_stride has shape [e] with each value k.
            Similarly for output, if the output is [m, n], then the c_stride is a
            tensor of shape [e] with each element being k.
            Note: cutlass_fp4_group_mm is designed to accept the strides of
            activations and weights to be the same, so it is passed in as a single
            tensor.
            ab_strides_13: [e] dtype: int64 [Gemm 1: Activation / Weight strides]
            ab_strides_2: [e] dtype: int64 [Gemm 2: Activation / Weight strides]
            c_strides_13: [e] dtype: int64 [Gemm 1: Output Strides]
            c_strides_2: [e] dtype: int64 [Gemm 1: Output Strides]
            topk_weights: [m, topk] dtype: float8
            topk_ids: [m, topk] dtype: float8
            m, n, k: Unquantized weight shapes, dtype: int
            e: number of experts for the current rank, dtype: int
            assumes that topk < k < n to satisfy - up/down projection expectations.


============================================================
FILE: python/sglang/srt/layers/moe/cutlass_moe_params.py
Functions: 3
============================================================


CLASS: CutlassMoEParams
----------------------------------------
  L  90: __init__(self, cutlass_moe_type: CutlassMoEType, device: torch.device, num_experts: int, intermediate_size_per_partition: int, hidden_size: int)

  L 143: to_gemm1_args(self)
         ‚Üí dict

  L 157: to_gemm2_args(self)
         ‚Üí dict


============================================================
FILE: python/sglang/srt/layers/moe/cutlass_w4a8_moe.py
Functions: 1
============================================================

MODULE FUNCTIONS:
----------------------------------------
  L  20: def cutlass_w4a8_moe(start_expert_id: int,
        end_expert_id: int,
        total_num_experts: int,
        a: torch.Tensor,
        w1_q: torch.Tensor,
        w2_q: torch.Tensor,
        w1_scale: torch.Tensor,
        w2_scale: torch.Tensor,
        topk_weights: torch.Tensor,
        topk_ids_: torch.Tensor,
        local_topk_ids: torch.Tensor,
        a_strides1: torch.Tensor,
        b_strides1: torch.Tensor,
        c_strides1: torch.Tensor,
        a_strides2: torch.Tensor,
        b_strides2: torch.Tensor,
        c_strides2: torch.Tensor,
        s_strides13: torch.Tensor,
        s_strides2: torch.Tensor,
        expert_offsets: torch.Tensor,
        problem_sizes1: torch.Tensor,
        problem_sizes2: torch.Tensor,
        a1_scale: Optional[torch.Tensor],
        a2_scale: Optional[torch.Tensor],
        apply_router_weight_on_input: bool)
         ‚Üí torch.Tensor
         üìù This function computes a w4a8-quantized Mixture of Experts (MoE) layer
            using two sets of quantized weights, w1_q and w2_q, and top-k gating
            mechanism. The matrix multiplications are implemented with CUTLASS
            grouped gemm.
            Parameters:
            - a (torch.Tensor): The input tensor to the MoE layer.
            Shape: [M, K]
            - w1_q (torch.Tensor): The first set of int4-quantized expert weights.
            Shape: [num_experts, N * 2,  K // 2]
            (the weights are passed transposed and int4-packed)
            - w2_q (torch.Tensor): The second set of int4-quantized expert weights.
            Shape: [num_experts, K, N // 2]
            (the weights are passed transposed and int4-packed)
            - w1_scale (torch.Tensor): The fp32 scale to dequantize w1_q.
            Shape: [num_experts, K // 512, N * 8]
            - w2_scale (torch.Tensor): The fp32 scale to dequantize w2_q.
            Shape: [num_experts, N // 512, K * 4]
            - topk_weights (torch.Tensor): The weights of each token->expert mapping.
            - a_strides1 (torch.Tensor): The input strides of the first grouped gemm.
            - b_strides1 (torch.Tensor): The weights strides of the first grouped gemm.
            - c_strides1 (torch.Tensor): The output strides of the first grouped gemm.
            - a_strides2 (torch.Tensor): The input strides of the second grouped gemm.
            - b_strides2 (torch.Tensor): The weights strides of the second grouped gemm.
            - c_strides2 (torch.Tensor): The output strides of the second grouped gemm.
            - s_strides13 (torch.Tensor): The input and scale strides of the first grouped gemm.
            - s_strides2 (torch.Tensor): The scale strides of the second grouped gemm.
            - a1_scale (Optional[torch.Tensor]): The optional fp32 scale to quantize a.
            Shape: scalar or [1, K]
            - a2_scale (Optional[torch.Tensor]): The optional fp32 scale to
            quantize the intermediate result between the gemms.
            Shape: scalar or [1, N]
            - apply_router_weight_on_input (bool): When true, the topk weights are
            applied directly on the inputs. This is only applicable when topk is 1.
            Returns:
            - torch.Tensor: The fp8 output tensor after applying the MoE layer.


============================================================
FILE: python/sglang/srt/layers/moe/ep_moe/kernels.py
Functions: 30
============================================================

MODULE FUNCTIONS:
----------------------------------------
  L  23: def deepep_permute_triton_kernel(input_ptr,
        gateup_input_ptr,
        src2dst_ptr,
        topk_ids_ptr,
        a1_scales_ptr,
        topk,
        hidden_size,
        BLOCK_SIZE: tl.constexpr)
         @triton.jit

  L  54: def deepep_post_reorder_triton_kernel(down_output_ptr,
        output_ptr,
        src2dst_ptr,
        topk_ids_ptr,
        topk_weights_ptr,
        topk,
        hidden_size,
        BLOCK_SIZE: tl.constexpr)
         @triton.jit

  L  87: def compute_src2dst_triton_kernel(reorder_ids,
        src2dst,
        num_toks,
        BLOCK_SIZE: tl.constexpr)
         @triton.jit

  L  98: def deepep_compute_src2dst_triton_kernel(reorder_ids,
        src2dst,
        num_toks,
        num_minus_one,
        BLOCK_SIZE: tl.constexpr)
         @triton.jit

  L 109: def deepep_run_moe_deep_preprocess(topk_ids: torch.Tensor, num_experts: int)

  L 132: def compute_seg_indptr_triton_kernel(reorder_topk_ids, seg_indptr, num_toks)
         @triton.jit

  L 148: def run_moe_ep_preproess(topk_ids: torch.Tensor, num_experts: int)

  L 167: def run_cutlass_moe_ep_preproess(local_topk_ids: torch.Tensor,
        local_num_experts: int)

  L 187: def pre_reorder_triton_kernel_for_cutlass_moe(input_ptr,
        gateup_input_ptr,
        src2dst_ptr,
        topk_ids_ptr,
        a1_scales_ptr,
        num_experts,
        topk,
        hidden_size,
        BLOCK_SIZE: tl.constexpr)
         @triton.jit

  L 224: def pre_reorder_triton_kernel(input_ptr,
        gateup_input_ptr,
        src2dst_ptr,
        topk_ids_ptr,
        a1_scales_ptr,
        start_expert_id,
        end_expert_id,
        topk,
        hidden_size,
        BLOCK_SIZE: tl.constexpr,
        use_per_token_if_dynamic: tl.constexpr)
         @triton.jit

  L 271: def silu_and_mul_triton_kernel(gateup_output,
        down_input,
        hidden_size,
        reorder_topk_ids,
        scales,
        start_expert_id,
        end_expert_id,
        BLOCK_SIZE: tl.constexpr)
         @triton.jit

  L 395: def silu_and_mul_masked_post_quant_fwd(input: torch.Tensor,
        output: torch.Tensor,
        output_scale: torch.Tensor,
        quant_group_size: int,
        masked_m: torch.Tensor,
        scale_ue8m0: bool)
         üìù input shape [expert_num, token_num_padded, hidden_dim]
            output shape [expert_num, token_num_padded, hidden_dim // 2], dtype fp8
            output_scale [expert_num token_num_paddded, hidden_dim // 2 // 128] dtype float32
            quant_group_size  int,
            masked_m shape [expert_num],

  L 464: def tanh(x)
         @triton.jit

  L 469: def gelu_and_mul_triton_kernel(gateup_output,
        down_input,
        hidden_size,
        reorder_topk_ids,
        scales,
        start_expert_id,
        end_expert_id,
        BLOCK_SIZE: tl.constexpr)
         @triton.jit

  L 531: def post_reorder_triton_kernel(down_output_ptr,
        output_ptr,
        src2dst_ptr,
        topk_ids_ptr,
        topk_weights_ptr,
        start_expert_id,
        end_expert_id,
        topk,
        hidden_size,
        dst_start,
        BLOCK_SIZE: tl.constexpr)
         @triton.jit

  L 585: def post_reorder_triton_kernel_for_cutlass_moe(down_output_ptr,
        output_ptr,
        src2dst_ptr,
        topk_ids_ptr,
        topk_weights_ptr,
        num_experts,
        topk,
        hidden_size,
        dst_start,
        BLOCK_SIZE: tl.constexpr)
         @triton.jit

  L 628: def compute_m_range(pid,
        batch_size,
        seg_indptr,
        weight_indices,
        m_num_tiles_indptr,
        BLOCK_SIZE_M: tl.constexpr)
         @triton.jit

  L 651: def grouped_gemm_triton_kernel(a,
        b,
        c,
        batch_size,
        N,
        K,
        seg_indptr,
        weight_indices,
        m_num_tiles_indptr,
        scale_a,
        scale_b,
        use_fp8_w8a8: tl.constexpr,
        group_n: tl.constexpr,
        group_k: tl.constexpr,
        a_stride_0: tl.constexpr,
        b_stride_0: tl.constexpr,
        b_stride_1: tl.constexpr,
        as_stride_0: tl.constexpr,
        as_stride_1: tl.constexpr,
        bs_stride_0: tl.constexpr,
        bs_stride_2: tl.constexpr,
        bs_stride_1: tl.constexpr,
        use_per_token_if_dynamic: tl.constexpr,
        BLOCK_SIZE_M: tl.constexpr,
        BLOCK_SIZE_N: tl.constexpr,
        BLOCK_SIZE_K: tl.constexpr)
         @triton.jit

  L 755: def compute_m_num_tiles_indptr(m_num_tiles_indptr,
        seg_indptr,
        batch_size: tl.constexpr,
        BLOCK_SIZE_M: tl.constexpr)
         @triton.jit

  L 765: def grouped_gemm_triton(a: torch.Tensor,
        b: torch.Tensor,
        c: torch.Tensor,
        batch_size: int,
        weight_column_major: bool,
        seg_indptr: Optional[torch.Tensor],
        weight_indices: Optional[torch.Tensor],
        use_fp8_w8a8: bool,
        scale_a: torch.Tensor,
        scale_b: torch.Tensor,
        block_shape: Optional[List[int]],
        c_dtype,
        use_per_token_if_dynamic: bool)

  L 960: def ep_scatter(recv_x: torch.Tensor,
        recv_x_scale: torch.Tensor,
        recv_topk: torch.Tensor,
        num_recv_tokens_per_expert: torch.Tensor,
        expert_start_loc: torch.Tensor,
        output_tensor: torch.Tensor,
        output_tensor_scale: torch.Tensor,
        m_indices: torch.Tensor,
        output_index: torch.Tensor,
        scale_ue8m0: bool)
         @torch.no_grad()

  L1100: def ep_gather(input_tensor: torch.Tensor,
        recv_topk_ids: torch.Tensor,
        recv_topk_weight: torch.Tensor,
        input_index: torch.Tensor,
        output_tensor: torch.Tensor)
         @torch.no_grad()

  L1139: def get_tma_aligned_size(x: int, element_size: int)
         ‚Üí int
         üìù Global memory address of TMA must be 16-byte aligned.
            Since we use column-major layout for the LHS scaling tensor,
            the M-axis of the LHS scaling tensor needs to be padded to a multiple of 16 bytes.
            Arguments:
            x: original M-axis shape of the LHS scaling tensor.
            element_size: element size of the LHS scaling tensor.
            Returns:
            M-axis shape of the LHS scaling tensor after padding.

  L1189: def tma_align_input_scale(input_scale: torch.Tensor)

  L1215: def compute_masked_m_triton_kernel(seg_indptr, masked_m)
         @triton.jit

  L1223: def deepgemm_compute_src2dst_triton_kernel(topk_ids,
        reorder_ids,
        seg_indptr,
        src2dst,
        m_max,
        num_toks,
        BLOCK_SIZE: tl.constexpr)
         @triton.jit

  L1244: def fill_gateup_input_triton_kernel(input_ptr,
        scale_ptr,
        gateup_input_ptr,
        gateup_input_scale_ptr,
        src2dst_ptr,
        topk_ids_ptr,
        start_expert_id,
        end_expert_id,
        topk,
        m_max,
        hidden_size,
        scale_size,
        BLOCK_SIZE: tl.constexpr)
         @triton.jit

  L1288: def moe_ep_deepgemm_preprocess(topk_ids: torch.Tensor,
        num_experts: int,
        hidden_states: torch.Tensor,
        top_k: int,
        start_expert_id,
        end_expert_id,
        block_shape,
        output_dtype: torch.dtype)

  L1368: def compute_identity_kernel(top_k,
        hidden_states_ptr,
        expert_scales_ptr,
        num_tokens,
        output_ptr,
        hidden_dim,
        scales_stride,
        BLOCK_SIZE: tl.constexpr)
         @triton.jit

  L1406: def zero_experts_compute_triton(expert_indices,
        expert_scales,
        num_experts,
        zero_expert_type,
        hidden_states)


============================================================
FILE: python/sglang/srt/layers/moe/ep_moe/layer.py
Functions: 13
============================================================

MODULE FUNCTIONS:
----------------------------------------
  L 785: def get_moe_impl_class(quant_config: Optional[QuantizationConfig])


CLASS: DeepEPMoE
----------------------------------------
  L 339: __init__(self, num_experts: int, top_k: int, hidden_size: int, intermediate_size: int, layer_id: int, num_fused_shared_experts: int, params_dtype: Optional[torch.dtype], quant_config: Optional[QuantizationConfig], prefix: str, activation: str, routed_scaling_factor: Optional[float])

  L 421: forward(self, hidden_states: torch.Tensor, topk_idx: torch.Tensor, topk_weights: torch.Tensor, forward_batch: ForwardBatch)

  L 440: dispatch(self, hidden_states: torch.Tensor, topk_idx: torch.Tensor, topk_weights: torch.Tensor, forward_batch: ForwardBatch)

  L 454: moe_impl(self, dispatch_output: DispatchOutput)

  L 475: combine(self, hidden_states: torch.Tensor, topk_idx: torch.Tensor, topk_weights: torch.Tensor, forward_batch: ForwardBatch)

  L 489: forward_aiter(self, dispatch_output: Union[DeepEPNormalOutput, DeepEPLLOutput])

  L 523: forward_deepgemm_contiguous(self, dispatch_output: DeepEPNormalOutput)

  L 647: forward_deepgemm_masked(self, dispatch_output: DeepEPLLOutput)

  L 724: forward_npu(self, dispatch_output: DeepEPLLOutput)


CLASS: EPMoE
----------------------------------------
  L  82: __init__(self, num_experts: int, top_k: int, hidden_size: int, intermediate_size: int, layer_id: int, num_fused_shared_experts: int, params_dtype: Optional[torch.dtype], quant_config: Optional[QuantizationConfig], prefix: str, activation: str, routed_scaling_factor: Optional[float], gemm1_alpha: Optional[float], gemm1_clamp_limit: Optional[float], with_bias: bool)

  L 138: forward(self, hidden_states: torch.Tensor, topk_output: TopKOutput)

  L 144: forward_deepgemm(self, hidden_states: torch.Tensor, topk_output: TopKOutput)


============================================================
FILE: python/sglang/srt/layers/moe/fused_moe_native.py
Functions: 2
============================================================

MODULE FUNCTIONS:
----------------------------------------
  L  14: def fused_moe_forward_native(layer: torch.nn.Module,
        x: torch.Tensor,
        topk_output: StandardTopKOutput,
        moe_runner_config: MoeRunnerConfig)
         ‚Üí torch.Tensor

  L  41: def moe_forward_native(layer: torch.nn.Module,
        x: torch.Tensor,
        topk_output: StandardTopKOutput,
        moe_runner_config: MoeRunnerConfig)
         ‚Üí torch.Tensor


============================================================
FILE: python/sglang/srt/layers/moe/fused_moe_triton/__init__.py
Functions: 2
============================================================

MODULE FUNCTIONS:
----------------------------------------
  L  19: def override_config(config)
         @contextmanager

  L  27: def get_config()
         ‚Üí Optional[Dict[str, Any]]


============================================================
FILE: python/sglang/srt/layers/moe/fused_moe_triton/fused_moe.py
Functions: 20
============================================================

MODULE FUNCTIONS:
----------------------------------------
  L  72: def write_zeros_to_output(c_ptr,
        stride_cm,
        stride_cn,
        pid_n,
        N,
        offs_token,
        token_mask,
        BLOCK_SIZE_M,
        BLOCK_SIZE_N,
        compute_type)
         @triton.jit

  L  92: def fused_moe_kernel_gptq_awq(a_ptr,
        b_ptr,
        c_ptr,
        b_scale_ptr,
        b_zp_ptr,
        topk_weights_ptr,
        sorted_token_ids_ptr,
        expert_ids_ptr,
        num_tokens_post_padded_ptr,
        N: tl.constexpr,
        K: tl.constexpr,
        EM,
        num_valid_tokens,
        stride_am,
        stride_ak,
        stride_be,
        stride_bk,
        stride_bn,
        stride_cm,
        stride_cn,
        stride_bse,
        stride_bsk,
        stride_bsn,
        stride_bze,
        stride_bzk,
        stride_bzn,
        group_size: tl.constexpr,
        BLOCK_SIZE_M: tl.constexpr,
        BLOCK_SIZE_N: tl.constexpr,
        BLOCK_SIZE_K: tl.constexpr,
        GROUP_SIZE_M: tl.constexpr,
        MUL_ROUTED_WEIGHT: tl.constexpr,
        top_k: tl.constexpr,
        compute_type: tl.constexpr,
        has_zp: tl.constexpr,
        use_int4_w4a16: tl.constexpr,
        use_int8_w8a16: tl.constexpr,
        even_Ks: tl.constexpr)
         üìù Implements the fused computation for a Mixture of Experts (MOE) using
            token and expert matrices.
            Key Parameters:
            - A: The input tensor representing tokens with shape (*, K), where '*' can
            be any shape representing batches and K is the feature dimension of
            each token.
            - B: The stacked MOE weight tensor with shape (E, N, K), where E is
            the number of experts, K is the input feature dimension, and N is
            the output feature dimension.
            - C: The output cache tensor with shape (M, topk, N), where M is the
            total number of tokens post padding, topk is the number of times
            each token is repeated, and N is the output feature dimension.
            - sorted_token_ids: A tensor containing the sorted indices of tokens,
            repeated topk times and arranged by the expert index they are
            assigned to.
            - expert_ids: A tensor containing the indices of the expert for each
            block. It determines which expert matrix from B should be used for
            each block in A.
            This kernel performs the multiplication of a token by its corresponding
            expert matrix as determined by `expert_ids`. The sorting of
            `sorted_token_ids` by expert index and padding ensures divisibility by
            BLOCK_SIZE_M, which is necessary to maintain consistency in block matrix
            multiplication across different blocks processed by the same expert.
         @triton.jit

  L 323: def fused_moe_kernel(a_ptr,
        b_ptr,
        bias_ptr,
        c_ptr,
        a_scale_ptr,
        b_scale_ptr,
        topk_weights_ptr,
        sorted_token_ids_ptr,
        expert_ids_ptr,
        num_tokens_post_padded_ptr,
        N,
        K,
        EM,
        num_valid_tokens,
        stride_am,
        stride_ak,
        stride_be,
        stride_bk,
        stride_bn,
        stride_bias_e,
        stride_bias_n,
        stride_cm,
        stride_cn,
        stride_asm,
        stride_ask,
        stride_bse,
        stride_bsk,
        stride_bsn,
        group_n: tl.constexpr,
        group_k: tl.constexpr,
        BLOCK_SIZE_M: tl.constexpr,
        BLOCK_SIZE_N: tl.constexpr,
        BLOCK_SIZE_K: tl.constexpr,
        GROUP_SIZE_M: tl.constexpr,
        MUL_ROUTED_WEIGHT: tl.constexpr,
        top_k: tl.constexpr,
        compute_type: tl.constexpr,
        use_fp8_w8a8: tl.constexpr,
        use_int8_w8a8: tl.constexpr,
        use_int8_w8a16: tl.constexpr,
        per_channel_quant: tl.constexpr,
        even_Ks: tl.constexpr)
         üìù Implements the fused computation for a Mixture of Experts (MOE) using
            token and expert matrices.
            Key Parameters:
            - A: The input tensor representing tokens with shape (*, K), where '*' can
            be any shape representing batches and K is the feature dimension of
            each token.
            - B: The stacked MOE weight tensor with shape (E, N, K), where E is
            the number of experts, K is the input feature dimension, and N is
            the output feature dimension.
            - C: The output cache tensor with shape (M, topk, N), where M is the
            total number of tokens post padding, topk is the number of times
            each token is repeated, and N is the output feature dimension.
            - sorted_token_ids: A tensor containing the sorted indices of tokens,
            repeated topk times and arranged by the expert index they are
            assigned to.
            - expert_ids: A tensor containing the indices of the expert for each
            block. It determines which expert matrix from B should be used for
            each block in A.
            This kernel performs the multiplication of a token by its corresponding
            expert matrix as determined by `expert_ids`. The sorting of
            `sorted_token_ids` by expert index and padding ensures divisibility by
            BLOCK_SIZE_M, which is necessary to maintain consistency in block matrix
            multiplication across different blocks processed by the same expert.
         @triton.jit

  L 563: def moe_align_block_size(topk_ids: torch.Tensor,
        block_size: int,
        num_experts: int)
         ‚Üí Tuple[torch.Tensor, torch.Tensor, torch.Tensor]
         üìù Aligns the token distribution across experts to be compatible with block
            size for matrix multiplication.
            Parameters:
            - topk_ids: A tensor of shape [total_tokens, top_k] representing the
            top-k expert indices for each token.
            - block_size: The block size used in block matrix multiplication.
            - num_experts: The total number of experts.
            Returns:
            - sorted_token_ids: A tensor containing the sorted token indices according
            to their allocated expert.
            - expert_ids: A tensor indicating the assigned expert index for each block.
            - num_tokens_post_padded: The total number of tokens after padding,
            ensuring divisibility by block_size.
            This function pads the number of tokens that each expert needs to process
            so that it is divisible by block_size.
            Padding ensures that during block matrix multiplication, the dimensions
            align correctly.
            Example:
            Given topk_ids = [[2, 3, 4], [1, 2, 4], [1, 3, 4], [1, 2, 3]],
            block_size = 4, and num_experts = 4:
            - We initially have 12 tokens (after repeating 'top_k' times) and 4 experts,
            with each expert needing to process 3 tokens.
            - As block_size is 4, we pad 1 token for each expert.
            - First, flatten topk_ids to [2, 3, 4, 1, 2, 4, 1, 3, 4, 1, 2, 3].
            - Then append padding tokens [12, 12, 12, 12] for each block.
            - After sorting by expert index, we obtain token_ids
            [3, 6, 9, 12, 0, 4, 10, 12, 1, 7, 11, 12, 2, 5, 8, 12].
            Tokens 12 are non-existent (padding) and are ignored in
            the subsequent matrix multiplication.
            - The padding ensures that the total number of tokens is now divisible
            by block_size for proper block matrix operations.

  L 636: def invoke_fused_moe_kernel(A: torch.Tensor,
        B: torch.Tensor,
        bias: Optional[torch.Tensor],
        C: torch.Tensor,
        A_scale: Optional[torch.Tensor],
        B_scale: Optional[torch.Tensor],
        B_zp: Optional[torch.Tensor],
        topk_weights: torch.Tensor,
        topk_ids: torch.Tensor,
        sorted_token_ids: torch.Tensor,
        expert_ids: torch.Tensor,
        num_tokens_post_padded: torch.Tensor,
        mul_routed_weight: bool,
        top_k: int,
        config: Dict[str,
        Any],
        compute_type: tl.dtype,
        use_fp8_w8a8: bool,
        use_int8_w8a8: bool,
        use_int8_w8a16: bool,
        use_int4_w4a16: bool,
        per_channel_quant: bool,
        block_shape: Optional[List[int]],
        no_combine: bool)
         ‚Üí None

  L 813: def get_config_file_name(E: int,
        N: int,
        dtype: Optional[str],
        block_shape: Optional[int])
         ‚Üí str

  L 825: def get_moe_configs(E: int,
        N: int,
        dtype: Optional[str],
        block_n: Optional[int],
        block_k: Optional[int])
         ‚Üí Optional[Dict[int, Any]]
         üìù Return optimized configurations for the fused MoE kernel.
            The return value will be a dictionary that maps an irregular grid of
            batch sizes to configurations of the fused_moe kernel. To evaluate the
            kernel on a given batch size bs, the closest batch size in the grid should
            be picked and the associated configuration chosen to invoke the kernel.
         @functools.lru_cache

  L 898: def get_default_config(M: int,
        E: int,
        N: int,
        K: int,
        topk: int,
        dtype: Optional[str],
        is_marlin: bool,
        block_shape: Optional[List[int]])
         ‚Üí Dict[str, int]

  L 955: def try_get_optimal_moe_config(w1_shape: Tuple[int,
        ...],
        w2_shape: Tuple[int,
        ...],
        top_k: int,
        dtype: Optional[str],
        M: int,
        is_marlin: bool,
        block_shape: Optional[List[int]])

  L 988: def get_config_dtype_str(dtype: torch.dtype,
        use_int8_w8a16: Optional[bool],
        use_int4_w4a16: Optional[bool],
        use_fp8_w8a8: Optional[bool],
        use_int8_w8a8: Optional[bool])

  L1010: def inplace_fused_experts(hidden_states: torch.Tensor,
        w1: torch.Tensor,
        w2: torch.Tensor,
        topk_weights: torch.Tensor,
        topk_ids: torch.Tensor,
        b1: Optional[torch.Tensor],
        b2: Optional[torch.Tensor],
        activation: str,
        apply_router_weight_on_input: bool,
        use_fp8_w8a8: bool,
        use_int8_w8a8: bool,
        use_int8_w8a16: bool,
        use_int4_w4a16: bool,
        per_channel_quant: bool,
        w1_scale: Optional[torch.Tensor],
        w2_scale: Optional[torch.Tensor],
        w1_zp: Optional[torch.Tensor],
        w2_zp: Optional[torch.Tensor],
        a1_scale: Optional[torch.Tensor],
        a2_scale: Optional[torch.Tensor],
        block_shape: Optional[List[int]],
        routed_scaling_factor: Optional[float],
        gemm1_alpha: Optional[float],
        gemm1_limit: Optional[float])
         ‚Üí None

  L1066: def inplace_fused_experts_fake(hidden_states: torch.Tensor,
        w1: torch.Tensor,
        w2: torch.Tensor,
        topk_weights: torch.Tensor,
        topk_ids: torch.Tensor,
        b1: Optional[torch.Tensor],
        b2: Optional[torch.Tensor],
        activation: str,
        apply_router_weight_on_input: bool,
        use_fp8_w8a8: bool,
        use_int8_w8a8: bool,
        use_int8_w8a16: bool,
        use_int4_w4a16: bool,
        per_channel_quant: bool,
        w1_scale: Optional[torch.Tensor],
        w2_scale: Optional[torch.Tensor],
        w1_zp: Optional[torch.Tensor],
        w2_zp: Optional[torch.Tensor],
        a1_scale: Optional[torch.Tensor],
        a2_scale: Optional[torch.Tensor],
        block_shape: Optional[List[int]],
        routed_scaling_factor: Optional[float],
        gemm1_alpha: Optional[float],
        gemm1_limit: Optional[float])
         ‚Üí None

  L1103: def outplace_fused_experts(hidden_states: torch.Tensor,
        w1: torch.Tensor,
        w2: torch.Tensor,
        topk_weights: torch.Tensor,
        topk_ids: torch.Tensor,
        b1: Optional[torch.Tensor],
        b2: Optional[torch.Tensor],
        activation: str,
        apply_router_weight_on_input: bool,
        use_fp8_w8a8: bool,
        use_int8_w8a8: bool,
        use_int8_w8a16: bool,
        use_int4_w4a16: bool,
        per_channel_quant: bool,
        w1_scale: Optional[torch.Tensor],
        w2_scale: Optional[torch.Tensor],
        w1_zp: Optional[torch.Tensor],
        w2_zp: Optional[torch.Tensor],
        a1_scale: Optional[torch.Tensor],
        a2_scale: Optional[torch.Tensor],
        block_shape: Optional[List[int]],
        no_combine: bool,
        routed_scaling_factor: Optional[float],
        gemm1_alpha: Optional[float],
        gemm1_limit: Optional[float])
         ‚Üí torch.Tensor

  L1160: def outplace_fused_experts_fake(hidden_states: torch.Tensor,
        w1: torch.Tensor,
        w2: torch.Tensor,
        topk_weights: torch.Tensor,
        topk_ids: torch.Tensor,
        b1: Optional[torch.Tensor],
        b2: Optional[torch.Tensor],
        activation: str,
        apply_router_weight_on_input: bool,
        use_fp8_w8a8: bool,
        use_int8_w8a8: bool,
        use_int8_w8a16: bool,
        use_int4_w4a16: bool,
        per_channel_quant: bool,
        w1_scale: Optional[torch.Tensor],
        w2_scale: Optional[torch.Tensor],
        w1_zp: Optional[torch.Tensor],
        w2_zp: Optional[torch.Tensor],
        a1_scale: Optional[torch.Tensor],
        a2_scale: Optional[torch.Tensor],
        block_shape: Optional[List[int]],
        no_combine: bool,
        routed_scaling_factor: Optional[float],
        gemm1_alpha: Optional[float],
        gemm1_limit: Optional[float])
         ‚Üí torch.Tensor

  L1198: def fused_experts(hidden_states: torch.Tensor,
        w1: torch.Tensor,
        w2: torch.Tensor,
        topk_output: StandardTopKOutput,
        moe_runner_config: MoeRunnerConfig,
        b1: Optional[torch.Tensor],
        b2: Optional[torch.Tensor],
        use_fp8_w8a8: bool,
        use_int8_w8a8: bool,
        use_int8_w8a16: bool,
        use_int4_w4a16: bool,
        per_channel_quant: bool,
        w1_scale: Optional[torch.Tensor],
        w2_scale: Optional[torch.Tensor],
        w1_zp: Optional[torch.Tensor],
        w2_zp: Optional[torch.Tensor],
        a1_scale: Optional[torch.Tensor],
        a2_scale: Optional[torch.Tensor],
        block_shape: Optional[List[int]])

  L1329: def moe_sum_reduce_triton(input: torch.Tensor,
        output: torch.Tensor,
        routed_scaling_factor: float)

  L1366: def moe_sum_reduce_torch_compile(x, out, routed_scaling_factor)
         @torch.compile

  L1372: def swiglu_with_alpha_and_limit(x, gemm1_alpha, gemm1_limit)
         @torch.compile

  L1379: def fused_experts_impl(hidden_states: torch.Tensor,
        w1: torch.Tensor,
        w2: torch.Tensor,
        topk_weights: torch.Tensor,
        topk_ids: torch.Tensor,
        b1: Optional[torch.Tensor],
        b2: Optional[torch.Tensor],
        inplace: bool,
        activation: str,
        apply_router_weight_on_input: bool,
        use_fp8_w8a8: bool,
        use_int8_w8a8: bool,
        use_int8_w8a16: bool,
        use_int4_w4a16: bool,
        per_channel_quant: bool,
        w1_scale: Optional[torch.Tensor],
        w2_scale: Optional[torch.Tensor],
        w1_zp: Optional[torch.Tensor],
        w2_zp: Optional[torch.Tensor],
        a1_scale: Optional[torch.Tensor],
        a2_scale: Optional[torch.Tensor],
        block_shape: Optional[List[int]],
        no_combine: bool,
        routed_scaling_factor: Optional[float],
        gemm1_alpha: Optional[float],
        gemm1_limit: Optional[float])

  L1646: def fused_moe(hidden_states: torch.Tensor,
        w1: torch.Tensor,
        w2: torch.Tensor,
        topk_output: StandardTopKOutput,
        moe_runner_config: MoeRunnerConfig,
        b1: Optional[torch.Tensor],
        b2: Optional[torch.Tensor],
        use_fp8_w8a8: bool,
        use_int8_w8a8: bool,
        use_int8_w8a16: bool,
        use_int4_w4a16: bool,
        per_channel_quant: bool,
        w1_scale: Optional[torch.Tensor],
        w2_scale: Optional[torch.Tensor],
        w1_zp: Optional[torch.Tensor],
        w2_zp: Optional[torch.Tensor],
        a1_scale: Optional[torch.Tensor],
        a2_scale: Optional[torch.Tensor],
        block_shape: Optional[List[int]])
         ‚Üí torch.Tensor
         üìù This function computes a Mixture of Experts (MoE) layer using two sets of
            weights, w1 and w2, and top-k gating mechanism.
            Parameters:
            - hidden_states (torch.Tensor): The input tensor to the MoE layer.
            - w1 (torch.Tensor): The first set of expert weights.
            - w2 (torch.Tensor): The second set of expert weights.
            - topk_output (StandardTopKOutput): The top-k output of the experts.
            - moe_runner_config (MoeRunnerConfig): The configuration for the MoE runner.
            - b1 (Optional[torch.Tensor]): Optional bias for w1.
            - b2 (Optional[torch.Tensor]): Optional bias for w2.
            - use_fp8_w8a8 (bool): If True, use fp8 arithmetic to compute the inner
            products for w1 and w2. Defaults to False.
            - use_int8_w8a8 (bool): If True, use int8 arithmetic to compute the inner
            products for w1 and w2. Defaults to False.
            - use_int8_w8a16 (bool): If True, use fp8 arithmetic to compute the inner
            products for w1 and w2. Defaults to False.
            - use_int4_w4a16 (bool): If True, use matmul of int4 weight and bf16/fp16
            activation to compute the inner products for w1 and w2.
            Defaults to False.
            - w1_scale (Optional[torch.Tensor]): Optional scale to be used for
            w1.
            - w2_scale (Optional[torch.Tensor]): Optional scale to be used for
            w2.
            - a1_scale (Optional[torch.Tensor]): Optional scale to be used for
            a1.
            - a2_scale (Optional[torch.Tensor]): Optional scale to be used for
            a2.
            - block_shape: (Optional[List[int]]): Optional block size for block-wise
            quantization.
            - gemm1_alpha (Optional[float]): Optional gemm1_alpha for the activation
            function.
            - gemm1_limit (Optional[float]): Optional gemm1_limit for the swiglu activation
            function.
            Returns:
            - torch.Tensor: The output tensor after applying the MoE layer.


============================================================
FILE: python/sglang/srt/layers/moe/fused_moe_triton/layer.py
Functions: 14
============================================================

MODULE FUNCTIONS:
----------------------------------------
  L1057: def get_fused_moe_impl_class()
         üìù Factory function to get the appropriate FusedMoE implementation class.


CLASS: FlashInferFP4MoE
----------------------------------------
  L 967: __init__(self)

  L1000: forward(self, hidden_states: torch.Tensor, topk_output: TopKOutput)
         üìù Forward pass using FP4 TRTLLM kernel.
            Args:
            hidden_states: Input tensor
            topk_output: TopKOutput object with Bypassed format


CLASS: FlashInferFusedMoE
----------------------------------------
  L 931: __init__(self)

  L 935: forward(self, hidden_states: torch.Tensor, topk_output: TopKOutput)


CLASS: FusedMoE
----------------------------------------
  L 119: __init__(self, num_experts: int, hidden_size: int, intermediate_size: int, layer_id: int, top_k: Optional[int], num_fused_shared_experts: int, params_dtype: Optional[torch.dtype], reduce_results: bool, quant_config: Optional[QuantizationConfig], prefix: str, activation: str, apply_router_weight_on_input: bool, use_presharded_weights: bool, inplace: bool, no_combine: bool, routed_scaling_factor: Optional[float], gemm1_alpha: Optional[float], gemm1_clamp_limit: Optional[float], use_weight_loader_fused: bool, with_bias)

  L 459: weight_loader(self, param: torch.nn.Parameter, loaded_weight: torch.Tensor, weight_name: str, shard_id: str, expert_id: Optional[int])
         ‚Üí None

  L 716: weight_loader_fused(self, param: torch.nn.Parameter, loaded_weight: torch.Tensor, weight_name: str, shard_id: str)
         ‚Üí None

  L 794: forward(self, hidden_states: torch.Tensor, topk_output: TopKOutput)

  L 832: make_expert_params_mapping(cls, ckpt_gate_proj_name: str, ckpt_down_proj_name: str, ckpt_up_proj_name: str, num_experts: int)
         ‚Üí List[Tuple[str, str, int, str]]

  L 861: make_expert_params_mapping_fused(cls, ckpt_gate_up_proj_name: str, ckpt_down_proj_name: str, ckpt_gate_up_proj_bias_name: str, ckpt_down_proj_bias_name: str)

  L 880: make_expert_params_mapping_fused_mxfp4(cls, ckpt_gate_up_proj_name: str, ckpt_down_proj_name: str, ckpt_gate_up_proj_bias_name: str, ckpt_down_proj_bias_name: str, ckpt_gate_up_proj_scale_name: str, ckpt_down_proj_scale_name: str)

  L 907: make_expert_input_scale_params_mapping(cls, num_experts: int)
         ‚Üí List[Tuple[str, str, int, str]]

  L 923: should_fuse_routed_scaling_factor_in_topk(self)


============================================================
FILE: python/sglang/srt/layers/moe/fused_moe_triton/triton_kernels_moe.py
Functions: 5
============================================================

MODULE FUNCTIONS:
----------------------------------------
  L  25: def quantize(w, dtype, dev)

  L  54: def triton_kernel_moe_forward(hidden_states: torch.Tensor,
        w1: torch.Tensor,
        w2: torch.Tensor,
        topk_output: TopKOutput,
        moe_runner_config: MoeRunnerConfig,
        apply_router_weight_on_input: bool,
        use_fp8_w8a8: bool,
        per_channel_quant: bool,
        global_num_experts: int,
        expert_map: Optional[torch.Tensor],
        w1_scale: Optional[torch.Tensor],
        w2_scale: Optional[torch.Tensor],
        a1_scale: Optional[torch.Tensor],
        a2_scale: Optional[torch.Tensor],
        block_shape: Optional[list[int]])
         ‚Üí torch.Tensor

  L 101: def triton_kernel_fused_experts(hidden_states: torch.Tensor,
        w1: torch.Tensor,
        w2: torch.Tensor,
        routing_data: RoutingData,
        gather_indx: GatherIndx,
        scatter_indx: ScatterIndx,
        inplace: bool,
        activation: str,
        apply_router_weight_on_input: bool,
        use_fp8_w8a8: bool,
        per_channel_quant: bool,
        global_num_experts: int,
        expert_map: Optional[torch.Tensor],
        w1_scale: Optional[torch.Tensor],
        w2_scale: Optional[torch.Tensor],
        a1_scale: Optional[torch.Tensor],
        a2_scale: Optional[torch.Tensor],
        block_shape: Optional[list[int]])
         ‚Üí torch.Tensor

  L 189: def triton_kernel_moe_with_bias_forward(hidden_states: torch.Tensor,
        w1: torch.Tensor,
        w1_pcg,
        b1: torch.Tensor,
        w2: torch.Tensor,
        w2_pcg,
        b2: torch.Tensor,
        topk_output: TopKOutput,
        moe_runner_config: MoeRunnerConfig,
        use_fp8_w8a8: bool,
        per_channel_quant: bool,
        global_num_experts: int,
        expert_map: Optional[torch.Tensor],
        w1_scale: Optional[torch.Tensor],
        w2_scale: Optional[torch.Tensor],
        a1_scale: Optional[torch.Tensor],
        a2_scale: Optional[torch.Tensor],
        block_shape: Optional[list[int]])
         ‚Üí torch.Tensor

  L 242: def triton_kernel_fused_experts_with_bias(hidden_states: torch.Tensor,
        w1: torch.Tensor,
        w1_pcg,
        b1: torch.Tensor,
        w2: torch.Tensor,
        w2_pcg,
        b2: torch.Tensor,
        routing_data: RoutingData,
        gather_indx: GatherIndx,
        scatter_indx: ScatterIndx,
        inplace: bool,
        activation: str,
        use_fp8_w8a8: bool,
        per_channel_quant: bool,
        global_num_experts: int,
        expert_map: Optional[torch.Tensor],
        w1_scale: Optional[torch.Tensor],
        w2_scale: Optional[torch.Tensor],
        a1_scale: Optional[torch.Tensor],
        a2_scale: Optional[torch.Tensor],
        block_shape: Optional[list[int]],
        gemm1_alpha: Optional[float],
        gemm1_clamp_limit: Optional[float])
         ‚Üí torch.Tensor


============================================================
FILE: python/sglang/srt/layers/moe/rocm_moe_utils.py
Functions: 3
============================================================

MODULE FUNCTIONS:
----------------------------------------
  L  23: def rocm_aiter_asm_moe_tkw1_impl(hidden_states: torch.Tensor,
        w1: torch.Tensor,
        w2: torch.Tensor,
        topk_weights: torch.Tensor,
        topk_ids: torch.Tensor,
        fc1_scale: Optional[torch.Tensor],
        fc2_scale: Optional[torch.Tensor],
        fc1_smooth_scale: Optional[torch.Tensor],
        fc2_smooth_scale: Optional[torch.Tensor],
        a16: bool,
        per_tensor_quant_scale: Optional[torch.Tensor],
        expert_mask: Optional[torch.Tensor],
        activation_method: int)
         ‚Üí torch.Tensor

  L  61: def rocm_aiter_asm_moe_tkw1_fake(hidden_states: torch.Tensor,
        w1: torch.Tensor,
        w2: torch.Tensor,
        topk_weights: torch.Tensor,
        topk_ids: torch.Tensor,
        fc1_scale: Optional[torch.Tensor],
        fc2_scale: Optional[torch.Tensor],
        fc1_smooth_scale: Optional[torch.Tensor],
        fc2_smooth_scale: Optional[torch.Tensor],
        a16: bool,
        per_tensor_quant_scale: Optional[torch.Tensor],
        expert_mask: Optional[torch.Tensor],
        activation_method: int)
         ‚Üí torch.Tensor

  L  89: def rocm_fused_experts_tkw1(hidden_states: torch.Tensor,
        w1: torch.Tensor,
        w2: torch.Tensor,
        topk_weights: torch.Tensor,
        topk_ids: torch.Tensor,
        activation: str,
        apply_router_weight_on_input: bool,
        use_fp8_w8a8: bool,
        per_channel_quant: bool,
        w1_scale: Optional[torch.Tensor],
        w2_scale: Optional[torch.Tensor],
        a1_scale: Optional[torch.Tensor],
        a2_scale: Optional[torch.Tensor],
        block_shape: Optional[list[int]])
         ‚Üí torch.Tensor


============================================================
FILE: python/sglang/srt/layers/moe/router.py
Functions: 10
============================================================

MODULE FUNCTIONS:
----------------------------------------
  L  14: def fused_moe_router_kernel(input_ptr,
        moe_router_weight_ptr,
        topk_weights_ptr,
        topk_ids_ptr,
        correction_bias_ptr,
        is_correction_bias: tl.constexpr,
        num_experts: tl.constexpr,
        topk: tl.constexpr,
        moe_softcapping: tl.constexpr,
        moe_renormalize: tl.constexpr,
        hidden_dim: tl.constexpr,
        BLOCK_SIZE: tl.constexpr)
         @triton.jit

  L 117: def fused_moe_router_impl(x: torch.Tensor,
        router_weight: torch.Tensor,
        topk: int,
        moe_softcapping: float,
        correction_bias: Optional[torch.Tensor])

  L 160: def fused_moe_router_large_bs_kernel(a_ptr,
        b_ptr,
        topk_weights_ptr,
        topk_ids_ptr,
        bs,
        num_experts: tl.constexpr,
        topk: tl.constexpr,
        moe_softcapping: tl.constexpr,
        moe_renormalize: tl.constexpr,
        K: tl.constexpr,
        BLOCK_SIZE_M: tl.constexpr,
        BLOCK_SIZE_N: tl.constexpr,
        BLOCK_SIZE_K: tl.constexpr,
        stride_am: tl.constexpr,
        stride_bn: tl.constexpr)
         @triton.jit

  L 269: def fused_moe_router_large_bs_impl(x: torch.Tensor,
        router_weight: torch.Tensor,
        topk: int,
        moe_softcapping: float,
        BLOCK_SIZE_M: int,
        BLOCK_SIZE_N: int,
        BLOCK_SIZE_K: int)

  L 312: def fused_moe_router_shim(moe_softcapping,
        hidden_states,
        gating_output,
        topk,
        renormalize,
        correction_bias: Optional[torch.Tensor])


CLASS: FusedMoeRouter
----------------------------------------
  L 356: __init__(self, router_linear, topk, moe_softcapping)
         ‚Üí None

  L 361: __call__(self)

  L 364: forward(self, x: torch.Tensor, residual: torch.Tensor)
         ‚Üí Tuple[torch.Tensor, torch.Tensor]

  L 372: forward_cuda(self, x: torch.Tensor, autotune)
         ‚Üí Tuple[torch.Tensor, torch.Tensor]

  L 383: forward_vllm(self, x: torch.Tensor)
         ‚Üí Tuple[torch.Tensor, torch.Tensor]


============================================================
FILE: python/sglang/srt/layers/moe/token_dispatcher/base_dispatcher.py
Functions: 13
============================================================


CLASS: BaseDispatcher
----------------------------------------
  L  95: dispatch(self)
         ‚Üí DispatchOutput

  L  99: combine(self)
         ‚Üí torch.Tensor


CLASS: DispatchOutput
----------------------------------------
  L  82: format(self)
         ‚Üí DispatchOutputFormat


CLASS: DispatchOutputChecker
----------------------------------------
  L  21: format_is_standard(dispatch_output: DispatchOutput)
         ‚Üí TypeGuard[StandardDispatchOutput]

  L  27: format_is_deepep_normal(dispatch_output: DispatchOutput)
         ‚Üí TypeGuard[DeepEPNormalOutput]

  L  33: format_is_deepep_ll(dispatch_output: DispatchOutput)
         ‚Üí TypeGuard[DeepEPLLOutput]

  L  39: format_is_deepep(dispatch_output: DispatchOutput)
         ‚Üí TypeGuard[Union[DeepEPNormalOutput, DeepEPLLOutput]]

  L  45: format_is_ascent_ll(dispatch_output: DispatchOutput)
         ‚Üí TypeGuard[AscendDeepEPLLOutput]


CLASS: DispatchOutputFormat
----------------------------------------
  L  58: is_standard(self)
         ‚Üí bool

  L  61: is_deepep_normal(self)
         ‚Üí bool

  L  64: is_deepep_ll(self)
         ‚Üí bool

  L  67: is_deepep(self)
         ‚Üí bool

  L  73: is_ascent_ll(self)
         ‚Üí bool


============================================================
FILE: python/sglang/srt/layers/moe/token_dispatcher/deepep.py
Functions: 31
============================================================


CLASS: AscendDeepEPLLOutput
----------------------------------------
  L  93: format(self)
         ‚Üí DispatchOutputFormat


CLASS: DeepEPBuffer
----------------------------------------
  L 115: get_deepep_buffer(cls, group: dist.ProcessGroup, hidden_size: int, param_bytes: int, deepep_mode: DeepEPMode, num_max_dispatch_tokens_per_rank: int, num_experts: int)

  L 195: clean_buffer(cls)

  L 205: set_dispatch_mode_as_normal(cls)

  L 209: set_dispatch_mode_as_low_latency(cls)


CLASS: DeepEPConfig
----------------------------------------
  L 218: __init__(self)

  L 238: get_instance(cls)


CLASS: DeepEPDispatcher
----------------------------------------
  L 625: __init__(self, group: torch.distributed.ProcessGroup, router_topk: int, permute_fusion: bool, num_experts: int, num_local_experts: int, hidden_size: int, params_dtype: torch.dtype, deepep_mode: DeepEPMode, async_finish: bool, return_recv_hook: bool)

  L 664: dispatch(self)
         ‚Üí DispatchOutput

  L 669: dispatch_a(self, hidden_states: torch.Tensor, topk_idx: torch.Tensor, topk_weights: torch.Tensor, forward_batch: ForwardBatch)

  L 684: dispatch_b(self)

  L 690: combine(self)
         ‚Üí Tuple

  L 695: combine_a(self, hidden_states: torch.Tensor, topk_idx: torch.Tensor, topk_weights: torch.Tensor, forward_batch: ForwardBatch)

  L 710: combine_b(self)


CLASS: DeepEPLLOutput
----------------------------------------
  L  78: format(self)
         ‚Üí DispatchOutputFormat


CLASS: DeepEPNormalOutput
----------------------------------------
  L  64: format(self)
         ‚Üí DispatchOutputFormat


CLASS: _DeepEPDispatcherImplBase
----------------------------------------
  L 245: __init__(self, group: torch.distributed.ProcessGroup, router_topk: int, permute_fusion: bool, num_experts: int, num_local_experts: int, hidden_size: int, params_dtype: torch.dtype, deepep_mode: DeepEPMode)

  L 278: dispatch_a(self, hidden_states: torch.Tensor, topk_idx: torch.Tensor, topk_weights: torch.Tensor)

  L 286: dispatch_b(self)

  L 289: combine_a(self, hidden_states: torch.Tensor, topk_idx: torch.Tensor, topk_weights: torch.Tensor)

  L 297: combine_b(self)


CLASS: _DeepEPDispatcherImplLowLatency
----------------------------------------
  L 474: __init__(self, return_recv_hook: bool)

  L 483: dispatch_a(self, hidden_states: torch.Tensor, topk_idx: torch.Tensor, topk_weights: torch.Tensor)

  L 510: dispatch_b(self, hidden_states, topk_idx, topk_weights, masked_m, expected_m, event, hook)

  L 569: combine_a(self, hidden_states: torch.Tensor, topk_idx: torch.Tensor, topk_weights: torch.Tensor)

  L 582: combine_b(self, hidden_states, event, hook)


CLASS: _DeepEPDispatcherImplNormal
----------------------------------------
  L 305: __init__(self, async_finish: bool)

  L 311: dispatch_a(self, hidden_states: torch.Tensor, topk_idx: torch.Tensor, topk_weights: torch.Tensor)

  L 330: dispatch_b(self, hidden_states, topk_idx, topk_weights, previous_event)

  L 406: combine_a(self, hidden_states: torch.Tensor, topk_idx: torch.Tensor, topk_weights: torch.Tensor)

  L 441: combine_b(self, output, previous_event)


============================================================
FILE: python/sglang/srt/layers/moe/token_dispatcher/standard.py
Functions: 1
============================================================


CLASS: StandardDispatchOutput
----------------------------------------
  L  15: format(self)
         ‚Üí DispatchOutputFormat


============================================================
FILE: python/sglang/srt/layers/moe/topk.py
Functions: 27
============================================================

MODULE FUNCTIONS:
----------------------------------------
  L 355: def fused_topk_torch_native(hidden_states: torch.Tensor,
        gating_output: torch.Tensor,
        topk: int,
        renormalize: bool,
        correction_bias: torch.Tensor)

  L 387: def fused_topk_cpu(hidden_states: torch.Tensor,
        gating_output: torch.Tensor,
        topk: int,
        renormalize: bool,
        num_token_non_padded: Optional[torch.Tensor],
        expert_location_dispatch_info: Optional[ExpertLocationDispatchInfo],
        correction_bias: torch.Tensor)

  L 407: def apply_topk_weights_cpu(need_apply, topk_weights, inputs)

  L 420: def fused_topk(hidden_states: torch.Tensor,
        gating_output: torch.Tensor,
        topk: int,
        renormalize: bool,
        num_token_non_padded: Optional[torch.Tensor],
        expert_location_dispatch_info: Optional[ExpertLocationDispatchInfo])

  L 451: def grouped_topk_gpu(hidden_states: torch.Tensor,
        gating_output: torch.Tensor,
        topk: int,
        renormalize: bool,
        num_expert_group: Optional[int],
        topk_group: Optional[int],
        num_fused_shared_experts: int,
        routed_scaling_factor: Optional[float],
        num_token_non_padded: Optional[torch.Tensor],
        expert_location_dispatch_info: Optional[ExpertLocationDispatchInfo],
        apply_routed_scaling_factor_on_output: Optional[bool])
         @torch.compile(dynamic=True, backend=get_compiler_backend())

  L 519: def grouped_topk_cpu(hidden_states: torch.Tensor,
        gating_output: torch.Tensor,
        topk: int,
        renormalize: bool,
        num_expert_group: Optional[int],
        topk_group: Optional[int],
        num_fused_shared_experts: int,
        routed_scaling_factor: Optional[float],
        num_token_non_padded: Optional[torch.Tensor],
        expert_location_dispatch_info: Optional[ExpertLocationDispatchInfo],
        apply_routed_scaling_factor_on_output: Optional[bool])

  L 548: def biased_grouped_topk_impl(hidden_states: torch.Tensor,
        gating_output: torch.Tensor,
        correction_bias: torch.Tensor,
        topk: int,
        renormalize: bool,
        num_expert_group: Optional[int],
        topk_group: Optional[int],
        num_fused_shared_experts: int,
        routed_scaling_factor: Optional[float],
        num_token_non_padded: Optional[torch.Tensor],
        expert_location_dispatch_info: Optional[ExpertLocationDispatchInfo],
        apply_routed_scaling_factor_on_output: Optional[bool])
         @torch.compile(dynamic=True, backend=get_compiler_backend(), disable=_is_npu)

  L 621: def is_power_of_two(n)

  L 644: def biased_grouped_topk_gpu(hidden_states: torch.Tensor,
        gating_output: torch.Tensor,
        correction_bias: torch.Tensor,
        topk: int,
        renormalize: bool,
        num_expert_group: Optional[int],
        topk_group: Optional[int],
        num_fused_shared_experts: int,
        routed_scaling_factor: Optional[float],
        num_token_non_padded: Optional[torch.Tensor],
        expert_location_dispatch_info: Optional[ExpertLocationDispatchInfo],
        apply_routed_scaling_factor_on_output: Optional[bool])

  L 723: def biased_grouped_topk_cpu(hidden_states: torch.Tensor,
        gating_output: torch.Tensor,
        correction_bias: torch.Tensor,
        topk: int,
        renormalize: bool,
        num_expert_group: Optional[int],
        topk_group: Optional[int],
        compiled: bool,
        num_fused_shared_experts: int,
        routed_scaling_factor: Optional[float],
        num_token_non_padded: Optional[torch.Tensor],
        expert_location_dispatch_info: Optional[ExpertLocationDispatchInfo],
        apply_routed_scaling_factor_on_output: Optional[bool])

  L 765: def select_experts(hidden_states: torch.Tensor,
        router_logits: torch.Tensor,
        topk_config: TopKConfig)
         ‚Üí StandardTopKOutput


CLASS: BypassedTopKOutput
----------------------------------------
  L 178: format(self)
         ‚Üí TopKOutputFormat


CLASS: StandardTopKOutput
----------------------------------------
  L 152: format(self)
         ‚Üí TopKOutputFormat


CLASS: TopK
----------------------------------------
  L 187: __init__(self, top_k: int)

  L 226: forward_native(self, hidden_states: torch.Tensor, router_logits: torch.Tensor)
         ‚Üí TopKOutput

  L 243: forward_cuda(self, hidden_states: torch.Tensor, router_logits: torch.Tensor)
         ‚Üí TopKOutput

  L 280: forward_cpu(self, hidden_states: torch.Tensor, router_logits: torch.Tensor)
         ‚Üí TopKOutput

  L 296: forward_npu(self, hidden_states: torch.Tensor, router_logits: torch.Tensor)
         ‚Üí TopKOutput

  L 344: empty_topk_output(self, device: torch.device)
         ‚Üí TopKOutput


CLASS: TopKOutput
----------------------------------------
  L 139: format(self)
         ‚Üí TopKOutputFormat
         üìù The format of the output.


CLASS: TopKOutputChecker
----------------------------------------
  L 105: format_is_standard(topk_output: TopKOutput)
         ‚Üí TypeGuard[StandardTopKOutput]

  L 109: format_is_triton_kernel(topk_output: TopKOutput)
         ‚Üí TypeGuard[TritonKernelTopKOutput]

  L 115: format_is_bypassed(topk_output: TopKOutput)
         ‚Üí TypeGuard[BypassedTopKOutput]


CLASS: TopKOutputFormat
----------------------------------------
  L 124: is_standard(self)
         ‚Üí bool

  L 127: is_triton_kernel(self)
         ‚Üí bool

  L 130: is_bypassed(self)
         ‚Üí bool


CLASS: TritonKernelTopKOutput
----------------------------------------
  L 164: format(self)
         ‚Üí TopKOutputFormat


============================================================
FILE: python/sglang/srt/layers/moe/utils.py
Functions: 23
============================================================

MODULE FUNCTIONS:
----------------------------------------
  L 110: def initialize_moe_config(server_args: ServerArgs)

  L 130: def get_moe_a2a_backend()
         ‚Üí MoeA2ABackend

  L 138: def get_moe_runner_backend()
         ‚Üí MoeRunnerBackend

  L 146: def get_deepep_mode()
         ‚Üí DeepEPMode

  L 154: def get_deepep_config()
         ‚Üí str

  L 162: def is_tbo_enabled()
         ‚Üí bool

  L 170: def get_tbo_token_distribution_threshold()
         ‚Üí float

  L 181: def should_use_flashinfer_trtllm_moe()
         @lru_cache(maxsize=1)

  L 191: def should_use_flashinfer_cutlass_moe_fp4_allgather()
         üìù Perform FP4 quantize before all-gather for flashinfer cutlass moe to reduce communication cost for high-throughput serving.
         @lru_cache(maxsize=1)


CLASS: DeepEPMode
----------------------------------------
  L  76: enable_normal(self)
         ‚Üí bool

  L  79: enable_low_latency(self)
         ‚Üí bool

  L  82: resolve(self, is_extend_in_batch: bool)
         ‚Üí DeepEPMode

  L  91: is_normal(self)
         ‚Üí bool

  L  94: is_low_latency(self)
         ‚Üí bool

  L  97: is_auto(self)
         ‚Üí bool


CLASS: MoeA2ABackend
----------------------------------------
  L  35: is_none(self)

  L  38: is_deepep(self)


CLASS: MoeRunnerBackend
----------------------------------------
  L  51: is_auto(self)

  L  54: is_triton(self)

  L  57: is_triton_kernel(self)

  L  60: is_flashinfer_trtllm(self)

  L  63: is_flashinfer_cutlass(self)

  L  66: is_flashinfer_mxfp4(self)


============================================================
FILE: python/sglang/srt/layers/multimodal.py
Functions: 3
============================================================

MODULE FUNCTIONS:
----------------------------------------
  L  44: def hash_tiles32_kernel_blocked(in_ptr,
        out_ptr,
        n_u32,
        seed1,
        seed2,
        FM_C1: tl.constexpr,
        FM_C2: tl.constexpr,
        POS_A: tl.constexpr,
        POS_B: tl.constexpr,
        TILE: tl.constexpr,
        BLOCK: tl.constexpr,
        USE_CG: tl.constexpr)
         @triton.jit

  L 108: def add_tree_reduce_u64_kernel(in_ptr, out_ptr, n_elems, CHUNK: tl.constexpr)
         @triton.jit

  L 145: def gpu_tensor_hash(tensor: torch.Tensor)
         ‚Üí int
         @torch.inference_mode()


============================================================
FILE: python/sglang/srt/layers/parameter.py
Functions: 31
============================================================

MODULE FUNCTIONS:
----------------------------------------
  L 460: def permute_param_layout_(param: BasevLLMParameter,
        input_dim: int,
        output_dim: int)
         ‚Üí BasevLLMParameter
         üìù Permute a parameter's layout to the specified input and output dimensions,
            useful for forcing the parameter into a known layout, for example, if I need
            a packed (quantized) weight matrix to be in the layout
            {input_dim = 0, output_dim = 1, packed_dim = 0}
            then I can call:
            permute_param_layout_(x, input_dim=0, output_dim=1, packed_dim=0)
            to ensure x is in the correct layout (permuting it to the correct layout if
            required, asserting if it cannot get it to the correct layout)


CLASS: BasevLLMParameter
----------------------------------------
  L  36: __new__(cls, data: torch.Tensor)

  L  40: __init__(self, data: torch.Tensor, weight_loader: Callable)
         üìù Initialize the BasevLLMParameter
            :param data: torch tensor with the parameter data
            :param weight_loader: weight loader callable
            :returns: a torch.nn.parameter

  L  53: weight_loader(self)

  L  60: load_column_parallel_weight(self, loaded_weight: torch.Tensor)

  L  63: load_row_parallel_weight(self, loaded_weight: torch.Tensor)

  L  66: load_merged_column_weight(self, loaded_weight: torch.Tensor)

  L  69: load_qkv_weight(self, loaded_weight: torch.Tensor)


CLASS: PackedColumnParameter
----------------------------------------
  L 383: __init__(self, packed_factor: Union[int, Fraction], packed_dim: int, marlin_tile_size: Optional[int])

  L 396: packed_dim(self)

  L 400: packed_factor(self)

  L 404: marlin_tile_size(self)

  L 407: adjust_shard_indexes_for_packing(self, shard_size, shard_offset)


CLASS: PackedvLLMParameter
----------------------------------------
  L 427: __init__(self, packed_factor: Union[int, Fraction], packed_dim: int, marlin_tile_size: Optional[int])

  L 440: packed_dim(self)

  L 444: packed_factor(self)

  L 448: marlin_tile_size(self)

  L 451: adjust_shard_indexes_for_packing(self, shard_size, shard_offset)


CLASS: PerTensorScaleParameter
----------------------------------------
  L 322: __init__(self)

  L 338: load_row_parallel_weight(self)

  L 343: load_merged_column_weight(self)

  L 346: load_qkv_weight(self)

  L 349: load_column_parallel_weight(self)


CLASS: RowvLLMParameter
----------------------------------------
  L 225: __init__(self, input_dim: int)

  L 230: input_dim(self)

  L 233: load_row_parallel_weight(self, loaded_weight: torch.Tensor, tp_rank: int, use_presharded_weights: bool)


CLASS: _ColumnvLLMParameter
----------------------------------------
  L  84: __init__(self, output_dim: int)

  L  89: output_dim(self)

  L  92: load_column_parallel_weight(self, loaded_weight: torch.Tensor, tp_rank: int, use_presharded_weights: bool)

  L 125: load_merged_column_weight(self, loaded_weight: torch.Tensor)

  L 166: load_qkv_weight(self, loaded_weight: torch.Tensor, tp_rank: int, use_presharded_weights: bool)


============================================================
FILE: python/sglang/srt/layers/pooler.py
Functions: 4
============================================================


CLASS: CrossEncodingPooler
----------------------------------------
  L  71: __init__(self, config: PretrainedConfig, classifier: nn.Module, pooler: Optional[nn.Module])

  L  82: forward(self, hidden_states: torch.Tensor, forward_batch: ForwardBatch)
         ‚Üí EmbeddingPoolerOutput
         üìù Pools sentence pair scores from the hidden_states.


CLASS: Pooler
----------------------------------------
  L  37: __init__(self, pooling_type: PoolingType, normalize: bool)

  L  42: forward(self, hidden_states: torch.Tensor, forward_batch: ForwardBatch)
         ‚Üí EmbeddingPoolerOutput


============================================================
FILE: python/sglang/srt/layers/quantization/__init__.py
Functions: 5
============================================================

MODULE FUNCTIONS:
----------------------------------------
  L 124: def get_quantization_config(quantization: str)
         ‚Üí Type[QuantizationConfig]

  L 143: def monkey_patch_isinstance_for_vllm_base_layer(reverse: bool)
         üìù Patch isinstance so that the `get_quant_method` in vllm's QuantizationConfig
            can recognize sglang layers

  L 179: def monkey_patch_moe_apply(class_obj: 'FusedMoEMethodBase')
         üìù Monkey patch the apply function of vllm's FusedMoEMethodBase.
            Convert sglang arguments to vllm arguments.

  L 215: def monkey_patch_quant_configs()
         üìù Apply all monkey patches in one place.


CLASS: DummyConfig
----------------------------------------
  L  34: override_quantization_method(self)


============================================================
FILE: python/sglang/srt/layers/quantization/awq.py
Functions: 33
============================================================

MODULE FUNCTIONS:
----------------------------------------
  L  67: def is_layer_skipped_awq(prefix: str, modules_to_not_convert: List[str])


CLASS: AWQConfig
----------------------------------------
  L  77: __init__(self, weight_bits: int, group_size: int, zero_point: bool, modules_to_not_convert: Optional[List[str]])
         ‚Üí None

  L  97: __repr__(self)
         ‚Üí str

  L 105: get_scaled_act_names(self)
         ‚Üí List[str]

  L 108: get_name(self)
         ‚Üí str

  L 111: get_supported_act_dtypes(self)
         ‚Üí List[torch.dtype]

  L 115: get_min_capability(cls)
         ‚Üí int

  L 120: get_config_filenames()
         ‚Üí List[str]

  L 128: from_config(cls, config: Dict[str, Any])
         ‚Üí AWQConfig

  L 137: get_quant_method(self, layer: torch.nn.Module, prefix: str)
         ‚Üí Optional[LinearMethodBase]


CLASS: AWQLinearMethod
----------------------------------------
  L 326: __init__(self, quant_config: AWQConfig)

  L 329: create_weights(self, layer: torch.nn.Module, input_size_per_partition: int, output_partition_sizes: List[int], input_size: int, output_size: int, params_dtype: torch.dtype)

  L 396: process_weights_after_loading(self, layer: torch.nn.Module)
         ‚Üí None

  L 401: apply(self, layer: torch.nn.Module, x: torch.Tensor, bias: Optional[torch.Tensor])
         ‚Üí torch.Tensor


CLASS: AWQMarlinConfig
----------------------------------------
  L 158: __init__(self, weight_bits: int, group_size: int, zero_point: bool, lm_head_quantized: bool, modules_to_not_convert: Optional[list[str]], full_config: dict[str, Any])
         ‚Üí None

  L 188: __repr__(self)
         ‚Üí str

  L 197: get_scaled_act_names(self)
         ‚Üí List[str]

  L 201: get_name(cls)
         ‚Üí str

  L 205: get_supported_act_dtypes(cls)
         ‚Üí list[torch.dtype]

  L 209: get_min_capability(cls)
         ‚Üí int

  L 213: get_config_filenames(cls)
         ‚Üí list[str]

  L 217: from_config(cls, config: dict[str, Any])
         ‚Üí AWQMarlinConfig

  L 235: override_quantization_method(cls, hf_quant_cfg, user_quant)
         ‚Üí Optional[str]

  L 258: get_quant_method(self, layer: torch.nn.Module, prefix: str)
         ‚Üí Optional[QuantizeMethodBase]

  L 294: is_awq_marlin_compatible(cls, quant_config: dict[str, Any])


CLASS: AWQMarlinLinearMethod
----------------------------------------
  L 428: __init__(self, quant_config: AWQMarlinConfig)
         ‚Üí None

  L 431: create_weights(self, layer: torch.nn.Module, input_size_per_partition: int, output_partition_sizes: list[int], input_size: int, output_size: int, params_dtype: torch.dtype)
         ‚Üí None

  L 509: process_weights_after_loading(self, layer: torch.nn.Module)
         ‚Üí None

  L 549: apply(self, layer: torch.nn.Module, x: torch.Tensor, bias: Optional[torch.Tensor])
         ‚Üí torch.Tensor


CLASS: AWQMoEMethod
----------------------------------------
  L 572: __init__(self, quant_config: AWQMarlinConfig)

  L 578: create_weights(self, layer: torch.nn.Module, num_experts: int, hidden_size: int, intermediate_size_per_partition: int, params_dtype: torch.dtype)

  L 674: process_weights_after_loading(self, layer: torch.nn.Module)
         ‚Üí None

  L 739: apply(self, layer: torch.nn.Module, x: torch.Tensor, topk_output: StandardTopKOutput, moe_runner_config: MoeRunnerConfig)
         ‚Üí torch.Tensor


============================================================
FILE: python/sglang/srt/layers/quantization/awq_triton.py
Functions: 4
============================================================

MODULE FUNCTIONS:
----------------------------------------
  L  14: def awq_dequantize_kernel(qweight_ptr,
        scales_ptr,
        zeros_ptr,
        group_size,
        result_ptr,
        num_cols,
        num_rows,
        BLOCK_SIZE_X: tl.constexpr,
        BLOCK_SIZE_Y: tl.constexpr)
         @triton.jit

  L 111: def awq_gemm_kernel(a_ptr,
        b_ptr,
        c_ptr,
        zeros_ptr,
        scales_ptr,
        M,
        N,
        K,
        group_size,
        BLOCK_SIZE_M: tl.constexpr,
        BLOCK_SIZE_N: tl.constexpr,
        BLOCK_SIZE_K: tl.constexpr,
        SPLIT_K: tl.constexpr)
         @triton.jit

  L 235: def awq_dequantize_triton(qweight: torch.Tensor,
        scales: torch.Tensor,
        zeros: torch.Tensor,
        block_size_x: int,
        block_size_y: int)
         ‚Üí torch.Tensor

  L 289: def awq_gemm_triton(input: torch.Tensor,
        qweight: torch.Tensor,
        scales: torch.Tensor,
        qzeros: torch.Tensor,
        split_k_iters: int,
        block_size_m: int,
        block_size_n: int,
        block_size_k: int)
         ‚Üí torch.Tensor


============================================================
FILE: python/sglang/srt/layers/quantization/base_config.py
Functions: 19
============================================================

MODULE FUNCTIONS:
----------------------------------------
  L 202: def method_has_implemented_embedding(method_class: Type[QuantizeMethodBase])
         ‚Üí bool
         üìù Not all quant methods have embedding implemented, so we need to check that
            it exists for our given method. We check this by making sure the function
            has been changed from the base implementation.


CLASS: FusedMoEMethodBase
----------------------------------------
  L  87: create_weights(self, layer: torch.nn.Module, num_experts: int, hidden_size: int, intermediate_size: int, params_dtype: torch.dtype)

  L  99: apply(self, layer: torch.nn.Module, x: torch.Tensor, topk_output: TopKOutput, moe_runner_config: MoeRunnerConfig)
         ‚Üí torch.Tensor


CLASS: LinearMethodBase
----------------------------------------
  L  47: create_weights(self, layer: torch.nn.Module, input_size_per_partition: int, output_partition_sizes: List[int], input_size: int, output_size: int, params_dtype: torch.dtype)
         üìù Create weights for a linear layer.
            The weights will be set as attributes of the layer.
            Args:
            layer: The layer that is using the LinearMethodBase factory.
            input_size_per_partition: Size of the weight input dim on rank X.
            output_partition_sizes: Sizes of the output dim of each logical
            weight on rank X. E.g., output_partition_sizes for QKVLinear
            is a list contains the width of Wq, Wk, Wv on rank X.
            input_size: Size of the input dim of the weight across all ranks.
            output_size: Size of the output dim of the weight across all ranks.
            params_dtype: Datatype of the parameters.

  L  73: apply(self, layer: torch.nn.Module, x: torch.Tensor, bias: Optional[torch.Tensor])
         ‚Üí torch.Tensor
         üìù Apply the weights in layer to the input tensor.
            Expects create_weights to have been called before on the layer.


CLASS: QuantizationConfig
----------------------------------------
  L 112: __init__(self)

  L 118: get_name(self)
         ‚Üí str
         üìù Name of the quantization method.

  L 123: get_supported_act_dtypes(self)
         ‚Üí List[torch.dtype]
         üìù List of supported activation dtypes.

  L 129: get_min_capability(cls)
         ‚Üí int
         üìù Minimum GPU capability to support the quantization method.
            E.g., 70 for Volta, 75 for Turing, 80 for Ampere.
            This requirement is due to the custom CUDA kernels used by the
            quantization method.

  L 140: get_config_filenames()
         ‚Üí List[str]
         üìù List of filenames to search for in the model directory.

  L 146: from_config(cls, config: Dict[str, Any])
         ‚Üí 'QuantizationConfig'
         üìù Create a config class from the model's quantization config.

  L 151: override_quantization_method(cls, hf_quant_cfg, user_quant)
         ‚Üí Optional[str]
         üìù Detects if this quantization method can support a given checkpoint
            format by overriding the user specified quantization method --
            this method should only be overwritten by subclasses in exceptional
            circumstances

  L 161: get_from_keys(config: Dict[str, Any], keys: List[str])
         ‚Üí Any
         üìù Get a value from the model's quantization config.

  L 171: get_from_keys_or(config: Dict[str, Any], keys: List[str], default: Any)
         ‚Üí Any
         üìù Get a optional value from the model's quantization config.

  L 179: get_quant_method(self, layer: torch.nn.Module, prefix: str)
         ‚Üí Optional[QuantizeMethodBase]
         üìù Get the quantize method to use for the quantized layer.
            Args:
            layer: The layer for the quant method.
            prefix: The full name of the layer in the state dict
            Returns:
            The quantize method. None if the given layer doesn't support quant
            method.

  L 194: get_scaled_act_names(self)
         ‚Üí List[str]
         üìù Returns the activation function names that should be post-scaled.
            For now, this is only used by AWQ.


CLASS: QuantizeMethodBase
----------------------------------------
  L  20: create_weights(self, layer: torch.nn.Module)
         üìù Create weights for a layer.
            The weights will be set as attributes of the layer.

  L  29: apply(self, layer: torch.nn.Module)
         ‚Üí torch.Tensor
         üìù Apply the weights in layer to the input tensor.
            Expects create_weights to have been called before on the layer.

  L  35: process_weights_after_loading(self, layer: nn.Module)
         ‚Üí None
         üìù Process the weight after loading.
            This can be used for example, to transpose weights for computation.


============================================================
FILE: python/sglang/srt/layers/quantization/blockwise_int8.py
Functions: 16
============================================================


CLASS: BlockInt8Config
----------------------------------------
  L  36: __init__(self, is_checkpoint_int8_serialized: bool, activation_scheme: str, ignored_layers: Optional[List[str]], weight_block_size: List[int])
         ‚Üí None

  L  69: get_name(cls)
         ‚Üí str

  L  73: get_supported_act_dtypes(cls)
         ‚Üí List[torch.dtype]

  L  77: get_min_capability(cls)
         ‚Üí int

  L  81: get_config_filenames(cls)
         ‚Üí List[str]

  L  85: from_config(cls, config: Dict[str, Any])
         ‚Üí BlockInt8Config

  L  98: get_quant_method(self, layer: torch.nn.Module, prefix: str)
         ‚Üí Optional[QuantizeMethodBase]

  L 112: get_scaled_act_names(self)
         ‚Üí List[str]


CLASS: BlockInt8LinearMethod
----------------------------------------
  L 128: __init__(self, quant_config: BlockInt8Config)

  L 133: create_weights(self, layer: torch.nn.Module, input_size_per_partition: int, output_partition_sizes: List[int], input_size: int, output_size: int, params_dtype: torch.dtype)

  L 214: process_weights_after_loading(self, layer: Module)
         ‚Üí None

  L 222: apply(self, layer: torch.nn.Module, x: torch.Tensor, bias: Optional[torch.Tensor])
         ‚Üí torch.Tensor


CLASS: BlockInt8MoEMethod
----------------------------------------
  L 250: __init__(self, quant_config: BlockInt8Config)

  L 255: create_weights(self, layer: Module, num_experts: int, hidden_size: int, intermediate_size: int, params_dtype: torch.dtype)

  L 343: process_weights_after_loading(self, layer: Module)
         ‚Üí None

  L 347: apply(self, layer: torch.nn.Module, x: torch.Tensor, topk_output: TopKOutput, moe_runner_config: MoeRunnerConfig)
         ‚Üí torch.Tensor


============================================================
FILE: python/sglang/srt/layers/quantization/compressed_tensors/compressed_tensors.py
Functions: 18
============================================================


CLASS: CompressedTensorsConfig
----------------------------------------
  L  79: __init__(self, target_scheme_map: Dict[str, Any], ignore: List[str], quant_format: str, sparsity_scheme_map: Dict[str, SparsityCompressionConfig], sparsity_ignore_list: List[str], kv_cache_scheme: Optional[Dict[str, Any]], config: Optional[Dict[str, Any]], packed_modules_mapping: Dict[str, List[str]])

  L 101: get_linear_method(self)
         ‚Üí CompressedTensorsLinearMethod

  L 104: get_supported_act_dtypes(cls)
         ‚Üí List[torch.dtype]

  L 108: get_min_capability(cls)
         ‚Üí int

  L 111: get_name(self)
         ‚Üí str

  L 114: get_scaled_act_names(self)
         ‚Üí List[str]

  L 117: get_quant_method(self, layer: torch.nn.Module, prefix: str)
         ‚Üí Optional[QuantizeMethodBase]

  L 143: from_config(cls, config: Dict[str, Any])
         ‚Üí CompressedTensorsConfig

  L 234: get_config_filenames(cls)
         ‚Üí List[str]

  L 438: get_scheme(self, layer: torch.nn.Module, layer_name: Optional[str])
         ‚Üí Optional[CompressedTensorsScheme]
         üìù compressed-tensors supports non uniform in the following way:
            targets of config_groups: There can be N config_groups which each
            have a quantization scheme. Each config_group has a list of targets
            which can be a full layer_name, a regex for a layer_name, or
            an nn.Module name.
            Detect whether a layer_name is found in any target and
            use the quantization scheme corresponding to the matched target
            to select the CompressedTensorsScheme used for infernece.

  L 533: get_cache_scale(self, name: str)
         ‚Üí Optional[str]
         üìù Check whether the param name matches the format for k/v cache scales
            in compressed-tensors. If this is the case, return its equivalent
            param name expected by vLLM
            :param name: param name
            :return: matching param name for KV cache scale in vLLM

  L 550: supports_cutlass_24(weight_quant: Optional[QuantizationArgs], input_quant: Optional[QuantizationArgs], sparsity_scheme: Optional[SparsityCompressionConfig])
         ‚Üí bool
         üìù Check if the layer is supported by the Cutlass 2:4 Kernel
            Conditions:
            - Overarching condition: Sparsity Structure is 2:4
            - Unquantized cases are supported
            - Weight only quantization is not-supported
            - Supported weight quantization strategies are TENSOR and CHANNEL
            - Supported input quantization strategies are TENSOR and TOKEN
            - Only 8 bit quantization is supported
            :return: True if the layer is supported by the Cutlass 2:4 Kernel
            False otherwise


CLASS: CompressedTensorsLinearMethod
----------------------------------------
  L 618: __init__(self, quantization_config: CompressedTensorsConfig)

  L 621: process_weights_after_loading(self, layer: torch.nn.Module)
         ‚Üí None

  L 624: create_weights(self, layer: torch.nn.Module, input_size_per_partition: int, output_partition_sizes: List[int], input_size: int, output_size: int, params_dtype: torch.dtype)
         üìù Use the CompressedTensorsScheme associated with each layer to create
            the necessary parameters for the layer. See LinearMethodBase for param
            details

  L 650: apply(self, layer: torch.nn.Module, x: torch.Tensor, bias: Optional[torch.Tensor])
         üìù Use the output of create_weights and the CompressedTensorsScheme
            associated with the layer to apply the forward pass with the
            layer input.  See LinearMethodBase for param details


CLASS: DeviceCapability
----------------------------------------
  L  64: as_version_str(self)
         ‚Üí str

  L  67: to_int(self)
         ‚Üí int
         üìù Express device capability as an integer ``<major><minor>``.
            It is assumed that the minor version is always a single digit.


============================================================
FILE: python/sglang/srt/layers/quantization/compressed_tensors/compressed_tensors_moe.py
Functions: 10
============================================================


CLASS: CompressedTensorsMoEMethod
----------------------------------------
  L  70: __new__(cls)

  L  76: get_moe_method(quant_config: CompressedTensorsConfig)
         ‚Üí 'CompressedTensorsMoEMethod'


CLASS: CompressedTensorsW8A8Fp8MoEMethod
----------------------------------------
  L 100: __init__(self, quant_config: CompressedTensorsConfig)

  L 109: create_weights(self, layer: torch.nn.Module, num_experts: int, hidden_size: int, intermediate_size_per_partition: int, params_dtype: torch.dtype)

  L 207: process_weights_after_loading(self, layer: FusedMoE)
         ‚Üí None

  L 296: apply(self, layer: torch.nn.Module, x: torch.Tensor, topk_output: TopKOutput, moe_runner_config: MoeRunnerConfig)
         ‚Üí torch.Tensor


CLASS: CompressedTensorsWNA16MoEMethod
----------------------------------------
  L 346: __init__(self, quant_config: CompressedTensorsConfig)

  L 369: create_weights(self, layer: torch.nn.Module, num_experts: int, hidden_size: int, intermediate_size_per_partition: int, params_dtype: torch.dtype)

  L 513: process_weights_after_loading(self, layer: torch.nn.Module)
         ‚Üí None

  L 643: apply(self, layer: torch.nn.Module, x: torch.Tensor, topk_output: TopKOutput, moe_runner_config: MoeRunnerConfig)
         ‚Üí torch.Tensor


============================================================
FILE: python/sglang/srt/layers/quantization/compressed_tensors/schemes/compressed_tensors_scheme.py
Functions: 4
============================================================


CLASS: CompressedTensorsScheme
----------------------------------------
  L  20: get_min_capability(cls)
         ‚Üí int
         üìù Get minimum device capability.

  L  27: create_weights(self)
         üìù Weight creation for the particular scheme. Inputs to this function

  L  35: apply_weights(self, layer: torch.nn.Module, x: torch.Tensor, bias: Optional[torch.Tensor])
         üìù Run the forward pass for the particular scheme. This is where
            scheme-specific dequant/quant steps/kernels should be applied.
            :param layer: torch.nn.Module with the registered weights and
            other parameters relevant to the particular scheme.
            :param x: input to the layer
            :param bias: bias parameter

  L  51: process_weights_after_loading(self, layer: torch.nn.Module)
         üìù Called after weight loading is complete for any cleanup that
            needs to occur.


============================================================
FILE: python/sglang/srt/layers/quantization/compressed_tensors/schemes/compressed_tensors_w8a16_fp8.py
Functions: 7
============================================================

MODULE FUNCTIONS:
----------------------------------------
  L  29: def apply_fp8_marlin_linear()

  L  32: def prepare_fp8_layer_for_marlin()


CLASS: CompressedTensorsW8A16Fp8
----------------------------------------
  L  42: __init__(self, strategy: str, is_static_input_scheme: bool)

  L  52: get_min_capability(cls)
         ‚Üí int

  L  59: process_weights_after_loading(self, layer)
         ‚Üí None

  L  81: create_weights(self, layer: torch.nn.Module, input_size: int, output_partition_sizes: List[int], input_size_per_partition: int, params_dtype: torch.dtype, weight_loader: Callable)

  L 139: apply_weights(self, layer: torch.nn.Module, x: torch.Tensor, bias: Optional[torch.Tensor])
         ‚Üí torch.Tensor


============================================================
FILE: python/sglang/srt/layers/quantization/compressed_tensors/schemes/compressed_tensors_w8a8_fp8.py
Functions: 5
============================================================


CLASS: CompressedTensorsW8A8Fp8
----------------------------------------
  L  30: __init__(self, strategy: str, is_static_input_scheme: bool)

  L  35: get_min_capability(cls)
         ‚Üí int

  L  39: process_weights_after_loading(self, layer)
         ‚Üí None

  L  92: create_weights(self, layer: torch.nn.Module, output_partition_sizes: List[int], input_size_per_partition: int, params_dtype: torch.dtype, weight_loader: Callable)

  L 146: apply_weights(self, layer: torch.nn.Module, x: torch.Tensor, bias: Optional[torch.Tensor])
         ‚Üí torch.Tensor


============================================================
FILE: python/sglang/srt/layers/quantization/compressed_tensors/utils.py
Functions: 4
============================================================

MODULE FUNCTIONS:
----------------------------------------
  L  12: def is_activation_quantization_format(format: str)
         ‚Üí bool

  L  21: def should_ignore_layer(layer_name: Optional[str],
        ignore: Iterable[str],
        fused_mapping: Mapping[str,
        List[str]])
         ‚Üí bool

  L  76: def check_equal_or_regex_match(layer_name: str, targets: Iterable[str])
         ‚Üí bool
         üìù Checks whether a layer_name is exactly equal or a regex match for
            if target starts with 're:' to any target in list.

  L  87: def find_matched_target(layer_name: Optional[str],
        module: Module,
        targets: Iterable[str],
        fused_mapping: Mapping[str,
        List[str]])
         ‚Üí str
         üìù Helper function to look up which "target" in the compressed-tensors
            config that a layer corresponds to.
            Recall that a compressed-tensors configs has a concept of
            config_groups, where each layer can be quantized with with a different
            scheme.
            targets in each config_group will be a list of either layer names
            (or regexes corresponding to layer names) or names of torch Modules.
            First, we try to match the layer_name with a target
            Second, we try to match the module's name with a target
            Third, we try to map the layer_name to a list of fused module names.
            *All* component module names must match in order for a match to be
            successful. A successful match returns the first component target
            :param layer_name: layer name
            :param module: torch.nn.Module
            :param targets: list of targets to match the layer against
            :param fused_mapping: map from fused layer names to its components
            :param fused_strategy: either "all" or "any". If using "all", fused
            layers match if "all" of its components match


============================================================
FILE: python/sglang/srt/layers/quantization/deep_gemm_wrapper/compile_utils.py
Functions: 10
============================================================

MODULE FUNCTIONS:
----------------------------------------
  L  42: def update_deep_gemm_config(gpu_id: int, server_args: ServerArgs)

  L 229: def deep_gemm_execution_hook(m: int,
        n: int,
        k: int,
        num_groups: int,
        kernel_type: DeepGemmKernelType)
         @contextmanager


CLASS: _BaseWarmupExecutor
----------------------------------------
  L 142: create(kernel_type: DeepGemmKernelType)

  L 149: execute(self, m)


CLASS: _GroupedContWarmupExecutor
----------------------------------------
  L 193: __init__(self, max_m: int, n: int, k: int, num_groups: int)

  L 199: execute(self, m)


CLASS: _GroupedMaskedWarmupExecutor
----------------------------------------
  L 209: __init__(self, max_m: int, n: int, k: int, num_groups: int)

  L 217: execute(self, m)


CLASS: _NormalWarmupExecutor
----------------------------------------
  L 179: __init__(self, max_m: int, n: int, k: int, num_groups: int)

  L 184: execute(self, m)


============================================================
FILE: python/sglang/srt/layers/quantization/deep_gemm_wrapper/entrypoint.py
Functions: 5
============================================================

MODULE FUNCTIONS:
----------------------------------------
  L  23: def grouped_gemm_nt_f8f8bf16_masked(lhs: Tuple[torch.Tensor,
        torch.Tensor],
        rhs: Tuple[torch.Tensor,
        torch.Tensor],
        out: torch.Tensor,
        masked_m: torch.Tensor,
        expected_m: int)

  L  46: def grouped_gemm_nt_f8f8bf16_contig(lhs: Tuple[torch.Tensor,
        torch.Tensor],
        rhs: Tuple[torch.Tensor,
        torch.Tensor],
        out: torch.Tensor,
        m_indices: torch.Tensor)

  L  60: def gemm_nt_f8f8bf16(lhs: Tuple[torch.Tensor,
        torch.Tensor],
        rhs: Tuple[torch.Tensor,
        torch.Tensor],
        out: torch.Tensor)

  L  78: def update_deep_gemm_config(gpu_id: int, server_args: ServerArgs)

  L  83: def configure_deep_gemm_num_sms(num_sms)
         @contextmanager


============================================================
FILE: python/sglang/srt/layers/quantization/fp8.py
Functions: 23
============================================================

MODULE FUNCTIONS:
----------------------------------------
  L  23: def dummy_func()

  L 491: def get_tile_tokens_dim(num_tokens, top_k, num_experts)


CLASS: Fp8Config
----------------------------------------
  L 113: __init__(self, is_checkpoint_fp8_serialized: bool, activation_scheme: str, ignored_layers: Optional[List[str]], weight_block_size: List[int])
         ‚Üí None

  L 143: get_name(cls)
         ‚Üí str

  L 147: get_supported_act_dtypes(cls)
         ‚Üí List[torch.dtype]

  L 151: get_min_capability(cls)
         ‚Üí int

  L 155: get_config_filenames(cls)
         ‚Üí List[str]

  L 159: from_config(cls, config: Dict[str, Any])
         ‚Üí Fp8Config

  L 172: get_quant_method(self, layer: torch.nn.Module, prefix: str)
         ‚Üí Optional[QuantizeMethodBase]

  L 186: get_scaled_act_names(self)
         ‚Üí List[str]


CLASS: Fp8KVCacheMethod
----------------------------------------
  L1210: __init__(self, quant_config: Fp8Config)


CLASS: Fp8LinearMethod
----------------------------------------
  L 208: __init__(self, quant_config: Union[Fp8Config, W4AFp8Config])

  L 224: create_weights(self, layer: torch.nn.Module, input_size_per_partition: int, output_partition_sizes: List[int], input_size: int, output_size: int, params_dtype: torch.dtype)

  L 332: process_weights_after_loading(self, layer: Module)
         ‚Üí None

  L 442: apply(self, layer: torch.nn.Module, x: torch.Tensor, bias: Optional[torch.Tensor])
         ‚Üí torch.Tensor


CLASS: Fp8MoEMethod
----------------------------------------
  L 514: __init__(self, quant_config: Fp8Config)

  L 525: create_weights(self, layer: Module, num_experts: int, hidden_size: int, intermediate_size: int, params_dtype: torch.dtype)

  L 749: process_weights_after_loading(self, layer: Module)
         ‚Üí None

  L 911: process_weights_hip_int4(self, layer: Module)

  L 954: process_weights_hip_scale_padding(self, layer: Module)

  L 987: apply(self, layer: torch.nn.Module, x: torch.Tensor, topk_output: TopKOutput, moe_runner_config: MoeRunnerConfig)
         ‚Üí torch.Tensor

  L1082: apply_with_router_logits(self, layer: torch.nn.Module, x: torch.Tensor, topk_output: TopKOutput, moe_runner_config: MoeRunnerConfig)
         ‚Üí torch.Tensor

  L1141: maybe_apply_hip_fused_experts(self, layer: torch.nn.Module, x: torch.Tensor, topk_output: TopKOutput, activation: str, no_combine: bool)
         ‚Üí Optional[torch.Tensor]


============================================================
FILE: python/sglang/srt/layers/quantization/fp8_kernel.py
Functions: 26
============================================================

MODULE FUNCTIONS:
----------------------------------------
  L  72: def is_fp8_fnuz()
         ‚Üí bool
         @lru_cache()

  L  89: def deep_gemm_fp8_fp8_bf16_nt(A: torch.Tensor,
        As: torch.Tensor,
        B: torch.Tensor,
        Bs: torch.Tensor,
        C: torch.Tensor)
         ‚Üí None

  L  98: def deep_gemm_fp8_fp8_bf16_nt_fake(A: torch.Tensor,
        As: torch.Tensor,
        B: torch.Tensor,
        Bs: torch.Tensor,
        C: torch.Tensor)
         ‚Üí None

  L 394: def per_token_group_quant_8bit(x: torch.Tensor,
        group_size: int,
        dst_dtype: torch.dtype,
        eps: float,
        column_major_scales: bool,
        scale_tma_aligned: bool,
        scale_ue8m0: bool,
        fuse_silu_and_mul: bool,
        masked_m: Optional[torch.Tensor])
         ‚Üí Tuple[torch.Tensor, torch.Tensor]

  L 427: def create_per_token_group_quant_fp8_output_scale(x_shape,
        device,
        group_size,
        column_major_scales: bool,
        scale_tma_aligned: bool,
        scale_ue8m0: bool)

  L 471: def sglang_per_token_group_quant_fp8(x: torch.Tensor,
        group_size: int,
        eps: float,
        column_major_scales: bool,
        scale_tma_aligned: bool,
        scale_ue8m0: bool,
        fuse_silu_and_mul: bool,
        masked_m: Optional[torch.Tensor])

  L 507: def sglang_per_token_group_quant_8bit(x: torch.Tensor,
        group_size: int,
        dst_dtype: torch.dtype,
        eps: float,
        column_major_scales: bool,
        scale_tma_aligned: bool,
        scale_ue8m0: bool,
        fuse_silu_and_mul: bool,
        masked_m: Optional[torch.Tensor])

  L 546: def sglang_per_token_quant_fp8(x: torch.Tensor, dtype: torch.dtype)

  L 608: def static_quant_fp8(x: torch.Tensor, x_s: torch.Tensor, repeat_scale: bool)
         ‚Üí Tuple[torch.Tensor, torch.Tensor]
         üìù Function to perform static quantization using the given scale on an input tensor `x`.
            It converts the tensor values into signed float8 values and returns the
            quantized tensor along with the scaling factor used for quantization.
            Args:
            x: The input tenosr with ndim >= 2.
            x_s: The quantization scale.
            repeat_scale: Whether to broadcast per-tensor scale to per-channel scale.
            dtype: The dype of output tensor.
            Returns:
            Tuple[torch.Tensor, torch.Tensor]: The quantized tensor and the scaling factor for quantization.

  L 909: def get_w8a8_block_fp8_configs(N: int, K: int, block_n: int, block_k: int)
         ‚Üí Optional[Dict[int, Any]]
         üìù Return optimized configurations for the w8a8 block fp8 kernel.
            The return value will be a dictionary that maps an irregular grid of
            batch sizes to configurations of the w8a8 block fp8 kernel. To evaluate the
            kernel on a given batch size bs, the closest batch size in the grid should
            be picked and the associated configuration chosen to invoke the kernel.
         @functools.lru_cache

  L 950: def select_w8a8_block_fp8_matmul_kernel(M, N, META)

  L 956: def use_w8a8_block_fp8_matmul_unrolledx4(M, N, META)

  L 965: def select_w8a8_block_fp8_matmul_kernel(M, N, META)

  L 972: def prepare_block_fp8_matmul_inputs(A: torch.Tensor,
        B: torch.Tensor,
        As: torch.Tensor,
        Bs: torch.Tensor,
        block_size: List[int],
        output_dtype: torch.dtype)
         ‚Üí Tuple[int, int, int]

  L1020: def w8a8_block_fp8_matmul_deepgemm(A: torch.Tensor,
        B: torch.Tensor,
        As: torch.Tensor,
        Bs: torch.Tensor,
        block_size: List[int],
        output_dtype: torch.dtype)
         ‚Üí torch.Tensor

  L1041: def w8a8_block_fp8_matmul_triton(A: torch.Tensor,
        B: torch.Tensor,
        As: torch.Tensor,
        Bs: torch.Tensor,
        block_size: List[int],
        output_dtype: torch.dtype)
         ‚Üí torch.Tensor
         üìù This function performs matrix multiplication with block-wise quantization.
            It takes two input tensors `A` and `B` with scales `As` and `Bs`.
            The output is returned in the specified `output_dtype`.
            Args:
            A: The input tensor, e.g., activation.
            B: The input tensor, e.g., weight.
            As: The per-token-group quantization scale for `A`.
            Bs: The per-block quantization scale for `B`.
            block_size: The block size for per-block quantization. It should be 2-dim, e.g., [128, 128].
            output_dytpe: The dtype of the returned tensor.
            Returns:
            torch.Tensor: The result of matmul.

  L1122: def w8a8_block_fp8_matmul(A: torch.Tensor,
        B: torch.Tensor,
        As: torch.Tensor,
        Bs: torch.Tensor,
        block_size: List[int],
        output_dtype: torch.dtype)
         ‚Üí torch.Tensor

  L1192: def per_tensor_quant_mla_fp8(x: torch.Tensor, x_s_out: torch.Tensor, eps: float)
         ‚Üí Tuple[torch.Tensor, torch.Tensor]
         üìù This function quantizes input values to float8 values with tensor-wise quantization
            and specialized for mla absorbed case.

  L1288: def per_token_group_quant_mla_deep_gemm_masked_fp8(x: torch.Tensor,
        group_size: int,
        eps: float,
        dtype: torch.dtype)
         ‚Üí Tuple[torch.Tensor, torch.Tensor]
         üìù This function quantizes input values to float8 values with per-token-group-quantization
            for deep_gemm grouped_gemm_masked and specialized for mla absorbed case.

  L1358: def scaled_fp8_quant(input: torch.Tensor,
        scale: Optional[torch.Tensor],
        num_token_padding: Optional[int],
        use_per_token_if_dynamic: bool)
         ‚Üí tuple[torch.Tensor, torch.Tensor]

  L1402: def scaled_fp8_quant(input: torch.Tensor,
        scale: Optional[torch.Tensor],
        num_token_padding: Optional[int],
        use_per_token_if_dynamic: bool)
         ‚Üí tuple[torch.Tensor, torch.Tensor]

  L1500: def per_token_group_quant_fp8_hopper_moe_mn_major(A: torch.Tensor,
        expert_offsets: torch.Tensor,
        problem_sizes: torch.Tensor,
        group_size: int,
        expert_tokens_alignment: int)
         ‚Üí Tuple[torch.Tensor, torch.Tensor]

  L1568: def per_group_transpose(a: torch.Tensor,
        expert_offsets: torch.Tensor,
        M_ALIGNMENT: int)
         ‚Üí torch.Tensor

  L1591: def is_weak_contiguous(x: torch.Tensor)

  L1600: def scaled_mm_kernel(a_ptr,
        b_ptr,
        scale_a_ptr,
        scale_b_ptr,
        c_ptr,
        bias_ptr,
        M,
        N,
        K,
        stride_am,
        stride_ak,
        stride_bk,
        stride_bn,
        stride_cm,
        stride_cn,
        ACCUMULATOR_DTYPE: tl.constexpr,
        BLOCK_SIZE_M: tl.constexpr,
        BLOCK_SIZE_N: tl.constexpr,
        BLOCK_SIZE_K: tl.constexpr,
        BLOCK_SIZE_SCALE_A: tl.constexpr,
        BLOCK_SIZE_SCALE_B: tl.constexpr)
         @triton.jit

  L1723: def triton_scaled_mm(input: torch.Tensor,
        weight: torch.Tensor,
        scale_a: torch.Tensor,
        scale_b: torch.Tensor,
        out_dtype: type[torch.dtype],
        bias: Optional[torch.Tensor],
        block_size_m: int,
        block_size_n: int,
        block_size_k: int,
        use_heuristic)
         ‚Üí torch.Tensor


============================================================
FILE: python/sglang/srt/layers/quantization/fp8_utils.py
Functions: 20
============================================================

MODULE FUNCTIONS:
----------------------------------------
  L  63: def use_rowwise_torch_scaled_mm()

  L  81: def cutlass_fp8_supported()

  L  93: def normalize_e4m3fn_to_e4m3fnuz(weight: torch.Tensor,
        weight_scale: torch.Tensor,
        input_scale: Optional[torch.Tensor])
         ‚Üí Tuple[torch.Tensor, torch.Tensor, Optional[torch.Tensor]]

  L 118: def cutlass_block_fp8_supported()
         ‚Üí bool

  L 140: def dispatch_w8a8_block_fp8_linear()
         ‚Üí Callable

  L 153: def flashinfer_gemm_w8a8_block_fp8_linear(input: torch.Tensor,
        weight: torch.Tensor,
        block_size: List[int],
        weight_scale: torch.Tensor,
        input_scale: Optional[torch.Tensor],
        bias: Optional[torch.Tensor])
         ‚Üí torch.Tensor

  L 185: def cutlass_w8a8_block_fp8_linear_with_fallback(input: torch.Tensor,
        weight: torch.Tensor,
        block_size: List[int],
        weight_scale: torch.Tensor,
        input_scale: Optional[torch.Tensor],
        bias: Optional[torch.Tensor])
         ‚Üí torch.Tensor

  L 218: def deepgemm_w8a8_block_fp8_linear_with_fallback(input: torch.Tensor,
        weight: torch.Tensor,
        block_size: List[int],
        weight_scale: torch.Tensor,
        input_scale: Optional[torch.Tensor],
        bias: Optional[torch.Tensor])
         ‚Üí torch.Tensor

  L 269: def aiter_w8a8_block_fp8_linear(input: torch.Tensor,
        weight: torch.Tensor,
        block_size: List[int],
        weight_scale: torch.Tensor,
        input_scale: Optional[torch.Tensor],
        bias: Optional[torch.Tensor])
         ‚Üí torch.Tensor

  L 292: def triton_w8a8_block_fp8_linear(input: torch.Tensor,
        weight: torch.Tensor,
        block_size: List[int],
        weight_scale: torch.Tensor,
        input_scale: Optional[torch.Tensor],
        bias: Optional[torch.Tensor])
         ‚Üí torch.Tensor

  L 315: def dequant_mxfp4(w_block: torch.Tensor, w_scale: torch.Tensor, out_dtype)
         ‚Üí torch.Tensor
         üìù :param w_block: (batch, n, k, 16), uint8, pack two mxfp4 into one byte
            :param w_scale: (batch, n, k), uint8
            :return: (batch, n, k * 32), float32

  L 342: def input_to_float8(x: torch.Tensor, dtype: torch.dtype)
         ‚Üí Tuple[torch.Tensor, torch.Tensor]
         üìù This function quantizes input values to float8 values with tensor-wise quantization.

  L 361: def block_quant_to_tensor_quant(x_q_block: torch.Tensor,
        x_s: torch.Tensor,
        block_size: List[int])
         ‚Üí Tuple[torch.Tensor, torch.Tensor]
         üìù This function converts block-wise quantization to tensor-wise quantization.
            The inputs are block-wise quantization tensor `x_q_block`, block-wise quantization scale
            and the block size.
            The outputs are tensor-wise quantization tensor and tensor-wise quantization scale.
            Note only float8 is supported for now.

  L 404: def block_quant_dequant(x_q_block: torch.Tensor,
        x_s: torch.Tensor,
        block_size: List[int],
        dtype: torch.dtype)
         ‚Üí torch.Tensor
         üìù This function converts block-wise quantization to unquantized.
            The inputs are block-wise quantization tensor `x_q_block`, block-wise quantization scale
            and the block size.
            The output is an unquantized tensor with dtype.

  L 427: def requant_weight_ue8m0_inplace(weight, weight_scale_inv, weight_block_size)

  L 471: def per_block_cast_to_fp8(x: torch.Tensor)
         ‚Üí Tuple[torch.Tensor, torch.Tensor]

  L 488: def ceil_to_ue8m0(x: torch.Tensor)

  L 492: def channel_quant_to_tensor_quant(x_q_channel: torch.Tensor, x_s: torch.Tensor)
         ‚Üí Tuple[torch.Tensor, torch.Tensor]

  L 542: def apply_fp8_linear(input: torch.Tensor,
        weight: torch.Tensor,
        weight_scale: torch.Tensor,
        input_scale: Optional[torch.Tensor],
        input_scale_ub: Optional[torch.Tensor],
        bias: Optional[torch.Tensor],
        cutlass_fp8_supported: bool,
        use_per_token_if_dynamic: bool,
        pad_output: Optional[bool],
        compressed_tensor_quant: bool)
         ‚Üí torch.Tensor

  L 809: def can_auto_enable_marlin_fp8()
         ‚Üí bool


============================================================
FILE: python/sglang/srt/layers/quantization/fpgemm_fp8.py
Functions: 12
============================================================


CLASS: FBGEMMFp8Config
----------------------------------------
  L  43: __init__(self, ignore_list: list[str], input_scale_ub: float)

  L  58: get_name(cls)
         ‚Üí str

  L  62: get_supported_act_dtypes(cls)
         ‚Üí list[torch.dtype]

  L  66: get_min_capability(cls)
         ‚Üí int

  L  70: get_config_filenames(cls)
         ‚Üí list[str]

  L  74: from_config(cls, config: dict[str, Any])
         ‚Üí FBGEMMFp8Config

  L  79: get_quant_method(self, layer: torch.nn.Module, prefix: str)
         ‚Üí Optional[QuantizeMethodBase]

  L  92: get_scaled_act_names(self)
         ‚Üí List[str]


CLASS: FBGEMMFp8LinearMethod
----------------------------------------
  L  98: __init__(self, quant_config: FBGEMMFp8Config)

  L 105: create_weights(self, layer: torch.nn.Module, input_size_per_partition: int, output_partition_sizes: list[int], input_size: int, output_size: int, params_dtype: torch.dtype)

  L 155: process_weights_after_loading(self, layer: Module)
         ‚Üí None

  L 176: apply(self, layer: torch.nn.Module, x: torch.Tensor, bias: Optional[torch.Tensor])
         ‚Üí torch.Tensor


============================================================
FILE: python/sglang/srt/layers/quantization/gptq.py
Functions: 34
============================================================

MODULE FUNCTIONS:
----------------------------------------
  L  62: def check_marlin_format(hf_quant_cfg: Dict[str, Any])
         ‚Üí bool

  L  70: def gptq_marlin_moe_repack(b_q_weight: torch.Tensor,
        perm: torch.Tensor,
        size_k: int,
        size_n: int,
        num_bits: int)
         ‚Üí torch.Tensor


CLASS: GPTQConfig
----------------------------------------
  L 106: __init__(self, weight_bits: int, group_size: int, desc_act: bool, lm_head_quantized: bool, dynamic: Dict[str, Dict[str, Union[int, bool]]])
         ‚Üí None

  L 151: __repr__(self)
         ‚Üí str

  L 160: get_scaled_act_names(self)
         ‚Üí List[str]
         üìù Returns the activation function names that should be post-scaled.
            For now, this is only used by AWQ.

  L 168: get_name(cls)
         ‚Üí str

  L 172: get_supported_act_dtypes(cls)
         ‚Üí List[torch.dtype]

  L 177: get_min_capability(cls)
         ‚Üí int

  L 181: get_config_filenames(cls)
         ‚Üí List[str]

  L 185: from_config(cls, config: Dict[str, Any])
         ‚Üí GPTQConfig

  L 195: get_quant_method(self, layer: torch.nn.Module, prefix: str)
         ‚Üí Optional[LinearMethodBase]


CLASS: GPTQLinearMethod
----------------------------------------
  L 399: __init__(self, quant_config: GPTQConfig)

  L 402: create_weights(self, layer: torch.nn.Module, input_size_per_partition: int, output_partition_sizes: list[int], input_size: int, output_size: int, params_dtype: torch.dtype)

  L 513: process_weights_after_loading(self, layer: torch.nn.Module)
         ‚Üí None

  L 531: apply(self, layer: torch.nn.Module, x: torch.Tensor, bias: Optional[torch.Tensor])
         ‚Üí torch.Tensor


CLASS: GPTQMarlinConfig
----------------------------------------
  L 219: __init__(self, weight_bits: int, group_size: int, desc_act: bool, is_sym: bool, lm_head_quantized: bool, dynamic: Dict[str, Dict[str, Union[int, bool]]], full_config: Dict[str, Any])
         ‚Üí None

  L 277: __repr__(self)
         ‚Üí str

  L 286: get_scaled_act_names(self)
         ‚Üí List[str]
         üìù Returns the activation function names that should be post-scaled.
            For now, this is only used by AWQ.

  L 294: get_name(cls)
         ‚Üí str

  L 298: get_supported_act_dtypes(cls)
         ‚Üí List[torch.dtype]

  L 302: get_min_capability(cls)
         ‚Üí int

  L 306: get_config_filenames(cls)
         ‚Üí List[str]

  L 310: from_config(cls, config: Dict[str, Any])
         ‚Üí GPTQMarlinConfig

  L 330: override_quantization_method(cls, hf_quant_cfg, user_quant)
         ‚Üí Optional[str]

  L 356: get_quant_method(self, layer: torch.nn.Module, prefix: str)
         ‚Üí Optional[QuantizeMethodBase]

  L 367: is_gptq_marlin_compatible(cls, quant_config: Dict[str, Any])


CLASS: GPTQMarlinLinearMethod
----------------------------------------
  L 563: __init__(self, quant_config: GPTQMarlinConfig)
         ‚Üí None

  L 572: create_weights(self, layer: torch.nn.Module, input_size_per_partition: int, output_partition_sizes: list[int], input_size: int, output_size: int, params_dtype: torch.dtype)
         ‚Üí None

  L 685: process_weights_after_loading(self, layer: torch.nn.Module)
         ‚Üí None

  L 779: apply(self, layer: torch.nn.Module, x: torch.Tensor, bias: Optional[torch.Tensor])
         ‚Üí torch.Tensor


CLASS: GPTQMarlinMoEMethod
----------------------------------------
  L 825: __init__(self, quant_config: GPTQMarlinConfig)
         ‚Üí None

  L 828: create_weights(self, layer: torch.nn.Module, num_experts: int, hidden_size: int, intermediate_size_per_partition: int, params_dtype: torch.dtype)

  L 974: process_weights_after_loading(self, layer: torch.nn.Module)
         ‚Üí None

  L1055: apply(self, layer: torch.nn.Module, x: torch.Tensor, topk_output: TopKOutput, moe_runner_config: MoeRunnerConfig)
         ‚Üí torch.Tensor


============================================================
FILE: python/sglang/srt/layers/quantization/int8_kernel.py
Functions: 5
============================================================

MODULE FUNCTIONS:
----------------------------------------
  L  51: def per_token_quant_int8(x, scale_dtype, cal_sum)

  L 126: def per_token_group_quant_int8(x: torch.Tensor,
        group_size: int,
        eps: float,
        dtype: torch.dtype)
         ‚Üí Tuple[torch.Tensor, torch.Tensor]
         üìù Function to perform per-token-group quantization on an input tensor `x`.
            It converts the tensor values into signed int8 values and returns the
            quantized tensor along with the scaling factor used for quantization.
            Args:
            x: The input tenosr with ndim >= 2.
            group_size: The group size used for quantization.
            eps: The minimum to avoid dividing zero.
            dtype: The dype of output tensor. Note that only `torch.int8` is supported for now.
            Returns:
            Tuple[torch.Tensor, torch.Tensor]: The quantized tensor and the scaling factor for quantization.

  L 185: def sglang_per_token_group_quant_int8(x: torch.Tensor,
        group_size: int,
        eps: float,
        dtype: torch.dtype)

  L 298: def get_w8a8_block_int8_configs(N: int, K: int, block_n: int, block_k: int)
         ‚Üí Optional[Dict[int, Any]]
         üìù Return optimized configurations for the w8a8 block fp8 kernel.
            The return value will be a dictionary that maps an irregular grid of
            batch sizes to configurations of the w8a8 block fp8 kernel. To evaluate the
            kernel on a given batch size bs, the closest batch size in the grid should
            be picked and the associated configuration chosen to invoke the kernel.
         @functools.lru_cache

  L 339: def w8a8_block_int8_matmul(A: torch.Tensor,
        B: torch.Tensor,
        As: torch.Tensor,
        Bs: torch.Tensor,
        block_size: List[int],
        output_dtype: torch.dtype)
         ‚Üí torch.Tensor
         üìù This function performs matrix multiplication with block-wise quantization.
            It takes two input tensors `A` and `B` with scales `As` and `Bs`.
            The output is returned in the specified `output_dtype`.
            Args:
            A: The input tensor, e.g., activation.
            B: The input tensor, e.g., weight.
            As: The per-token-group quantization scale for `A`.
            Bs: The per-block quantization scale for `B`.
            block_size: The block size for per-block quantization. It should be 2-dim, e.g., [128, 128].
            output_dytpe: The dtype of the returned tensor.
            Returns:
            torch.Tensor: The result of matmul.


============================================================
FILE: python/sglang/srt/layers/quantization/int8_utils.py
Functions: 3
============================================================

MODULE FUNCTIONS:
----------------------------------------
  L  11: def apply_w8a8_block_int8_linear(input: torch.Tensor,
        weight: torch.Tensor,
        block_size: List[int],
        weight_scale: torch.Tensor,
        input_scale: Optional[torch.Tensor],
        bias: Optional[torch.Tensor])
         ‚Üí torch.Tensor

  L  34: def input_to_int8(x: torch.Tensor, dtype: torch.dtype)
         ‚Üí Tuple[torch.Tensor, torch.Tensor]
         üìù This function quantizes input values to int8 values with tensor-wise quantization.

  L  47: def block_dequant(x_q_block: torch.Tensor,
        x_s: torch.Tensor,
        block_size: List[int])
         ‚Üí torch.Tensor
         üìù This function conducts block-wise dequantization.
            The inputs are block-wise quantization tensor `x_q_block`, block-wise quantization scale
            and the block size.
            The outputs are dequantized tensor.


============================================================
FILE: python/sglang/srt/layers/quantization/kv_cache.py
Functions: 4
============================================================


CLASS: BaseKVCacheMethod
----------------------------------------
  L  28: __init__(self, quant_config: QuantizationConfig)

  L  31: create_weights(self, layer: torch.nn.Module)
         üìù Create "weight" (aka k_scale and v_scale) for an attention layer.

  L  45: apply(self, layer: torch.nn.Module)
         ‚Üí torch.Tensor

  L  48: process_weights_after_loading(self, layer: RadixAttention)
         ‚Üí None


============================================================
FILE: python/sglang/srt/layers/quantization/marlin_utils.py
Functions: 38
============================================================

MODULE FUNCTIONS:
----------------------------------------
  L  63: def query_marlin_supported_quant_types(has_zp: Optional[bool],
        include_fp_type: bool,
        device_capability: Optional[int])

  L 134: def check_marlin_supported(quant_type: ScalarType,
        group_size: int,
        has_zp: bool,
        device_capability: Optional[int])
         ‚Üí bool

  L 144: def verify_marlin_supported(quant_type: ScalarType,
        group_size: int,
        has_zp: bool)
         ‚Üí None

  L 153: def verify_marlin_supports_shape(output_size_per_partition: int,
        input_size_per_partition: int,
        input_size: int,
        group_size: int)
         ‚Üí None

  L 189: def check_marlin_supports_shape(output_size_per_partition: int,
        input_size_per_partition: int,
        input_size: int,
        group_size: int)
         ‚Üí tuple[bool, Optional[str]]

  L 204: def check_marlin_supports_layer(layer: LinearBase, group_size: int)
         ‚Üí bool

  L 220: def check_moe_marlin_supports_layer(layer: FusedMoE, group_size: int)
         ‚Üí bool

  L 244: def marlin_make_workspace(device: torch.device, max_blocks_per_sm: int)
         ‚Üí torch.Tensor

  L 255: def marlin_is_k_full(act_order: bool, is_row_parallel: bool)
         ‚Üí bool

  L 259: def marlin_repeat_scales_on_all_ranks(act_order: bool,
        group_size: int,
        is_row_parallel: bool)
         ‚Üí bool

  L 268: def marlin_make_empty_g_idx(device: torch.device)
         ‚Üí torch.Tensor

  L 274: def marlin_make_empty_zp(device: torch.device)
         ‚Üí torch.Tensor

  L 280: def marlin_sort_g_idx(g_idx: torch.Tensor)
         ‚Üí tuple[torch.Tensor, torch.Tensor]

  L 285: def get_scale_perms()

  L 295: def marlin_permute_scales(s: torch.Tensor,
        size_k: int,
        size_n: int,
        group_size: int)
         ‚Üí torch.Tensor

  L 309: def marlin_permute_bias(s: torch.Tensor)
         ‚Üí torch.Tensor

  L 316: def marlin_moe_permute_scales(s: torch.Tensor,
        size_k: int,
        size_n: int,
        group_size: int)

  L 334: def marlin_zero_points(zp: torch.Tensor,
        size_k: int,
        size_n: int,
        num_bits: int)
         ‚Üí torch.Tensor

  L 357: def awq_to_marlin_zero_points(q_zp_packed: torch.Tensor,
        size_k: int,
        size_n: int,
        num_bits: int)
         ‚Üí torch.Tensor

  L 381: def moe_awq_to_marlin_zero_points(q_zp_packed: torch.Tensor,
        size_k: int,
        size_n: int,
        num_bits: int)

  L 395: def maybe_warn_marlin_atomic_add(device, dtype)

  L 407: def maybe_warn_marlin_atomic_add_env()

  L 423: def should_use_atomic_add_reduce(m: int,
        n: int,
        k: int,
        device: torch.device,
        dtype: torch.dtype)
         ‚Üí bool

  L 448: def apply_gptq_marlin_linear(input: torch.Tensor,
        weight: torch.Tensor,
        weight_scale: torch.Tensor,
        weight_zp: torch.Tensor,
        g_idx: torch.Tensor,
        g_idx_sort_indices: torch.Tensor,
        workspace: torch.Tensor,
        wtype: ScalarType,
        output_size_per_partition: int,
        input_size_per_partition: int,
        is_k_full: bool,
        bias: Optional[torch.Tensor],
        use_fp32_reduce: bool)
         ‚Üí torch.Tensor

  L 500: def apply_awq_marlin_linear(input: torch.Tensor,
        weight: torch.Tensor,
        weight_scale: torch.Tensor,
        weight_zp: torch.Tensor,
        g_idx: torch.Tensor,
        g_idx_sort_indices: torch.Tensor,
        workspace: torch.Tensor,
        quant_type: ScalarType,
        output_size_per_partition: int,
        input_size_per_partition: int,
        bias: Optional[torch.Tensor],
        use_fp32_reduce: bool)
         ‚Üí torch.Tensor


CLASS: MarlinConfig
----------------------------------------
  L 556: __init__(self, group_size: int, lm_head_quantized: bool)
         ‚Üí None

  L 592: __repr__(self)
         ‚Üí str

  L 599: get_name(cls)
         ‚Üí str

  L 603: get_supported_act_dtypes(cls)
         ‚Üí list[torch.dtype]

  L 608: get_min_capability(cls)
         ‚Üí int

  L 612: get_config_filenames(cls)
         ‚Üí list[str]

  L 616: from_config(cls, config: dict[str, Any])
         ‚Üí 'MarlinConfig'

  L 622: override_quantization_method(cls, hf_quant_cfg, user_quant)
         ‚Üí Optional[str]

  L 642: get_quant_method(self, layer: torch.nn.Module, prefix: str)
         ‚Üí Optional[MarlinLinearMethod]


CLASS: MarlinLinearMethod
----------------------------------------
  L 662: __init__(self, quant_config: MarlinConfig)

  L 665: create_weights(self, layer: torch.nn.Module, input_size_per_partition: int, output_partition_sizes: list[int], input_size: int, output_size: int, params_dtype: torch.dtype)

  L 777: process_weights_after_loading(self, layer: torch.nn.Module)
         ‚Üí None

  L 783: apply(self, layer: torch.nn.Module, x: torch.Tensor, bias: Optional[torch.Tensor])
         ‚Üí torch.Tensor


============================================================
FILE: python/sglang/srt/layers/quantization/marlin_utils_fp8.py
Functions: 6
============================================================

MODULE FUNCTIONS:
----------------------------------------
  L  27: def fp8_fused_exponent_bias_into_scales(scales)

  L  41: def apply_fp8_marlin_linear(input: torch.Tensor,
        weight: torch.Tensor,
        weight_scale: torch.Tensor,
        workspace: torch.Tensor,
        size_n: int,
        size_k: int,
        bias: Optional[torch.Tensor],
        use_fp32_reduce: bool)
         ‚Üí torch.Tensor

  L  83: def prepare_fp8_layer_for_marlin(layer: torch.nn.Module, size_k_first: bool)
         ‚Üí None

  L 175: def prepare_moe_fp8_layer_for_marlin(layer: torch.nn.Module, size_k_first: bool)
         ‚Üí None

  L 305: def pack_fp8_to_int32(fp8_tensor: torch.Tensor, size_k_first: bool)
         ‚Üí torch.Tensor
         üìù Repack FP8 weights to gptq format (packed int32 elements)

  L 322: def marlin_quant_fp8_torch(weight, group_size)


============================================================
FILE: python/sglang/srt/layers/quantization/modelopt_quant.py
Functions: 38
============================================================


CLASS: ModelOptFp4Config
----------------------------------------
  L 487: __init__(self, is_checkpoint_nvfp4_serialized: bool, kv_cache_quant_algo: str, group_size: int, exclude_modules: List[str])
         ‚Üí None

  L 505: get_name(cls)
         ‚Üí str

  L 509: get_supported_act_dtypes(cls)
         ‚Üí List[torch.dtype]

  L 513: get_min_capability(cls)
         ‚Üí int

  L 517: get_config_filenames(cls)
         ‚Üí List[str]

  L 521: from_config(cls, config: Dict[str, Any])
         ‚Üí ModelOptFp4Config

  L 595: is_layer_excluded(self, prefix: str, exclude_modules: list)

  L 611: get_quant_method(self, layer: torch.nn.Module, prefix: str)
         ‚Üí Optional[QuantizeMethodBase]

  L 633: get_scaled_act_names(self)
         ‚Üí List[str]


CLASS: ModelOptFp4LinearMethod
----------------------------------------
  L 652: __init__(self, quant_config: ModelOptFp4Config)

  L 655: create_weights(self, layer: torch.nn.Module, input_size_per_partition: int, output_partition_sizes: List[int], input_size: int, output_size: int, params_dtype: torch.dtype)

  L 729: process_weights_after_loading(self, layer: torch.nn.Module)
         ‚Üí None

  L 766: apply(self, layer: torch.nn.Module, x: torch.Tensor, bias: Optional[torch.Tensor])
         ‚Üí torch.Tensor


CLASS: ModelOptFp8Config
----------------------------------------
  L  78: __init__(self, is_checkpoint_fp8_serialized: bool, kv_cache_quant_method: Optional[str], exclude_modules: Optional[List[str]])
         ‚Üí None
         üìù Args:
            is_checkpoint_fp8_serialized (bool): Indicates if the checkpoint uses serialized FP8 format.

  L  97: get_name(cls)
         ‚Üí str

  L 101: get_supported_act_dtypes(cls)
         ‚Üí List[torch.dtype]

  L 105: get_min_capability(cls)
         ‚Üí int

  L 109: get_config_filenames(cls)
         ‚Üí List[str]

  L 113: from_config(cls, config: Dict[str, Any])
         ‚Üí ModelOptFp8Config

  L 168: get_quant_method(self, layer: torch.nn.Module, prefix: str)
         ‚Üí Optional[QuantizeMethodBase]

  L 195: get_scaled_act_names(self)
         ‚Üí List[str]


CLASS: ModelOptFp8KVCacheMethod
----------------------------------------
  L 304: __init__(self, quant_config: ModelOptFp8Config)


CLASS: ModelOptFp8LinearMethod
----------------------------------------
  L 213: __init__(self, quant_config: ModelOptFp8Config)

  L 218: create_weights(self, layer: torch.nn.Module, input_size_per_partition: int, output_partition_sizes: List[int], params_dtype: torch.dtype)
         ‚Üí None
         üìù Creates and registers weights, weight scales, and input scales for FP8 quantization.

  L 270: process_weights_after_loading(self, layer: torch.nn.Module)
         ‚Üí None
         üìù Requantizes weights after loading using the maximum scale.

  L 282: apply(self, layer: torch.nn.Module, x: torch.Tensor, bias: Optional[torch.Tensor])
         ‚Üí torch.Tensor
         üìù Applies FP8 linear transformation.


CLASS: ModelOptFp8MoEMethod
----------------------------------------
  L 316: __init__(self, quant_config: ModelOptFp8Config)

  L 320: create_weights(self, layer: torch.nn.Module, num_experts: int, hidden_size: int, intermediate_size: int, params_dtype: torch.dtype)

  L 397: process_weights_after_loading(self, layer: torch.nn.Module)
         ‚Üí None
         üìù Process FP8 MoE weights after loading from serialized checkpoint.
            Only supports pre-quantized checkpoints with FP8 weights and scales.

  L 460: apply(self, layer: torch.nn.Module, x: torch.Tensor, topk_output: TopKOutput, moe_runner_config: MoeRunnerConfig)
         ‚Üí torch.Tensor


CLASS: ModelOptNvFp4FusedMoEMethod
----------------------------------------
  L 811: __init__(self, quant_config: ModelOptFp4Config)

  L 823: enable_flashinfer_cutlass_moe(self)
         ‚Üí bool

  L 829: create_weights(self, layer: torch.nn.Module, num_experts: int, hidden_size: int, intermediate_size_per_partition: int, params_dtype: torch.dtype)

  L 951: swizzle_blockscale(self, scale: torch.Tensor)

  L 976: prepare_static_weights_for_kernel(self, gemm1_weights, gemm2_weights, gemm1_scales_linear_fp4_bytes, gemm2_scales_linear_fp4_bytes, hidden_size, intermediate_size, num_experts)

  L1109: process_weights_after_loading(self, layer: torch.nn.Module)
         ‚Üí None
         üìù Process FP4 MoE weights after loading from serialized checkpoint.
            Only supports pre-quantized checkpoints with FP8 weights and scales.

  L1244: load_up_proj_weight_first(self)
         ‚Üí bool

  L1248: apply(self, layer: FusedMoE, x: torch.Tensor, topk_output: TopKOutput, moe_runner_config: MoeRunnerConfig)
         ‚Üí torch.Tensor


============================================================
FILE: python/sglang/srt/layers/quantization/moe_wna16.py
Functions: 16
============================================================

MODULE FUNCTIONS:
----------------------------------------
  L  29: def get_weight_perm(num_bits: int)

  L 216: def is_layer_skipped_quant(prefix: str, modules_to_not_convert: List[str])


CLASS: MoeWNA16Config
----------------------------------------
  L  62: __init__(self, linear_quant_method: str, weight_bits: int, group_size: int, has_zp: bool, lm_head_quantized: bool, modules_to_not_convert: Optional[List[str]], full_config: Dict[str, Any])
         ‚Üí None

  L 109: get_name(cls)
         ‚Üí str

  L 113: get_supported_act_dtypes(cls)
         ‚Üí List[torch.dtype]

  L 117: get_min_capability(cls)
         ‚Üí int

  L 121: get_config_filenames(cls)
         ‚Üí List[str]

  L 124: get_scaled_act_names(self)
         ‚Üí List[str]

  L 128: from_config(cls, config: Dict[str, Any])
         ‚Üí MoeWNA16Config

  L 155: override_quantization_method(cls, hf_quant_cfg, user_quant)
         ‚Üí Optional[str]

  L 161: is_moe_wna16_compatible(cls, quant_config: Dict[str, Any])

  L 185: get_quant_method(self, layer: torch.nn.Module, prefix: str)
         ‚Üí Optional[QuantizeMethodBase]


CLASS: MoeWNA16Method
----------------------------------------
  L 227: __init__(self, quant_config: MoeWNA16Config)

  L 230: create_weights(self, layer: torch.nn.Module, num_experts: int, hidden_size: int, intermediate_size_per_partition: int, params_dtype: torch.dtype)

  L 352: apply(self, layer: torch.nn.Module, x: torch.Tensor, topk_output: TopKOutput, moe_runner_config: MoeRunnerConfig)
         ‚Üí torch.Tensor

  L 385: get_weight_loader(layer, weight_loader)


============================================================
FILE: python/sglang/srt/layers/quantization/mxfp4.py
Functions: 17
============================================================


CLASS: Mxfp4Config
----------------------------------------
  L 172: __init__(self, ignored_layers: Optional[list[str]], is_checkpoint_mxfp4_serialized: bool)

  L 182: from_config(cls, config)

  L 202: get_min_capability(cls)
         ‚Üí int

  L 206: get_name(cls)
         ‚Üí str

  L 210: get_supported_act_dtypes(cls)
         ‚Üí list[torch.dtype]

  L 214: get_config_filenames(cls)
         ‚Üí list[str]

  L 217: is_static_cfg(self)

  L 220: get_quant_method(self, layer: torch.nn.Module, prefix: str)
         ‚Üí Optional['QuantizeMethodBase']

  L 247: get_scaled_act_names(self)
         ‚Üí List[str]


CLASS: Mxfp4DynamicQuantMoEMethod
----------------------------------------
  L 726: create_weights(self, layer: torch.nn.Module, num_experts: int, hidden_size: int, intermediate_size_per_partition: int, params_dtype: torch.dtype)

  L 783: mxfp4_quantize(self, w)

  L 801: process_weights_after_loading(self, layer: Module)
         ‚Üí None

  L 811: apply(self, layer: torch.nn.Module, x: torch.Tensor, topk_output: TopKOutput, moe_runner_config: MoeRunnerConfig)
         ‚Üí torch.Tensor


CLASS: Mxfp4MoEMethod
----------------------------------------
  L 253: __init__(self, prefix: str)

  L 281: create_weights(self, layer: torch.nn.Module, num_experts: int, hidden_size: int, intermediate_size: int, params_dtype: torch.dtype, with_bias: bool)

  L 389: process_weights_after_loading(self, layer)

  L 616: apply(self, layer: torch.nn.Module, x: torch.Tensor, topk_output: TopKOutput, moe_runner_config: MoeRunnerConfig)
         ‚Üí torch.Tensor


============================================================
FILE: python/sglang/srt/layers/quantization/mxfp4_tensor.py
Functions: 2
============================================================


CLASS: MXFP4QuantizeUtil
----------------------------------------
  L  29: quantize(cls, input: torch.Tensor, block_size: Optional[int])
         ‚Üí tuple
         üìù Converting a tensor to a quantized format based on MXFP4 quantization. Only E4M3 is supported.
            Args:
            input (torch.Tensor): The input tensor to be quantized.
            block_sizes (dict | None): The block sizes for quantization.

  L  77: dequantize(cls, quantized_data, dtype: torch.dtype, scale, block_sizes)
         üìù Dequantze MXFP4 packed tensor to a target dtype.


============================================================
FILE: python/sglang/srt/layers/quantization/petit.py
Functions: 15
============================================================


CLASS: PetitNvFp4Config
----------------------------------------
  L  36: __init__(self, is_checkpoint_nvfp4_serialized: bool, kv_cache_quant_algo: str, group_size: int, exclude_modules: List[str])
         ‚Üí None

  L  54: get_name(cls)
         ‚Üí str

  L  58: get_supported_act_dtypes(cls)
         ‚Üí List[torch.dtype]

  L  62: get_min_capability(cls)
         ‚Üí int

  L  67: get_config_filenames(cls)
         ‚Üí List[str]

  L  71: from_config(cls, config: Dict[str, Any])
         ‚Üí 'PetitNvFp4Config'

  L 101: override_quantization_method(cls, hf_quant_cfg, user_quant)
         ‚Üí Optional[str]

  L 108: is_petit_nvfp4_compatible(cls, quant_config: Dict[str, Any])
         ‚Üí bool

  L 112: is_layer_excluded(self, prefix: str, exclude_modules: list)

  L 119: get_quant_method(self, layer: torch.nn.Module, prefix: str)
         ‚Üí Optional['QuantizeMethodBase']

  L 130: get_scaled_act_names(self)
         ‚Üí List[str]


CLASS: PetitNvFp4LinearMethod
----------------------------------------
  L 149: __init__(self, quant_config: PetitNvFp4Config)

  L 152: create_weights(self, layer: torch.nn.Module, input_size_per_partition: int, output_partition_sizes: List[int], input_size: int, output_size: int, params_dtype: torch.dtype)

  L 226: process_weights_after_loading(self, layer: torch.nn.Module)
         ‚Üí None

  L 238: apply(self, layer: torch.nn.Module, x: torch.Tensor, bias: Optional[torch.Tensor])
         ‚Üí torch.Tensor


============================================================
FILE: python/sglang/srt/layers/quantization/petit_utils.py
Functions: 5
============================================================

MODULE FUNCTIONS:
----------------------------------------
  L  17: def prepare_nvfp4_layer_for_petit(layer: torch.nn.Module)
         ‚Üí None

  L  22: def apply_petit_nvfp4_linear(input: torch.Tensor,
        weight: torch.Tensor,
        weight_scale: torch.Tensor,
        weight_scale_2: torch.Tensor,
        size_n: int,
        size_k: int,
        bias: Optional[torch.Tensor])
         ‚Üí torch.Tensor

  L  55: def verify_petit_nvfp4_supported(quant_method: str, group_size: Optional[int])
         ‚Üí None

  L  61: def prepare_nvfp4_layer_for_petit(layer: torch.nn.Module)
         ‚Üí None

  L  78: def apply_petit_nvfp4_linear(input: torch.Tensor,
        weight: torch.Tensor,
        weight_scale: torch.Tensor,
        weight_scale_2: torch.Tensor,
        size_n: int,
        size_k: int,
        bias: Optional[torch.Tensor])
         ‚Üí torch.Tensor


============================================================
FILE: python/sglang/srt/layers/quantization/qoq.py
Functions: 13
============================================================


CLASS: QoQConfig
----------------------------------------
  L  40: __init__(self, weight_bits: int, group_size: int)
         ‚Üí None

  L  61: __repr__(self)
         ‚Üí str

  L  67: get_supported_act_dtypes(cls)
         ‚Üí List[torch.dtype]

  L  71: get_min_capability(cls)
         ‚Üí int

  L  75: get_name(cls)
         ‚Üí str

  L  79: get_config_filenames(cls)
         ‚Üí List[str]
         üìù List of filenames to search for in the model directory.

  L  87: from_config(cls, config: Dict[str, Any])
         ‚Üí QoQConfig

  L  92: get_quant_method(self, layer: torch.nn.Module, prefix: str)
         ‚Üí Optional[QuantizeMethodBase]

  L 103: get_scaled_act_names(self)
         ‚Üí List[str]


CLASS: QoQLinearMethod
----------------------------------------
  L 114: __init__(self, quant_config: QoQConfig)

  L 117: create_weights(self, layer: torch.nn.Module, input_size_per_partition: int, output_partition_sizes: List[int], input_size: int, output_size: int, params_dtype: torch.dtype)

  L 210: process_weights_after_loading(self, layer: torch.nn.Module)
         ‚Üí None

  L 219: apply(self, layer: torch.nn.Module, x: torch.Tensor, bias: Optional[torch.Tensor])


============================================================
FILE: python/sglang/srt/layers/quantization/quark/quark.py
Functions: 16
============================================================


CLASS: QuarkConfig
----------------------------------------
  L  29: __init__(self, quant_config: dict[str, Any], kv_cache_group: Optional[list[str]], kv_cache_config: Optional[dict[str, Any]], pack_method: str)

  L  46: get_linear_method(self)
         ‚Üí 'QuarkLinearMethod'

  L  50: get_supported_act_dtypes(cls)
         ‚Üí list[torch.dtype]

  L  54: get_min_capability(cls)
         ‚Üí int

  L  57: get_name(self)
         ‚Üí str

  L  60: get_quant_method(self, layer: torch.nn.Module, prefix: str)
         ‚Üí Optional['QuantizeMethodBase']

  L  86: from_config(cls, config: dict[str, Any])
         ‚Üí 'QuarkConfig'

  L 153: get_config_filenames(cls)
         ‚Üí list[str]

  L 289: get_scheme(self, layer: torch.nn.Module, layer_name: str)
         ‚Üí 'QuarkScheme'

  L 302: get_scaled_act_names(self)
         ‚Üí List[str]


CLASS: QuarkKVCacheMethod
----------------------------------------
  L 363: __init__(self, quant_config: QuarkConfig)

  L 368: validate_kv_cache_config(kv_cache_config: Optional[dict[str, Any]])
         üìù Validator for the kv cache configuration. Useful for controlling the
            kv cache quantization schemes, that are being supported in vLLM
            :param kv_cache_config: the quark kv cache scheme


CLASS: QuarkLinearMethod
----------------------------------------
  L 308: __init__(self, quantization_config: QuarkConfig)

  L 311: process_weights_after_loading(self, layer: torch.nn.Module)
         ‚Üí None

  L 314: create_weights(self, layer: torch.nn.Module, input_size_per_partition: int, output_partition_sizes: list[int], input_size: int, output_size: int, params_dtype: torch.dtype)
         üìù Use the CompressedTensorsScheme associated with each layer to create
            the necessary parameters for the layer. See LinearMethodBase for param
            details

  L 340: apply(self, layer: torch.nn.Module, x: torch.Tensor, bias: Optional[torch.Tensor])
         üìù Use the output of create_weights and the CompressedTensorsScheme
            associated with the layer to apply the forward pass with the
            layer input.  See LinearMethodBase for param details


============================================================
FILE: python/sglang/srt/layers/quantization/quark/quark_moe.py
Functions: 6
============================================================


CLASS: QuarkMoEMethod
----------------------------------------
  L  26: __new__(cls)

  L  45: get_moe_method(quant_config: 'QuarkConfig', module: torch.nn.Module, layer_name: str)
         ‚Üí 'QuarkMoEMethod'


CLASS: QuarkW4A4MXFp4MoEMethod
----------------------------------------
  L  69: __init__(self, weight_config: dict[str, Any], input_config: dict[str, Any])

  L  85: create_weights(self, layer: torch.nn.Module, num_experts: int, hidden_size: int, intermediate_size_per_partition: int, params_dtype: torch.dtype)

  L 157: process_weights_after_loading(self, layer: torch.nn.Module)
         ‚Üí None

  L 173: apply(self, layer: torch.nn.Module, x: torch.Tensor, topk_output: TopKOutput, moe_runner_config: MoeRunnerConfig)
         ‚Üí torch.Tensor


============================================================
FILE: python/sglang/srt/layers/quantization/quark/schemes/quark_scheme.py
Functions: 4
============================================================


CLASS: QuarkScheme
----------------------------------------
  L  19: get_min_capability(cls)
         ‚Üí int
         üìù Get minimum device capability.

  L  26: create_weights(self)
         üìù Weight creation for the particular scheme. Inputs to this function

  L  34: apply_weights(self, layer: torch.nn.Module, x: torch.Tensor, bias: Optional[torch.Tensor])
         üìù Run the forward pass for the particular scheme. This is where
            scheme-specific dequant/quant steps/kernels should be applied.
            :param layer: torch.nn.Module with the registered weights and
            other parameters relevant to the particular scheme.
            :param x: input to the layer
            :param bias: bias parameter

  L  50: process_weights_after_loading(self, layer: torch.nn.Module)
         üìù Called after weight loading is complete for any cleanup that
            needs to occur.


============================================================
FILE: python/sglang/srt/layers/quantization/quark/schemes/quark_w4a4_mxfp4.py
Functions: 5
============================================================


CLASS: QuarkW4A4MXFP4
----------------------------------------
  L  26: __init__(self, weight_quant_spec: dict[str, Any], input_quant_spec: dict[str, Any])

  L  35: get_min_capability(cls)
         ‚Üí int

  L  38: process_weights_after_loading(self, layer: torch.nn.Module)
         ‚Üí None

  L  50: create_weights(self, layer: torch.nn.Module, output_partition_sizes: list[int], input_size_per_partition: int, params_dtype: torch.dtype, weight_loader: Callable)

  L  90: apply_weights(self, layer: torch.nn.Module, x: torch.Tensor, bias: Optional[torch.Tensor])
         ‚Üí torch.Tensor


============================================================
FILE: python/sglang/srt/layers/quantization/quark/utils.py
Functions: 3
============================================================

MODULE FUNCTIONS:
----------------------------------------
  L   9: def deep_compare(dict1: Any, dict2: Any)
         ‚Üí bool

  L  22: def should_ignore_layer(layer_name: Optional[str],
        ignore: Iterable[str],
        fused_mapping: Mapping[str,
        list[str]])
         ‚Üí bool

  L  78: def check_equal_or_regex_match(layer_name: str, targets: Iterable[str])
         ‚Üí bool
         üìù Checks whether a layer_name is exactly equal or a regex match for
            if target starts with 're:' to any target in list.


============================================================
FILE: python/sglang/srt/layers/quantization/unquant.py
Functions: 14
============================================================


CLASS: UnquantizedEmbeddingMethod
----------------------------------------
  L  47: create_weights(self, layer: torch.nn.Module, input_size_per_partition: int, output_partition_sizes: List[int], input_size: int, output_size: int, params_dtype: torch.dtype)
         üìù Create weights for embedding layer.

  L  70: apply(self, layer: torch.nn.Module, x: torch.Tensor, bias: Optional[torch.Tensor])
         ‚Üí torch.Tensor

  L  78: embedding(self, layer: torch.nn.Module, input_: torch.Tensor)
         ‚Üí torch.Tensor


CLASS: UnquantizedFusedMoEMethod
----------------------------------------
  L 135: __init__(self, use_triton_kernels: bool)

  L 153: create_weights(self, layer: torch.nn.Module, num_experts: int, hidden_size: int, intermediate_size: int, params_dtype: torch.dtype, with_bias: bool)

  L 206: process_weights_after_loading(self, layer: torch.nn.Module)
         ‚Üí None

  L 225: apply(self, layer: torch.nn.Module, x: torch.Tensor, topk_output: TopKOutput, moe_runner_config: MoeRunnerConfig)
         ‚Üí torch.Tensor

  L 240: forward_cuda(self, layer: torch.nn.Module, x: torch.Tensor, topk_output: TopKOutput, moe_runner_config: MoeRunnerConfig)
         ‚Üí torch.Tensor

  L 314: forward_cpu(self, layer: torch.nn.Module, x: torch.Tensor, topk_output: TopKOutput, moe_runner_config: MoeRunnerConfig)
         ‚Üí torch.Tensor

  L 361: forward_npu(self, layer: torch.nn.Module, x: torch.Tensor, topk_output: TopKOutput, moe_runner_config: MoeRunnerConfig)
         ‚Üí torch.Tensor

  L 377: forward_tpu(self)
         ‚Üí torch.Tensor


CLASS: UnquantizedLinearMethod
----------------------------------------
  L  85: create_weights(self, layer: torch.nn.Module, input_size_per_partition: int, output_partition_sizes: List[int], input_size: int, output_size: int, params_dtype: torch.dtype)

  L 107: process_weights_after_loading(self, layer: torch.nn.Module)
         ‚Üí None

  L 111: apply(self, layer: torch.nn.Module, x: torch.Tensor, bias: Optional[torch.Tensor])
         ‚Üí torch.Tensor


============================================================
FILE: python/sglang/srt/layers/quantization/utils.py
Functions: 20
============================================================

MODULE FUNCTIONS:
----------------------------------------
  L  20: def get_scalar_types()
         üìù Returns:
            tuple: (ScalarType, scalar_types)

  L  47: def is_layer_skipped(prefix: str,
        ignored_layers: List[str],
        fused_mapping: Mapping[str,
        List[str]])
         ‚Üí bool

  L  98: def per_tensor_dequantize(tensor: torch.Tensor,
        inv_scale: Union[float,
        torch.Tensor])
         ‚Üí torch.Tensor

  L 106: def all_close_1d(x: torch.Tensor)
         ‚Üí bool

  L 111: def convert_to_channelwise(weight_scale: torch.Tensor,
        logical_widths: List[int])
         ‚Üí Tuple[torch.Tensor, torch.Tensor]

  L 134: def requantize_with_max_scale(weight: torch.Tensor,
        weight_scale: torch.Tensor,
        logical_widths: List[int])
         ‚Üí Tuple[torch.Tensor, torch.Tensor]

  L 162: def update_tensor_inplace(old: torch.Tensor, new: torch.Tensor)
         ‚Üí None

  L 169: def replace_parameter(mod: torch.nn.Module,
        name: str,
        new: Union[torch.Tensor,
        torch.nn.Parameter])
         ‚Üí None

  L 192: def assert_fp8_all_close(a: torch.Tensor, b: torch.Tensor)

  L 215: def override_config(config: QuantizationConfig, prefix: str)

  L 247: def get_dynamic_override(config: QuantizationConfig,
        layer_name: str,
        key: Optional[str],
        default_value: Union[int,
        bool,
        None])
         ‚Üí Union[Dict, int, bool, None]

  L 268: def get_linear_quant_method(config: QuantizationConfig,
        layer: torch.nn.Module,
        prefix: str,
        linear_method_cls: type)

  L 301: def get_pack_factor(num_bits)

  L 306: def permute_rows(q_w: torch.Tensor,
        w_ref: torch.Tensor,
        group_size: int,
        test_perm: Optional[torch.Tensor])

  L 336: def pack_cols(q_w: torch.Tensor, num_bits: int, size_k: int, size_n: int)

  L 362: def pack_rows(q_w: torch.Tensor, num_bits: int, size_k: int, size_n: int)

  L 386: def unpack_cols(packed_q_w: torch.Tensor,
        num_bits: int,
        size_k: int,
        size_n: int)

  L 419: def quantize_weights(w: torch.Tensor,
        quant_type: ScalarType,
        group_size: Optional[int],
        zero_points: bool,
        ref_zero_points_after_scales: bool)

  L 518: def gptq_quantize_weights(w: torch.Tensor,
        quant_type: ScalarType,
        group_size: int,
        act_order: bool,
        test_perm: Optional[torch.Tensor])

  L 552: def sort_weights(q_w: torch.Tensor, g_idx: torch.Tensor)


============================================================
FILE: python/sglang/srt/layers/quantization/w4afp8.py
Functions: 12
============================================================


CLASS: W4AFp8Config
----------------------------------------
  L  33: __init__(self, is_checkpoint_fp8_serialized: bool, is_checkpoint_w4afp8_serialized: bool, linear_activation_scheme: str, moe_activation_scheme: str, ignored_layers: Optional[List[str]], weight_block_size: Optional[List[int]], group_size: int)
         ‚Üí None

  L  57: get_name(cls)
         ‚Üí str

  L  61: get_supported_act_dtypes(cls)
         ‚Üí List[torch.dtype]

  L  65: get_min_capability(cls)
         ‚Üí int

  L  69: get_config_filenames(cls)
         ‚Üí List[str]

  L  73: from_config(cls, config: Dict[str, Any])
         ‚Üí W4AFp8Config

  L  88: get_quant_method(self, layer: torch.nn.Module, prefix: str)
         ‚Üí Optional[QuantizeMethodBase]

  L 103: get_scaled_act_names(self)
         ‚Üí List[str]


CLASS: W4AFp8MoEMethod
----------------------------------------
  L 109: __init__(self, quant_config: W4AFp8Config)

  L 112: create_weights(self, layer: EPMoE, num_experts: int, hidden_size: int, intermediate_size: int, params_dtype: torch.dtype)

  L 252: process_weights_after_loading(self, layer: Module)
         ‚Üí None

  L 281: apply(self, layer: EPMoE, x: torch.Tensor, topk_output: StandardTopKOutput, moe_runner_config: MoeRunnerConfig)
         ‚Üí torch.Tensor


============================================================
FILE: python/sglang/srt/layers/quantization/w8a8_fp8.py
Functions: 16
============================================================


CLASS: W8A8FP8MoEMethod
----------------------------------------
  L 204: __init__(self, quant_config: W8A8Fp8Config)

  L 207: create_weights(self, layer: torch.nn.Module, num_experts: int, hidden_size: int, intermediate_size: int, params_dtype: torch.dtype)

  L 259: process_weights_after_loading(self, layer: torch.nn.Module)
         ‚Üí None

  L 269: apply(self, layer: torch.nn.Module, x: torch.Tensor, topk_output: StandardTopKOutput, moe_runner_config: MoeRunnerConfig)
         ‚Üí torch.Tensor


CLASS: W8A8Fp8Config
----------------------------------------
  L  54: __init__(self, is_checkpoint_fp8_serialized: bool)

  L  58: get_supported_act_dtypes(cls)
         ‚Üí List[torch.dtype]

  L  62: get_min_capability(cls)
         ‚Üí int

  L  66: get_name(self)
         ‚Üí str

  L  70: get_config_filenames(cls)
         ‚Üí List[str]

  L  74: from_config(cls, config: Dict[str, Any])
         ‚Üí W8A8Fp8Config

  L  81: get_quant_method(self, layer: torch.nn.Module, prefix: str)
         ‚Üí Optional[QuantizeMethodBase]

  L  95: get_scaled_act_names(self)
         ‚Üí List[str]


CLASS: W8A8Fp8LinearMethod
----------------------------------------
  L 101: __init__(self, quantization_config: W8A8Fp8Config)

  L 105: process_weights_after_loading(self, layer: torch.nn.Module)
         ‚Üí None

  L 137: create_weights(self, layer: torch.nn.Module, input_size_per_partition: int, output_partition_sizes: List[int], input_size: int, output_size: int, params_dtype: torch.dtype)

  L 178: apply(self, layer: torch.nn.Module, x: torch.Tensor, bias: Optional[torch.Tensor])


============================================================
FILE: python/sglang/srt/layers/quantization/w8a8_int8.py
Functions: 50
============================================================

MODULE FUNCTIONS:
----------------------------------------
  L  75: def npu_wrapper_rmsnorm_init(func)

  L  86: def npu_wrapper_rmsnorm_forward(func)

  L 108: def npu_fused_experts(hidden_states: torch.Tensor,
        w13: torch.Tensor,
        w13_scale: torch.Tensor,
        w2: torch.Tensor,
        w2_scale: torch.Tensor,
        topk_weights: torch.Tensor,
        topk_ids: torch.Tensor,
        top_k: int)


CLASS: NPU_W8A8DynamicLinearMethod
----------------------------------------
  L 827: __init__(self, quantization_config: W8A8Int8Config)
         ‚Üí None

  L 831: create_weights(self, layer: torch.nn.Module, input_size_per_partition: int, output_partition_sizes: List[int], input_size: int, output_size: int, params_dtype: torch.dtype)
         ‚Üí None

  L 871: process_weights_after_loading(self, layer: torch.nn.Module)
         ‚Üí None

  L 875: apply(self, layer: torch.nn.Module, x: torch.Tensor, bias: Optional[torch.Tensor])
         ‚Üí torch.Tensor


CLASS: NPU_W8A8DynamicLinearMethodImpl
----------------------------------------
  L 767: __init__(self)

  L 771: get_weight(input_size: int, output_size: int, params_dtype: torch.dtype)
         ‚Üí Dict[str, Any]

  L 778: get_pertensor_param(params_dtype: torch.dtype)
         ‚Üí Dict[str, Any]

  L 782: get_perchannel_param(output_size: int, params_dtype: torch.dtype)
         ‚Üí Dict[str, Any]

  L 792: apply(layer: torch.nn.Module, x: torch.Tensor, bias: Optional[torch.Tensor], tp_rank: Optional[int])
         ‚Üí torch.Tensor

  L 809: process_weights_after_loading(self, layer)


CLASS: NPU_W8A8LinearMethod
----------------------------------------
  L 703: __init__(self, quantization_config: W8A8Int8Config)
         ‚Üí None

  L 711: create_weights(self, layer: torch.nn.Module, input_size_per_partition: int, output_partition_sizes: List[int], input_size: int, output_size: int, params_dtype: torch.dtype)
         ‚Üí None

  L 751: process_weights_after_loading(self, layer: torch.nn.Module)
         ‚Üí None

  L 755: apply(self, layer: torch.nn.Module, x: torch.Tensor, bias: Optional[torch.Tensor])
         ‚Üí torch.Tensor


CLASS: NPU_W8A8LinearMethodImpl
----------------------------------------
  L 537: __init__(self)
         ‚Üí None

  L 542: get_weight(input_size: int, output_size: int, params_dtype: torch.dtype)
         ‚Üí Dict[str, Any]

  L 551: get_pertensor_param(params_dtype: torch.dtype)
         ‚Üí Dict[str, Any]

  L 558: get_perchannel_param(output_size: int, params_dtype: torch.dtype)
         ‚Üí Dict[str, Any]

  L 573: apply(layer: torch.nn.Module, x: torch.Tensor, bias: Optional[torch.Tensor])
         ‚Üí torch.Tensor

  L 605: process_weights_after_loading(self, layer)


CLASS: NPU_W8A8LinearMethodMTImpl
----------------------------------------
  L 628: __init__(self)
         ‚Üí None

  L 632: get_weight(input_size: int, output_size: int, params_dtype: torch.dtype)
         ‚Üí Dict[str, Any]

  L 641: get_pertensor_param(params_dtype: torch.dtype)
         ‚Üí Dict[str, Any]

  L 648: get_perchannel_param(output_size: int, params_dtype: torch.dtype)
         ‚Üí Dict[str, Any]

  L 663: apply(layer: torch.nn.Module, x: torch.Tensor, bias: Optional[torch.Tensor])
         ‚Üí torch.Tensor

  L 686: process_weights_after_loading(self, layer)


CLASS: NPU_W8A8MoEMethod
----------------------------------------
  L 894: __init__(self, quantization_config: W8A8Int8Config)
         ‚Üí None

  L 898: create_weights(self, layer: torch.nn.Module, num_experts: int, hidden_size: int, intermediate_size: int, params_dtype: torch.dtype)
         ‚Üí None

  L 956: process_weights_after_loading(self, layer: torch.nn.Module)
         ‚Üí None

  L 976: apply(self, layer, x, topk_output: TopKOutput, moe_runner_config: MoeRunnerConfig)
         ‚Üí torch.Tensor


CLASS: W8A8Int8Config
----------------------------------------
  L 191: __init__(self, quant_config: Dict[str, Any])

  L 218: get_supported_act_dtypes(cls)
         ‚Üí List[torch.dtype]

  L 226: get_min_capability(cls)
         ‚Üí int

  L 235: get_name(self)
         ‚Üí str

  L 239: get_config_filenames(cls)
         ‚Üí List[str]

  L 246: from_config(cls, config: Dict[str, Any])
         ‚Üí W8A8Int8Config

  L 249: get_quant_method(self, layer: torch.nn.Module, prefix: str)
         ‚Üí Optional[QuantizeMethodBase]

  L 296: is_layer_skipped(self, prefix: str, fused_mapping: Mapping[str, List[str]])

  L 327: get_scaled_act_names(self)
         ‚Üí List[str]


CLASS: W8A8Int8LinearMethod
----------------------------------------
  L 333: __init__(self, quantization_config: W8A8Int8Config)

  L 336: process_weights_after_loading(self, layer: torch.nn.Module)
         ‚Üí None

  L 347: create_weights(self, layer: torch.nn.Module, input_size_per_partition: int, output_partition_sizes: List[int], input_size: int, output_size: int, params_dtype: torch.dtype)

  L 378: apply(self, layer: torch.nn.Module, x: torch.Tensor, bias: Optional[torch.Tensor])


CLASS: W8A8Int8MoEMethod
----------------------------------------
  L 412: __init__(self, quant_config: W8A8Int8Config)

  L 415: create_weights(self, layer: torch.nn.Module, num_experts: int, hidden_size: int, intermediate_size: int, params_dtype: torch.dtype)

  L 469: process_weights_after_loading(self, layer: torch.nn.Module)
         ‚Üí None

  L 486: apply(self, layer: torch.nn.Module, x: torch.Tensor, topk_output: TopKOutput, moe_runner_config: MoeRunnerConfig)
         ‚Üí torch.Tensor


============================================================
FILE: python/sglang/srt/layers/radix_attention.py
Functions: 2
============================================================


CLASS: RadixAttention
----------------------------------------
  L  44: __init__(self, num_heads: int, head_dim: int, scaling: float, num_kv_heads: int, layer_id: int, logit_cap: float, v_head_dim: int, sliding_window_size: int, is_cross_attention: bool, pos_encoding_mode: str, logit_capping_method: str, quant_config: Optional[QuantizationConfig], attn_type: AttentionType, use_irope: bool, prefix: str)

  L  90: forward(self, q, k, v, forward_batch: ForwardBatch, save_kv_cache: bool)


============================================================
FILE: python/sglang/srt/layers/rotary_embedding.py
Functions: 35
============================================================

MODULE FUNCTIONS:
----------------------------------------
  L 646: def yarn_get_mscale(scale: float, mscale: float)
         ‚Üí float

  L1654: def get_rope(head_size: int,
        rotary_dim: int,
        max_position: int,
        base: int,
        is_neox_style: bool,
        rope_scaling: Optional[Dict[str,
        Any]],
        dtype: Optional[torch.dtype],
        partial_rotary_factor: float,
        dual_chunk_attention_config: Optional[Dict[str,
        Any]])
         ‚Üí RotaryEmbedding

  L1872: def rotate_half(x)
         üìù Rotates half the hidden dims of the input.

  L1879: def apply_rotary_pos_emb_native(q: torch.Tensor,
        k: torch.Tensor,
        cos: torch.Tensor,
        sin: torch.Tensor,
        unsqueeze_dim)
         ‚Üí Tuple[torch.Tensor, torch.Tensor]

  L1902: def apply_rotary_pos_emb_npu(q: torch.Tensor,
        k: torch.Tensor,
        cos: torch.Tensor,
        sin: torch.Tensor,
        unsqueeze_dim)
         ‚Üí Tuple[torch.Tensor, torch.Tensor]

  L1929: def get_rope_cpu(head_size: int,
        rotary_dim: int,
        max_position: int,
        base: int,
        is_neox_style: bool,
        rope_scaling: Optional[Dict[str,
        Any]],
        dtype: Optional[torch.dtype],
        partial_rotary_factor: float,
        device: Optional[str])
         ‚Üí RotaryEmbedding

  L2001: def get_rope_wrapper(head_size: int,
        rotary_dim: int,
        max_position: int,
        base: int,
        is_neox_style: bool,
        rope_scaling: Optional[Dict[str,
        Any]],
        dtype: Optional[torch.dtype],
        partial_rotary_factor: float,
        device: Optional[str])


CLASS: DeepseekScalingRotaryEmbedding
----------------------------------------
  L 658: __init__(self, head_size: int, rotary_dim: int, max_position_embeddings: int, base: int, is_neox_style: bool, scaling_factor: float, dtype: torch.dtype)
         ‚Üí None

  L 737: forward_native(self, positions: torch.Tensor, query: torch.Tensor, key: torch.Tensor, offsets: Optional[torch.Tensor])
         ‚Üí Tuple[torch.Tensor, torch.Tensor]
         üìù PyTorch-native implementation equivalent to forward().

  L 778: forward_npu(self, positions: torch.Tensor, query: torch.Tensor, key: torch.Tensor, offsets: Optional[torch.Tensor])
         ‚Üí Tuple[torch.Tensor, torch.Tensor]

  L 818: forward_cpu(self, positions: torch.Tensor, query: torch.Tensor, key: torch.Tensor, offsets: Optional[torch.Tensor])
         ‚Üí Tuple[torch.Tensor, torch.Tensor]


CLASS: DualChunkRotaryEmbedding
----------------------------------------
  L1458: __init__(self, head_size: int, rotary_dim: int, max_position_embeddings: int, base: int, is_neox_style: bool, dtype: torch.dtype, chunk_size: int, local_size: int)
         ‚Üí None

  L1560: forward(self, positions: torch.Tensor, query: torch.Tensor, key: torch.Tensor, offsets: Optional[torch.Tensor])
         ‚Üí Tuple[torch.Tensor, torch.Tensor]

  L1643: extra_repr(self)
         ‚Üí str


CLASS: DynamicNTKAlphaRotaryEmbedding
----------------------------------------
  L 950: __init__(self, head_size: int, rotary_dim: int, max_position_embeddings: int, base: int, is_neox_style: bool, scaling_alpha: float, dtype: torch.dtype)
         ‚Üí None


CLASS: DynamicNTKScalingRotaryEmbedding
----------------------------------------
  L 357: __init__(self, head_size: int, rotary_dim: int, max_position_embeddings: int, base: int, is_neox_style: bool, scaling_factor: float, dtype: torch.dtype)
         ‚Üí None


CLASS: LinearScalingRotaryEmbedding
----------------------------------------
  L 293: __init__(self, head_size: int, rotary_dim: int, max_position_embeddings: int, base: int, is_neox_style: bool, scaling_factors: Union[List[float], float], dtype: torch.dtype)
         ‚Üí None

  L 347: scaling_factor_to_offset(self)
         ‚Üí Dict[float, int]


CLASS: Llama3RotaryEmbedding
----------------------------------------
  L 836: __init__(self, head_size: int, rotary_dim: int, max_position_embeddings: int, base: int, is_neox_style: bool, dtype: torch.dtype, scaling_factor: float, low_freq_factor: float, high_freq_factor: float, orig_max_position: int)
         ‚Üí None


CLASS: Llama4VisionRotaryEmbedding
----------------------------------------
  L 883: __init__(self, head_size: int, rotary_dim: int, max_position_embeddings: int, base: int, is_neox_style: bool, dtype: torch.dtype)

  L 926: forward(self, query: torch.Tensor, key: torch.Tensor)
         ‚Üí Tuple[torch.Tensor, torch.Tensor]


CLASS: MRotaryEmbedding
----------------------------------------
  L 984: __init__(self, head_size: int, rotary_dim: int, max_position_embeddings: int, base: int, is_neox_style: bool, dtype: torch.dtype, mrope_section: Optional[List[int]])
         ‚Üí None

  L1033: forward(self, positions: torch.Tensor, query: torch.Tensor, key: torch.Tensor)
         ‚Üí Tuple[torch.Tensor, torch.Tensor]
         üìù PyTorch-native implementation equivalent to forward().
            Args:
            positions:
            [num_tokens,] (text only) or
            [3, num_tokens] (T/H/W positions with multimodal inputs)
            query: [num_tokens, num_heads * head_size]
            key: [num_tokens, num_kv_heads * head_size]

  L1082: get_rope_index(spatial_merge_size: int, image_token_id: int, video_token_id: int, vision_start_token_id: int, model_type: str, tokens_per_second: Optional[int], input_ids: Optional[torch.LongTensor], image_grid_thw: Optional[torch.LongTensor], video_grid_thw: Optional[torch.LongTensor], second_per_grid_ts: Optional[torch.Tensor])
         ‚Üí Tuple[torch.Tensor, torch.Tensor]

  L1240: get_rope_index_glm4v(input_ids: torch.Tensor, hf_config: Any, image_grid_thw: Union[list[list[int]], torch.Tensor], video_grid_thw: Union[list[list[int]], torch.Tensor], attention_mask: torch.Tensor)
         ‚Üí tuple[torch.Tensor, torch.Tensor]
         üìù Get mrope input positions and delta value for GLM4V.

  L1437: get_next_input_positions(mrope_position_delta: int, context_len: int, seq_len: int)
         ‚Üí torch.Tensor


CLASS: Phi3LongRoPEScaledRotaryEmbedding
----------------------------------------
  L 513: __init__(self, head_size: int, rotary_dim: int, max_position_embeddings: int, original_max_position_embeddings: int, base: int, is_neox_style: bool, dtype: torch.dtype, short_factor: List[float], long_factor: List[float], short_mscale: Optional[float], long_mscale: Optional[float])

  L 604: forward(self, positions: torch.Tensor, query: torch.Tensor, key: torch.Tensor, offsets: Optional[torch.Tensor])
         ‚Üí Tuple[torch.Tensor, torch.Tensor]


CLASS: RotaryEmbedding
----------------------------------------
  L  82: __init__(self, head_size: int, rotary_dim: int, max_position_embeddings: int, base: int, is_neox_style: bool, dtype: torch.dtype)
         ‚Üí None

  L 139: forward_native(self, positions: torch.Tensor, query: torch.Tensor, key: torch.Tensor, offsets: Optional[torch.Tensor])
         ‚Üí Tuple[torch.Tensor, torch.Tensor]
         üìù A PyTorch-native implementation of forward().

  L 169: forward_npu(self, positions: torch.Tensor, query: torch.Tensor, key: torch.Tensor, offsets: Optional[torch.Tensor])
         ‚Üí Tuple[torch.Tensor, torch.Tensor]
         üìù A PyTorch-npu implementation of forward().

  L 199: forward_cpu(self, positions: torch.Tensor, query: torch.Tensor, key: torch.Tensor, offsets: Optional[torch.Tensor])
         ‚Üí Tuple[torch.Tensor, torch.Tensor]

  L 219: forward_cuda(self, positions: torch.Tensor, query: torch.Tensor, key: torch.Tensor, offsets: Optional[torch.Tensor], fused_set_kv_buffer_arg)
         ‚Üí Tuple[torch.Tensor, torch.Tensor]

  L 257: extra_repr(self)
         ‚Üí str


CLASS: YaRNScalingRotaryEmbedding
----------------------------------------
  L 444: __init__(self, head_size: int, rotary_dim: int, max_position_embeddings: int, base: int, is_neox_style: bool, scaling_factor: float, dtype: torch.dtype)
         ‚Üí None


============================================================
FILE: python/sglang/srt/layers/sampler.py
Functions: 8
============================================================

MODULE FUNCTIONS:
----------------------------------------
  L 168: def top_k_top_p_min_p_sampling_from_probs_torch(probs: torch.Tensor,
        top_ks: torch.Tensor,
        top_ps: torch.Tensor,
        min_ps: torch.Tensor,
        need_min_p_sampling: bool)
         üìù A top-k, top-p and min-p sampling implementation with native pytorch operations.

  L 195: def sampling_from_probs_torch(probs: torch.Tensor)
         üìù A sampling implementation with native pytorch operations, without
            top-k, top-p, or min-p filtering.

  L 203: def top_p_normalize_probs_torch(probs: torch.Tensor, top_ps: torch.Tensor)

  L 215: def get_top_logprobs(logprobs: torch.Tensor, top_logprobs_nums: List[int])

  L 236: def get_token_ids_logprobs(logprobs: torch.Tensor,
        token_ids_logprobs: List[List[int]])

  L 256: def apply_custom_logit_processor(logits: torch.Tensor,
        sampling_batch_info: SamplingBatchInfo,
        num_tokens_in_batch: int)
         üìù Apply custom logit processors to the logits.
            This function will modify the logits in-place.
            num_tokens_in_batch is needed to support spec decoding, where each batch can contain multiple
            tokens. By default, we assume each batch contains only 1 token.


CLASS: Sampler
----------------------------------------
  L  34: __init__(self)

  L  42: forward(self, logits_output: LogitsProcessorOutput, sampling_info: SamplingBatchInfo, return_logprob: bool, top_logprobs_nums: List[int], token_ids_logprobs: List[List[int]])
         üìù Run a sampler & compute logprobs and update logits_output accordingly.
            Args:
            logits_output: The logits from the model forward
            sampling_info: Metadata for sampling
            return_logprob: If set, store the output logprob information to
            logits_output
            top_logprobs_nums: Number of top lobprobs per sequence in a batch
            batch_next_token_ids: next token IDs. If set, skip sampling and only
            compute output logprobs It is used for speculative decoding which
            performs sampling in draft workers.


============================================================
FILE: python/sglang/srt/layers/torchao_utils.py
Functions: 4
============================================================

MODULE FUNCTIONS:
----------------------------------------
  L  15: def get_gemlite_cache_path()
         ‚Üí str

  L  19: def save_gemlite_cache(print_error: bool)
         ‚Üí bool

  L  31: def proj_filter(module: torch.nn.Module, fqn: str)
         üìù Filter function for quantizing projection layers.

  L  39: def apply_torchao_config_to_model(model: torch.nn.Module,
        torchao_config: str,
        filter_fn: Optional[Callable])
         üìù Quantize a modelwith torchao quantization specified by torchao_config
            Args:
            `model`: a model to be quantized based on torchao_config
            `torchao_config` (str): type of quantization and their arguments we want to use to
            quantize the model, e.g. int4wo-128 means int4 weight only quantization with group_size
            128


============================================================
FILE: python/sglang/srt/layers/utils.py
Functions: 3
============================================================

MODULE FUNCTIONS:
----------------------------------------
  L  10: def get_layer_id(weight_name)


CLASS: PPMissingLayer
----------------------------------------
  L  25: __init__(self)

  L  29: forward(self)
         üìù Return the first arg from args or the first value from kwargs.
            Wraps the input in a tuple if `self.return_tuple` is True.


============================================================
FILE: python/sglang/srt/layers/vocab_parallel_embedding.py
Functions: 20
============================================================

MODULE FUNCTIONS:
----------------------------------------
  L  44: def pad_vocab_size(vocab_size: int, pad_to: int)
         ‚Üí int
         üìù Pad the vocab size to the given value.

  L  49: def vocab_range_from_per_partition_vocab_size(per_partition_vocab_size: int,
        rank: int,
        offset: int)
         ‚Üí Sequence[int]

  L  57: def vocab_range_from_global_vocab_size(global_vocab_size: int,
        rank: int,
        world_size: int,
        offset: int)
         ‚Üí Sequence[int]

  L 126: def get_masked_input_and_mask(input_: torch.Tensor,
        org_vocab_start_index: int,
        org_vocab_end_index: int,
        num_org_vocab_padding: int,
        added_vocab_start_index: int,
        added_vocab_end_index: int)
         ‚Üí Tuple[torch.Tensor, torch.Tensor]
         @torch.compile(dynamic=True, backend=get_compiler_backend())


CLASS: ParallelLMHead
----------------------------------------
  L 514: __init__(self, num_embeddings: int, embedding_dim: int)

  L 560: tie_weights(self, embed_tokens: VocabParallelEmbedding)
         üìù Tie the weights with word embeddings.

  L 569: forward(self, input_)


CLASS: VocabParallelEmbedding
----------------------------------------
  L 192: __init__(self, num_embeddings: int, embedding_dim: int)

  L 346: get_sharded_to_full_mapping(self)
         ‚Üí Optional[List[int]]
         üìù Get a mapping that can be used to reindex the gathered
            logits for sampling.
            During sampling, we gather logits from all ranks. The relationship
            of index->token_id will follow the same format as outlined in the class
            docstring. However, after the gather, we want to reindex the final
            logits tensor to map index->token_id one-to-one (the index is always
            equal the token_id it corresponds to). The indices returned by this
            method allow us to do that.

  L 411: weight_loader(self, param: Parameter, loaded_weight: torch.Tensor)

  L 462: forward(self, input_)

  L 488: extra_repr(self)
         ‚Üí str


CLASS: VocabParallelEmbeddingShardIndices
----------------------------------------
  L  81: num_org_elements(self)
         ‚Üí int

  L  85: num_added_elements(self)
         ‚Üí int

  L  89: num_org_elements_padded(self)
         ‚Üí int

  L  93: num_added_elements_padded(self)
         ‚Üí int

  L  97: num_org_vocab_padding(self)
         ‚Üí int

  L 101: num_added_vocab_padding(self)
         ‚Üí int

  L 105: num_elements_padded(self)
         ‚Üí int

  L 108: __post_init__(self)


============================================================
FILE: python/sglang/srt/lora/backend/base_backend.py
Functions: 7
============================================================

MODULE FUNCTIONS:
----------------------------------------
  L 100: def get_backend_from_name(name: str)
         ‚Üí BaseLoRABackend
         üìù Get corresponding backend class from backend's name


CLASS: BaseLoRABackend
----------------------------------------
  L  17: __init__(self, name: str, batch_info: LoRABatchInfo)

  L  21: run_lora_a_sgemm(self, x: torch.Tensor, weights: torch.Tensor)
         ‚Üí torch.Tensor
         üìù Run segment Gemm of lora a modules with current backend.
            The definition of segment Gemm can be referred to https://docs.flashinfer.ai/api/gemm.html.
            Args:
            x: input matrix with shape (s, input_dim), here s is the sum of all sequence lengths
            weights: a set of lora weights with shape (num_lora, c * r, input_dim),
            here r is lora rank, c is a multiplier for stacked modules (e.g., c=3 for qkv_proj, c=2 for gate_up_proj)
            usually input_dim is much larger than r
            Returns:
            result with shape (s, c * r)

  L  37: run_lora_b_sgemm(self, x: torch.Tensor, weights: torch.Tensor)
         ‚Üí torch.Tensor
         üìù Run segment Gemm of lora b modules with current backend.
            The definition of segment Gemm can be referred to https://docs.flashinfer.ai/api/gemm.html.
            Args:
            x: input matrix with shape (s, r), here s is the sum of all sequence lengths, r is lora rank
            weights: a set of lora weights with shape (num_lora, output_dim, r)
            usually output_dim is much larger than r
            Returns:
            result with shape (s, output_dim)

  L  52: run_qkv_lora(self, x: torch.Tensor, qkv_lora_a: torch.Tensor, qkv_lora_b: Union[torch.Tensor, Tuple[torch.Tensor]])
         ‚Üí torch.Tensor
         üìù Run the lora pass for QKV Layer.
            Args:
            x: input matrix with shape (s, input_dim), here s is the sum of all sequence lengths
            qkv_lora_a: lora_a module for qkv, with shape (num_lora, 3 * r, input_dim)
            qkv_lora_b: lora_b module for qkv.
            If passed in as a tensor, its shape should be (num_lora,output_dim_q + 2 * output_dim_kv, r)
            If passed in as a tuple of two tensors, it should contain:
            a lora_b module for q, with shape (1, num_lora, output_dim_q, r)
            and a combined lora_b module for kv, with shape (2, num_lora, output_dim_kv, r)
            Returns:
            result with shape (s, output_dim_q + 2 * output_dim_kv)

  L  75: run_gate_up_lora(self, x: torch.Tensor, gate_up_lora_a: torch.Tensor, gate_up_lora_b: Union[torch.Tensor, Tuple[torch.Tensor]])
         ‚Üí torch.Tensor
         üìù Run the lora pass for gate_up_proj, usually attached to MergedColumnParallelLayer.
            Args:
            x: input matrix with shape (s, input_dim), here s is the sum of all sequence lengths
            gate_up_lora_a: lora_a module for gate_up_proj, with shape (num_lora, 2 * r, input_dim)
            gate_up_lora_b: lora_b module for qkv.
            If passed in as a tensor, its shape should be (num_lora, 2 * output_dim, r)
            If passed in as a tuple, it should contain two tensors with shape (num_lora, output_dim, r)
            Returns:
            result with shape (s, 2 * output_dim)

  L  96: set_batch_info(self, batch_info: LoRABatchInfo)


============================================================
FILE: python/sglang/srt/lora/backend/triton_backend.py
Functions: 5
============================================================


CLASS: TritonLoRABackend
----------------------------------------
  L  15: __init__(self, name: str, batch_info: LoRABatchInfo)

  L  18: run_lora_a_sgemm(self, x: torch.Tensor, weights: torch.Tensor)
         ‚Üí torch.Tensor

  L  23: run_lora_b_sgemm(self, x: torch.Tensor, weights: torch.Tensor, base_output: torch.Tensor)
         ‚Üí torch.Tensor

  L  33: run_qkv_lora(self, x: torch.Tensor, qkv_lora_a: torch.Tensor, qkv_lora_b: torch.Tensor, output_offset: torch.Tensor, max_qkv_out_dim: int, base_output: torch.Tensor)
         ‚Üí torch.Tensor

  L  61: run_gate_up_lora(self, x: torch.Tensor, gate_up_lora_a: torch.Tensor, gate_up_lora_b: torch.Tensor, base_output: torch.Tensor)
         ‚Üí torch.Tensor


============================================================
FILE: python/sglang/srt/lora/layers.py
Functions: 29
============================================================

MODULE FUNCTIONS:
----------------------------------------
  L 305: def get_lora_layer(layer: nn.Module, lora_backend: BaseLoRABackend)
         ‚Üí BaseLayerWithLoRA


CLASS: BaseLayerWithLoRA
----------------------------------------
  L  21: __init__(self, base_layer: nn.Module, lora_backend: BaseLoRABackend)

  L  31: forward(self, x: torch.Tensor)

  L  34: set_lora_info(self)

  L  37: slice_lora_a_weights(self, A: torch.Tensor, tp_rank: int)

  L  40: slice_lora_b_weights(self, B: torch.Tensor, tp_rank: int)


CLASS: ColumnParallelLinearWithLoRA
----------------------------------------
  L  63: __init__(self, base_layer: ColumnParallelLinear, lora_backend: BaseLoRABackend)
         ‚Üí None

  L  70: set_lora_info(self, A_buffer: torch.Tensor, B_buffer: torch.Tensor)

  L  79: apply_lora(self, base_output: torch.Tensor, x: torch.Tensor)
         ‚Üí torch.Tensor

  L  88: forward(self, input_: torch.Tensor)

  L 105: slice_lora_a_weights(self, A: torch.Tensor, tp_rank: int)

  L 108: slice_lora_b_weights(self, B: torch.Tensor, tp_rank: int)


CLASS: MergedColumnParallelLinearWithLoRA
----------------------------------------
  L 117: __init__(self, base_layer: MergedColumnParallelLinear, lora_backend: BaseLoRABackend)
         ‚Üí None

  L 124: set_lora_info(self, A_buffer: torch.Tensor, B_buffer: torch.Tensor)

  L 133: apply_lora(self, base_output: torch.Tensor, x: torch.Tensor)
         ‚Üí torch.Tensor

  L 142: slice_lora_a_weights(self, A: torch.Tensor, tp_rank: int)

  L 145: slice_lora_b_weights(self, B: torch.Tensor, tp_rank: int)


CLASS: QKVParallelLinearWithLoRA
----------------------------------------
  L 161: __init__(self, base_layer: QKVParallelLinear, lora_backend: BaseLoRABackend)
         ‚Üí None

  L 183: set_lora_info(self, A_buffer_qkv: torch.Tensor, B_buffer_qkv: torch.Tensor)

  L 192: apply_lora(self, base_output: torch.Tensor, x: torch.Tensor)
         ‚Üí torch.Tensor

  L 203: slice_lora_a_weights(self, A: torch.Tensor, tp_rank: int)

  L 206: slice_lora_b_weights(self, B: torch.Tensor, tp_rank: int)
         ‚Üí torch.Tensor


CLASS: RowParallelLinearWithLoRA
----------------------------------------
  L 235: __init__(self, base_layer: RowParallelLinear, lora_backend: BaseLoRABackend)
         ‚Üí None

  L 242: set_lora_info(self, A_buffer: torch.Tensor, B_buffer: torch.Tensor)

  L 247: apply_lora(self, base_output: torch.Tensor, x: torch.Tensor)
         ‚Üí torch.Tensor

  L 256: forward(self, input_: torch.Tensor, skip_all_reduce)

  L 294: slice_lora_a_weights(self, A: torch.Tensor, tp_rank: int)

  L 301: slice_lora_b_weights(self, B: torch.Tensor, tp_rank: int)


CLASS: VocabParallelEmbeddingWithLoRA
----------------------------------------
  L  53: __init__(self, base_layer: VocabParallelEmbedding, lora_backend: BaseLoRABackend)
         ‚Üí None


============================================================
FILE: python/sglang/srt/lora/lora.py
Functions: 5
============================================================


CLASS: LoRAAdapter
----------------------------------------
  L  48: __init__(self, uid: str, config: LoRAConfig, base_hf_config: AutoConfig, load_config: LoadConfig, lora_backend: BaseLoRABackend)

  L  75: initialize_weights(self)

  L  97: normalize_qkv_proj(self, weight_names: List[str], weights: Dict[str, torch.Tensor])

  L 150: normalize_gate_up_proj(self, weight_names: List[str], weights: Dict[str, torch.Tensor])


CLASS: LoRALayer
----------------------------------------
  L  38: __init__(self, config: LoRAConfig, base_hf_config: AutoConfig)


============================================================
FILE: python/sglang/srt/lora/lora_config.py
Functions: 2
============================================================


CLASS: LoRAConfig
----------------------------------------
  L  22: __init__(self, path: str)
         ‚Üí None

  L  37: get_lora_config(self, dummy)


============================================================
FILE: python/sglang/srt/lora/lora_manager.py
Functions: 16
============================================================


CLASS: LoRAManager
----------------------------------------
  L  46: __init__(self, base_model: torch.nn.Module, base_hf_config: AutoConfig, max_loras_per_batch: int, load_config: LoadConfig, dtype: torch.dtype, lora_backend: str, tp_size: int, tp_rank: int, max_lora_rank: Optional[int], target_modules: Optional[Iterable[str]], lora_paths: Optional[List[LoRARef]])

  L  81: init_cuda_graph_batch_info(self, max_bs_in_cuda_graph: int)

  L 109: create_lora_update_result(self, success: bool, error_message: str)
         ‚Üí LoRAUpdateResult

  L 121: load_lora_adapter(self, lora_ref: LoRARef)
         ‚Üí LoRAUpdateResult
         üìù Load a single LoRA adapter from the specified path.
            Args:
            lora_ref (LoRARef): The LoRARef object containing the LoRA name, path, and ID.

  L 155: validate_new_adapter(self, lora_config: LoRAConfig, lora_ref: LoRARef)
         üìù Validate if an adapter can be loaded into the current LoRA memory pool and generate error if it is incompatible.

  L 178: unload_lora_adapter(self, lora_ref: LoRARef)
         ‚Üí LoRAUpdateResult
         üìù Unload LoRA adapters by their names. This will remove the adapters from the memory pool and
            delete the corresponding LoRA modules.

  L 203: validate_lora_batch(self, lora_ids: set[str])
         ‚Üí bool
         üìù Validate if the LoRA IDs in the batch can be loaded into the current LoRA memory pool.

  L 234: prepare_lora_batch(self, forward_batch: ForwardBatch)

  L 347: update_lora_info(self)
         üìù Update all LoRA modules to associate them with the latest memory buffer.

  L 369: init_state(self, max_lora_rank: Optional[int], target_modules: Optional[Iterable[str]], lora_paths: Optional[List[LoRARef]])
         üìù Initialize the internal (mutable) state of the LoRAManager.
            When `lora_paths` is provided and not empty, it might be used for inferring LoRA shape info such as
            the target modules and max_lora_rank.

  L 395: init_lora_adapters(self, lora_paths: Optional[List[LoRARef]])

  L 416: init_lora_shapes(self, max_lora_rank: Optional[int], target_modules: Optional[Iterable[str]])
         üìù Infer LoRA target modules and max_lora_rank from loaded adapters if not provided.

  L 463: load_lora_weights(self, lora_ref: LoRARef)
         üìù Load the weights of a LoRA adapter to CPU memory and conducts post-loading validation.

  L 477: init_memory_pool(self)
         üìù (Re)initialize the LoRA memory pool based on the current configurations.

  L 490: set_lora_module(self, module_name, module)

  L 495: init_lora_modules(self)


============================================================
FILE: python/sglang/srt/lora/lora_registry.py
Functions: 9
============================================================


CLASS: LoRARef
----------------------------------------
  L  40: __post_init__(self)

  L  44: __str__(self)
         ‚Üí str


CLASS: LoRARegistry
----------------------------------------
  L  62: __init__(self, lora_paths: Optional[List[LoRARef]])

  L  84: register(self, lora_ref: LoRARef)
         üìù Register a new LoRARef object in the registry.
            Args:
            lora_ref (LoRARef): The LoRARef object to register.

  L  94: unregister(self, lora_name: str)
         ‚Üí str
         üìù Unregister a LoRARef object from the registry and returns the removed LoRA ID.
            Args:
            lora_name (str): The name of the LoRA model to unregister.

  L 111: acquire(self, lora_name: Union[str, List[str]])
         ‚Üí Union[str, List[str]]
         üìù Queries registry for LoRA IDs based on LoRA names and start tracking the usage of the corresponding LoRA adapters
            by incrementing its counter.

  L 151: release(self, lora_id: Union[str, List[str]])
         üìù Decrements the usage counter for a LoRA adapter, indicating that it is no longer in use.

  L 170: wait_for_unload(self, lora_id: str)
         üìù Waits until the usage counter for a LoRA adapter reaches zero, indicating that it is no longer in use.
            This is useful for ensuring that a LoRA adapter can be safely unloaded.
            This method itself is not synchronized, which is safe because it should only be called during LoRA unloading,
            which itself is guaranteed to be sequential.

  L 203: num_registered_loras(self)
         ‚Üí int
         üìù Returns the total number of LoRA adapters currently registered.


============================================================
FILE: python/sglang/srt/lora/mem_pool.py
Functions: 11
============================================================


CLASS: EmptySlot
----------------------------------------
  L  32: __repr__(self)

  L  35: __new__(cls)


CLASS: LoRAMemoryPool
----------------------------------------
  L  47: __init__(self, base_hf_config: AutoConfig, max_loras_per_batch: int, dtype: torch.dtype, tp_size: int, tp_rank: int, max_lora_rank: int, target_modules: Set[str], base_model: torch.nn.Module)

  L  87: can_support(self, config: Union[LoRAConfig, Iterable[LoRAConfig]])
         ‚Üí bool
         üìù Check if the memory pool can support the given LoRA adapters.

  L 106: get_lora_A_shape(self, module_name: str, base_model: torch.nn.Module, max_lora_dim: int)
         ‚Üí Tuple[int]
         üìù Given a module_name (might be a stacked name), return the hidden dims of modules' input and output.

  L 122: get_lora_B_shape(self, module_name: str, base_model: torch.nn.Module, max_lora_dim: int)
         ‚Üí Tuple[int]
         üìù Given a module_name (might be a stacked name), return the hidden dims of modules' input and output.

  L 137: init_buffers(self, base_model: torch.nn.Module)

  L 170: prepare_lora_batch(self, cur_uids: Set[Optional[str]], lora_adapters: Dict[str, LoRAAdapter], lora_modules: List[Dict[str, BaseLayerWithLoRA]], lora_refs: Dict[str, LoRARef])

  L 214: load_lora_weight_to_buffer(self, uid: str, buffer_id: int, lora_adapter: LoRAAdapter, lora_modules: List[Dict[str, BaseLayerWithLoRA]])

  L 286: get_tensor(self, target_module: str, layer_id: int, lora_type: LoRAType)
         ‚Üí torch.Tensor

  L 294: get_buffer_id(self, lora_uid: str)


============================================================
FILE: python/sglang/srt/lora/triton_ops/gate_up_lora_b.py
Functions: 1
============================================================

MODULE FUNCTIONS:
----------------------------------------
  L 126: def gate_up_lora_b_fwd(x: torch.Tensor,
        gate_up_lora_b: torch.Tensor,
        batch_info: LoRABatchInfo,
        output_dim: int,
        base_output: torch.Tensor)
         ‚Üí torch.Tensor


============================================================
FILE: python/sglang/srt/lora/triton_ops/qkv_lora_b.py
Functions: 1
============================================================

MODULE FUNCTIONS:
----------------------------------------
  L 127: def qkv_lora_b_fwd(x: torch.Tensor,
        qkv_lora_b: torch.Tensor,
        batch_info: LoRABatchInfo,
        output_offset: torch.Tensor,
        max_qkv_out_dim: int,
        base_output: torch.Tensor)
         ‚Üí torch.Tensor


============================================================
FILE: python/sglang/srt/lora/triton_ops/sgemm_lora_a.py
Functions: 1
============================================================

MODULE FUNCTIONS:
----------------------------------------
  L 114: def sgemm_lora_a_fwd(x: torch.Tensor,
        weights: torch.Tensor,
        batch_info: LoRABatchInfo,
        stack_num: int)
         ‚Üí torch.Tensor


============================================================
FILE: python/sglang/srt/lora/triton_ops/sgemm_lora_b.py
Functions: 1
============================================================

MODULE FUNCTIONS:
----------------------------------------
  L 118: def sgemm_lora_b_fwd(x: torch.Tensor,
        weights: torch.Tensor,
        batch_info: LoRABatchInfo,
        base_output: torch.Tensor)
         ‚Üí torch.Tensor


============================================================
FILE: python/sglang/srt/lora/utils.py
Functions: 5
============================================================

MODULE FUNCTIONS:
----------------------------------------
  L  40: def get_layer_id(name: str)
         ‚Üí int
         üìù Extract integer id of layer from its name in string.

  L  50: def get_hidden_dim(module_name: str,
        config: AutoConfig,
        base_model: torch.nn.Module)
         ‚Üí Tuple[int]
         üìù Given a module_name (might be a stacked name), return the hidden dims of modules' input and output.

  L  87: def get_normalized_target_modules(target_modules: Iterable[str])
         ‚Üí set[str]
         üìù Mapping a list of target module name to names of the normalized LoRA weights.

  L 108: def get_stacked_multiply(module_name: str)
         ‚Üí int
         üìù Mapping a lora module name to its magnification at output dimension

  L 119: def get_target_module_name(full_module_name: str, target_modules: Set[str])
         ‚Üí str
         üìù Get the target module name in target_modules that can match full_module_name.
            If there is a target module name in target_modules that can match full_module_name, return this name
            Else raise ValueError.


============================================================
FILE: python/sglang/srt/managers/cache_controller.py
Functions: 40
============================================================


CLASS: CacheOperation
----------------------------------------
  L  84: __init__(self, host_indices: torch.Tensor, device_indices: torch.Tensor, node_id: int, priority: Optional[int])

  L 101: merge(self, other: 'CacheOperation')
         ‚Üí None

  L 108: split(self, factor)
         ‚Üí List['CacheOperation']

  L 129: __lt__(self, other: 'CacheOperation')


CLASS: HiCacheController
----------------------------------------
  L 233: __init__(self, token_to_kv_pool_allocator: BaseTokenToKVPoolAllocator, mem_pool_host: HostKVCache, page_size: int, tp_group: torch.distributed.ProcessGroup, load_cache_event: threading.Event, write_policy: str, io_backend: str, storage_backend: Optional[str], prefetch_threshold: int, model_name: Optional[str], storage_backend_extra_config: Optional[str])

  L 414: reset(self)

  L 453: write(self, device_indices: torch.Tensor, priority: Optional[int], node_id: int)
         ‚Üí Optional[torch.Tensor]
         üìù Back up KV caches from device memory to host memory.

  L 472: load(self, host_indices: torch.Tensor, priority: Optional[int], node_id: int)
         ‚Üí Optional[torch.Tensor]
         üìù Load KV caches from host memory to device memory.

  L 492: move_indices(self, host_indices, device_indices)

  L 503: write_thread_func_direct(self)
         üìù Directly write through KV caches to host memory without buffering.

  L 527: load_thread_func_layer_by_layer(self)
         üìù Load KV caches from host memory to device memory layer by layer.

  L 570: evict_device(self, device_indices: torch.Tensor, host_indices: torch.Tensor)
         ‚Üí int

  L 582: evict_host(self, host_indices: torch.Tensor, backup_only: bool)
         ‚Üí int

  L 594: prefetch(self, request_id: str, host_indices: torch.Tensor, new_input_tokens: List[int], last_hash: Optional[str])
         ‚Üí PrefetchOperation
         üìù Prefetch KV caches from storage backend to host memory.

  L 610: terminate_prefetch(self, operation)

  L 614: append_host_mem_release(self, host_indices: torch.Tensor)

  L 702: prefetch_io_aux_func(self)
         üìù Auxiliary function conducting IO operations for prefetching.

  L 717: prefetch_rate_limited(self)
         ‚Üí bool
         üìù Rate limit the prefetching operations to avoid overwhelming the storage backend.

  L 754: prefetch_thread_func(self)
         üìù Manage prefetching operations from storage backend to host memory.

  L 803: write_storage(self, host_indices: torch.Tensor, token_ids: List[int], hash_value: Optional[List[str]])
         ‚Üí int
         üìù Write KV caches from host memory to storage backend.

  L 873: backup_thread_func(self)
         üìù Manage backup operations from host memory to storage backend.


CLASS: LayerDoneCounter
----------------------------------------
  L  46: __init__(self, num_layers)

  L  55: next_producer(self)

  L  58: update_producer(self)

  L  62: set_consumer(self, index)

  L  65: increment(self)

  L  70: wait_until(self, threshold)

  L  75: reset(self)


CLASS: PrefetchOperation
----------------------------------------
  L 200: __init__(self, request_id: str, host_indices: torch.Tensor, token_ids: List[int], last_hash: Optional[str])

  L 216: increment(self, num_tokens: int)

  L 223: mark_done(self)

  L 227: is_done(self)
         ‚Üí bool


CLASS: StorageOperation
----------------------------------------
  L 179: __init__(self, host_indices: torch.Tensor, token_ids: List[int], last_hash: Optional[str], hash_value: Optional[List[str]])

  L 195: __lt__(self, other: 'StorageOperation')


CLASS: TransferBuffer
----------------------------------------
  L 138: __init__(self, stop_event, buffer_count: int, max_buffer_size: int)
         ‚Üí None

  L 146: full(self)
         ‚Üí bool

  L 149: empty(self)
         ‚Üí bool

  L 152: put(self, item, block, timeout)
         ‚Üí None

  L 164: get(self, block, timeout)
         ‚Üí Optional[CacheOperation]

  L 172: clear(self)


============================================================
FILE: python/sglang/srt/managers/data_parallel_controller.py
Functions: 11
============================================================

MODULE FUNCTIONS:
----------------------------------------
  L 341: def run_data_parallel_controller_process(server_args: ServerArgs,
        port_args: PortArgs,
        pipe_writer)


CLASS: DataParallelController
----------------------------------------
  L  67: __init__(self, server_args: ServerArgs, port_args: PortArgs, dp_balance_meta: DPBalanceMeta)
         ‚Üí None

  L 124: launch_dp_schedulers(self, server_args, port_args)

  L 164: launch_tensor_parallel_group_thread(self, server_args: ServerArgs, port_args: PortArgs, base_gpu_id: int, dp_rank: int, ready_event: threading.Event)

  L 180: launch_dp_attention_schedulers(self, server_args, port_args)

  L 187: launch_tensor_parallel_group(self, server_args: ServerArgs, port_args: PortArgs, base_gpu_id: int, dp_rank: int)

  L 269: round_robin_scheduler(self, req: Req)

  L 286: shortest_queue_scheduler(self, input_requests)

  L 289: minimum_tokens_scheduler(self, req)

  L 316: event_loop(self)


CLASS: LoadBalanceMethod
----------------------------------------
  L  56: from_str(cls, method: str)


============================================================
FILE: python/sglang/srt/managers/detokenizer_manager.py
Functions: 10
============================================================

MODULE FUNCTIONS:
----------------------------------------
  L 277: def run_detokenizer_process(server_args: ServerArgs, port_args: PortArgs)


CLASS: DetokenizerManager
----------------------------------------
  L  73: __init__(self, server_args: ServerArgs, port_args: PortArgs)

  L 111: event_loop(self)
         üìù The event loop that handles requests

  L 119: trim_matched_stop(self, output: Union[str, List[int]], finished_reason: Dict, no_stop_trim: bool)

  L 145: handle_batch_embedding_out(self, recv_obj: BatchEmbeddingOut)

  L 149: handle_batch_token_id_out(self, recv_obj: BatchTokenIDOut)

  L 248: handle_multimodal_decode_req(self, recv_obj: BatchMultimodalDecodeReq)

  L 259: handle_freeze_gc_req(self, recv_req: FreezeGCReq)


CLASS: LimitedCapacityDict
----------------------------------------
  L 265: __init__(self, capacity: int)

  L 269: __setitem__(self, key, value)


============================================================
FILE: python/sglang/srt/managers/io_struct.py
Functions: 16
============================================================


CLASS: BatchTokenizedEmbeddingReqInput
----------------------------------------
  L 691: __len__(self)

  L 694: __getitem__(self, i)

  L 697: __iter__(self)


CLASS: BatchTokenizedGenerateReqInput
----------------------------------------
  L 541: __len__(self)

  L 544: __getitem__(self, i)

  L 547: __iter__(self)


CLASS: EmbeddingReqInput
----------------------------------------
  L 584: normalize_batch_and_arguments(self)

  L 635: regenerate_rid(self)

  L 639: contains_mm_input(self)
         ‚Üí bool

  L 646: __getitem__(self, i)


CLASS: GenerateReqInput
----------------------------------------
  L 131: contains_mm_input(self)
         ‚Üí bool

  L 138: normalize_batch_and_arguments(self)
         üìù Normalize the batch size and arguments for the request.
            This method resolves various input formats and ensures all parameters
            are properly formatted as either single values or batches depending on the input.
            It also handles parallel sampling expansion and sets default values for
            unspecified parameters.
            Raises:
            ValueError: If inputs are not properly specified (e.g., none or all of
            text, input_ids, input_embeds are provided)

  L 432: regenerate_rid(self)
         üìù Generate a new request ID and return it.

  L 437: __getitem__(self, i)


CLASS: LoadLoRAAdapterReqInput
----------------------------------------
  L1153: to_ref(self)
         ‚Üí LoRARef


CLASS: UnloadLoRAAdapterReqInput
----------------------------------------
  L1169: to_ref(self)
         ‚Üí LoRARef


============================================================
FILE: python/sglang/srt/managers/mm_utils.py
Functions: 20
============================================================

MODULE FUNCTIONS:
----------------------------------------
  L 290: def init_embedding_cache(max_size: int)

  L 295: def get_embedding_hash(embedding_items: List[MultimodalDataItem])
         ‚Üí int

  L 300: def get_embedding_chunk(embedding: torch.Tensor,
        extend_prefix_len: int,
        extend_seq_len: int,
        items_offset: List[Tuple[int,
        int]])
         ‚Üí Tuple[torch.Tensor, int, int]
         üìù Extract a chunk of embeddings based on the specified prefix length, sequence length, and offset ranges.
            Args:
            embedding: The full embedding tensor to extract a chunk from
            extend_prefix_len: The starting position (prefix length) for extraction
            extend_seq_len: The number of tokens to extract
            items_offset: List of [start, end] offset ranges for multimodal items in the input sequence
            Returns:
            A tuple containing:
            - The extracted embedding chunk as a tensor
            - The start index used for extraction
            - The end index used for extraction
            Note:
            If there's no overlap between the requested range and the offset ranges,
            an empty tensor is returned with zeros for start and end indices.

  L 449: def get_embedding_and_mask(data_embedding_func: Callable[[List[MultimodalDataItem]],
        torch.Tensor],
        embedding_items: List[MultimodalDataItem],
        placeholder_tensor: torch.Tensor,
        input_ids: torch.Tensor,
        items_size: List[int],
        prefix_length: List[int],
        extend_length: List[int],
        items_offset_list: List[List[Tuple[int,
        int]]])
         ‚Üí Tuple[torch.Tensor, torch.Tensor]
         üìù Generate multimodal embeddings and create a mask for identifying their positions in the input sequence.
            Args:
            data_embedding_func: Function that generates embeddings for multimodal items
            embedding_items: List of multimodal items to embed
            placeholder_tensor: Tensor containing token IDs that serve as placeholders for multimodal content
            input_ids: The input token IDs tensor
            items_size: Cumulative sizes of multimodal items per request
            prefix_length: Prefix lengths for each request
            extend_length: Sequence lengths for each request
            items_offset_list: List of offset ranges for multimodal items in each request
            Returns:
            A tuple containing:
            - The generated embeddings tensor
            - A boolean mask tensor indicating where these embeddings should be placed

  L 499: def embed_mm_inputs(mm_inputs_list: List[MultimodalInputs],
        extend_prefix_lens: List[int],
        extend_seq_lens: List[int],
        input_ids: torch.Tensor,
        input_embedding: nn.Embedding,
        multimodal_model: nn.Module,
        data_embedding_func_mapping: Dict[Modality,
        Callable[[List[MultimodalDataItem]],
        torch.Tensor]],
        placeholder_tokens: dict[Modality,
        List[int]])
         ‚Üí Optional[torch.Tensor]
         üìù Embed multimodal inputs and integrate them with text token embeddings.
            Args:
            mm_inputs_list: List of multimodal inputs to process
            extend_prefix_lens: Prefix lengths for each request
            extend_seq_lens: Sequence lengths for each request
            input_ids: Input token IDs tensor
            input_embedding: Embedding layer for text tokens
            placeholder_tokens: Token IDs for multimodal placeholders (uses pad_values if None)
            Returns:
            Combined embedding tensor with multimodal content integrated

  L 603: def general_mm_embed_routine(input_ids: torch.Tensor,
        forward_batch: ForwardBatch,
        language_model: nn.Module,
        multimodal_model: Optional[nn.Module],
        data_embedding_funcs: Dict[Modality,
        Callable[[List[MultimodalDataItem]],
        torch.Tensor]],
        placeholder_tokens: Optional[dict[Modality,
        List[int]]])
         ‚Üí torch.Tensor
         üìù Process multimodal inputs and forward through language model.
            Args:
            input_ids: Input token IDs tensor
            forward_batch: Batch information for model forward pass
            language_model: Base language model to use
            data_embedding_funcs: A dictionary mapping from modality type to the corresponding embedding function.
            placeholder_tokens: Token IDs for multimodal placeholders
            **kwargs: Additional arguments passed to language model
            Returns:
            Hidden states from language model forward pass

  L 672: def get_multimodal_data_bounds(input_ids: torch.Tensor,
        pad_values: List[int],
        token_pairs: List[Tuple[int,
        int]])
         ‚Üí torch.Tensor
         üìù Returns a tensor indicating the bounds of multimodal data (images, video, audio, etc.)
            Returns:
            [bounds_count, 2]

  L 732: def data_hash(data)
         ‚Üí int

  L 737: def tensor_hash(tensor_list)
         ‚Üí int
         üìù hash a tensor or a tensor list

  L 763: def hash_feature(f)


CLASS: MultiModalityDataPaddingPattern
----------------------------------------
  L 164: pad_input_tokens(self, input_ids: List[int], mm_inputs: MultimodalInputs)
         ‚Üí List[int]
         üìù Pad the input ids sequence containing data tokens, and replace them with pad_values


CLASS: MultiModalityDataPaddingPatternMultimodalTokens
----------------------------------------
  L 253: pad_input_tokens(self, input_ids: List[int], mm_inputs: MultimodalInputs)
         ‚Üí List[int]
         üìù Replaces multimodal tokens in input_ids with corresponding pad_values from mm_items.
            Each modality (image, audio, video) is handled separately based on its token_id.


CLASS: MultiModalityDataPaddingPatternTokenPairs
----------------------------------------
  L 181: __init__(self, data_token_pairs: Optional[List[Tuple[int, int]]], data_start_token_ids: Optional[List[int]])
         ‚Üí None
         üìù Args:
            data_start_token_ids marks the start of a single multimodal data
            See Minicpmo's slice_start_id for example

  L 197: pad_input_tokens(self, input_ids: List[int], mm_inputs: MultimodalInputs)
         ‚Üí List[int]
         üìù This function will replace the data-tokens in between with pad_values accordingly


CLASS: TransportProxyTensor
----------------------------------------
  L  45: __new__(cls, data: torch.Tensor, name: Optional[str], fields: Optional[Dict[str, Any]], transport_mode: TensorTransportMode)

  L  70: __getstate__(self)
         üìù Called during pickling. Implements the serialization logic.

  L 106: __setstate__(self, state: Dict[str, Any])
         üìù Called during unpickling. Implements the deserialization logic.

  L 144: name(self)
         ‚Üí Optional[str]

  L 148: fields(self)
         ‚Üí Dict[str, Any]

  L 152: transport_mode(self)
         ‚Üí TensorTransportMode


============================================================
FILE: python/sglang/srt/managers/multimodal_processor.py
Functions: 2
============================================================

MODULE FUNCTIONS:
----------------------------------------
  L  15: def import_processors()

  L  39: def get_mm_processor(hf_config,
        server_args: ServerArgs,
        processor,
        transport_mode)
         ‚Üí BaseMultimodalProcessor


============================================================
FILE: python/sglang/srt/managers/schedule_batch.py
Functions: 72
============================================================

MODULE FUNCTIONS:
----------------------------------------
  L1927: def write_req_to_token_pool_triton(req_to_token_ptr,
        req_pool_indices,
        pre_lens,
        seq_lens,
        extend_lens,
        out_cache_loc,
        req_to_token_ptr_stride: tl.constexpr)
         @triton.jit

  L1963: def get_last_loc(req_to_token: torch.Tensor,
        req_pool_indices_tensor: torch.Tensor,
        prefix_lens_tensor: torch.Tensor)
         ‚Üí torch.Tensor

  L1979: def get_last_loc_torch(req_to_token: torch.Tensor,
        req_pool_indices_tensor: torch.Tensor,
        prefix_lens_tensor: torch.Tensor)
         ‚Üí torch.Tensor

  L1992: def get_last_loc_kernel(req_to_token,
        req_pool_indices_tensor,
        prefix_lens_tensor,
        result,
        num_tokens,
        req_to_token_stride,
        BLOCK_SIZE: tl.constexpr)
         @triton.jit

  L2015: def get_last_loc_triton(req_to_token: torch.Tensor,
        req_pool_indices_tensor: torch.Tensor,
        prefix_lens_tensor: torch.Tensor)
         ‚Üí torch.Tensor


CLASS: BaseFinishReason
----------------------------------------
  L 120: __init__(self, is_error: bool)

  L 123: to_json(self)


CLASS: FINISH_ABORT
----------------------------------------
  L 164: __init__(self, message, status_code, err_type)

  L 170: to_json(self)


CLASS: FINISH_LENGTH
----------------------------------------
  L 152: __init__(self, length: int)

  L 156: to_json(self)


CLASS: FINISH_MATCHED_STR
----------------------------------------
  L 140: __init__(self, matched: str)

  L 144: to_json(self)


CLASS: FINISH_MATCHED_TOKEN
----------------------------------------
  L 128: __init__(self, matched: Union[int, List[int]])

  L 132: to_json(self)


CLASS: Modality
----------------------------------------
  L 186: from_str(modality_str: str)

  L 195: all()


CLASS: MultimodalDataItem
----------------------------------------
  L 223: __getattr__(self, name: str)

  L 234: __setitem__(self, key: str, value: Any)

  L 240: set(self, key: str, value: Any)

  L 244: is_empty_list(l)

  L 249: set_pad_value(self)
         üìù Set the pad value after first hashing the data

  L 264: is_modality(self, modality: Modality)
         ‚Üí bool

  L 267: is_audio(self)

  L 270: is_image(self)

  L 273: is_video(self)

  L 276: is_valid(self)
         ‚Üí bool

  L 279: validate(self)

  L 284: from_dict(obj: dict)

  L 293: merge(self, other)


CLASS: MultimodalInputs
----------------------------------------
  L 329: from_dict(obj: dict)

  L 358: contains_image_inputs(self)
         ‚Üí bool

  L 361: contains_video_inputs(self)
         ‚Üí bool

  L 364: contains_audio_inputs(self)
         ‚Üí bool

  L 367: contains_mm_input(self)
         ‚Üí bool

  L 370: merge(self, other: MultimodalInputs)
         üìù merge image inputs when requests are being merged


CLASS: Req
----------------------------------------
  L 414: __init__(self, rid: str, origin_input_text: str, origin_input_ids: List[int], sampling_params: SamplingParams, return_logprob: bool, top_logprobs_num: int, token_ids_logprob: List[int], stream: bool, origin_input_ids_unpadded: Optional[Tuple[int]], lora_id: Optional[str], input_embeds: Optional[List[List[float]]], token_type_ids: List[int], session_id: Optional[str], custom_logit_processor: Optional[str], return_hidden_states: bool, eos_token_ids: Optional[Set[int]], bootstrap_host: Optional[str], bootstrap_port: Optional[int], bootstrap_room: Optional[int], data_parallel_rank: Optional[int], vocab_size: Optional[int])

  L 619: seqlen(self)

  L 622: extend_image_inputs(self, image_inputs)

  L 628: finished(self)
         ‚Üí bool

  L 632: init_next_round_input(self, tree_cache: Optional[BasePrefixCache])

  L 660: adjust_max_prefix_ids(self)

  L 679: init_incremental_detokenize(self)

  L 691: check_finished(self)

  L 751: reset_for_retract(self)

  L 765: offload_kv_cache(self, req_to_token_pool, token_to_kv_pool_allocator)

  L 771: load_kv_cache(self, req_to_token_pool, token_to_kv_pool_allocator)

  L 778: log_time_stats(self)

  L 790: set_finish_with_abort(self, error_msg: str)

  L 801: __repr__(self)


CLASS: ScheduleBatch
----------------------------------------
  L 917: init_new(cls, reqs: List[Req], req_to_token_pool: ReqToTokenPool, token_to_kv_pool_allocator: BaseTokenToKVPoolAllocator, tree_cache: BasePrefixCache, model_config: ModelConfig, enable_overlap: bool, spec_algorithm: SpeculativeAlgorithm, chunked_req: Optional[Req])

  L 959: batch_size(self)

  L 962: is_empty(self)

  L 965: alloc_req_slots(self, num_reqs: int)

  L 976: alloc_token_slots(self, num_tokens: int, backup_state: bool)

  L1000: alloc_paged_token_slots_extend(self, prefix_lens: torch.Tensor, seq_lens: torch.Tensor, last_loc: torch.Tensor, extend_num_tokens: int, backup_state: bool)

  L1035: alloc_paged_token_slots_decode(self, seq_lens: torch.Tensor, last_loc: torch.Tensor, backup_state: bool)

  L1063: prepare_encoder_info_extend(self, input_ids: List[int], seq_lens: List[int])

  L1136: prepare_for_extend(self)

  L1340: prepare_for_split_prefill(self)

  L1345: mix_with_running(self, running_batch: 'ScheduleBatch')

  L1375: new_page_count_next_decode(self)

  L1387: check_decode_mem(self, buf_multiplier)

  L1397: retract_decode(self, server_args: ServerArgs)
         üìù Retract the decoding requests when there is not enough memory.

  L1521: prepare_encoder_info_decode(self)

  L1525: prepare_for_idle(self)

  L1539: prepare_for_decode(self)

  L1613: filter_batch(self, chunked_req_to_exclude: Optional[Union[Req, List[Req]]], keep_indices: Optional[List[int]])

  L1671: merge_batch(self, other: 'ScheduleBatch')

  L1711: get_model_worker_batch(self, seq_lens_cpu_cache: Optional[torch.Tensor])
         ‚Üí ModelWorkerBatch

  L1785: copy(self)

  L1846: __str__(self)


============================================================
FILE: python/sglang/srt/managers/schedule_policy.py
Functions: 10
============================================================


CLASS: PrefillAdder
----------------------------------------
  L 272: __init__(self, page_size: int, tree_cache: BasePrefixCache, token_to_kv_pool_allocator: BaseTokenToKVPoolAllocator, running_batch: ScheduleBatch, new_token_ratio: float, rem_input_tokens: int, rem_chunk_tokens: Optional[int], mixed_with_decode_tokens: int)

  L 320: rem_total_tokens(self)

  L 337: cur_rem_tokens(self)

  L 353: ceil_paged_tokens(self, tokens: int)
         ‚Üí int

  L 356: budget_state(self)

  L 382: add_chunked_req(self, req: Req)

  L 415: add_one_req_ignore_eos(self, req: Req, has_chunked_req: bool)

  L 497: add_one_req(self, req: Req, has_chunked_req: bool)


CLASS: SchedulePolicy
----------------------------------------
  L  80: __init__(self, policy: str, tree_cache: BasePrefixCache, enable_hierarchical_cache: bool)

  L  98: calc_priority(self, waiting_queue: List[Req])
         ‚Üí bool


============================================================
FILE: python/sglang/srt/managers/scheduler.py
Functions: 54
============================================================

MODULE FUNCTIONS:
----------------------------------------
  L2571: def is_health_check_generate_req(recv_req)

  L2575: def is_work_request(recv_req)

  L2587: def run_scheduler_process(server_args: ServerArgs,
        port_args: PortArgs,
        gpu_id: int,
        tp_rank: int,
        moe_ep_rank: int,
        pp_rank: int,
        dp_rank: Optional[int],
        pipe_writer,
        balance_meta: Optional[DPBalanceMeta])


CLASS: IdleSleeper
----------------------------------------
  L2554: __init__(self, sockets)

  L2560: maybe_sleep(self)


CLASS: Scheduler
----------------------------------------
  L 205: __init__(self, server_args: ServerArgs, port_args: PortArgs, gpu_id: int, tp_rank: int, moe_ep_rank: int, pp_rank: int, dp_rank: Optional[int], dp_balance_meta: Optional[DPBalanceMeta])

  L 555: init_tokenizer(self)

  L 579: init_memory_pool_and_cache(self)

  L 687: init_disaggregation(self)

  L 780: init_moe_config(self)

  L 785: event_loop_normal(self)
         üìù A normal scheduler loop.

  L 804: event_loop_overlap(self)
         üìù A scheduler loop that overlaps the CPU processing and GPU computation.

  L 847: event_loop_pp(self)
         üìù A non-overlap scheduler loop for pipeline parallelism.

  L 979: recv_requests(self)
         ‚Üí List[Req]
         üìù Receive results at tp_rank = 0 and broadcast it to all other TP ranks.

  L1080: process_input_requests(self, recv_reqs: List)

  L1112: handle_generate_request(self, recv_req: TokenizedGenerateReqInput)

  L1277: handle_batch_generate_request(self, recv_req: BatchTokenizedGenerateReqInput)
         üìù Handle optimized batch generate request.

  L1325: handle_embedding_request(self, recv_req: TokenizedEmbeddingReqInput)

  L1371: handle_batch_embedding_request(self, recv_req: BatchTokenizedEmbeddingReqInput)
         üìù Handle optimized batch embedding request.

  L1384: self_check_during_idle(self)

  L1390: check_memory(self)

  L1467: check_tree_cache(self)

  L1502: get_next_batch_to_run(self)
         ‚Üí Optional[ScheduleBatch]

  L1567: get_num_allocatable_reqs(self, running_bs)

  L1573: get_new_batch_prefill(self)
         ‚Üí Optional[ScheduleBatch]

  L1725: update_running_batch(self, batch: ScheduleBatch)
         ‚Üí Optional[ScheduleBatch]
         üìù Update the current running decoding batch.

  L1765: run_batch(self, batch: ScheduleBatch)
         ‚Üí Union[GenerationBatchResult, EmbeddingBatchResult]
         üìù Run a batch.

  L1846: process_batch_result(self, batch: ScheduleBatch, result: Union[GenerationBatchResult, EmbeddingBatchResult], launch_done: Optional[threading.Event])

  L1865: maybe_send_health_check_signal(self)

  L1873: prepare_mlp_sync_batch(self, local_batch: ScheduleBatch)

  L1887: handle_dp_balance_data(self, local_batch: ScheduleBatch)

  L1968: prepare_mlp_sync_batch_raw(local_batch: ScheduleBatch, dp_size, attn_tp_size: int, tp_group, get_idle_batch, disable_cuda_graph: bool, spec_algorithm, speculative_num_draft_tokens, require_mlp_tp_gather: bool, disable_overlap_schedule: bool)

  L2071: get_idle_batch(self)

  L2084: move_ready_grammar_requests(self)
         üìù Move requests whose grammar objects are ready from grammar_queue to waiting_queue.

  L2149: set_next_batch_sampling_info_done(self, batch: ScheduleBatch)

  L2156: watchdog_thread(self)
         üìù A watch dog thread that will try to kill the server itself if one forward batch takes too long.

  L2209: flush_cache_wrapped(self, recv_req: FlushCacheReqInput)

  L2213: clear_hicache_storage_wrapped(self, recv_req: ClearHiCacheReqInput)

  L2223: flush_cache(self)
         üìù Flush the memory pool and cache.

  L2260: get_load(self)

  L2294: get_internal_state(self, recv_req: GetInternalStateReq)

  L2323: set_internal_state(self, recv_req: SetInternalStateReq)

  L2361: handle_rpc_request(self, recv_req: RpcReqInput)

  L2380: abort_request(self, recv_req: AbortReq)

  L2461: load_lora_adapter(self, recv_req: LoadLoRAAdapterReqInput)
         ‚Üí LoadLoRAAdapterReqOutput
         üìù In-place loading a new lora adapter from disk or huggingface.

  L2469: unload_lora_adapter(self, recv_req: UnloadLoRAAdapterReqInput)
         ‚Üí UnloadLoRAAdapterReqOutput
         üìù Unload the lora adapter.

  L2477: slow_down(self, recv_req: SlowDownReqInput)

  L2484: expert_distribution_handle(self, recv_req: ExpertDistributionReq)

  L2495: open_session(self, recv_req: OpenSessionReqInput)

  L2510: close_session(self, recv_req: CloseSessionReqInput)

  L2518: get_print_prefix(self)

  L2528: current_scheduler_metrics_enabled(self)

  L2531: maybe_sleep_on_idle(self)

  L2535: handle_freeze_gc(self, recv_req: FreezeGCReq)
         üìù Handle freeze_gc request: freeze scheduler's GC and forward to detokenizer.


============================================================
FILE: python/sglang/srt/managers/scheduler_input_blocker.py
Functions: 3
============================================================

MODULE FUNCTIONS:
----------------------------------------
  L 101: def input_blocker_guard_region(send_to_scheduler)
         @contextmanager


CLASS: SchedulerInputBlocker
----------------------------------------
  L  26: __init__(self, noop: bool)

  L  32: handle(self, recv_reqs: Optional[List[Any]])


============================================================
FILE: python/sglang/srt/managers/scheduler_metrics_mixin.py
Functions: 5
============================================================


CLASS: KvMetrics
----------------------------------------
  L  19: __init__(self)


CLASS: SchedulerMetricsMixin
----------------------------------------
  L  31: init_metrics(self, tp_rank: int, pp_rank: int, dp_rank: Optional[int])

  L  53: init_kv_events(self, kv_events_config: Optional[str])

  L  59: log_prefill_stats(self, adder: PrefillAdder, can_run_list: List[Req], running_bs: int)

  L 140: log_decode_stats(self, can_run_cuda_graph: bool, running_batch: ScheduleBatch)


============================================================
FILE: python/sglang/srt/managers/scheduler_output_processor_mixin.py
Functions: 7
============================================================


CLASS: SchedulerOutputProcessorMixin
----------------------------------------
  L  32: process_batch_result_prefill(self: Scheduler, batch: ScheduleBatch, result: Union[GenerationBatchResult, EmbeddingBatchResult], launch_done: Optional[threading.Event])

  L 196: process_batch_result_decode(self: Scheduler, batch: ScheduleBatch, result: GenerationBatchResult, launch_done: Optional[threading.Event])

  L 300: add_input_logprob_return_values(self: Scheduler, i: int, req: Req, output: LogitsProcessorOutput, logprob_pt: int, num_input_logprobs: int, last_prefill_chunk: bool)
         üìù Incrementally add input logprobs to `req`.
            Args:
            i: The request index in a batch.
            req: The request. Input logprobs inside req are modified as a
            consequence of the API
            fill_ids: The prefill ids processed.
            output: Logit processor output that's used to compute input logprobs
            last_prefill_chunk: True if it is the last prefill (when chunked).
            Some of input logprob operation should only happen at the last
            prefill (e.g., computing input token logprobs).

  L 434: add_logprob_return_values(self: Scheduler, i: int, req: Req, pt: int, next_token_ids: List[int], num_input_logprobs: int, output: LogitsProcessorOutput)
         üìù Attach logprobs to the return values.

  L 465: stream_output(self: Scheduler, reqs: List[Req], return_logprob: bool, skip_req: Optional[Req])
         üìù Stream the output to detokenizer.

  L 477: stream_output_generation(self: Scheduler, reqs: List[Req], return_logprob: bool, skip_req: Optional[Req])

  L 706: stream_output_embedding(self: Scheduler, reqs: List[Req])


============================================================
FILE: python/sglang/srt/managers/scheduler_profiler_mixin.py
Functions: 5
============================================================


CLASS: SchedulerProfilerMixin
----------------------------------------
  L  29: init_profier(self)

  L  45: init_profile(self, output_dir: Optional[str], start_step: Optional[int], num_steps: Optional[int], activities: Optional[List[str]], with_stack: Optional[bool], record_shapes: Optional[bool], profile_by_stage: bool, profile_id: str)
         ‚Üí ProfileReqOutput

  L  97: start_profile(self, stage: Optional[ForwardMode])
         ‚Üí ProfileReqOutput | None

  L 172: stop_profile(self, stage: Optional[ForwardMode])
         ‚Üí ProfileReqOutput | None

  L 273: profile(self, recv_req: ProfileReq)


============================================================
FILE: python/sglang/srt/managers/scheduler_recv_skipper.py
Functions: 3
============================================================


CLASS: SchedulerRecvSkipper
----------------------------------------
  L   7: maybe_create(server_args: ServerArgs)

  L  12: __init__(self, server_args: ServerArgs)

  L  18: handle(self, last_forward_mode: ForwardMode)


============================================================
FILE: python/sglang/srt/managers/scheduler_update_weights_mixin.py
Functions: 9
============================================================


CLASS: SchedulerUpdateWeightsMixin
----------------------------------------
  L  29: update_weights_from_disk(self, recv_req: UpdateWeightFromDiskReqInput)
         üìù In-place update of the weights from disk.

  L  39: init_weights_update_group(self, recv_req: InitWeightsUpdateGroupReqInput)
         üìù Initialize the online model parameter update group.

  L  44: update_weights_from_distributed(self, recv_req: UpdateWeightsFromDistributedReqInput)
         ‚Üí Tuple[bool, str]
         üìù Update the online model parameter.

  L  58: update_weights_from_tensor(self, recv_req: UpdateWeightsFromTensorReqInput)
         üìù Update the online model parameter from tensors.

  L  71: get_weights_by_name(self, recv_req: GetWeightsByNameReqInput)

  L  75: release_memory_occupation(self, recv_req: ReleaseMemoryOccupationReqInput)

  L  97: resume_memory_occupation(self, recv_req: ResumeMemoryOccupationReqInput)

  L 120: save_remote_model(self, params)

  L 134: save_sharded_model(self, params)


============================================================
FILE: python/sglang/srt/managers/session_controller.py
Functions: 7
============================================================


CLASS: Session
----------------------------------------
  L  63: __init__(self, capacity_of_str_len: int, session_id: Optional[str])

  L  68: create_req(self, req: TokenizedGenerateReqInput, tokenizer)


CLASS: SessionReqNode
----------------------------------------
  L  22: __init__(self, req, parent, childs)

  L  29: clear_childs(self, req_dict)

  L  34: clear(self, req_dict)

  L  42: abort(self)

  L  46: __str__(self)


============================================================
FILE: python/sglang/srt/managers/template_manager.py
Functions: 9
============================================================


CLASS: TemplateManager
----------------------------------------
  L  54: __init__(self)

  L  61: chat_template_name(self)
         ‚Üí Optional[str]
         üìù Get the current chat template name.

  L  66: completion_template_name(self)
         ‚Üí Optional[str]
         üìù Get the current completion template name.

  L  71: jinja_template_content_format(self)
         ‚Üí Optional[str]
         üìù Get the detected template content format ('string' or 'openai' or None).

  L  76: force_reasoning(self)
         ‚Üí bool
         üìù Check if the current chat template enforces reasoning/thinking.
            Returns:
            True if the template contains reasoning patterns like <think> tags

  L 101: load_chat_template(self, tokenizer_manager, chat_template_arg: Optional[str], model_path: str)
         ‚Üí None
         üìù Load a chat template from various sources.
            Args:
            tokenizer_manager: The tokenizer manager instance
            chat_template_arg: Template name, file path, or None to auto-detect
            model_path: Path to the model

  L 166: guess_chat_template_from_model_path(self, model_path: str)
         ‚Üí None
         üìù Infer chat template name from model path.
            Args:
            model_path: Path to the model

  L 178: load_completion_template(self, completion_template_arg: str)
         ‚Üí None
         üìù Load completion template for code completion.
            Args:
            completion_template_arg: Template name or file path

  L 198: initialize_templates(self, tokenizer_manager, model_path: str, chat_template: Optional[str], completion_template: Optional[str])
         ‚Üí None
         üìù Initialize all templates based on provided configuration.
            Args:
            tokenizer_manager: The tokenizer manager instance
            model_path: Path to the model
            chat_template: Optional chat template name/path
            completion_template: Optional completion template name/path


============================================================
FILE: python/sglang/srt/managers/tokenizer_manager.py
Functions: 49
============================================================

MODULE FUNCTIONS:
----------------------------------------
  L2079: async def print_exception_wrapper(func)
         üìù Sometimes an asyncio function does not print exception.
            We do another wrapper to handle the exception.


CLASS: SignalHandler
----------------------------------------
  L2096: __init__(self, tokenizer_manager: TokenizerManager)

  L2099: sigterm_handler(self, signum, frame)

  L2105: running_phase_sigquit_handler(self, signum, frame)


CLASS: TokenizerManager
----------------------------------------
  L 184: __init__(self, server_args: ServerArgs, port_args: PortArgs)

  L 491: generate_request(self, obj: Union[GenerateReqInput, EmbeddingReqInput], request: Optional[fastapi.Request])

  L 997: flush_cache(self)
         ‚Üí FlushCacheReqOutput

  L1000: clear_hicache_storage(self)
         ‚Üí ClearHiCacheReqOutput
         üìù Clear the hierarchical cache storage.

  L1007: abort_request(self, rid: str, abort_all: bool)

  L1016: start_profile(self, output_dir: Optional[str], start_step: Optional[int], num_steps: Optional[int], activities: Optional[List[str]], with_stack: Optional[bool], record_shapes: Optional[bool], profile_by_stage: bool)

  L1042: stop_profile(self)

  L1053: start_expert_distribution_record(self)

  L1057: stop_expert_distribution_record(self)

  L1061: dump_expert_distribution_record(self)

  L1065: pause_generation(self)

  L1070: continue_generation(self)

  L1075: update_weights_from_disk(self, obj: UpdateWeightFromDiskReqInput, request: Optional[fastapi.Request])
         ‚Üí Tuple[bool, str]

  L1123: init_weights_update_group(self, obj: InitWeightsUpdateGroupReqInput, request: Optional[fastapi.Request])
         ‚Üí Tuple[bool, str]

  L1135: update_weights_from_distributed(self, obj: UpdateWeightsFromDistributedReqInput, request: Optional[fastapi.Request])
         ‚Üí Tuple[bool, str]

  L1154: update_weights_from_tensor(self, obj: UpdateWeightsFromTensorReqInput, request: Optional[fastapi.Request])
         ‚Üí Tuple[bool, str]

  L1173: load_lora_adapter(self, obj: LoadLoRAAdapterReqInput, _: Optional[fastapi.Request])
         ‚Üí LoadLoRAAdapterReqOutput

  L1231: unload_lora_adapter(self, obj: UnloadLoRAAdapterReqInput, _: Optional[fastapi.Request])
         ‚Üí UnloadLoRAAdapterReqOutput

  L1273: get_weights_by_name(self, obj: GetWeightsByNameReqInput, request: Optional[fastapi.Request])

  L1284: release_memory_occupation(self, obj: ReleaseMemoryOccupationReqInput, request: Optional[fastapi.Request])

  L1292: resume_memory_occupation(self, obj: ResumeMemoryOccupationReqInput, request: Optional[fastapi.Request])

  L1300: slow_down(self, obj: SlowDownReqInput, request: Optional[fastapi.Request])

  L1308: open_session(self, obj: OpenSessionReqInput, request: Optional[fastapi.Request])

  L1325: close_session(self, obj: CloseSessionReqInput, request: Optional[fastapi.Request])

  L1330: get_internal_state(self)
         ‚Üí List[Dict[Any, Any]]

  L1338: set_internal_state(self, obj: SetInternalStateReq)
         ‚Üí List[bool]

  L1344: get_load(self)
         ‚Üí dict

  L1352: get_log_request_metadata(self)

  L1406: configure_logging(self, obj: ConfigureLoggingReq)

  L1420: freeze_gc(self)
         üìù Send a freeze_gc message to the scheduler first, then freeze locally.

  L1426: create_abort_task(self, obj: GenerateReqInput)

  L1440: auto_create_handle_loop(self)

  L1471: dump_requests_before_crash(self)

  L1554: sigterm_watchdog(self)

  L1591: handle_loop(self)
         üìù The event loop that handles requests

  L1704: convert_logprob_style(self, meta_info: dict, state: ReqState, top_logprobs_num: int, token_ids_logprob: List[int], return_text_in_logprobs: bool, recv_obj: BatchStrOut, recv_obj_index: int)

  L1793: detokenize_logprob_tokens(self, token_logprobs_val: List[float], token_logprobs_idx: List[int], decode_to_text: bool)

  L1809: detokenize_top_logprobs_tokens(self, token_logprobs_val: List[float], token_logprobs_idx: List[int], decode_to_text: bool)

  L1829: collect_metrics(self, state: ReqState, recv_obj: BatchStrOut, i: int)

  L1872: dump_requests(self, state: ReqState, out_dict: dict)

  L1889: record_request_for_crash_dump(self, state: ReqState, out_dict: dict)

  L1959: score_request(self, query: Optional[Union[str, List[int]]], items: Optional[Union[str, List[str], List[List[int]]]], label_token_ids: Optional[List[int]], apply_softmax: bool, item_first: bool, request: Optional[Any])
         ‚Üí List[List[float]]
         üìù See Engine.score() for more details.


CLASS: _Communicator
----------------------------------------
  L2119: __init__(self, sender, fan_out: int)

  L2126: __call__(self, obj)

  L2148: handle_recv(self, recv_obj: T)


============================================================
FILE: python/sglang/srt/managers/tp_worker.py
Functions: 22
============================================================


CLASS: TpModelWorker
----------------------------------------
  L  54: __init__(self, server_args: ServerArgs, gpu_id: int, tp_rank: int, moe_ep_rank: int, pp_rank: int, dp_rank: Optional[int], nccl_port: int, is_draft_worker: bool, req_to_token_pool: Optional[ReqToTokenPool], token_to_kv_pool_allocator: Optional[BaseTokenToKVPoolAllocator])

  L 165: register_hicache_layer_transfer_counter(self, counter)

  L 168: set_hicache_consumer(self, consumer_index)

  L 172: get_worker_info(self)

  L 189: sliding_window_size(self)
         ‚Üí Optional[int]

  L 193: is_hybrid(self)
         ‚Üí bool

  L 196: get_tokens_per_layer_info(self)

  L 202: get_pad_input_ids_func(self)

  L 205: get_tp_group(self)

  L 208: get_attention_tp_group(self)

  L 211: get_attention_tp_cpu_group(self)

  L 214: get_memory_pool(self)

  L 220: forward_batch_generation(self, model_worker_batch: ModelWorkerBatch, launch_done: Optional[threading.Event], skip_sample: bool)
         ‚Üí Tuple[Union[LogitsProcessorOutput, torch.Tensor], Optional[torch.Tensor], bool]

  L 260: forward_batch_embedding(self, model_worker_batch: ModelWorkerBatch)

  L 266: update_weights_from_disk(self, recv_req: UpdateWeightFromDiskReqInput)

  L 272: init_weights_update_group(self, recv_req: InitWeightsUpdateGroupReqInput)

  L 283: update_weights_from_distributed(self, recv_req: UpdateWeightsFromDistributedReqInput)

  L 291: update_weights_from_tensor(self, recv_req: UpdateWeightsFromTensorReqInput)

  L 302: get_weights_by_name(self, recv_req: GetWeightsByNameReqInput)

  L 308: load_lora_adapter(self, recv_req: LoadLoRAAdapterReqInput)

  L 312: unload_lora_adapter(self, recv_req: UnloadLoRAAdapterReqInput)

  L 316: can_run_lora_batch(self, lora_ids: list[str])
         ‚Üí bool


============================================================
FILE: python/sglang/srt/managers/tp_worker_overlap_thread.py
Functions: 27
============================================================

MODULE FUNCTIONS:
----------------------------------------
  L  45: def resolve_future_token_ids(input_ids, future_token_ids_map)
         @torch.compile(dynamic=True, backend=get_compiler_backend())


CLASS: TpModelWorkerClient
----------------------------------------
  L  56: __init__(self, server_args: ServerArgs, gpu_id: int, tp_rank: int, moe_ep_rank: int, pp_rank: int, dp_rank: Optional[int], nccl_port: int)

  L  96: register_hicache_layer_transfer_counter(self, counter)

  L  99: set_hicache_consumer(self, consumer_index)

  L 103: get_worker_info(self)

  L 106: get_tokens_per_layer_info(self)

  L 110: sliding_window_size(self)
         ‚Üí Optional[int]

  L 114: is_hybrid(self)
         ‚Üí bool

  L 117: get_pad_input_ids_func(self)

  L 120: get_tp_group(self)

  L 123: get_attention_tp_group(self)

  L 126: get_attention_tp_cpu_group(self)

  L 129: get_memory_pool(self)

  L 135: get_kv_cache(self)

  L 138: forward_thread_func(self)

  L 148: forward_thread_func_(self)

  L 207: resolve_last_batch_result(self, launch_done: Optional[threading.Event])
         üìù This function is called to resolve the last batch result and
            wait for the current batch to be launched. Used in overlap mode.

  L 231: forward_batch_generation(self, model_worker_batch: ModelWorkerBatch)
         ‚Üí Tuple[None, torch.Tensor, bool]

  L 264: update_weights_from_disk(self, recv_req: UpdateWeightFromDiskReqInput)

  L 268: init_weights_update_group(self, recv_req: InitWeightsUpdateGroupReqInput)

  L 272: update_weights_from_distributed(self, recv_req: UpdateWeightsFromDistributedReqInput)

  L 278: update_weights_from_tensor(self, recv_req: UpdateWeightsFromTensorReqInput)

  L 282: get_weights_by_name(self, recv_req: GetWeightsByNameReqInput)

  L 285: load_lora_adapter(self, recv_req: LoadLoRAAdapterReqInput)

  L 288: unload_lora_adapter(self, recv_req: UnloadLoRAAdapterReqInput)

  L 291: can_run_lora_batch(self, lora_ids: list[str])
         ‚Üí bool

  L 294: __delete__(self)


============================================================
FILE: python/sglang/srt/managers/utils.py
Functions: 11
============================================================

MODULE FUNCTIONS:
----------------------------------------
  L  18: def validate_input_length(req: Req,
        max_req_input_len: int,
        allow_auto_truncate: bool)
         ‚Üí Optional[str]
         üìù Validate and potentially truncate input length.
            Args:
            req: The request containing input_ids to validate
            max_req_input_len: Maximum allowed input length
            allow_auto_truncate: Whether to truncate long inputs
            Returns:
            Error message if validation fails, None if successful

  L  51: def get_logprob_dict_from_result(result: GenerationBatchResult)
         ‚Üí dict

  L  72: def get_logprob_from_pp_outputs(next_pp_outputs: PPProxyTensors)
         ‚Üí tuple[LogitsProcessorOutput, list[int], list[int]]


CLASS: DPBalanceMeta
----------------------------------------
  L 107: __init__(self, num_workers: int)

  L 119: destructor(self)

  L 123: get_shared_onfly(self)
         ‚Üí List[Dict[int, int]]

  L 126: set_shared_onfly_info(self, data: List[Dict[int, int]])

  L 129: get_shared_local_tokens(self)
         ‚Üí List[int]

  L 132: set_shared_local_tokens(self, data: List[int])

  L 135: __getstate__(self)

  L 140: __setstate__(self, state)


============================================================
FILE: python/sglang/srt/mem_cache/allocator.py
Functions: 48
============================================================

MODULE FUNCTIONS:
----------------------------------------
  L 291: def alloc_extend_kernel(pre_lens_ptr,
        seq_lens_ptr,
        last_loc_ptr,
        free_page_ptr,
        out_indices,
        ret_values,
        bs_upper: tl.constexpr,
        page_size: tl.constexpr,
        max_num_extend_tokens: tl.constexpr)
         @triton.jit

  L 379: def alloc_decode_kernel(seq_lens_ptr,
        last_loc_ptr,
        free_page_ptr,
        out_indices,
        ret_values,
        bs_upper: tl.constexpr,
        page_size: tl.constexpr)
         @triton.jit


CLASS: BaseTokenToKVPoolAllocator
----------------------------------------
  L  38: __init__(self, size: int, page_size: int, dtype: torch.dtype, device: str, kvcache: KVCache, need_sort: bool)

  L  59: debug_print(self)
         ‚Üí str

  L  62: available_size(self)

  L  65: get_kvcache(self)

  L  68: restore_state(self, state)

  L  71: backup_state(self)

  L  74: free_group_begin(self)

  L  78: free_group_end(self)

  L  83: merge_and_sort_free(self)

  L  91: get_cpu_copy(self)

  L  95: load_cpu_copy(self)

  L  99: alloc_extend(self)

  L 102: alloc_decode(self)

  L 106: clear(self)

  L 110: alloc(self, need_size: int)

  L 114: free(self, free_index: torch.Tensor)


CLASS: PagedTokenToKVPoolAllocator
----------------------------------------
  L 429: __init__(self, size: int, page_size: int, dtype: torch.dtype, device: str, kvcache: KVCache, need_sort: bool)

  L 445: alloc(self, need_size: int)

  L 468: alloc_extend(self, prefix_lens: torch.Tensor, seq_lens: torch.Tensor, last_loc: torch.Tensor, extend_num_tokens: int)

  L 517: alloc_decode(self, seq_lens: torch.Tensor, last_loc: torch.Tensor)

  L 552: free(self, free_index: torch.Tensor)

  L 568: clear(self)

  L 577: get_cpu_copy(self, indices)

  L 580: load_cpu_copy(self, kv_cache_cpu, indices)


CLASS: SWATokenToKVPoolAllocator
----------------------------------------
  L 178: __init__(self, size: int, size_swa: int, dtype: torch.dtype, device: str, kvcache: SWAKVPool, need_sort: bool)

  L 214: available_size(self)

  L 217: full_available_size(self)

  L 220: swa_available_size(self)

  L 224: size_full(self)

  L 228: size_swa(self)

  L 231: debug_print(self)
         ‚Üí str

  L 239: get_kvcache(self)

  L 242: translate_loc_from_full_to_swa(self, kv_indices: torch.Tensor)

  L 246: alloc(self, need_size: int)

  L 257: free(self, free_index: torch.Tensor)

  L 270: free_swa(self, free_index: torch.Tensor)

  L 276: backup_state(self)

  L 279: restore_state(self, state)

  L 282: clear(self)


CLASS: TokenToKVPoolAllocator
----------------------------------------
  L 121: __init__(self, size: int, dtype: torch.dtype, device: str, kvcache: KVCache, need_sort: bool)

  L 132: clear(self)

  L 141: available_size(self)

  L 145: alloc(self, need_size: int)

  L 156: free(self, free_index: torch.Tensor)

  L 168: get_cpu_copy(self, indices)

  L 171: load_cpu_copy(self, kv_cache_cpu, indices)


============================================================
FILE: python/sglang/srt/mem_cache/allocator_ascend.py
Functions: 3
============================================================

MODULE FUNCTIONS:
----------------------------------------
  L  13: def alloc_extend_kernel_ascend(prefix_lens,
        seq_lens,
        last_loc,
        free_pages,
        out_indices,
        page_size,
        device)


CLASS: AscendPagedTokenToKVPoolAllocator
----------------------------------------
  L  69: alloc_extend(self, prefix_lens: torch.Tensor, seq_lens: torch.Tensor, last_loc: torch.Tensor, extend_num_tokens: int)

  L 115: alloc_decode(self, seq_lens: torch.Tensor, last_loc: torch.Tensor)


============================================================
FILE: python/sglang/srt/mem_cache/base_prefix_cache.py
Functions: 19
============================================================


CLASS: BasePrefixCache
----------------------------------------
  L  35: reset(self)

  L  39: match_prefix(self, key: List[int])
         ‚Üí MatchResult

  L  43: cache_finished_req(self, req: Req)

  L  47: cache_unfinished_req(self, req: Req)

  L  51: evict(self, num_tokens: int)

  L  55: inc_lock_ref(self, node: Any)

  L  59: dec_lock_ref(self, node: Any, swa_uuid_for_lock: Optional[str])

  L  62: evictable_size(self)

  L  65: full_evictable_size(self)

  L  68: swa_evictable_size(self)

  L  71: protected_size(self)

  L  74: full_protected_size(self)

  L  77: swa_protected_size(self)

  L  80: total_size(self)

  L  83: pretty_print(self)

  L  86: init_load_back(self, last_host_node: Any, host_hit_length: int)
         ‚Üí Tuple[torch.Tensor, Any]
         üìù Preparing KV cache loading from host to device.

  L  96: ready_to_load_host_cache(self)
         ‚Üí Any
         üìù Notify the cache controller to start the KV cache loading

  L 102: check_hicache_events(self)
         ‚Üí Any
         üìù Check HiCache related activities to update radix tree and synchronize across TP workers if needed

  L 108: take_events(self)


============================================================
FILE: python/sglang/srt/mem_cache/chunk_cache.py
Functions: 12
============================================================


CLASS: ChunkCache
----------------------------------------
  L  21: __init__(self, req_to_token_pool: ReqToTokenPool, token_to_kv_pool_allocator: BaseTokenToKVPoolAllocator, page_size: int)

  L  31: reset(self)

  L  34: match_prefix(self)
         ‚Üí MatchResult

  L  41: cache_finished_req(self, req: Req)

  L  50: cache_unfinished_req(self, req: Req, chunked)

  L  58: evict(self, num_tokens: int)

  L  61: inc_lock_ref(self, node: Any)

  L  64: dec_lock_ref(self, node: Any, swa_uuid_for_lock: Optional[str])

  L  67: pretty_print(self)


CLASS: SWAChunkCache
----------------------------------------
  L  74: __init__(self, req_to_token_pool: ReqToTokenPool, token_to_kv_pool_allocator: SWATokenToKVPoolAllocator, page_size: int)

  L  83: evict_swa(self, req: Req, prelen: int, attention_chunk_size: int)

  L  99: evict(self, num_tokens: int)


============================================================
FILE: python/sglang/srt/mem_cache/cpp_radix_tree/radix_tree.py
Functions: 13
============================================================


CLASS: RadixTreeCpp
----------------------------------------
  L  33: __init__(self, disabled: bool, host_size: Optional[int], page_size: int, write_through_threshold: int)
         üìù Initializes the RadixTreeCpp instance.
            Args:
            disabled (bool): If True, the radix tree is disabled.
            host_size (Optional[int]): Size of the radix tree on the CPU. None means no CPU tree.
            page_size (int): Size of the page for the radix tree.
            write_through_threshold (int): Threshold for writing through from GPU to CPU.

  L  52: match_prefix(self, prefix: List[int])
         ‚Üí Tuple[List[torch.Tensor], int, TreeNodeCpp, TreeNodeCpp]
         üìù Matches a prefix in the radix tree.
            Args:
            prefix (List[int]): The prefix to match.
            Returns:
            Tuple[List[torch.Tensor], TreeNodeCpp, TreeNodeCpp]:
            0. A list of indices that is matched by the prefix on the GPU.
            1. Sum length of the indices matched on the CPU.
            2. The last node of the prefix matched on the GPU.
            3. The last node of the prefix matched on the CPU.

  L  68: evict(self, num_tokens: int)
         ‚Üí List[torch.Tensor]
         üìù Evicts a number of tokens from the radix tree.
            Args:
            num_tokens (int): The number of tokens to evict.
            Returns:
            List[torch.Tensor]: A list of indices that were evicted.

  L  78: lock_ref(self, handle: TreeNodeCpp, lock: bool)
         ‚Üí None
         üìù Locks or unlocks a reference to a tree node.
            After locking, the node will not be evicted from the radix tree.
            Args:
            handle (TreeNodeCpp): The tree node to lock or unlock.
            lock (bool): If True, locks the node; if False, unlocks it.

  L  88: writing_through(self, key: List[int], indices: torch.Tensor)
         ‚Üí Tuple[List[Tuple[IOHandle, torch.Tensor, torch.Tensor]], int]
         üìù Inserts a key-value pair into the radix tree and perform write-through check.
            Args:
            key (List[int]): The key to insert.
            indices (torch.Tensor): The value associated with the key.
            Returns:
            Tuple[List[Tuple[IOHandle, torch.Tensor, torch.Tensor]], int]:
            0. A list of (IOHandle, device indices, host indices) tuples.
            These IOhandles require write-through to the CPU in python side.
            1. The number of indices that are matched on device.

  L 104: loading_onboard(self, host_node: TreeNodeCpp, new_device_indices: torch.Tensor)
         ‚Üí Tuple[IOHandle, List[torch.Tensor]]
         üìù Updates the device indices of tree nodes within a range on the tree.
            Args:
            host_node (TreeNodeCpp): The tree node on the host, must be descendant of device_node.
            new_device_indices (torch.Tensor): The new device indices to set.
            The length of this tensor must be exactly host indices length.
            Returns:
            Tuple[IOHandle, List[torch.Tensor]]:
            0. An IOHandle that requires loading to the CPU in python side.
            1. A list of host indices corresponding to the new device indices.

  L 122: commit_writing_through(self, handle: IOHandle, success: bool)
         ‚Üí None
         üìù Commits the write-through process for a tree node.
            Args:
            handle (IOHandle): The IOHandle to commit.
            success (bool): If True, commits the write-through; if False, just indicates failure.

  L 131: commit_loading_onboard(self, handle: IOHandle, success: bool)
         ‚Üí None
         üìù Commits the load onboard process for tree nodes within a range on the tree.
            Args:
            handle (IOHandle): The IOHandle to commit.
            success (bool): If True, commits the load-onboard; if False, just indicates failure.

  L 140: evictable_size(self)
         ‚Üí int
         üìù Returns the size of the evictable part of the radix tree.
            This is the size of the part that can be evicted from the GPU (ref_count = 0).
            Returns:
            int: The size of the evictable part.

  L 149: protected_size(self)
         ‚Üí int
         üìù Returns the size of the protected part of the radix tree.
            This is the size of the part that cannot be evicted from the GPU (ref_count > 0).
            Returns:
            int: The size of the protected part.

  L 158: total_size(self)
         ‚Üí int
         üìù Returns the total size of the radix tree (including CPU nodes).
            Returns:
            int: The total size of the radix tree.

  L 166: reset(self)
         ‚Üí None
         üìù Resets the radix tree, clearing all nodes and indices.

  L 172: debug_print(self)
         ‚Üí None
         üìù Prints the internal state of the radix tree for debugging purposes.


============================================================
FILE: python/sglang/srt/mem_cache/hicache_storage.py
Functions: 17
============================================================

MODULE FUNCTIONS:
----------------------------------------
  L  13: def get_hash_str(token_ids: List[int], prior_hash: str)
         ‚Üí str


CLASS: HiCacheFile
----------------------------------------
  L 133: __init__(self, storage_config: HiCacheStorageConfig, file_path: str)

  L 151: get(self, key: str, target_location: torch.Tensor, target_sizes: Optional[Any])
         ‚Üí torch.Tensor | None

  L 172: batch_get(self, keys: List[str], target_locations: List[torch.Tensor], target_sizes: Optional[Any])
         ‚Üí List[torch.Tensor | None]

  L 185: set(self, key: str, value: Optional[Any], target_location: Optional[Any], target_sizes: Optional[Any])
         ‚Üí bool

  L 205: batch_set(self, keys: List[str], values: Optional[Any], target_locations: Optional[Any], target_sizes: Optional[Any])
         ‚Üí bool

  L 217: exists(self, key: str)
         ‚Üí bool

  L 222: delete(self, key: str)
         ‚Üí None

  L 231: clear(self)
         ‚Üí bool


CLASS: HiCacheStorage
----------------------------------------
  L  44: get(self, key: str, target_location: Optional[Any], target_sizes: Optional[Any])
         ‚Üí torch.Tensor | None
         üìù Retrieve the value associated with the given key.
            Returns None if the key does not exist.

  L  57: batch_get(self, keys: List[str], target_locations: Optional[Any], target_sizes: Optional[Any])
         ‚Üí List[torch.Tensor | None] | int
         üìù Retrieve values for multiple keys.
            Returns a list of tensors or None for each key.

  L  70: set(self, key: str, value: Optional[Any], target_location: Optional[Any], target_sizes: Optional[Any])
         ‚Üí bool
         üìù Store the value associated with the given key.
            Returns True if the operation was successful, False otherwise.

  L  84: batch_set(self, keys: List[str], values: Optional[Any], target_locations: Optional[Any], target_sizes: Optional[Any])
         ‚Üí bool
         üìù Store multiple key-value pairs.
            Returns True if all operations were successful, False otherwise.

  L  98: exists(self, key: str)
         ‚Üí bool
         üìù Check if the key exists in the storage.
            Returns True if the key exists, False otherwise.

  L 106: delete(self, key: str)
         ‚Üí bool
         üìù Delete the entry associated with the given key.

  L 113: clear(self)
         ‚Üí bool
         üìù Clear all entries in the storage.

  L 119: batch_exists(self, keys: List[str])
         ‚Üí int
         üìù Check if the keys exist in the storage.
            return the number of consecutive existing keys from the start.
            Can be overridden by subclasses for more efficient implementation.


============================================================
FILE: python/sglang/srt/mem_cache/hiradix_cache.py
Functions: 21
============================================================


CLASS: HiRadixCache
----------------------------------------
  L  29: __init__(self, req_to_token_pool: ReqToTokenPool, token_to_kv_pool_allocator: BaseTokenToKVPoolAllocator, tp_cache_group: torch.distributed.ProcessGroup, page_size: int, hicache_ratio: float, hicache_size: int, hicache_write_policy: str, hicache_io_backend: str, hicache_mem_layout: str, hicache_storage_backend: Optional[str], hicache_storage_prefetch_policy: Optional[str], model_name: Optional[str], storage_backend_extra_config: Optional[str])

  L 112: reset(self)

  L 118: get_height(self, node: TreeNode)

  L 125: clear_storage_backend(self)

  L 134: write_backup(self, node: TreeNode, write_back)

  L 157: write_backup_storage(self, node: TreeNode)

  L 175: writing_check(self, write_back)

  L 200: loading_check(self)

  L 215: evictable_size(self)

  L 218: evict(self, num_tokens: int)

  L 270: evict_host(self, num_tokens: int)

  L 297: load_back(self, node: TreeNode, mem_quota: Optional[int])
         ‚Üí Optional[torch.Tensor]

  L 349: init_load_back(self, last_node: TreeNode, host_hit_length: int, mem_quota: Optional[int])

  L 372: ready_to_load_host_cache(self)

  L 377: check_hicache_events(self)

  L 383: drain_storage_control_queues(self)
         üìù Combine prefetch revoke, backup ack, and host mem release checks
            to minimize TP synchronization and Python overhead.

  L 430: can_terminate_prefetch(self, operation: PrefetchOperation)

  L 464: check_prefetch_progress(self, req_id: str)
         ‚Üí bool

  L 520: match_prefix(self, key: List[int])

  L 555: prefetch_from_storage(self, req_id: str, last_host_node: TreeNode, new_input_tokens: List[int], last_hash: Optional[str])

  L 682: insert(self, key: List, value, chunked)


============================================================
FILE: python/sglang/srt/mem_cache/lora_radix_cache.py
Functions: 21
============================================================

MODULE FUNCTIONS:
----------------------------------------
  L  32: def get_child_key(key: LoRAKey)


CLASS: LoRAKey
----------------------------------------
  L  22: __init__(self, lora_id: str, token_ids: List[int])

  L  28: __len__(self)


CLASS: LoRARadixCache
----------------------------------------
  L  79: __init__(self, req_to_token_pool: ReqToTokenPool, token_to_kv_pool_allocator: BaseTokenToKVPoolAllocator, page_size: int, disable: bool)

  L 104: reset(self)

  L 111: match_prefix(self, key: List[int])
         ‚Üí MatchResult

  L 116: match_prefix_with_lora_id(self, key: LoRAKey)
         ‚Üí MatchResult
         üìù Find the matching prefix from the lora radix tree.
            Args:
            key: A LoRAKey to find a matching prefix.
            Returns:
            A tuple of a tensor of matching prefix token IDs and
            the last node that contains the prefix values. Note that
            this API can modify the internal state of the Radix tree.
            The last node create a new child if the prefix is shorter
            than the last node's value.

  L 149: insert(self, key: LoRAKey, value)

  L 157: cache_finished_req(self, req: Req)
         üìù Cache request when it finishes.

  L 186: cache_unfinished_req(self, req: Req, chunked)
         üìù Cache request when it is unfinished.

  L 221: pretty_print(self)

  L 225: total_size(self)

  L 228: evict(self, num_tokens: int)

  L 251: inc_lock_ref(self, node: LoRATreeNode)

  L 265: dec_lock_ref(self, node: LoRATreeNode)

  L 279: evictable_size(self)

  L 282: protected_size(self)

  L 286: all_values_flatten(self)


CLASS: LoRATreeNode
----------------------------------------
  L  45: __init__(self, id: Optional[int])

  L  57: evicted(self)

  L  60: __lt__(self, other: 'LoRATreeNode')


============================================================
FILE: python/sglang/srt/mem_cache/memory_pool.py
Functions: 62
============================================================

MODULE FUNCTIONS:
----------------------------------------
  L 644: def set_mla_kv_buffer_kernel(kv_buffer_ptr,
        cache_k_nope_ptr,
        cache_k_rope_ptr,
        loc_ptr,
        buffer_stride: tl.constexpr,
        nope_stride: tl.constexpr,
        rope_stride: tl.constexpr,
        nope_dim: tl.constexpr,
        rope_dim: tl.constexpr,
        BLOCK: tl.constexpr)
         @triton.jit

  L 682: def set_mla_kv_buffer_triton(kv_buffer: torch.Tensor,
        loc: torch.Tensor,
        cache_k_nope: torch.Tensor,
        cache_k_rope: torch.Tensor)

  L1110: def copy_all_layer_kv_cache(data_ptrs,
        strides,
        tgt_loc_ptr,
        src_loc_ptr,
        num_locs,
        num_locs_upper: tl.constexpr)
         @triton.jit


CLASS: AscendMLAPagedTokenToKVPool
----------------------------------------
  L 885: __init__(self, size: int, page_size: int, dtype: torch.dtype, kv_lora_rank: int, qk_rope_head_dim: int, layer_num: int, device: str, enable_memory_saver: bool, start_layer: Optional[int], end_layer: Optional[int])

  L 947: get_kv_size_bytes(self)

  L 957: get_kv_buffer(self, layer_id: int)

  L 965: get_key_buffer(self, layer_id: int)

  L 973: get_value_buffer(self, layer_id: int)

  L 982: get_contiguous_buf_infos(self)

  L 995: set_kv_buffer(self, layer: RadixAttention, loc: torch.Tensor, cache_k: torch.Tensor, cache_v: torch.Tensor)


CLASS: AscendTokenToKVPool
----------------------------------------
  L 582: get_contiguous_buf_infos(self)

  L 608: set_kv_buffer(self, layer: RadixAttention, loc: torch.Tensor, cache_k: torch.Tensor, cache_v: torch.Tensor, k_scale: Optional[float], v_scale: Optional[float])


CLASS: DoubleSparseTokenToKVPool
----------------------------------------
  L1031: __init__(self, size: int, page_size: int, dtype: torch.dtype, head_num: int, head_dim: int, layer_num: int, device: str, heavy_channel_num: int, enable_memory_saver: bool, start_layer: Optional[int], end_layer: Optional[int])

  L1079: get_key_buffer(self, layer_id: int)

  L1082: get_value_buffer(self, layer_id: int)

  L1085: get_label_buffer(self, layer_id: int)

  L1088: get_kv_buffer(self, layer_id: int)

  L1094: set_kv_buffer(self, layer: RadixAttention, loc: torch.Tensor, cache_k: torch.Tensor, cache_v: torch.Tensor, cache_label: torch.Tensor)


CLASS: KVCache
----------------------------------------
  L 102: __init__(self, size: int, page_size: int, dtype: torch.dtype, layer_num: int, device: str, enable_memory_saver: bool, start_layer: Optional[int], end_layer: Optional[int])

  L 134: get_key_buffer(self, layer_id: int)
         ‚Üí torch.Tensor

  L 138: get_value_buffer(self, layer_id: int)
         ‚Üí torch.Tensor

  L 142: get_kv_buffer(self, layer_id: int)
         ‚Üí Tuple[torch.Tensor, torch.Tensor]

  L 146: set_kv_buffer(self, layer: RadixAttention, loc: torch.Tensor, cache_k: torch.Tensor, cache_v: torch.Tensor)
         ‚Üí None

  L 155: register_layer_transfer_counter(self, layer_transfer_counter)

  L 158: get_cpu_copy(self, indices)

  L 161: load_cpu_copy(self, kv_cache_cpu, indices)


CLASS: MHATokenToKVPool
----------------------------------------
  L 167: __init__(self, size: int, page_size: int, dtype: torch.dtype, head_num: int, head_dim: int, layer_num: int, device: str, enable_memory_saver: bool, start_layer: Optional[int], end_layer: Optional[int])

  L 267: get_kv_size_bytes(self)

  L 279: get_contiguous_buf_infos(self)

  L 305: maybe_get_custom_mem_pool(self)

  L 308: get_cpu_copy(self, indices)

  L 326: load_cpu_copy(self, kv_cache_cpu, indices)

  L 349: get_key_buffer(self, layer_id: int)

  L 364: get_value_buffer(self, layer_id: int)

  L 369: get_kv_buffer(self, layer_id: int)

  L 372: set_kv_buffer(self, layer: RadixAttention, loc: torch.Tensor, cache_k: torch.Tensor, cache_v: torch.Tensor, k_scale: Optional[float], v_scale: Optional[float], layer_id_override: Optional[int])

  L 412: move_kv_cache(self, tgt_loc: torch.Tensor, src_loc: torch.Tensor)


CLASS: MLATokenToKVPool
----------------------------------------
  L 710: __init__(self, size: int, page_size: int, dtype: torch.dtype, kv_lora_rank: int, qk_rope_head_dim: int, layer_num: int, device: str, enable_memory_saver: bool, start_layer: Optional[int], end_layer: Optional[int])

  L 779: get_kv_size_bytes(self)

  L 787: get_contiguous_buf_infos(self)

  L 796: maybe_get_custom_mem_pool(self)

  L 799: get_key_buffer(self, layer_id: int)

  L 807: get_value_buffer(self, layer_id: int)

  L 817: get_kv_buffer(self, layer_id: int)

  L 820: set_kv_buffer(self, layer: RadixAttention, loc: torch.Tensor, cache_k: torch.Tensor, cache_v: torch.Tensor)

  L 837: set_mla_kv_buffer(self, layer: RadixAttention, loc: torch.Tensor, cache_k_nope: torch.Tensor, cache_k_rope: torch.Tensor)

  L 856: get_cpu_copy(self, indices)

  L 871: load_cpu_copy(self, kv_cache_cpu, indices)


CLASS: ReqToTokenPool
----------------------------------------
  L  53: __init__(self, size: int, max_context_len: int, device: str, enable_memory_saver: bool)

  L  75: write(self, indices, values)

  L  78: available_size(self)

  L  81: alloc(self, need_size: int)
         ‚Üí List[int]

  L  90: free(self, free_index: Union[int, List[int]])

  L  96: clear(self)


CLASS: SWAKVPool
----------------------------------------
  L 426: __init__(self, size: int, size_swa: int, dtype: torch.dtype, head_num: int, head_dim: int, swa_attention_layer_ids: List[int], full_attention_layer_ids: List[int], enable_kvcache_transpose: bool, device: str)

  L 478: get_kv_size_bytes(self)

  L 483: get_contiguous_buf_infos(self)

  L 497: get_key_buffer(self, layer_id: int)

  L 504: get_value_buffer(self, layer_id: int)

  L 511: get_kv_buffer(self, layer_id: int)

  L 518: translate_loc_from_full_to_swa(self, kv_indices: torch.Tensor)

  L 522: set_kv_buffer(self, layer: RadixAttention, loc: torch.Tensor, cache_k: torch.Tensor, cache_v: torch.Tensor, k_scale: float, v_scale: float)


============================================================
FILE: python/sglang/srt/mem_cache/memory_pool_host.py
Functions: 48
============================================================

MODULE FUNCTIONS:
----------------------------------------
  L  38: def synchronized(debug_only)


CLASS: HostKVCache
----------------------------------------
  L  55: __init__(self, device_pool: KVCache, host_to_device_ratio: float, host_size: int, page_size: int, layout: str, pin_memory: bool, device: str)

  L 112: get_size_per_token(self)

  L 116: init_kv_buffer(self)

  L 120: load_to_device_per_layer(self, device_pool, host_indices, device_indices, layer_id, io_backend)
         ‚Üí None
         üìù Load KV data from the host memory pool to the device memory pool for a specific layer.

  L 129: backup_from_device_all_layer(self, device_pool, host_indices, device_indices, io_backend)
         ‚Üí None
         üìù Backup KV data from the device memory pool to the host memory pool for all layers.

  L 138: get_flat_data_page(self, index)
         ‚Üí torch.Tensor
         üìù Get a flat data page from the host memory pool.

  L 145: get_dummy_flat_data_page(self)
         ‚Üí torch.Tensor
         üìù Get a dummy flat data page from the host memory pool.
            This is used for prefetching or initializing empty pages.

  L 153: set_from_flat_data_page(self, index: int, data_page: torch.Tensor)
         ‚Üí None
         üìù Set a flat data page to the host memory pool.

  L 160: clear(self)

  L 167: available_size(self)

  L 171: alloc(self, need_size: int)
         ‚Üí torch.Tensor

  L 187: free(self, indices: torch.Tensor)
         ‚Üí int

  L 194: get_state(self, indices: torch.Tensor)
         ‚Üí MemoryStateInt

  L 203: is_reserved(self, indices: torch.Tensor)
         ‚Üí bool

  L 207: is_protected(self, indices: torch.Tensor)
         ‚Üí bool

  L 211: is_synced(self, indices: torch.Tensor)
         ‚Üí bool

  L 215: is_backup(self, indices: torch.Tensor)
         ‚Üí bool

  L 219: update_backup(self, indices: torch.Tensor)

  L 228: update_prefetch(self, indices: torch.Tensor)

  L 237: update_synced(self, indices: torch.Tensor)

  L 241: protect_write(self, indices: torch.Tensor)

  L 250: protect_load(self, indices: torch.Tensor)

  L 259: complete_io(self, indices: torch.Tensor)


CLASS: MHATokenToKVPoolHost
----------------------------------------
  L 271: __init__(self, device_pool: MHATokenToKVPool, host_to_device_ratio: float, host_size: int, page_size: int, layout: str, pin_memory: bool, device: str)

  L 303: get_size_per_token(self)

  L 310: get_ksize_per_token(self)

  L 313: init_kv_buffer(self)

  L 330: k_buffer(self)

  L 334: v_buffer(self)

  L 337: load_to_device_per_layer(self, device_pool, host_indices, device_indices, layer_id, io_backend)

  L 387: backup_from_device_all_layer(self, device_pool, host_indices, device_indices, io_backend)

  L 430: get_flat_data_page(self, index)
         ‚Üí torch.Tensor

  L 438: get_dummy_flat_data_page(self)
         ‚Üí torch.Tensor

  L 446: set_from_flat_data_page(self, index: int, data_page: torch.Tensor)
         ‚Üí None

  L 466: get_buffer_meta(self, keys, indices, local_rank)

  L 502: get_buffer_with_hash(self, keys, indices)


CLASS: MLATokenToKVPoolHost
----------------------------------------
  L 521: __init__(self, device_pool: MLATokenToKVPool, host_to_device_ratio: float, host_size: int, page_size: int, layout: str, pin_memory: bool, device: str)

  L 547: get_size_per_token(self)

  L 559: get_ksize_per_token(self)

  L 562: init_kv_buffer(self)

  L 591: load_to_device_per_layer(self, device_pool, host_indices, device_indices, layer_id, io_backend)

  L 627: backup_from_device_all_layer(self, device_pool, host_indices, device_indices, io_backend)

  L 666: get_flat_data_page(self, index)
         ‚Üí torch.Tensor

  L 674: get_dummy_flat_data_page(self)
         ‚Üí torch.Tensor

  L 687: set_from_flat_data_page(self, index: int, data_page: torch.Tensor)
         ‚Üí None

  L 705: get_buffer_meta(self, keys, indices, local_rank)

  L 729: get_buffer_with_hash(self, keys, indices)


============================================================
FILE: python/sglang/srt/mem_cache/multimodal_cache.py
Functions: 6
============================================================


CLASS: MultiModalCache
----------------------------------------
  L  14: __init__(self, max_size: int)

  L  40: put(self, mm_hash: int, embedding: torch.Tensor)
         ‚Üí bool

  L  49: has(self, mm_hash: int)
         ‚Üí bool

  L  52: get(self, mm_hash: int)
         ‚Üí torch.Tensor
         üìù Get embedding and update LRU order

  L  60: clear(self)

  L  67: __len__(self)


============================================================
FILE: python/sglang/srt/mem_cache/radix_cache.py
Functions: 22
============================================================


CLASS: RadixCache
----------------------------------------
  L 120: __init__(self, req_to_token_pool: ReqToTokenPool, token_to_kv_pool_allocator: BaseTokenToKVPoolAllocator, page_size: int, disable: bool, enable_kv_cache_events: bool)

  L 150: reset(self)

  L 160: match_prefix(self, key: List[int])
         ‚Üí MatchResult
         üìù Find the matching prefix from the radix tree.
            Args:
            key: A list of token IDs to find a matching prefix.
            Returns:
            A tuple of a tensor of matching prefix token IDs and
            the last node that contains the prefix values. Note that
            this API can modify the internal state of the Radix tree.
            The last node create a new child if the prefix is shorter
            than the last node's value.

  L 197: insert(self, key: List, value, chunked)

  L 205: cache_finished_req(self, req: Req)
         üìù Cache request when it finishes.

  L 242: cache_unfinished_req(self, req: Req, chunked)
         üìù Cache request when it is unfinished.

  L 289: pretty_print(self)

  L 293: total_size(self)

  L 296: evict(self, num_tokens: int)

  L 321: inc_lock_ref(self, node: TreeNode)

  L 335: dec_lock_ref(self, node: TreeNode)

  L 349: evictable_size(self)

  L 352: protected_size(self)

  L 356: all_values_flatten(self)

  L 543: take_events(self)
         üìù Atomically takes all events and clears the queue.
            Returns:
            A list of KV cache events.


CLASS: TreeNode
----------------------------------------
  L  47: __init__(self, id: Optional[int])

  L  70: evicted(self)

  L  74: backuped(self)

  L  77: protect_host(self)
         üìù Protect the host value from eviction.

  L  81: release_host(self)
         üìù Release the host value, allowing it to be evicted.

  L  88: get_last_hash_value(self)
         ‚Üí Optional[str]
         üìù Returns the hash value of the last page in this node.

  L  94: __lt__(self, other: 'TreeNode')


============================================================
FILE: python/sglang/srt/mem_cache/radix_cache_cpp.py
Functions: 12
============================================================


CLASS: RadixCacheCpp
----------------------------------------
  L  40: __init__(self, disable: bool, use_hicache: bool, req_to_token_pool: ReqToTokenPool, token_to_kv_pool: BaseTokenToKVPoolAllocator, tp_cache_group: torch.distributed.ProcessGroup, page_size: int, hicache_ratio: float, hicache_size: int, hicache_write_policy: str, enable_kv_cache_events: bool, hicache_oracle: bool, enable_write_cancel: bool)

  L  90: reset(self)

  L  96: match_prefix(self, key: List[int])
         ‚Üí MatchResult

  L 123: dec_lock_ref(self, node: TreeNodeCpp)
         üìù Decrement the reference count of a node to root of the radix tree.
            Args:
            node (TreeNodeCpp): The handle of the node to decrement the reference count for.

  L 131: inc_lock_ref(self, node: TreeNodeCpp)
         üìù Increment the reference count of from a node to root of the radix tree.
            Args:
            node (TreeNodeCpp): The handle of the node to increment the reference count for.

  L 139: evict(self, num_tokens: int)

  L 144: evictable_size(self)

  L 147: protected_size(self)

  L 150: total_size(self)

  L 153: cache_finished_req(self, req: Req)
         üìù Cache request when it finishes.

  L 184: cache_unfinished_req(self, req: Req, chunked)
         üìù Cache request when it is unfinished.

  L 228: pretty_print(self)


============================================================
FILE: python/sglang/srt/mem_cache/storage/hf3fs/client_hf3fs.py
Functions: 9
============================================================

MODULE FUNCTIONS:
----------------------------------------
  L  30: def rsynchronized()

  L  42: def wsynchronized()


CLASS: Hf3fsClient
----------------------------------------
  L  55: __init__(self, path: str, size: int, bytes_per_page: int, entries: int)

  L 106: batch_read(self, offsets: List[int], tensors: List[torch.Tensor])
         ‚Üí List[int]

  L 129: batch_write(self, offsets: List[int], tensors: List[torch.Tensor])
         ‚Üí List[int]

  L 151: check(self, offsets: List[int], tensors: List[torch.Tensor])
         ‚Üí None

  L 169: get_size(self)
         ‚Üí int

  L 172: close(self)
         ‚Üí None

  L 182: flush(self)
         ‚Üí None


============================================================
FILE: python/sglang/srt/mem_cache/storage/hf3fs/mini_3fs_metadata_server.py
Functions: 39
============================================================

MODULE FUNCTIONS:
----------------------------------------
  L 405: def run_metadata_server(host: str,
        port: int,
        persistence_path: Optional[str],
        save_interval: int)
         üìù Run the HF3FS metadata server.


CLASS: GlobalMetadataState
----------------------------------------
  L 103: __init__(self, persistence_path: Optional[str], save_interval: int)

  L 111: load_from_disk(self)

  L 139: save_to_disk(self)

  L 163: schedule_save(self)

  L 170: shutdown(self)


CLASS: Hf3fsGlobalMetadataClient
----------------------------------------
  L 302: __init__(self, base_url: str, max_retries: int)

  L 324: initialize(self, rank: int, num_pages: int)
         ‚Üí None

  L 327: reserve_and_allocate_page_indices(self, rank: int, keys: List[Tuple[str, str]])
         ‚Üí List[Tuple[bool, int]]

  L 335: confirm_write(self, rank: int, written_keys_to_confirm: List[Tuple[str, int]], pages_to_release: List[int])
         ‚Üí None

  L 349: delete_keys(self, rank: int, keys: List[str])
         ‚Üí None

  L 352: exists(self, rank: int, keys: List[str])
         ‚Üí List[bool]

  L 356: clear(self, rank: int)
         ‚Üí None

  L 359: get_page_indices(self, rank: int, keys: List[str])
         ‚Üí List[Optional[int]]


CLASS: Hf3fsLocalMetadataClient
----------------------------------------
  L 367: __init__(self)

  L 370: initialize(self, rank: int, num_pages: int)
         ‚Üí None

  L 373: reserve_and_allocate_page_indices(self, rank: int, keys: List[Tuple[str, str]])
         ‚Üí List[Tuple[bool, int]]
         üìù Reserve and allocate page indices for keys.

  L 379: confirm_write(self, rank: int, written_keys_to_confirm: List[Tuple[str, int]], pages_to_release: List[int])
         ‚Üí None
         üìù Confirm write operations.

  L 388: delete_keys(self, rank: int, keys: List[str])
         ‚Üí None
         üìù Delete keys.

  L 392: exists(self, rank: int, keys: List[str])
         ‚Üí List[bool]
         üìù Check if keys exist.

  L 396: clear(self, rank: int)
         ‚Üí None
         üìù Clear all metadata for rank.

  L 400: get_page_indices(self, rank: int, keys: List[str])
         ‚Üí List[Optional[int]]
         üìù Get page indices for keys.


CLASS: Hf3fsMetadataServer
----------------------------------------
  L 183: __init__(self, persistence_path: Optional[str], save_interval: int)

  L 200: get_rank_metadata(self, rank: int)
         ‚Üí RankMetadata
         üìù Get rank metadata with proper error handling.

  L 210: initialize(self, rank: int, request: Request)
         üìù Initialize a rank with specified number of pages.

  L 228: exists(self, rank: int, request: Request)
         üìù Check if keys exist in metadata.

  L 236: reserve_and_allocate_page_indices(self, rank: int, request: Request)
         üìù Reserve and allocate page indices for keys.

  L 244: confirm_write(self, rank: int, request: Request)
         üìù Confirm write operations and release pages.

  L 257: delete_keys(self, rank: int, request: Request)
         üìù Delete keys from metadata.

  L 264: clear(self, rank: int)
         üìù Clear all metadata for a rank.

  L 270: get_page_indices(self, rank: int, request: Request)
         üìù Get page indices for keys.

  L 278: run(self, host: str, port: int)
         üìù Run the metadata server.


CLASS: RankMetadata
----------------------------------------
  L  26: __init__(self, num_pages: int)

  L  33: exists_keys(self, keys: List[str])
         ‚Üí List[bool]
         üìù Check if keys exist in metadata.

  L  38: reserve_and_allocate_page_indices(self, keys: List[Tuple[str, str]])
         ‚Üí List[Tuple[bool, int]]
         üìù Reserve and allocate page indices for keys.

  L  62: confirm_write(self, written_keys_to_confirm: List[Tuple[str, int]], pages_to_release: List[int])
         ‚Üí None
         üìù Confirm write operations and release pages.

  L  76: delete_keys(self, keys: List[str])
         ‚Üí int
         üìù Delete keys and return count of deleted keys.

  L  88: clear_all(self)
         ‚Üí None
         üìù Clear all metadata.

  L  94: get_page_indices(self, keys: List[str])
         ‚Üí List[Optional[int]]
         üìù Get page indices for keys.


============================================================
FILE: python/sglang/srt/mem_cache/storage/hf3fs/storage_hf3fs.py
Functions: 21
============================================================

MODULE FUNCTIONS:
----------------------------------------
  L 103: def synchronized()


CLASS: AtomicCounter
----------------------------------------
  L  90: __init__(self, n: int)

  L  96: next(self)
         ‚Üí int


CLASS: Hf3fsMetadataInterface
----------------------------------------
  L  24: initialize(self, rank: int, num_pages: int)
         ‚Üí None
         üìù Initialize the metadata service with specified number of pages.

  L  29: reserve_and_allocate_page_indices(self, rank: int, keys: List[Tuple[str, str]])
         ‚Üí List[Tuple[bool, int]]
         üìù Reserve and allocate page indices for the specified keys.
            Args:
            rank: The rank of the process.
            keys: The keys to reserve and allocate page indices for. Each tuple contains a key and the key of its prefix block.
            Returns:
            List[Tuple[bool, int]]: A list of tuples, where each tuple contains a boolean indicating whether the key has existed and an integer indicating the allocated page index.

  L  45: confirm_write(self, rank: int, written_keys_to_confirm: List[Tuple[str, int]], pages_to_release: List[int])
         ‚Üí None
         üìù Confirm that key-value pairs have been successfully written to storage.
            Args:
            rank: The rank of the process.
            written_keys_to_confirm: A list of tuples, where each tuple contains a key and its corresponding page index.
            pages_to_release: A list of page indices to be released.

  L  61: get_page_indices(self, rank: int, keys: List[str])
         ‚Üí List[Optional[int]]
         üìù Get page indices for the specified keys.
            Args:
            rank: The rank of the process.
            keys: A list of keys.
            Returns:
            List[Optional[int]]: A list of integers representing the page indices for the specified keys.
            If a key is not found, the corresponding index will be None.

  L  74: delete_keys(self, rank: int, keys: List[str])
         ‚Üí None
         üìù Delete specified keys and their associated pages.

  L  79: exists(self, rank: int, keys: List[str])
         ‚Üí List[bool]
         üìù Check if the specified keys exist.

  L  84: clear(self, rank: int)
         ‚Üí None
         üìù Clear all key-value pairs and page allocations for the specified rank.


CLASS: HiCacheHF3FS
----------------------------------------
  L 118: __init__(self, rank: int, file_path: str, file_size: int, numjobs: int, bytes_per_page: int, entries: int, dtype: torch.dtype, metadata_client: Hf3fsMetadataInterface, is_mla_model: bool)

  L 174: from_env_config(bytes_per_page: int, dtype: torch.dtype, storage_config: HiCacheStorageConfig)
         ‚Üí 'HiCacheHF3FS'

  L 245: get(self, key: str, target_location: Optional[Any], target_sizes: Optional[Any])
         ‚Üí torch.Tensor | None

  L 258: batch_get(self, keys: List[str], target_locations: Optional[Any], target_sizes: Optional[Any])
         ‚Üí List[torch.Tensor | None]

  L 305: set(self, key: str, value: Optional[Any], target_location: Optional[Any], target_sizes: Optional[Any])
         ‚Üí bool

  L 319: batch_set(self, keys: List[str], values: Optional[Any], target_locations: Optional[Any], target_sizes: Optional[Any])
         ‚Üí bool

  L 381: delete(self, key: str)
         ‚Üí None

  L 384: exists(self, key: str)
         ‚Üí bool

  L 388: batch_exists(self, keys: List[str])
         ‚Üí int

  L 396: clear(self)
         ‚Üí bool

  L 405: close(self)
         ‚Üí None


============================================================
FILE: python/sglang/srt/mem_cache/storage/hf3fs/test_hf3fs_utils.py
Functions: 1
============================================================

MODULE FUNCTIONS:
----------------------------------------
  L  15: def test_rw_shm()


============================================================
FILE: python/sglang/srt/mem_cache/storage/mooncake_store/mooncake_store.py
Functions: 15
============================================================


CLASS: MooncakeStore
----------------------------------------
  L  87: __init__(self, storage_config: HiCacheStorageConfig)

  L 132: warmup(self)

  L 139: register_buffer(self, buffer: torch.Tensor)
         ‚Üí None

  L 150: set(self, key, value: Optional[Any], target_location: Optional[List[int]], target_sizes: Optional[List[int]])
         ‚Üí bool

  L 159: batch_set(self, keys: List[str], values: Optional[List[torch.Tensor]], target_location: Optional[List[int]], target_sizes: Optional[List[int]])
         ‚Üí bool

  L 201: get(self, key, target_location: Optional[Any], target_sizes: Optional[Any])
         ‚Üí bool

  L 209: batch_get(self, keys: List[str], target_location: Optional[Any], target_sizes: Optional[Any])
         ‚Üí int

  L 228: exists(self, key)
         ‚Üí bool

  L 231: batch_exists(self, keys)
         ‚Üí int

  L 248: delete(self, key)
         ‚Üí None

  L 251: close(self)

  L 256: clear(self)
         ‚Üí None


CLASS: MooncakeStoreConfig
----------------------------------------
  L  32: from_file()
         ‚Üí 'MooncakeStoreConfig'
         üìù Load the config from a JSON file.

  L  55: load_from_env()
         ‚Üí 'MooncakeStoreConfig'
         üìù Load config from a file specified in the environment variable.
            export MOONCAKE_MASTER=10.13.3.232:50051
            export MOONCAKE_PROTOCOL="rdma"
            export MOONCAKE_DEVICE="auto"
            export MOONCAKE_TE_META_DATA_SERVER="P2PHANDSHAKE"

  L  78: __post_init__(self)


============================================================
FILE: python/sglang/srt/mem_cache/storage/mooncake_store/unit_test.py
Functions: 4
============================================================

MODULE FUNCTIONS:
----------------------------------------
  L   5: def test_init_and_warmup()

  L  10: def test_register_buffer()

  L  16: def test_set_and_get()

  L  28: def test_exists()


============================================================
FILE: python/sglang/srt/mem_cache/storage/nixl/hicache_nixl.py
Functions: 9
============================================================


CLASS: HiCacheNixl
----------------------------------------
  L  29: __init__(self, file_path: str, plugin: str)
         üìù Initialize NIXL storage connector.

  L  49: register_buffers(self, buffers: Union[torch.Tensor, List[torch.Tensor], List[tuple]])
         ‚Üí Optional[Any]
         üìù Register tensor(s) or target locations in host memory (list of addr,len tuples) with NIXL.

  L  59: register_files(self, file_paths: List[str], open_file: Optional[bool])
         ‚Üí Optional[Any]
         üìù Register files with NIXL.

  L  66: register_objects(self, keys: List[str], sizes: Optional[List[int]])
         ‚Üí Optional[Any]
         üìù Register objects with NIXL.

  L 161: get(self, key: str, target_location: Optional[torch.Tensor | int], target_sizes: Optional[int])
         ‚Üí torch.Tensor | None

  L 176: batch_get(self, keys: List[str], target_locations: Optional[List[torch.Tensor | int]], target_sizes: Optional[List[int]])
         ‚Üí List[torch.Tensor | None]

  L 204: set(self, key: str, value: Optional[torch.Tensor], target_location: Optional[int], target_sizes: Optional[int])
         ‚Üí bool

  L 216: batch_set(self, keys: List[str], values: Optional[List[torch.Tensor]], target_locations: Optional[List[int]], target_sizes: Optional[List[int]])
         ‚Üí bool

  L 243: exists(self, key: str)
         ‚Üí bool


============================================================
FILE: python/sglang/srt/mem_cache/storage/nixl/nixl_utils.py
Functions: 11
============================================================


CLASS: NixlBackendSelection
----------------------------------------
  L  18: __init__(self, plugin: str)
         üìù Initialize backend selection.
            Args:
            plugin: Plugin to use (default "auto" selects best available).
            Can be a file plugin (3FS, POSIX, GDS, GDS_MT) or
            an object plugin (OBJ).

  L  29: set_bucket(self, bucket_name: str)
         ‚Üí None
         üìù Set AWS bucket name in environment variable.

  L  34: create_backend(self, agent)
         ‚Üí bool
         üìù Create the appropriate NIXL backend based on configuration.


CLASS: NixlFileManager
----------------------------------------
  L 145: __init__(self, base_dir: str)
         üìù Initialize file manager.
            Args:
            base_dir: Base directory for storing tensor files

  L 158: get_file_path(self, key: str)
         ‚Üí str
         üìù Get full file path for a given key.

  L 162: create_file(self, file_path: str)
         ‚Üí bool
         üìù Create a file if it doesn't exist.

  L 174: open_file(self, file_path: str)
         ‚Üí Optional[int]
         üìù Open a file and return its file descriptor.

  L 183: close_file(self, fd: int)
         ‚Üí bool
         üìù Close a file descriptor.

  L 192: files_to_nixl_tuples(self, file_paths: List[str])
         ‚Üí List[Tuple[int, int, int, str]]
         üìù Create NIXL tuples (offset, length, fd, file_path) for given files.


CLASS: NixlRegistration
----------------------------------------
  L  89: __init__(self, agent)

  L  92: create_query_tuples(self, key: str, mem_type: str, file_manager)
         ‚Üí List[Tuple]
         üìù Create NIXL tuples for querying memory.
            Args:
            key: Key to query (file path for FILE or object key for OBJ)
            mem_type: Memory type ("FILE" or "OBJ")
            file_manager: Optional NixlFileManager for FILE memory type
            Returns:
            List of NIXL tuples for querying


============================================================
FILE: python/sglang/srt/mem_cache/storage/nixl/test_hicache_nixl_storage.py
Functions: 14
============================================================


CLASS: TestNixlUnified
----------------------------------------
  L  20: setUp(self)
         üìù Set up test environment.

  L  39: tearDown(self)
         üìù Clean up test directories.

  L  46: delete_test_file(self, file_path: str)
         ‚Üí bool
         üìù Helper method to delete a test file.
            Args:
            file_path: Path to the file to delete
            Returns:
            bool: True if file was deleted or didn't exist, False on error

  L  62: verify_tensors_equal(self, expected: torch.Tensor, actual: torch.Tensor)
         üìù Helper to verify tensor equality.

  L  70: verify_tensor_lists_equal(self, expected: List[torch.Tensor], actual: List[torch.Tensor])
         üìù Helper to verify lists of tensors are equal.

  L  82: test_single_set_get(self)
         üìù Test single tensor set/get operations.

  L 115: test_batch_set_get(self)
         üìù Test batch tensor set/get operations.

  L 150: test_mixed_operations(self)
         üìù Test mixing single and batch operations.

  L 169: test_data_integrity(self)
         üìù Test data integrity across operations.

  L 195: test_basic_file_operations(self)
         üìù Test basic file operations.

  L 206: test_create_nixl_tuples(self)
         üìù Test creation of NIXL tuples.

  L 216: test_error_handling(self)
         üìù Test error handling in file operations.

  L 226: test_register_buffers(self)
         üìù Test registration of memory buffers.

  L 238: test_register_files_with_tuples(self)
         üìù Test registration of files using NIXL tuples.


============================================================
FILE: python/sglang/srt/mem_cache/swa_radix_cache.py
Functions: 38
============================================================

MODULE FUNCTIONS:
----------------------------------------
  L 113: def gen_swa_uuid()
         ‚Üí int


CLASS: LRUList
----------------------------------------
  L 119: __init__(self, swa: bool)

  L 168: reset_node_mru(self, node)
         üìù Move a (existing) node to most recently used position

  L 179: reset_node_and_parents_mru(self, node, root_node)
         üìù Move an (existing) node and its parents to most recently used position. Child node is
            more recently used than parent node.

  L 196: insert_mru(self, node)
         üìù Insert a (new) node as most recently used

  L 209: remove_node(self, node: TreeNode)
         üìù Remove node from lru list

  L 220: get_lru_no_lock(self)
         ‚Üí Optional[TreeNode]
         üìù Get the least recently used node that is not locked

  L 226: get_leaf_lru_no_lock(self)
         ‚Üí Optional[TreeNode]
         üìù Get the least recently used leaf node that is not locked

  L 232: get_prev_no_lock(self, node: TreeNode, check_id: bool)
         ‚Üí Optional[TreeNode]
         üìù Get the previous (i.e. more recently used) node that is not locked

  L 250: get_prev_leaf_no_lock(self, node: TreeNode, check_id: bool)
         üìù Get the previous (i.e. more recently used) leaf node that is not locked

  L 266: in_list(self, node: Optional[TreeNode])
         üìù Check if the node is in the lru list

  L 275: sanity_check_evictable_size(self)
         üìù Check the evictable size (i.e. the size of the nodes that are not locked)

  L 287: sanity_check(self, tree_cache: 'SWARadixCache')
         üìù Check if the lru list is valid by rebuilding the lru list from the tree, heapifying it, and
            checking if the lru list is valid.


CLASS: SWARadixCache
----------------------------------------
  L 340: __init__(self, req_to_token_pool: ReqToTokenPool, token_to_kv_pool_allocator: SWATokenToKVPoolAllocator, sliding_window_size: int, page_size: int, disable: bool)

  L 371: reset(self)
         ‚Üí None

  L 385: match_prefix(self, key: List[int])
         ‚Üí MatchResult
         üìù Find the matching prefix from the radix tree.
            Args:
            key: A list of token IDs to find a matching prefix.
            Returns:
            A tuple of a tensor of matching prefix token IDs and
            the last node that contains the prefix values. Note that
            this API can modify the internal state of the Radix tree.
            The last node create a new child if the prefix is shorter
            than the last node's value.

  L 422: insert(self, key: List, value, prev_prefix_len: int)
         ‚Üí int

  L 430: cache_finished_req(self, req: Req)
         ‚Üí None
         üìù Cache request when it finishes.

  L 467: cache_unfinished_req(self, req: Req, chunked)
         ‚Üí None
         üìù Cache request when it is unfinished.

  L 521: pretty_print(self)
         ‚Üí None

  L 526: total_size(self)
         ‚Üí Tuple[int, int]

  L 529: evict(self, full_num_tokens: int, swa_num_tokens: int)
         ‚Üí None

  L 612: inc_lock_ref(self, node: TreeNode)
         ‚Üí Optional[int]
         üìù Increment the lock reference count for the node. Returns the swa_uuid_for_lock, which needs
            to be passed to dec_lock_ref.
            It locks the full_lock_ref for nodes between the [last node, root), exclusive.
            It locks the swa_lock_ref for nodes between the [last node, swa_uuid_for_lock], inclusive.

  L 653: dec_lock_ref(self, node: TreeNode, swa_uuid_for_lock: Optional[int])
         üìù Decrement the lock reference count for the node.
            It unlocks the full_lock_ref for nodes between the [last node, root), exclusive.
            It unlocks the swa_lock_ref for nodes between the [last node, swa_uuid_for_lock], inclusive.
            If swa_uuid_for_lock is None, it unlocks to the root, exclusive.

  L 690: sanity_check(self)

  L 694: evictable_size(self)
         ‚Üí Tuple[int, int]

  L 698: full_evictable_size(self)
         ‚Üí int

  L 701: swa_evictable_size(self)
         ‚Üí int

  L 705: full_lru_list_evictable_size(self)
         ‚Üí int

  L 709: swa_lru_list_evictable_size(self)
         ‚Üí int

  L 712: protected_size(self)
         ‚Üí Tuple[int, int]

  L 716: full_protected_size(self)
         ‚Üí int

  L 720: swa_protected_size(self)
         ‚Üí int

  L 724: all_values_flatten(self)
         ‚Üí torch.Tensor


CLASS: TreeNode
----------------------------------------
  L  47: __init__(self, id: Optional[int])

  L  81: evicted(self)

  L  85: backuped(self)

  L  88: __lt__(self, other: 'TreeNode')


============================================================
FILE: python/sglang/srt/metrics/collector.py
Functions: 12
============================================================


CLASS: SchedulerMetricsCollector
----------------------------------------
  L 153: __init__(self, labels: Dict[str, str])
         ‚Üí None

  L 275: increment_bootstrap_failed_reqs(self)
         ‚Üí None

  L 278: increment_transfer_failed_reqs(self)
         ‚Üí None

  L 281: log_stats(self, stats: SchedulerStats)
         ‚Üí None


CLASS: TimeStats
----------------------------------------
  L  51: __str__(self)
         ‚Üí str

  L 106: format_duration(self, duration: float)
         ‚Üí str

  L 109: get_type(self)
         ‚Üí RequestType
         üìù Determine the type of request based on timestamp values.


CLASS: TokenizerMetricsCollector
----------------------------------------
  L 310: __init__(self, labels: Dict[str, str], bucket_time_to_first_token: Optional[List[float]], bucket_inter_token_latency: Optional[List[float]], bucket_e2e_request_latency: Optional[List[float]], collect_tokens_histogram: bool)
         ‚Üí None

  L 516: observe_one_finished_request(self, prompt_tokens: int, generation_tokens: int, cached_tokens: int, e2e_latency: float, has_grammar: bool)

  L 536: observe_time_to_first_token(self, value: float)

  L 539: observe_inter_token_latency(self, internval: float, num_new_tokens: int)

  L 552: observe_one_aborted_request(self)


============================================================
FILE: python/sglang/srt/metrics/func_timer.py
Functions: 3
============================================================

MODULE FUNCTIONS:
----------------------------------------
  L  26: def enable_func_timer()

  L  45: def exponential_buckets(start: float, width: float, length: int)
         ‚Üí List[float]

  L  52: def time_func_latency(func: Callable, name: Optional[str])
         ‚Üí Callable[..., Any]
         üìù A decorator to observe the latency of a function's execution. Supports both sync and async functions.
            NOTE: We use our own implementation of a timer decorator since prometheus_client does not support async
            context manager yet.
            Overhead: The overhead introduced here in case of an async function could likely be because of `await` introduced
            which will return in another coroutine object creation and under heavy load could see longer wall time
            (scheduling delays due to introduction of another awaitable).


============================================================
FILE: python/sglang/srt/model_executor/cuda_graph_runner.py
Functions: 16
============================================================

MODULE FUNCTIONS:
----------------------------------------
  L  73: def get_is_capture_mode()

  L  78: def model_capture_mode()
         @contextmanager

  L  88: def freeze_gc(enable_cudagraph_gc: bool)
         üìù Optimize garbage collection during CUDA graph capture.
            Clean up, then freeze all remaining objects from being included
            in future collections if GC is disabled during capture.
         @contextmanager

  L 117: def patch_model(model: torch.nn.Module,
        enable_compile: bool,
        num_tokens: int,
        tp_group: GroupCoordinator)
         üìù Patch the model to make it compatible with with torch.compile
         @contextmanager

  L 149: def set_torch_compile_config()

  L 165: def get_batch_sizes_to_capture(model_runner: ModelRunner)

  L 228: def get_global_graph_memory_pool()

  L 232: def set_global_graph_memory_pool(val)


CLASS: CudaGraphRunner
----------------------------------------
  L 240: __init__(self, model_runner: ModelRunner)

  L 393: can_run(self, forward_batch: ForwardBatch)

  L 445: capture(self)
         ‚Üí None

  L 520: capture_one_batch_size(self, bs: int, forward: Callable)

  L 675: recapture_if_needed(self, forward_batch: ForwardBatch)

  L 706: replay_prepare(self, forward_batch: ForwardBatch, pp_proxy_tensors: Optional[PPProxyTensors])

  L 796: replay(self, forward_batch: ForwardBatch, skip_attn_backend_init: bool, pp_proxy_tensors: Optional[PPProxyTensors])
         ‚Üí Union[LogitsProcessorOutput, PPProxyTensors]

  L 826: get_spec_info(self, num_tokens: int)


============================================================
FILE: python/sglang/srt/model_executor/forward_batch_info.py
Functions: 44
============================================================

MODULE FUNCTIONS:
----------------------------------------
  L 875: def enable_num_token_non_padded(server_args)

  L 909: def compute_position(attn_backend: str,
        extend_prefix_lens: torch.Tensor,
        extend_seq_lens: torch.Tensor,
        extend_seq_lens_sum: int)

  L 928: def compute_position_triton(extend_prefix_lens: torch.Tensor,
        extend_seq_lens: torch.Tensor,
        extend_seq_lens_sum)
         üìù Compute positions. It is a fused version of `compute_position_torch`.

  L 955: def compute_position_kernel(positions,
        extend_start_loc,
        extend_prefix_lens,
        extend_seq_lens,
        has_prefix: tl.constexpr)
         @triton.jit

  L 984: def compute_position_torch(extend_prefix_lens: torch.Tensor,
        extend_seq_lens: torch.Tensor)

  L1002: def clamp_position(seq_lens)
         @torch.compile(dynamic=True, backend=get_compiler_backend(), disable=_is_npu)

  L1007: def create_chunked_prefix_cache_kv_indices(req_to_token_ptr,
        req_pool_indices_ptr,
        chunk_start_idx_ptr,
        chunk_seq_lens_ptr,
        chunk_cu_seq_lens_ptr,
        chunk_kv_indices_ptr,
        req_to_token_ptr_stride: tl.constexpr)
         @triton.jit


CLASS: CaptureHiddenMode
----------------------------------------
  L 151: need_capture(self)

  L 154: is_full(self)

  L 157: is_last(self)

  L 160: __lt__(self, other)


CLASS: ForwardBatch
----------------------------------------
  L 310: init_new(cls, batch: ModelWorkerBatch, model_runner: ModelRunner)

  L 456: merge_mm_inputs(self)
         ‚Üí Optional[MultimodalInputs]
         üìù Merge all multimodal inputs in the batch into a single MultiModalInputs object.
            Returns:
            if none, current batch contains no multimodal input

  L 479: contains_image_inputs(self)
         ‚Üí bool

  L 487: contains_audio_inputs(self)
         ‚Üí bool

  L 495: contains_video_inputs(self)
         ‚Üí bool

  L 503: contains_mm_inputs(self)
         ‚Üí bool

  L 568: get_max_chunk_capacity(self)

  L 573: set_prefix_chunk_idx(self, idx: int)

  L 576: set_attn_attend_prefix_cache(self, attn_attend_prefix_cache: bool)

  L 579: prepare_chunked_kv_indices(self, device: torch.device)

  L 617: prepare_mlp_sync_batch(self, model_runner: ModelRunner)

  L 733: post_forward_mlp_sync_batch(self, logits_output: LogitsProcessorOutput)

  L 789: get_prefix_chunk_seq_lens(self, prefix_lens: torch.Tensor, num_prefix_chunks: int, prefix_chunk_len: int)

  L 812: prepare_chunked_prefix_cache_info(self, device: torch.device)

  L 871: can_run_tbo(self)


CLASS: ForwardMode
----------------------------------------
  L  92: is_prefill(self)

  L  95: is_extend(self)

  L 103: is_decode(self)

  L 106: is_mixed(self)

  L 109: is_idle(self)

  L 112: is_decode_or_idle(self)

  L 115: is_target_verify(self)

  L 118: is_draft_extend(self)

  L 121: is_extend_or_draft_extend_or_mixed(self)

  L 128: is_cuda_graph(self)

  L 135: is_dummy_first(self)

  L 138: is_split_prefill(self)


CLASS: PPProxyTensors
----------------------------------------
  L 883: __init__(self, tensors)

  L 890: __getitem__(self, key: Union[str, slice])

  L 896: __setitem__(self, key: str, value: torch.Tensor)

  L 899: __len__(self)

  L 902: __eq__(self, other: object)

  L 905: __repr__(self)
         ‚Üí str


============================================================
FILE: python/sglang/srt/model_executor/model_runner.py
Functions: 35
============================================================


CLASS: LocalSerializedTensor
----------------------------------------
  L1912: get(self, rank: int)


CLASS: ModelRunner
----------------------------------------
  L 162: __init__(self, model_config: ModelConfig, mem_fraction_static: float, gpu_id: int, tp_rank: int, tp_size: int, moe_ep_rank: int, moe_ep_size: int, pp_rank: int, pp_size: int, nccl_port: int, server_args: ServerArgs, dp_rank: Optional[int], is_draft_worker: bool, req_to_token_pool: Optional[ReqToTokenPool], token_to_kv_pool_allocator: Optional[BaseTokenToKVPoolAllocator])

  L 255: initialize(self, min_per_gpu_memory: float)

  L 385: model_specific_adjustment(self)

  L 554: init_torch_distributed(self)

  L 650: load_model(self)

  L 757: update_expert_location(self, new_expert_location_metadata: ExpertLocationMetadata, update_layer_ids: List[int])

  L 770: update_weights_from_disk(self, model_path: str, load_format: str)
         ‚Üí tuple[bool, str]
         üìù Update engine weights in-place from the disk.

  L 825: init_weights_update_group(self, master_address, master_port, rank_offset, world_size, group_name, backend)
         üìù Initialize the Torch process group for model parameter updates.
            `_model_update_group` is used in the RLHF workflow, where rank
            0 is the actor model in the training engine, and the other ranks are
            the inference engine, which is used for rollout.
            In the RLHF workflow, the training engine updates the model
            weights/parameters online, and broadcasts them to the inference
            engine through the `_model_update_group` process group.

  L 870: update_weights_from_distributed(self, names, dtypes, shapes, group_name)
         üìù Update specific parameter in the model weights online
            through `_model_update_group` process group.
            Args:
            name: the name of the parameter to be updated.
            dtype: the data type of the parameter to be updated.
            shape: the shape of the parameter to be updated.

  L 918: update_weights_from_tensor(self, named_tensors: List[Tuple[str, Union[torch.Tensor, 'LocalSerializedTensor']]], load_format: Optional[str])

  L 981: get_weights_by_name(self, name: str, truncate_size: int)
         ‚Üí Optional[torch.Tensor]
         üìù Get the weights of the parameter by its name. Similar to `get_parameter` in Hugging Face.
            Only used for unit test with an unoptimized performance.
            For optimized performance, please use torch.save and torch.load.

  L 998: init_lora_manager(self)

  L1013: load_lora_adapter(self, lora_ref: LoRARef)
         üìù Load a new lora adapter from disk or huggingface.

  L1030: unload_lora_adapter(self, lora_ref: LoRARef)
         üìù Unload a lora adapter that was previously loaded during initialization or dynamic loading.

  L1047: profile_max_num_token(self, total_gpu_memory: int)

  L1082: set_num_token_hybrid(self)

  L1164: init_memory_pool(self, total_gpu_memory: int, max_num_reqs: Optional[int], max_total_tokens: Optional[int])

  L1417: init_cublas(self)
         üìù We need to run a small matmul to init cublas. Otherwise, it will raise some errors later.

  L1426: init_attention_backend(self)
         üìù Init attention kernel backend.

  L1588: init_double_sparsity_channel_config(self, selected_channel)

  L1605: init_device_graphs(self)
         üìù Capture cuda graphs.

  L1632: init_threads_binding(self)

  L1656: apply_torch_tp(self)

  L1663: forward_decode(self, forward_batch: ForwardBatch, skip_attn_backend_init: bool, pp_proxy_tensors)
         ‚Üí LogitsProcessorOutput

  L1682: forward_extend(self, forward_batch: ForwardBatch, skip_attn_backend_init: bool, pp_proxy_tensors)
         ‚Üí LogitsProcessorOutput

  L1705: forward_idle(self, forward_batch: ForwardBatch, pp_proxy_tensors)
         ‚Üí LogitsProcessorOutput

  L1718: forward_split_prefill(self, forward_batch: ForwardBatch, reinit_attn_backend: bool, forward_count: int)
         ‚Üí LogitsProcessorOutput

  L1739: forward(self, forward_batch: ForwardBatch, skip_attn_backend_init: bool, pp_proxy_tensors: Optional[PPProxyTensors], reinit_attn_backend: bool, split_forward_count: int)
         ‚Üí Tuple[Union[LogitsProcessorOutput, PPProxyTensors], bool]

  L1833: sample(self, logits_output: LogitsProcessorOutput, forward_batch: ForwardBatch)
         ‚Üí torch.Tensor
         üìù Sample and compute logprobs and update logits_output.
            Args:
            logits_output: The logits output from the model forward
            forward_batch: The forward batch that generates logits_output
            Returns:
            A list of next_token_ids

  L1867: model_is_mrope(self)
         ‚Üí bool
         üìù Detect if the model has "mrope" rope_scaling type.
            mrope requires keep "rope_deltas" between prompt and decoding phases.

  L1876: save_remote_model(self, url: str)

  L1882: save_sharded_model(self, path: str, pattern: Optional[str], max_size: Optional[int])


CLASS: RankZeroFilter
----------------------------------------
  L 149: __init__(self, is_rank_zero)

  L 153: filter(self, record)


============================================================
FILE: python/sglang/srt/model_executor/npu_graph_runner.py
Functions: 2
============================================================


CLASS: NPUGraphRunner
----------------------------------------
  L  38: __init__(self, model_runner: ModelRunner)

  L  62: replay(self, forward_batch: ForwardBatch, skip_attn_backend_init: bool, pp_proxy_tensors: Optional[PPProxyTensors])
         ‚Üí Union[LogitsProcessorOutput, PPProxyTensors]


============================================================
FILE: python/sglang/srt/model_loader/__init__.py
Functions: 1
============================================================

MODULE FUNCTIONS:
----------------------------------------
  L  15: def get_model()
         ‚Üí nn.Module


============================================================
FILE: python/sglang/srt/model_loader/loader.py
Functions: 30
============================================================

MODULE FUNCTIONS:
----------------------------------------
  L  77: def device_loading_context(module: torch.nn.Module, target_device: torch.device)
         @contextmanager

  L1514: def load_model_with_cpu_quantization(self)
         ‚Üí nn.Module

  L1546: def get_model_loader(load_config: LoadConfig)
         ‚Üí BaseModelLoader
         üìù Get a model loader based on the load format.


CLASS: BaseModelLoader
----------------------------------------
  L 214: __init__(self, load_config: LoadConfig)

  L 218: download_model(self, model_config: ModelConfig)
         ‚Üí None
         üìù Download a model so that it can be immediately loaded.

  L 223: load_model(self)
         ‚Üí nn.Module
         üìù Load a model with the given configurations.


CLASS: BitsAndBytesModelLoader
----------------------------------------
  L 811: __init__(self, load_config: LoadConfig)

  L1243: download_model(self, model_config: ModelConfig)
         ‚Üí None

  L1246: load_model(self)
         ‚Üí nn.Module


CLASS: DefaultModelLoader
----------------------------------------
  L 264: __init__(self, load_config: LoadConfig)

  L 449: download_model(self, model_config: ModelConfig)
         ‚Üí None

  L 454: load_model(self)
         ‚Üí nn.Module

  L 475: load_weights_and_postprocess(model, weights, target_device)


CLASS: DummyModelLoader
----------------------------------------
  L 565: __init__(self, load_config: LoadConfig)

  L 573: download_model(self, model_config: ModelConfig)
         ‚Üí None

  L 576: load_model(self)
         ‚Üí nn.Module


CLASS: GGUFModelLoader
----------------------------------------
  L1271: __init__(self, load_config: LoadConfig)

  L1335: download_model(self, model_config: ModelConfig)
         ‚Üí None

  L1338: load_model(self)
         ‚Üí nn.Module


CLASS: LayeredModelLoader
----------------------------------------
  L 494: __init__(self, load_config: LoadConfig)

  L 499: load_model(self)
         ‚Üí nn.Module


CLASS: RemoteModelLoader
----------------------------------------
  L1372: __init__(self, load_config: LoadConfig)

  L1394: download_model(self, model_config: ModelConfig)
         ‚Üí None

  L1398: save_model(model: torch.nn.Module, model_path: str, url: str)
         ‚Üí None

  L1475: load_model(self)
         ‚Üí nn.Module


CLASS: ShardedStateLoader
----------------------------------------
  L 619: __init__(self, load_config: LoadConfig)

  L 683: download_model(self, model_config: ModelConfig)
         ‚Üí None

  L 686: load_model(self)
         ‚Üí nn.Module

  L 750: save_model(model: torch.nn.Module, path: str, pattern: Optional[str], max_size: Optional[int])
         ‚Üí None


CLASS: Source
----------------------------------------
  L 256: init_new(cls, model_config: ModelConfig, model)


============================================================
FILE: python/sglang/srt/model_loader/utils.py
Functions: 5
============================================================

MODULE FUNCTIONS:
----------------------------------------
  L  19: def set_default_torch_dtype(dtype: torch.dtype)
         üìù Sets the default torch dtype to the given dtype.
         @contextlib.contextmanager

  L  27: def resolve_transformers_arch(model_config: ModelConfig,
        architectures: list[str])

  L  82: def get_model_architecture(model_config: ModelConfig)
         ‚Üí Tuple[Type[nn.Module], str]

  L 106: def get_architecture_class_name(model_config: ModelConfig)
         ‚Üí str

  L 110: def post_load_weights(model: nn.Module, model_config: ModelConfig)


============================================================
FILE: python/sglang/srt/model_loader/weight_utils.py
Functions: 35
============================================================

MODULE FUNCTIONS:
----------------------------------------
  L  51: def enable_hf_transfer()
         üìù automatically activates hf_transfer

  L  71: def get_lock(model_name_or_path: str, cache_dir: Optional[str])

  L  94: def convert_bin_to_safetensor_file(pt_filename: str, sf_filename: str)
         ‚Üí None

  L 134: def get_quant_config(model_config: ModelConfig,
        load_config: LoadConfig,
        packed_modules_mapping: Dict[str,
        List[str]])
         ‚Üí QuantizationConfig

  L 238: def download_weights_from_hf(model_name_or_path: str,
        cache_dir: Optional[str],
        allow_patterns: List[str],
        revision: Optional[str],
        ignore_patterns: Optional[Union[str,
        List[str]]])
         ‚Üí str
         üìù Download model weights from Hugging Face Hub.
            Args:
            model_name_or_path (str): The model name or path.
            cache_dir (Optional[str]): The cache directory to store the model
            weights. If None, will use HF defaults.
            allow_patterns (List[str]): The allowed patterns for the
            weight files. Files matched by any of the patterns will be
            downloaded.
            revision (Optional[str]): The revision of the model.
            ignore_patterns (Optional[Union[str, List[str]]]): The patterns to
            filter out the weight files. Files matched by any of the patterns
            will be ignored.
            Returns:
            str: The path to the downloaded model weights.

  L 290: def download_safetensors_index_file_from_hf(model_name_or_path: str,
        index_file: str,
        cache_dir: Optional[str],
        revision: Optional[str])
         ‚Üí None
         üìù Download hf safetensors index file from Hugging Face Hub.
            Args:
            model_name_or_path (str): The model name or path.
            cache_dir (Optional[str]): The cache directory to store the model
            weights. If None, will use HF defaults.
            revision (Optional[str]): The revision of the model.

  L 329: def filter_duplicate_safetensors_files(hf_weights_files: List[str],
        hf_folder: str,
        index_file: str)
         ‚Üí List[str]

  L 350: def filter_files_not_needed_for_inference(hf_weights_files: List[str])
         ‚Üí List[str]
         üìù Exclude files that are not needed for inference.
            See https://github.com/huggingface/transformers/blob/v4.34.0/src/transformers/trainer.py#L227-L233

  L 376: def np_cache_weights_iterator(model_name_or_path: str,
        cache_dir: Optional[str],
        hf_folder: str,
        hf_weights_files: List[str])
         ‚Üí Generator[Tuple[str, torch.Tensor], None, None]
         üìù Iterate over the weights in the model np files.
            Will dump the model weights to numpy files if they are not already dumped.

  L 424: def decrypt(fn, key)

  L 428: def safetensors_encrypted_weights_iterator(hf_weights_files: List[str],
        is_all_weights_sharded: bool,
        decryption_key: Optional[str])

  L 436: def safetensors_weights_iterator(hf_weights_files: List[str],
        is_all_weights_sharded: bool,
        decryption_key: Optional[str],
        disable_mmap: bool)
         ‚Üí Generator[Tuple[str, torch.Tensor], None, None]
         üìù Iterate over the weights in the model safetensor files.
            If is_all_weights_sharded is True, it uses more optimize read by reading an
            entire file instead of reading each tensor one by one.

  L 473: def multi_thread_safetensors_weights_iterator(hf_weights_files: List[str],
        is_all_weights_sharded: bool,
        decryption_key: Optional[str],
        max_workers: int,
        disable_mmap: bool)
         ‚Üí Generator[Tuple[str, torch.Tensor], None, None]
         üìù Multi-Thread iterate over the weights in the model safetensor files.
            If is_all_weights_sharded is True, it uses more optimize read by reading an
            entire file instead of reading each tensor one by one.

  L 528: def pt_weights_iterator(hf_weights_files: List[str])
         ‚Üí Generator[Tuple[str, torch.Tensor], None, None]
         üìù Iterate over the weights in the model bin/pt files.

  L 546: def multi_thread_pt_weights_iterator(hf_weights_files: List[str],
        max_workers: int)
         ‚Üí Generator[Tuple[str, torch.Tensor], None, None]
         üìù Multi-Thread iterate over the weights in the model bin/pt files.

  L 579: def get_gguf_extra_tensor_names(gguf_file: str,
        gguf_to_hf_name_map: Dict[str,
        str])
         ‚Üí List[str]

  L 591: def gguf_quant_weights_iterator(gguf_file: str,
        gguf_to_hf_name_map: Dict[str,
        str])
         ‚Üí Generator[Tuple[str, torch.Tensor], None, None]
         üìù Iterate over the quant weights in the model gguf files and convert
            them to torch tensors

  L 625: def convert_pyslice_to_tensor(x: Any)
         ‚Üí torch.Tensor
         üìù convert PySafeSlice object from safetensors to torch.Tensor
            PySafeSlice object supports indexing, which is done before loading the
            actual tensor and can reduce the amount of memory being read into the
            memory. However, it does not support more advanced functionalities
            like `.view()` or `.t()`. Therefore, if we need to modify the loaded
            tensor with these more complicated operators, we need to convert to
            tensor first.

  L 640: def default_weight_loader(param: torch.Tensor, loaded_weight: torch.Tensor)
         ‚Üí None
         üìù Default weight loader.

  L 661: def row_parallel_weight_loader(param: torch.Tensor, loaded_weight: torch.Tensor)
         ‚Üí None
         üìù Load weights that are row-parallelized.

  L 679: def sharded_weight_loader(shard_axis: int)
         ‚Üí LoaderFunction
         üìù Create a weight loader that shards the weights along the given axis

  L 694: def composed_weight_loader(loader: LoaderFunction,
        fn: Callable[[torch.Tensor],
        torch.Tensor])
         ‚Üí LoaderFunction
         üìù Create a weight loader that post-processes the weights after loading

  L 707: def runai_safetensors_weights_iterator(hf_weights_files: List[str])
         ‚Üí Generator[Tuple[str, torch.Tensor], None, None]
         üìù Iterate over the weights in the model safetensor files.

  L 728: def set_runai_streamer_env(load_config: LoadConfig)

  L 752: def initialize_dummy_weights(model: torch.nn.Module,
        low: float,
        high: float,
        seed: int)
         ‚Üí None
         üìù Initialize model weights with random values.
            The model weights must be randomly initialized for accurate performance
            measurements. Additionally, the model weights should not cause NaNs in the
            forward pass. We empirically found that initializing the weights with
            values between -1e-3 and 1e-3 works well for most models.
            We use per-parameter random seed, so that dummy weights are consistent,
            even if the model is partitioned across multiple devices. When the seed
            is fixed, the random values generated by this function only depends on
            the parameter's number of elements and its data type.

  L 784: def maybe_remap_kv_scale_name(name: str, params_dict: dict)
         ‚Üí Optional[str]
         üìù Remap the name of FP8 k/v_scale parameters.
            This function handles the remapping of FP8 k/v_scale parameter names.
            It detects if the given name ends with a suffix and attempts to remap
            it to the expected name format in the model. If the remapped name is not
            found in the params_dict, a warning is printed and None is returned.
            Args:
            name (str): The original loaded checkpoint parameter name.
            params_dict (dict): Dictionary containing the model's named parameters.
            Returns:
            str: The remapped parameter name if successful, or the original name
            if no remapping is needed.
            None: If the remapped name is not found in params_dict.

  L 935: def kv_cache_scales_loader(filename: str,
        tp_rank: int,
        tp_size: int,
        num_hidden_layers: int,
        model_type: Optional[str])
         ‚Üí Iterable[Tuple[int, float]]
         üìù A simple utility to read in KV cache scaling factors that have been
            previously serialized to disk. Used by the model to populate the appropriate
            KV cache scaling factors. The serialization should represent a dictionary
            whose keys are the TP ranks and values are another dictionary mapping layers
            to their KV cache scaling factors.

  L 978: def get_actual_shard_size(shard_size, weight_start, weight_end)

  L 985: def reset_param_data_if_needed(param_data, dim, start, length)

  L 995: def narrow_padded_param_and_loaded_weight(param_data,
        loaded_weight,
        param_data_start,
        weight_start,
        dim,
        shard_size,
        narrow_weight)


CLASS: DisabledTqdm
----------------------------------------
  L  67: __init__(self)


CLASS: KVCacheQuantSchema
----------------------------------------
  L 870: check_is_fp8(self)
         ‚Üí 'KVCacheQuantSchema'

  L 878: check_tp_ranks(self, info: ValidationInfo)
         ‚Üí 'KVCacheQuantSchema'

  L 900: check_current_rank(self, info: ValidationInfo)
         ‚Üí 'KVCacheQuantSchema'


CLASS: QuantParamSchema
----------------------------------------
  L 922: check_model_type(self, info: ValidationInfo)
         ‚Üí 'QuantParamSchema'


============================================================
FILE: python/sglang/srt/model_parallel.py
Functions: 1
============================================================

MODULE FUNCTIONS:
----------------------------------------
  L 121: def tensor_parallel(module: torch.nn.Module, device_mesh: Optional[DeviceMesh])
         üìù Tensor parallelize the model across the given device mesh.
            Args:
            module (`torch.nn.Module`):
            The module to tensor parallelize.
            device_mesh (`torch.distributed.DeviceMesh`):
            The device mesh to use for tensor parallelism.


============================================================
FILE: python/sglang/srt/models/arcee.py
Functions: 16
============================================================


CLASS: ArceeAttention
----------------------------------------
  L 105: __init__(self, config: LlamaConfig, hidden_size: int, num_heads: int, num_kv_heads: int, layer_id: int, rope_theta: float, rope_scaling: Optional[Dict[str, Any]], rope_is_neox_style: bool, max_position_embeddings: int, quant_config: Optional[QuantizationConfig], prefix: str, bias: bool)
         ‚Üí None

  L 178: forward(self, positions: torch.Tensor, hidden_states: torch.Tensor, forward_batch: ForwardBatch)
         ‚Üí torch.Tensor


CLASS: ArceeDecoderLayer
----------------------------------------
  L 193: __init__(self, config: LlamaConfig, layer_id: int, quant_config: Optional[QuantizationConfig], prefix: str)
         ‚Üí None

  L 241: forward(self, positions: torch.Tensor, hidden_states: torch.Tensor, forward_batch: ForwardBatch, residual: Optional[torch.Tensor])
         ‚Üí Tuple[torch.Tensor, torch.Tensor]


CLASS: ArceeForCausalLM
----------------------------------------
  L 393: __init__(self, config: LlamaConfig, quant_config: Optional[QuantizationConfig], prefix: str)
         ‚Üí None

  L 432: forward(self, input_ids: torch.Tensor, positions: torch.Tensor, forward_batch: ForwardBatch, input_embeds: torch.Tensor, get_embedding: bool, pp_proxy_tensors: Optional[PPProxyTensors])
         ‚Üí LogitsProcessorOutput

  L 468: start_layer(self)

  L 472: end_layer(self)

  L 475: get_input_embeddings(self)
         ‚Üí nn.Embedding

  L 478: load_weights(self, weights: Iterable[Tuple[str, torch.Tensor]])

  L 528: load_kv_cache_scales(self, quantization_param_path: str)
         ‚Üí None


CLASS: ArceeMLP
----------------------------------------
  L  63: __init__(self, hidden_size: int, intermediate_size: int, hidden_act: str, quant_config: Optional[QuantizationConfig], prefix: str, reduce_results: bool)
         ‚Üí None

  L  97: forward(self, x, forward_batch)


CLASS: ArceeModel
----------------------------------------
  L 267: __init__(self, config: LlamaConfig, quant_config: Optional[QuantizationConfig], prefix: str)
         ‚Üí None

  L 304: forward(self, input_ids: torch.Tensor, positions: torch.Tensor, forward_batch: ForwardBatch, input_embeds: torch.Tensor, pp_proxy_tensors: Optional[PPProxyTensors])
         ‚Üí Union[torch.Tensor, Tuple[torch.Tensor, List[torch.Tensor]], PPProxyTensors]

  L 350: load_kv_cache_scales(self, quantization_param_path: str)
         ‚Üí None


============================================================
FILE: python/sglang/srt/models/baichuan.py
Functions: 12
============================================================


CLASS: BaiChuanAttention
----------------------------------------
  L 118: __init__(self, hidden_size: int, num_heads: int, position_embedding: str, rope_theta: float, max_position_embeddings: int, quant_config: Optional[QuantizationConfig], layer_id: int, prefix: str)

  L 202: forward(self, positions: torch.Tensor, hidden_states: torch.Tensor, forward_batch: ForwardBatch)
         ‚Üí torch.Tensor


CLASS: BaiChuanBaseForCausalLM
----------------------------------------
  L 348: __init__(self, config: PretrainedConfig, position_embedding: str, quant_config: Optional[QuantizationConfig], prefix: str)

  L 374: forward(self, input_ids: torch.Tensor, positions: torch.Tensor, forward_batch: ForwardBatch)
         ‚Üí torch.Tensor

  L 385: load_weights(self, weights: Iterable[Tuple[str, torch.Tensor]])


CLASS: BaiChuanDecoderLayer
----------------------------------------
  L 219: __init__(self, config: PretrainedConfig, position_embedding: str, layer_id: int, quant_config: Optional[QuantizationConfig], prefix: str)

  L 253: forward(self, positions: torch.Tensor, hidden_states: torch.Tensor, forward_batch: ForwardBatch, residual: Optional[torch.Tensor])
         ‚Üí Tuple[torch.Tensor, torch.Tensor]


CLASS: BaiChuanMLP
----------------------------------------
  L  78: __init__(self, hidden_size: int, intermediate_size: int, hidden_act: str, quant_config: Optional[QuantizationConfig], prefix: str)

  L 108: forward(self, x)


CLASS: BaiChuanModel
----------------------------------------
  L 280: __init__(self, config: PretrainedConfig, position_embedding: str, quant_config: Optional[QuantizationConfig], prefix: str)

  L 310: forward(self, input_ids: torch.Tensor, positions: torch.Tensor, forward_batch: ForwardBatch)
         ‚Üí torch.Tensor


CLASS: BaichuanForCausalLM
----------------------------------------
  L 429: __init__(self, config, quant_config: Optional[QuantizationConfig], prefix: str)


============================================================
FILE: python/sglang/srt/models/bailing_moe.py
Functions: 13
============================================================


CLASS: BailingAttention
----------------------------------------
  L  41: __init__(self, config: PretrainedConfig, layer_id: int, quant_config: Optional[QuantizationConfig], prefix: str)

  L 103: forward(self, hidden_states: torch.Tensor, position_ids: torch.Tensor, forward_batch: ForwardBatch)
         ‚Üí torch.Tensor


CLASS: BailingMLP
----------------------------------------
  L 119: __init__(self, intermediate_size: int, config: PretrainedConfig, quant_config: Optional[QuantizationConfig], reduce_results: Optional[bool], prefix: str)
         ‚Üí None

  L 145: forward(self, x)


CLASS: BailingMoE
----------------------------------------
  L 154: __init__(self, config: PretrainedConfig, layer_id: int, quant_config: Optional[QuantizationConfig], prefix: str)

  L 201: forward(self, hidden_states: torch.Tensor)
         ‚Üí torch.Tensor


CLASS: BailingMoeBlock
----------------------------------------
  L 224: __init__(self, config: PretrainedConfig, layer_id: int, quant_config: Optional[QuantizationConfig], prefix: str)

  L 246: forward(self, hidden_states: torch.Tensor, position_ids: torch.Tensor, residual: Optional[torch.Tensor], forward_batch: ForwardBatch)
         ‚Üí Tuple[torch.Tensor, torch.Tensor]


CLASS: BailingMoeForCausalLM
----------------------------------------
  L 338: __init__(self, config: PretrainedConfig, quant_config: Optional[QuantizationConfig])
         ‚Üí None

  L 356: forward(self, input_ids: torch.Tensor, positions: torch.Tensor, forward_batch: ForwardBatch, inputs_embeds: Optional[torch.Tensor])
         ‚Üí torch.Tensor

  L 368: load_weights(self, weights: Iterable[Tuple[str, torch.Tensor]])


CLASS: BailingMoeModel
----------------------------------------
  L 279: __init__(self, config: PretrainedConfig, quant_config: Optional[QuantizationConfig], prefix: str)

  L 311: forward(self, input_ids: torch.Tensor, position_ids: torch.Tensor, forward_batch: ForwardBatch, input_embeds: Optional[torch.Tensor])
         ‚Üí torch.Tensor


============================================================
FILE: python/sglang/srt/models/bert.py
Functions: 24
============================================================


CLASS: BertAttention
----------------------------------------
  L 177: __init__(self, hidden_size: int, num_attention_heads: int, layer_norm_eps: float, layer_id: int, quant_config: Optional[QuantizationConfig], prefix: str)

  L 203: forward(self, hidden_states: torch.Tensor, forward_batch: ForwardBatch)
         ‚Üí torch.Tensor


CLASS: BertEmbedding
----------------------------------------
  L  27: __init__(self, config: BertConfig)

  L  51: forward(self, input_ids: torch.Tensor, positions: torch.Tensor, forward_batch: ForwardBatch)
         ‚Üí torch.Tensor


CLASS: BertEncoder
----------------------------------------
  L 100: __init__(self, config: BertConfig, quant_config: Optional[QuantizationConfig], prefix: str)

  L 121: forward(self, hidden_states: torch.Tensor, forward_batch: ForwardBatch)
         ‚Üí torch.Tensor


CLASS: BertForSequenceClassification
----------------------------------------
  L 439: __init__(self)

  L 458: load_weights(self, weights: Iterable[Tuple[str, torch.Tensor]])

  L 478: forward(self, input_ids: torch.Tensor, positions: torch.Tensor, forward_batch: ForwardBatch, input_embeds: torch.Tensor, get_embedding: bool)
         ‚Üí torch.Tensor


CLASS: BertIntermediate
----------------------------------------
  L 295: __init__(self, hidden_size: int, intermediate_size: int, hidden_act: str, quant_config: Optional[QuantizationConfig], prefix: str)

  L 313: forward(self, hidden_states: torch.Tensor)
         ‚Üí torch.Tensor


CLASS: BertLayer
----------------------------------------
  L 131: __init__(self, config: BertConfig, layer_id: int, quant_config: Optional[QuantizationConfig], prefix: str)

  L 167: forward(self, hidden_states: torch.Tensor, forward_batch: ForwardBatch)


CLASS: BertModel
----------------------------------------
  L 351: __init__(self)

  L 375: forward(self, input_ids: torch.Tensor, positions: torch.Tensor, forward_batch: ForwardBatch, input_embeds: torch.Tensor, get_embedding: bool)
         ‚Üí torch.Tensor

  L 399: load_weights(self, weights: Iterable[Tuple[str, torch.Tensor]])
         ‚Üí Set[str]


CLASS: BertOutput
----------------------------------------
  L 321: __init__(self, hidden_size: int, intermediate_size: int, layer_norm_eps: float, quant_config: Optional[QuantizationConfig], prefix: str)

  L 341: forward(self, hidden_states: torch.Tensor, input_tensor: torch.Tensor)
         ‚Üí torch.Tensor


CLASS: BertPooler
----------------------------------------
  L  81: __init__(self, config: BertConfig)

  L  86: forward(self, hidden_states: torch.Tensor, forward_batch: ForwardBatch)
         ‚Üí torch.Tensor


CLASS: BertSelfAttention
----------------------------------------
  L 212: __init__(self, hidden_size: int, num_attention_heads: int, layer_id: int, quant_config: Optional[QuantizationConfig], prefix: str)

  L 257: forward(self, hidden_states: torch.Tensor, forward_batch: ForwardBatch)
         ‚Üí torch.Tensor


CLASS: BertSelfOutput
----------------------------------------
  L 268: __init__(self, hidden_size: int, layer_norm_eps: float, quant_config: Optional[QuantizationConfig], prefix: str)

  L 285: forward(self, hidden_states: torch.Tensor, input_tensor: torch.Tensor)
         ‚Üí torch.Tensor


============================================================
FILE: python/sglang/srt/models/chatglm.py
Functions: 13
============================================================


CLASS: ChatGLMForCausalLM
----------------------------------------
  L 380: __init__(self, config: ChatGLMConfig, quant_config: Optional[QuantizationConfig], prefix: str)

  L 397: forward(self, input_ids: torch.Tensor, positions: torch.Tensor, forward_batch: ForwardBatch)
         ‚Üí torch.Tensor

  L 408: load_weights(self, weights: Iterable[Tuple[str, torch.Tensor]])


CLASS: ChatGLMM
----------------------------------------
  L 321: __init__(self, config, quant_config: Optional[QuantizationConfig], prefix: str)

  L 348: forward(self, input_ids: torch.Tensor, position_ids: torch.Tensor, forward_batch: ForwardBatch)
         ‚Üí torch.Tensor


CLASS: GLMAttention
----------------------------------------
  L  50: __init__(self, config, layer_id: int, quant_config: Optional[QuantizationConfig], prefix: str)

  L 120: forward(self, hidden_states: torch.Tensor, position_ids: torch.Tensor, forward_batch: ForwardBatch)
         ‚Üí torch.Tensor


CLASS: GLMBlock
----------------------------------------
  L 193: __init__(self, config, layer_id: int, quant_config: Optional[QuantizationConfig], prefix: str)

  L 227: forward(self, hidden_states: torch.Tensor, position_ids: torch.Tensor, forward_batch: ForwardBatch)
         ‚Üí torch.Tensor


CLASS: GLMMLP
----------------------------------------
  L 147: __init__(self, config, quant_config: Optional[QuantizationConfig], prefix: str)

  L 177: forward(self, hidden_states)


CLASS: GLMTransformer
----------------------------------------
  L 268: __init__(self, config, quant_config: Optional[QuantizationConfig], prefix: str)

  L 300: forward(self, hidden_states: torch.Tensor, position_ids: torch.Tensor, forward_batch: ForwardBatch)
         ‚Üí torch.Tensor


============================================================
FILE: python/sglang/srt/models/clip.py
Functions: 26
============================================================

MODULE FUNCTIONS:
----------------------------------------
  L 518: def monkey_patch_weight_loader()


CLASS: CLIPEncoder
----------------------------------------
  L 219: __init__(self, config: CLIPVisionConfig, quant_config: Optional[QuantizationConfig], prefix: str)
         ‚Üí None

  L 244: forward(self, inputs_embeds: torch.Tensor, attention_mask: torch.Tensor, causal_attention_mask: torch.Tensor, return_all_hidden_states: bool)
         ‚Üí Union[torch.Tensor, list[torch.Tensor]]


CLASS: CLIPEncoderLayer
----------------------------------------
  L 139: __init__(self, config: CLIPVisionConfig, act_layer: Type[nn.Module], norm_layer: Type[nn.Module], attn_implementation: Optional[str], quant_config: Optional[QuantizationConfig], prefix: str)
         ‚Üí None

  L 180: forward(self, hidden_states: torch.Tensor, attention_mask: torch.Tensor, causal_attention_mask: torch.Tensor)
         ‚Üí torch.Tensor


CLASS: CLIPMLP
----------------------------------------
  L 108: __init__(self, config, act_layer: Type[nn.Module], quant_config: Optional[QuantizationConfig], prefix: str)

  L 130: forward(self, x: torch.Tensor)
         ‚Üí torch.Tensor


CLASS: CLIPModel
----------------------------------------
  L 407: __init__(self, config: CLIPConfig, quant_config: Optional[QuantizationConfig], prefix: str)
         ‚Üí None

  L 454: forward(self, input_ids: torch.Tensor, positions: torch.Tensor, forward_batch: ForwardBatch, get_embedding: bool)

  L 486: pad_input_ids(self, input_ids: List[int], image_inputs: MultimodalInputs)

  L 490: load_weights(self, weights: Iterable[Tuple[str, torch.Tensor]])


CLASS: CLIPTextEmbeddings
----------------------------------------
  L  68: __init__(self, config: CLIPTextConfig)

  L  84: forward(self, input_ids: Optional[torch.LongTensor], position_ids: Optional[torch.LongTensor], inputs_embeds: Optional[torch.FloatTensor])
         ‚Üí torch.Tensor


CLASS: CLIPTextModel
----------------------------------------
  L 307: __init__(self, config: CLIPTextConfig, quant_config: Optional[QuantizationConfig], prefix: str)
         ‚Üí None

  L 321: forward(self, input_ids: torch.Tensor, position_ids: torch.Tensor)


CLASS: CLIPTextTransformer
----------------------------------------
  L 266: __init__(self, config: CLIPTextConfig, quant_config: Optional[QuantizationConfig], prefix: str)
         ‚Üí None

  L 284: device(self)
         ‚Üí torch.device

  L 287: forward(self, input_ids: torch.Tensor, attention_mask: Optional[torch.Tensor], position_ids: Optional[torch.Tensor])


CLASS: CLIPVisionEmbeddings
----------------------------------------
  L  25: __init__(self, config: CLIPVisionConfig)

  L  52: forward(self, pixel_values: torch.Tensor)
         ‚Üí torch.Tensor


CLASS: CLIPVisionModel
----------------------------------------
  L 387: __init__(self, config: CLIPVisionConfig, quant_config: Optional[QuantizationConfig], prefix: str)

  L 399: device(self)
         ‚Üí torch.device

  L 402: forward(self, pixel_values: torch.Tensor)


CLASS: CLIPVisionTransformer
----------------------------------------
  L 331: __init__(self, config: CLIPVisionConfig, quant_config: Optional[QuantizationConfig], prefix: str)
         ‚Üí None

  L 364: device(self)
         ‚Üí torch.device

  L 367: forward(self, pixel_values: torch.Tensor)
         ‚Üí torch.Tensor


============================================================
FILE: python/sglang/srt/models/commandr.py
Functions: 15
============================================================

MODULE FUNCTIONS:
----------------------------------------
  L  72: def layer_norm_func(hidden_states, weight, variance_epsilon)
         @torch.compile(backend=get_compiler_backend())


CLASS: CohereAttention
----------------------------------------
  L 143: __init__(self, config: PretrainedConfig, layer_id: int, quant_config: Optional[QuantizationConfig], prefix: str)

  L 228: forward(self, positions: torch.Tensor, hidden_states: torch.Tensor, forward_batch: ForwardBatch)
         ‚Üí torch.Tensor


CLASS: CohereDecoderLayer
----------------------------------------
  L 245: __init__(self, config: PretrainedConfig, layer_id: int, quant_config: Optional[QuantizationConfig], prefix: str)

  L 271: forward(self, positions: torch.Tensor, hidden_states: torch.Tensor, forward_batch: ForwardBatch, residual: Optional[torch.Tensor])
         ‚Üí Tuple[torch.Tensor, torch.Tensor]


CLASS: CohereForCausalLM
----------------------------------------
  L 342: __init__(self, config: PretrainedConfig, quant_config: Optional[QuantizationConfig], prefix: str)
         ‚Üí None

  L 357: forward(self, input_ids: torch.Tensor, positions: torch.Tensor, forward_batch: ForwardBatch)
         ‚Üí torch.Tensor

  L 372: load_weights(self, weights: Iterable[Tuple[str, torch.Tensor]])


CLASS: CohereMLP
----------------------------------------
  L 109: __init__(self, config, quant_config: Optional[QuantizationConfig], prefix: str)

  L 135: forward(self, x)


CLASS: CohereModel
----------------------------------------
  L 294: __init__(self, config: PretrainedConfig, quant_config: Optional[QuantizationConfig], prefix: str)

  L 321: forward(self, input_ids: torch.Tensor, positions: torch.Tensor, forward_batch: ForwardBatch)
         ‚Üí torch.Tensor


CLASS: LayerNorm
----------------------------------------
  L  83: __init__(self, param_shape, eps)

  L  89: forward(self, hidden_states, residuals)

  L  95: weight_loader(self, param: Parameter, loaded_weight: torch.Tensor)


============================================================
FILE: python/sglang/srt/models/dbrx.py
Functions: 16
============================================================


CLASS: DbrxAttention
----------------------------------------
  L 195: __init__(self, config: DbrxConfig, layer_id: int, quant_config: Optional[QuantizationConfig], prefix: str)

  L 262: forward(self, position_ids: torch.Tensor, hidden_states: torch.Tensor, forward_batch: ForwardBatch)
         ‚Üí torch.Tensor


CLASS: DbrxBlock
----------------------------------------
  L 317: __init__(self, config: DbrxConfig, layer_id: int, quant_config: Optional[QuantizationConfig], prefix: str)

  L 333: forward(self, position_ids: torch.Tensor, hidden_states: torch.Tensor, forward_batch: ForwardBatch)
         ‚Üí torch.Tensor


CLASS: DbrxExperts
----------------------------------------
  L  90: __init__(self, config: DbrxConfig, quant_config: Optional[QuantizationConfig], params_dtype: Optional[torch.dtype], prefix: str)

  L 146: weight_loader(self, param: nn.Parameter, loaded_weight: torch.Tensor, weight_name: str)

  L 174: forward(self, hidden_states: torch.Tensor)
         ‚Üí torch.Tensor


CLASS: DbrxForCausalLM
----------------------------------------
  L 397: __init__(self, config: DbrxConfig, quant_config: Optional[QuantizationConfig], prefix: str)

  L 420: forward(self, input_ids: torch.Tensor, positions: torch.Tensor, forward_batch: ForwardBatch)
         ‚Üí torch.Tensor

  L 431: load_weights(self, weights: Iterable[Tuple[str, torch.Tensor]])


CLASS: DbrxFusedNormAttention
----------------------------------------
  L 279: __init__(self, config: DbrxConfig, layer_id: int, quant_config: Optional[QuantizationConfig], prefix: str)

  L 297: forward(self, position_ids: torch.Tensor, hidden_states: torch.Tensor, forward_batch: ForwardBatch)
         ‚Üí Tuple[torch.Tensor, torch.Tensor]


CLASS: DbrxModel
----------------------------------------
  L 350: __init__(self, config: DbrxConfig, quant_config: Optional[QuantizationConfig], prefix: str)

  L 378: forward(self, input_ids: torch.Tensor, position_ids: torch.Tensor, forward_batch: ForwardBatch, input_embeds: torch.Tensor)
         ‚Üí torch.Tensor


CLASS: DbrxRouter
----------------------------------------
  L  59: __init__(self, config: DbrxConfig, params_dtype: Optional[torch.dtype], prefix: str)

  L  77: forward(self, hidden_states: torch.Tensor)
         ‚Üí torch.Tensor


============================================================
FILE: python/sglang/srt/models/deepseek.py
Functions: 15
============================================================


CLASS: DeepseekAttention
----------------------------------------
  L 196: __init__(self, hidden_size: int, num_heads: int, num_kv_heads: int, layer_id: int, rope_theta: float, rope_scaling: Optional[Dict[str, Any]], max_position_embeddings: int, quant_config: Optional[QuantizationConfig], prefix: str)
         ‚Üí None

  L 266: forward(self, positions: torch.Tensor, hidden_states: torch.Tensor, forward_batch: ForwardBatch)
         ‚Üí torch.Tensor


CLASS: DeepseekDecoderLayer
----------------------------------------
  L 282: __init__(self, config: PretrainedConfig, layer_id: int, quant_config: Optional[QuantizationConfig], prefix: str)
         ‚Üí None

  L 328: forward(self, positions: torch.Tensor, hidden_states: torch.Tensor, forward_batch: ForwardBatch, residual: Optional[torch.Tensor])
         ‚Üí torch.Tensor


CLASS: DeepseekForCausalLM
----------------------------------------
  L 409: __init__(self, config: PretrainedConfig, quant_config: Optional[QuantizationConfig], prefix: str)
         ‚Üí None

  L 429: get_input_embeddings(self)
         ‚Üí nn.Embedding

  L 433: forward(self, input_ids: torch.Tensor, positions: torch.Tensor, forward_batch: ForwardBatch, input_embeds: torch.Tensor)
         ‚Üí torch.Tensor

  L 445: load_weights(self, weights: Iterable[Tuple[str, torch.Tensor]])


CLASS: DeepseekMLP
----------------------------------------
  L  56: __init__(self, hidden_size: int, intermediate_size: int, hidden_act: str, quant_config: Optional[QuantizationConfig], reduce_results: bool, prefix: str)
         ‚Üí None

  L  88: forward(self, x)


CLASS: DeepseekMoE
----------------------------------------
  L  97: __init__(self, config: PretrainedConfig, quant_config: Optional[QuantizationConfig], prefix: str)

  L 152: pack_params(self)

  L 171: forward(self, hidden_states: torch.Tensor)
         ‚Üí torch.Tensor


CLASS: DeepseekModel
----------------------------------------
  L 357: __init__(self, config: PretrainedConfig, quant_config: Optional[QuantizationConfig], prefix: str)
         ‚Üí None

  L 384: forward(self, input_ids: torch.Tensor, positions: torch.Tensor, forward_batch: ForwardBatch, input_embeds: torch.Tensor)
         ‚Üí torch.Tensor


============================================================
FILE: python/sglang/srt/models/deepseek_janus_pro.py
Functions: 84
============================================================

MODULE FUNCTIONS:
----------------------------------------
  L  82: def named_apply(fn: Callable,
        module: nn.Module,
        name,
        depth_first: bool,
        include_root: bool)
         ‚Üí nn.Module

  L 105: def VQ_16()

  L 176: def trunc_normal_tf_(tensor: torch.Tensor,
        mean: float,
        std: float,
        a: float,
        b: float)
         üìù Fills the input Tensor with values drawn from a truncated
            normal distribution. The values are effectively drawn from the
            normal distribution :math:`\mathcal{N}(     ext{mean},      ext{std}^2)`
            with values outside :math:`[a, b]` redrawn until they are within
            the bounds. The method used for generating the random values works
            best when :math:`a \leq     ext{mean} \leq b`.
            NOTE: this 'tf' variant behaves closer to Tensorflow / JAX impl where the
            bounds [a, b] are applied when sampling the normal distribution with mean=0, std=1.0
            and the result is subsequently scaled and shifted by the mean and std args.
            Args:
            tensor: an n-dimensional `torch.Tensor`
            mean: the mean of the normal distribution
            std: the standard deviation of the normal distribution
            a: the minimum cutoff value
            b: the maximum cutoff value

  L 214: def nchw_to(x: torch.Tensor, fmt: Format)

  L 224: def resample_patch_embed(patch_embed,
        new_size: List[int],
        interpolation: str,
        antialias: bool,
        verbose: bool)
         üìù Resample the weights of the patch embedding kernel to target resolution.
            We resample the patch embedding kernel by approximately inverting the effect
            of patch resizing.
            Code based on:
            https://github.com/google-research/big_vision/blob/b00544b81f8694488d5f36295aeb7972f3755ffe/big_vision/models/proj/flexi/vit.py
            With this resizing, we can for example load a B/8 filter into a B/16 model
            and, on 2x larger input image, the result will match.
            Args:
            patch_embed: original parameter to be resized.
            new_size (tuple(int, int): target shape (height, width)-only.
            interpolation (str): interpolation for resize
            antialias (bool): use anti-aliasing filter in resize
            verbose (bool): log operation
            Returns:
            Resized patch embedding kernel.

  L 473: def drop_path(x, drop_prob: float, training: bool, scale_by_keep: bool)
         üìù Drop paths (Stochastic Depth) per sample (when applied in main path of residual blocks).
            This is the same as the DropConnect impl I created for EfficientNet, etc networks, however,
            the original name is misleading as 'Drop Connect' is a different form of dropout in a separate paper...
            See discussion: https://github.com/tensorflow/tpu/issues/494#issuecomment-532968956 ... I've opted for
            changing the layer and argument names to 'drop path' rather than mix DropConnect as a layer name and use
            'survival rate' as the argument.

  L 625: def resample_abs_pos_embed(posemb: torch.Tensor,
        new_size: List[int],
        old_size: Optional[List[int]],
        num_prefix_tokens: int,
        interpolation: str,
        antialias: bool,
        verbose: bool)

  L 673: def init_weights(self)

  L 679: def init_weights_vit_timm(module: nn.Module, name: str)
         ‚Üí None
         üìù ViT weight initialization, original timm impl (for reproducibility)

  L 984: def model_name_to_cls(cls_name)

  L1054: def create_siglip_vit(model_name: str,
        image_size: int,
        select_layer: int,
        ckpt_path: str)

  L1328: def use_fused_attn(experimental: bool)
         ‚Üí bool

  L1790: def nonlinearity(x)

  L1795: def Normalize(in_channels, norm_type)

  L1847: def compute_entropy_loss(affinity, loss_type, temperature)


CLASS: AttentionPoolLatent
----------------------------------------
  L1342: __init__(self, in_features: int, out_features: int, embed_dim: int, num_heads: int, feat_size: Optional[int], mlp_ratio: float, qkv_bias: bool, qk_norm: bool, latent_len: int, latent_dim: int, pos_embed: str, pool_type: str, norm_layer: Optional[nn.Module], drop: float)

  L1394: init_weights(self)

  L1399: forward(self, x)


CLASS: AttnBlock
----------------------------------------
  L1753: __init__(self, in_channels, norm_type)

  L1763: forward(self, x)


CLASS: CLIPVisionTower
----------------------------------------
  L1138: __init__(self, model_name: str, image_size: Union[Tuple[int, int], int], select_feature: str, select_layer: int, select_layers: list, ckpt_path: str, pixel_mean: Optional[List[float]], pixel_std: Optional[List[float]])

  L1176: device(self)
         ‚Üí torch.device

  L1180: dtype(self)

  L1183: build_vision_tower(self, vision_tower_params)

  L1201: feature_select(self, image_forward_outs)

  L1220: forward(self, images)
         üìù Args:
            images (torch.Tensor): [b, 3, H, W]
            Returns:
            image_features (torch.Tensor): [b, n_patch, d]


CLASS: Decoder
----------------------------------------
  L1524: __init__(self, z_channels, ch, ch_mult, num_res_blocks, norm_type, dropout, resamp_with_conv, out_channels)

  L1586: last_layer(self)

  L1589: forward(self, z)


CLASS: Downsample
----------------------------------------
  L1828: __init__(self, in_channels, with_conv)

  L1837: forward(self, x)


CLASS: DropPath
----------------------------------------
  L 500: __init__(self, drop_prob: float, scale_by_keep: bool)

  L 505: forward(self, x)

  L 508: extra_repr(self)


CLASS: Encoder
----------------------------------------
  L1443: __init__(self, in_channels, ch, ch_mult, num_res_blocks, norm_type, dropout, resamp_with_conv, z_channels)

  L1501: forward(self, x)


CLASS: LayerScale
----------------------------------------
  L1301: __init__(self, dim: int, init_values: float, inplace: bool)
         ‚Üí None

  L1311: forward(self, x: torch.Tensor)
         ‚Üí torch.Tensor


CLASS: Mlp
----------------------------------------
  L 436: __init__(self, in_features, hidden_features, out_features, act_layer, norm_layer, bias, drop, use_conv)

  L 463: forward(self, x)


CLASS: MlpProjector
----------------------------------------
  L1239: __init__(self, cfg)

  L1274: forward(self, x_or_tuple: Union[Tuple[torch.Tensor, torch.Tensor], torch.Tensor])
         üìù Args:
            x_or_tuple (Union[Tuple[torch.Tensor, torch.Tensor], torch.Tensor]:  if it is a tuple of torch.Tensor,
            then it comes from the hybrid vision encoder, and x = high_res_x, low_res_x);
            otherwise it is the feature from the single vision encoder.
            Returns:
            x (torch.Tensor): [b, s, c]


CLASS: MultiModalityCausalLM
----------------------------------------
  L1924: __init__(self, config: MultiModalityConfig, quant_config: Optional[QuantizationConfig])

  L1962: get_image_feature(self, items: List[MultimodalDataItem])
         ‚Üí torch.Tensor

  L1978: get_input_embeddings(self)
         ‚Üí nn.Embedding

  L1982: forward(self, input_ids: torch.LongTensor, positions: torch.Tensor, forward_batch: ForwardBatch, get_embedding: bool)
         ‚Üí torch.Tensor

  L1999: prepare_gen_img_embeds(self, image_ids: torch.LongTensor)

  L2002: pad_input_ids(self, input_ids: List[int], image_inputs: MultimodalInputs)

  L2011: load_weights(self, weights: Iterable[Tuple[str, torch.Tensor]])


CLASS: Normalize
----------------------------------------
  L1116: __init__(self, mean, std, inplace)

  L1123: forward(self, tensor: Tensor)
         ‚Üí Tensor
         üìù Args:
            tensor (Tensor): Tensor image to be normalized.
            Returns:
            Tensor: Normalized Tensor image.

  L1133: __repr__(self)
         ‚Üí str


CLASS: PatchDropout
----------------------------------------
  L 573: __init__(self, prob: float, num_prefix_tokens: int, ordered: bool, return_indices: bool)

  L 589: forward(self, x)
         ‚Üí Union[torch.Tensor, Tuple[torch.Tensor, Optional[torch.Tensor]]]


CLASS: PatchEmbed
----------------------------------------
  L 308: __init__(self, img_size: Optional[int], patch_size: int, in_chans: int, embed_dim: int, norm_layer: Optional[Callable], flatten: bool, output_fmt: Optional[str], bias: bool, strict_img_size: bool, dynamic_img_pad: bool)

  L 349: set_input_size(self, img_size: Optional[Union[int, Tuple[int, int]]], patch_size: Optional[Union[int, Tuple[int, int]]])

  L 379: feat_ratio(self, as_scalar)
         ‚Üí Union[Tuple[int, int], int]

  L 385: dynamic_feat_size(self, img_size: Tuple[int, int])
         ‚Üí Tuple[int, int]
         üìù Get grid (feature) size for given image size taking account of dynamic padding.
            NOTE: must be torchscript compatible so using fixed tuple indexing

  L 396: forward(self, x)


CLASS: ResnetBlock
----------------------------------------
  L1700: __init__(self, in_channels, out_channels, conv_shortcut, dropout, norm_type)

  L1734: forward(self, x)


CLASS: Upsample
----------------------------------------
  L1806: __init__(self, in_channels, with_conv)

  L1814: forward(self, x)


CLASS: VQModel
----------------------------------------
  L1864: __init__(self, config: ModelArgs)

  L1891: encode(self, x)

  L1897: decode(self, quant)

  L1902: decode_code(self, code_b, shape, channel_first)

  L1907: forward(self, input)


CLASS: VectorQuantizer
----------------------------------------
  L1614: __init__(self, n_e, e_dim, beta, entropy_loss_ratio, l2_norm, show_usage)

  L1633: forward(self, z)

  L1681: get_codebook_entry(self, indices, shape, channel_first)


CLASS: VisionTransformer
----------------------------------------
  L 698: __init__(self, img_size: Union[int, Tuple[int, int]], patch_size: Union[int, Tuple[int, int]], in_chans: int, num_classes: int, global_pool: Literal['', 'avg', 'token', 'map'], embed_dim: int, depth: int, num_heads: int, mlp_ratio: float, qkv_bias: bool, qk_norm: bool, init_values: Optional[float], class_token: bool, no_embed_class: bool, reg_tokens: int, pre_norm: bool, fc_norm: Optional[bool], dynamic_img_size: bool, dynamic_img_pad: bool, drop_rate: float, pos_drop_rate: float, patch_drop_rate: float, proj_drop_rate: float, attn_drop_rate: float, drop_path_rate: float, weight_init: Literal['skip', 'jax', 'jax_nlhb', 'moco', ''], embed_layer: Callable, _norm_layer: Optional[LayerType], _act_layer: Optional[LayerType], block_fn: Type[nn.Module], mlp_layer: Type[nn.Module], ignore_head: bool)
         ‚Üí None
         üìù Args:
            img_size: Input image size.
            patch_size: Patch size.
            in_chans: Number of image input channels.
            num_classes: Number of classes for classification head.
            global_pool: Type of global pooling for final sequence (default: 'token').
            embed_dim: Transformer embedding dimension.
            depth: Depth of transformer.
            num_heads: Number of attention heads.
            mlp_ratio: Ratio of mlp hidden dim to embedding dim.
            qkv_bias: Enable bias for qkv projections if True.
            init_values: Layer-scale init values (layer-scale enabled if not None).
            class_token: Use class token.
            no_embed_class: Don't include position embeddings for class (or reg) tokens.
            reg_tokens: Number of register tokens.
            fc_norm: Pre head norm after pool (instead of before), if None, enabled when global_pool == 'avg'.
            drop_rate: Head dropout rate.
            pos_drop_rate: Position embedding dropout rate.
            attn_drop_rate: Attention dropout rate.
            drop_path_rate: Stochastic depth rate.
            weight_init: Weight initialization scheme.
            embed_layer: Patch embedding layer.
            _norm_layer: Normalization layer.
            _act_layer: MLP activation layer.
            block_fn: Transformer block layer.

  L 864: init_weights(self, mode: Literal['jax', 'jax_nlhb', 'moco', ''])
         ‚Üí None

  L 873: no_weight_decay(self)
         ‚Üí Set

  L 877: group_matcher(self, coarse: bool)
         ‚Üí Dict

  L 884: get_classifier(self)
         ‚Üí nn.Module

  L 887: reset_classifier(self, num_classes: int, global_pool)
         ‚Üí None

  L 957: forward_features(self, x: torch.Tensor)
         ‚Üí torch.Tensor

  L 966: forward_head(self, x: torch.Tensor, pre_logits: bool)
         ‚Üí torch.Tensor

  L 977: forward(self, x: torch.Tensor)
         ‚Üí torch.Tensor


CLASS: VisionTransformerBlock
----------------------------------------
  L 513: __init__(self, dim: int, num_heads: int, mlp_ratio: float, qkv_bias: bool, qk_norm: bool, proj_drop: float, attn_drop: float, init_values: Optional[float], drop_path: float, act_layer: nn.Module, norm_layer: nn.Module, mlp_layer: nn.Module)
         ‚Üí None

  L 557: forward(self, x: torch.Tensor)
         ‚Üí torch.Tensor


CLASS: vision_head
----------------------------------------
  L1003: __init__(self, params)

  L1013: forward(self, x)


============================================================
FILE: python/sglang/srt/models/deepseek_nextn.py
Functions: 5
============================================================


CLASS: DeepseekModelNextN
----------------------------------------
  L  42: __init__(self, config: PretrainedConfig, quant_config: Optional[QuantizationConfig], prefix: str)
         ‚Üí None

  L  80: forward(self, input_ids: torch.Tensor, positions: torch.Tensor, forward_batch: ForwardBatch, input_embeds: torch.Tensor)
         ‚Üí torch.Tensor


CLASS: DeepseekV3ForCausalLMNextN
----------------------------------------
  L 128: __init__(self, config: PretrainedConfig, quant_config: Optional[QuantizationConfig], prefix: str)
         ‚Üí None

  L 155: forward(self, input_ids: torch.Tensor, positions: torch.Tensor, forward_batch: ForwardBatch)
         ‚Üí torch.Tensor

  L 166: load_weights(self, weights: Iterable[Tuple[str, torch.Tensor]])


============================================================
FILE: python/sglang/srt/models/deepseek_v2.py
Functions: 59
============================================================

MODULE FUNCTIONS:
----------------------------------------
  L 738: def yarn_get_mscale(scale: float, mscale: float)
         ‚Üí float


CLASS: DeepseekV2AttentionMLA
----------------------------------------
  L 748: __init__(self, config: PretrainedConfig, hidden_size: int, num_heads: int, qk_nope_head_dim: int, qk_rope_head_dim: int, v_head_dim: int, q_lora_rank: int, kv_lora_rank: int, rope_theta: float, rope_scaling: Optional[Dict[str, Any]], max_position_embeddings: int, quant_config: Optional[QuantizationConfig], reduce_results: bool, layer_id: int, prefix: str, alt_stream: Optional[torch.cuda.Stream])
         ‚Üí None

  L 972: dispatch_attn_forward_method(self, forward_batch: ForwardBatch)
         ‚Üí AttnForwardMethod

  L1062: op_prepare(self, state)

  L1070: op_core(self, state)

  L1075: forward(self, positions: torch.Tensor, hidden_states: torch.Tensor, forward_batch: ForwardBatch, zero_allocator: BumpAllocator)

  L1090: forward_prepare(self, positions: torch.Tensor, hidden_states: torch.Tensor, forward_batch: ForwardBatch, zero_allocator: BumpAllocator)

  L1132: forward_core(self, intermediate_state)

  L1152: forward_normal_prepare(self, positions: torch.Tensor, hidden_states: torch.Tensor, forward_batch: ForwardBatch, zero_allocator: BumpAllocator)

  L1202: forward_normal_core(self, q, k, v, forward_batch)

  L1218: forward_absorb_prepare(self, positions: torch.Tensor, hidden_states: torch.Tensor, forward_batch: ForwardBatch, zero_allocator: BumpAllocator)

  L1303: forward_absorb_core(self, q_pe, k_pe, q_nope_out, k_nope, forward_batch, zero_allocator)

  L1390: forward_absorb_fused_mla_rope_prepare(self, positions: torch.Tensor, hidden_states: torch.Tensor, forward_batch: ForwardBatch, zero_allocator: BumpAllocator)

  L1504: forward_absorb_fused_mla_rope_cpu_prepare(self, positions: torch.Tensor, hidden_states: torch.Tensor, forward_batch: ForwardBatch, zero_allocator: BumpAllocator)

  L1555: forward_absorb_fused_mla_rope_core(self, q_input, key_cache_buf, val_cache_buf, attn_output, kv_indptr, kv_indices, k_pe_output, cos_sin_cache, positions, attn_logits, num_kv_split, sm_scale, enable_rope_fusion, k_input, forward_batch, zero_allocator)

  L1628: forward_absorb_fused_mla_rope_cpu_core(self, q_input, k_input, v_input, forward_batch, zero_allocator)

  L1716: forward_normal_chunked_kv_prepare(self, positions: torch.Tensor, hidden_states: torch.Tensor, forward_batch: ForwardBatch, zero_allocator: BumpAllocator)

  L1734: forward_normal_chunked_kv_core(self, q, k, v, forward_batch)


CLASS: DeepseekV2DecoderLayer
----------------------------------------
  L1765: __init__(self, config: PretrainedConfig, layer_id: int, quant_config: Optional[QuantizationConfig], is_nextn: bool, prefix: str, alt_stream: Optional[torch.cuda.Stream])
         ‚Üí None

  L1860: forward(self, positions: torch.Tensor, hidden_states: torch.Tensor, forward_batch: ForwardBatch, residual: Optional[torch.Tensor], zero_allocator: BumpAllocator)
         ‚Üí torch.Tensor

  L1908: op_comm_prepare_attn(self, state, positions: torch.Tensor, hidden_states: torch.Tensor, forward_batch: ForwardBatch, residual: Optional[torch.Tensor], zero_allocator: BumpAllocator, tbo_subbatch_index: Optional[int])

  L1930: op_comm_prepare_mlp(self, state)

  L1939: op_mlp(self, state)

  L1952: op_comm_postprocess_layer(self, state)


CLASS: DeepseekV2ForCausalLM
----------------------------------------
  L2121: __init__(self, config: PretrainedConfig, quant_config: Optional[QuantizationConfig], prefix: str)
         ‚Üí None

  L2166: routed_experts_weights_of_layer(self)

  L2169: determine_num_fused_shared_experts(self, architecture: str)

  L2200: get_input_embeddings(self)
         ‚Üí nn.Embedding

  L2204: forward(self, input_ids: torch.Tensor, positions: torch.Tensor, forward_batch: ForwardBatch, input_embeds: torch.Tensor, pp_proxy_tensors: Optional[PPProxyTensors])
         ‚Üí torch.Tensor

  L2224: start_layer(self)

  L2228: end_layer(self)

  L2231: post_load_weights(self, is_nextn, weight_names)

  L2470: load_weights(self, weights: Iterable[Tuple[str, torch.Tensor]], is_nextn)

  L2711: get_embed_and_head(self)

  L2714: set_embed_and_head(self, embed, head)

  L2723: get_model_config_for_expert_location(cls, config)


CLASS: DeepseekV2MLP
----------------------------------------
  L 181: __init__(self, hidden_size: int, intermediate_size: int, hidden_act: str, quant_config: Optional[QuantizationConfig], reduce_results: bool, prefix: str, tp_rank: Optional[int], tp_size: Optional[int])
         ‚Üí None

  L 221: forward(self, x, forward_batch, should_allreduce_fusion: bool, use_reduce_scatter: bool)


CLASS: DeepseekV2MoE
----------------------------------------
  L 287: __init__(self, config: PretrainedConfig, layer_id: int, quant_config: Optional[QuantizationConfig], prefix: str, alt_stream: Optional[torch.cuda.Stream], is_nextn: bool)

  L 429: get_moe_weights(self)

  L 436: forward(self, hidden_states: torch.Tensor, forward_batch: Optional[ForwardBatch], should_allreduce_fusion: bool, use_reduce_scatter: bool)
         ‚Üí torch.Tensor

  L 465: forward_normal_dual_stream(self, hidden_states: torch.Tensor, should_allreduce_fusion: bool, use_reduce_scatter: bool)
         ‚Üí torch.Tensor

  L 500: forward_normal(self, hidden_states: torch.Tensor, should_allreduce_fusion: bool, use_reduce_scatter: bool)
         ‚Üí torch.Tensor

  L 539: forward_cpu(self, hidden_states: torch.Tensor, should_allreduce_fusion: bool)
         ‚Üí torch.Tensor

  L 597: forward_deepep(self, hidden_states: torch.Tensor, forward_batch: ForwardBatch)
         ‚Üí torch.Tensor

  L 640: op_gate(self, state)

  L 649: op_shared_experts(self, state)

  L 658: op_select_experts(self, state)

  L 682: op_dispatch_a(self, state)

  L 692: op_dispatch_b(self, state)

  L 701: op_experts(self, state)

  L 706: op_combine_a(self, state)

  L 717: op_combine_b(self, state)

  L 725: op_output(self, state)


CLASS: DeepseekV2Model
----------------------------------------
  L1982: __init__(self, config: PretrainedConfig, quant_config: Optional[QuantizationConfig], prefix: str)
         ‚Üí None

  L2039: get_input_embeddings(self)
         ‚Üí torch.Tensor

  L2042: forward(self, input_ids: torch.Tensor, positions: torch.Tensor, forward_batch: ForwardBatch, input_embeds: torch.Tensor, pp_proxy_tensors: Optional[PPProxyTensors])
         ‚Üí Union[torch.Tensor, PPProxyTensors]


CLASS: MoEGate
----------------------------------------
  L 240: __init__(self, config, prefix: str, is_nextn: bool)

  L 260: forward(self, hidden_states)


============================================================
FILE: python/sglang/srt/models/deepseek_vl2.py
Functions: 7
============================================================


CLASS: DeepseekVL2ForCausalLM
----------------------------------------
  L 160: __init__(self, config: DeepseekVL2Config, quant_config: Optional[QuantizationConfig])

  L 219: forward(self, input_ids: torch.Tensor, positions: torch.Tensor, forward_batch: ForwardBatch)

  L 236: load_weights(self, weights: Iterable[Tuple[str, torch.Tensor]])

  L 256: pad_input_ids(self, input_ids: List[int], mm_inputs: MultimodalInputs)

  L 260: get_image_feature(self, items: List[MultimodalDataItem])


CLASS: DeepseekVL2MlpProjector
----------------------------------------
  L  26: __init__(self, config: DeepseekVL2MlpProjectorConfig, quant_config: Optional[QuantizationConfig])

  L 111: forward(self, x)


============================================================
FILE: python/sglang/srt/models/ernie4.py
Functions: 14
============================================================


CLASS: Ernie4DecoderLayer
----------------------------------------
  L 148: __init__(self, config, layer_id: int, quant_config: Optional[QuantizationConfig], prefix: str, is_mtp: bool)

  L 212: forward(self, positions: torch.Tensor, hidden_states: torch.Tensor, forward_batch: ForwardBatch, residual: Optional[torch.Tensor])
         ‚Üí Tuple[torch.Tensor, torch.Tensor]


CLASS: Ernie4Model
----------------------------------------
  L 239: __init__(self, config: Ernie4_5_MoeConfig, quant_config: Optional[QuantizationConfig], prefix: str)
         ‚Üí None

  L 264: forward(self, input_ids: torch.Tensor, positions: torch.Tensor, forward_batch: ForwardBatch, input_embeds: torch.Tensor)
         ‚Üí Union[torch.Tensor, Tuple[torch.Tensor, List[torch.Tensor]]]


CLASS: Ernie4Moe
----------------------------------------
  L  68: __init__(self, config: Ernie4_5_MoeConfig, layer_id: int, quant_config: Optional[QuantizationConfig], prefix: str)

  L 119: forward(self, hidden_states: torch.Tensor)
         ‚Üí torch.Tensor

  L 122: forward_normal(self, hidden_states: torch.Tensor)
         ‚Üí torch.Tensor


CLASS: Ernie4_5_ForCausalLM
----------------------------------------
  L 302: __init__(self, config: Ernie4_5_MoeConfig, quant_config: Optional[QuantizationConfig], prefix: str)

  L 324: forward(self, input_ids: torch.Tensor, positions: torch.Tensor, forward_batch: ForwardBatch)
         ‚Üí torch.Tensor

  L 335: load_weights(self, weights: Iterable[Tuple[str, torch.Tensor]])

  L 358: get_embed_and_head(self)


CLASS: Ernie4_5_MoeForCausalLM
----------------------------------------
  L 363: load_weights(self, weights: Iterable[Tuple[str, torch.Tensor]])


CLASS: MoEGate
----------------------------------------
  L  49: __init__(self, config, prefix: str)

  L  62: forward(self, hidden_states)


============================================================
FILE: python/sglang/srt/models/ernie4_eagle.py
Functions: 7
============================================================


CLASS: Ernie4ModelMTP
----------------------------------------
  L  39: __init__(self, config: Ernie4_5_MoeConfig, layer_id: int, prefix: str, quant_config: Optional[QuantizationConfig])
         ‚Üí None

  L  67: forward(self, input_ids: torch.Tensor, positions: torch.Tensor, forward_batch: ForwardBatch, input_embeds: torch.Tensor)
         ‚Üí torch.Tensor


CLASS: Ernie4_5_MoeForCausalLMMTP
----------------------------------------
  L 102: __init__(self, config: Ernie4_5_MoeConfig, quant_config: Optional[QuantizationConfig], prefix: str, mtp_layer_id: int)
         ‚Üí None

  L 132: forward(self, input_ids: torch.Tensor, positions: torch.Tensor, forward_batch: ForwardBatch)
         ‚Üí torch.Tensor

  L 143: load_weights(self, weights: Iterable[Tuple[str, torch.Tensor]])

  L 188: get_embed_and_head(self)

  L 191: set_embed_and_head(self, embed, head)


============================================================
FILE: python/sglang/srt/models/exaone.py
Functions: 11
============================================================


CLASS: ExaoneAttention
----------------------------------------
  L  84: __init__(self, config, hidden_size: int, num_heads: int, num_kv_heads: int, layer_id: int, rope_theta: float, rope_scaling: Optional[Dict[str, Any]], rope_is_neox_style: bool, max_position_embeddings: int, quant_config: Optional[QuantizationConfig], prefix: str)
         ‚Üí None

  L 161: forward(self, positions: torch.Tensor, hidden_states: torch.Tensor, forward_batch: ForwardBatch)
         ‚Üí torch.Tensor


CLASS: ExaoneDecoderLayer
----------------------------------------
  L 176: __init__(self, config, layer_id: int, quant_config: Optional[QuantizationConfig], prefix: str)
         ‚Üí None

  L 219: forward(self, positions: torch.Tensor, hidden_states: torch.Tensor, forward_batch: ForwardBatch, residual: Optional[torch.Tensor])
         ‚Üí Tuple[torch.Tensor, torch.Tensor]


CLASS: ExaoneForCausalLM
----------------------------------------
  L 298: __init__(self, config, quant_config: Optional[QuantizationConfig], prefix: str)
         ‚Üí None

  L 321: forward(self, input_ids: torch.Tensor, positions: torch.Tensor, forward_batch: ForwardBatch, input_embeds: torch.Tensor)
         ‚Üí LogitsProcessorOutput

  L 335: load_weights(self, weights: Iterable[Tuple[str, torch.Tensor]])


CLASS: ExaoneGatedMLP
----------------------------------------
  L  46: __init__(self, hidden_size: int, intermediate_size: int, hidden_act: str, quant_config: Optional[QuantizationConfig], prefix: str)
         ‚Üí None

  L  76: forward(self, x)


CLASS: ExaoneModel
----------------------------------------
  L 245: __init__(self, config, quant_config: Optional[QuantizationConfig], prefix: str)
         ‚Üí None

  L 273: forward(self, input_ids: torch.Tensor, positions: torch.Tensor, forward_batch: ForwardBatch, input_embeds: torch.Tensor)
         ‚Üí torch.Tensor


============================================================
FILE: python/sglang/srt/models/gemma.py
Functions: 12
============================================================


CLASS: GemmaAttention
----------------------------------------
  L  76: __init__(self, hidden_size: int, num_heads: int, num_kv_heads: int, head_dim: int, layer_id: int, max_position_embeddings: int, rope_theta: float, quant_config: Optional[QuantizationConfig], prefix: str)
         ‚Üí None

  L 144: forward(self, positions: torch.Tensor, hidden_states: torch.Tensor, forward_batch: ForwardBatch)
         ‚Üí torch.Tensor


CLASS: GemmaDecoderLayer
----------------------------------------
  L 159: __init__(self, config: PretrainedConfig, layer_id: int, quant_config: Optional[QuantizationConfig], prefix: str)
         ‚Üí None

  L 190: forward(self, positions: torch.Tensor, hidden_states: torch.Tensor, forward_batch: ForwardBatch, residual: Optional[torch.Tensor])
         ‚Üí Tuple[torch.Tensor, torch.Tensor]


CLASS: GemmaForCausalLM
----------------------------------------
  L 294: __init__(self, config: PretrainedConfig, quant_config: Optional[QuantizationConfig], prefix: str)
         ‚Üí None

  L 309: forward(self, input_ids: torch.Tensor, positions: torch.Tensor, forward_batch: ForwardBatch, input_embeds: torch.Tensor)
         ‚Üí torch.Tensor

  L 322: forward_split_prefill(self, input_ids: torch.Tensor, positions: torch.Tensor, forward_batch: ForwardBatch, split_interval: Tuple[int, int], input_embeds: torch.Tensor)

  L 369: load_weights(self, weights: Iterable[Tuple[str, torch.Tensor]])


CLASS: GemmaMLP
----------------------------------------
  L  44: __init__(self, hidden_size: int, intermediate_size: int, quant_config: Optional[QuantizationConfig], prefix: str)
         ‚Üí None

  L  68: forward(self, x)


CLASS: GemmaModel
----------------------------------------
  L 216: __init__(self, config: PretrainedConfig, quant_config: Optional[QuantizationConfig], prefix: str)
         ‚Üí None

  L 242: forward(self, input_ids: torch.Tensor, positions: torch.Tensor, forward_batch: ForwardBatch, input_embeds: torch.Tensor)
         ‚Üí torch.Tensor


============================================================
FILE: python/sglang/srt/models/gemma2.py
Functions: 14
============================================================

MODULE FUNCTIONS:
----------------------------------------
  L  47: def get_attention_sliding_window_size(config)


CLASS: Gemma2Attention
----------------------------------------
  L  92: __init__(self, layer_id: int, config: PretrainedConfig, hidden_size: int, num_heads: int, num_kv_heads: int, head_dim: int, max_position_embeddings: int, rope_theta: float, quant_config: Optional[QuantizationConfig], prefix: str)
         ‚Üí None

  L 170: forward(self, positions: torch.Tensor, hidden_states: torch.Tensor, forward_batch: ForwardBatch)
         ‚Üí torch.Tensor


CLASS: Gemma2DecoderLayer
----------------------------------------
  L 185: __init__(self, layer_id: int, config: PretrainedConfig, quant_config: Optional[QuantizationConfig], prefix: str)
         ‚Üí None

  L 227: forward(self, positions: torch.Tensor, hidden_states: torch.Tensor, forward_batch: ForwardBatch, residual: Optional[torch.Tensor])
         ‚Üí Tuple[torch.Tensor, torch.Tensor]


CLASS: Gemma2ForCausalLM
----------------------------------------
  L 357: __init__(self, config: PretrainedConfig, quant_config: Optional[QuantizationConfig], prefix: str)
         ‚Üí None

  L 372: forward(self, input_ids: torch.Tensor, positions: torch.Tensor, forward_batch: ForwardBatch, input_embeds: torch.Tensor)
         ‚Üí torch.Tensor

  L 385: forward_split_prefill(self, input_ids: torch.Tensor, positions: torch.Tensor, forward_batch: ForwardBatch, split_interval: Tuple[int, int], input_embeds: torch.Tensor)

  L 435: get_attention_sliding_window_size(self)

  L 438: load_weights(self, weights: Iterable[Tuple[str, torch.Tensor]])


CLASS: Gemma2MLP
----------------------------------------
  L  52: __init__(self, hidden_size: int, intermediate_size: int, hidden_act: str, hidden_activation: str, quant_config: Optional[QuantizationConfig], prefix: str)
         ‚Üí None

  L  84: forward(self, x: torch.Tensor)
         ‚Üí torch.Tensor


CLASS: Gemma2Model
----------------------------------------
  L 255: __init__(self, config: PretrainedConfig, quant_config: Optional[QuantizationConfig], prefix: str)
         ‚Üí None

  L 286: forward(self, input_ids: torch.Tensor, positions: torch.Tensor, forward_batch: ForwardBatch, input_embeds: torch.Tensor)
         ‚Üí torch.Tensor


============================================================
FILE: python/sglang/srt/models/gemma2_reward.py
Functions: 3
============================================================


CLASS: Gemma2ForSequenceClassification
----------------------------------------
  L  29: __init__(self, config: Gemma2Config, quant_config: Optional[QuantizationConfig], prefix: str)
         ‚Üí None

  L  48: forward(self, input_ids: torch.Tensor, positions: torch.Tensor, forward_batch: ForwardBatch, input_embeds: torch.Tensor, get_embedding: bool)
         ‚Üí EmbeddingPoolerOutput

  L  66: load_weights(self, weights: Iterable[Tuple[str, torch.Tensor]])


============================================================
FILE: python/sglang/srt/models/gemma3_causal.py
Functions: 22
============================================================

MODULE FUNCTIONS:
----------------------------------------
  L  52: def get_attention_sliding_window_size(config)

  L  58: def extract_layer_index(prefix: str)
         ‚Üí int
         üìù Extract the layer index from a prefix string.


CLASS: Gemma3Attention
----------------------------------------
  L 111: __init__(self, layer_id: int, config: Gemma3TextConfig, max_position_embeddings: int, quant_config: Optional[QuantizationConfig], prefix: str)
         ‚Üí None

  L 203: naive_attn_with_masks(self, q: torch.Tensor, k: torch.Tensor, v: torch.Tensor, out: torch.Tensor)
         ‚Üí torch.Tensor

  L 249: forward(self, hidden_states: torch.Tensor, position_embeddings: Tuple[torch.Tensor, torch.Tensor], forward_batch: ForwardBatch)
         ‚Üí torch.Tensor


CLASS: Gemma3DecoderLayer
----------------------------------------
  L 291: __init__(self, layer_id: int, config: PretrainedConfig, quant_config: Optional[QuantizationConfig], prefix: str)
         ‚Üí None

  L 330: forward(self, positions: torch.Tensor, hidden_states: torch.Tensor, position_embeddings_global: torch.Tensor, position_embeddings_local: torch.Tensor, forward_batch: ForwardBatch)
         ‚Üí tuple[torch.FloatTensor, Optional[tuple[torch.FloatTensor, torch.FloatTensor]]]


CLASS: Gemma3ForCausalLM
----------------------------------------
  L 599: __init__(self, config: Gemma3TextConfig, quant_config: Optional[QuantizationConfig], prefix: str)
         ‚Üí None

  L 624: get_input_embeddings(self)
         ‚Üí nn.Embedding

  L 627: get_attention_sliding_window_size(self)

  L 630: dtype(self)
         ‚Üí torch.dtype

  L 634: forward(self, input_ids: torch.Tensor, positions: torch.Tensor, forward_batch: ForwardBatch, input_embeds: torch.Tensor)
         ‚Üí LogitsProcessor

  L 651: forward_split_prefill(self, input_ids: torch.Tensor, positions: torch.Tensor, forward_batch: ForwardBatch, split_interval: Tuple[int, int], input_embeds: torch.Tensor)

  L 713: load_weights(self, weights: Iterable[Tuple[str, torch.Tensor]])


CLASS: Gemma3MLP
----------------------------------------
  L  72: __init__(self, hidden_size: int, intermediate_size: int, hidden_activation: str, quant_config: Optional[QuantizationConfig], prefix: str)
         ‚Üí None

  L 103: forward(self, x: torch.Tensor)
         ‚Üí torch.Tensor


CLASS: Gemma3RotaryEmbedding
----------------------------------------
  L 372: __init__(self, config: Gemma3TextConfig, device)

  L 418: forward(self, x, position_ids)


CLASS: Gemma3TextModel
----------------------------------------
  L 469: __init__(self, config: Gemma3TextConfig, quant_config: Optional[QuantizationConfig], prefix: str)
         ‚Üí None

  L 513: forward(self, input_ids: torch.Tensor, positions: torch.Tensor, forward_batch: ForwardBatch, input_embeds: torch.Tensor)
         ‚Üí torch.Tensor


CLASS: Gemma3TextScaledWordEmbedding
----------------------------------------
  L 454: __init__(self, num_embeddings: int, embedding_dim: int, padding_idx: int, embed_scale: Optional[float])

  L 464: forward(self, input_ids: torch.Tensor)


============================================================
FILE: python/sglang/srt/models/gemma3_mm.py
Functions: 11
============================================================


CLASS: Gemma3ForConditionalGeneration
----------------------------------------
  L 158: __init__(self, config: Gemma3Config, quant_config: Optional[QuantizationConfig], prefix: str)
         ‚Üí None

  L 188: pad_input_ids(self, input_ids: List[int], image_inputs: MultimodalInputs)
         ‚Üí List[int]
         üìù Pad input IDs with image tokens.

  L 201: prepare_attn_masks(self, input_ids: torch.Tensor, positions: torch.Tensor, mask_dtype: torch.dtype)
         ‚Üí Dict
         üìù Prepare attention masks for multimodal inputs.

  L 269: get_input_embeddings(self)
         ‚Üí nn.Embedding

  L 272: get_attention_sliding_window_size(self)
         üìù This value is used to initialize attention backends in `ForwardBatch`.

  L 278: get_image_feature(self, items: List[MultimodalDataItem])
         üìù Projects the last hidden state from the vision model into language model space.
            Returns:
            image_features (`torch.Tensor`): Image feature tensor of shape `(num_images, image_length, embed_dim)`).

  L 316: forward(self, input_ids: torch.LongTensor, positions: torch.Tensor, forward_batch: ForwardBatch, input_embeds: torch.Tensor)
         ‚Üí LogitsProcessor
         üìù labels (`torch.LongTensor` of shape `(batch_size, sequence_length)`, *optional*):
            Labels for computing the masked language modeling loss. Indices should either be in `[0, ...,
            config.text_config.vocab_size]` or -100 (see `input_ids` docstring). Tokens with indices set to `-100` are ignored
            (masked), the loss is only computed for the tokens with labels in `[0, ..., config.text_config.vocab_size]`.
            logits_to_keep (`int` or `torch.Tensor`, *optional*):
            If an `int`, compute logits for the last `logits_to_keep` tokens. If `0`, calculate logits for all
            `input_ids` (special case). Only last token logits are needed for generation, and calculating them only for that
            token can save memory, which becomes pretty significant for long sequences or large vocabulary size.
            If a `torch.Tensor`, must be 1D corresponding to the indices to keep in the sequence length dimension.
            This is useful when using packed tensor format (single dimension for batch and sequence length).
            Returns:
            Example:
            ```python
            >>> from PIL import Image
            >>> import requests
            >>> from transformers import AutoProcessor, Gemma3ForConditionalGeneration
            >>> model = Gemma3ForConditionalGeneration.from_pretrained("google/Gemma3-test-224px-hf")
            >>> processor = AutoProcessor.from_pretrained("google/Gemma3-test-224px-hf")
            >>> prompt = "answer en Where is the cow standing?"
            >>> url = "https://huggingface.co/gv-hf/Gemma3-test-224px-hf/resolve/main/cow_beach_1.png"
            >>> image = Image.open(requests.get(url, stream=True).raw)
            >>> inputs = processor(images=image, text=prompt,  return_tensors="pt")
            >>> # Generate
            >>> generate_ids = model.generate(**inputs, max_length=30)
            >>> processor.batch_decode(generate_ids, skip_special_tokens=True, clean_up_tokenization_spaces=False)[0]
            "answer en Where is the cow standing?\nbeach"
            ```

  L 383: tie_weights(self)

  L 386: load_weights(self, weights: Iterable[Tuple[str, torch.Tensor]])


CLASS: Gemma3MultiModalProjector
----------------------------------------
  L  61: __init__(self, config: Gemma3Config)

  L  83: forward(self, vision_outputs: torch.Tensor)
         ‚Üí torch.Tensor


============================================================
FILE: python/sglang/srt/models/gemma3n_audio.py
Functions: 20
============================================================


CLASS: Gemma3nAudioAttention
----------------------------------------
  L 280: __init__(self, config: Gemma3nAudioConfig, quant_config: Optional[QuantizationConfig], prefix: str)

  L 388: forward(self, x: torch.Tensor, mask: torch.BoolTensor)
         ‚Üí torch.Tensor


CLASS: Gemma3nAudioConformerAttention
----------------------------------------
  L 614: __init__(self, config: Gemma3nAudioConfig, quant_config: Optional[QuantizationConfig], prefix: str)

  L 646: forward(self, audio_encodings: torch.Tensor, audio_mel_mask: torch.BoolTensor)
         ‚Üí torch.Tensor


CLASS: Gemma3nAudioConformerBlock
----------------------------------------
  L 793: __init__(self, config: Gemma3nAudioConfig, quant_config: Optional[QuantizationConfig], prefix: str)

  L 821: forward(self, audio_encodings: torch.Tensor, audio_mel_mask: torch.BoolTensor)
         ‚Üí torch.Tensor


CLASS: Gemma3nAudioConformerFeedForward
----------------------------------------
  L 669: __init__(self, config: Gemma3nAudioConfig, quant_config: Optional[QuantizationConfig], prefix: str)

  L 702: forward(self, audio_encodings: torch.Tensor)
         ‚Üí torch.Tensor


CLASS: Gemma3nAudioConformerLightConv1d
----------------------------------------
  L 719: __init__(self, config: Gemma3nAudioConfig, quant_config: Optional[QuantizationConfig], prefix: str)

  L 766: forward(self, audio_encodings: torch.Tensor)
         ‚Üí torch.Tensor


CLASS: Gemma3nAudioEncoder
----------------------------------------
  L 846: __init__(self, config: Gemma3nAudioConfig, quant_config: Optional[QuantizationConfig], prefix: str)

  L 868: forward(self, audio_mel: torch.Tensor, audio_mel_mask: torch.BoolTensor)
         ‚Üí Tuple[torch.Tensor, torch.BoolTensor]
         üìù Encodes a batch of MELs.
            Args:
            audio_mel: a torch.Tensor of shape [batch, num_frames, mel_bins].
            audio_mel_mask: a torch.BoolTensor of shape [batch, num_frames].
            Returns:
            audio_encodings: a torch.Tensor of shape
            `[batch_size, reduced_time_frames, hidden_size]`
            audio_mel_mask: a torch.BoolTensor of shape [batch, reduced_time_frames].


CLASS: Gemma3nAudioRelativePositionEmbedding
----------------------------------------
  L 139: __init__(self, config: Gemma3nAudioConfig, quant_config: Optional[QuantizationConfig], prefix: str)

  L 227: forward(self, queries: torch.Tensor, keys: torch.Tensor)
         ‚Üí torch.Tensor


CLASS: Gemma3nAudioSSCPConvBlock
----------------------------------------
  L 490: __init__(self, config: Gemma3nAudioConfig, idx: int, input_freq_dim: int, manual_padding: Tuple[int, int, int, int], quant_config: Optional[QuantizationConfig], prefix: str)

  L 528: forward(self, audio_encodings: torch.Tensor)
         ‚Üí torch.Tensor


CLASS: Gemma3nAudioSubSampleConvProjection
----------------------------------------
  L 540: __init__(self, config: Gemma3nAudioConfig, quant_config: Optional[QuantizationConfig], prefix: str)

  L 602: forward(self, audio_encodings: torch.Tensor)
         ‚Üí torch.Tensor


CLASS: Gemma3nCumulativeGroupNorm
----------------------------------------
  L  36: __init__(self, num_channels: int, feature_dims: Sequence[int], eps: float)

  L  56: forward(self, x: torch.Tensor, mask: Optional[torch.Tensor])
         ‚Üí torch.Tensor
         üìù Applies cumulative group norm, optionally using a mask.
            Args:
            x: Input tensor, shape [B, T, *feature_dims, C].
            mask: Optional boolean mask, shape [B, T]. True indicates a valid
            (non-padded) time step. If None, all time steps are considered valid.
            Returns:
            Normalized tensor with the same shape as x.


============================================================
FILE: python/sglang/srt/models/gemma3n_causal.py
Functions: 29
============================================================

MODULE FUNCTIONS:
----------------------------------------
  L  33: def get_attention_sliding_window_size(config)


CLASS: Gemma3nAltUp
----------------------------------------
  L 174: __init__(self, config: Gemma3nTextConfig, quant_config: Optional[QuantizationConfig], prefix: str)

  L 219: compute_router_modalities(self, x: torch.Tensor)
         ‚Üí torch.Tensor

  L 230: predict(self, hidden_states: torch.Tensor)
         ‚Üí torch.Tensor
         üìù Predicts the output of a layer using a trainable map.
            hidden_states: [num_altup_inputs, num_tokens, hidden_size]

  L 262: correct(self, predictions: torch.Tensor, activated: torch.Tensor)
         ‚Üí torch.Tensor
         üìù Corrects the predictions relative to the activated inputs.

  L 293: scale_corrected_output(self, corrected: torch.Tensor)
         ‚Üí torch.Tensor
         üìù Scales the provided 3D tensor.

  L 297: forward(self, hidden_states: torch.Tensor, activated: torch.Tensor)
         ‚Üí Tuple[torch.Tensor, torch.Tensor]
         üìù Predicts, correct, and optionally scales the output of a layer using trainable maps.
            hidden_states: [num_altup_inputs, num_tokens, hidden_size]


CLASS: Gemma3nAttention
----------------------------------------
  L 316: __init__(self, layer_id: int, config: Gemma3nTextConfig, max_position_embeddings: int, quant_config: Optional[QuantizationConfig], prefix: str)
         ‚Üí None

  L 434: forward(self, hidden_states: torch.Tensor, positions: Tuple[torch.Tensor, torch.Tensor], forward_batch: ForwardBatch)
         ‚Üí torch.Tensor


CLASS: Gemma3nDecoderLayer
----------------------------------------
  L 496: __init__(self, layer_id: int, config: PretrainedConfig, quant_config: Optional[QuantizationConfig], prefix: str)
         ‚Üí None

  L 567: forward(self, positions: torch.Tensor, hidden_states: torch.Tensor, per_layer_input: torch.Tensor, forward_batch: ForwardBatch)
         ‚Üí torch.Tensor


CLASS: Gemma3nForCausalLM
----------------------------------------
  L 900: __init__(self, config: Gemma3nTextConfig, quant_config: Optional[QuantizationConfig], prefix: str)
         ‚Üí None

  L 927: get_input_embeddings(self)
         ‚Üí nn.Embedding

  L 930: get_attention_sliding_window_size(self)

  L 933: dtype(self)
         ‚Üí torch.dtype

  L 937: forward(self, input_ids: torch.Tensor, positions: torch.Tensor, forward_batch: ForwardBatch, input_embeds: torch.Tensor, per_layer_inputs: Optional[torch.Tensor])
         ‚Üí LogitsProcessor

  L 959: load_weights(self, weights: Iterable[Tuple[str, torch.Tensor]])


CLASS: Gemma3nLaurelBlock
----------------------------------------
  L 135: __init__(self, config: Gemma3nTextConfig, quant_config: Optional[QuantizationConfig], prefix: str)

  L 163: forward(self, x: torch.Tensor)
         ‚Üí torch.Tensor


CLASS: Gemma3nRMSNorm
----------------------------------------
  L  38: __init__(self, dim: int, eps: float, with_scale: bool)
         ‚Üí None

  L  53: forward(self, x: torch.Tensor)
         ‚Üí torch.Tensor


CLASS: Gemma3nTextMLP
----------------------------------------
  L  66: __init__(self, hidden_size: int, intermediate_size: int, hidden_activation: str, activation_sparsity: float, quant_config: Optional[QuantizationConfig], prefix: str)
         ‚Üí None

  L 105: forward(self, x: torch.Tensor)
         ‚Üí torch.Tensor


CLASS: Gemma3nTextModel
----------------------------------------
  L 629: __init__(self, config: Gemma3nTextConfig, quant_config: Optional[QuantizationConfig], prefix: str)
         ‚Üí None

  L 724: get_input_embeddings(self)
         ‚Üí nn.Embedding

  L 727: dtype(self)
         ‚Üí torch.dtype

  L 730: get_per_layer_inputs(self, input_ids: torch.LongTensor)
         ‚Üí torch.Tensor

  L 738: project_per_layer_inputs(self, inputs_embeds: torch.Tensor, per_layer_inputs: Optional[torch.Tensor])
         ‚Üí torch.Tensor

  L 765: forward(self, input_ids: torch.Tensor, positions: torch.Tensor, forward_batch: ForwardBatch, input_embeds: torch.Tensor, per_layer_inputs: Optional[torch.Tensor])
         ‚Üí torch.Tensor


============================================================
FILE: python/sglang/srt/models/gemma3n_mm.py
Functions: 15
============================================================


CLASS: Gemma3nForConditionalGeneration
----------------------------------------
  L 193: __init__(self, config: Gemma3nConfig, quant_config: Optional[QuantizationConfig], prefix: str)
         ‚Üí None

  L 245: pad_input_ids(self, input_ids: List[int], mm_inputs: MultimodalInputs)
         ‚Üí List[int]
         üìù Pad input IDs with image and audio tokens.

  L 254: get_input_embeddings(self)
         ‚Üí nn.Embedding

  L 257: get_attention_sliding_window_size(self)

  L 260: get_image_feature(self, items: List[MultimodalDataItem])
         üìù Projects the last hidden state from the vision model into language model space.
            Returns:
            image_features (`torch.Tensor`): Image feature tensor of shape `(num_images, image_length, embed_dim)`).

  L 308: get_audio_feature(self, items: List[MultimodalDataItem])
         ‚Üí torch.Tensor
         üìù Projects the last hidden state from the audio encoder into language model space.
            Args:
            items: List of multimodal data items containing audio data.
            Returns:
            audio_features (`torch.Tensor`): Audio feature tensor of shape `(num_audios, audio_length, embed_dim)`).

  L 388: get_per_layer_inputs(self, input_ids: torch.LongTensor)
         ‚Üí Optional[torch.Tensor]

  L 393: project_per_layer_inputs(self, inputs_embeds: torch.Tensor, per_layer_inputs: Optional[torch.Tensor])
         ‚Üí torch.Tensor

  L 403: forward(self, input_ids: torch.LongTensor, positions: torch.Tensor, forward_batch: ForwardBatch, input_embeds: torch.Tensor)
         ‚Üí LogitsProcessor
         üìù Forward pass for multimodal Gemma3n.

  L 449: tie_weights(self)

  L 452: load_weights(self, weights: Iterable[Tuple[str, torch.Tensor]])

  L 499: should_apply_lora(self, module_name: str)
         ‚Üí bool

  L 502: get_hidden_dim(self, module_name)


CLASS: Gemma3nMultimodalEmbedder
----------------------------------------
  L  62: __init__(self, multimodal_config: Union[Gemma3nAudioConfig, Gemma3nVisionConfig], text_config: Gemma3nTextConfig, quant_config: Optional[QuantizationConfig], prefix: str)

  L 108: forward(self, input_ids: Optional[torch.LongTensor], inputs_embeds: Optional[torch.Tensor])
         ‚Üí torch.Tensor
         üìù Embeds token ids or soft tokens for multimodal content into language model space.
            Args:
            input_ids: A torch.LongTensor containing the token ids to embed. Values should be in the range
            `[vocab_offset, vocab_offset + vocab_size)`.
            inputs_embeds: A torch.Tensor containing the soft tokens to embed.
            Returns:
            A torch.Tensor of embeddings with  shape `[batch_size, seq_len, self.config.text_config.hidden_size]`.


============================================================
FILE: python/sglang/srt/models/glm4.py
Functions: 11
============================================================


CLASS: Glm4Attention
----------------------------------------
  L  44: __init__(self, config, layer_id: int, quant_config: Optional[QuantizationConfig], prefix: str)

  L 111: forward(self, positions: torch.Tensor, hidden_states: torch.Tensor, forward_batch: ForwardBatch)
         ‚Üí torch.Tensor


CLASS: Glm4DecoderLayer
----------------------------------------
  L 137: __init__(self, config, layer_id: int, quant_config: Optional[QuantizationConfig], prefix: str)

  L 168: forward(self, positions: torch.Tensor, hidden_states: torch.Tensor, forward_batch: ForwardBatch, residual: Optional[torch.Tensor])
         ‚Üí Tuple[torch.Tensor, torch.Tensor]


CLASS: Glm4ForCausalLM
----------------------------------------
  L 253: __init__(self, config: Glm4Config, quant_config: Optional[QuantizationConfig], prefix: str)

  L 275: forward(self, input_ids: torch.Tensor, positions: torch.Tensor, forward_batch: ForwardBatch)
         ‚Üí torch.Tensor

  L 286: load_weights(self, weights: Iterable[Tuple[str, torch.Tensor]])


CLASS: Glm4Model
----------------------------------------
  L 197: __init__(self, config: Glm4Config, quant_config: Optional[QuantizationConfig], prefix: str)
         ‚Üí None

  L 221: get_input_embeddings(self)
         ‚Üí nn.Embedding

  L 224: dtype(self)
         ‚Üí torch.dtype

  L 228: forward(self, input_ids: torch.Tensor, positions: torch.Tensor, forward_batch: ForwardBatch, input_embeds: torch.Tensor)
         ‚Üí Union[torch.Tensor, Tuple[torch.Tensor, List[torch.Tensor]]]


============================================================
FILE: python/sglang/srt/models/glm4_moe.py
Functions: 20
============================================================


CLASS: Glm4MoeAttention
----------------------------------------
  L 167: __init__(self, hidden_size: int, num_heads: int, num_kv_heads: int, layer_id: int, rope_theta: float, partial_rotary_factor: float, rope_scaling: Optional[Dict[str, Any]], max_position_embeddings: int, head_dim: Optional[int], rms_norm_eps: float, attention_bias: bool, quant_config: Optional[QuantizationConfig], use_qk_norm: bool, prefix: str, alt_stream: Optional[torch.cuda.Stream])
         ‚Üí None

  L 280: op_prepare(self, state)

  L 287: op_core(self, state)

  L 292: forward_prepare(self, positions: torch.Tensor, hidden_states: torch.Tensor, forward_batch: ForwardBatch)

  L 308: forward_core(self, intermediate_state)

  L 316: forward(self, positions: torch.Tensor, hidden_states: torch.Tensor, forward_batch: ForwardBatch)
         ‚Üí torch.Tensor


CLASS: Glm4MoeDecoderLayer
----------------------------------------
  L 578: __init__(self, config: PretrainedConfig, layer_id: int, quant_config: Optional[QuantizationConfig], is_nextn: bool, prefix: str, alt_stream: Optional[torch.cuda.Stream])
         ‚Üí None

  L 662: forward(self, positions: torch.Tensor, hidden_states: torch.Tensor, forward_batch: ForwardBatch, residual: Optional[torch.Tensor], zero_allocator: BumpAllocator)
         ‚Üí torch.Tensor


CLASS: Glm4MoeForCausalLM
----------------------------------------
  L 731: __init__(self, config: PretrainedConfig, quant_config: Optional[QuantizationConfig], prefix: str)
         ‚Üí None

  L 764: determine_num_fused_shared_experts(self, architecture: str)

  L 794: get_input_embeddings(self)
         ‚Üí nn.Embedding

  L 797: load_weights(self, weights: Iterable[Tuple[str, torch.Tensor]], is_nextn)


CLASS: Glm4MoeGate
----------------------------------------
  L 331: __init__(self, config, prefix: str, is_nextn: bool)

  L 348: forward(self, hidden_states)


CLASS: Glm4MoeMLP
----------------------------------------
  L 116: __init__(self, hidden_size: int, intermediate_size: int, hidden_act: str, quant_config: Optional[QuantizationConfig], reduce_results: bool, prefix: str, tp_rank: Optional[int], tp_size: Optional[int])
         ‚Üí None

  L 156: forward(self, x, forward_batch, should_allreduce_fusion)


CLASS: Glm4MoeModel
----------------------------------------
  L 694: __init__(self, config: PretrainedConfig, quant_config: Optional[QuantizationConfig], prefix: str)
         ‚Üí None


CLASS: Glm4MoeSparseMoeBlock
----------------------------------------
  L 376: __init__(self, config: PretrainedConfig, layer_id: int, quant_config: Optional[QuantizationConfig], prefix: str, alt_stream: Optional[torch.cuda.Stream], is_nextn: bool)

  L 499: forward_normal_dual_stream(self, hidden_states: torch.Tensor, should_allreduce_fusion: bool, use_reduce_scatter: bool)
         ‚Üí torch.Tensor

  L 541: forward_normal(self, hidden_states: torch.Tensor, should_allreduce_fusion: bool, use_reduce_scatter: bool)
         ‚Üí torch.Tensor


============================================================
FILE: python/sglang/srt/models/glm4_moe_nextn.py
Functions: 5
============================================================


CLASS: Glm4MoeForCausalLMNextN
----------------------------------------
  L 128: __init__(self, config: PretrainedConfig, quant_config: Optional[QuantizationConfig], prefix: str)
         ‚Üí None

  L 153: forward(self, input_ids: torch.Tensor, positions: torch.Tensor, forward_batch: ForwardBatch)
         ‚Üí torch.Tensor

  L 164: load_weights(self, weights: Iterable[Tuple[str, torch.Tensor]])


CLASS: Glm4MoeModelNextN
----------------------------------------
  L  42: __init__(self, config: PretrainedConfig, quant_config: Optional[QuantizationConfig], prefix: str)
         ‚Üí None

  L  80: forward(self, input_ids: torch.Tensor, positions: torch.Tensor, forward_batch: ForwardBatch, input_embeds: torch.Tensor)
         ‚Üí torch.Tensor


============================================================
FILE: python/sglang/srt/models/glm4v.py
Functions: 22
============================================================


CLASS: Glm4vForConditionalGeneration
----------------------------------------
  L 465: __init__(self, config: Glm4vConfig, quant_config: Optional[QuantizationConfig], prefix: str)
         ‚Üí None

  L 501: get_image_feature(self, items: List[MultimodalDataItem])
         ‚Üí torch.Tensor

  L 516: get_video_feature(self, items: List[MultimodalDataItem])
         ‚Üí torch.Tensor

  L 587: load_weights(self, weights: Iterable[Tuple[str, torch.Tensor]])


CLASS: Glm4vPatchMerger
----------------------------------------
  L 145: __init__(self, d_model: int, context_dim: int, quant_config: Optional[QuantizationConfig], bias: bool, prefix: str)
         ‚Üí None

  L 180: forward(self, x: torch.Tensor)


CLASS: Glm4vRMSNorm
----------------------------------------
  L  38: forward(self, x: torch.Tensor)
         ‚Üí torch.Tensor


CLASS: Glm4vVisionBlock
----------------------------------------
  L  80: __init__(self, config: Glm4vVisionConfig, norm_layer: Optional[nn.Module], quant_config: Optional[QuantizationConfig], prefix: str)
         ‚Üí None


CLASS: Glm4vVisionEmbeddings
----------------------------------------
  L 191: __init__(self, config: Glm4vVisionConfig)

  L 207: forward(self, embeddings, lengths, image_shapes, h_coords, w_coords)
         ‚Üí torch.Tensor


CLASS: Glm4vVisionMLP
----------------------------------------
  L  47: __init__(self, in_features: int, hidden_features: int, bias: bool, quant_config: Optional[QuantizationConfig], prefix: str)

  L  72: forward(self, x: torch.Tensor)


CLASS: Glm4vVisionModel
----------------------------------------
  L 320: __init__(self, vision_config: Glm4vVisionConfig, norm_eps: float, quant_config: Optional[QuantizationConfig], prefix: str)
         ‚Üí None

  L 387: dtype(self)
         ‚Üí torch.dtype

  L 391: device(self)
         ‚Üí torch.device

  L 394: rot_pos_emb(self, grid_thw: torch.Tensor)
         ‚Üí torch.Tensor

  L 426: forward(self, x: torch.Tensor, grid_thw: torch.Tensor)
         ‚Üí torch.Tensor


CLASS: Glm4vVisionPatchEmbed
----------------------------------------
  L 110: __init__(self, patch_size: int, temporal_patch_size: int, in_channels: int, hidden_size: int)
         ‚Üí None

  L 132: forward(self, x: torch.Tensor)
         ‚Üí torch.Tensor


CLASS: Glm4vVisionRotaryEmbedding
----------------------------------------
  L 282: __init__(self, dim: int, theta: float)
         ‚Üí None

  L 291: update_freqs_cache(self, seqlen: int)
         ‚Üí None

  L 314: forward(self, seqlen: int)
         ‚Üí torch.Tensor


============================================================
FILE: python/sglang/srt/models/glm4v_moe.py
Functions: 3
============================================================


CLASS: Glm4vMoeForConditionalGeneration
----------------------------------------
  L  34: __init__(self, config: Glm4vMoeConfig, quant_config: Optional[QuantizationConfig], prefix: str)
         ‚Üí None

  L  77: determine_num_fused_shared_experts(self, architecture: str)

  L 107: load_weights(self, weights: Iterable[Tuple[str, torch.Tensor]], is_nextn)


============================================================
FILE: python/sglang/srt/models/gpt2.py
Functions: 11
============================================================


CLASS: GPT2Attention
----------------------------------------
  L  44: __init__(self, layer_id: int, config: GPT2Config, quant_config: Optional[QuantizationConfig], prefix: str)

  L  84: forward(self, hidden_states: torch.Tensor, forward_batch: ForwardBatch)
         ‚Üí torch.Tensor


CLASS: GPT2Block
----------------------------------------
  L 136: __init__(self, layer_id: int, config: GPT2Config, act_layer: Type[nn.Module], quant_config: Optional[QuantizationConfig], prefix: str)

  L 161: forward(self, hidden_states: torch.Tensor, forward_batch: ForwardBatch)
         ‚Üí torch.Tensor


CLASS: GPT2LMHeadModel
----------------------------------------
  L 233: __init__(self, config: GPT2Config, quant_config: Optional[QuantizationConfig], prefix: str)

  L 249: forward(self, input_ids: torch.Tensor, positions: torch.Tensor, forward_batch: ForwardBatch)
         ‚Üí torch.Tensor

  L 260: load_weights(self, weights: Iterable[Tuple[str, torch.Tensor]])


CLASS: GPT2MLP
----------------------------------------
  L  98: __init__(self, intermediate_size: int, config: GPT2Config, act_layer: Type[nn.Module], quant_config: Optional[QuantizationConfig], prefix: str)

  L 124: forward(self, hidden_states: torch.Tensor)
         ‚Üí torch.Tensor


CLASS: GPT2Model
----------------------------------------
  L 185: __init__(self, config: GPT2Config, quant_config: Optional[QuantizationConfig], prefix: str)

  L 213: forward(self, input_ids: torch.Tensor, position_ids: torch.Tensor, forward_batch: ForwardBatch)
         ‚Üí torch.Tensor


============================================================
FILE: python/sglang/srt/models/gpt_bigcode.py
Functions: 11
============================================================


CLASS: GPTBigCodeAttention
----------------------------------------
  L  43: __init__(self, layer_id: int, config: GPTBigCodeConfig, quant_config: Optional[QuantizationConfig], prefix: str)

  L  94: forward(self, hidden_states: torch.Tensor, forward_batch: ForwardBatch)
         ‚Üí torch.Tensor


CLASS: GPTBigCodeBlock
----------------------------------------
  L 151: __init__(self, layer_id: int, config: GPTBigCodeConfig, quant_config: Optional[QuantizationConfig], prefix: str)

  L 171: forward(self, hidden_states: torch.Tensor, forward_batch: ForwardBatch)
         ‚Üí torch.Tensor


CLASS: GPTBigCodeForCausalLM
----------------------------------------
  L 254: __init__(self, config: GPTBigCodeConfig, quant_config: Optional[QuantizationConfig], prefix: str)

  L 273: forward(self, input_ids: torch.Tensor, positions: torch.Tensor, forward_batch: ForwardBatch)
         ‚Üí torch.Tensor

  L 284: load_weights(self, weights: Iterable[Tuple[str, torch.Tensor]])


CLASS: GPTBigCodeModel
----------------------------------------
  L 194: __init__(self, config: GPTBigCodeConfig, quant_config: Optional[QuantizationConfig], prefix: str)

  L 224: forward(self, input_ids: torch.Tensor, position_ids: torch.Tensor, forward_batch: ForwardBatch)
         ‚Üí torch.Tensor


CLASS: GPTBigMLP
----------------------------------------
  L 115: __init__(self, intermediate_size: int, config: GPTBigCodeConfig, quant_config: Optional[QuantizationConfig], prefix: str)

  L 142: forward(self, hidden_states: torch.Tensor)
         ‚Üí torch.Tensor


============================================================
FILE: python/sglang/srt/models/gpt_oss.py
Functions: 27
============================================================

MODULE FUNCTIONS:
----------------------------------------
  L  99: def get_attention_sliding_window_size(config)


CLASS: GptOssAttention
----------------------------------------
  L 223: __init__(self, hidden_size: int, num_heads: int, num_kv_heads: int, layer_id: int, rope_theta: float, rope_scaling: Optional[Dict[str, Any]], max_position_embeddings: int, head_dim: Optional[int], rms_norm_eps: float, attention_bias: bool, quant_config: Optional[QuantizationConfig], prefix: str, sliding_window_size: int, layer_type: str, params_dtype: torch.dtype)
         ‚Üí None

  L 323: forward_prepare(self, positions: torch.Tensor, hidden_states: torch.Tensor, forward_batch: ForwardBatch)

  L 351: forward_core(self, intermediate_state)

  L 363: forward(self, positions: torch.Tensor, hidden_states: torch.Tensor, forward_batch: ForwardBatch)
         ‚Üí torch.Tensor


CLASS: GptOssConfig
----------------------------------------
  L  90: __init__(self)


CLASS: GptOssDecoderLayer
----------------------------------------
  L 378: __init__(self, config: GptOssConfig, layer_id: int, quant_config: Optional[QuantizationConfig], prefix: str, sliding_window_size: int | None)
         ‚Üí None

  L 463: forward(self, positions: torch.Tensor, hidden_states: torch.Tensor, forward_batch: ForwardBatch, residual: Optional[torch.Tensor])
         ‚Üí Tuple[torch.Tensor, torch.Tensor]


CLASS: GptOssForCausalLM
----------------------------------------
  L 598: __init__(self, config: GptOssConfig, quant_config: Optional[QuantizationConfig], prefix: str)
         ‚Üí None

  L 630: routed_experts_weights_of_layer(self)

  L 634: forward(self, input_ids: torch.Tensor, positions: torch.Tensor, forward_batch: ForwardBatch, input_embeds: torch.Tensor, pp_proxy_tensors: Optional[PPProxyTensors])
         ‚Üí torch.Tensor

  L 666: start_layer(self)

  L 670: end_layer(self)

  L 741: load_weights(self, weights: Iterable[Tuple[str, torch.Tensor]], is_nextn: bool, weight_name_mapping: dict)

  L1111: get_embed_and_head(self)

  L1114: set_embed_and_head(self, embed, head)

  L1122: set_eagle3_layers_to_capture(self, layer_ids: Optional[List[int]])

  L1137: get_model_config_for_expert_location(cls, config)

  L1144: get_attention_sliding_window_size(self)


CLASS: GptOssModel
----------------------------------------
  L 505: __init__(self, config: PretrainedConfig, quant_config: Optional[QuantizationConfig], prefix: str, decoder_layer_type: type[nn.Module])
         ‚Üí None

  L 548: forward(self, input_ids: torch.Tensor, positions: torch.Tensor, forward_batch: ForwardBatch, input_embeds: torch.Tensor, pp_proxy_tensors: Optional[PPProxyTensors])
         ‚Üí Union[torch.Tensor, PPProxyTensors]


CLASS: GptOssSparseMoeBlock
----------------------------------------
  L 104: __init__(self, layer_id: int, config: GptOssConfig, quant_config: Optional[QuantizationConfig], prefix: str)

  L 160: forward(self, hidden_states: torch.Tensor, forward_batch: Optional[ForwardBatch], should_allreduce_fusion: bool)
         ‚Üí torch.Tensor

  L 171: get_moe_weights(self)

  L 178: forward_normal(self, hidden_states: torch.Tensor, should_allreduce_fusion: bool)
         ‚Üí torch.Tensor


CLASS: _WeightCreator
----------------------------------------
  L1190: __init__(self, fn)

  L1194: maybe_materialize(obj)


============================================================
FILE: python/sglang/srt/models/granite.py
Functions: 14
============================================================


CLASS: GraniteAttention
----------------------------------------
  L  90: __init__(self, config: GraniteConfig, hidden_size: int, num_heads: int, num_kv_heads: int, layer_id: int, rope_theta: float, rope_scaling: Optional[Dict[str, Any]], rope_is_neox_style: bool, max_position_embeddings: int, quant_config: Optional[QuantizationConfig], prefix: str)
         ‚Üí None

  L 165: forward(self, positions: torch.Tensor, hidden_states: torch.Tensor, forward_batch: ForwardBatch)
         ‚Üí torch.Tensor


CLASS: GraniteDecoderLayer
----------------------------------------
  L 180: __init__(self, config: GraniteConfig, layer_id: int, quant_config: Optional[QuantizationConfig], prefix: str)
         ‚Üí None

  L 225: forward(self, positions: torch.Tensor, hidden_states: torch.Tensor, forward_batch: ForwardBatch, residual: Optional[torch.Tensor])
         ‚Üí Tuple[torch.Tensor, torch.Tensor]


CLASS: GraniteForCausalLM
----------------------------------------
  L 306: __init__(self, config: GraniteConfig, quant_config: Optional[QuantizationConfig], prefix: str)
         ‚Üí None

  L 349: forward(self, input_ids: torch.Tensor, positions: torch.Tensor, forward_batch: ForwardBatch, input_embeds: torch.Tensor, get_embedding: bool)
         ‚Üí LogitsProcessorOutput

  L 366: get_module_name_from_weight_name(self, name)

  L 375: get_num_params(self)

  L 379: load_weights(self, weights: Iterable[Tuple[str, torch.Tensor]])

  L 431: get_weights_by_name(self, name: str, truncate_size: int, tp_size: int)
         ‚Üí Optional[torch.Tensor]
         üìù Get the weights of the parameter by its name. Similar to `get_parameter` in Hugging Face.
            Only used for unit test with an unoptimized performance.
            For optimized performance, please use torch.save and torch.load.


CLASS: GraniteMLP
----------------------------------------
  L  52: __init__(self, hidden_size: int, intermediate_size: int, hidden_act: str, quant_config: Optional[QuantizationConfig], prefix: str)
         ‚Üí None

  L  82: forward(self, x)


CLASS: GraniteModel
----------------------------------------
  L 254: __init__(self, config: GraniteConfig, quant_config: Optional[QuantizationConfig], prefix: str)
         ‚Üí None

  L 280: forward(self, input_ids: torch.Tensor, positions: torch.Tensor, forward_batch: ForwardBatch, input_embeds: torch.Tensor)
         ‚Üí torch.Tensor


============================================================
FILE: python/sglang/srt/models/granitemoe.py
Functions: 12
============================================================


CLASS: GraniteMoeAttention
----------------------------------------
  L  94: __init__(self, hidden_size: int, num_heads: int, num_kv_heads: int, max_position: int, layer_id: int, rope_theta: float, quant_config: Optional[QuantizationConfig], attention_multiplier: Optional[float], prefix: str)
         ‚Üí None

  L 165: forward(self, positions: torch.Tensor, hidden_states: torch.Tensor, forward_batch: ForwardBatch)
         ‚Üí torch.Tensor


CLASS: GraniteMoeDecoderLayer
----------------------------------------
  L 181: __init__(self, config: GraniteConfig, layer_id: int, quant_config: Optional[QuantizationConfig], prefix: str)
         ‚Üí None

  L 219: forward(self, positions: torch.Tensor, hidden_states: torch.Tensor, forward_batch: ForwardBatch)
         ‚Üí torch.Tensor


CLASS: GraniteMoeForCausalLM
----------------------------------------
  L 300: __init__(self, config: GraniteConfig, quant_config: Optional[QuantizationConfig], prefix: str)

  L 331: forward(self, input_ids: torch.Tensor, positions: torch.Tensor, forward_batch: ForwardBatch, input_embeds: torch.Tensor, get_embedding: bool)
         ‚Üí LogitsProcessorOutput

  L 348: load_weights(self, weights: Iterable[tuple[str, torch.Tensor]])
         ‚Üí set[str]


CLASS: GraniteMoeMoE
----------------------------------------
  L  40: __init__(self, num_experts: int, top_k: int, hidden_size: int, intermediate_size: int, layer_id: int, params_dtype: Optional[torch.dtype], quant_config: Optional[QuantizationConfig], tp_size: Optional[int], prefix: str)

  L  82: forward(self, hidden_states: torch.Tensor)
         ‚Üí torch.Tensor


CLASS: GraniteMoeModel
----------------------------------------
  L 244: __init__(self, config: GraniteConfig, quant_config: Optional[QuantizationConfig], prefix: str)

  L 271: get_input_embeddings(self, input_ids: torch.Tensor)
         ‚Üí torch.Tensor

  L 274: forward(self, input_ids: torch.Tensor, positions: torch.Tensor, forward_batch: ForwardBatch, inputs_embeds: Optional[torch.Tensor])
         ‚Üí torch.Tensor


============================================================
FILE: python/sglang/srt/models/grok.py
Functions: 18
============================================================

MODULE FUNCTIONS:
----------------------------------------
  L 218: def get_rope_scaling(config)


CLASS: Grok1Attention
----------------------------------------
  L 337: __init__(self, config: PretrainedConfig, hidden_size: int, num_heads: int, num_kv_heads: int, layer_id: int, max_position: int, rope_theta: float, quant_config: Optional[QuantizationConfig], reduce_results: bool, alt_stream: Optional[torch.cuda.Stream], load_presharded_attn: bool, prefix: str)
         ‚Üí None

  L 457: forward(self, positions: torch.Tensor, hidden_states: torch.Tensor, forward_batch: ForwardBatch)
         ‚Üí torch.Tensor


CLASS: Grok1DecoderLayer
----------------------------------------
  L 538: __init__(self, config: PretrainedConfig, layer_id: int, quant_config: Optional[QuantizationConfig], load_presharded_moe: bool, load_presharded_attn: bool, load_presharded_mlp: bool, alt_stream: Optional[torch.cuda.Stream], skip_moe: bool, prefix: str)
         ‚Üí None

  L 630: forward(self, positions: torch.Tensor, hidden_states: torch.Tensor, forward_batch: ForwardBatch, residual: Optional[torch.Tensor], deferred_norm: Optional[RMSNorm])
         ‚Üí Tuple[torch.Tensor, torch.Tensor, RMSNorm]

  L 696: moe_with_rmoe(self, x)


CLASS: Grok1ForCausalLM
----------------------------------------
  L 808: __init__(self, config: PretrainedConfig, quant_config: Optional[QuantizationConfig], prefix: str)
         ‚Üí None

  L 893: forward(self, input_ids: torch.Tensor, positions: torch.Tensor, forward_batch: ForwardBatch, input_embeds: torch.Tensor)
         ‚Üí torch.Tensor

  L 908: load_weights(self, weights: Iterable[Tuple[str, torch.Tensor]], ignore_parent_name: bool, check_hit_names: bool, model_config: PretrainedConfig | None)
         ‚Üí dict[str, torch.Tensor]

  L1025: get_num_params_analytical(self)

  L1073: get_num_params_torch(self)


CLASS: Grok1MLP
----------------------------------------
  L  88: __init__(self, hidden_size: int, intermediate_size: int, layer_id: int, quant_config: Optional[QuantizationConfig], prefix: str, reduce_results, use_presharded_weights: bool, split_gate_up: bool)
         ‚Üí None

  L 121: forward(self, x)


CLASS: Grok1MoE
----------------------------------------
  L 137: __init__(self, config: PretrainedConfig, layer_id: int, num_experts: int, top_k: int, hidden_size: int, intermediate_size: int, params_dtype: Optional[torch.dtype], quant_config: Optional[QuantizationConfig], tp_size: Optional[int], reduce_results: bool, use_presharded_weights: bool, inplace: bool, no_combine: bool, prefix: str)

  L 201: forward(self, hidden_states: torch.Tensor)
         ‚Üí torch.Tensor


CLASS: Grok1Model
----------------------------------------
  L 708: __init__(self, config: PretrainedConfig, quant_config: Optional[QuantizationConfig], load_presharded_moe: bool, load_presharded_embedding: bool, load_presharded_attn: bool, load_presharded_mlp: bool, replicate_embedding: bool, prefix: str)
         ‚Üí None

  L 749: forward(self, input_ids: torch.Tensor, positions: torch.Tensor, forward_batch: ForwardBatch, input_embeds: torch.Tensor)
         ‚Üí torch.Tensor


CLASS: ScalingRotaryEmbedding
----------------------------------------
  L 247: __init__(self, head_size: int, rotary_dim: int, max_position_embeddings: int, base: int, is_neox_style: bool, scaling_factor: float, dtype: torch.dtype)
         ‚Üí None


============================================================
FILE: python/sglang/srt/models/hunyuan.py
Functions: 17
============================================================

MODULE FUNCTIONS:
----------------------------------------
  L 213: def get_head_dim(config)

  L 224: def check_head_dim(config)


CLASS: HunYuanAttention
----------------------------------------
  L 251: __init__(self, config: PretrainedConfig, hidden_size: int, num_heads: int, num_kv_heads: int, rope_theta: float, rope_scaling: Optional[Dict[str, Any]], max_position_embeddings: int, quant_config: Optional[QuantizationConfig], bias: bool, prefix: str, attention_type: str, layer_id: int)
         ‚Üí None

  L 351: forward(self, positions: torch.Tensor, hidden_states: torch.Tensor, forward_batch: ForwardBatch, kv_states: Optional[Tuple[torch.Tensor]])
         ‚Üí torch.Tensor


CLASS: HunYuanDecoderLayer
----------------------------------------
  L 392: __init__(self, config: PretrainedConfig, quant_config: Optional[QuantizationConfig], prefix: str, layer_id: int)
         ‚Üí None

  L 462: forward(self, positions: torch.Tensor, hidden_states: torch.Tensor, forward_batch: ForwardBatch, residual: Optional[torch.Tensor], kv_states: Optional[Tuple[torch.Tensor]])
         ‚Üí Tuple[torch.Tensor, torch.Tensor]


CLASS: HunYuanMLP
----------------------------------------
  L  82: __init__(self, hidden_size: int, intermediate_size: int, hidden_act: str, quant_config: Optional[QuantizationConfig], bias: bool, prefix: str, reduce_results: bool)
         ‚Üí None

  L 115: forward(self, x)


CLASS: HunYuanMoEV1ForCausalLM
----------------------------------------
  L 585: __init__(self, config: PretrainedConfig, quant_config: Optional[QuantizationConfig])
         ‚Üí None

  L 613: forward(self, input_ids: torch.Tensor, positions: torch.Tensor, forward_batch: ForwardBatch, input_embeds: torch.Tensor)
         ‚Üí torch.Tensor

  L 642: load_weights(self, weights: Iterable[Tuple[str, torch.Tensor]])

  L 788: load_kv_cache_scales(self, quantization_param_path: str)
         ‚Üí None


CLASS: HunYuanModel
----------------------------------------
  L 491: __init__(self, config: PretrainedConfig, quant_config: Optional[QuantizationConfig], prefix: str)
         ‚Üí None

  L 522: get_input_embeddings(self, input_ids: torch.Tensor)
         ‚Üí torch.Tensor

  L 525: forward(self, input_ids: Optional[torch.Tensor], positions: torch.Tensor, forward_batch: ForwardBatch, input_embeds: Optional[torch.Tensor])
         ‚Üí torch.Tensor


CLASS: HunYuanSparseMoeBlock
----------------------------------------
  L 124: __init__(self, config: PretrainedConfig, quant_config: Optional[QuantizationConfig], layer_id: int)

  L 192: forward(self, hidden_states: torch.Tensor)
         ‚Üí torch.Tensor


============================================================
FILE: python/sglang/srt/models/idefics2.py
Functions: 13
============================================================


CLASS: Idefics2Encoder
----------------------------------------
  L 131: __init__(self, config: PretrainedConfig, quant_config: Optional[QuantizationConfig], prefix: str)
         ‚Üí None

  L 151: forward(self, inputs_embeds: torch.Tensor, cu_seqlens: torch.Tensor)
         ‚Üí torch.Tensor
         üìù Args:
            inputs_embeds (torch.Tensor):
            Optionally, instead of passing `input_ids` you can choose to
            directly pass an embedded representation.
            This is useful if you want more control over how to convert
            `input_ids` indices into associated vectorsthan the model's
            internal embedding lookup matrix.


CLASS: Idefics2EncoderLayer
----------------------------------------
  L  69: __init__(self, config: PretrainedConfig, quant_config: Optional[QuantizationConfig], prefix: str)
         ‚Üí None

  L  98: forward(self, hidden_states: torch.Tensor, cu_seqlens: torch.Tensor)
         ‚Üí torch.Tensor
         üìù Args:
            hidden_states (`torch.FloatTensor`):
            Input to the layer of shape `(batch, seq_len, embed_dim)`.


CLASS: Idefics2VisionEmbeddings
----------------------------------------
  L 189: __init__(self, config: PretrainedConfig)

  L 206: get_position_ids(self, pixel_values: torch.FloatTensor, patch_attention_mask: torch.BoolTensor, tgt_sizes: Optional[torch.IntTensor])

  L 248: forward(self, pixel_values: torch.FloatTensor, patch_attention_mask: torch.BoolTensor, tgt_sizes: Optional[torch.IntTensor])
         ‚Üí torch.Tensor


CLASS: Idefics2VisionMLP
----------------------------------------
  L  36: __init__(self, config: PretrainedConfig, quant_config: Optional[QuantizationConfig], prefix: str)
         ‚Üí None

  L  60: forward(self, hidden_states: torch.Tensor)
         ‚Üí torch.Tensor


CLASS: Idefics2VisionTransformer
----------------------------------------
  L 270: __init__(self, config: PretrainedConfig, quant_config: Optional[QuantizationConfig], require_post_norm: bool, prefix: str)
         ‚Üí None

  L 293: get_input_embeddings(self)
         ‚Üí nn.Embedding

  L 296: compute_cu_seqlens(self, tgt_sizes: Optional[torch.Tensor], input_embeds: Optional[torch.Tensor])
         ‚Üí torch.Tensor

  L 325: forward(self, pixel_values, patch_attention_mask: Optional[torch.BoolTensor], tgt_sizes: Optional[torch.IntTensor])
         ‚Üí torch.Tensor


============================================================
FILE: python/sglang/srt/models/internlm2.py
Functions: 12
============================================================


CLASS: InternLM2Attention
----------------------------------------
  L  83: __init__(self, hidden_size: int, num_heads: int, num_kv_heads: int, rope_theta: float, rope_scaling: Optional[Dict[str, Any]], max_position_embeddings: int, layer_id: int, quant_config: Optional[QuantizationConfig], prefix: str)
         ‚Üí None

  L 152: forward(self, positions: torch.Tensor, hidden_states: torch.Tensor, forward_batch: ForwardBatch)
         ‚Üí torch.Tensor


CLASS: InternLM2ForCausalLM
----------------------------------------
  L 276: __init__(self, config: PretrainedConfig, quant_config: Optional[QuantizationConfig], prefix: str)
         ‚Üí None

  L 293: get_input_embeddings(self)
         ‚Üí nn.Embedding

  L 297: forward(self, input_ids: torch.Tensor, positions: torch.Tensor, forward_batch: ForwardBatch, input_embeds: torch.Tensor)
         ‚Üí torch.Tensor

  L 309: load_weights(self, weights: Iterable[Tuple[str, torch.Tensor]])


CLASS: InternLM2MLP
----------------------------------------
  L  45: __init__(self, hidden_size: int, intermediate_size: int, hidden_act: str, quant_config: Optional[QuantizationConfig], prefix: str)
         ‚Üí None

  L  75: forward(self, x)


CLASS: InternLM2Model
----------------------------------------
  L 226: __init__(self, config: PretrainedConfig, quant_config: Optional[QuantizationConfig], prefix: str)
         ‚Üí None

  L 251: forward(self, input_ids: torch.Tensor, positions: torch.Tensor, forward_batch: ForwardBatch, input_embeds: torch.Tensor)
         ‚Üí torch.Tensor


CLASS: InternLMDecoderLayer
----------------------------------------
  L 167: __init__(self, config: PretrainedConfig, layer_id: int, quant_config: Optional[QuantizationConfig], prefix: str)
         ‚Üí None

  L 200: forward(self, positions: torch.Tensor, hidden_states: torch.Tensor, forward_batch: ForwardBatch, residual: Optional[torch.Tensor])
         ‚Üí Tuple[torch.Tensor, torch.Tensor]


============================================================
FILE: python/sglang/srt/models/internlm2_reward.py
Functions: 3
============================================================


CLASS: InternLM2ForRewardModel
----------------------------------------
  L  29: __init__(self, config: PretrainedConfig, quant_config: Optional[QuantizationConfig], prefix: str)
         ‚Üí None

  L  46: forward(self, input_ids: torch.Tensor, positions: torch.Tensor, forward_batch: ForwardBatch, input_embeds: torch.Tensor, get_embedding: bool)
         ‚Üí EmbeddingPoolerOutput

  L  60: load_weights(self, weights: Iterable[Tuple[str, torch.Tensor]])


============================================================
FILE: python/sglang/srt/models/interns1.py
Functions: 7
============================================================


CLASS: InternS1ForConditionalGeneration
----------------------------------------
  L  30: __init__(self, config: PretrainedConfig, quant_config: Optional[QuantizationConfig], use_flash_attn)
         ‚Üí None

  L  95: pixel_shuffle(self, x, scale_factor)

  L 117: extract_feature(self, pixel_values)

  L 135: get_image_feature(self, items: List[MultimodalDataItem])
         üìù Projects the last hidden state from the vision model into language model space.
            Returns:
            image_features (`torch.Tensor`): Image feature tensor of shape `(num_images, image_length, embed_dim)`).

  L 147: forward(self, input_ids: torch.Tensor, positions: torch.Tensor, forward_batch: ForwardBatch, input_embeds: torch.Tensor)
         ‚Üí torch.Tensor

  L 167: pad_input_ids(self, input_ids: List[int], mm_inputs: MultimodalInputs)

  L 209: load_weights(self, weights: Iterable[Tuple[str, torch.Tensor]])


============================================================
FILE: python/sglang/srt/models/internvl.py
Functions: 23
============================================================


CLASS: InternAttention
----------------------------------------
  L  36: __init__(self, config, quant_config: QuantizationConfig)

  L  66: forward(self, hidden_states: torch.Tensor, cu_seqlens: torch.Tensor)
         ‚Üí torch.Tensor


CLASS: InternMLP
----------------------------------------
  L 165: __init__(self, config: PretrainedConfig)

  L 172: forward(self, hidden_states: torch.Tensor)
         ‚Üí torch.Tensor


CLASS: InternRMSNorm
----------------------------------------
  L 151: __init__(self, hidden_size, eps)

  L 156: forward(self, hidden_states)


CLASS: InternVLChatModel
----------------------------------------
  L 406: __init__(self, config: PretrainedConfig, quant_config: Optional[QuantizationConfig], use_flash_attn)
         ‚Üí None

  L 465: pixel_shuffle(self, x, scale_factor)

  L 487: extract_feature(self, pixel_values)

  L 505: get_image_feature(self, items: List[MultimodalDataItem])
         üìù Projects the last hidden state from the vision model into language model space.
            Returns:
            image_features (`torch.Tensor`): Image feature tensor of shape `(num_images, image_length, embed_dim)`).

  L 517: forward(self, input_ids: torch.Tensor, positions: torch.Tensor, forward_batch: ForwardBatch, input_embeds: torch.Tensor)
         ‚Üí torch.Tensor

  L 537: pad_input_ids(self, input_ids: List[int], mm_inputs: MultimodalInputs)

  L 547: load_weights(self, weights: Iterable[Tuple[str, torch.Tensor]])


CLASS: InternVisionEmbeddings
----------------------------------------
  L  77: __init__(self, config: PretrainedConfig)

  L 130: forward(self, pixel_values: torch.FloatTensor)
         ‚Üí torch.Tensor


CLASS: InternVisionEncoder
----------------------------------------
  L 249: __init__(self, config: PretrainedConfig, quant_config: Optional[QuantizationConfig])

  L 268: forward(self, inputs_embeds, output_hidden_states: Optional[bool], return_dict: Optional[bool])
         ‚Üí Union[Tuple, BaseModelOutput]
         üìù Args:
            inputs_embeds (`torch.FloatTensor` of shape `(batch_size, sequence_length, hidden_size)`):
            Embedded representation of the inputs. Should be float, not int tokens.
            output_hidden_states (`bool`, *optional*):
            Whether or not to return the hidden states of all layers. See `hidden_states` under returned tensors
            for more detail.
            return_dict (`bool`, *optional*):
            Whether or not to return a [`~utils.ModelOutput`] instead of a plain tuple.


CLASS: InternVisionEncoderLayer
----------------------------------------
  L 187: __init__(self, config: PretrainedConfig, drop_path_rate: float, quant_config: QuantizationConfig)

  L 211: forward(self, hidden_states: torch.Tensor, cu_seqlens: torch.Tensor)
         ‚Üí Tuple[torch.FloatTensor, Optional[torch.FloatTensor], Optional[Tuple[torch.FloatTensor]]]
         üìù Args:
            hidden_states (`Tuple[torch.FloatTensor, Optional[torch.FloatTensor]]`): input to the layer of shape `(batch, seq_len, embed_dim)`


CLASS: InternVisionModel
----------------------------------------
  L 320: __init__(self, config: PretrainedConfig, quant_config: Optional[QuantizationConfig])

  L 333: resize_pos_embeddings(self, old_size, new_size, patch_size)

  L 356: get_input_embeddings(self)

  L 359: forward(self, pixel_values: Optional[torch.FloatTensor], output_hidden_states: Optional[bool], return_dict: Optional[bool], pixel_embeds: Optional[torch.FloatTensor])
         ‚Üí Union[Tuple, BaseModelOutputWithPooling]


============================================================
FILE: python/sglang/srt/models/kimi_vl.py
Functions: 8
============================================================

MODULE FUNCTIONS:
----------------------------------------
  L 300: def get_spec_layer_idx_from_weight_name(config: DeepseekV2Config,
        weight_name: str)
         ‚Üí Optional[int]


CLASS: KimiVLForConditionalGeneration
----------------------------------------
  L 122: __init__(self, config: KimiVLConfig, quant_config: Optional[QuantizationConfig], prefix: str)
         ‚Üí None

  L 145: get_image_feature(self, items: List[MultimodalDataItem])
         ‚Üí torch.Tensor

  L 160: pad_input_ids(self, input_ids: List[int], mm_inputs: MultimodalInputs)

  L 164: forward(self, input_ids: torch.Tensor, positions: torch.Tensor, forward_batch: ForwardBatch, get_embedding: bool)

  L 183: load_weights(self, weights: Iterable[Tuple[str, torch.Tensor]])


CLASS: KimiVLMultiModalProjector
----------------------------------------
  L  96: __init__(self, config: KimiVLConfig)

  L 113: forward(self, image_features: torch.Tensor)
         ‚Üí torch.Tensor


============================================================
FILE: python/sglang/srt/models/kimi_vl_moonvit.py
Functions: 25
============================================================

MODULE FUNCTIONS:
----------------------------------------
  L  63: def multihead_attention(q: torch.Tensor,
        k: torch.Tensor,
        v: torch.Tensor,
        q_cu_seqlens: Optional[torch.Tensor],
        k_cu_seqlens: Optional[torch.Tensor])
         üìù Multi-head attention using flash attention 2.
            This function is used to handle the case where the query, key, and value are packed.
            Args:
            q, k, v: tensor of shape (tot_seqlens, num_heads, head_dim).
            q_cu_seqlens (torch.Tensor): cumulative sequence lengths of q.
            The first element should be 0 and the last element should be q.shape[0].
            k_cu_seqlens (torch.Tensor): cumulative sequence lengths of k.
            The first element should be 0 and the last element should be k.shape[0].
            Returns:
            output: shape (batch_size, seqlen, dim) or (tot_seqlens, dim) if packing,
            where dim = num_heads * head_dim

  L 115: def sdpa_attention(q: torch.Tensor,
        k: torch.Tensor,
        v: torch.Tensor,
        q_cu_seqlens: Optional[torch.Tensor],
        k_cu_seqlens: Optional[torch.Tensor])
         ‚Üí torch.Tensor
         üìù Multi-head attention using torch scaled dot product attention.
            This function is used to handle the case where the query, key, and value are packed.
            Args:
            q, k, v: tensor of shape (tot_seqlens, num_heads, head_dim).
            q_cu_seqlens (torch.Tensor): cumulative sequence lengths of q.
            The first element should be 0 and the last element should be q.shape[0].
            k_cu_seqlens (torch.Tensor): cumulative sequence lengths of k.
            The first element should be 0 and the last element should be k.shape[0].
            Returns:
            output: shape (batch_size, seqlen, dim) or (tot_seqlens, dim) if packing,
            where dim = num_heads * head_dim

  L 170: def apply_rope(xq: torch.Tensor, xk: torch.Tensor, freqs_cis: torch.Tensor)
         ‚Üí tuple[torch.Tensor, torch.Tensor]
         üìù Args: (The leading dimensions of all inputs should be the same)
            xq: query, tensor of shape (..., num_heads, head_dim)
            xk: key, tensor of shape (..., num_heads, head_dim)
            freqs_cis: tensor of shape (..., head_dim/2), dtype=torch.complex64. It contains the precomputed cis(freqs) for each position in the 2D grid.
            Returns:
            xq_out, xk_out: tensors of shape (..., num_heads, head_dim)

  L 536: def patch_merger(x: torch.Tensor,
        grid_hw: torch.Tensor,
        merge_kernel_size: list[int,
        int])
         ‚Üí List[torch.Tensor]


CLASS: Learnable2DInterpPosEmb
----------------------------------------
  L 195: __init__(self, height: int, width: int, dim: int, interpolation_mode: str)
         ‚Üí None

  L 205: reset_parameters(self)

  L 208: forward(self, x: torch.Tensor, grid_hws: torch.Tensor)
         ‚Üí torch.Tensor


CLASS: MLP2
----------------------------------------
  L 396: __init__(self, dims: list[int], activation, bias)

  L 407: forward(self, x: torch.Tensor)
         ‚Üí torch.Tensor


CLASS: MoonVisionPatchEmbed
----------------------------------------
  L 230: __init__(self, out_dim: int, in_dim: int, patch_size: Union[int, Tuple[int, int]], pos_emb_height: int, pos_emb_width: int)

  L 257: forward(self, x: torch.Tensor, grid_hw: torch.Tensor)
         ‚Üí torch.Tensor
         üìù Args:
            x (L, Channels): input tensor
            grid_hw (N, 2): grid height and width
            Returns:
            (L, Cout) tensor


CLASS: MoonVitEncoder
----------------------------------------
  L 497: __init__(self, hidden_dim: int, num_layers: int, block_cfg: dict)
         ‚Üí None

  L 513: forward(self, hidden_states: torch.Tensor, grid_hw: torch.Tensor)
         ‚Üí torch.Tensor


CLASS: MoonVitEncoderLayer
----------------------------------------
  L 415: __init__(self, num_heads: int, hidden_dim: int, mlp_dim: int)

  L 437: attention_qkvpacked(self, x: torch.Tensor, cu_seqlens: torch.Tensor, rope_freqs_cis: Optional[torch.Tensor])
         üìù Args:
            x (torch.Tensor): (batch_size, seqlen, hidden_dim)
            cu_seqlens (torch.Tensor):

  L 469: forward(self, hidden_states: torch.Tensor, cu_seqlens: torch.Tensor, rope_freqs_cis: Union[torch.Tensor, None])
         ‚Üí torch.Tensor
         üìù Args:
            hidden_states: non-packed (B, N, D) or packed (L, D). if non-packed, seqlens should be None, if packed, seqlens should be set
            Returns:
            output: same shape of input, non-packed (B, N, D) for non-packed input, (L, D) for packed input


CLASS: MoonVitPretrainedModel
----------------------------------------
  L 598: __init__(self, config: MoonViTConfig)

  L 623: forward(self, pixel_values: torch.Tensor, grid_hw: torch.Tensor)
         ‚Üí torch.Tensor
         üìù Args:
            pixel_values (torch.Tensor): The input pixel values.
            grid_hw (torch.Tensor): The grid height and width.
            Returns:
            torch.Tensor: The output tokens.


CLASS: MoonVitVLProjector
----------------------------------------
  L 567: __init__(self, in_channels: int, merge_kernel_size: list[int, int], hidden_act: str, ln_eps: float, out_dim: int)

  L 583: forward(self, hidden_states: torch.Tensor)
         ‚Üí torch.Tensor


CLASS: Rope2DPosEmb
----------------------------------------
  L 294: __init__(self, dim: int, max_height: int, max_width: int, theta_base, device)

  L 305: extra_repr(self)

  L 309: precomputed_freqs_cis(self)
         ‚Üí torch.Tensor
         üìù Calculate the cis(freqs) for each position in the 2D grid.
            Return: complex tensor of shape (max_height, max_width, dim//2) and value:
            height axis: ret[h, w, 2*i] = cis(h * theta_base**(-4*i/dim))
            weight axis: ret[h, w, 2*i+1] = cis(w * theta_base**(-4*i/dim))   with (i in [0, dim//4))
            note: `cis` is a mathematical notation defined by cis x = cos x + i sin x,

  L 337: get_freqs_cis_by_seqlens(self, grid_hws: torch.Tensor)
         ‚Üí torch.Tensor
         üìù Args:
            grid_hws (torch.Tensor): containing list of (height, width) or (t, height, width) tuples.
            Returns:
            freqs_cis: tensor of shape (sum(t * height * width), dim//2)

  L 361: get_freqs_cis_by_idx(self, pos_idx: torch.Tensor, pos_idx_mask: torch.Tensor)
         ‚Üí torch.Tensor
         üìù Args:
            pos_idx: tensor of shape (..., 2), It contains the (h, w) position indices of each 2D token.
            pos_idx_mask: a mask of shape (...), the leading dimensions should be the same as pos_idx.
            Rope will only be applied to the tokens with True mask. `freqs_cis` for the tokens with False mask with be ones.
            Return:
            freqs_cis: tensor of shape (..., dim//2)


============================================================
FILE: python/sglang/srt/models/llama.py
Functions: 25
============================================================


CLASS: LlamaAttention
----------------------------------------
  L 110: __init__(self, config: LlamaConfig, hidden_size: int, num_heads: int, num_kv_heads: int, layer_id: int, rope_theta: float, rope_scaling: Optional[Dict[str, Any]], rope_is_neox_style: bool, max_position_embeddings: int, quant_config: Optional[QuantizationConfig], prefix: str, bias: bool)
         ‚Üí None

  L 188: forward(self, positions: torch.Tensor, hidden_states: torch.Tensor, forward_batch: ForwardBatch)
         ‚Üí torch.Tensor


CLASS: LlamaDecoderLayer
----------------------------------------
  L 203: __init__(self, config: LlamaConfig, layer_id: int, quant_config: Optional[QuantizationConfig], prefix: str)
         ‚Üí None

  L 253: forward(self, positions: torch.Tensor, hidden_states: torch.Tensor, forward_batch: ForwardBatch, residual: Optional[torch.Tensor])
         ‚Üí Tuple[torch.Tensor, torch.Tensor]


CLASS: LlamaForCausalLM
----------------------------------------
  L 411: __init__(self, config: LlamaConfig, quant_config: Optional[QuantizationConfig], prefix: str)
         ‚Üí None

  L 456: forward(self, input_ids: torch.Tensor, positions: torch.Tensor, forward_batch: ForwardBatch, input_embeds: torch.Tensor, get_embedding: bool, pp_proxy_tensors: Optional[PPProxyTensors])
         ‚Üí LogitsProcessorOutput

  L 492: forward_split_prefill(self, input_ids: torch.Tensor, positions: torch.Tensor, forward_batch: ForwardBatch, split_interval: Tuple[int, int], input_embeds: torch.Tensor)
         ‚Üí Optional[LogitsProcessorOutput]

  L 533: start_layer(self)

  L 537: end_layer(self)

  L 540: get_input_embeddings(self)
         ‚Üí nn.Embedding

  L 543: get_module_name_from_weight_name(self, name)

  L 552: get_num_params(self)

  L 556: load_weights(self, weights: Iterable[Tuple[str, torch.Tensor]])

  L 624: get_weights_by_name(self, name: str, truncate_size: int, tp_size: int)
         ‚Üí Optional[torch.Tensor]
         üìù Get the weights of the parameter by its name. Similar to `get_parameter` in Hugging Face.
            Only used for unit test with an unoptimized performance.
            For optimized performance, please use torch.save and torch.load.

  L 697: get_embed_and_head(self)

  L 700: set_embed_and_head(self, embed, head)

  L 708: get_embed(self)

  L 711: set_embed(self, embed)

  L 723: load_kv_cache_scales(self, quantization_param_path: str)
         ‚Üí None

  L 726: set_eagle3_layers_to_capture(self, layer_ids: Optional[List[int]])


CLASS: LlamaMLP
----------------------------------------
  L  62: __init__(self, hidden_size: int, intermediate_size: int, hidden_act: str, quant_config: Optional[QuantizationConfig], prefix: str, reduce_results: bool)
         ‚Üí None

  L  94: forward(self, x, forward_batch, use_reduce_scatter: bool)


CLASS: LlamaModel
----------------------------------------
  L 279: __init__(self, config: LlamaConfig, quant_config: Optional[QuantizationConfig], prefix: str)
         ‚Üí None

  L 316: forward(self, input_ids: torch.Tensor, positions: torch.Tensor, forward_batch: ForwardBatch, input_embeds: torch.Tensor, pp_proxy_tensors: Optional[PPProxyTensors])
         ‚Üí Union[torch.Tensor, Tuple[torch.Tensor, List[torch.Tensor]], PPProxyTensors]

  L 367: load_kv_cache_scales(self, quantization_param_path: str)
         ‚Üí None


============================================================
FILE: python/sglang/srt/models/llama4.py
Functions: 11
============================================================


CLASS: Llama4Attention
----------------------------------------
  L 193: __init__(self, config: Llama4TextConfig, layer_id: int, hidden_size: int, num_heads: int, num_kv_heads: int, rope_theta: float, rope_scaling: Optional[Dict[str, Any]], max_position_embeddings: int, quant_config: Optional[QuantizationConfig], bias: bool, bias_o_proj: bool, prefix: str)
         ‚Üí None

  L 317: forward(self, positions: torch.Tensor, hidden_states: torch.Tensor, forward_batch: ForwardBatch)
         ‚Üí torch.Tensor


CLASS: Llama4DecoderLayer
----------------------------------------
  L 353: __init__(self, config: Llama4TextConfig, layer_id: int, quant_config: Optional[QuantizationConfig], prefix: str)

  L 426: forward(self, positions: torch.Tensor, hidden_states: torch.Tensor, forward_batch: ForwardBatch, residual: Optional[torch.Tensor])
         ‚Üí Tuple[torch.Tensor, torch.Tensor]


CLASS: Llama4ForCausalLM
----------------------------------------
  L 532: __init__(self, config: Llama4TextConfig, quant_config: Optional[QuantizationConfig], prefix: str)

  L 540: get_input_embeddings(self)


CLASS: Llama4MoE
----------------------------------------
  L  71: custom_routing_function(hidden_states: torch.Tensor, gating_output: torch.Tensor, topk: int, renormalize: bool)
         ‚Üí Tuple[torch.Tensor, torch.Tensor]

  L  86: __init__(self, config: Llama4TextConfig, layer_id: int, quant_config: Optional[QuantizationConfig], prefix: str)

  L 133: forward(self, hidden_states, forward_batch: ForwardBatch, use_reduce_scatter: bool)


CLASS: Llama4Model
----------------------------------------
  L 465: __init__(self, config: Llama4TextConfig, quant_config: Optional[QuantizationConfig], prefix: str)
         ‚Üí None

  L 493: forward(self, input_ids: torch.Tensor, positions: torch.Tensor, forward_batch: ForwardBatch, input_embeds: torch.Tensor, pp_proxy_tensors: Optional[PPProxyTensors])
         ‚Üí Union[torch.Tensor, Tuple[torch.Tensor, List[torch.Tensor]]]


============================================================
FILE: python/sglang/srt/models/llama_classification.py
Functions: 3
============================================================


CLASS: LlamaForClassification
----------------------------------------
  L  30: __init__(self, config: LlamaConfig, quant_config: Optional[QuantizationConfig], prefix: str)
         ‚Üí None

  L  49: forward(self, input_ids: torch.Tensor, positions: torch.Tensor, forward_batch: ForwardBatch, input_embeds: torch.Tensor, get_embedding: bool)
         ‚Üí EmbeddingPoolerOutput

  L  67: load_weights(self, weights: Iterable[Tuple[str, torch.Tensor]])


============================================================
FILE: python/sglang/srt/models/llama_eagle.py
Functions: 5
============================================================


CLASS: LlamaDecoderLayer
----------------------------------------
  L  40: __init__(self, config: LlamaConfig, layer_id: int, quant_config: Optional[QuantizationConfig], prefix: str)
         ‚Üí None


CLASS: LlamaForCausalLMEagle
----------------------------------------
  L 114: __init__(self, config: LlamaConfig, quant_config: Optional[QuantizationConfig], prefix: str)
         ‚Üí None

  L 142: load_weights(self, weights: Iterable[Tuple[str, torch.Tensor]])


CLASS: LlamaModel
----------------------------------------
  L  57: __init__(self, config: LlamaConfig, quant_config: Optional[QuantizationConfig], prefix: str)
         ‚Üí None

  L  84: forward(self, input_ids: torch.Tensor, positions: torch.Tensor, forward_batch: ForwardBatch, input_embeds: torch.Tensor, pp_proxy_tensors: Optional[PPProxyTensors])
         ‚Üí torch.Tensor


============================================================
FILE: python/sglang/srt/models/llama_eagle3.py
Functions: 7
============================================================


CLASS: LlamaDecoderLayer
----------------------------------------
  L  43: __init__(self, config: LlamaConfig, layer_id: int, quant_config: Optional[QuantizationConfig], prefix: str)
         ‚Üí None

  L  74: forward(self, positions: torch.Tensor, embeds: torch.Tensor, hidden_states: torch.Tensor, forward_batch: ForwardBatch, residual: Optional[torch.Tensor])
         ‚Üí Tuple[torch.Tensor, torch.Tensor]


CLASS: LlamaForCausalLMEagle3
----------------------------------------
  L 169: __init__(self, config: LlamaConfig, quant_config: Optional[QuantizationConfig], prefix: str)
         ‚Üí None

  L 206: load_weights(self, weights: Iterable[Tuple[str, torch.Tensor]])
         ‚Üí None

  L 249: get_hot_token_id(self)


CLASS: LlamaModel
----------------------------------------
  L 104: __init__(self, config: LlamaConfig, quant_config: Optional[QuantizationConfig], prefix: str)
         ‚Üí None

  L 134: forward(self, input_ids: torch.Tensor, positions: torch.Tensor, forward_batch: ForwardBatch, input_embeds: torch.Tensor, pp_proxy_tensors: Optional[PPProxyTensors])
         ‚Üí torch.Tensor


============================================================
FILE: python/sglang/srt/models/llama_embedding.py
Functions: 3
============================================================


CLASS: LlamaEmbeddingModel
----------------------------------------
  L  15: __init__(self, config: LlamaConfig, quant_config, prefix: str)
         ‚Üí None

  L  28: forward(self, input_ids: torch.Tensor, positions: torch.Tensor, forward_batch: ForwardBatch, input_embeds: torch.Tensor, get_embedding: bool)
         ‚Üí EmbeddingPoolerOutput

  L  42: load_weights(self, weights: Iterable[Tuple[str, torch.Tensor]])


============================================================
FILE: python/sglang/srt/models/llama_reward.py
Functions: 8
============================================================


CLASS: LlamaForSequenceClassification
----------------------------------------
  L  29: __init__(self, config: LlamaConfig, quant_config: Optional[QuantizationConfig], prefix: str)
         ‚Üí None

  L  48: forward(self, input_ids: torch.Tensor, positions: torch.Tensor, forward_batch: ForwardBatch, input_embeds: torch.Tensor, get_embedding: bool)
         ‚Üí EmbeddingPoolerOutput

  L  66: load_weights(self, weights: Iterable[Tuple[str, torch.Tensor]])


CLASS: LlamaForSequenceClassificationWithNormal_Weights
----------------------------------------
  L  85: __init__(self, config: LlamaConfig, quant_config: Optional[QuantizationConfig], prefix: str)
         ‚Üí None

  L  95: forward(self, input_ids: torch.Tensor, positions: torch.Tensor, forward_batch: ForwardBatch, input_embeds: torch.Tensor, get_embedding: bool)
         ‚Üí EmbeddingPoolerOutput

  L 119: load_weights(self, weights: Iterable[Tuple[str, torch.Tensor]])


CLASS: Weights
----------------------------------------
  L  72: __init__(self, hidden_size, num_label)

  L  82: forward(self, x)


============================================================
FILE: python/sglang/srt/models/llava.py
Functions: 14
============================================================


CLASS: LlavaBaseForCausalLM
----------------------------------------
  L  58: pad_input_ids(self, input_ids: List[int], image_inputs: MultimodalInputs)

  L 126: encode_images(self, pixel_values: Union[torch.Tensor, List[torch.Tensor]])
         ‚Üí torch.Tensor
         üìù encode images by vision tower and multimodal projector
            Args:
            pixel_values: torch.Tensor or List[torch.Tensor]: each tensor for an input image
            Returns:
            torch.Tensor: encoded image features from the input image; if multiple, flattened by seq_len axis

  L 151: forward(self, input_ids: torch.LongTensor, positions: torch.Tensor, forward_batch: ForwardBatch)
         ‚Üí torch.Tensor

  L 440: load_weights(self, weights: Iterable[Tuple[str, torch.Tensor]])

  L 498: num_patches_per_side(self)


CLASS: LlavaForConditionalGeneration
----------------------------------------
  L 615: dtype(self)

  L 618: pad_input_ids(self, input_ids: List[int], image_inputs: MultimodalInputs)

  L 670: __init__(self, config: LlavaConfig, quant_config: Optional[QuantizationConfig], prefix: str)
         ‚Üí None

  L 747: get_image_feature(self, items: List[MultimodalDataItem])
         ‚Üí torch.Tensor
         üìù Extract features from image inputs.
            Args:
            items: List of MultimodalDataItem objects containing image data
            Note that an item can be either "image" or "multi-images"
            Returns:
            torch.Tensor: features from image inputs, concatenated

  L 782: forward(self, input_ids: torch.Tensor, positions: torch.Tensor, forward_batch: ForwardBatch, get_embedding: bool)

  L 803: load_weights(self, weights: Iterable[Tuple[str, torch.Tensor]])
         üìù Load weights for LlavaForConditionalGeneration.
            Unlike the base class implementation, this one doesn't need to handle
            weight name remapping as the weights are already properly structured with
            'language_model' and 'vision_tower' prefixes in the safetensors files.


CLASS: LlavaLlamaForCausalLM
----------------------------------------
  L 503: __init__(self, config: LlavaConfig, quant_config: Optional[QuantizationConfig], prefix: str)
         ‚Üí None


CLASS: LlavaMistralForCausalLM
----------------------------------------
  L 566: __init__(self, config: LlavaConfig, quant_config: Optional[QuantizationConfig], prefix: str)
         ‚Üí None


CLASS: LlavaQwenForCausalLM
----------------------------------------
  L 529: __init__(self, config: LlavaConfig, quant_config: Optional[QuantizationConfig], prefix: str)
         ‚Üí None


============================================================
FILE: python/sglang/srt/models/llavavid.py
Functions: 6
============================================================


CLASS: LlavaVidForCausalLM
----------------------------------------
  L  33: __init__(self, config: LlavaConfig, quant_config: Optional[QuantizationConfig], prefix: str)
         ‚Üí None

  L  60: pad_input_ids(self, input_ids: List[int], image_inputs: MultimodalInputs)

  L  77: encode_images(self, pixel_values: torch.Tensor)
         ‚Üí torch.Tensor

  L 109: forward(self, input_ids: torch.LongTensor, positions: torch.Tensor, forward_batch: ForwardBatch)
         ‚Üí torch.Tensor

  L 221: load_weights(self, weights: Iterable[Tuple[str, torch.Tensor]])

  L 279: num_patches_per_side(self)


============================================================
FILE: python/sglang/srt/models/longcat_flash.py
Functions: 21
============================================================


CLASS: LongcatFlashDecoderLayer
----------------------------------------
  L 314: __init__(self, config: LongcatFlashConfig, layer_id: int, quant_config: Optional[QuantizationConfig], prefix: str, alt_stream: Optional[torch.cuda.Stream])
         ‚Üí None

  L 419: forward(self, positions: torch.Tensor, hidden_states: torch.Tensor, forward_batch: ForwardBatch, residual: Optional[torch.Tensor], zero_allocator: BumpAllocator)
         ‚Üí torch.Tensor

  L 457: forward_mlp(self, hidden_states, positions, residual, forward_batch, zero_allocator)


CLASS: LongcatFlashForCausalLM
----------------------------------------
  L 568: __init__(self, config: LongcatFlashConfig, quant_config: Optional[QuantizationConfig], prefix: str)
         ‚Üí None

  L 602: get_input_embeddings(self)
         ‚Üí nn.Embedding

  L 606: forward(self, input_ids: torch.Tensor, positions: torch.Tensor, forward_batch: ForwardBatch, input_embeds: torch.Tensor)
         ‚Üí torch.Tensor

  L 619: post_load_weights(self, weight_names)

  L 835: load_weights(self, weights: Iterable[Tuple[str, torch.Tensor]])

  L 996: get_embed_and_head(self)

  L 999: set_embed_and_head(self, embed, head)

  L1008: get_model_config_for_expert_location(cls, config)


CLASS: LongcatFlashMLP
----------------------------------------
  L 140: __init__(self, hidden_size: int, intermediate_size: int, hidden_act: str, quant_config: Optional[QuantizationConfig], reduce_results: bool, prefix: str)
         ‚Üí None

  L 172: forward(self, x)


CLASS: LongcatFlashMoE
----------------------------------------
  L 213: __init__(self, config: LongcatFlashConfig, layer_id: int, quant_config: Optional[QuantizationConfig], prefix: str)

  L 273: forward(self, hidden_states: torch.Tensor)
         ‚Üí torch.Tensor

  L 304: get_moe_weights(self)


CLASS: LongcatFlashModel
----------------------------------------
  L 495: __init__(self, config: LongcatFlashConfig, quant_config: Optional[QuantizationConfig], prefix: str)
         ‚Üí None

  L 525: get_input_embeddings(self)
         ‚Üí torch.Tensor

  L 528: forward(self, input_ids: torch.Tensor, positions: torch.Tensor, forward_batch: ForwardBatch, input_embeds: torch.Tensor)
         ‚Üí torch.Tensor


CLASS: LongcatFlashRouter
----------------------------------------
  L 183: __init__(self, config, zero_expert_num, rounter_params_dtype, prefix: str)

  L 206: forward(self, hidden_states)


============================================================
FILE: python/sglang/srt/models/longcat_flash_nextn.py
Functions: 9
============================================================


CLASS: LongcatFlashDenseDecoderLayer
----------------------------------------
  L 122: __init__(self, config: LongcatFlashConfig, layer_id: int, quant_config: Optional[QuantizationConfig], prefix: str, alt_stream: Optional[torch.cuda.Stream])
         ‚Üí None

  L 181: forward(self, positions: torch.Tensor, hidden_states: torch.Tensor, forward_batch: ForwardBatch, residual: Optional[torch.Tensor], zero_allocator: BumpAllocator)
         ‚Üí torch.Tensor


CLASS: LongcatFlashForCausalLMNextN
----------------------------------------
  L 294: __init__(self, config: LongcatFlashConfig, quant_config: Optional[QuantizationConfig])
         ‚Üí None

  L 315: forward(self, input_ids: torch.Tensor, positions: torch.Tensor, forward_batch: ForwardBatch)
         ‚Üí torch.Tensor

  L 326: post_load_weights(self)

  L 502: load_weights(self, weights: Iterable[Tuple[str, torch.Tensor]])


CLASS: LongcatFlashModelNextN
----------------------------------------
  L 212: __init__(self, config: LongcatFlashConfig, quant_config: Optional[QuantizationConfig], prefix: str)
         ‚Üí None

  L 245: get_input_embeddings(self)
         ‚Üí torch.Tensor

  L 248: forward(self, input_ids: torch.Tensor, positions: torch.Tensor, forward_batch: ForwardBatch, input_embeds: torch.Tensor)
         ‚Üí torch.Tensor


============================================================
FILE: python/sglang/srt/models/mimo.py
Functions: 8
============================================================


CLASS: MiMoForCausalLM
----------------------------------------
  L  66: __init__(self, config: MiMoConfig, quant_config: Optional[QuantizationConfig], prefix: str)
         ‚Üí None

  L  90: get_input_embeddings(self, input_ids: torch.Tensor)
         ‚Üí torch.Tensor

  L  94: forward(self, input_ids: torch.Tensor, positions: torch.Tensor, forward_batch: ForwardBatch, input_embeds: torch.Tensor, get_embedding: bool)
         ‚Üí torch.Tensor

  L 110: load_weights(self, weights: Iterable[Tuple[str, torch.Tensor]])

  L 156: get_embed_and_head(self)

  L 159: set_embed_and_head(self, embed, head)

  L 167: load_kv_cache_scales(self, quantization_param_path: str)
         ‚Üí None


CLASS: MiMoModel
----------------------------------------
  L  32: __init__(self, config: MiMoConfig, quant_config: Optional[QuantizationConfig], prefix: str)
         ‚Üí None


============================================================
FILE: python/sglang/srt/models/mimo_mtp.py
Functions: 8
============================================================


CLASS: MiMoMTP
----------------------------------------
  L  84: __init__(self, config: PretrainedConfig, quant_config: Optional[QuantizationConfig], prefix: str)
         ‚Üí None

  L 108: forward(self, input_ids: torch.Tensor, positions: torch.Tensor, forward_batch: ForwardBatch)
         ‚Üí torch.Tensor

  L 119: load_weights(self, weights: Iterable[Tuple[str, torch.Tensor]])

  L 173: map_model_name_to_mtp_param_name(self, name: str)
         ‚Üí str

  L 192: get_embed_and_head(self)

  L 195: set_embed_and_head(self, embed, head)


CLASS: MiMoMultiTokenPredictorLayer
----------------------------------------
  L  25: __init__(self, config: PretrainedConfig, prefix: str, quant_config: Optional[QuantizationConfig])
         ‚Üí None

  L  47: forward(self, input_ids: torch.Tensor, positions: torch.Tensor, forward_batch: ForwardBatch, input_embeds: torch.Tensor)
         ‚Üí torch.Tensor


============================================================
FILE: python/sglang/srt/models/minicpm.py
Functions: 11
============================================================


CLASS: MiniCPMAttention
----------------------------------------
  L  82: __init__(self, hidden_size: int, num_heads: int, num_kv_heads: int, layer_id: int, rope_theta: float, rope_scaling: Optional[Dict[str, Any]], max_position_embeddings: int, quant_config: Optional[QuantizationConfig], prefix: str)
         ‚Üí None

  L 151: forward(self, positions: torch.Tensor, hidden_states: torch.Tensor, forward_batch: ForwardBatch)
         ‚Üí torch.Tensor


CLASS: MiniCPMDecoderLayer
----------------------------------------
  L 169: __init__(self, config, layer_id: int, quant_config: Optional[QuantizationConfig], prefix: str)
         ‚Üí None

  L 205: forward(self, positions: torch.Tensor, hidden_states: torch.Tensor, forward_batch: ForwardBatch, residual: Optional[torch.Tensor])
         ‚Üí Tuple[torch.Tensor, torch.Tensor]


CLASS: MiniCPMForCausalLM
----------------------------------------
  L 291: __init__(self, config, quant_config: Optional[QuantizationConfig], prefix: str)
         ‚Üí None

  L 319: forward(self, input_ids: torch.Tensor, positions: torch.Tensor, forward_batch: ForwardBatch, input_embeds: torch.Tensor)
         ‚Üí torch.Tensor

  L 336: load_weights(self, weights: Iterable[Tuple[str, torch.Tensor]])


CLASS: MiniCPMMLP
----------------------------------------
  L  44: __init__(self, hidden_size: int, intermediate_size: int, hidden_act: str, quant_config: Optional[QuantizationConfig], prefix: str)
         ‚Üí None

  L  74: forward(self, x)


CLASS: MiniCPMModel
----------------------------------------
  L 236: __init__(self, config, quant_config: Optional[QuantizationConfig], prefix: str)
         ‚Üí None

  L 265: forward(self, input_ids: torch.Tensor, positions: torch.Tensor, forward_batch: ForwardBatch, input_embeds: torch.Tensor)
         ‚Üí torch.Tensor


============================================================
FILE: python/sglang/srt/models/minicpm3.py
Functions: 12
============================================================

MODULE FUNCTIONS:
----------------------------------------
  L  86: def input_to_float8(x, dtype)


CLASS: MiniCPM3AttentionMLA
----------------------------------------
  L  97: __init__(self, config: PretrainedConfig, hidden_size: int, num_heads: int, qk_nope_head_dim: int, qk_rope_head_dim: int, v_head_dim: int, q_lora_rank: int, kv_lora_rank: int, rope_theta: float, rope_scaling: Optional[Dict[str, Any]], max_position_embeddings: int, quant_config: Optional[QuantizationConfig], layer_id, prefix: str)
         ‚Üí None

  L 202: forward(self, positions: torch.Tensor, hidden_states: torch.Tensor, forward_batch: ForwardBatch)
         ‚Üí torch.Tensor


CLASS: MiniCPM3DecoderLayer
----------------------------------------
  L 271: __init__(self, config: PretrainedConfig, layer_id: int, quant_config: Optional[QuantizationConfig], prefix: str)
         ‚Üí None

  L 315: forward(self, positions: torch.Tensor, hidden_states: torch.Tensor, forward_batch: ForwardBatch, residual: Optional[torch.Tensor])
         ‚Üí Tuple[torch.Tensor, torch.Tensor]


CLASS: MiniCPM3ForCausalLM
----------------------------------------
  L 401: __init__(self, config: PretrainedConfig, quant_config: Optional[QuantizationConfig], prefix: str)
         ‚Üí None

  L 429: forward(self, input_ids: torch.Tensor, positions: torch.Tensor, forward_batch: ForwardBatch, input_embeds: torch.Tensor)
         ‚Üí torch.Tensor

  L 446: load_weights(self, weights: Iterable[Tuple[str, torch.Tensor]])


CLASS: MiniCPM3MLP
----------------------------------------
  L  49: __init__(self, hidden_size: int, intermediate_size: int, hidden_act: str, quant_config: Optional[QuantizationConfig], prefix: str)
         ‚Üí None

  L  79: forward(self, x)


CLASS: MiniCPM3Model
----------------------------------------
  L 346: __init__(self, config: PretrainedConfig, quant_config: Optional[QuantizationConfig], prefix: str)
         ‚Üí None

  L 375: forward(self, input_ids: torch.Tensor, positions: torch.Tensor, forward_batch: ForwardBatch, input_embeds: torch.Tensor)
         ‚Üí torch.Tensor


============================================================
FILE: python/sglang/srt/models/minicpmo.py
Functions: 40
============================================================

MODULE FUNCTIONS:
----------------------------------------
  L  71: def apply_spk_emb(input_ids: torch.Tensor,
        spk_emb: torch.Tensor,
        input_embeds: torch.Tensor,
        spk_emb_token_id: int,
        num_spk_embs: int)
         üìù Replace consecutive `num_spk_embs` speaker embedding placeholders in input_embeds with pre-prepared speaker embeddings. This is an in-place replacement, no new tensor is created, so no value is returned.
            Args:
            input_ids (torch.Tensor): Input ID tensor, shape [batch_size, seq_len_max]
            spk_emb (torch.Tensor): Speaker embedding tensor, shape [batch_size, num_spk_emb, hidden_dim]
            input_embeds (torch.Tensor): Input embedding tensor, shape [batch_size, seq_len_max, hidden_dim]
            spk_emb_token_id (int): ID of the speaker embedding token
            num_spk_embs (int): Number of speaker embeddings
            Returns:
            None

  L 126: def make_streaming_chunk_mask_generation(inputs_embeds: torch.Tensor,
        past_seen_tokens: int,
        streaming_tts_text_mask: torch.Tensor,
        streaming_reserved_length: int,
        streaming_audio_chunk_size: int,
        streaming_text_chunk_size: int,
        num_spk_emb: int,
        use_spk_emb: bool)
         ‚Üí torch.Tensor
         üìù In streaming audio generation, determine which `text` positions the TTS model can attend to when generating each chunk of `audio` tokens.
            This function creates a mask that allows the model to attend to a specific chunk of text
            tokens when generating each chunk of audio tokens, enabling streaming TTS generation.
            Args:
            inputs_embeds (torch.Tensor): Input embeddings tensor.
            past_seen_tokens (int): Number of tokens already seen by the model.
            streaming_tts_text_mask (torch.Tensor): Mask for the text tokens.
            streaming_reserved_length (int, optional): Number of reserved tokens for streaming. Defaults to 300.
            streaming_text_chunk_size (int, optional): Size of each text chunk. Defaults to 7.
            Returns:
            torch.Tensor: Causal mask for streaming TTS generation, shape is [batch_size=1, 1, seq_len=1, past_seen_tokens+1]
            Raises:
            AssertionError: If the batch size is not 1 (only supports batch size of 1 for inference).


CLASS: ConditionalChatTTS
----------------------------------------
  L 551: __init__(self, config: PretrainedConfig)

  L 610: merge_inputs_embeds(self, input_ids: torch.Tensor, lm_spk_emb_last_hidden_states: Optional[torch.Tensor])
         üìù Merge `input_ids` and `lm_spk_emb_last_hidden_states` to `inputs_embeds`.
            Args:
            input_ids (torch.Tensor): Input token IDs.
            lm_spk_emb_last_hidden_states (Optional[torch.Tensor], optional): Last hidden states of speaker embeddings from the language model. Defaults to None.
            Raises:
            NotImplementedError: If speaker embedding is not used and language model hidden states are not implemented.
            Returns:
            torch.Tensor: Prepared input embeddings for the model.

  L 656: prefill_text(self, input_ids: torch.Tensor, position_ids: torch.LongTensor, past_key_values: List[Tuple[torch.Tensor, torch.Tensor]], lm_spk_emb_last_hidden_states: Optional[torch.Tensor])
         üìù Prefill a chunk of new text tokens in streaming setting.
            Specifically speaking, update `past_key_values` using new text tokens, then the model will read the new text tokens.
            Args:
            input_ids (Tensor): Tensor of shape [batch_size, seq_len]
            position_ids (LongTensor): Tensor of shape [batch_size, seq_len]
            past_key_values (List[Tuple[Tensor]]): KV Cache of all layers, each layer is a tuple (Tensor, Tensor) denoting keys and values. Each tensor is of seq_len = `self.streaming_text_reserved_len`. `past_key_values` will be updated.
            lm_spk_emb_last_hidden_states (Tensor, optional): Tensor of shape [batch_size, num_spk_emb, llm_dim]. Defaults to None.
            Note that all `batch_size` should be `1`.

  L 728: prefill_audio_ids(self, input_ids: torch.Tensor, past_key_values: List[Tuple[torch.Tensor, torch.Tensor]], streaming_tts_text_mask, add_audio_bos: bool)
         üìù Prefill a chunk of audio ids to the model. Used in sliding-window long audio generation.
            Specifically, prefill many audio ids (typically from last window) to the model in the new window.
            Args:
            input_ids (torch.Tensor): (1, seq_len, num_vq) Audio input token ids.
            past_key_values (List[Tuple[torch.Tensor, torch.Tensor]]): Past key values for attention mechanism.

  L 788: generate(self, input_ids: torch.Tensor, past_key_values: List[Tuple[torch.Tensor, torch.Tensor]], temperature: torch.Tensor, eos_token: Union[int, torch.Tensor], streaming_tts_text_mask, force_no_stop, min_new_token, max_new_token, logits_warpers: List[LogitsWarper], logits_processors: List[CustomRepetitionPenaltyLogitsProcessorRepeat], show_tqdm)
         üìù Generate audio codes in streaming setting or non-streaming setting.
            Specifically speaking, generate audio codes when not all text tokens are prefilled.
            Always pass a valid `past_key_values` to the method. The method does not do `prefill` by itself. It relies on `prefill_text` method to provide valid `past_key_values`. Please refer to docstring of this class for more details.
            In this method, we borrowed a lot of codes from `https://github.com/2noise/ChatTTS/blob/main/ChatTTS/model/gpt.py`.
            Args:
            input_ids (torch.Tensor): Input token ids.
            past_key_values (List[Tuple[torch.Tensor, torch.Tensor]]): Past key values for attention mechanism.
            temperature (torch.Tensor): Temperature for sampling.
            eos_token (Union[int, torch.Tensor]): End of sequence token.
            streaming_tts_text_mask (Optional[torch.Tensor], optional): Mask for streaming TTS text. Defaults to None.
            max_new_token (int, optional): Maximum number of new tokens to generate. Defaults to 50.
            logits_warpers (List[LogitsWarper], optional): List of logits warpers. Defaults to [].
            logits_processors (List[CustomRepetitionPenaltyLogitsProcessorRepeat], optional): List of logits processors. Defaults to [].
            show_tqdm (bool, optional): Whether to show progress bar. Defaults to True.
            Returns:
            GenerationOutputs: Generation outputs.

  L1051: decode_to_mel_specs(self, result_list: List[torch.Tensor])
         üìù Decode discrete audio codes to mel spectrograms.
            Borrowed from `https://github.com/2noise/ChatTTS/blob/main/ChatTTS/core.py`
            Args:
            result_list (List[torch.Tensor]): Audio codes output from `generate`.
            Returns:
            torch.Tensor: Mel spectrograms.


CLASS: ConvNeXtBlock
----------------------------------------
  L 203: __init__(self, dim: int, intermediate_dim: int, kernel: int, dilation: int, layer_scale_init_value: float)

  L 232: forward(self, x: torch.Tensor, cond)
         ‚Üí torch.Tensor


CLASS: CustomRepetitionPenaltyLogitsProcessorRepeat
----------------------------------------
  L 426: __init__(self, penalty: float, max_input_ids: int, past_window: int)

  L 436: __call__(self, input_ids: torch.LongTensor, scores: torch.FloatTensor)
         ‚Üí torch.FloatTensor


CLASS: DVAE
----------------------------------------
  L 345: __init__(self)

  L 386: forward(self, inp: torch.Tensor, mode: Literal['encode', 'decode'])
         ‚Üí torch.Tensor


CLASS: DVAEDecoder
----------------------------------------
  L 257: __init__(self, idim: int, odim: int, n_layer, bn_dim, hidden, kernel, dilation, up)

  L 288: forward(self, x: torch.Tensor, conditioning)
         ‚Üí torch.Tensor


CLASS: GFSQ
----------------------------------------
  L 302: __init__(self, dim: int, levels: List[int], G: int, R: int, eps, transpose)

  L 331: __call__(self, x: torch.Tensor)
         ‚Üí torch.Tensor

  L 334: forward(self, x: torch.Tensor)
         ‚Üí torch.Tensor


CLASS: MiniCPMO
----------------------------------------
  L1417: __init__(self, config: PretrainedConfig, quant_config: Optional[QuantizationConfig])
         ‚Üí None

  L1459: init_tts_module(self)

  L1463: init_audio_module(self)

  L1467: init_llm(self, config: PretrainedConfig, quant_config: Optional[QuantizationConfig], prefix: str)
         ‚Üí nn.Module

  L1475: init_vision_module(self, config: PretrainedConfig, quant_config: Optional[QuantizationConfig], prefix: str)

  L1496: init_resampler(self, embed_dim: int, vision_dim: int, quant_config: Optional[QuantizationConfig], prefix: str)
         ‚Üí nn.Module

  L1516: pad_input_ids(self, input_ids: List[int], mm_input: MultimodalInputs)

  L1547: get_audio_embedding_streaming(self, items: List[MultimodalDataItem])
         üìù Extract audio embeddings in a streaming manner using cached key-value pairs.
            This method processes incoming audio features incrementally and stores/updates `past_key_values`
            for faster inference on subsequent audio frames. It only supports batch_size=1 and is intended
            for streaming scenarios.
            Returns:
            List[List[torch.Tensor]]: audio embeddings

  L1614: subsequent_chunk_mask(self, size: int, chunk_size: int, num_left_chunks: int, device: torch.device, num_lookhead: int)
         ‚Üí torch.Tensor
         üìù Create mask for subsequent steps (size, size) with chunk size,
            this is for streaming encoder
            Args:
            size (int): size of mask
            chunk_size (int): size of chunk
            num_left_chunks (int): number of left chunks
            <0: use full chunk
            >=0: use num_left_chunks
            device (torch.device): "cpu" or "cuda" or torch.Tensor.device
            Returns:
            torch.Tensor: mask

  L1647: get_audio_embedding(self, items: List[MultimodalDataItem], chunk_length)
         üìù Extract full audio embeddings with optional chunk-based attention.
            This method computes embeddings for all audio frames at once, either using full attention (when
            `chunk_length` is -1) or chunk-based attention (when `chunk_length` is a positive number). It does
            not use key-value caching and is suitable for non-streaming inference.
            Args:
            chunk_length (int, optional): Determines whether to use full attention (-1) or chunk-based
            attention (>0) during embedding computation.
            Returns:
            List[List[torch.Tensor]]: audio embeddings

  L1746: get_audio_feature(self, items: List[MultimodalDataItem])
         ‚Üí torch.Tensor

  L1754: get_omni_embedding(self, items: List[MultimodalDataItem], chunk_length, stream_input)
         üìù Args:
            chunk_length: whisper use full attention or chunk attention
            stream_input: use streaming audio embedding
            Returns:
            final embeddings with audio feature

  L1778: get_image_feature(self, items: List[MultimodalDataItem])
         ‚Üí torch.Tensor

  L1817: forward(self, input_ids: torch.Tensor, positions: torch.Tensor, forward_batch: ForwardBatch)
         ‚Üí torch.Tensor

  L1834: load_weights(self, weights: Iterable[Tuple[str, torch.Tensor]])


CLASS: MiniCPMWhisperEncoder
----------------------------------------
  L1186: __init__(self, config: WhisperConfig)

  L1195: forward(self, input_features, attention_mask, head_mask, output_attentions, output_hidden_states, return_dict, past_key_values: Optional[EncoderDecoderCache], use_cache: Optional[bool])
         üìù Forward pass of the Whisper encoder.
            Args:
            input_features (`torch.FloatTensor` of shape `(batch_size, feature_size, sequence_length)`):
            Float values of log-mel features extracted from the raw audio waveform. Typically generated
            by a feature extractor (e.g., `WhisperFeatureExtractor`) that processes `.flac` or `.wav`
            files into padded 2D mel spectrogram frames. These features are projected via convolution layers
            (`conv1` and `conv2`) and then transformed into embeddings for the encoder.
            attention_mask (`torch.Tensor`, *optional*):
            Not used by Whisper for masking `input_features`, but included for API compatibility with
            other models. If provided, it is simply ignored within the model. By default, Whisper
            effectively ignores silence in the input log-mel spectrogram.
            head_mask (`torch.Tensor` of shape `(encoder_layers, encoder_attention_heads)`, *optional*):
            Mask to nullify selected attention heads. The elements should be either 1 or 0, where:
            - 1 indicates the head is **not masked**,
            - 0 indicates the head is **masked** (i.e., the attention head is dropped).
            output_attentions (`bool`, *optional*):
            Whether or not to return the attention tensors of all encoder layers. If set to `True`, the
            returned tuple (or `BaseModelOutputWithPast`) will contain an additional element with
            attention weights for each encoder layer.
            output_hidden_states (`bool`, *optional*):
            Whether or not to return the hidden states of all layers. If set to `True`, the returned
            tuple (or `BaseModelOutputWithPast`) will contain a tuple of hidden states, including the
            initial embedding output as well as the outputs of each layer.
            return_dict (`bool`, *optional*):
            Whether or not to return a `BaseModelOutputWithPast` (a subclass of `ModelOutput`) instead
            of a plain tuple. If set to `True`, the output will be a `BaseModelOutputWithPast` object,
            otherwise it will be a tuple.
            past_key_values (`EncoderDecoderCache`, *optional*):
            When using caching for faster inference, this is an object that stores the key-value pairs
            for attention states. If provided, the model will append new states to the existing cache
            and return the updated cache. This speeds up sequential decoding or chunked inference.
            - If `past_key_values` is `None`, no past states are used or returned.
            - If `past_key_values` is not `None` and `use_cache=True`, the model will use the provided
            cache and return the updated cache (as `next_encoder_cache`).
            use_cache (`bool`, *optional*):
            Whether or not the model should use caching (`past_key_values`) to speed up processing
            during inference. When set to `True`, the model will:
            - Inspect and use `past_key_values` if provided.
            - Return updated `past_key_values` (under the name `next_encoder_cache` in
            `BaseModelOutputWithPast`).
            Returns:
            `BaseModelOutputWithPast` or `tuple` (depending on `return_dict`):
            If `return_dict=True`, a `BaseModelOutputWithPast` is returned, which contains:
            - **last_hidden_state** (`torch.FloatTensor` of shape `(batch_size, sequence_length, hidden_size)`):
            The output of the final encoder layer.
            - **hidden_states** (`tuple(torch.FloatTensor)`, *optional*, returned if `output_hidden_states=True`):
            Hidden states of the model at each layer (including the initial projection).
            - **attentions** (`tuple(torch.FloatTensor)`, *optional*, returned if `output_attentions=True`):
            Attention weights from each encoder layer.
            - **past_key_values** (an object of type `EncoderDecoderCache` or `None`, *optional*):
            Updated cache of key-value pairs if `use_cache=True`.
            If `return_dict=False`, a tuple is returned, where the format is:
            `(last_hidden_state, hidden_states, attentions)`, with `hidden_states` and `attentions`
            only present if their respective `output_*` arguments are set to `True`.


CLASS: MiniCPMWhisperEncoderLayer
----------------------------------------
  L1090: __init__(self, config: WhisperConfig, layer_idx: int)

  L1108: forward(self, hidden_states: torch.Tensor, attention_mask: torch.Tensor, layer_head_mask: torch.Tensor, output_attentions: bool, past_key_values: Optional[EncoderDecoderCache], use_cache: Optional[bool])
         ‚Üí torch.Tensor
         üìù Args:
            hidden_states (`torch.FloatTensor` of shape `(batch_size, seq_len, embed_dim)`):
            Hidden states to be fed into the encoder layer.
            attention_mask (`torch.FloatTensor` of shape `(batch_size, 1, tgt_len, src_len)`):
            Attention mask where padding elements are indicated by large negative values.
            layer_head_mask (`torch.FloatTensor` of shape `(encoder_attention_heads,)`):
            Mask to nullify selected heads of the attention modules.
            output_attentions (`bool`, *optional*):
            Whether or not to return the attention weights.
            past_key_values (`EncoderDecoderCache`, *optional*):
            Past key-value pairs used for incremental decoding.
            use_cache (`bool`, *optional*):
            Whether or not to return updated `past_key_values` for caching.
            Returns:
            A tuple of shape `(hidden_states, optional(attn_weights), optional(past_key_values))`.


CLASS: MultiModalProjector
----------------------------------------
  L1404: __init__(self, in_dim, out_dim)

  L1410: forward(self, audio_features)


============================================================
FILE: python/sglang/srt/models/minicpmv.py
Functions: 27
============================================================

MODULE FUNCTIONS:
----------------------------------------
  L  65: def get_1d_sincos_pos_embed_from_grid(embed_dim: int,
        pos: np.ndarray,
        version: Tuple[int,
        int])
         ‚Üí torch.Tensor
         üìù embed_dim: output dimension for each position
            pos: a list of positions to be encoded: size (M,) / (H, W)
            out: (M, D) / (H, W, D)

  L  92: def get_2d_sincos_pos_embed_from_grid(embed_dim: int,
        grid: np.ndarray,
        version: Tuple[int,
        int])
         ‚Üí torch.Tensor

  L 112: def get_2d_sincos_pos_embed(embed_dim: int,
        grid_size: Union[int,
        Tuple[int,
        int]],
        cls_token: bool,
        version: Tuple[int,
        int])
         ‚Üí torch.Tensor
         üìù grid_size: int of the grid height and width
            return:
            pos_embed: [grid_size*grid_size, embed_dim] or
            [1+grid_size*grid_size, embed_dim] (w/ or w/o cls_token)

  L 358: def get_version_by_config(config: PretrainedConfig)
         ‚Üí Tuple[int, ...]


CLASS: BaseResampler
----------------------------------------
  L 201: __init__(self, num_queries: int, embed_dim: int, num_heads: int, kv_dim: Optional[int], norm_layer: Callable[[int], nn.LayerNorm], do_post_projection: bool, quant_config: Optional[QuantizationConfig], prefix: str)
         ‚Üí None


CLASS: MiniCPMBaseModel
----------------------------------------
  L 378: __init__(self)

  L 527: get_embedding(self, input_ids: torch.Tensor, image_inputs: Optional[MiniCPMVImageInputs])
         ‚Üí Tuple[torch.Tensor, torch.Tensor]

  L 563: get_input_embeddings(self)
         ‚Üí nn.Embedding

  L 566: forward(self, input_ids: torch.Tensor, positions: torch.Tensor, forward_batch: ForwardBatch)
         ‚Üí torch.Tensor

  L 582: init_llm(self, config: Qwen2Config, quant_config: Optional[QuantizationConfig], prefix: str)
         ‚Üí nn.Module

  L 590: init_vision_module(self, config: PretrainedConfig, quant_config: Optional[QuantizationConfig], prefix: str)
         ‚Üí nn.Module

  L 598: init_resampler(self, embed_dim: int, vision_dim: int, quant_config: Optional[QuantizationConfig], prefix: str)
         ‚Üí nn.Module

  L 607: get_vision_embedding(self, pixel_values: List[torch.Tensor], patch_attn_mask: Optional[torch.Tensor], tgt_sizes: Optional[torch.Tensor])
         ‚Üí torch.Tensor

  L 615: get_image_feature(self, items: List[MultimodalDataItem])
         ‚Üí torch.Tensor


CLASS: MiniCPMV
----------------------------------------
  L 796: __init__(self, config: PretrainedConfig, quant_config: Optional[QuantizationConfig], prefix: str)
         ‚Üí None

  L 824: __getattr__(self, name)

  L 829: __call__(self)

  L 832: load_weights(self, weights: Iterable[Tuple[str, torch.Tensor]])


CLASS: MiniCPMV2_6
----------------------------------------
  L 659: __init__(self, config: PretrainedConfig, quant_config: Optional[QuantizationConfig], prefix: str)

  L 668: init_llm(self, config: Qwen2Config, quant_config: Optional[QuantizationConfig], prefix: str)
         ‚Üí nn.Module

  L 676: init_vision_module(self, config: PretrainedConfig, quant_config: Optional[QuantizationConfig], prefix: str)
         ‚Üí nn.Module

  L 692: init_resampler(self, embed_dim: int, vision_dim: int, quant_config: Optional[QuantizationConfig], prefix: str)
         ‚Üí nn.Module

  L 712: get_vision_embedding(self, pixel_values: List[torch.Tensor], patch_attn_mask: Optional[torch.Tensor], tgt_sizes: Optional[torch.Tensor])
         ‚Üí torch.Tensor

  L 725: get_image_feature(self, items: List[MultimodalDataItem])
         ‚Üí torch.Tensor

  L 764: pad_input_ids(self, input_ids: List[int], image_inputs: MultimodalInputs)


CLASS: Resampler2_5
----------------------------------------
  L 260: __init__(self, num_queries: int, embed_dim: int, num_heads: int, kv_dim: Optional[int], norm_layer: Callable[[int], nn.LayerNorm], max_size: Tuple[int, int], quant_config: Optional[QuantizationConfig], prefix: str)
         ‚Üí None

  L 309: forward(self, x: torch.Tensor, tgt_sizes: torch.Tensor)
         ‚Üí torch.Tensor


============================================================
FILE: python/sglang/srt/models/mistral.py
Functions: 5
============================================================


CLASS: Mistral3ForConditionalGeneration
----------------------------------------
  L  32: __init__(self)

  L  46: get_image_feature(self, items: List[MultimodalDataItem])
         ‚Üí torch.Tensor
         üìù Extract features from image inputs.
            Args:
            items: List of MultimodalDataItem objects containing image data
            Note that an item can be either "image" or "multi-images"
            Returns:
            torch.Tensor: features from image inputs, concatenated

  L  83: __getattr__(self, name)

  L  86: __hasattr__(self, name)

  L  89: __call__(self)


============================================================
FILE: python/sglang/srt/models/mixtral.py
Functions: 13
============================================================


CLASS: MixtralAttention
----------------------------------------
  L 123: __init__(self, hidden_size: int, num_heads: int, num_kv_heads: int, layer_id: int, max_position: int, rope_theta: float, quant_config: Optional[QuantizationConfig], prefix: str)
         ‚Üí None

  L 189: forward(self, positions: torch.Tensor, hidden_states: torch.Tensor, forward_batch: ForwardBatch)
         ‚Üí torch.Tensor


CLASS: MixtralDecoderLayer
----------------------------------------
  L 204: __init__(self, config: MixtralConfig, layer_id: int, quant_config: Optional[QuantizationConfig], prefix: str)
         ‚Üí None

  L 239: forward(self, positions: torch.Tensor, hidden_states: torch.Tensor, forward_batch: ForwardBatch, residual: Optional[torch.Tensor])
         ‚Üí torch.Tensor


CLASS: MixtralForCausalLM
----------------------------------------
  L 341: __init__(self, config: MixtralConfig, quant_config: Optional[QuantizationConfig], prefix: str)
         ‚Üí None

  L 359: forward(self, input_ids: torch.Tensor, positions: torch.Tensor, forward_batch: ForwardBatch, input_embeds: torch.Tensor, pp_proxy_tensors: Optional[PPProxyTensors])
         ‚Üí torch.Tensor

  L 383: start_layer(self)

  L 387: end_layer(self)

  L 390: load_weights(self, weights: Iterable[Tuple[str, torch.Tensor]])


CLASS: MixtralMoE
----------------------------------------
  L  66: __init__(self, num_experts: int, top_k: int, hidden_size: int, intermediate_size: int, layer_id: int, params_dtype: Optional[torch.dtype], quant_config: Optional[QuantizationConfig], tp_size: Optional[int], prefix: str)

  L 109: forward(self, hidden_states: torch.Tensor)
         ‚Üí torch.Tensor


CLASS: MixtralModel
----------------------------------------
  L 265: __init__(self, config: MixtralConfig, quant_config: Optional[QuantizationConfig], prefix: str)
         ‚Üí None

  L 301: forward(self, input_ids: torch.Tensor, positions: torch.Tensor, forward_batch: ForwardBatch, input_embeds: torch.Tensor, pp_proxy_tensors: Optional[PPProxyTensors])
         ‚Üí Union[torch.Tensor, PPProxyTensors]


============================================================
FILE: python/sglang/srt/models/mixtral_quant.py
Functions: 13
============================================================


CLASS: MixtralAttention
----------------------------------------
  L 173: __init__(self, hidden_size: int, num_heads: int, num_kv_heads: int, layer_id: int, max_position: int, rope_theta: float, quant_config: Optional[QuantizationConfig], prefix: str)
         ‚Üí None

  L 239: forward(self, positions: torch.Tensor, hidden_states: torch.Tensor, forward_batch: ForwardBatch)
         ‚Üí torch.Tensor


CLASS: MixtralDecoderLayer
----------------------------------------
  L 254: __init__(self, config: MixtralConfig, layer_id: int, quant_config: Optional[QuantizationConfig], prefix: str)
         ‚Üí None

  L 285: forward(self, positions: torch.Tensor, hidden_states: torch.Tensor, forward_batch: ForwardBatch, residual: Optional[torch.Tensor])
         ‚Üí torch.Tensor


CLASS: MixtralMLP
----------------------------------------
  L  52: __init__(self, num_experts: int, hidden_size: int, intermediate_size: int, quant_config: Optional[QuantizationConfig], prefix: str)
         ‚Üí None

  L  90: forward(self, hidden_states: torch.Tensor)
         ‚Üí torch.Tensor


CLASS: MixtralMoE
----------------------------------------
  L 100: __init__(self, config: MixtralConfig, quant_config: Optional[QuantizationConfig], prefix: str)

  L 148: forward(self, hidden_states: torch.Tensor)
         ‚Üí torch.Tensor


CLASS: MixtralModel
----------------------------------------
  L 311: __init__(self, config: MixtralConfig, quant_config: Optional[QuantizationConfig], prefix: str)
         ‚Üí None

  L 339: forward(self, input_ids: torch.Tensor, positions: torch.Tensor, forward_batch: ForwardBatch, input_embeds: torch.Tensor)
         ‚Üí torch.Tensor


CLASS: QuantMixtralForCausalLM
----------------------------------------
  L 361: __init__(self, config: MixtralConfig, quant_config: Optional[QuantizationConfig], prefix: str)
         ‚Üí None

  L 379: forward(self, input_ids: torch.Tensor, positions: torch.Tensor, forward_batch: ForwardBatch, input_embeds: torch.Tensor)
         ‚Üí torch.Tensor

  L 391: load_weights(self, weights: Iterable[Tuple[str, torch.Tensor]])


============================================================
FILE: python/sglang/srt/models/mllama.py
Functions: 32
============================================================


CLASS: ColumnParallelConv2dPatch
----------------------------------------
  L  56: __init__(self, in_channels: int, out_channels: int, kernel_size: Union[int, Tuple[int, int]], stride: Union[int, Tuple[int, int]], bias: bool)
         ‚Üí None

  L  74: forward(self, x: torch.Tensor)
         ‚Üí torch.Tensor


CLASS: MllamaCrossAttentionDecoderLayer
----------------------------------------
  L 591: __init__(self, config: config_mllama.MllamaTextConfig, layer_id: int, quant_config: Optional[QuantizationConfig], prefix: str)
         ‚Üí None

  L 622: forward(self, hidden_states: torch.Tensor, cross_attention_states: torch.Tensor, cross_attention_mask: torch.Tensor, full_text_row_masked_out_mask: torch.Tensor, forward_batch: ForwardBatch)
         ‚Üí torch.Tensor


CLASS: MllamaForCausalLM
----------------------------------------
  L 740: __init__(self, config: config_mllama.MllamaTextConfig, quant_config: Optional[QuantizationConfig], prefix: str)

  L 760: forward(self, input_ids: torch.LongTensor, positions: Optional[torch.LongTensor], cross_attention_states: Optional[torch.LongTensor], cross_attention_mask: Optional[torch.LongTensor], full_text_row_masked_out_mask: Optional[Tuple[torch.Tensor, torch.Tensor]], forward_batch: ForwardBatch, skip_cross_attention: bool)
         ‚Üí torch.Tensor


CLASS: MllamaForConditionalGeneration
----------------------------------------
  L 804: __init__(self, config: config_mllama.MllamaConfig, quant_config: Optional[QuantizationConfig], prefix: str)

  L 840: pad_input_ids(self, input_ids: List[int], mm_inputs: MultimodalInputs)

  L 913: flat_encoder_result(self, cross_attention_states: torch.Tensor, encoder_lens_need: List[int])

  L 939: get_full_text_row_masked_out_mask(self, forward_batch: ForwardBatch)

  L 963: forward(self, input_ids: torch.Tensor, positions: torch.Tensor, forward_batch: ForwardBatch)
         ‚Üí Union[Tuple, CausalLMOutputWithPast]

  L1027: load_weights(self, weights: Iterable[Tuple[str, torch.Tensor]])


CLASS: MllamaPrecomputedAspectRatioEmbedding
----------------------------------------
  L  83: __init__(self, config: config_mllama.MllamaVisionConfig, is_gated: bool)

  L  96: forward(self, hidden_state: torch.Tensor, aspect_ratio_ids: torch.Tensor)
         ‚Üí torch.Tensor


CLASS: MllamaPrecomputedPositionEmbedding
----------------------------------------
  L 110: __init__(self, config: config_mllama.MllamaVisionConfig)

  L 130: forward(self, hidden_state: torch.Tensor, aspect_ratio_ids: torch.Tensor)
         ‚Üí torch.Tensor


CLASS: MllamaTextCrossAttention
----------------------------------------
  L 499: __init__(self, config: Optional[config_mllama.MllamaTextConfig], layer_id: Optional[int], quant_config: Optional[QuantizationConfig], prefix: str)

  L 557: forward(self, hidden_states: torch.Tensor, attention_mask: Optional[torch.Tensor], cross_attention_states: Optional[torch.Tensor], forward_batch: ForwardBatch)
         ‚Üí torch.Tensor


CLASS: MllamaTextModel
----------------------------------------
  L 654: __init__(self, config: config_mllama.MllamaTextConfig, quant_config: Optional[QuantizationConfig], prefix: str)

  L 695: forward(self, input_ids: torch.LongTensor, positions: Optional[torch.LongTensor], cross_attention_states: Optional[torch.LongTensor], cross_attention_mask: Optional[torch.LongTensor], full_text_row_masked_out_mask: Optional[Tuple[torch.Tensor, torch.Tensor]], forward_batch: ForwardBatch, skip_cross_attention: bool)
         ‚Üí torch.Tensor


CLASS: MllamaTextRMSNorm
----------------------------------------
  L 482: __init__(self, hidden_size, eps)

  L 487: forward(self, hidden_states)

  L 494: extra_repr(self)


CLASS: MllamaVisionEncoder
----------------------------------------
  L 248: __init__(self, config: config_mllama.MllamaVisionConfig, quant_config: Optional[QuantizationConfig], num_layers, is_gated, output_hidden_states, prefix: str)

  L 272: forward(self, hidden_states: torch.Tensor, attention_mask: Optional[torch.Tensor])
         ‚Üí Union[Tuple, BaseModelOutput]


CLASS: MllamaVisionEncoderLayer
----------------------------------------
  L 185: __init__(self, config: config_mllama.MllamaVisionConfig, quant_config: Optional[QuantizationConfig], is_gated: bool, prefix: str)

  L 225: forward(self, hidden_state: torch.Tensor, attention_mask: Optional[torch.Tensor])


CLASS: MllamaVisionMLP
----------------------------------------
  L 152: __init__(self, config, quant_config: Optional[QuantizationConfig], prefix: str)

  L 176: forward(self, hidden_states: torch.Tensor)
         ‚Üí torch.Tensor


CLASS: MllamaVisionModel
----------------------------------------
  L 294: __init__(self, config: config_mllama.MllamaVisionConfig, quant_config: Optional[QuantizationConfig], prefix: str)

  L 350: apply_class_embedding(self, hidden_state: torch.Tensor)
         ‚Üí torch.Tensor

  L 356: forward(self, pixel_values: torch.Tensor, aspect_ratio_ids: torch.Tensor, aspect_ratio_mask: torch.Tensor)
         ‚Üí torch.Tensor


============================================================
FILE: python/sglang/srt/models/mllama4.py
Functions: 27
============================================================

MODULE FUNCTIONS:
----------------------------------------
  L  91: def pixel_shuffle(input_tensor, shuffle_ratio)

  L 143: def apply_position_embedding(q, k, freqs_ci, shape)


CLASS: Llama4ForConditionalGeneration
----------------------------------------
  L 425: __init__(self, config: Llama4Config, quant_config: Optional[QuantizationConfig], prefix: str)

  L 524: pad_input_ids(self, input_ids: List[int], mm_inputs: MultimodalInputs)

  L 527: get_image_feature(self, items: List[MultimodalDataItem])
         ‚Üí torch.Tensor

  L 547: forward(self, input_ids: torch.Tensor, positions: torch.Tensor, forward_batch: ForwardBatch)
         ‚Üí torch.Tensor

  L 570: permute_qk_weight_for_rotary(self, name: str, loaded_weight: torch.Tensor)
         ‚Üí Tuple[str, torch.Tensor]

  L 604: load_weights(self, weights: Iterable[Tuple[str, torch.Tensor]])
         ‚Üí Set[str]

  L 935: set_eagle3_layers_to_capture(self, layer_ids: Optional[List[int]])

  L 939: get_embed_and_head(self)

  L 951: set_embed_and_head(self, embed, head)

  L 958: get_embed(self)

  L 961: set_embed(self, embed)


CLASS: Llama4UnfoldConvolution
----------------------------------------
  L 266: __init__(self, config: Llama4VisionConfig, quant_config: Optional[QuantizationConfig], prefix: str, use_data_parallel: bool)

  L 292: forward(self, hidden_states: torch.Tensor)
         ‚Üí torch.Tensor


CLASS: Llama4VisionEncoder
----------------------------------------
  L 220: __init__(self, config: Llama4VisionConfig, quant_config: Optional[QuantizationConfig], prefix: str, use_data_parallel: bool)

  L 241: forward(self, hidden_states: torch.Tensor, freqs_ci: torch.Tensor)
         ‚Üí torch.Tensor
         üìù Args:
            hidden_states (`torch.FloatTensor` of shape
            `(batch_size, sequence_length, hidden_size)`):
            Optionally, instead of passing `input_ids` you can choose to
            directly pass an embedded representation. This is useful if you
            want more control over how to convert `input_ids` indices into
            associated vectors than the model's internal embedding
            lookup matrix.


CLASS: Llama4VisionEncoderLayer
----------------------------------------
  L 156: __init__(self, config: Llama4VisionConfig, quant_config: Optional[QuantizationConfig], prefix: str, use_data_parallel: bool)

  L 197: forward(self, hidden_state: torch.Tensor, freqs_ci: torch.Tensor)


CLASS: Llama4VisionMLP
----------------------------------------
  L  51: __init__(self, input_size: int, intermediate_size: int, output_size: int, bias: bool, output_activation: bool, quant_config: Optional[QuantizationConfig], prefix: str, use_data_parallel: bool)

  L  82: forward(self, hidden_states: torch.Tensor)
         ‚Üí torch.Tensor


CLASS: Llama4VisionModel
----------------------------------------
  L 332: __init__(self, config: Llama4VisionConfig, quant_config: Optional[QuantizationConfig], prefix: str)

  L 377: forward(self, pixel_values: torch.Tensor)
         ‚Üí torch.Tensor


CLASS: Llama4VisionPixelShuffleMLP
----------------------------------------
  L 118: __init__(self, config, quant_config: Optional[QuantizationConfig], prefix: str, use_data_parallel: bool)

  L 138: forward(self, encoded_patches: torch.Tensor)
         ‚Üí torch.Tensor


CLASS: Llama4VisionRotaryEmbedding
----------------------------------------
  L 300: __init__(self, config)

  L 326: forward(self, hidden_states)


============================================================
FILE: python/sglang/srt/models/nemotron_nas.py
Functions: 9
============================================================


CLASS: DeciLMDecoderLayer
----------------------------------------
  L  59: __init__(self, config: LlamaConfig, layer_idx: int, quant_config: Optional[QuantizationConfig], prefix: str)
         ‚Üí None

  L 127: forward(self, positions: torch.Tensor, hidden_states: torch.Tensor, forward_batch: ForwardBatch, residual: Optional[torch.Tensor])
         ‚Üí Tuple[torch.Tensor, torch.Tensor]


CLASS: DeciLMForCausalLM
----------------------------------------
  L 295: __init__(self)

  L 341: get_input_embeddings(self, input_ids: torch.Tensor)
         ‚Üí torch.Tensor

  L 345: forward(self, input_ids: torch.Tensor, positions: torch.Tensor, forward_batch: ForwardBatch, inputs_embeds: Optional[torch.Tensor], get_embedding: bool, pp_proxy_tensors: Optional[PPProxyTensors])
         ‚Üí LogitsProcessorOutput

  L 371: load_weights(self, weights: Iterable[Tuple[str, torch.Tensor]])
         ‚Üí None


CLASS: DeciModel
----------------------------------------
  L 160: __init__(self)

  L 210: get_input_embeddings(self, input_ids: torch.Tensor)
         ‚Üí torch.Tensor

  L 213: forward(self, input_ids: Optional[torch.Tensor], positions: torch.Tensor, forward_batch: ForwardBatch, inputs_embeds: Optional[torch.Tensor], pp_proxy_tensors: Optional[PPProxyTensors])
         ‚Üí Union[torch.Tensor, PPProxyTensors]


============================================================
FILE: python/sglang/srt/models/olmo.py
Functions: 11
============================================================


CLASS: OlmoAttention
----------------------------------------
  L  51: __init__(self, config: OlmoConfig, layer_id: int, quant_config: Optional[QuantizationConfig], prefix: str)

  L 108: forward(self, positions: torch.Tensor, hidden_states: torch.Tensor, forward_batch: ForwardBatch)
         ‚Üí torch.Tensor


CLASS: OlmoDecoderLayer
----------------------------------------
  L 180: __init__(self, config: OlmoConfig, layer_id: int, quant_config: Optional[QuantizationConfig], prefix: str)

  L 211: forward(self, positions: torch.Tensor, hidden_states: torch.Tensor, forward_batch: ForwardBatch)
         ‚Üí Tuple[torch.Tensor, Optional[Tuple[torch.Tensor, torch.Tensor]]]


CLASS: OlmoForCausalLM
----------------------------------------
  L 299: __init__(self, config: OlmoConfig, quant_config: Optional[QuantizationConfig], prefix: str)

  L 321: forward(self, input_ids: torch.Tensor, positions: torch.Tensor, forward_batch: ForwardBatch, input_embeds: torch.Tensor)
         ‚Üí torch.Tensor

  L 338: load_weights(self, weights: Iterable[Tuple[str, torch.Tensor]])


CLASS: OlmoMLP
----------------------------------------
  L 131: __init__(self, config: OlmoConfig, quant_config: Optional[QuantizationConfig], prefix: str)

  L 163: forward(self, x: torch.Tensor)
         ‚Üí torch.Tensor


CLASS: OlmoModel
----------------------------------------
  L 233: __init__(self, config: OlmoConfig, quant_config: Optional[QuantizationConfig], prefix: str)

  L 261: forward(self, input_ids: torch.Tensor, positions: torch.Tensor, forward_batch: ForwardBatch, input_embeds: torch.Tensor)
         ‚Üí torch.Tensor
         üìù :param input_ids: A tensor of shape `(batch_size, seq_len)`.


============================================================
FILE: python/sglang/srt/models/olmo2.py
Functions: 11
============================================================


CLASS: Olmo2Attention
----------------------------------------
  L  58: __init__(self, config: PretrainedConfig, layer_id: int, quant_config: Optional[QuantizationConfig], prefix: str)

  L 148: forward(self, positions: torch.Tensor, hidden_states: torch.Tensor, forward_batch: ForwardBatch)
         ‚Üí torch.Tensor


CLASS: Olmo2DecoderLayer
----------------------------------------
  L 219: __init__(self, config: PretrainedConfig, layer_id: int, quant_config: Optional[QuantizationConfig], prefix: str)

  L 244: forward(self, positions: torch.Tensor, hidden_states: torch.Tensor, forward_batch: ForwardBatch)
         ‚Üí torch.Tensor


CLASS: Olmo2ForCausalLM
----------------------------------------
  L 330: __init__(self, config: PretrainedConfig, quant_config: Optional[QuantizationConfig], prefix: str)

  L 354: forward(self, input_ids: torch.Tensor, positions: torch.Tensor, forward_batch: ForwardBatch, input_embeds: torch.Tensor)
         ‚Üí torch.Tensor

  L 371: load_weights(self, weights: Iterable[Tuple[str, torch.Tensor]])


CLASS: Olmo2MLP
----------------------------------------
  L 170: __init__(self, config: PretrainedConfig, quant_config: Optional[QuantizationConfig], prefix: str)

  L 202: forward(self, x: torch.Tensor)
         ‚Üí torch.Tensor


CLASS: Olmo2Model
----------------------------------------
  L 266: __init__(self, config: PretrainedConfig, quant_config: Optional[QuantizationConfig], prefix: str)

  L 292: forward(self, input_ids: torch.Tensor, positions: torch.Tensor, forward_batch: ForwardBatch, input_embeds: torch.Tensor)
         ‚Üí torch.Tensor
         üìù :param input_ids: A tensor of shape `(batch_size, seq_len)`.


============================================================
FILE: python/sglang/srt/models/olmoe.py
Functions: 11
============================================================


CLASS: OlmoeAttention
----------------------------------------
  L 109: __init__(self, layer_id: int, hidden_size: int, num_heads: int, num_kv_heads: int, rope_theta: float, rope_scaling: Optional[Dict[str, Any]], max_position_embeddings: int, quant_config: Optional[QuantizationConfig], prefix: str)
         ‚Üí None

  L 181: forward(self, positions: torch.Tensor, hidden_states: torch.Tensor, forward_batch: ForwardBatch)
         ‚Üí torch.Tensor


CLASS: OlmoeDecoderLayer
----------------------------------------
  L 198: __init__(self, config: PretrainedConfig, layer_id: int, quant_config: Optional[QuantizationConfig], prefix: str)
         ‚Üí None

  L 235: forward(self, positions: torch.Tensor, hidden_states: torch.Tensor, forward_batch: ForwardBatch, residual: Optional[torch.Tensor])
         ‚Üí torch.Tensor


CLASS: OlmoeForCausalLM
----------------------------------------
  L 315: __init__(self, config: PretrainedConfig, quant_config: Optional[QuantizationConfig], prefix: str)
         ‚Üí None

  L 335: forward(self, input_ids: torch.Tensor, positions: torch.Tensor, forward_batch: ForwardBatch, input_embeds: torch.Tensor)
         ‚Üí torch.Tensor

  L 347: load_weights(self, weights: Iterable[Tuple[str, torch.Tensor]])


CLASS: OlmoeMoE
----------------------------------------
  L  57: __init__(self, num_experts: int, top_k: int, hidden_size: int, intermediate_size: int, params_dtype: Optional[torch.dtype], quant_config: Optional[QuantizationConfig], tp_size: Optional[int], layer_id: int, prefix: str)

  L  96: forward(self, hidden_states: torch.Tensor)
         ‚Üí torch.Tensor


CLASS: OlmoeModel
----------------------------------------
  L 263: __init__(self, config: PretrainedConfig, quant_config: Optional[QuantizationConfig], prefix: str)
         ‚Üí None

  L 290: forward(self, input_ids: torch.Tensor, positions: torch.Tensor, forward_batch: ForwardBatch, input_embeds: torch.Tensor)
         ‚Üí torch.Tensor


============================================================
FILE: python/sglang/srt/models/persimmon.py
Functions: 13
============================================================


CLASS: PersimmonAttention
----------------------------------------
  L  52: __init__(self, config: PersimmonConfig, quant_config: Optional[QuantizationConfig], prefix: str, layer_id: int)

  L 120: forward(self, position_ids: torch.Tensor, forward_batch: ForwardBatch, hidden_states: torch.Tensor)
         ‚Üí torch.Tensor


CLASS: PersimmonDecoderLayer
----------------------------------------
  L 147: __init__(self, config: PersimmonConfig, quant_config: Optional[QuantizationConfig], prefix: str, idx: int)

  L 170: forward(self, position_ids: torch.Tensor, forward_batch: ForwardBatch, hidden_states: torch.Tensor)
         ‚Üí torch.Tensor


CLASS: PersimmonForCausalLM
----------------------------------------
  L 262: __init__(self, config: PersimmonConfig, quant_config: Optional[QuantizationConfig], prefix: str)

  L 282: get_input_embeddings(self, input_ids: torch.Tensor)
         ‚Üí torch.Tensor

  L 285: forward(self, input_ids: torch.Tensor, positions: torch.Tensor, forward_batch: ForwardBatch, inputs_embeds: Optional[torch.Tensor])
         ‚Üí LogitsProcessorOutput

  L 303: load_weights(self, weights: Iterable[tuple[str, torch.Tensor]])


CLASS: PersimmonMLP
----------------------------------------
  L  31: __init__(self, config: PersimmonConfig, quant_config: Optional[QuantizationConfig])

  L  43: forward(self, hidden_states)
         ‚Üí torch.Tensor


CLASS: PersimmonModel
----------------------------------------
  L 199: __init__(self, config: PersimmonConfig, quant_config: Optional[QuantizationConfig], prefix: str)

  L 233: get_input_embeddings(self, input_ids: torch.Tensor)
         ‚Üí torch.Tensor

  L 236: forward(self, input_ids: torch.Tensor, forward_batch: ForwardBatch, positions: torch.Tensor, inputs_embeds: Optional[torch.Tensor])
         ‚Üí torch.Tensor


============================================================
FILE: python/sglang/srt/models/phi.py
Functions: 13
============================================================


CLASS: PhiAttention
----------------------------------------
  L  30: __init__(self, config: PhiConfig, quant_config: Optional[QuantizationConfig], prefix: str, layer_id: int)

  L  84: forward(self, position_ids: torch.Tensor, forward_batch: ForwardBatch, hidden_states: torch.Tensor)
         ‚Üí torch.Tensor


CLASS: PhiForCausalLM
----------------------------------------
  L 234: __init__(self, config: PhiConfig, quant_config: Optional[QuantizationConfig], prefix: str)

  L 257: get_input_embeddings(self, input_ids: torch.Tensor)
         ‚Üí torch.Tensor

  L 260: forward(self, input_ids: torch.Tensor, positions: torch.Tensor, forward_batch: ForwardBatch, inputs_embeds: Optional[torch.Tensor])
         ‚Üí LogitsProcessorOutput

  L 279: load_weights(self, weights: Iterable[tuple[str, torch.Tensor]])


CLASS: PhiLayer
----------------------------------------
  L 129: __init__(self, config: PhiConfig, quant_config: Optional[QuantizationConfig], prefix: str, idx: int)

  L 148: forward(self, position_ids: torch.Tensor, forward_batch: ForwardBatch, hidden_states: torch.Tensor)
         ‚Üí torch.Tensor


CLASS: PhiMLP
----------------------------------------
  L 100: __init__(self, config: PhiConfig, quant_config: Optional[QuantizationConfig])

  L 120: forward(self, hidden_states)


CLASS: PhiModel
----------------------------------------
  L 168: __init__(self, config: PhiConfig, quant_config: Optional[QuantizationConfig], prefix: str)

  L 199: get_input_embeddings(self, input_ids: torch.Tensor)
         ‚Üí torch.Tensor

  L 202: forward(self, input_ids: torch.Tensor, forward_batch: ForwardBatch, positions: torch.Tensor, inputs_embeds: Optional[torch.Tensor])
         ‚Üí torch.Tensor


============================================================
FILE: python/sglang/srt/models/phi3_small.py
Functions: 21
============================================================

MODULE FUNCTIONS:
----------------------------------------
  L  32: def quick_gelu(x)
         @torch.jit.script

  L  37: def gegelu(input, limit: Optional[float])
         @torch.jit.script


CLASS: Phi3SmallDecoderLayer
----------------------------------------
  L 236: __init__(self, config: PretrainedConfig, layer_id: int, quant_config: Optional[QuantizationConfig], prefix: str)

  L 264: forward(self, positions: torch.Tensor, hidden_states: torch.Tensor, forward_batch: ForwardBatch)
         ‚Üí torch.Tensor


CLASS: Phi3SmallForCausalLM
----------------------------------------
  L 364: __init__(self, config: Phi3Config, quant_config: Optional[QuantizationConfig], prefix: str)

  L 406: get_input_embeddings(self, input_ids: torch.Tensor)
         ‚Üí torch.Tensor

  L 409: set_input_embeddings(self, value)

  L 412: get_output_embeddings(self)

  L 415: set_output_embeddings(self, value)

  L 418: set_decoder(self, decoder)

  L 421: get_decoder(self)

  L 424: compute_logits(self, input_ids: torch.LongTensor, hidden_states: torch.Tensor, sampling_metadata)
         ‚Üí Optional[torch.Tensor]

  L 437: forward(self, input_ids: torch.LongTensor, positions: Optional[torch.LongTensor], forward_batch: ForwardBatch, inputs_embeds: Optional[torch.Tensor], get_embedding: bool)
         ‚Üí LogitsProcessorOutput

  L 460: load_weights(self, weights: Iterable[Tuple[str, torch.Tensor]])


CLASS: Phi3SmallMLP
----------------------------------------
  L  54: __init__(self, config: PretrainedConfig, quant_config: Optional[QuantizationConfig], prefix: str)
         ‚Üí None

  L  84: forward(self, x)


CLASS: Phi3SmallModel
----------------------------------------
  L 289: __init__(self, config: Phi3Config, quant_config: Optional[QuantizationConfig], prefix: str)

  L 332: get_input_embeddings(self, input_ids: torch.Tensor)
         ‚Üí torch.Tensor

  L 335: forward(self, input_ids: torch.LongTensor, positions: Optional[torch.LongTensor], forward_batch: ForwardBatch, inputs_embeds: Optional[torch.Tensor])
         ‚Üí Union[torch.Tensor]


CLASS: Phi3SmallSelfAttention
----------------------------------------
  L  93: __init__(self, config: PretrainedConfig, layer_id: int, quant_config: Optional[QuantizationConfig], prefix: str)
         ‚Üí None

  L 210: forward(self, positions: torch.Tensor, hidden_states: torch.Tensor, forward_batch: ForwardBatch)
         ‚Üí Tuple[torch.Tensor, Optional[torch.Tensor], Optional[Tuple[torch.Tensor]]]


============================================================
FILE: python/sglang/srt/models/phi4mm.py
Functions: 10
============================================================


CLASS: Phi4MMForCausalLM
----------------------------------------
  L 387: __init__(self, config: PretrainedConfig, quant_config: Optional[QuantizationConfig], prefix: str)

  L 416: get_image_feature(self, items: List[MultimodalDataItem])
         ‚Üí torch.Tensor

  L 433: get_audio_feature(self, items: List[MultimodalDataItem])
         ‚Üí torch.Tensor

  L 454: forward(self, input_ids: torch.Tensor, positions: torch.Tensor, forward_batch: ForwardBatch)
         ‚Üí torch.Tensor

  L 474: pad_input_ids(self, input_ids: List[int], mm_inputs: MultimodalInputs)

  L 478: should_apply_lora(self, module_name: str)
         ‚Üí bool

  L 481: load_weights(self, weights: Iterable[Tuple[str, torch.Tensor]])


CLASS: Phi4MMImageEncoder
----------------------------------------
  L  60: __init__(self, config: PretrainedConfig, quant_config: Optional[QuantizationConfig], prefix: str, model_dir: str)
         ‚Üí None

  L 136: get_img_features(self, img_embeds: torch.FloatTensor, attention_mask)
         ‚Üí torch.FloatTensor

  L 169: forward(self, pixel_values: torch.FloatTensor, image_sizes: torch.Tensor, image_attention_mask: torch.Tensor)
         ‚Üí list[torch.FloatTensor]
         üìù process image and return vision embeddings.
            pixel_values: (num_images, num_crops, c, h, w)
            image_sizes: [[h1, w1], [h2, w2]]
            image_attention_mask: num_images x num_crops x 32 x 32
            output: (num_images, num_img_tokens, hidden_size)


============================================================
FILE: python/sglang/srt/models/phi4mm_audio.py
Functions: 18
============================================================


CLASS: AudioEmbedding
----------------------------------------
  L1078: __init__(self, config: PretrainedConfig)
         ‚Üí None

  L1182: set_audio_embeds(self, input_embeds: torch.FloatTensor)
         ‚Üí None

  L1185: set_audio_embed_sizes(self, audio_embed_sizes: torch.LongTensor)
         ‚Üí None

  L1188: get_audio_features(self, input_embeds: torch.FloatTensor, audio_attention_mask: torch.Tensor, audio_projection_mode: str)
         ‚Üí torch.FloatTensor
         üìù arguments:
            input_embeds: audio features (B, T, D)  B: num audios in a sequence

  L1242: forward(self, audio_features: torch.FloatTensor, audio_attention_mask: torch.Tensor, audio_projection_mode: str)
         ‚Üí torch.FloatTensor
         üìù arguments:
            audio_features: audio features (num_audio_tokens, T, D)
            returns:
            audio_embeds: audio embeddings (num_audio_tokens, hidden_dim)


CLASS: ConformerEncoder
----------------------------------------
  L 778: __init__(self, input_size, chunk_size, left_chunk, num_lang, attention_dim, attention_heads, linear_units, num_blocks, dropout_rate, input_layer, causal, batch_norm, cnn_out, cnn_layer_norm, ext_pw_out_channel, ext_pw_kernel_size, depthwise_seperable_out_channel, depthwise_multiplier, chunk_se, kernel_size, activation, conv_activation, conv_glu_type, bias_in_glu, linear_glu_in_convm, attention_glu_type, export, extra_layer_output_idx, extra_multi_layer_output_idxs, activation_checkpointing, relative_attention_bias_args, time_reduction, use_pt_scaled_dot_product_attention, nemo_conv_settings, conv2d_extra_padding: Literal['feat', 'feat_time', 'none', True], replication_pad_for_subsample_embedding, attention_group_size, encoder_embedding_config)

  L 884: init_relative_attention_bias(self, input_tensor)

  L 888: calculate_hs_mask(self, xs_pad, device, mask)

  L 908: forward(self, xs_pad, masks)
         üìù Conformer Forward function
            Args:
            xs_pad: torch.Tensor
            input tensor
            masks: torch.Tensor
            post-embedding input lengths


CLASS: ConformerEncoderLayer
----------------------------------------
  L 148: __init__(self, d_model, ext_pw_out_channel, depthwise_seperable_out_channel, depthwise_multiplier, n_head, d_ffn, ext_pw_kernel_size, kernel_size, dropout_rate, causal, batch_norm, activation, chunk_se, chunk_size, conv_activation, conv_glu_type, bias_in_glu, linear_glu_in_convm, attention_inner_dim, attention_glu_type, activation_checkpointing, export, use_pt_scaled_dot_product_attention, attn_group_sizes: int)

  L 225: forward(self, x, pos_k, pos_v, mask, relative_attention_bias: Optional[Tensor])
         üìù ConformerEncoder forward.
            Args:
            x: torch.Tensor
            input feature of shape (batch, max_time_in, size)
            pos_k: torch.Tensor
            positional key embedding.
            mask: torch.Tensor
            mask for x (batch, max_time_in)
            relative_attention_bias: Optional[torch.Tensor]
            bias added to attention logits w.r.t. relative positions
            (1, n_head, time1, time2)


CLASS: TransformerEncoderBase
----------------------------------------
  L 339: __init__(self, input_size, chunk_size, left_chunk, attention_dim, attention_heads, input_layer, cnn_out, cnn_layer_norm, time_reduction, dropout_rate, padding_idx, relative_attention_bias_args, positional_dropout_rate, nemo_conv_settings, conv2d_extra_padding: Literal['feat', 'feat_time', 'none', True], attention_group_size, encoder_embedding_config)

  L 423: compute_lens_change(self, feature_lens)
         üìù feature_lens: int
            return updated feature lens.
            This used to return a different lambda function for each case that
            computed the right thing.  That does not work within Torchscript.
            If you really need this to be faster, create nn.Module()-s for all
            the cases and return one of them.  Torchscript does support that.

  L 458: forward(self)
         üìù Abstract forward method implementation.

  L 534: forward_embeddings(self, xs_pad, masks, chunk_size_nc, left_chunk_nc)
         üìù Forwarding the inputs through the top embedding layers
            Args:
            xs_pad: torch.Tensor
            input tensor
            masks: torch.Tensor
            input mask
            chunk_size_nc: (optional, default is None) chunk size for
            non-causal layers
            left_chunk_nc: (optional, default is None) # of left chunks for
            non-causal layers

  L 598: get_offset(self)
         üìù Returns offset used when retaining inputs for decoding.
            This is essentially, how many additional frames have to be added to
            the front-end CNN input to ensure it can produce a single output.
            So if the "padding" parameter is 0, typically offset will be > 0.


CLASS: WindowQformer
----------------------------------------
  L1001: __init__(self, window_size: int, num_queries: int, num_blocks: int, attention_dim: int, attention_heads: int, linear_units: int, dropout_rate: float, normalize_before: bool)

  L1035: forward(self, audio_embed, mask, embed_len)
         üìù forward decoder


============================================================
FILE: python/sglang/srt/models/phi4mm_utils.py
Functions: 49
============================================================

MODULE FUNCTIONS:
----------------------------------------
  L  32: def get_activation(name)
         üìù Select an activation function by name
            Args:
            name: str
            activation function name,
            one of ["relu", "gelu", "swish", "sigmoid"],
            default "relu".

  L  53: def adaptive_enc_mask(x_len, chunk_start_idx, left_window, right_window)
         üìù The function is very important for Transformer Transducer Streaming mode
            Args:
            xs_len (int): sequence length
            chunk_start_idx (list): first idx of each chunk, such as [0,18,36,48].
            It also supports adaptive chunk size [0,10,15,45]
            left_window (int): how many left chunks can be seen
            right_window (int): how many right chunks can be seen. It is used for
            chunk overlap model.
            Returns:
            mask (torch.Tensor): a mask tensor for streaming model
            Torch 1.0.1
            tensor([[1., 1., 0., 0.],
            [0., 1., 1., 0.],
            [0., 0., 1., 1.]])
            Torch 1.4.1
            tensor([[True., True., False., False.],
            [False., True., True., False.],
            [False., False., True., True.]])

  L1586: def calc_length(lengths,
        all_paddings,
        kernel_size,
        stride,
        ceil_mode,
        repeat_num)
         üìù Calculates the output length of a Tensor passed through a convolution or
            max pooling layer

  L1639: def masked_softmax(scores, mask: Optional[Tensor])

  L1875: def get_offset(input_layer: str, time_reduction: int)
         üìù Get an offset. We will use the offset for determining #frames of a
            subsampled feature.
            Args:
            input_layer (str): Type of an input layer
            time_reduction (int): time reduction factor for downsampling a feature
            Returns:
            int: offset

  L1894: def unfold_tensor(xs_pad, max_seq_len)
         üìù For a given tensor with shape of (N, T, D), if sequence length T is
            longer than max_seq_len, this function unfold it to a
            (NT', max_seq_len, D) where T' is T // max_seq_len.
            Args:
            xs_pad: N, T, D


CLASS: AbsolutePositionalEncoding
----------------------------------------
  L 827: __init__(self, d_model, dropout_rate, max_len)
         üìù Construct an PositionalEncoding object.

  L 837: extend_pe(self, x)
         üìù Reset the positional encodings.
            Args:
            x: torch.Tensor

  L 858: forward(self, x: torch.Tensor)
         üìù Add positional encoding.
            Args:
            x: torch.Tensor
            Input tensor. shape is (batch, time, ...)
            Returns:
            torch.Tensor: Encoded tensor. Its shape is (batch, time, ...)


CLASS: AttBlock
----------------------------------------
  L1634: memory_dims(self, max_len)
         üìù memory dimensions


CLASS: AttModule
----------------------------------------
  L1601: __init__(self)

  L1605: set_export(self, mode)
         üìù set the export mode

  L1609: forward(self, x: Tensor, memory: Optional[Tensor], pos_emb: Optional[Tensor], att_mask: Optional[Tensor])
         ‚Üí tuple[Tensor, Tensor, Optional[Tensor], Optional[Tensor]]
         üìù AttModule forward
            Args:
            x: torch.Tensor
            input tensor.
            memory: torch.Tensor, optional
            memory tensor.
            pos_emb: torch.Tensor, optional
            positional encoder embedding.
            att_mask: torch.Tensor, optional
            attention mask tensor.


CLASS: BlockBase
----------------------------------------
  L  26: __init__(self, input_size, output_size)


CLASS: CausalConv1D
----------------------------------------
  L 919: __init__(self, in_channels: int, out_channels: int, kernel_size: int, stride: int, padding: Union[str, int], dilation: int, groups: int, bias: bool, padding_mode: str, device, dtype)
         ‚Üí None

  L 969: update_cache(self, x, cache)

  L 983: forward(self, x, cache)


CLASS: CausalConv2D
----------------------------------------
  L1000: __init__(self, in_channels: int, out_channels: int, kernel_size: int, stride: int, padding: Union[str, int], dilation: int, groups: int, bias: bool, padding_mode: str, device, dtype)
         ‚Üí None

  L1034: forward(self, x)


CLASS: ConvModule
----------------------------------------
  L 389: __init__(self, input_dim, ext_pw_out_channel, depthwise_seperable_out_channel, ext_pw_kernel_size, kernel_size, depthwise_multiplier, dropout_rate, causal, batch_norm, chunk_se, chunk_size, activation, glu_type, bias_in_glu, linear_glu_in_convm, export)

  L 512: forward(self, x)
         üìù ConvModule Forward.
            Args:
            x: torch.Tensor
            input tensor.


CLASS: DepthWiseSeperableConv1d
----------------------------------------
  L 286: __init__(self, input_dim, depthwise_seperable_out_channel, kernel_size, depthwise_multiplier, padding)

  L 317: forward(self, x)
         üìù Args:
            x: torch.Tensor
            input tensor


CLASS: FeedForward
----------------------------------------
  L 622: __init__(self, d_model, d_inner, dropout_rate, activation, bias_in_glu)

  L 643: forward(self, x)
         üìù FeedForward forward function.
            Args:
            x: torch.Tensor
            input tensor.


CLASS: GLU
----------------------------------------
  L 125: __init__(self, dim: int, act_name: str)
         ‚Üí None

  L 141: forward(self, x: Tensor)
         ‚Üí Tensor
         üìù GLU forward
            Apply Swish function on the first half of input matrices
            with sigmoid of the second half.
            Args:
            x: torch.Tensor
            Input.


CLASS: GLULinear
----------------------------------------
  L 580: __init__(self, input_dim, output_dim, glu_type, bias_in_glu)

  L 591: forward(self, x)
         üìù GLULinear forward
            Args:
            x: torch.Tensor
            inpute tensor.


CLASS: GLUPointWiseConv
----------------------------------------
  L 182: __init__(self, input_dim, output_dim, kernel_size, glu_type, bias_in_glu, causal)

  L 228: forward(self, x)
         üìù Args:
            x: torch.Tensor
            input tensor


CLASS: MeanVarianceNormLayer
----------------------------------------
  L 886: __init__(self, input_size)

  L 892: forward(self, input_: Tensor)
         ‚Üí Tensor
         üìù MeanVarianceNormLayer Forward
            Args:
            input_: torch.Tensor
            input tensor.


CLASS: MultiHeadedAttention
----------------------------------------
  L1693: __init__(self, n_head, n_feat, dropout_rate, attention_inner_dim, glu_type, bias_in_glu, use_pt_scaled_dot_product_attention, n_value, group_size: int)

  L1741: forward(self, query: Tensor, key: Tensor, value: Tensor, pos_k: Tensor, pos_v: Tensor, mask: Optional[Tensor], relative_attention_bias: Optional[Tensor])
         üìù Compute 'Scaled Dot Product Attention'.
            Args:
            query: torch.Tensor
            query tensor (batch, time1, size)
            key: torch.Tensor
            key tensor (batch, time2, size)
            value: torch.Tensor
            value tensor (batch, time1, size)
            pos_k: torch.Tensor
            key tensor used for relative positional embedding.
            pos_v: torch.Tensor
            value tensor used for relative positional embedding.
            mask: torch.Tensor
            mask tensor (batch, time1, time2)
            relative_attention_bias: torch.Tensor
            bias added to attention logits w.r.t. relative positions
            (1, n_head, time1, time2)


CLASS: MultiSequential
----------------------------------------
  L1868: forward(self)
         üìù Forward method implementation.


CLASS: NemoConvSubsampling
----------------------------------------
  L1080: __init__(self, feat_in, feat_out, subsampling_factor, subsampling, conv_channels, subsampling_conv_chunking_factor, activation, is_causal)

  L1369: get_sampling_frames(self)

  L1372: get_streaming_cache_size(self)

  L1375: forward(self, x, mask)
         üìù Forward method for NeMo subsampling.
            Args:
            x[Batch, Time, Filters]: torch.Tensor
            input tensor
            x_mask: torch.Tensor
            input mask
            Returns:
            x: torch.Tensor
            Resulting tensor from subsampling (B, T //
            time_reduction_factor, feat_out)
            pad_mask: torch.Tensor
            tensor of padded hidden state sequences (B, 1, T //
            time_reduction_factor)

  L1443: reset_parameters(self)

  L1468: conv_split_by_batch(self, x)
         üìù Tries to split input by batch, run conv and concat results

  L1494: conv_split_by_channel(self, x)
         üìù For dw convs, tries to split input by time, run conv and concat
            results

  L1532: channel_chunked_conv(self, conv, chunk_size, x)
         üìù Performs channel chunked convolution

  L1572: change_subsampling_conv_chunking_factor(self, subsampling_conv_chunking_factor: int)


CLASS: Swish
----------------------------------------
  L 108: __init__(self)
         ‚Üí None

  L 112: forward(self, x: Tensor)
         ‚Üí Tensor
         üìù Apply Swish function
            Args:
            x: torch.Tensor
            Input.


CLASS: T5RelativeAttentionLogitBias
----------------------------------------
  L 722: __init__(self, num_heads, num_buckets, max_distance, symmetric)

  L 739: forward(self, x)


============================================================
FILE: python/sglang/srt/models/phimoe.py
Functions: 14
============================================================

MODULE FUNCTIONS:
----------------------------------------
  L 107: def sparsemixer(scores, jitter_eps)

  L 159: def phimoe_routing_function(hidden_states: torch.Tensor,
        gating_output: torch.Tensor,
        topk: int,
        renormalize: bool)


CLASS: PhiMoE
----------------------------------------
  L 182: __init__(self, num_experts: int, top_k: int, hidden_size: int, intermediate_size: int, layer_id: int, quant_config: Optional[QuantizationConfig], prefix: str)

  L 221: forward(self, hidden_states: torch.Tensor, forward_batch: Optional[ForwardBatch])
         ‚Üí torch.Tensor


CLASS: PhiMoEAttention
----------------------------------------
  L 235: __init__(self, hidden_size: int, num_heads: int, num_kv_heads: int, head_dim: Optional[int], max_position: int, rope_theta: float, layer_id: int, attention_bias: bool, quant_config: Optional[QuantizationConfig], rope_scaling: Optional[dict], prefix: str)
         ‚Üí None

  L 315: forward(self, positions: torch.Tensor, hidden_states: torch.Tensor, forward_batch: ForwardBatch)
         ‚Üí torch.Tensor


CLASS: PhiMoEConfig
----------------------------------------
  L  39: __init__(self, vocab_size, hidden_size, intermediate_size, num_hidden_layers, num_attention_heads, num_key_value_heads, head_dim, hidden_act, max_position_embeddings, initializer_range, rms_norm_eps, use_cache, pad_token_id, bos_token_id, eos_token_id, tie_word_embeddings, rope_theta, sliding_window, attention_dropout, num_experts_per_tok, num_local_experts, output_router_logits, router_aux_loss_coef, router_jitter_noise, attention_bias, lm_head_bias)


CLASS: PhiMoEDecoderLayer
----------------------------------------
  L 331: __init__(self, config: PhiMoEConfig, layer_id: int, quant_config: Optional[QuantizationConfig], prefix: str)
         ‚Üí None

  L 372: forward(self, positions: torch.Tensor, hidden_states: torch.Tensor, residual: Optional[torch.Tensor], forward_batch: ForwardBatch)
         ‚Üí Tuple[torch.Tensor, torch.Tensor]


CLASS: PhiMoEForCausalLM
----------------------------------------
  L 455: __init__(self, config: PhiMoEConfig, quant_config: Optional[QuantizationConfig], prefix: str)

  L 484: forward(self, input_ids: torch.Tensor, positions: torch.Tensor, forward_batch: ForwardBatch, inputs_embeds: Optional[torch.Tensor], get_embedding: bool)
         ‚Üí LogitsProcessorOutput

  L 502: load_weights(self, weights: Iterable[Tuple[str, torch.Tensor]])


CLASS: PhiMoEModel
----------------------------------------
  L 402: __init__(self, config: PhiMoEConfig, quant_config: Optional[QuantizationConfig], prefix: str)

  L 431: forward(self, input_ids: torch.Tensor, positions: torch.Tensor, forward_batch: ForwardBatch, input_embeds: Optional[torch.Tensor])
         ‚Üí Union[torch.Tensor]


============================================================
FILE: python/sglang/srt/models/pixtral.py
Functions: 13
============================================================

MODULE FUNCTIONS:
----------------------------------------
  L 225: def resolve_visual_encoder_outputs(outputs: Union[torch.Tensor,
        List[torch.Tensor]],
        feature_sample_layers: Optional[List[int]],
        post_norm: Optional[nn.Module],
        num_hidden_layers: int)
         ‚Üí torch.Tensor
         üìù Resolve outputs from visual encoder based on feature_sample_layers.


CLASS: PixtralHFMLP
----------------------------------------
  L  46: __init__(self, config: PretrainedConfig, quant_config: Optional[QuantizationConfig])
         ‚Üí None

  L  76: forward(self, x: torch.Tensor)
         ‚Üí torch.Tensor


CLASS: PixtralHFTransformer
----------------------------------------
  L 166: __init__(self, config: PixtralVisionConfig, quant_config: Optional[QuantizationConfig])
         ‚Üí None

  L 192: forward(self, x: torch.Tensor, attention_mask: Optional[torch.Tensor], position_embeddings: Optional[Tuple[torch.Tensor, torch.Tensor]], return_all_hidden_states: bool)
         ‚Üí Union[torch.Tensor, List[torch.Tensor]]
         üìù Forward pass through transformer layers.
            Args:
            x: Input tensor
            attention_mask: Optional attention mask
            position_embeddings: Optional position embeddings for rotary attention
            return_all_hidden_states: Whether to return all hidden states
            Returns:
            Either the final hidden state, or a list of all hidden states if
            return_all_hidden_states is True


CLASS: PixtralHFTransformerBlock
----------------------------------------
  L  90: __init__(self, config: PretrainedConfig, layer_id: int, quant_config: Optional[QuantizationConfig])
         ‚Üí None

  L 123: forward(self, hidden_states: torch.Tensor, attention_mask: Optional[torch.Tensor], position_embeddings: Optional[Tuple[torch.Tensor, torch.Tensor]])
         ‚Üí torch.Tensor


CLASS: PixtralHFVisionModel
----------------------------------------
  L 271: pad_input_ids(self, input_ids: List[int], mm_inputs: MultimodalInputs)

  L 274: __init__(self, config: PixtralVisionConfig, quant_config: Optional[QuantizationConfig])
         ‚Üí None

  L 320: dtype(self)

  L 324: device(self)

  L 327: forward(self, pixel_values: torch.Tensor, image_sizes: list[tuple[int, int]], output_hidden_states: bool, feature_sample_layers: Optional[list[int]])
         ‚Üí Union[torch.Tensor, tuple]
         üìù Args:
            pixel_values: [batch_size, C, H, W], padded if multiple images
            image_sizes: list of (H, W) for each image in the batch
            output_hidden_states: Whether to return all hidden states.
            feature_sample_layers: Layer indices whose features should be
            concatenated and used as the visual encoder output. If none
            are provided, the last layer is used.
            Returns:
            A tuple containing:
            - hidden_states: Final model outputs (or selected layers if feature_sample_layers given)
            - hidden_states tuple (optional): All hidden states if output_hidden_states=True

  L 419: load_weights(self, weights: Iterable[Tuple[str, torch.Tensor]])
         ‚Üí Set[str]
         üìù Load weights from a HuggingFace checkpoint with proper parameter mapping.


============================================================
FILE: python/sglang/srt/models/qwen.py
Functions: 12
============================================================


CLASS: QWenAttention
----------------------------------------
  L  87: __init__(self, hidden_size: int, num_heads: int, max_position_embeddings: int, layer_id: int, rope_theta: float, rope_scaling: Optional[Dict[str, Any]], quant_config: Optional[QuantizationConfig], prefix: str)

  L 141: forward(self, positions: torch.Tensor, hidden_states: torch.Tensor, forward_batch: ForwardBatch)
         ‚Üí torch.Tensor


CLASS: QWenBlock
----------------------------------------
  L 156: __init__(self, config: PretrainedConfig, layer_id, quant_config: Optional[QuantizationConfig], prefix: str)

  L 188: forward(self, positions: torch.Tensor, hidden_states: torch.Tensor, forward_batch: ForwardBatch)
         ‚Üí torch.Tensor


CLASS: QWenLMHeadModel
----------------------------------------
  L 261: __init__(self, config: PretrainedConfig, quant_config: Optional[QuantizationConfig], prefix: str)

  L 279: forward(self, input_ids: torch.Tensor, positions: torch.Tensor, forward_batch: ForwardBatch)

  L 291: forward_split_prefill(self, input_ids: torch.Tensor, positions: torch.Tensor, forward_batch: ForwardBatch, split_interval: Tuple[int, int])

  L 326: load_weights(self, weights: Iterable[Tuple[str, torch.Tensor]])


CLASS: QWenMLP
----------------------------------------
  L  47: __init__(self, hidden_size: int, intermediate_size: int, hidden_act: str, quant_config: Optional[QuantizationConfig], prefix: str)

  L  79: forward(self, x)


CLASS: QWenModel
----------------------------------------
  L 213: __init__(self, config: PretrainedConfig, quant_config: Optional[QuantizationConfig], prefix: str)

  L 242: forward(self, input_ids: torch.Tensor, positions: torch.Tensor, forward_batch: ForwardBatch)
         ‚Üí torch.Tensor


============================================================
FILE: python/sglang/srt/models/qwen2.py
Functions: 23
============================================================


CLASS: Qwen2Attention
----------------------------------------
  L  99: __init__(self, hidden_size: int, num_heads: int, num_kv_heads: int, head_dim: Optional[int], layer_id: int, rope_theta: float, rope_scaling: Optional[Dict[str, Any]], max_position_embeddings: int, quant_config: Optional[QuantizationConfig], dual_chunk_attention_config: Optional[dict[str, Any]], prefix: str)
         ‚Üí None

  L 174: forward(self, positions: torch.Tensor, hidden_states: torch.Tensor, forward_batch: ForwardBatch)
         ‚Üí torch.Tensor


CLASS: Qwen2DecoderLayer
----------------------------------------
  L 189: __init__(self, config: Qwen2Config, layer_id: int, quant_config: Optional[QuantizationConfig], prefix: str, alt_stream: Optional[torch.cuda.Stream])
         ‚Üí None

  L 231: forward(self, positions: torch.Tensor, hidden_states: torch.Tensor, forward_batch: ForwardBatch, residual: Optional[torch.Tensor])
         ‚Üí Tuple[torch.Tensor, torch.Tensor]


CLASS: Qwen2ForCausalLM
----------------------------------------
  L 409: __init__(self, config: Qwen2Config, quant_config: Optional[QuantizationConfig], prefix: str)
         ‚Üí None

  L 457: get_input_embedding(self, input_ids: torch.Tensor)
         ‚Üí torch.Tensor

  L 460: get_input_embeddings(self)
         ‚Üí nn.Embedding

  L 464: forward(self, input_ids: torch.Tensor, positions: torch.Tensor, forward_batch: ForwardBatch, input_embeds: torch.Tensor, get_embedding: bool, pp_proxy_tensors: Optional[PPProxyTensors])
         ‚Üí torch.Tensor

  L 499: forward_split_prefill(self, input_ids: torch.Tensor, positions: torch.Tensor, forward_batch: ForwardBatch, split_interval: Tuple[int, int], input_embeds: torch.Tensor)

  L 540: start_layer(self)

  L 544: end_layer(self)

  L 547: load_weights(self, weights: Iterable[Tuple[str, torch.Tensor]])

  L 616: get_embed_and_head(self)

  L 619: set_embed_and_head(self, embed, head)

  L 627: load_kv_cache_scales(self, quantization_param_path: str)
         ‚Üí None

  L 630: set_eagle3_layers_to_capture(self, layer_ids: Optional[List[int]])


CLASS: Qwen2MLP
----------------------------------------
  L  61: __init__(self, hidden_size: int, intermediate_size: int, hidden_act: str, quant_config: Optional[QuantizationConfig], prefix: str)
         ‚Üí None

  L  91: forward(self, x)


CLASS: Qwen2Model
----------------------------------------
  L 257: __init__(self, config: Qwen2Config, quant_config: Optional[QuantizationConfig], prefix: str, decoder_layer_type: type[nn.Module], alt_stream: Optional[torch.cuda.Stream])
         ‚Üí None

  L 305: get_input_embedding(self, input_ids: torch.Tensor)
         ‚Üí torch.Tensor

  L 311: get_input_embeddings(self)
         ‚Üí nn.Embedding

  L 314: forward(self, input_ids: torch.Tensor, positions: torch.Tensor, forward_batch: ForwardBatch, input_embeds: torch.Tensor, pp_proxy_tensors: Optional[PPProxyTensors])
         ‚Üí Union[torch.Tensor, PPProxyTensors]

  L 368: load_kv_cache_scales(self, quantization_param_path: str)
         ‚Üí None


============================================================
FILE: python/sglang/srt/models/qwen2_5_vl.py
Functions: 19
============================================================


CLASS: Qwen2_5_VLForConditionalGeneration
----------------------------------------
  L 482: __init__(self, config: Qwen2_5_VLConfig, quant_config: Optional[QuantizationConfig], prefix: str)
         ‚Üí None

  L 520: pad_input_ids(self, input_ids: List[int], mm_inputs: MultimodalInputs)

  L 524: get_image_feature(self, items: List[MultimodalDataItem])
         ‚Üí torch.Tensor

  L 535: get_video_feature(self, items: List[MultimodalDataItem])
         ‚Üí torch.Tensor

  L 546: get_input_embeddings(self)

  L 550: forward(self, input_ids: torch.Tensor, positions: torch.Tensor, forward_batch: ForwardBatch, get_embedding: bool)
         üìù Run forward pass for Qwen2_5-VL.
            Args:
            input_ids: Flattened (concatenated) input_ids corresponding to a
            batch.
            positions: Flattened (concatenated) position ids corresponding to a
            batch.
            **NOTE**: If mrope is enabled (default setting for Qwen2-VL
            opensource models), the shape will be `(3, seq_len)`,
            otherwise it will be `(seq_len,).
            (Use input_metadata.mrope_positions to replace it)

  L 597: load_weights(self, weights: Iterable[Tuple[str, torch.Tensor]])


CLASS: Qwen2_5_VLMLP
----------------------------------------
  L  69: __init__(self, in_features: int, hidden_features: int, bias: bool, hidden_act, quant_config: Optional[QuantizationConfig], prefix: str)

  L  95: forward(self, x: torch.Tensor)
         ‚Üí torch.Tensor


CLASS: Qwen2_5_VisionBlock
----------------------------------------
  L 105: __init__(self, dim: int, intermediate_dim: int, num_heads: int, hidden_act, norm_layer: Type[nn.Module], attn_implementation: Optional[str], quant_config: Optional[QuantizationConfig], prefix: str, num_dummy_heads: int)
         ‚Üí None

  L 166: forward(self, x: torch.Tensor, cu_seqlens: torch.Tensor, position_embeddings: torch.Tensor)
         ‚Üí torch.Tensor


CLASS: Qwen2_5_VisionPatchMerger
----------------------------------------
  L 200: __init__(self, dim: int, context_dim: int, spatial_merge_size: int, quant_config: Optional[QuantizationConfig], prefix: str)
         ‚Üí None

  L 231: forward(self, x: torch.Tensor)
         ‚Üí torch.Tensor


CLASS: Qwen2_5_VisionTransformer
----------------------------------------
  L 246: __init__(self, vision_config: Qwen2_5_VLVisionConfig, norm_eps: float, quant_config: Optional[QuantizationConfig], prefix: str)
         ‚Üí None

  L 300: get_window_index(self, grid_thw)

  L 346: dtype(self)
         ‚Üí torch.dtype

  L 350: device(self)
         ‚Üí torch.device

  L 353: rot_pos_emb(self, grid_thw: torch.Tensor)
         ‚Üí torch.Tensor

  L 385: forward(self, x: torch.Tensor, grid_thw: torch.Tensor)
         ‚Üí torch.Tensor


============================================================
FILE: python/sglang/srt/models/qwen2_audio.py
Functions: 5
============================================================


CLASS: Qwen2AudioForConditionalGeneration
----------------------------------------
  L  88: __init__(self, config: Qwen2AudioConfig, quant_config: Optional[QuantizationConfig], prefix: str)
         ‚Üí None

  L 115: pad_input_ids(self, input_ids: List[int], mm_inputs: MultimodalInputs)

  L 118: get_audio_feature(self, items: List[MultimodalDataItem])
         ‚Üí torch.Tensor

  L 134: forward(self, input_ids: torch.Tensor, positions: torch.Tensor, forward_batch: ForwardBatch)
         ‚Üí torch.Tensor

  L 153: load_weights(self, weights: Iterable[Tuple[str, torch.Tensor]])


============================================================
FILE: python/sglang/srt/models/qwen2_eagle.py
Functions: 5
============================================================


CLASS: Qwen2DecoderLayer
----------------------------------------
  L  41: __init__(self, config: Qwen2Config, layer_id: int, quant_config: Optional[QuantizationConfig], prefix: str)
         ‚Üí None


CLASS: Qwen2ForCausalLMEagle
----------------------------------------
  L 115: __init__(self, config: Qwen2Config, quant_config: Optional[QuantizationConfig], prefix: str)
         ‚Üí None

  L 139: load_weights(self, weights: Iterable[Tuple[str, torch.Tensor]])


CLASS: Qwen2Model
----------------------------------------
  L  58: __init__(self, config: Qwen2Config, quant_config: Optional[QuantizationConfig], prefix: str)
         ‚Üí None

  L  85: forward(self, input_ids: torch.Tensor, positions: torch.Tensor, forward_batch: ForwardBatch, input_embeds: torch.Tensor, pp_proxy_tensors: Optional[PPProxyTensors])
         ‚Üí torch.Tensor


============================================================
FILE: python/sglang/srt/models/qwen2_moe.py
Functions: 18
============================================================


CLASS: Qwen2MoeAttention
----------------------------------------
  L 197: __init__(self, hidden_size: int, num_heads: int, num_kv_heads: int, layer_id: int, rope_theta: float, rope_scaling: Optional[Dict[str, Any]], max_position_embeddings: int, qkv_bias: int, quant_config: Optional[QuantizationConfig], dual_chunk_attention_config: Optional[dict[str, Any]], prefix: str)
         ‚Üí None

  L 278: forward(self, positions: torch.Tensor, hidden_states: torch.Tensor, forward_batch: ForwardBatch)
         ‚Üí torch.Tensor


CLASS: Qwen2MoeDecoderLayer
----------------------------------------
  L 293: __init__(self, config: PretrainedConfig, layer_id: int, quant_config: Optional[QuantizationConfig], prefix: str, alt_stream: Optional[torch.cuda.Stream])
         ‚Üí None

  L 367: forward(self, positions: torch.Tensor, hidden_states: torch.Tensor, forward_batch: ForwardBatch, residual: Optional[torch.Tensor])
         ‚Üí Tuple[torch.Tensor, torch.Tensor]


CLASS: Qwen2MoeForCausalLM
----------------------------------------
  L 518: __init__(self, config: PretrainedConfig, quant_config: Optional[QuantizationConfig], prefix: str)
         ‚Üí None

  L 543: forward(self, input_ids: torch.Tensor, positions: torch.Tensor, forward_batch: ForwardBatch, input_embeds: torch.Tensor, pp_proxy_tensors: Optional[PPProxyTensors])
         ‚Üí torch.Tensor

  L 569: forward_split_prefill(self, input_ids: torch.Tensor, positions: torch.Tensor, forward_batch: ForwardBatch, split_interval: Tuple[int, int], input_embeds: torch.Tensor)

  L 612: start_layer(self)

  L 616: end_layer(self)

  L 619: load_weights(self, weights: Iterable[Tuple[str, torch.Tensor]])

  L 706: get_model_config_for_expert_location(cls, config)

  L 713: set_eagle3_layers_to_capture(self, layer_ids: Optional[List[int]])


CLASS: Qwen2MoeMLP
----------------------------------------
  L  74: __init__(self, hidden_size: int, intermediate_size: int, hidden_act: str, quant_config: Optional[QuantizationConfig], reduce_results: bool, prefix: str)
         ‚Üí None

  L 105: forward(self, x, use_reduce_scatter: bool)


CLASS: Qwen2MoeModel
----------------------------------------
  L 405: __init__(self, config: PretrainedConfig, quant_config: Optional[QuantizationConfig], prefix: str, decoder_layer_type: type[nn.Module], alt_stream: Optional[torch.cuda.Stream])
         ‚Üí None

  L 452: forward(self, input_ids: torch.Tensor, positions: torch.Tensor, forward_batch: ForwardBatch, input_embeds: torch.Tensor, pp_proxy_tensors: Optional[PPProxyTensors])
         ‚Üí Union[torch.Tensor, PPProxyTensors]


CLASS: Qwen2MoeSparseMoeBlock
----------------------------------------
  L 117: __init__(self, layer_id: int, config: PretrainedConfig, quant_config: Optional[QuantizationConfig], prefix: str)

  L 168: forward(self, hidden_states: torch.Tensor, forward_batch: Optional[ForwardBatch], use_reduce_scatter: bool)
         ‚Üí torch.Tensor


============================================================
FILE: python/sglang/srt/models/qwen2_rm.py
Functions: 3
============================================================


CLASS: Qwen2ForRewardModel
----------------------------------------
  L  29: __init__(self, config: Qwen2Config, quant_config: Optional[QuantizationConfig], prefix: str)
         ‚Üí None

  L  52: forward(self, input_ids: torch.Tensor, positions: torch.Tensor, forward_batch: ForwardBatch, input_embeds: torch.Tensor, get_embedding: bool)
         ‚Üí EmbeddingPoolerOutput

  L  68: load_weights(self, weights: Iterable[Tuple[str, torch.Tensor]])


============================================================
FILE: python/sglang/srt/models/qwen2_vl.py
Functions: 23
============================================================


CLASS: Qwen2VLForConditionalGeneration
----------------------------------------
  L 445: __init__(self, config: Qwen2VLConfig, quant_config: Optional[QuantizationConfig], prefix: str)
         ‚Üí None

  L 481: pad_input_ids(self, input_ids: List[int], mm_inputs: MultimodalInputs)

  L 485: get_image_feature(self, items: List[MultimodalDataItem])
         ‚Üí torch.Tensor

  L 496: get_video_feature(self, items: List[MultimodalDataItem])
         ‚Üí torch.Tensor

  L 514: get_input_embeddings(self)

  L 517: forward(self, input_ids: torch.Tensor, positions: torch.Tensor, forward_batch: ForwardBatch, get_embedding: bool)
         üìù Run forward pass for Qwen2-VL.
            Args:
            input_ids: Flattened (concatenated) input_ids corresponding to a
            batch.
            positions: Flattened (concatenated) position ids corresponding to a
            batch.
            **NOTE**: If mrope is enabled (default setting for Qwen2-VL
            opensource models), the shape will be `(3, seq_len)`,
            otherwise it will be `(seq_len,).
            (Use input_metadata.mrope_positions to replace it)

  L 563: load_weights(self, weights: Iterable[Tuple[str, torch.Tensor]])


CLASS: Qwen2VisionBlock
----------------------------------------
  L 124: __init__(self, dim: int, num_heads: int, mlp_ratio: float, act_layer: Type[nn.Module], norm_layer: Type[nn.Module], attn_implementation: Optional[str], quant_config: Optional[QuantizationConfig], prefix: str)
         ‚Üí None

  L 170: forward(self, x: torch.Tensor, cu_seqlens: torch.Tensor, position_embeddings: torch.Tensor)
         ‚Üí torch.Tensor


CLASS: Qwen2VisionMLP
----------------------------------------
  L  92: __init__(self, in_features: int, hidden_features: int, act_layer: Type[nn.Module], quant_config: Optional[QuantizationConfig], prefix: str)

  L 115: forward(self, x: torch.Tensor)
         ‚Üí torch.Tensor


CLASS: Qwen2VisionPatchEmbed
----------------------------------------
  L 191: __init__(self, patch_size: int, temporal_patch_size: int, in_chans: int, embed_dim: int)
         ‚Üí None

  L 208: forward(self, x: torch.Tensor)
         ‚Üí torch.Tensor


CLASS: Qwen2VisionPatchMerger
----------------------------------------
  L 217: __init__(self, d_model: int, context_dim: int, norm_layer: Type[nn.Module], spatial_merge_size: int, quant_config: Optional[QuantizationConfig], prefix: str)
         ‚Üí None

  L 251: forward(self, x: torch.Tensor)
         ‚Üí torch.Tensor


CLASS: Qwen2VisionRotaryEmbedding
----------------------------------------
  L 264: __init__(self, dim: int, theta: float)
         ‚Üí None

  L 273: update_freqs_cache(self, seqlen: int)
         ‚Üí None

  L 292: forward(self, seqlen: int)
         ‚Üí torch.Tensor


CLASS: Qwen2VisionTransformer
----------------------------------------
  L 299: __init__(self, vision_config: Qwen2VLVisionConfig, norm_eps: float, quant_config: Optional[QuantizationConfig], prefix: str)
         ‚Üí None

  L 353: dtype(self)
         ‚Üí torch.dtype

  L 357: device(self)
         ‚Üí torch.device

  L 360: rot_pos_emb(self, grid_thw: torch.Tensor)
         ‚Üí torch.Tensor

  L 393: forward(self, x: torch.Tensor, grid_thw: torch.Tensor)
         ‚Üí torch.Tensor


============================================================
FILE: python/sglang/srt/models/qwen3.py
Functions: 16
============================================================


CLASS: Qwen3Attention
----------------------------------------
  L  39: __init__(self, hidden_size: int, num_heads: int, num_kv_heads: int, layer_id: int, rope_theta: float, rope_scaling: Optional[Dict[str, Any]], head_dim: Optional[int], max_position_embeddings: int, quant_config: Optional[QuantizationConfig], rms_norm_eps: float, attention_bias: bool, prefix: str, alt_stream: Optional[torch.cuda.Stream])
         ‚Üí None

  L 146: forward(self, positions: torch.Tensor, hidden_states: torch.Tensor, forward_batch: ForwardBatch)
         ‚Üí torch.Tensor


CLASS: Qwen3DecoderLayer
----------------------------------------
  L 162: __init__(self, config: Qwen3Config, layer_id: int, quant_config: Optional[QuantizationConfig], prefix: str, alt_stream: Optional[torch.cuda.Stream])
         ‚Üí None

  L 215: forward(self, positions: torch.Tensor, hidden_states: torch.Tensor, forward_batch: ForwardBatch, residual: Optional[torch.Tensor])
         ‚Üí Tuple[torch.Tensor, torch.Tensor]


CLASS: Qwen3ForCausalLM
----------------------------------------
  L 281: __init__(self, config: Qwen3Config, quant_config: Optional[QuantizationConfig], prefix: str)
         ‚Üí None

  L 330: get_input_embeddings(self)
         ‚Üí nn.Embedding

  L 334: forward(self, input_ids: torch.Tensor, positions: torch.Tensor, forward_batch: ForwardBatch, input_embeds: torch.Tensor, get_embedding: bool, pp_proxy_tensors: Optional[PPProxyTensors])
         ‚Üí torch.Tensor

  L 370: forward_split_prefill(self, input_ids: torch.Tensor, positions: torch.Tensor, forward_batch: ForwardBatch, split_interval: Tuple[int, int], input_embeds: torch.Tensor)

  L 411: start_layer(self)

  L 415: end_layer(self)

  L 418: load_weights(self, weights: Iterable[Tuple[str, torch.Tensor]])

  L 487: get_embed_and_head(self)

  L 490: set_embed_and_head(self, embed, head)

  L 498: load_kv_cache_scales(self, quantization_param_path: str)
         ‚Üí None

  L 501: set_eagle3_layers_to_capture(self, layer_ids: Optional[List[int]])


CLASS: Qwen3Model
----------------------------------------
  L 245: __init__(self, config: Qwen3Config, quant_config: Optional[QuantizationConfig], prefix: str)
         ‚Üí None


============================================================
FILE: python/sglang/srt/models/qwen3_classification.py
Functions: 3
============================================================


CLASS: Qwen3ForSequenceClassification
----------------------------------------
  L  29: __init__(self, config: Qwen2Config, quant_config: Optional[QuantizationConfig], prefix: str)
         ‚Üí None

  L  56: forward(self, input_ids: torch.Tensor, positions: torch.Tensor, forward_batch: ForwardBatch, input_embeds: Optional[torch.Tensor], get_embedding: bool)
         ‚Üí EmbeddingPoolerOutput

  L  74: load_weights(self, weights: Iterable[Tuple[str, torch.Tensor]])


============================================================
FILE: python/sglang/srt/models/qwen3_moe.py
Functions: 36
============================================================


CLASS: Qwen3MoeAttention
----------------------------------------
  L 263: __init__(self, hidden_size: int, num_heads: int, num_kv_heads: int, layer_id: int, rope_theta: float, rope_scaling: Optional[Dict[str, Any]], max_position_embeddings: int, head_dim: Optional[int], rms_norm_eps: float, attention_bias: bool, quant_config: Optional[QuantizationConfig], prefix: str, dual_chunk_attention_config: Optional[dict[str, Any]], alt_stream: Optional[torch.cuda.Stream])
         ‚Üí None

  L 373: op_prepare(self, state)

  L 380: op_core(self, state)

  L 385: forward_prepare(self, positions: torch.Tensor, hidden_states: torch.Tensor, forward_batch: ForwardBatch)

  L 400: forward_core(self, intermediate_state)

  L 408: forward(self, positions: torch.Tensor, hidden_states: torch.Tensor, forward_batch: ForwardBatch)
         ‚Üí torch.Tensor


CLASS: Qwen3MoeDecoderLayer
----------------------------------------
  L 423: __init__(self, config: Qwen3MoeConfig, layer_id: int, quant_config: Optional[QuantizationConfig], prefix: str, alt_stream: Optional[torch.cuda.Stream])
         ‚Üí None

  L 505: forward(self, positions: torch.Tensor, hidden_states: torch.Tensor, forward_batch: ForwardBatch, residual: Optional[torch.Tensor])
         ‚Üí Tuple[torch.Tensor, torch.Tensor]

  L 541: op_comm_prepare_attn(self, state, positions: torch.Tensor, hidden_states: torch.Tensor, forward_batch: ForwardBatch, residual: Optional[torch.Tensor], tbo_subbatch_index: Optional[int])

  L 561: op_comm_prepare_mlp(self, state)

  L 570: op_mlp(self, state)

  L 574: op_comm_postprocess_layer(self, state)


CLASS: Qwen3MoeForCausalLM
----------------------------------------
  L 619: __init__(self, config: Qwen3MoeConfig, quant_config: Optional[QuantizationConfig], prefix: str)
         ‚Üí None

  L 642: get_input_embeddings(self)
         ‚Üí nn.Embedding

  L 646: forward(self, input_ids: torch.Tensor, positions: torch.Tensor, forward_batch: ForwardBatch, input_embeds: torch.Tensor, pp_proxy_tensors: Optional[PPProxyTensors])
         ‚Üí torch.Tensor

  L 674: forward_split_prefill(self, input_ids: torch.Tensor, positions: torch.Tensor, forward_batch: ForwardBatch, split_interval: Tuple[int, int], input_embeds: torch.Tensor)

  L 717: start_layer(self)

  L 721: end_layer(self)

  L 724: get_embed_and_head(self)

  L 727: set_eagle3_layers_to_capture(self, layer_ids: Optional[List[int]])

  L 742: load_weights(self, weights: Iterable[Tuple[str, torch.Tensor]])

  L 857: get_model_config_for_expert_location(cls, config)


CLASS: Qwen3MoeModel
----------------------------------------
  L 600: __init__(self, config: Qwen3MoeConfig, quant_config: Optional[QuantizationConfig], prefix: str)
         ‚Üí None


CLASS: Qwen3MoeSparseMoeBlock
----------------------------------------
  L  69: __init__(self, layer_id: int, config: Qwen3MoeConfig, quant_config: Optional[QuantizationConfig], prefix: str)

  L 118: forward(self, hidden_states: torch.Tensor, forward_batch: Optional[ForwardBatch], use_reduce_scatter: bool)
         ‚Üí torch.Tensor

  L 130: get_moe_weights(self)

  L 137: forward_normal(self, hidden_states: torch.Tensor, use_reduce_scatter: bool)
         ‚Üí torch.Tensor

  L 154: forward_deepep(self, hidden_states: torch.Tensor, forward_batch: ForwardBatch)
         ‚Üí torch.Tensor

  L 183: op_gate(self, state)

  L 192: op_select_experts(self, state)

  L 215: op_dispatch_a(self, state)

  L 225: op_dispatch_b(self, state)

  L 234: op_experts(self, state)

  L 239: op_combine_a(self, state)

  L 250: op_combine_b(self, state)

  L 258: op_output(self, state)


============================================================
FILE: python/sglang/srt/models/registry.py
Functions: 3
============================================================

MODULE FUNCTIONS:
----------------------------------------
  L  77: def import_model_classes()
         @lru_cache()


CLASS: _ModelRegistry
----------------------------------------
  L  20: get_supported_archs(self)
         ‚Üí AbstractSet[str]

  L  62: resolve_model_cls(self, architectures: Union[str, List[str]])
         ‚Üí Tuple[Type[nn.Module], str]


============================================================
FILE: python/sglang/srt/models/roberta.py
Functions: 14
============================================================

MODULE FUNCTIONS:
----------------------------------------
  L 192: def create_position_ids_from_input_ids(input_ids,
        padding_idx,
        past_key_values_length)


CLASS: RobertaClassificationHead
----------------------------------------
  L  23: __init__(self, config: RobertaConfig)

  L  28: forward(self, features)


CLASS: RobertaEmbedding
----------------------------------------
  L  38: __init__(self, config: RobertaConfig)

  L  66: forward(self, input_ids: torch.Tensor, seq_lens: torch.Tensor, position_ids: torch.Tensor, forward_batch: ForwardBatch)
         ‚Üí torch.Tensor


CLASS: XLMRobertaBaseModel
----------------------------------------
  L 115: __init__(self)

  L 135: forward(self, input_ids: torch.Tensor, positions: torch.Tensor, forward_batch: ForwardBatch, input_embeds: torch.Tensor, get_embedding: bool)
         ‚Üí torch.Tensor

  L 157: load_weights(self, weights: Iterable[Tuple[str, torch.Tensor]])


CLASS: XLMRobertaForSequenceClassification
----------------------------------------
  L 234: __init__(self)

  L 248: forward(self, input_ids: torch.Tensor, positions: torch.Tensor, forward_batch: ForwardBatch, input_embeds: torch.Tensor, get_embedding: bool)
         ‚Üí torch.Tensor

  L 265: load_weights(self, weights: Iterable[Tuple[str, torch.Tensor]])


CLASS: XLMRobertaModel
----------------------------------------
  L 203: __init__(self)

  L 216: forward(self, input_ids: torch.Tensor, positions: torch.Tensor, forward_batch: ForwardBatch, input_embeds: torch.Tensor, get_embedding: bool)
         ‚Üí torch.Tensor

  L 229: load_weights(self, weights: Iterable[Tuple[str, torch.Tensor]])


============================================================
FILE: python/sglang/srt/models/siglip.py
Functions: 14
============================================================


CLASS: SiglipEncoder
----------------------------------------
  L 176: __init__(self, config: SiglipVisionConfig, quant_config: Optional[QuantizationConfig], prefix: str)
         ‚Üí None

  L 201: forward(self, inputs_embeds: torch.Tensor, attention_mask: torch.Tensor, causal_attention_mask: torch.Tensor, return_all_hidden_states: bool)
         ‚Üí Union[torch.Tensor, list[torch.Tensor]]


CLASS: SiglipEncoderLayer
----------------------------------------
  L  95: __init__(self, config: SiglipVisionConfig, act_layer: Type[nn.Module], norm_layer: Type[nn.Module], attn_implementation: Optional[str], quant_config: Optional[QuantizationConfig], prefix: str)
         ‚Üí None

  L 136: forward(self, hidden_states: torch.Tensor, attention_mask: torch.Tensor, causal_attention_mask: torch.Tensor)
         ‚Üí torch.Tensor


CLASS: SiglipMLP
----------------------------------------
  L  63: __init__(self, config, act_layer: Type[nn.Module], quant_config: Optional[QuantizationConfig], prefix: str)

  L  85: forward(self, x: torch.Tensor)
         ‚Üí torch.Tensor


CLASS: SiglipVisionEmbeddings
----------------------------------------
  L  22: __init__(self, config: SiglipVisionConfig)

  L  48: forward(self, pixel_values: torch.Tensor)
         ‚Üí torch.Tensor


CLASS: SiglipVisionModel
----------------------------------------
  L 278: __init__(self, config: SiglipVisionConfig, quant_config: Optional[QuantizationConfig], prefix: str)

  L 290: device(self)
         ‚Üí torch.device

  L 293: forward(self, pixel_values: torch.Tensor)


CLASS: SiglipVisionTransformer
----------------------------------------
  L 225: __init__(self, config: SiglipVisionConfig, quant_config: Optional[QuantizationConfig], prefix: str)
         ‚Üí None

  L 255: device(self)
         ‚Üí torch.device

  L 258: forward(self, pixel_values: torch.Tensor)
         ‚Üí torch.Tensor


============================================================
FILE: python/sglang/srt/models/stablelm.py
Functions: 11
============================================================


CLASS: StableLMEpochModel
----------------------------------------
  L 215: __init__(self, config: PretrainedConfig, quant_config: Optional[QuantizationConfig], prefix: str)
         ‚Üí None

  L 241: forward(self, input_ids: torch.Tensor, positions: torch.Tensor, forward_batch: ForwardBatch, input_embeds: torch.Tensor)
         ‚Üí torch.Tensor


CLASS: StableLmForCausalLM
----------------------------------------
  L 264: __init__(self, config: PretrainedConfig, quant_config: Optional[QuantizationConfig], prefix: str)
         ‚Üí None

  L 282: forward(self, input_ids: torch.Tensor, positions: torch.Tensor, forward_batch: ForwardBatch, input_embeds: torch.Tensor)
         ‚Üí torch.Tensor

  L 294: load_weights(self, weights: Iterable[Tuple[str, torch.Tensor]])


CLASS: StablelmAttention
----------------------------------------
  L  83: __init__(self, config: PretrainedConfig, layer_id: int, quant_config: Optional[QuantizationConfig], prefix: str)
         ‚Üí None

  L 156: forward(self, positions: torch.Tensor, hidden_states: torch.Tensor, forward_batch: ForwardBatch)
         ‚Üí torch.Tensor


CLASS: StablelmDecoderLayer
----------------------------------------
  L 171: __init__(self, config: PretrainedConfig, layer_id: int, quant_config: Optional[QuantizationConfig], prefix: str)
         ‚Üí None

  L 189: forward(self, positions: torch.Tensor, hidden_states: torch.Tensor, forward_batch: ForwardBatch)
         ‚Üí Tuple[torch.Tensor, torch.Tensor]


CLASS: StablelmMLP
----------------------------------------
  L  49: __init__(self, config: PretrainedConfig, quant_config: Optional[QuantizationConfig], prefix: str)
         ‚Üí None

  L  75: forward(self, x: torch.Tensor)
         ‚Üí torch.Tensor


============================================================
FILE: python/sglang/srt/models/step3_vl.py
Functions: 32
============================================================

MODULE FUNCTIONS:
----------------------------------------
  L 496: def get_abs_pos(abs_pos, tgt_size)


CLASS: Step3TextAttention
----------------------------------------
  L 173: __init__(self, hidden_size: int, num_heads: int, num_kv_heads: int, head_dim: int, share_q_dim: int, layer_id: int, rope_theta: float, rope_scaling: Optional[Dict[str, Any]], max_position_embeddings: int, quant_config: Optional[QuantizationConfig], rms_norm_eps, prefix: str)
         ‚Üí None

  L 267: forward(self, positions: torch.Tensor, hidden_states: torch.Tensor, forward_batch: ForwardBatch)
         ‚Üí torch.Tensor


CLASS: Step3TextDecoderLayer
----------------------------------------
  L 284: __init__(self, config: Step3TextConfig, layer_id: int, quant_config: Optional[QuantizationConfig], prefix: str)
         ‚Üí None

  L 388: moe_mlp_forward(self, hidden_states)

  L 397: forward(self, positions: torch.Tensor, hidden_states: torch.Tensor, forward_batch: ForwardBatch, residual: Optional[torch.Tensor])
         ‚Üí Tuple[torch.Tensor, torch.Tensor]


CLASS: Step3TextMLP
----------------------------------------
  L  75: __init__(self, hidden_size: int, intermediate_size: int, hidden_act: str, quant_config: Optional[QuantizationConfig], prefix: str)
         ‚Üí None

  L 105: forward(self, x)


CLASS: Step3TextMoEMLP
----------------------------------------
  L 114: __init__(self, layer_id: int, config: Step3TextConfig, quant_config: Optional[QuantizationConfig], prefix: str)

  L 157: forward(self, hidden_states: torch.Tensor)
         ‚Üí torch.Tensor


CLASS: Step3TextModel
----------------------------------------
  L 432: __init__(self, config: PretrainedConfig, quant_config: Optional[QuantizationConfig], prefix: str)
         ‚Üí None

  L 461: get_input_embeddings(self)

  L 464: forward(self, input_ids: torch.Tensor, positions: torch.Tensor, forward_batch: ForwardBatch, input_embeds: torch.Tensor)
         ‚Üí torch.Tensor


CLASS: Step3VLForConditionalGeneration
----------------------------------------
  L 739: __init__(self, config: Step3VLConfig, quant_config: Optional[QuantizationConfig], prefix: str)
         ‚Üí None

  L 815: get_image_feature(self, items: List[MultimodalDataItem])
         ‚Üí torch.Tensor

  L 858: pad_input_ids(self, input_ids: List[int], mm_inputs: MultimodalInputs)

  L 863: forward(self, input_ids: torch.Tensor, positions: torch.Tensor, forward_batch: ForwardBatch, input_embeds: torch.Tensor)
         ‚Üí torch.Tensor

  L 884: load_weights(self, weights: Iterable[Tuple[str, torch.Tensor]])

  L 997: get_model_config_for_expert_location(cls, config: Step3VLConfig)


CLASS: Step3VisionAttention
----------------------------------------
  L 572: __init__(self, dim: int, num_heads: int, qkv_backend, quant_config, prefix: str)
         ‚Üí None

  L 605: forward(self, hidden_states: torch.Tensor)
         ‚Üí torch.Tensor


CLASS: Step3VisionEmbeddings
----------------------------------------
  L 612: __init__(self, config: Step3VisionEncoderConfig)

  L 641: forward(self, pixel_values: torch.Tensor)
         ‚Üí torch.Tensor


CLASS: Step3VisionEncoder
----------------------------------------
  L 716: __init__(self, config: Step3VisionEncoderConfig)

  L 723: forward(self, inputs_embeds)
         ‚Üí torch.Tensor


CLASS: Step3VisionEncoderLayer
----------------------------------------
  L 665: __init__(self, config, attn_implementation: str)
         ‚Üí None

  L 680: forward(self, hidden_states)
         ‚Üí torch.Tensor


CLASS: Step3VisionMLP
----------------------------------------
  L 529: __init__(self, dim: int, intermediate_size: int, bias: bool, hidden_act, quant_config: Optional[QuantizationConfig], prefix: str)
         ‚Üí None

  L 564: forward(self, hidden_states)
         ‚Üí torch.Tensor


CLASS: Step3VisionTransformer
----------------------------------------
  L 687: __init__(self, config: Step3VisionEncoderConfig)

  L 695: dtype(self)
         ‚Üí torch.dtype

  L 698: forward(self, pixel_values: torch.Tensor)


============================================================
FILE: python/sglang/srt/models/torch_native_llama.py
Functions: 16
============================================================

MODULE FUNCTIONS:
----------------------------------------
  L  73: def gate_up_proj_weight_loader(self,
        param: Parameter,
        loaded_weight: torch.Tensor,
        loaded_shard_id: int)

  L 142: def qkv_proj_weight_loader(self,
        param: Parameter,
        loaded_weight: torch.Tensor,
        loaded_shard_id: str)


CLASS: LlamaAttention
----------------------------------------
  L 180: __init__(self, config: LlamaConfig, hidden_size: int, num_heads: int, num_kv_heads: int, layer_id: int, rope_theta: float, rope_scaling: Optional[Dict[str, Any]], rope_is_neox_style: bool, max_position_embeddings: int, quant_config: Optional[QuantizationConfig], prefix: str)
         ‚Üí None

  L 253: forward(self, positions: torch.Tensor, hidden_states: torch.Tensor, forward_batch: ForwardBatch)
         ‚Üí torch.Tensor


CLASS: LlamaDecoderLayer
----------------------------------------
  L 268: __init__(self, config: LlamaConfig, layer_id: int, quant_config: Optional[QuantizationConfig], prefix: str)
         ‚Üí None

  L 312: forward(self, positions: torch.Tensor, hidden_states: torch.Tensor, forward_batch: ForwardBatch, residual: Optional[torch.Tensor])
         ‚Üí Tuple[torch.Tensor, torch.Tensor]


CLASS: LlamaMLP
----------------------------------------
  L 108: __init__(self, hidden_size: int, intermediate_size: int, hidden_act: str, quant_config: Optional[QuantizationConfig], prefix: str)
         ‚Üí None

  L 135: forward(self, x)


CLASS: LlamaModel
----------------------------------------
  L 338: __init__(self, config: LlamaConfig, quant_config: Optional[QuantizationConfig])
         ‚Üí None

  L 361: forward(self, input_ids: torch.Tensor, positions: torch.Tensor, forward_batch: ForwardBatch, input_embeds: torch.Tensor)
         ‚Üí torch.Tensor


CLASS: TorchNativeLlamaForCausalLM
----------------------------------------
  L 386: __init__(self, config: LlamaConfig, quant_config: Optional[QuantizationConfig])
         ‚Üí None

  L 407: forward(self, input_ids: torch.Tensor, positions: torch.Tensor, forward_batch: ForwardBatch, input_embeds: torch.Tensor)
         ‚Üí LogitsProcessorOutput

  L 419: get_module_name_from_weight_name(self, name)

  L 436: get_num_params(self)

  L 440: load_weights_to_module(self, fqn: str, weights: Iterable[Tuple[str, torch.Tensor]])
         üìù Load weights onto submodule pointed by path `fqn`.

  L 488: load_weights(self, weights: Iterable[Tuple[str, torch.Tensor]])
         üìù Load weights onto the full model.


============================================================
FILE: python/sglang/srt/models/transformers.py
Functions: 11
============================================================

MODULE FUNCTIONS:
----------------------------------------
  L  46: def maybe_prefix(prefix: str, name: str)
         ‚Üí str
         üìù Add a prefix to a name if the prefix is non-empty.
            Args:
            prefix: The prefix to add. If empty, no prefix will be added.
            name: The name to potentially prefix.
            Returns:
            The string "prefix.name" if prefix was non-empty, otherwise just "name".

  L  59: def sglang_flash_attention_forward(module: torch.nn.Module,
        query: torch.Tensor,
        key: torch.Tensor,
        value: torch.Tensor,
        attention_mask: torch.Tensor,
        forward_batch: ForwardBatch,
        scaling: float,
        attention_instances: list[RadixAttention])

  L  97: def replace_linear_class(linear: nn.Linear,
        style: Literal['colwise',
        'rowwise'],
        quant_config: QuantizationConfig)
         ‚Üí Union[ColumnParallelLinear, RowParallelLinear]
         üìù Replace nn.Linear with one of vLLM's tensor parallel linear classes.
            Args:
            linear (nn.Linear): `nn.Linear` to be replaced.
            style (str): Tensor parallel style of the new linear, e.g. "colwise".
            quant_config (QuantConfig): Quantization config for the new linear.
            Returns:
            Union[ColumnParallelLinear, RowParallelLinear]: The new linear.


CLASS: HFColumnParallelLinear
----------------------------------------
  L  87: forward(self, input: torch.Tensor)
         ‚Üí torch.Tensor


CLASS: HFRowParallelLinear
----------------------------------------
  L  93: forward(self, input: torch.Tensor)
         ‚Üí torch.Tensor


CLASS: TransformersForCausalLM
----------------------------------------
  L 143: __init__(self, config: PretrainedConfig, quant_config: Optional[QuantizationConfig], prefix: str)
         ‚Üí None

  L 206: log_replacement(self, name: str, old_module: nn.Module, new_module: nn.Module)

  L 209: tensor_parallel(self, tp_size: int)
         üìù Apply the model's tensor parallelization plan.
            Currently only supports linear layers.

  L 238: replace_vocab_embed_class(self, module: nn.Module)

  L 252: forward(self, input_ids: torch.Tensor, positions: torch.Tensor, forward_batch: ForwardBatch, input_embeds: torch.Tensor, get_embedding: bool)
         ‚Üí LogitsProcessorOutput

  L 277: load_weights(self, weights: Iterable[Tuple[str, torch.Tensor]])


============================================================
FILE: python/sglang/srt/models/vila.py
Functions: 12
============================================================


CLASS: DownSample3x3BlockFix
----------------------------------------
  L  94: forward(self, x: Tensor)
         ‚Üí Tensor
         üìù Args:
            x: The input tensor of shape (batch_size, sequence_length, mm_hidden_size).
            Returns:
            The output tensor of shape (batch_size, image_pad_len, mm_hidden_size * 9).


CLASS: MultimodalProjector
----------------------------------------
  L 130: __init__(self, config: VILAConfig)

  L 160: device(self)
         ‚Üí torch.device

  L 164: dtype(self)
         ‚Üí torch.dtype

  L 167: forward(self, x: Tensor)
         ‚Üí Tensor
         üìù Args:
            x: The input tensor of shape (batch_size, sequence_length, mm_hidden_size).
            Returns:
            The output tensor of shape (batch_size, image_pad_len, hidden_size).


CLASS: VILAConfig
----------------------------------------
  L  56: __init__(self, text_config: Optional[Dict[str, Any]], vision_config: Optional[Dict[str, Any]])


CLASS: VILAForConditionalGeneration
----------------------------------------
  L 193: __init__(self, config: VILAConfig, quant_config: Optional[QuantizationConfig], prefix: str)
         ‚Üí None

  L 216: dtype(self)
         ‚Üí torch.dtype

  L 219: forward(self, input_ids: Tensor, positions: Tensor, forward_batch: ForwardBatch, get_embedding: bool)
         ‚Üí LogitsProcessorOutput

  L 239: get_image_feature(self, mm_input: List[MultimodalDataItem])
         ‚Üí Tensor

  L 265: load_weights(self, weights: Iterable[Tuple[str, Tensor]])
         ‚Üí None

  L 278: pad_input_ids(self, input_ids: List[int], mm_inputs: MultimodalInputs)
         ‚Üí List[int]


============================================================
FILE: python/sglang/srt/models/xverse.py
Functions: 11
============================================================


CLASS: XverseAttention
----------------------------------------
  L  85: __init__(self, config: LlamaConfig, hidden_size: int, num_heads: int, num_kv_heads: int, layer_id: int, rope_theta: float, rope_scaling: Optional[Dict[str, Any]], rope_is_neox_style: bool, max_position_embeddings: int, quant_config: Optional[QuantizationConfig], prefix: str)
         ‚Üí None

  L 160: forward(self, positions: torch.Tensor, hidden_states: torch.Tensor, forward_batch: ForwardBatch)
         ‚Üí torch.Tensor


CLASS: XverseDecoderLayer
----------------------------------------
  L 175: __init__(self, config: LlamaConfig, layer_id: int, quant_config: Optional[QuantizationConfig], prefix: str)
         ‚Üí None

  L 222: forward(self, positions: torch.Tensor, hidden_states: torch.Tensor, forward_batch: ForwardBatch, residual: Optional[torch.Tensor])
         ‚Üí Tuple[torch.Tensor, torch.Tensor]


CLASS: XverseForCausalLM
----------------------------------------
  L 302: __init__(self, config: LlamaConfig, quant_config: Optional[QuantizationConfig], prefix: str)
         ‚Üí None

  L 320: forward(self, input_ids: torch.Tensor, positions: torch.Tensor, forward_batch: ForwardBatch, input_embeds: torch.Tensor)
         ‚Üí torch.Tensor

  L 332: load_weights(self, weights: Iterable[Tuple[str, torch.Tensor]], name, loaded_weight)


CLASS: XverseMLP
----------------------------------------
  L  47: __init__(self, hidden_size: int, intermediate_size: int, hidden_act: str, quant_config: Optional[QuantizationConfig], prefix: str)
         ‚Üí None

  L  77: forward(self, x)


CLASS: XverseModel
----------------------------------------
  L 248: __init__(self, config: LlamaConfig, quant_config: Optional[QuantizationConfig], prefix: str)
         ‚Üí None

  L 276: forward(self, input_ids: torch.Tensor, positions: torch.Tensor, forward_batch: ForwardBatch, input_embeds: torch.Tensor)
         ‚Üí torch.Tensor


============================================================
FILE: python/sglang/srt/models/xverse_moe.py
Functions: 14
============================================================


CLASS: XverseAttention
----------------------------------------
  L 195: __init__(self, hidden_size: int, num_heads: int, num_kv_heads: int, layer_id: int, rope_theta: float, rope_scaling: Optional[Dict[str, Any]], max_position_embeddings: int, quant_config: Optional[QuantizationConfig], prefix: str)
         ‚Üí None

  L 265: forward(self, positions: torch.Tensor, hidden_states: torch.Tensor, forward_batch: ForwardBatch)
         ‚Üí torch.Tensor


CLASS: XverseDecoderLayer
----------------------------------------
  L 281: __init__(self, config: PretrainedConfig, layer_id: int, quant_config: Optional[QuantizationConfig], prefix: str)
         ‚Üí None

  L 326: forward(self, positions: torch.Tensor, hidden_states: torch.Tensor, forward_batch: ForwardBatch, residual: Optional[torch.Tensor])
         ‚Üí torch.Tensor


CLASS: XverseMLP
----------------------------------------
  L  53: __init__(self, hidden_size: int, intermediate_size: int, hidden_act: str, quant_config: Optional[QuantizationConfig], reduce_results: bool, prefix: str)
         ‚Üí None

  L  85: forward(self, x)


CLASS: XverseMoE
----------------------------------------
  L  94: __init__(self, config: PretrainedConfig, quant_config: Optional[QuantizationConfig], prefix: str)

  L 151: pack_params(self)

  L 170: forward(self, hidden_states: torch.Tensor)
         ‚Üí torch.Tensor


CLASS: XverseModel
----------------------------------------
  L 355: __init__(self, config: PretrainedConfig, quant_config: Optional[QuantizationConfig], prefix: str)
         ‚Üí None

  L 383: forward(self, input_ids: torch.Tensor, positions: torch.Tensor, forward_batch: ForwardBatch)
         ‚Üí torch.Tensor


CLASS: XverseMoeForCausalLM
----------------------------------------
  L 402: __init__(self, config: PretrainedConfig, quant_config: Optional[QuantizationConfig], prefix: str)
         ‚Üí None

  L 423: forward(self, input_ids: torch.Tensor, positions: torch.Tensor, forward_batch: ForwardBatch)
         ‚Üí torch.Tensor

  L 434: load_weights(self, weights: Iterable[Tuple[str, torch.Tensor]])


============================================================
FILE: python/sglang/srt/models/yivl.py
Functions: 4
============================================================


CLASS: YiVLForCausalLM
----------------------------------------
  L  28: __init__(self, config: LlavaConfig, quant_config: Optional[QuantizationConfig], prefix: str)
         ‚Üí None

  L  41: load_weights(self, weights: Iterable[Tuple[str, torch.Tensor]])


CLASS: YiVLMultiModalProjector
----------------------------------------
  L  93: __init__(self, config: LlavaConfig)

  L 106: forward(self, image_features)


============================================================
FILE: python/sglang/srt/multimodal/mm_utils.py
Functions: 11
============================================================

MODULE FUNCTIONS:
----------------------------------------
  L  42: def has_valid_data(data)
         ‚Üí bool

  L  50: def select_best_resolution(original_size, possible_resolutions)
         üìù Selects the best resolution from a list of possible resolutions based on the original size.
            Args:
            original_size (tuple): The original size of the image in the format (width, height).
            possible_resolutions (list): A list of possible resolutions in the format [(width1, height1), (width2, height2), ...].
            Returns:
            tuple: The best fit resolution in the format (width, height).

  L  90: def resize_and_pad_image(image, target_resolution)
         üìù Resize and pad an image to a target resolution while maintaining aspect ratio.
            Args:
            image (PIL.Image.Image): The input image.
            target_resolution (tuple): The target resolution (width, height) of the image.
            Returns:
            PIL.Image.Image: The resized and padded image.

  L 125: def divide_to_patches(image, patch_size)
         üìù Divides an image into patches of a specified size.
            Args:
            image (PIL.Image.Image): The input image.
            patch_size (int): The size of each patch.
            Returns:
            list: A list of PIL.Image.Image objects representing the patches.

  L 147: def get_anyres_image_grid_shape(image_size, grid_pinpoints, patch_size)
         üìù Calculate the shape of the image patch grid after the preprocessing for images of any resolution.
            Args:
            image_size (tuple): The size of the input image in the format (width, height).
            grid_pinpoints (str): A string representation of a list of possible resolutions.
            patch_size (int): The size of each image patch.
            Returns:
            tuple: The shape of the image patch grid in the format (width, height).

  L 187: def process_anyres_image(image, processor, grid_pinpoints)
         üìù Process an image with variable resolutions.
            Args:
            image (PIL.Image.Image): The input image to be processed.
            processor: The image processor object.
            grid_pinpoints (str): A string representation of a list of possible resolutions.
            Returns:
            np.array: An np array containing the processed image patches.

  L 254: def load_image_from_base64(image)

  L 258: def expand2square(pil_img, background_color)

  L 274: def unpad_image(tensor, original_size)
         üìù Unpads a PyTorch tensor of a padded and resized image.
            Args:
            tensor (torch.Tensor): The image tensor, assumed to be in CxHxW format.
            original_size (tuple): The original size of the image (height, width).
            Returns:
            torch.Tensor: The unpadded image tensor.

  L 305: def unpad_image_shape(current_height, current_width, original_size)
         üìù Unpads a PyTorch tensor of a padded and resized image
            and returns the new shape.

  L 329: def process_images(images, image_processor, model_cfg)


============================================================
FILE: python/sglang/srt/multimodal/processors/base_processor.py
Functions: 18
============================================================


CLASS: BaseMultiModalProcessorOutput
----------------------------------------
  L  41: organize_results(self)
         ‚Üí List[Tuple[Modality, Any]]
         üìù :return: a list of results, with their corresponding modalities


CLASS: BaseMultimodalProcessor
----------------------------------------
  L 153: __init__(self, hf_config, server_args, _processor, transport_mode)

  L 211: process_mm_data(self, input_text, images, videos, audios)
         ‚Üí dict
         üìù process multimodal data with transformers AutoProcessor

  L 254: process_mm_data_async(self, image_data, audio_data, input_text, request_obj)
         ‚Üí Optional[Dict[str, Any]]

  L 264: get_estimated_frames_list(self, image_data)
         üìù estimate the total frame count from all visual input

  L 316: submit_data_loading_tasks(self, text_parts: List[str], multimodal_tokens: MultimodalSpecialTokens, data_iterators: dict[Modality, Iterator[Any]], discard_alpha_channel: bool, image_estimated_frames_iter: Optional[iter], image_scaling_factor: float, max_image_frames: int, audio_sample_rate: Optional[int])
         ‚Üí Tuple[List, List]
         üìù load multimodal data parallelly using iterators.

  L 387: load_mm_data(self, prompt: str, multimodal_tokens: MultimodalSpecialTokens, image_data: Optional[list], video_data: Optional[list], audio_data: Optional[list], return_text: Optional[bool], discard_alpha_channel: bool, audio_sample_rate: Optional[int])
         ‚Üí BaseMultiModalProcessorOutput
         üìù Each frame of video/image will be replaced by a single image token
            Args:
            multimodal_tokens (list[str]): list of special token which denoting a single multimodal data
            e.g. image token or audio token
            discard_alpha_channel: if True, discards the alpha channel in the returned images

  L 500: get_mm_items_offset(input_ids: torch.Tensor, mm_token_id: int)
         ‚Üí List[Tuple[int, int]]
         üìù Get a set of range for mm_items from input_ids
            Example:
            input_ids = [1, 2, 3, 3, 3, 4, 3, 3]
            mm_token_id = 3
            return result = [(2,4),(6,7)]

  L 517: get_mm_items_offset_by_pair(input_ids: torch.Tensor, mm_start_id: int, mm_end_id: int)
         ‚Üí List[Tuple[int, int]]

  L 525: collect_mm_items_from_processor_output(self, data_dict: dict)
         ‚Üí List[MultimodalDataItem]
         üìù Create mm_items directly from processor output.

  L 576: process_and_combine_mm_data(self, base_output: BaseMultiModalProcessorOutput, mm_tokens: MultimodalSpecialTokens)
         ‚Üí Tuple[List[MultimodalDataItem], torch.Tensor, dict]
         üìù Process multimodal data and return the combined multimodal items and input_ids.
            Supports mixed modalities (images and audio in the same request).
            Returns:
            Tuple of (list of mm_items, input_ids)


CLASS: MultimodalSpecialTokens
----------------------------------------
  L  69: build(self, processor)

  L  75: convert_to_str(self, token: Union[str, int], processor)
         ‚Üí str

  L  82: convert_to_strs(self, processor)

  L  90: get_modality_of_token(self, token: str)
         ‚Üí Optional[Modality]
         üìù :return: the modality associated with the given token, if the token is a special_token or matches with the multimodal token regex

  L 112: get_token_id_by_modality(self, modality: Modality)
         ‚Üí Optional[int]

  L 120: parse_regex(self)

  L 128: get_combined_regex(self)
         ‚Üí re.Pattern
         üìù Builds and returns a regex, used to split input str into tokens (with mm special tokens)


============================================================
FILE: python/sglang/srt/multimodal/processors/clip.py
Functions: 2
============================================================


CLASS: ClipImageProcessor
----------------------------------------
  L  13: __init__(self, hf_config, server_args, _processor)

  L  19: process_mm_data_async(self, image_data: List[Union[str, bytes]], input_text)


============================================================
FILE: python/sglang/srt/multimodal/processors/deepseek_vl_v2.py
Functions: 2
============================================================


CLASS: DeepseekVL2ImageProcessor
----------------------------------------
  L  34: __init__(self, hf_config, server_args, _processor)

  L  40: process_mm_data_async(self, image_data: List[Union[str, bytes]], input_text, request_obj, max_req_input_len)


============================================================
FILE: python/sglang/srt/multimodal/processors/gemma3.py
Functions: 2
============================================================


CLASS: Gemma3SGLangImageProcessor
----------------------------------------
  L  17: __init__(self, hf_config, server_args, _processor)

  L  31: process_mm_data_async(self, image_data: List[Union[str, bytes, Dict]], input_text, request_obj)


============================================================
FILE: python/sglang/srt/multimodal/processors/gemma3n.py
Functions: 2
============================================================


CLASS: Gemma3nSGLangProcessor
----------------------------------------
  L  29: __init__(self, hf_config, server_args, _processor)

  L  44: process_mm_data_async(self, image_data: Optional[List[Union[str, bytes, Dict]]], audio_data: Optional[List[Union[str, bytes, Dict]]], input_text: str, request_obj)
         üìù Process multimodal data including images and audio.


============================================================
FILE: python/sglang/srt/multimodal/processors/glm4v.py
Functions: 3
============================================================


CLASS: Glm4vImageProcessor
----------------------------------------
  L  22: __init__(self, hf_config, server_args, _processor)

  L  55: preprocess_video(self, vr: VideoReader)
         üìù Preprocess video using VideoReader from Decord backend.
            Args:
            vr (VideoReader): VideoReader object from decord
            Returns:
            tuple: A tuple containing processed frames and metadata

  L  83: process_mm_data_async(self, image_data: List[Union[str, bytes]], input_text, request_obj)


============================================================
FILE: python/sglang/srt/multimodal/processors/internvl.py
Functions: 6
============================================================


CLASS: InternVLImageProcessor
----------------------------------------
  L  20: __init__(self, hf_config, server_args, _image_processor)

  L  52: build_transform(input_size)

  L  81: dynamic_preprocess(image, min_num, max_num, image_size, use_thumbnail)

  L 145: get_index(bound, fps, max_frame, first_idx, num_segments)

  L 162: load_video(video_path, bound, input_size, max_num, num_segments)

  L 184: process_mm_data_async(self, image_data, input_text, request_obj)


============================================================
FILE: python/sglang/srt/multimodal/processors/janus_pro.py
Functions: 2
============================================================


CLASS: JanusProImageProcessor
----------------------------------------
  L  14: __init__(self, hf_config, server_args, _processor)

  L  22: process_mm_data_async(self, image_data: List[Union[str, bytes]], input_text, request_obj)


============================================================
FILE: python/sglang/srt/multimodal/processors/kimi_vl.py
Functions: 2
============================================================


CLASS: KimiVLImageProcessor
----------------------------------------
  L  15: __init__(self, hf_config, server_args, _processor)

  L  24: process_mm_data_async(self, image_data: List[Union[str, bytes, Dict]], input_text, request_obj)


============================================================
FILE: python/sglang/srt/multimodal/processors/llava.py
Functions: 4
============================================================


CLASS: LlavaImageProcessor
----------------------------------------
  L  33: __init__(self, hf_config, server_args, _processor)

  L 109: process_mm_data_async(self, image_data: List[Union[str, bytes, ImageData]], input_text, request_obj)


CLASS: LlavaMultimodalProcessor
----------------------------------------
  L 194: __init__(self, hf_config, server_args, _processor)

  L 210: process_mm_data_async(self)


============================================================
FILE: python/sglang/srt/multimodal/processors/minicpm.py
Functions: 2
============================================================


CLASS: MiniCPMMultimodalProcessor
----------------------------------------
  L  18: __init__(self, hf_config, server_args, _processor)

  L  36: process_mm_data_async(self, image_data: List[Union[str, bytes]], audio_data: List[Union[str, bytes]], input_text, request_obj)


============================================================
FILE: python/sglang/srt/multimodal/processors/mlama.py
Functions: 2
============================================================


CLASS: MllamaImageProcessor
----------------------------------------
  L  13: __init__(self, hf_config, server_args, _processor)

  L  20: process_mm_data_async(self, image_data: List[Union[str, bytes]], input_text)


============================================================
FILE: python/sglang/srt/multimodal/processors/mllama4.py
Functions: 2
============================================================


CLASS: Mllama4ImageProcessor
----------------------------------------
  L  21: __init__(self, hf_config, server_args, _processor)

  L  33: process_mm_data_async(self, image_data: List[Union[str, bytes]], input_text)


============================================================
FILE: python/sglang/srt/multimodal/processors/phi4mm.py
Functions: 4
============================================================


CLASS: Phi4MMMultimodalProcessor
----------------------------------------
  L  50: __init__(self, hf_config, server_args, _processor)

  L  69: process_mm_data_async(self, image_data: List[Union[str, bytes]], audio_data, input_text, request_obj)


CLASS: Phi4MMProcessorAdapter
----------------------------------------
  L  19: __init__(self, _processor)
         ‚Üí None

  L  22: __call__(self)


============================================================
FILE: python/sglang/srt/multimodal/processors/pixtral.py
Functions: 3
============================================================


CLASS: PixtralProcessor
----------------------------------------
  L  23: get_patch_grid_size(self)
         ‚Üí tuple[int, int]

  L  45: __init__(self, hf_config, server_args, _processor)

  L  73: process_mm_data_async(self, image_data: List[Union[str, bytes]], input_text, request_obj)


============================================================
FILE: python/sglang/srt/multimodal/processors/qwen_audio.py
Functions: 2
============================================================


CLASS: Qwen2AudioMultimodalProcessor
----------------------------------------
  L  14: __init__(self, hf_config, server_args, _processor)

  L  34: process_mm_data_async(self, audio_data, input_text)


============================================================
FILE: python/sglang/srt/multimodal/processors/qwen_vl.py
Functions: 10
============================================================

MODULE FUNCTIONS:
----------------------------------------
  L  37: def smart_resize(height: int,
        width: int,
        factor: int,
        min_pixels: int,
        max_pixels: int)
         ‚Üí tuple[int, int]
         üìù Rescales the image so that the following conditions are met:
            1. Both dimensions (height and width) are divisible by 'factor'.
            2. The total number of pixels is within the range ['min_pixels', 'max_pixels'].
            3. The aspect ratio of the image is maintained as closely as possible.

  L  70: def resize_image(image, size_factor: int)
         ‚Üí Image.Image

  L  85: def round_by_factor(number: int, factor: int)
         ‚Üí int
         üìù Returns the closest integer to 'number' that is divisible by 'factor'.

  L  90: def ceil_by_factor(number: int, factor: int)
         ‚Üí int
         üìù Returns the smallest integer greater than or equal to 'number' that is divisible by 'factor'.

  L  95: def floor_by_factor(number: int, factor: int)
         ‚Üí int
         üìù Returns the largest integer less than or equal to 'number' that is divisible by 'factor'.

  L 100: async def resize_image_async(image)

  L 104: def smart_nframes(ele: dict, total_frames: int, video_fps: int | float)
         ‚Üí int
         üìù calculate the number of frames for video used for model inputs.
            Args:
            ele (dict): a dict contains the configuration of video.
            support either `fps` or `nframes`:
            - nframes: the number of frames to extract for model inputs.
            - fps: the fps to extract frames for model inputs.
            - min_frames: the minimum number of frames of the video, only used when fps is provided.
            - max_frames: the maximum number of frames of the video, only used when fps is provided.
            total_frames (int): the original total number of frames of the video.
            video_fps (int | float): the original fps of the video.
            Raises:
            ValueError: nframes should in interval [FRAME_FACTOR, total_frames].
            Returns:
            int: the number of frames for video used for model inputs.

  L 153: async def preprocess_video(vr, image_factor: int)
         ‚Üí torch.Tensor


CLASS: Qwen2_5VLImageProcessor
----------------------------------------
  L 204: __init__(self, hf_config, server_args, _processor)

  L 225: process_mm_data_async(self, image_data: List[Union[str, bytes]], input_text, request_obj)


============================================================
FILE: python/sglang/srt/multimodal/processors/step3_vl.py
Functions: 21
============================================================


CLASS: GPUToTensor
----------------------------------------
  L  24: forward(self, raw_image: Union[np.ndarray, Image.Image])
         ‚Üí torch.Tensor


CLASS: ImagePatcher
----------------------------------------
  L  91: determine_window_size(self, long: int, short: int)
         ‚Üí int

  L  96: slide_window(self, width: int, height: int, sizes: list[tuple[int, int]], steps: list[tuple[int, int]], img_rate_thr: float)
         ‚Üí tuple[list[tuple[int, int, int, int]], tuple[int, int]]

  L 131: square_pad(self, img: Image.Image)
         ‚Üí Image.Image

  L 140: get_image_size_for_padding(self, img_width: int, img_height: int)
         ‚Üí tuple[int, int]

  L 149: get_image_size_for_preprocess(self, img_width: int, img_height: int)
         ‚Üí tuple[int, int]

  L 161: get_image_size_for_crop(self, img_width: int, img_height: int, window_size: int)

  L 181: patch_crop(self, img: Image.Image, i: int, j: int, th: int, tw: int)

  L 185: get_num_patches(self, img_width: int, img_height: int)
         ‚Üí tuple[int, int]

  L 210: __call__(self, img: Image.Image)
         ‚Üí tuple[Image.Image, list[Image.Image], list[bool] | None]


CLASS: Step3VLImageProcessor
----------------------------------------
  L 474: __init__(self, hf_config, server_args, _processor)

  L 488: preprocess(self, image)

  L 491: __call__(self, image)

  L 494: process_mm_data_async(self, image_data: List[Union[str, bytes]], input_text: str | List[int], request_obj)


CLASS: Step3VLProcessor
----------------------------------------
  L 271: __init__(self, config, tokenizer)
         ‚Üí None

  L 298: image_token_id(self)
         ‚Üí int

  L 301: get_num_image_tokens(self, img_width: int, img_height: int)
         ‚Üí int

  L 377: replace_placeholder(self, text: str, placeholder: str, repls: list[str])
         ‚Üí str

  L 392: __call__(self, text: Optional[Union[str, list[str]]], images: Optional[Union[Image.Image, list[Image.Image]]], return_tensors: Optional[Union[str, TensorType]])
         ‚Üí BatchFeature


CLASS: Step3VisionProcessor
----------------------------------------
  L  41: __init__(self, size, interpolation_mode, patch_size)

  L  82: __call__(self, image, is_patch)


============================================================
FILE: python/sglang/srt/multimodal/processors/vila.py
Functions: 2
============================================================


CLASS: VILAMultimodalProcessor
----------------------------------------
  L  32: __init__(self, hf_config: PretrainedConfig, server_args: ServerArgs, _processor: VILAProcessor)
         ‚Üí None

  L  47: process_mm_data_async(self, image_data: Optional[ImageDataInputItem | List[ImageDataInputItem]], input_text: str | List[int], request_obj: GenerateReqInput | EmbeddingReqInput)
         ‚Üí Optional[Dict[str, Any]]


============================================================
FILE: python/sglang/srt/offloader.py
Functions: 30
============================================================

MODULE FUNCTIONS:
----------------------------------------
  L  50: def get_offloader()

  L  55: def set_offloader(instance: BaseOffloader)

  L  60: def create_offloader_from_server_args(server_args: ServerArgs, dp_rank: int)


CLASS: BaseOffloader
----------------------------------------
  L  30: wrap_modules(self, all_modules_generator: Generator[torch.nn.Module, None, None], submodule_accessor: Optional[_SubmoduleAccessor], whitelist_param_names_creator: Optional[_WhitelistParamNamesCreator])

  L  38: post_init(self)


CLASS: OffloaderV1
----------------------------------------
  L  81: __init__(self, cpu_offload_max_bytes: int)

  L  85: wrap_modules(self, all_modules_generator: Generator[torch.nn.Module, None, None], submodule_accessor: Optional[_SubmoduleAccessor], whitelist_param_names_creator: Optional[_WhitelistParamNamesCreator])

  L  93: maybe_offload_to_cpu(self, module: torch.nn.Module)
         ‚Üí torch.nn.Module


CLASS: OffloaderV2
----------------------------------------
  L 150: __init__(self, group_size: int, num_in_group: int, prefetch_step: int, mode: str, dp_rank: int, dp_size: int)

  L 189: wrap_modules(self, all_modules_generator: Generator[torch.nn.Module, None, None], submodule_accessor: Optional[_SubmoduleAccessor], whitelist_param_names_creator: Optional[_WhitelistParamNamesCreator])

  L 229: post_init(self)


CLASS: _BaseParamOffloader
----------------------------------------
  L 322: create(mode: str)
         ‚Üí '_BaseParamOffloader'

  L 330: __init__(self, module, param_name)

  L 338: post_init(self)

  L 341: create_device_tensor(self)


CLASS: _CpuParamOffloader
----------------------------------------
  L 357: __init__(self, module, param_name)

  L 361: create_device_tensor(self)


CLASS: _MetaParamOffloader
----------------------------------------
  L 348: __init__(self, module, param_name)

  L 352: create_device_tensor(self)


CLASS: _ModuleOffloader
----------------------------------------
  L 267: __init__(self, mode: str, module: torch.nn.Module, alt_stream: torch.cuda.Stream, whitelist_param_names: List[str])

  L 296: post_init(self)

  L 300: start_onload(self)

  L 307: offload(self)

  L 311: wait_and_get_device_tensors(self)


CLASS: _ShardedGpuParamOffloader
----------------------------------------
  L 453: __init__(self, module, param_name)

  L 472: post_init(self)

  L 501: create_device_tensor(self)


CLASS: _ShmCpuParamOffloader
----------------------------------------
  L 366: __init__(self, module, param_name)

  L 389: post_init(self)

  L 397: create_device_tensor(self)


============================================================
FILE: python/sglang/srt/operations.py
Functions: 15
============================================================

MODULE FUNCTIONS:
----------------------------------------
  L  21: def execute_operations(inputs, operations)

  L  30: def execute_overlapped_operations(inputs_arr: Sequence,
        operations_arr: Sequence,
        delta_stages: Sequence[int])
         ‚Üí Sequence


CLASS: _StageExecutor
----------------------------------------
  L  76: __init__(self, debug_name: str, stages: List[Stage], inputs: dict)

  L  89: next(self)

  L 114: output(self)

  L 119: done(self)

  L 123: num_stages(self)


CLASS: _StateDict
----------------------------------------
  L 138: __init__(self)

  L 141: __setattr__(self, key, value)

  L 150: __getattr__(self, item)

  L 153: __delattr__(self, item)

  L 156: pop(self, item)

  L 159: update(self, values: Dict[str, Any])

  L 163: get(self, item)

  L 166: clear(self, expect_keys: Sequence[str])


============================================================
FILE: python/sglang/srt/operations_strategy.py
Functions: 2
============================================================


CLASS: OperationsStrategy
----------------------------------------
  L  19: concat(cls, items: List['OperationsStrategy'])
         ‚Üí 'OperationsStrategy'

  L  31: init_new_tbo(layers: torch.nn.ModuleList, forward_mode: ForwardMode)
         ‚Üí 'OperationsStrategy'


============================================================
FILE: python/sglang/srt/patch_torch.py
Functions: 2
============================================================

MODULE FUNCTIONS:
----------------------------------------
  L  21: def monkey_patch_torch_reductions()
         üìù Monkey patching before Torch https://github.com/pytorch/pytorch/pull/149248 is fixed

  L  75: def monkey_patch_torch_compile()


============================================================
FILE: python/sglang/srt/poll_based_barrier.py
Functions: 3
============================================================


CLASS: PollBasedBarrier
----------------------------------------
  L   7: __init__(self, noop: bool)

  L  11: local_arrive(self)

  L  15: poll_global_arrived(self)
         ‚Üí bool


============================================================
FILE: python/sglang/srt/reasoning_parser.py
Functions: 13
============================================================


CLASS: BaseReasoningFormatDetector
----------------------------------------
  L  22: __init__(self, think_start_token: str, think_end_token: str, force_reasoning: bool, stream_reasoning: bool)

  L  37: detect_and_parse(self, text: str)
         ‚Üí StreamingParseResult
         üìù One-time parsing: Detects and parses reasoning sections in the provided text.
            Returns both reasoning content and normal text separately.

  L  63: parse_streaming_increment(self, new_text: str)
         ‚Üí StreamingParseResult
         üìù Streaming incremental parsing for reasoning content.
            Handles partial reasoning tags and content.
            If stream_reasoning is False:
            Accumulates reasoning content until the end tag is found
            If stream_reasoning is True:
            Streams reasoning content as it arrives


CLASS: DeepSeekR1Detector
----------------------------------------
  L 141: __init__(self, stream_reasoning: bool, force_reasoning: bool)


CLASS: GptOssDetector
----------------------------------------
  L 200: __init__(self, stream_reasoning: bool, force_reasoning: bool)

  L 209: detect_and_parse(self, text: str)
         ‚Üí StreamingParseResult

  L 232: parse_streaming_increment(self, new_text: str)
         ‚Üí StreamingParseResult


CLASS: KimiDetector
----------------------------------------
  L 186: __init__(self, stream_reasoning: bool, force_reasoning: bool)


CLASS: Qwen3Detector
----------------------------------------
  L 168: __init__(self, stream_reasoning: bool, force_reasoning: bool)


CLASS: ReasoningParser
----------------------------------------
  L 275: __init__(self, model_type: Optional[str], stream_reasoning: bool, force_reasoning: Optional[bool])

  L 299: parse_non_stream(self, full_text: str)
         ‚Üí Tuple[Optional[str], Optional[str]]
         üìù Non-streaming call: one-time parsing

  L 304: parse_stream_chunk(self, chunk_text: str)
         ‚Üí Tuple[Optional[str], Optional[str]]
         üìù Streaming call: incremental parsing


CLASS: StreamingParseResult
----------------------------------------
  L  10: __init__(self, normal_text: Optional[str], reasoning_text: Optional[str])


============================================================
FILE: python/sglang/srt/sampling/custom_logit_processor.py
Functions: 4
============================================================


CLASS: CustomLogitProcessor
----------------------------------------
  L  23: __call__(self, logits: torch.Tensor, custom_param_list: Optional[List[Dict[str, Any]]])
         ‚Üí torch.Tensor
         üìù Define the callable behavior.

  L  32: to_str(cls)
         ‚Üí str
         üìù Serialize the callable function to a JSON-compatible string.

  L  37: from_str(cls, json_str: str)
         üìù Deserialize a callable function from a JSON string.


CLASS: DisallowedTokensLogitsProcessor
----------------------------------------
  L  43: __call__(self, logits: torch.Tensor, custom_param_list: Optional[List[Dict[str, Any]]])
         ‚Üí torch.Tensor


============================================================
FILE: python/sglang/srt/sampling/penaltylib/frequency_penalty.py
Functions: 1
============================================================


CLASS: BatchedFrequencyPenalizer
----------------------------------------
  L  14: __init__(self, orchestrator: BatchedPenalizerOrchestrator)


============================================================
FILE: python/sglang/srt/sampling/penaltylib/min_new_tokens.py
Functions: 1
============================================================


CLASS: BatchedMinNewTokensPenalizer
----------------------------------------
  L  14: __init__(self, orchestrator: BatchedPenalizerOrchestrator)


============================================================
FILE: python/sglang/srt/sampling/penaltylib/orchestrator.py
Functions: 17
============================================================


CLASS: BatchedPenalizerOrchestrator
----------------------------------------
  L  14: __init__(self, vocab_size: int, batch: ScheduleBatch, penalizers: Set[Type['_BatchedPenalizer']])

  L  32: batch(self)
         ‚Üí ScheduleBatch | None

  L  36: batch(self, value: Optional[ScheduleBatch])

  L  42: reqs(self)

  L  45: cumulate_output_tokens(self, output_ids: torch.Tensor)
         üìù Feed the output tokens to the penalizers.
            Args:
            output_ids (torch.Tensor): The output tokens.

  L  55: apply(self, logits: torch.Tensor)
         ‚Üí torch.Tensor
         üìù Apply the penalizers to the logits.
            Note that it may apply the penalizers in-place.
            Args:
            logits (torch.Tensor): The logits to apply the penalizers to.
            Returns:
            torch.Tensor: The logits after applying the penalizers.

  L  69: filter(self, keep_indices: torch.Tensor)
         üìù Filter the penalizers based on the indices to keep in the batch.
            Args:
            keep_indices (torch.Tensor): Tensor of indices to keep in the batch.

  L  95: merge(self, their: 'BatchedPenalizerOrchestrator')
         üìù Merge the penalizers of another orchestrator into this one.
            Note that this function **must** be called _before_ self.batch.reqs is updated (filtered).
            Each unprepared penalizers would have to be prepared (creating tensors, etc.) first before merging.
            This step requires the original batch.reqs, before it gets merged with other batch.reqs.
            Args:
            their (BatchedPenalizerOrchestrator): The orchestrator to merge into this one.


CLASS: _BatchedPenalizer
----------------------------------------
  L 119: is_prepared(self)
         ‚Üí bool

  L 122: is_required(self)
         ‚Üí bool

  L 125: prepare(self)

  L 130: prepare_if_required(self)

  L 137: teardown(self)

  L 140: cumulate_output_tokens(self, output_ids: torch.Tensor)

  L 146: apply(self, logits: torch.Tensor)
         ‚Üí torch.Tensor

  L 152: filter(self, keep_indices: torch.Tensor)

  L 158: merge(self, their: '_BatchedPenalizer')


============================================================
FILE: python/sglang/srt/sampling/penaltylib/presence_penalty.py
Functions: 1
============================================================


CLASS: BatchedPresencePenalizer
----------------------------------------
  L  14: __init__(self, orchestrator: BatchedPenalizerOrchestrator)


============================================================
FILE: python/sglang/srt/sampling/sampling_batch_info.py
Functions: 9
============================================================

MODULE FUNCTIONS:
----------------------------------------
  L 353: def merge_bias_tensor(lhs: Optional[torch.Tensor],
        rhs: Optional[torch.Tensor],
        bs1: int,
        bs2: int,
        device: str,
        default: float)
         üìù Merge two bias tensors for batch merging.
            Args:
            lhs: Left-hand side tensor
            rhs: Right-hand side tensor
            bs1: Batch size of left-hand side tensor
            bs2: Batch size of right-hand side tensor
            device: Device to place the merged tensor on
            default: Default value for missing tensor elements
            Returns:
            Merged tensor or None if both inputs are None


CLASS: SamplingBatchInfo
----------------------------------------
  L  70: from_schedule_batch(cls, batch: ScheduleBatch, vocab_size: int)

  L 171: __len__(self)

  L 174: update_regex_vocab_mask(self)

  L 201: update_penalties(self)

  L 212: apply_logits_bias(self, logits: torch.Tensor)

  L 227: filter_batch(self, keep_indices: List[int], keep_indices_device: torch.Tensor)

  L 266: merge_custom_logit_processor(lhs: Optional[Dict[int, Tuple[CustomLogitProcessor, torch.Tensor]]], rhs: Optional[Dict[int, Tuple[CustomLogitProcessor, torch.Tensor]]], bs1: int, bs2: int, device: str)

  L 305: merge_batch(self, other: 'SamplingBatchInfo')


============================================================
FILE: python/sglang/srt/sampling/sampling_params.py
Functions: 3
============================================================


CLASS: SamplingParams
----------------------------------------
  L  31: __init__(self, max_new_tokens: int, stop: Optional[Union[str, List[str]]], stop_token_ids: Optional[List[int]], temperature: float, top_p: float, top_k: int, min_p: float, frequency_penalty: float, presence_penalty: float, repetition_penalty: float, min_new_tokens: int, n: int, json_schema: Optional[str], regex: Optional[str], ebnf: Optional[str], structural_tag: Optional[str], ignore_eos: bool, skip_special_tokens: bool, spaces_between_special_tokens: bool, no_stop_trim: bool, custom_params: Optional[Dict[str, Any]], stream_interval: Optional[int], logit_bias: Optional[Dict[str, float]])
         ‚Üí None

  L  92: verify(self, vocab_size)

  L 149: normalize(self, tokenizer)


============================================================
FILE: python/sglang/srt/server_args.py
Functions: 21
============================================================

MODULE FUNCTIONS:
----------------------------------------
  L 109: def add_load_format_choices(choices)

  L 113: def add_quantization_method_choices(choices)

  L 117: def add_attention_backend_choices(choices)

  L 121: def add_disagg_transfer_backend_choices(choices)

  L2383: def prepare_server_args(argv: List[str])
         ‚Üí ServerArgs
         üìù Prepare the server arguments from the command line arguments.
            Args:
            args: The command line arguments. Typically, it should be `sys.argv[1:]`
            to ensure compatibility with `parse_args` when no arguments are passed.
            Returns:
            The server arguments.

  L2511: def print_deprecated_warning(message: str)

  L2515: def auto_choose_speculative_params(self: ServerArgs)
         üìù Automatically choose the parameters for speculative decoding.
            You can tune them on your own models and prompts with scripts/playground/bench_speculative.py


CLASS: DeprecatedAction
----------------------------------------
  L2502: __init__(self, option_strings, dest, nargs)

  L2507: __call__(self, parser, namespace, values, option_string)


CLASS: LoRAPathAction
----------------------------------------
  L2482: __call__(self, parser, namespace, values, option_string)


CLASS: PortArgs
----------------------------------------
  L2423: init_new(server_args, dp_rank: Optional[int])
         ‚Üí 'PortArgs'


CLASS: ServerArgs
----------------------------------------
  L 385: __post_init__(self)

  L 815: add_cli_args(parser: argparse.ArgumentParser)

  L2113: from_cli_args(cls, args: argparse.Namespace)

  L2121: url(self)

  L2127: get_hf_config(self)

  L2138: check_server_args(self)

  L2179: check_lora_server_args(self)

  L2262: validate_disagg_tp_size(self, prefill_tp: int, decode_tp: int)

  L2270: model_specific_adjustments(self)

  L2344: adjust_mem_fraction_for_vlm(self, model_config)


============================================================
FILE: python/sglang/srt/speculative/build_eagle_tree.py
Functions: 3
============================================================

MODULE FUNCTIONS:
----------------------------------------
  L  17: def build_tree_kernel_efficient_preprocess(verified_id: torch.Tensor,
        score_list: List[torch.Tensor],
        token_list: List[torch.Tensor],
        parents_list: List[torch.Tensor],
        num_verify_tokens: int)

  L  51: def build_tree_kernel_efficient(verified_id: torch.Tensor,
        score_list: List[torch.Tensor],
        token_list: List[torch.Tensor],
        parents_list: List[torch.Tensor],
        seq_lens: torch.Tensor,
        seq_lens_sum: int,
        topk: int,
        spec_steps: int,
        num_verify_tokens: int,
        tree_mask_mode: TreeMaskMode,
        tree_mask_buf: Optional[torch.Tensor],
        position_buf: Optional[torch.Tensor])

  L 154: def test_build_tree_kernel_efficient()


============================================================
FILE: python/sglang/srt/speculative/eagle_draft_cuda_graph_runner.py
Functions: 5
============================================================


CLASS: EAGLEDraftCudaGraphRunner
----------------------------------------
  L  40: __init__(self, eagle_worker: EAGLEWorker)

  L 128: can_run(self, forward_batch: ForwardBatch)

  L 149: capture(self)

  L 152: capture_one_batch_size(self, num_seqs: int, forward: Callable)

  L 280: replay(self, forward_batch: ForwardBatch)


============================================================
FILE: python/sglang/srt/speculative/eagle_draft_extend_cuda_graph_runner.py
Functions: 5
============================================================


CLASS: EAGLEDraftExtendCudaGraphRunner
----------------------------------------
  L  37: __init__(self, eagle_worker: EAGLEWorker)

  L 155: can_run(self, forward_batch: ForwardBatch)

  L 176: capture(self)

  L 179: capture_one_batch_size(self, bs: int, forward: Callable)

  L 308: replay(self, forward_batch: ForwardBatch)


============================================================
FILE: python/sglang/srt/speculative/eagle_utils.py
Functions: 22
============================================================

MODULE FUNCTIONS:
----------------------------------------
  L 730: def create_extend_after_decode_spec_info(verified_id,
        seq_lens,
        accept_lens,
        positions,
        new_verified_id,
        bs_upper: tl.constexpr)
         @triton.jit

  L 756: def assign_req_to_token_pool(req_pool_indices,
        req_to_token,
        start_offset,
        end_offset,
        out_cache_loc,
        pool_len: tl.constexpr,
        bs_upper: tl.constexpr)
         @triton.jit

  L 791: def assign_draft_cache_locs(req_pool_indices,
        req_to_token,
        seq_lens,
        extend_lens,
        num_new_pages_per_topk,
        out_cache_loc,
        pool_len: tl.constexpr,
        topk: tl.constexpr,
        speculative_num_steps: tl.constexpr,
        page_size: tl.constexpr,
        bs_upper: tl.constexpr,
        iter_upper: tl.constexpr)
         @triton.jit

  L 867: def generate_draft_decode_kv_indices(req_pool_indices,
        req_to_token,
        paged_kernel_lens,
        kv_indices,
        kv_indptr,
        positions,
        pool_len: tl.constexpr,
        kv_indices_stride: tl.constexpr,
        kv_indptr_stride: tl.constexpr,
        bs_upper: tl.constexpr,
        iter_upper: tl.constexpr,
        num_tokens_upper: tl.constexpr,
        page_size: tl.constexpr)
         @triton.jit

  L 948: def align_evict_mask_to_page_size(seq_lens,
        evict_mask,
        page_size: tl.constexpr,
        num_draft_tokens: tl.constexpr,
        BLOCK_SIZE: tl.constexpr)
         @triton.jit

  L 973: def get_target_cache_loc(tgt_cache_loc,
        to_free_slots,
        accept_length,
        to_free_num_slots,
        out_cache_loc,
        num_verify_tokens: tl.constexpr,
        num_verify_tokens_upper: tl.constexpr,
        bs_upper: tl.constexpr)
         @triton.jit

  L1019: def get_src_tgt_cache_loc(seq_lens: torch.Tensor,
        out_cache_loc: torch.Tensor,
        accept_index: torch.Tensor,
        accept_length: torch.Tensor,
        draft_token_num: int,
        page_size: int)
         @torch.compile(dynamic=True)

  L1039: def filter_finished_cache_loc_kernel(out_cache_loc,
        tgt_cache_loc,
        accept_length,
        accept_length_filter,
        bs_upper: tl.constexpr,
        num_verify_tokens_upper: tl.constexpr)
         @triton.jit

  L1069: def create_accept_length_filter(accept_length: torch.Tensor,
        unfinished_index_device: torch.Tensor,
        seq_lens: torch.Tensor)
         @torch.compile(dynamic=True)

  L1083: def select_top_k_tokens(i: int,
        topk_p: torch.Tensor,
        topk_index: torch.Tensor,
        hidden_states: torch.Tensor,
        scores: torch.Tensor,
        topk: int)
         @torch.compile(dynamic=True)

  L1183: def traverse_tree(retrieve_next_token: torch.Tensor,
        retrieve_next_sibling: torch.Tensor,
        draft_tokens: torch.Tensor,
        grammar: BaseGrammarObject,
        allocate_token_bitmask: torch.Tensor)
         üìù Traverse the tree constructed by the draft model to generate the logits mask.

  L1249: def generate_token_bitmask(reqs: List[Req],
        verify_input: EagleVerifyInput,
        retrieve_next_token_cpu: torch.Tensor,
        retrieve_next_sibling_cpu: torch.Tensor,
        draft_tokens_cpu: torch.Tensor,
        vocab_size: int)
         üìù Generate the logit mask for structured output.
            Draft model's token can be either valid or invalid with respect to the grammar.
            We need to perform DFS to
            1. figure out which tokens are accepted by the grammar.
            2. if so, what is the corresponding logit mask.


CLASS: EagleDraftInput
----------------------------------------
  L  85: prepare_for_extend(self, batch: ScheduleBatch)

  L 102: create_idle_input(cls, device: torch.device, hidden_size: int, dtype: torch.dtype, topk: int, capture_hidden_mode: CaptureHiddenMode)

  L 120: prepare_extend_after_decode(self, batch: ScheduleBatch, speculative_num_steps: int)

  L 151: generate_attn_arg_prefill(self, req_pool_indices: torch.Tensor, paged_kernel_lens: torch.Tensor, paged_kernel_lens_sum: int, req_to_token: torch.Tensor)

  L 182: filter_batch(self, new_indices: torch.Tensor, has_been_filtered: bool)

  L 201: merge_batch(self, spec_info: EagleDraftInput)


CLASS: EagleVerifyInput
----------------------------------------
  L 250: create_idle_input(cls, topk: int, spec_steps: int, num_verify_tokens: int)

  L 273: prepare_for_verify(self, batch: ScheduleBatch, page_size: int)

  L 307: generate_attn_arg_prefill(self, req_pool_indices: torch.Tensor, paged_kernel_lens: torch.Tensor, paged_kernel_lens_sum: int, req_to_token: torch.Tensor)

  L 345: verify(self, batch: ScheduleBatch, logits_output: LogitsProcessorOutput, token_to_kv_pool_allocator: BaseTokenToKVPoolAllocator, page_size: int, vocab_mask: Optional[torch.Tensor])
         ‚Üí torch.Tensor
         üìù Verify and find accepted tokens based on logits output and batch
            (which contains spec decoding information).
            WARNING: This API in-place modifies the states of logits_output
            This API updates values inside logits_output based on the accepted
            tokens. I.e., logits_output.next_token_logits only contains
            accepted token logits.


============================================================
FILE: python/sglang/srt/speculative/eagle_worker.py
Functions: 18
============================================================

MODULE FUNCTIONS:
----------------------------------------
  L  62: def draft_tp_context(tp_group: GroupCoordinator)
         @contextmanager

  L1012: def load_token_map(token_map_path: str)
         ‚Üí List[int]

  L1024: def get_last_loc_large_page_size_top_k_1(req_to_token: torch.Tensor,
        req_pool_indices: torch.Tensor,
        seq_lens,
        speculative_num_steps: int)
         @torch.compile(dynamic=True)

  L1043: def get_last_loc_large_page_size_large_top_k(req_to_token: torch.Tensor,
        req_pool_indices: torch.Tensor,
        seq_lens: torch.Tensor,
        speculative_num_steps: int,
        topk: int,
        page_size: int)


CLASS: EAGLEWorker
----------------------------------------
  L  71: __init__(self, server_args: ServerArgs, gpu_id: int, tp_rank: int, dp_rank: Optional[int], moe_ep_rank: int, nccl_port: int, target_worker: TpModelWorker)

  L 184: init_attention_backend(self)

  L 322: init_cuda_graphs(self)
         üìù Capture cuda graphs.

  L 358: draft_model_runner(self)

  L 361: forward_batch_speculative_generation(self, batch: ScheduleBatch)
         ‚Üí Tuple[LogitsProcessorOutput, torch.Tensor, int, int, bool]
         üìù Run speculative decoding forward.
            NOTE: Many states of batch is modified as you go through. It is not guaranteed that
            the final output batch have the same state as the input.
            Args:
            batch: The batch to run forward. The state of the batch is modified as it runs.
            Returns:
            A tuple of the final logit output of the target model, next tokens accepted,
            the batch id (used for overlap schedule), and number of accepted tokens.

  L 409: check_forward_draft_extend_after_decode(self, batch: ScheduleBatch)

  L 427: forward_target_extend(self, batch: ScheduleBatch)
         ‚Üí Tuple[LogitsProcessorOutput, torch.Tensor, int, Optional[torch.Tensor]]
         üìù Run the target extend.
            Args:
            batch: The batch to run. States could be modified.
            Returns:
            logits_output: The output of logits. It will contain the full hidden states.
            next_token_ids: Next token ids generated.
            bid: The model batch ID. Used for overlap schedule.

  L 567: draft(self, batch: ScheduleBatch)

  L 645: draft_forward(self, forward_batch: ForwardBatch)

  L 704: verify(self, batch: ScheduleBatch, spec_info: EagleVerifyInput)

  L 781: add_logprob_values(self, batch: ScheduleBatch, res: EagleVerifyOutput, logits_output: LogitsProcessorOutput)

  L 860: forward_draft_extend(self, batch: ScheduleBatch, hidden_states: torch.Tensor, next_token_ids: torch.Tensor, seq_lens_cpu: Optional[torch.Tensor])
         üìù Run draft model extend. This API modifies the states of the batch.
            Args:
            batch: The batch to run.
            hidden_states: Hidden states from the target model forward
            next_token_ids: Next token ids generated from the target forward.

  L 911: forward_draft_extend_after_decode(self, batch: ScheduleBatch)

  L 997: capture_for_decode(self, logits_output: LogitsProcessorOutput, draft_input: EagleDraftInput)


============================================================
FILE: python/sglang/srt/speculative/spec_info.py
Functions: 4
============================================================


CLASS: SpeculativeAlgorithm
----------------------------------------
  L   9: is_none(self)

  L  12: is_eagle(self)

  L  15: is_eagle3(self)

  L  19: from_string(name: str)


============================================================
FILE: python/sglang/srt/tokenizer/tiktoken_tokenizer.py
Functions: 9
============================================================


CLASS: TiktokenProcessor
----------------------------------------
  L   7: __init__(self, name: str)

  L  10: image_processor(self, image)


CLASS: TiktokenTokenizer
----------------------------------------
  L  30: __init__(self, tokenizer_path)

  L 110: encode(self, x, add_special_tokens)

  L 113: decode(self, x)

  L 116: batch_decode(self, batch, skip_special_tokens, spaces_between_special_tokens)

  L 123: apply_chat_template(self, messages, tokenize, add_generation_prompt, tools, reasoning_effort)

  L 136: __call__(self, text)

  L 141: init_xgrammar(self)


============================================================
FILE: python/sglang/srt/torch_memory_saver_adapter.py
Functions: 17
============================================================


CLASS: TorchMemorySaverAdapter
----------------------------------------
  L  21: create(enable: bool)

  L  33: check_validity(self, caller_name)

  L  40: configure_subprocess(self)

  L  43: region(self, tag: str)

  L  46: pause(self, tag: str)

  L  49: resume(self, tag: str)

  L  53: enabled(self)


CLASS: _TorchMemorySaverAdapterNoop
----------------------------------------
  L  79: configure_subprocess(self)

  L  83: region(self, tag: str)

  L  86: pause(self, tag: str)

  L  89: resume(self, tag: str)

  L  93: enabled(self)


CLASS: _TorchMemorySaverAdapterReal
----------------------------------------
  L  60: configure_subprocess(self)

  L  63: region(self, tag: str)

  L  66: pause(self, tag: str)

  L  69: resume(self, tag: str)

  L  73: enabled(self)


============================================================
FILE: python/sglang/srt/two_batch_overlap.py
Functions: 24
============================================================

MODULE FUNCTIONS:
----------------------------------------
  L  49: def get_token_num_per_seq(forward_mode: ForwardMode,
        spec_info: Optional[Union[EagleDraftInput,
        EagleVerifyInput]])

  L  65: def compute_split_seq_index(forward_mode: 'ForwardMode',
        num_tokens: int,
        extend_lens: Optional[Sequence[int]],
        token_num_per_seq: Optional[int])
         ‚Üí Optional[int]

  L 180: def split_spec_info(spec_info: Optional[EagleVerifyInput],
        start_seq_index: int,
        end_seq_index: int,
        start_token_index: int,
        end_token_index: int)

  L 252: def compute_split_token_index(split_seq_index: int,
        forward_mode: 'ForwardMode',
        extend_seq_lens: Optional[Sequence[int]],
        token_num_per_seq: Optional[int])
         ‚Üí int

  L 273: def compute_split_indices_for_cuda_graph_replay(forward_mode: ForwardMode,
        cuda_graph_num_tokens: int,
        spec_info: Optional[Union[EagleDraftInput,
        EagleVerifyInput]])

  L 785: def model_forward_maybe_tbo(layers,
        enable_tbo: bool,
        positions: torch.Tensor,
        forward_batch: ForwardBatch,
        hidden_states: torch.Tensor,
        input_data_scatter_mode: ScatterMode,
        residual: Optional[torch.Tensor],
        zero_allocator: Optional[BumpAllocator])


CLASS: MaybeTboDeepEPDispatcher
----------------------------------------
  L 964: __init__(self)

  L 973: dispatch(self)
         ‚Üí DispatchOutput

  L 976: dispatch_a(self)

  L 979: dispatch_b(self)

  L 982: combine(self)
         ‚Üí torch.Tensor

  L 985: combine_a(self)

  L 988: combine_b(self)


CLASS: TboCudaGraphRunnerPlugin
----------------------------------------
  L 303: __init__(self)

  L 306: capture_one_batch_size(self, batch: ForwardBatch, num_tokens: int)

  L 331: replay_prepare(self, forward_mode: ForwardMode, bs: int, num_token_non_padded: int, spec_info: Optional[Union[EagleDraftInput, EagleVerifyInput]])


CLASS: TboDPAttentionPreparer
----------------------------------------
  L 358: prepare_all_gather(self, local_batch: ScheduleBatch)

  L 404: compute_output(self, partial_global_info)


CLASS: TboForwardBatchPreparer
----------------------------------------
  L 452: prepare(cls, batch: ForwardBatch, is_draft_worker: bool)

  L 464: prepare_raw(cls, batch: ForwardBatch, tbo_children_num_token_non_padded: torch.Tensor)

  L 529: derive_fields_related_to_seq_len_for_two_chunk(cls, batch: ForwardBatch)

  L 591: filter_batch(cls, batch: ForwardBatch)

  L 740: compute_tbo_children_num_token_non_padded(cls, batch: ForwardBatch)

  L 747: compute_tbo_children_num_token_non_padded_raw(cls, tbo_split_token_index: int, num_token_non_padded: int)


============================================================
FILE: python/sglang/srt/utils.py
Functions: 171
============================================================

MODULE FUNCTIONS:
----------------------------------------
  L 103: def is_hip()
         ‚Üí bool

  L 118: def is_cuda()

  L 122: def is_cuda_alike()

  L 126: def is_hpu()
         ‚Üí bool

  L 130: def is_xpu()
         ‚Üí bool

  L 134: def is_npu()
         ‚Üí bool

  L 138: def is_host_cpu_x86()
         ‚Üí bool

  L 147: def is_cpu()
         ‚Üí bool

  L 151: def get_cuda_version()

  L 169: def is_blackwell()

  L 176: def is_sm100_supported(device)
         ‚Üí bool
         @lru_cache(maxsize=1)

  L 183: def is_sm90_supported(device)
         ‚Üí bool
         @lru_cache(maxsize=1)

  L 192: def get_bool_env_var(name: str, default: str)
         ‚Üí bool

  L 209: def get_int_env_var(name: str, default: int)
         ‚Üí int

  L 219: def support_triton(backend: str)
         ‚Üí bool

  L 233: def cpu_has_amx_support()

  L 237: def use_intel_amx_backend(layer)

  L 241: def is_flashinfer_available()
         üìù Check whether flashinfer is available.
            As of Oct. 6, 2024, it is only available on NVIDIA GPUs.

  L 251: def random_uuid()
         ‚Üí str

  L 312: def enable_show_time_cost()

  L 339: def mark_start(name, interval, color, indent)

  L 349: def mark_end(name)

  L 359: def calculate_time(show, min_cost_ms)

  L 378: def get_available_gpu_memory(device,
        gpu_id,
        distributed,
        empty_cache,
        cpu_group)
         üìù Get available memory for cuda:gpu_id device.
            When distributed is True, the available memory is the minimum available memory of all GPUs.

  L 451: def is_pin_memory_available()
         ‚Üí bool

  L 460: def make_layers(num_hidden_layers: int,
        layer_fn: LayerFn,
        pp_rank: Optional[int],
        pp_size: Optional[int],
        prefix: str,
        return_tuple: bool,
        offloader_kwargs: Dict[str,
        Any])
         ‚Üí Tuple[int, int, torch.nn.ModuleList]
         üìù Make a list of layers with the given layer function

  L 504: def set_random_seed(seed: int)
         ‚Üí None
         üìù Set the random seed for all libraries.

  L 513: def find_process_using_port(port: int)
         ‚Üí Optional[psutil.Process]

  L 525: def wait_port_available(port: int,
        port_name: str,
        timeout_s: int,
        raise_exception: bool)
         ‚Üí bool

  L 553: def is_port_available(port)
         üìù Return whether a port is available.

  L 567: def get_free_port()

  L 580: def decode_video_base64(video_base64)

  L 659: def load_audio(audio_file: str, sr: Optional[int], mono: bool)
         ‚Üí np.ndarray

  L 707: def load_image(image_file: Union[Image.Image, str, ImageData, bytes])
         ‚Üí tuple[Image.Image, tuple[int, int]]

  L 741: def load_video(video_file: Union[str, bytes], use_gpu: bool)

  L 796: def suppress_other_loggers()

  L 816: def assert_pkg_version(pkg: str, min_version: str, message: str)

  L 831: def kill_process_tree(parent_pid, include_parent: bool, skip_pid: int)
         üìù Kill the process and all its child processes.

  L 870: def monkey_patch_p2p_access_check()
         üìù Monkey patch the slow p2p access check.
            NOTE: We assume the p2p access is always allowed, which can be wrong for some setups.

  L 888: def monkey_patch_vllm_gguf_config()

  L 914: def set_ulimit(target_soft_limit)

  L 938: def add_api_key_middleware(app, api_key: str)

  L 952: def prepare_model_and_tokenizer(model_path: str, tokenizer_path: str)

  L 964: def configure_logger(server_args, prefix: str)

  L 986: def replace_submodule(model: nn.Module, module_name: str, new_module: nn.Module)
         ‚Üí nn.Module
         üìù Replace a submodule in a model with a new module.

  L 996: def set_weight_attrs(weight: torch.Tensor,
        weight_attrs: Optional[Dict[str,
        Any]])
         üìù Set attributes on a weight tensor.
            This method is used to set attributes on a weight tensor. This method
            will not overwrite existing attributes.
            Args:
            weight: The weight tensor.
            weight_attrs: A dictionary of attributes to set on the weight tensor.

  L1016: def broadcast_pyobj(data: List[Any],
        rank: int,
        dist_group: Optional[torch.distributed.ProcessGroup],
        src: int,
        force_cpu_device: bool)
         üìù Broadcast inputs from src rank to all other ranks with torch.dist backend.
            The `rank` here refer to the source rank on global process group (regardless
            of dist_group argument).

  L1063: def point_to_point_pyobj(data: List[Any],
        rank: int,
        group: Optional[torch.distributed.ProcessGroup],
        src: int,
        dst: int)
         üìù Send data from src to dst in group using DeviceToDevice communication.

  L1122: def pytorch_profile(name, func)
         üìù Args:
            name (string): the name of recorded function.
            func: the function to be profiled.
            args: the arguments of the profiled function.
            data_size (int): some measurement of the computation complexity.
            Usually, it could be the batch size.

  L1150: def get_zmq_socket(context: zmq.Context,
        socket_type: zmq.SocketType,
        endpoint: str,
        bind: bool)

  L1191: def dump_to_file(dirpath, name, value)

  L1206: def is_triton_3()

  L1210: def maybe_torch_compile()
         üìù torch.compile does not work for triton 2.2.0, which is needed in xlm1's jax.
            Therefore, we disable it here.

  L1224: def delete_directory(dirpath)

  L1237: def set_prometheus_multiproc_dir()

  L1255: def add_prometheus_middleware(app)

  L1268: def bind_port(port)
         üìù Bind to a specific port, assuming it's available.

  L1277: def get_amdgpu_memory_capacity()

  L1310: def get_device_sm()

  L1317: def get_nvgpu_memory_capacity()

  L1356: def get_hpu_memory_capacity()

  L1387: def get_npu_memory_capacity()

  L1396: def get_device_memory_capacity(device: str)

  L1415: def init_custom_process_group(backend,
        init_method,
        timeout,
        world_size,
        rank,
        store,
        group_name,
        pg_options)

  L1484: def crash_on_warnings()

  L1489: def print_warning_once(msg: str)
         ‚Üí None

  L1495: def print_info_once(msg: str)
         ‚Üí None
         @functools.lru_cache(None)

  L1499: def get_device_name(device_id: int)
         ‚Üí str

  L1514: def is_habana_available()
         ‚Üí bool
         @lru_cache(maxsize=1)

  L1519: def get_device(device_id: Optional[int])
         ‚Üí str
         @lru_cache(maxsize=8)

  L1561: def get_device_count()
         ‚Üí int
         @lru_cache(maxsize=1)

  L1586: def get_device_core_count(device_id: int)
         ‚Üí int

  L1593: def get_device_capability(device_id: int)
         ‚Üí Tuple[int, int]

  L1618: def get_npu_compiler_config()

  L1627: def get_compiler_backend()
         ‚Üí str

  L1657: def supports_custom_op()
         ‚Üí bool

  L1661: def direct_register_custom_op(op_name: str,
        op_func: Callable,
        mutates_args: List[str],
        fake_impl: Optional[Callable],
        target_lib: Optional[Library])
         üìù `torch.library.custom_op` can have significant overhead because it
            needs to consider complicated dispatching logic. This function
            directly registers a custom op and dispatches it to the CUDA backend.
            See https://gist.github.com/youkaichao/ecbea9ec9fc79a45d2adce1784d7a9a5
            for more details.
            By default, the custom op is registered to the vLLM library. If you
            want to register it to a different library, you can pass the library
            object to the `target_lib` argument.
            IMPORTANT: the lifetime of the operator is tied to the lifetime of the
            library object. If you want to bind the operator to a different library,
            make sure the library object is alive when the operator is used.
            Note: This function will silently skip registration if the operator
            with the same name is already registered to avoid RuntimeError in
            multi-engine scenarios (e.g., VERL framework).

  L1731: def set_gpu_proc_affinity(tp_size: int, nnodes: int, gpu_id: int)

  L1766: def disable_request_logging()
         ‚Üí bool
         @lru_cache(maxsize=2)

  L1770: def dataclass_to_string_truncated(data,
        max_length,
        skip_names: Optional[Set[str]])

  L1812: def permute_weight(x: torch.Tensor)
         ‚Üí torch.Tensor

  L1874: def debug_timing(func)

  L1898: def nullable_str(val: str)

  L1904: def pyspy_dump_schedulers()
         üìù py-spy dump on all scheduler in a local node.

  L1918: def kill_itself_when_parent_died()

  L1928: def set_uvicorn_logging_configs()

  L1941: def get_ip()
         ‚Üí str

  L1985: def get_open_port()
         ‚Üí int

  L2009: def is_valid_ipv6_address(address: str)
         ‚Üí bool

  L2017: def maybe_wrap_ipv6_address(address: str)
         ‚Üí str

  L2023: def format_tcp_address(ip: str, port: int)
         ‚Üí str

  L2027: def configure_ipv6(dist_init_addr)

  L2059: def launch_dummy_health_check_server(host, port, enable_metrics)

  L2105: def create_checksum(directory: str)

  L2109: def set_cuda_arch()

  L2116: def next_power_of_2(n: int)

  L2120: def round_up(x: int, y: int)
         ‚Üí int

  L2135: def empty_context()

  L2139: def add_prefix(name: str, prefix: str)
         ‚Üí str
         üìù Add a weight path prefix to a module name.
            Args:
            name: base module name.
            prefix: weight prefix str to added to the front of `name` concatenated with `.`.
            Returns:
            The string `prefix.name` if prefix is non-empty, otherwise just `name`.

  L2152: def is_remote_url(url: Union[str, Path])
         ‚Üí bool
         üìù Check if the URL is a remote URL of the format:
            <connector_type>://<host>:<port>/<model_name>

  L2165: def parse_connector_type(url: str)
         ‚Üí str
         üìù Parse the connector type from the URL of the format:
            <connector_type>://<path>

  L2178: def retry(fn,
        max_retry: int,
        initial_delay: float,
        max_delay: float,
        should_retry: Callable[[Any],
        bool])

  L2207: def flatten_nested_list(nested_list)

  L2216: def is_non_idle_and_non_empty(forward_mode, hidden_states)

  L2224: def fast_topk(values, topk, dim)

  L2233: def bind_or_assign(target, source)

  L2241: def get_local_ip_auto()
         ‚Üí str

  L2250: def get_local_ip_by_nic(interface: str)
         ‚Üí str

  L2279: def get_local_ip_by_remote()
         ‚Üí str

  L2307: def is_page_size_one(server_args)

  L2313: def is_no_spec_infer_or_topk_one(server_args)

  L2321: def is_fa3_default_architecture(hf_config)

  L2353: def log_info_on_rank0(logger, msg)

  L2360: def load_json_config(data: str)

  L2367: def dispose_tensor(x: torch.Tensor)

  L2393: def require_mlp_tp_gather(server_args)
         üìù Check if the input of MLP is obtained by all-gather rather than all-reduce. This only happens when each MLP TP group contains multiple attention DP groups.

  L2416: def require_attn_tp_gather(server_args)
         üìù Check if the input of attention is scattered.

  L2430: def require_gathered_buffer(server_args)

  L2434: def require_mlp_sync(server_args)

  L2438: def find_local_repo_dir(repo_id: str, revision: Optional[str])
         ‚Üí Optional[str]

  L2463: def read_system_prompt_from_file(model_name: str)
         ‚Üí str
         üìù Read system prompt from a file in the HuggingFace cache directory.
            Args:
            model_name: The model name to construct the file path
            Returns:
            The system prompt content from the file, or empty string if file not found

  L2486: def bind_or_assign(target, source)

  L2494: def prepack_weight_if_needed(weight)

  L2506: def dim_is_supported(weight)

  L2578: def dynamic_import(func_path: str)

  L2591: def gc_object_counts()

  L2600: def configure_gc_warning(warn_threshold_secs)

  L2621: def freeze_gc(context: str)

  L2635: def configure_gc_logger()

  L2661: def align(x: int, y: int)
         ‚Üí int

  L2666: def ceil_div(x: int, y: int)
         ‚Üí int

  L2670: def parse_lscpu_topology()

  L2690: def get_physical_cpus_by_numa()

  L2725: def get_cpu_ids_by_node()

  L2736: def is_shm_available(dtype, world_size, local_size)

  L2745: def lru_cache_frozenset(maxsize)

  L2790: def apply_module_patch(target_module, target_function, wrappers)

  L2812: def parse_module_path(module_path, function_name, create_dummy)

  L2888: def mxfp_supported()
         üìù Returns whether the current platform supports MX types.

  L3002: def is_triton_kernels_available()
         ‚Üí bool
         @lru_cache(maxsize=1)

  L3006: def check_cuda_result(raw_output)


CLASS: BumpAllocator
----------------------------------------
  L2342: __init__(self, buffer_size: int, dtype, device)

  L2346: allocate(self, size: int)


CLASS: ConcurrentCounter
----------------------------------------
  L2924: __init__(self, initial: int)
         üìù Initialize the counter with an optional initial value.
            Args:
            initial (int): The initial value of the counter. Default is 0.

  L2934: value(self)
         ‚Üí int
         üìù Return the current value of the counter.
            Note:
            This method is not synchronized. It may return a stale value
            if other coroutines are concurrently modifying the counter.
            Returns:
            int: The current counter value.

  L2947: __repr__(self)
         ‚Üí str
         üìù Return an informative string representation of the counter.

  L2951: increment(self, n: int, notify_all: bool)
         üìù Atomically increment the counter by a given amount and notify all waiters.
            Args:
            n (int): The amount to increment the counter by. Default is 1.
            notify_all (bool): Whether to notify all waiters after incrementing. Default is True.

  L2964: decrement(self, n: int, notify_all: bool)
         üìù Atomically decrement the counter by a given amount and notify all waiters.
            Args:
            n (int): The amount to decrement the counter by. Default is 1.
            notify_all (bool): Whether to notify all waiters after decrementing. Default is True.

  L2977: wait_for(self, condition: Callable[[int], bool])
         üìù Asynchronously wait until the counter satisfies a given condition.
            This suspends the calling coroutine without blocking the thread, allowing
            other tasks to run while waiting. When the condition is met, the coroutine resumes.
            Args:
            condition (Callable[[int], bool]): A function that takes the current counter value
            and returns True when the condition is satisfied.

  L2991: wait_for_zero(self)
         üìù Asynchronously wait until the counter reaches zero.
            This suspends the calling coroutine without blocking the thread, allowing
            other tasks to run while waiting. When the counter becomes zero, the coroutine resumes.


CLASS: DynamicGradMode
----------------------------------------
  L 267: set_inference_mode(mode: bool)

  L 275: __init__(self, mode)

  L 283: __new__(cls, mode_or_orig_func)

  L 288: __enter__(self)
         ‚Üí None

  L 296: __exit__(self, exc_type: Any, exc_value: Any, traceback: Any)
         ‚Üí None

  L 302: clone(self)
         ‚Üí 'DynamicGradMode'
         üìù Create a copy of this class


CLASS: EmptyContextManager
----------------------------------------
  L2128: __enter__(self)

  L2131: __exit__(self, exc_type, exc_value, traceback)


CLASS: LayerFn
----------------------------------------
  L 457: __call__(self, layer_id: int, prefix: str)
         ‚Üí torch.nn.Module


CLASS: LazyValue
----------------------------------------
  L2566: __init__(self, creator: Callable)

  L2571: value(self)


CLASS: MultiprocessingSerializer
----------------------------------------
  L1834: serialize(obj, output_str: bool)
         üìù Serialize a Python object using ForkingPickler.
            Args:
            obj: The object to serialize.
            output_str (bool): If True, return a base64-encoded string instead of raw bytes.
            Returns:
            bytes or str: The serialized object.

  L1857: deserialize(data)
         üìù Deserialize a previously serialized object.
            Args:
            data (bytes or str): The serialized data, optionally base64-encoded.
            Returns:
            The deserialized Python object.


CLASS: PackWeightMethod
----------------------------------------
  L2557: __init__(self, weight_names, transpose_dims)

  L2561: process_weights_after_loading(self, module)
         ‚Üí None


CLASS: TimeInfo
----------------------------------------
  L 318: __init__(self, name, interval, color, indent)

  L 327: check(self)

  L 333: pretty_print(self)


CLASS: Withable
----------------------------------------
  L2375: __init__(self)

  L2379: value(self)
         ‚Üí T

  L2383: with_value(self, new_value: T)


============================================================
FILE: python/sglang/srt/warmup.py
Functions: 3
============================================================

MODULE FUNCTIONS:
----------------------------------------
  L  16: def warmup(name: str)
         ‚Üí callable

  L  24: async def execute_warmups(disaggregation_mode: str,
        warmup_names: List[str],
        tokenizer_manager: TokenizerManager)

  L  38: async def voice_chat(disaggregation_mode: str,
        tokenizer_manager: TokenizerManager)
         @warmup('voice_chat')


============================================================
FILE: python/sglang/srt/weight_sync/tensor_bucket.py
Functions: 4
============================================================


CLASS: FlattenedTensorBucket
----------------------------------------
  L  25: __init__(self, named_tensors: List[Tuple[str, torch.Tensor]], flattened_tensor: torch.Tensor, metadata: List[FlattenedTensorMetadata])
         üìù Initialize a tensor bucket from a list of named tensors OR from pre-flattened data.
            Args:
            named_tensors: List of (name, tensor) tuples (for creating new bucket)
            flattened_tensor: Pre-flattened tensor (for reconstruction)
            metadata: Pre-computed metadata (for reconstruction)

  L  79: get_flattened_tensor(self)
         ‚Üí torch.Tensor
         üìù Get the flattened tensor containing all bucket tensors

  L  83: get_metadata(self)
         ‚Üí List[FlattenedTensorMetadata]
         üìù Get metadata for all tensors in the bucket

  L  87: reconstruct_tensors(self)
         ‚Üí List[Tuple[str, torch.Tensor]]
         üìù Reconstruct original tensors from flattened tensor with optimized performance.
            Uses memory-efficient operations to minimize allocations and copies.


============================================================
FILE: python/sglang/srt/weight_sync/utils.py
Functions: 1
============================================================

MODULE FUNCTIONS:
----------------------------------------
  L  14: async def update_weights(engine: Engine,
        params_batch: list[tuple[str,
        torch.Tensor]],
        device_mesh_key: str,
        device_mesh: DeviceMesh,
        load_format: Optional[str])
         üìù Update weights for the inference engine.
            This function is designed to be stateless, so that the caller process could keep the stateful engine.
            Example Use Case:
            - Multiple Producer Process will call this function in a SPMD style
            Args:
            engine: The inference engine created by the caller process.
            params_batch: A list of (name, tensor) tuples. We batched the tensors to avoid the overhead of cpu call.
            device_mesh_key: The key of the device mesh. Typically "tp" or "infer_tp"
            device_mesh: The device mesh.
            load_format: The format of the weights.


============================================================
FILE: python/sglang/test/attention/test_flashattn_backend.py
Functions: 7
============================================================


CLASS: MockModelRunner
----------------------------------------
  L  16: __init__(self, page_size, num_heads, head_dim)


CLASS: TestFlashAttentionBackend
----------------------------------------
  L  74: setUp(self)

  L 324: test_forward_extend(self)
         üìù Test the standard extend operation.

  L 328: test_forward_decode(self)
         üìù Test the decode operation with cached tokens.

  L 332: test_forward_extend_with_prefix(self)
         üìù Test extending from cached prefix tokens.

  L 340: test_forward_extend_with_page_size_greater_than_1(self)
         üìù Test extending from cached prefix tokens with page size greater than 1.

  L 344: test_forward_decode_with_page_size_greater_than_1(self)
         üìù Test decode operation with page size greater than 1.


============================================================
FILE: python/sglang/test/attention/test_flashattn_mla_backend.py
Functions: 6
============================================================


CLASS: MockModelRunner
----------------------------------------
  L  15: __init__(self, kv_lora_rank, qk_rope_head_dim)


CLASS: MockReqToTokenPool
----------------------------------------
  L  63: __init__(self, batch_size, seq_len, device)


CLASS: TestFlashAttentionMLABackend
----------------------------------------
  L  73: setUp(self)

  L 267: test_forward_extend(self)
         üìù Test the standard extend operation.

  L 271: test_forward_decode(self)
         üìù Test the decode operation with cached tokens.

  L 275: test_forward_extend_with_prefix(self)
         üìù Test extending from cached prefix tokens.


============================================================
FILE: python/sglang/test/attention/test_prefix_chunk_info.py
Functions: 6
============================================================

MODULE FUNCTIONS:
----------------------------------------
  L 114: def check_kv_indices(forward_batch)


CLASS: MockForwardBatch
----------------------------------------
  L  96: __init__(self, max_chunk_capacity: int)

  L 100: get_max_chunk_capacity(self)


CLASS: MockReqToTokenPool
----------------------------------------
  L 105: __init__(self, batch_size, seq_len, device)


CLASS: TestPrefixChunkInfo
----------------------------------------
  L 138: setUp(self)

  L 168: test_prefix_chunk_info(self)
         üìù Test the standard extend operation.


============================================================
FILE: python/sglang/test/attention/test_trtllm_mla_backend.py
Functions: 12
============================================================

MODULE FUNCTIONS:
----------------------------------------
  L  59: def build_rotary_emb(config, device)

  L 266: def compare_outputs(trtllm_out, reference_out, tolerance)
         üìù Compare outputs with detailed analysis.


CLASS: MockModelRunner
----------------------------------------
  L 205: __init__(self, config)


CLASS: TestTRTLLMMLA
----------------------------------------
  L 458: test_basic_functionality(self)
         üìù Test basic functionality with minimal setup.

  L 523: test_decode_output_match(self)
         üìù Test that TRTLLM and FlashInfer MLA backends produce matching outputs.

  L 652: test_page_size_consistency(self)
         üìù Test output consistency across different page sizes.

  L 710: test_shape_sanity(self)
         üìù Smoke test decode across several configurations.

  L 792: test_metadata_initialization(self)
         üìù Test TRTLLM MLA metadata initialization and structure.

  L 861: test_metadata_block_calculation(self)
         üìù Test block count calculation logic.

  L 914: test_metadata_kv_indices_correctness(self)
         üìù Test KV indices creation and correctness.

  L 988: test_metadata_cuda_graph_compatibility(self)
         üìù Test metadata compatibility with CUDA graph capture/replay.

  L1057: test_metadata_consistency_across_calls(self)
         üìù Test metadata consistency across multiple forward calls.


============================================================
FILE: python/sglang/test/doc_patch.py
Functions: 2
============================================================

MODULE FUNCTIONS:
----------------------------------------
  L  23: def patched_post_init(self)

  L  37: def launch_server_cmd(command: str, host: str, port: int)
         üìù Launch the server using the given command.
            If no port is specified, a free port is reserved.


============================================================
FILE: python/sglang/test/few_shot_gsm8k.py
Functions: 4
============================================================

MODULE FUNCTIONS:
----------------------------------------
  L  22: def get_one_example(lines, i, include_answer)

  L  29: def get_few_shot_examples(lines, k)

  L  36: def get_answer_value(answer_str)

  L  47: def run_eval(args)


============================================================
FILE: python/sglang/test/few_shot_gsm8k_engine.py
Functions: 5
============================================================

MODULE FUNCTIONS:
----------------------------------------
  L  18: def get_one_example(lines, i, include_answer)

  L  25: def get_few_shot_examples(lines, k)

  L  32: def get_answer_value(answer_str)

  L  43: async def concurrent_generate(engine, prompts, sampling_param)

  L  52: def run_eval(args)


============================================================
FILE: python/sglang/test/run_eval.py
Functions: 1
============================================================

MODULE FUNCTIONS:
----------------------------------------
  L  18: def run_eval(args)


============================================================
FILE: python/sglang/test/runners.py
Functions: 22
============================================================

MODULE FUNCTIONS:
----------------------------------------
  L  69: def get_dtype_str(torch_dtype)

  L  78: def get_top_logprobs(logits, k)

  L  85: def get_token_ids_logprobs(logits, token_ids)

  L 809: def monkey_patch_gemma2_sdpa()
         üìù Use sdpa by default to fix the OOM issue.
            Revert this commit:
            https://github.com/huggingface/transformers/commit/975b988bfe6e7ebb47390cd9a1556c6888804883#diff-5f76eac6f18f4b491521314c318a9692318feb4d19228e9576cce7bde4240834R660

  L 824: def check_close_model_outputs(hf_outputs: ModelOutput,
        srt_outputs: ModelOutput,
        prefill_tolerance: float,
        decode_tolerance: float,
        rouge_l_tolerance: float,
        debug_text: str,
        check_logprobs: bool)


CLASS: HFRunner
----------------------------------------
  L 130: __init__(self, model_path: str, torch_dtype: torch.dtype, model_type: str, output_str_only: bool, trust_remote_code: bool, patch_model_do_sample_false: bool)

  L 158: needs_trust_remote_code(self, model_path)

  L 228: start_model_process(self, in_queue, out_queue, model_path, torch_dtype)

  L 353: forward(self, prompts: Union[List[List[str]], List[str], List[torch.Tensor]], image_data: Optional[List[str]], max_new_tokens: int, lora_paths: Optional[List[str]], token_ids_logprob: Optional[int])

  L 368: terminate(self)

  L 372: __enter__(self)

  L 375: __exit__(self, exc_type, exc_value, traceback)

  L 380: forward_generation_raw(base_model, prompts: Union[List[str], List[torch.Tensor]], max_new_tokens: int, tokenizer, torch_dtype: torch.dtype, lora_paths: Optional[List[str]], output_str_only: bool, token_ids_logprob: Optional[int], patch_model_do_sample_false: Optional[bool])
         ‚Üí ModelOutput


CLASS: SRTRunner
----------------------------------------
  L 486: __init__(self, model_path: str, torch_dtype: torch.dtype, model_type: str, tp_size: int, model_impl: str, port: int, lora_paths: Optional[Union[List[str], List[dict[str, str]]]], max_loras_per_batch: int, attention_backend: Optional[str], prefill_attention_backend: Optional[str], decode_attention_backend: Optional[str], lora_backend: str, disable_cuda_graph: bool, disable_radix_cache: bool, chunked_prefill_size: Optional[int], dp_size: int, tokenizer_path: Optional[str], mem_fraction_static: float, trust_remote_code: bool, speculative_draft_model_path: Optional[str], speculative_algorithm: Optional[str], speculative_num_steps: Optional[int], speculative_eagle_topk: Optional[int], speculative_num_draft_tokens: Optional[int], disable_overlap_schedule: bool, disable_custom_all_reduce: bool, torchao_config: Optional[str], cuda_graph_max_bs: int, sleep_on_idle, max_lora_rank: Optional[int], lora_target_modules: Optional[List[str]], enable_lora: Optional[bool], max_loaded_loras: Optional[int])

  L 574: load_lora_adapter(self, lora_name: str, lora_path: str, pinned: bool)

  L 577: unload_lora_adapter(self, lora_name: str)

  L 580: forward(self, prompts: Union[List[List[str]], List[str], List[torch.Tensor]], image_data: Optional[List[str]], max_new_tokens: int, lora_paths: Optional[List[str]], logprob_start_len: int, top_k: Optional[int], token_ids_logprob: Optional[List[int]])

  L 623: batch_forward(self, prompts: Union[List[str], List[torch.Tensor]], image_data: Optional[List[str]], max_new_tokens, lora_paths)
         üìù testing serving by sending all prompts once
            only return output strings and no logprobs

  L 650: __enter__(self)

  L 653: __exit__(self, exc_type, exc_value, traceback)

  L 658: forward_generation_raw(engine: Engine, prompts: Union[List[str], List[torch.Tensor]], max_new_tokens: int, lora_paths: Optional[List[str]], logprob_start_len: int, top_k: Optional[int], token_ids_logprob: Optional[List[int]])

  L 788: batch_forward_generation_raw(prompts: Union[List[str], List[torch.Tensor]], max_new_tokens, lora_paths, engine)


============================================================
FILE: python/sglang/test/send_one.py
Functions: 3
============================================================

MODULE FUNCTIONS:
----------------------------------------
  L  61: def send_one_prompt(args)


CLASS: BenchArgs
----------------------------------------
  L  34: add_cli_args(parser: argparse.ArgumentParser)

  L  56: from_cli_args(cls, args: argparse.Namespace)


============================================================
FILE: python/sglang/test/simple_eval_common.py
Functions: 14
============================================================

MODULE FUNCTIONS:
----------------------------------------
  L 254: def format_multichoice_question(row)

  L 258: def check_equality(sampler: SamplerBase, expr1: str, expr2: str)

  L 277: def aggregate_results(single_eval_results: List[SingleEvalResult],
        default_stats: Tuple[str],
        name2stats: Optional[Dict[str,
        Tuple[str]]])
         ‚Üí EvalResult
         üìù Aggregate results from multiple evaluations into a single EvalResult.

  L 310: def map_with_progress(f: callable, xs: List[Any], num_threads: int)
         üìù Apply f to each element of xs, using a ThreadPool, and show progress.

  L 339: def message_to_html(message: Message)
         ‚Üí str
         üìù Generate HTML snippet (inside a <div>) for a message.

  L 419: def make_report(eval_result: EvalResult)
         ‚Üí str
         üìù Create a standalone HTML report from an EvalResult.

  L 430: def make_report_from_example_htmls(htmls: List[str])
         üìù Create a standalone HTML report from a list of example htmls

  L 439: def download_dataset(path, url)

  L 464: def set_ulimit(target_soft_limit)


CLASS: ChatCompletionSampler
----------------------------------------
  L  88: __init__(self, base_url: str, model: Optional[str], system_message: Optional[str], temperature: float, reasoning_effort: Optional[str], max_tokens: int)

  L 133: __call__(self, message_list: MessageList)
         ‚Üí str


CLASS: Eval
----------------------------------------
  L  69: __call__(self, sampler: SamplerBase)
         ‚Üí EvalResult


CLASS: LargerHttpxClient
----------------------------------------
  L  74: __init__(self)


CLASS: SamplerBase
----------------------------------------
  L  36: __call__(self, message_list: MessageList)
         ‚Üí str


============================================================
FILE: python/sglang/test/simple_eval_gpqa.py
Functions: 2
============================================================


CLASS: GPQAEval
----------------------------------------
  L  29: __init__(self, filename: str, num_examples: Optional[int], num_threads: int, n_repeats: int)

  L  50: __call__(self, sampler: SamplerBase)
         ‚Üí EvalResult


============================================================
FILE: python/sglang/test/simple_eval_humaneval.py
Functions: 3
============================================================

MODULE FUNCTIONS:
----------------------------------------
  L  34: def evaluate_functional_correctness(sample: Dict[str,
        str],
        completions: List[str],
        n_workers: int,
        timeout: float)
         üìù Evaluates the functional correctness of generated samples, and writes
            results to f"{sample_file}_results.jsonl.gz"


CLASS: HumanEval
----------------------------------------
  L  62: __init__(self, num_examples: Optional[int], num_threads: int, num_samples_per_task: int, ks_passes: List[int], timeout: int)

  L  82: __call__(self, sampler: SamplerBase)
         ‚Üí EvalResult


============================================================
FILE: python/sglang/test/simple_eval_math.py
Functions: 2
============================================================


CLASS: MathEval
----------------------------------------
  L  36: __init__(self, filename: str, equality_checker: SamplerBase, num_examples: Optional[int], num_threads: int)

  L  51: __call__(self, sampler: SamplerBase)
         ‚Üí EvalResult


============================================================
FILE: python/sglang/test/simple_eval_mgsm.py
Functions: 6
============================================================

MODULE FUNCTIONS:
----------------------------------------
  L  91: def parse_answer(answer: str, answer_prefix: str)
         ‚Üí str

  L 105: def score_mgsm(target: str, prediction: str)
         ‚Üí bool

  L 115: def get_lang_examples(lang: str)
         ‚Üí list[dict[str, str]]

  L 128: def get_all_examples()
         ‚Üí list[dict[str, str]]


CLASS: MGSMEval
----------------------------------------
  L 138: __init__(self, num_examples_per_lang: int, num_threads: int, languages: Optional[list[str]])

  L 163: __call__(self, sampler: SamplerBase)
         ‚Üí EvalResult


============================================================
FILE: python/sglang/test/simple_eval_mmlu.py
Functions: 2
============================================================


CLASS: MMLUEval
----------------------------------------
  L  88: __init__(self, filename: str, num_examples: Optional[int], num_threads: int)

  L  96: __call__(self, sampler: SamplerBase)
         ‚Üí EvalResult


============================================================
FILE: python/sglang/test/test_activation.py
Functions: 4
============================================================


CLASS: TestGeluAndMul
----------------------------------------
  L  20: setUpClass(cls)

  L  42: test_gelu_and_mul(self)


CLASS: TestQuickGELU
----------------------------------------
  L  65: setUpClass(cls)

  L  91: test_quick_gelu(self)


============================================================
FILE: python/sglang/test/test_block_fp8.py
Functions: 19
============================================================

MODULE FUNCTIONS:
----------------------------------------
  L  24: def native_per_token_group_quant_fp8(x, group_size, eps, dtype)
         üìù Function to perform per-token-group quantization on an input tensor `x` using native torch.
            It converts the tensor values into float8 values and returns the
            quantized tensor along with the scaling factor used for quantization.
            Note that only `torch.float8_e4m3fn` is supported for now.

  L  98: def native_static_quant_fp8(x, x_s, dtype)
         üìù Function to perform static quantization on an input tensor `x` using native torch.
            It converts the tensor values into float8 values and returns the
            quantized tensor along with the scaling factor used for quantization.

  L 274: def native_w8a8_block_fp8_matmul(A, B, As, Bs, block_size, output_dtype)
         üìù This function performs matrix multiplication with block-wise quantization using native torch.
            It takes two input tensors `A` and `B` with scales `As` and `Bs`.
            The output is returned in the specified `output_dtype`.

  L 419: def torch_w8a8_block_fp8_moe(a, w1, w2, w1_s, w2_s, score, topk, block_shape)
         üìù This function performs fused moe with block-wise quantization using native torch.

  L 551: def torch_w8a8_block_fp8_bmm(a, a_s, w, w_s, block_shape, out_dtype)
         üìù This function performs bmm with block-wise quantization using native torch.


CLASS: TestPerTensorQuantMlaFP8
----------------------------------------
  L 171: setUpClass(cls)

  L 197: test_per_tensor_quant_mla_fp8(self)


CLASS: TestPerTokenGroupQuantFP8
----------------------------------------
  L  60: setUpClass(cls)

  L  79: test_per_token_group_quant_fp8(self)


CLASS: TestPerTokenGroupQuantMlaDeepGemmMaskedFP8
----------------------------------------
  L 226: setUpClass(cls)

  L 253: test_per_token_group_quant_mla_deep_gemm_masked_fp8(self)


CLASS: TestStaticQuantFP8
----------------------------------------
  L 126: setUpClass(cls)

  L 146: test_static_quant_fp8(self)


CLASS: TestW8A8BlockFP8BatchedDeepGemm
----------------------------------------
  L 576: setUpClass(cls)

  L 637: test_w8a8_block_fp8_batched_deep_gemm(self)


CLASS: TestW8A8BlockFP8FusedMoE
----------------------------------------
  L 463: setUpClass(cls)

  L 526: test_w8a8_block_fp8_fused_moe(self)


CLASS: TestW8A8BlockFP8Matmul
----------------------------------------
  L 362: setUpClass(cls)

  L 400: test_w8a8_block_fp8_matmul(self)


============================================================
FILE: python/sglang/test/test_block_fp8_deep_gemm_blackwell.py
Functions: 11
============================================================

MODULE FUNCTIONS:
----------------------------------------
  L  15: def ceil_div(x: int, y: int)
         ‚Üí int

  L  19: def align(x: int, y: int)
         ‚Üí int

  L  23: def per_token_group_quant_fp8(x: torch.Tensor)
         ‚Üí Tuple[torch.Tensor, torch.Tensor]

  L  32: def per_block_quant_fp8(x: torch.Tensor)
         ‚Üí Tuple[torch.Tensor, torch.Tensor]

  L  48: def ceil_to_ue8m0(x: torch.Tensor)

  L  53: def per_token_group_quant_mxfp8(x: torch.Tensor)
         ‚Üí Tuple[torch.Tensor, torch.Tensor]

  L  62: def per_block_quant_mxfp8(x: torch.Tensor)
         ‚Üí Tuple[torch.Tensor, torch.Tensor]

  L  79: def native_w8a8_block_fp8_matmul(A, B, As, Bs, block_size, output_dtype)
         üìù This function performs matrix multiplication with block-wise quantization using native torch.
            It takes two input tensors `A` and `B` with scales `As` and `Bs`.
            The output is returned in the specified `output_dtype`.

  L 134: def block_quant_dequant(x_q_block: torch.Tensor,
        x_s: torch.Tensor,
        block_size: List[int],
        dtype: torch.dtype)
         ‚Üí torch.Tensor
         üìù This function converts block-wise quantization to unquantized.
            The inputs are block-wise quantization tensor `x_q_block`, block-wise quantization scale
            and the block size.
            The output is an unquantized tensor with dtype.


CLASS: TestDeepGemmBlackwell
----------------------------------------
  L 202: setUpClass(cls)

  L 233: test_deep_gemm_blackwell(self)


============================================================
FILE: python/sglang/test/test_block_fp8_ep.py
Functions: 4
============================================================

MODULE FUNCTIONS:
----------------------------------------
  L  20: def ep_moe(hidden_states: torch.Tensor,
        w1: torch.Tensor,
        w2: torch.Tensor,
        router_logits: torch.Tensor,
        topk_config: TopKConfig,
        num_experts: int,
        fp8_dtype: torch.types,
        num_experts_per_partition: int,
        start_expert_id: int,
        end_expert_id: int,
        use_fp8_w8a8: bool,
        w1_scale_inv: Optional[torch.Tensor],
        w2_scale_inv: Optional[torch.Tensor],
        block_shape: Optional[List[int]])

  L 183: def block_dequant(x_q_block: torch.Tensor,
        x_s: torch.Tensor,
        block_size: List[int])
         ‚Üí Tuple[torch.Tensor, torch.Tensor]
         üìù This function converts block-wise quantization to tensor-wise quantization.
            The inputs are block-wise quantization tensor `x_q_block`, block-wise quantization scale
            and the block size.
            The outputs are tensor-wise quantization tensor and tensor-wise quantization scale.
            Note only float8 is supported for now.


CLASS: TestW8A8BlockFP8EPMoE
----------------------------------------
  L 241: setUpClass(cls)

  L 330: test_w8a8_block_fp8_ep_moe(self)


============================================================
FILE: python/sglang/test/test_custom_ops.py
Functions: 3
============================================================

MODULE FUNCTIONS:
----------------------------------------
  L  16: def test_scaled_fp8_quant_per_tensor(dtype)
         ‚Üí None
         @pytest.mark.parametrize('dtype', [torch.float16, torch.bfloat16])

  L  59: def test_scaled_fp8_quant_per_token_dynamic(dtype)
         ‚Üí None
         @pytest.mark.parametrize('dtype', [torch.float16, torch.bfloat16])

  L  91: def test_scaled_fp8_quant_with_padding(dtype)
         ‚Üí None
         @pytest.mark.parametrize('dtype', [torch.float16, torch.bfloat16])


============================================================
FILE: python/sglang/test/test_cutlass_moe.py
Functions: 5
============================================================

MODULE FUNCTIONS:
----------------------------------------
  L  15: def calc_diff(x, y)

  L  22: def get_model_config(tp_size: int)

  L  41: def to_fp8(tensor: torch.Tensor)
         ‚Üí torch.Tensor
         üìù Converts tensor to FP8 E4M3, scaling values to fit the range.

  L  63: def run_test(tp_size, batch_size, model_config, check)

  L 244: def main(tp_size, batch_sizes, check)


============================================================
FILE: python/sglang/test/test_cutlass_w4a8_moe.py
Functions: 5
============================================================

MODULE FUNCTIONS:
----------------------------------------
  L  12: def pack_int4_values_to_int8(int4_values_interleaved: torch.Tensor)
         ‚Üí torch.Tensor

  L  28: def pack_interleave(num_experts, ref_weight, ref_scale)

  L  55: def test_cutlass_w4a8_moe(M, N, K, E, ep_size, topk, group_size, dtype)
         @pytest.mark.parametrize('M', [1, 2, 4, 8, 16])
         @pytest.mark.parametrize('N', [2048])
         @pytest.mark.parametrize('K', [7168])
         @pytest.mark.parametrize('E', [256])
         @pytest.mark.parametrize('ep_size', [8])
         @pytest.mark.parametrize('topk', [8])
         @pytest.mark.parametrize('group_size', [128])
         @pytest.mark.parametrize('dtype', [torch.bfloat16])

  L 161: def cutlass_moe(a: torch.Tensor,
        w1_q: torch.Tensor,
        w2_q: torch.Tensor,
        w1_scale: torch.Tensor,
        w2_scale: torch.Tensor,
        topk_weights: torch.Tensor,
        topk_ids_: torch.Tensor,
        a_strides1: torch.Tensor,
        b_strides1: torch.Tensor,
        c_strides1: torch.Tensor,
        a_strides2: torch.Tensor,
        b_strides2: torch.Tensor,
        c_strides2: torch.Tensor,
        s_strides13: torch.Tensor,
        s_strides2: torch.Tensor,
        start_expert_id: int,
        end_expert_id: int,
        E: int,
        a1_scale: Optional[torch.Tensor],
        a2_scale: Optional[torch.Tensor],
        expert_map: Optional[torch.Tensor],
        apply_router_weight_on_input: bool)

  L 228: def ref(x: torch.Tensor,
        num_experts: int,
        topk_weights: torch.Tensor,
        topk_ids: torch.Tensor,
        ref_weight_1: torch.Tensor,
        ref_weight_2: torch.Tensor,
        ref_weight_scale_1: torch.Tensor,
        ref_weight_scale_2: torch.Tensor,
        has_pre_quant: bool,
        has_alpha: bool,
        pre_quant_scale_1: Optional[torch.Tensor],
        pre_quant_scale_2: Optional[torch.Tensor],
        alpha_1: Optional[torch.Tensor],
        alpha_2: Optional[torch.Tensor])


============================================================
FILE: python/sglang/test/test_deepep_utils.py
Functions: 13
============================================================

MODULE FUNCTIONS:
----------------------------------------
  L  12: def init_dist(local_rank: int, num_local_ranks: int)

  L  37: def calc_diff(x: torch.Tensor, y: torch.Tensor)

  L  44: def per_token_cast_to_fp8(x: torch.Tensor)

  L  54: def per_token_cast_back(x_fp8: torch.Tensor, x_scales: torch.Tensor)

  L  60: def inplace_unique(x: torch.Tensor, num_slots: int)

  L  75: def create_grouped_scores(scores: torch.Tensor,
        group_idx: torch.Tensor,
        num_groups: int)

  L  85: def bench(fn, num_warmups: int, num_tests: int, post_fn)

  L 158: def bench_kineto(fn,
        kernel_names,
        num_tests: int,
        suppress_kineto_output: bool,
        trace_path: Optional[str],
        barrier_comm_profiling: bool)

  L 218: def hash_tensor(t: torch.Tensor)


CLASS: empty_suppress
----------------------------------------
  L 116: __enter__(self)

  L 119: __exit__(self)


CLASS: suppress_stdout_stderr
----------------------------------------
  L 124: __enter__(self)

  L 144: __exit__(self)


============================================================
FILE: python/sglang/test/test_dynamic_grad_mode.py
Functions: 4
============================================================


CLASS: TestDynamicGradMode
----------------------------------------
  L  10: test_inference(self)

  L  21: test_no_grad(self)

  L  32: test_nested_inference(self)

  L  44: test_nested_no_grad(self)


============================================================
FILE: python/sglang/test/test_fp4_moe.py
Functions: 7
============================================================

MODULE FUNCTIONS:
----------------------------------------
  L  28: def convert_swizzled_to_linear(a_sf_swizzled: torch.Tensor, m, k, block_size)

  L  38: def dequantize_nvfp4_to_dtype(tensor_fp4,
        tensor_sf,
        global_scale,
        dtype,
        device,
        block_size)
         üìù Dequantize the fp4 tensor back to high precision.

  L  57: def break_fp4_bytes(a, dtype)

  L  96: def torch_moe(a, w1, w2, score, topk, expert_map)

  L 117: def check_moe(m: int,
        n: int,
        k: int,
        e: int,
        topk: int,
        dtype: torch.dtype,
        moe_impl: Callable,
        flip_w13: bool)

  L 244: def test_cutlass_fp4_moe_no_graph(m: int,
        n: int,
        k: int,
        e: int,
        topk: int,
        dtype: torch.dtype)
         @pytest.mark.parametrize('m,n,k', MNK_FACTORS)
         @pytest.mark.parametrize('e', [40, 64, 256])
         @pytest.mark.parametrize('topk', [1, 6, 8])
         @pytest.mark.parametrize('dtype', [torch.half, torch.bfloat16])
         @torch.inference_mode()

  L 291: def test_flashinfer_fp4_moe_no_graph(m: int,
        n: int,
        k: int,
        e: int,
        topk: int,
        dtype: torch.dtype)
         @pytest.mark.parametrize('m,n,k', MNK_FACTORS)
         @pytest.mark.parametrize('e', [40, 64, 256])
         @pytest.mark.parametrize('topk', [1, 6, 8])
         @pytest.mark.parametrize('dtype', [torch.half, torch.bfloat16])
         @torch.inference_mode()


============================================================
FILE: python/sglang/test/test_layernorm.py
Functions: 4
============================================================


CLASS: TestGemmaRMSNorm
----------------------------------------
  L  68: setUpClass(cls)

  L  94: test_gemma_rms_norm(self)


CLASS: TestRMSNorm
----------------------------------------
  L  18: setUpClass(cls)

  L  42: test_rms_norm(self)


============================================================
FILE: python/sglang/test/test_marlin_moe.py
Functions: 5
============================================================

MODULE FUNCTIONS:
----------------------------------------
  L  13: def stack_and_dev(tensors: list[torch.Tensor])

  L  18: def torch_experts(a: torch.Tensor,
        w1: torch.Tensor,
        w2: torch.Tensor,
        topk_weight: torch.Tensor,
        topk_ids: torch.Tensor,
        global_num_experts: int,
        expert_map: Optional[torch.Tensor],
        quant_dtype: Optional[torch.dtype],
        apply_router_weights_on_input: bool)
         ‚Üí torch.Tensor

  L  73: def torch_moe(a: torch.Tensor,
        w1: torch.Tensor,
        w2: torch.Tensor,
        score: torch.Tensor,
        topk: int,
        global_num_experts: int,
        expert_map: Optional[torch.Tensor])
         ‚Üí torch.Tensor

  L  89: def marlin_moe_generate_valid_test_cases()

  L 146: def test_fused_marlin_moe(m: int,
        n: int,
        k: int,
        e: int,
        topk: int,
        dtype: torch.dtype,
        group_size: int,
        act_order: bool,
        quant_type: ScalarType,
        is_k_full: bool)
         @pytest.mark.flaky(reruns=2)
         @pytest.mark.parametrize('m, n, k, e, topk, dtype, group_size,act_order, quant_type, is_k_full', marlin_moe_generate_valid_test_cases())


============================================================
FILE: python/sglang/test/test_marlin_utils.py
Functions: 6
============================================================

MODULE FUNCTIONS:
----------------------------------------
  L  42: def marlin_permute_weights(q_w, size_k, size_n, perm, tile)

  L  57: def marlin_weights(q_w, size_k, size_n, num_bits, perm)

  L  76: def get_weight_perm(num_bits: int)

  L 106: def marlin_quantize(w: torch.Tensor,
        quant_type: ScalarType,
        group_size: int,
        act_order: bool,
        test_perm: Optional[torch.Tensor])

  L 145: def awq_marlin_quantize(w: torch.Tensor,
        quant_type: ScalarType,
        group_size: int)


CLASS: MarlinWorkspace
----------------------------------------
  L  30: __init__(self, out_features, min_thread_n, max_parallel)


============================================================
FILE: python/sglang/test/test_programs.py
Functions: 19
============================================================

MODULE FUNCTIONS:
----------------------------------------
  L  13: def test_few_shot_qa()

  L  41: def test_mt_bench()

  L  62: def test_select(check_answer)

  L  96: def test_decode_int()

  L 107: def test_decode_json_regex()

  L 135: def test_decode_json()

  L 159: def test_expert_answer(check_answer)

  L 182: def test_tool_use()

  L 204: def test_react()

  L 240: def test_parallel_decoding()

  L 278: def test_parallel_encoding(check_answer)

  L 310: def test_image_qa()

  L 328: def test_stream()

  L 352: def test_regex()

  L 369: def test_dtype_gen()

  L 393: def test_completion_speculative()

  L 435: def test_chat_completion_speculative()

  L 456: def test_hellaswag_select()
         üìù Benchmark the accuracy of sgl.select on the HellaSwag dataset.

  L 545: def test_gen_min_new_tokens()
         üìù Validate sgl.gen(min_tokens) functionality.
            The test asks a question where, without a min_tokens constraint, the generated answer is expected to be short.
            By enforcing the min_tokens parameter, we ensure the generated answer has at least the specified number of tokens.
            We verify that the number of tokens in the answer is >= the min_tokens threshold.


============================================================
FILE: python/sglang/test/test_utils.py
Functions: 41
============================================================

MODULE FUNCTIONS:
----------------------------------------
  L 104: def is_in_ci()
         üìù Return whether it is in CI runner.

  L 109: def is_in_amd_ci()
         üìù Return whether it is in an AMD CI runner.

  L 137: def call_generate_lightllm(prompt, temperature, max_tokens, stop, url)

  L 154: def find_available_port(base_port: int)

  L 165: def call_generate_vllm(prompt, temperature, max_tokens, stop, n, url)

  L 184: def call_generate_outlines(prompt, temperature, max_tokens, stop, regex, n, url)

  L 206: def call_generate_srt_raw(prompt, temperature, max_tokens, stop, url)

  L 224: def call_generate_guidance(prompt,
        temperature,
        max_tokens,
        stop,
        n,
        regex,
        model)

  L 247: def call_select_lightllm(context, choices, url)

  L 264: def call_select_vllm(context, choices, url)

  L 288: def call_select_guidance(context, choices, model)

  L 296: def add_common_other_args_and_parse(parser: argparse.ArgumentParser)

  L 333: def auto_config_device()
         ‚Üí str
         üìù Auto-config available device platform

  L 345: def add_common_sglang_args_and_parse(parser: argparse.ArgumentParser)

  L 364: def select_sglang_backend(args: argparse.Namespace)

  L 418: def get_call_generate(args: argparse.Namespace)

  L 431: def get_call_select(args: argparse.Namespace)

  L 464: def try_cached_model(model_repo: str)

  L 469: def popen_launch_server(model: str,
        base_url: str,
        timeout: float,
        api_key: Optional[str],
        other_args: list[str],
        env: Optional[dict],
        return_stdout_stderr: Optional[tuple],
        device: str,
        pd_separated: bool)
         üìù Launch a server process with automatic device detection.
            Args:
            device: Device type ("auto", "cuda", "rocm" or "cpu").
            If "auto", will detect available platforms automatically.

  L 583: def popen_launch_pd_server(model: str,
        base_url: str,
        timeout: float,
        api_key: Optional[str],
        other_args: list[str],
        env: Optional[dict])

  L 624: def run_with_timeout(func: Callable,
        args: tuple,
        kwargs: Optional[dict],
        timeout: float)
         üìù Run a function with timeout.

  L 654: def run_unittest_files(files: List[TestFile], timeout_per_file: float)

  L 709: def get_similarities(vec1, vec2)

  L 713: def get_benchmark_args(base_url,
        dataset_name,
        dataset_path,
        tokenizer,
        num_prompts,
        sharegpt_output_len,
        random_input_len,
        random_output_len,
        sharegpt_context_len,
        request_rate,
        disable_stream,
        disable_ignore_eos,
        seed: int,
        device,
        pd_separated: bool,
        lora_name)

  L 764: def run_bench_serving(model,
        num_prompts,
        request_rate,
        other_server_args,
        dataset_name,
        dataset_path,
        tokenizer,
        random_input_len,
        random_output_len,
        sharegpt_context_len,
        disable_stream,
        disable_ignore_eos,
        need_warmup,
        seed: int,
        device,
        background_task: Optional[Callable[[str,
        asyncio.Event],
        Awaitable[None]]],
        lora_name: Optional[str])

  L 845: def run_bench_serving_multi(model,
        base_url,
        other_server_args,
        benchmark_args,
        need_warmup,
        pd_separated)

  L 879: def run_bench_one_batch(model, other_args)
         üìù Launch a offline process with automatic device detection.
            Args:
            device: Device type ("auto", "cuda", "rocm" or "cpu").
            If "auto", will detect available platforms automatically.

  L 934: def run_bench_offline_throughput(model, other_args)

  L 972: def run_bench_one_batch_server(model,
        base_url,
        server_args,
        bench_args,
        other_server_args,
        simulate_spec_acc_lens)

  L1000: def lcs(X, Y)

  L1017: def calculate_rouge_l(output_strs_list1, output_strs_list2)
         üìù calculate the ROUGE-L score

  L1038: def read_output(output_lines: List[str], filename: str)
         üìù Print the output in real time with another thread.

  L1059: def run_and_check_memory_leak(workload_func,
        disable_radix_cache,
        enable_mixed_chunk,
        disable_overlap,
        chunked_prefill_size,
        assert_has_abort)

  L1132: def run_command_and_capture_output(command, env: Optional[dict])

  L1159: def run_mmlu_test(disable_radix_cache,
        enable_mixed_chunk,
        disable_overlap,
        chunked_prefill_size)

  L1191: def run_mulit_request_test(disable_radix_cache,
        enable_mixed_chunk,
        enable_overlap,
        chunked_prefill_size)

  L1230: def write_github_step_summary(content)

  L1239: def run_logprob_check(self: unittest.TestCase, arg: Tuple)

  L1314: def send_generate_requests(base_url: str, num_requests: int)
         ‚Üí List[str]
         üìù Sends generate request serially and returns status codes. Max concurrency is 1.

  L1338: async def send_concurrent_generate_requests(base_url: str, num_requests: int)
         ‚Üí List[str]
         üìù Sends generate request concurrently and returns status codes. Max concurrency is num_requests.

  L1377: def dump_bench_raw_result(path: str, states, preds, labels)


============================================================
FILE: python/sglang/utils.py
Functions: 33
============================================================

MODULE FUNCTIONS:
----------------------------------------
  L  31: def execute_once(func)

  L  45: def info_once(message: str)
         @execute_once

  L  49: def convert_json_schema_to_str(json_schema: Union[dict, str, Type[BaseModel]])
         ‚Üí str
         üìù Convert a JSON schema to a string.
            Parameters
            ----------
            json_schema
            The JSON schema.
            Returns
            -------
            str
            The JSON schema converted to a string.
            Raises
            ------
            ValueError
            If the schema is not a dictionary, a string or a Pydantic class.

  L  79: def get_exception_traceback()

  L  85: def is_same_type(values: list)
         üìù Return whether the elements in values are of the same type.

  L  94: def read_jsonl(filename: str)
         üìù Read a JSONL file.

  L 103: def dump_state_text(filename: str, states: list, mode: str)
         üìù Dump program state in a text file.

  L 133: def http_request(url, json, stream, api_key, verify, method: Optional[str])
         üìù A faster version of requests.post with low-level urllib API.

  L 164: def encode_image_base64(image_path: Union[str, bytes])
         üìù Encode an image in base64.

  L 180: def encode_frame(frame)

  L 203: def encode_video_base64(video_path: str, num_frames: int)

  L 274: def find_printable_text(text: str)
         üìù Returns the longest printable substring of text that contains only entire words.

  L 316: def download_and_cache_file(url: str, filename: Optional[str])
         üìù Read and cache a file from a url.

  L 350: def is_in_ci()

  L 356: def print_highlight(html_content: str)

  L 367: def reserve_port(host, start, end)
         üìù Reserve an available port by trying to bind a socket.
            Returns a tuple (port, lock_socket) where `lock_socket` is kept open to hold the lock.

  L 388: def release_port(lock_socket)
         üìù Release the reserved port by closing the lock socket.

  L 398: def execute_shell_command(command: str)
         ‚Üí subprocess.Popen
         üìù Execute a shell command and return its process handle.

  L 407: def launch_server_cmd(command: str, host: str, port: int)
         üìù Launch the server using the given command.
            If no port is specified, a free port is reserved.

  L 426: def terminate_process(process)
         üìù Terminate the process and automatically release the reserved port.

  L 439: def wait_for_server(base_url: str, timeout: int)
         ‚Üí None
         üìù Wait for the server to be ready by polling the /v1/models endpoint.
            Args:
            base_url: The base URL of the server
            timeout: Maximum time to wait in seconds. None means wait forever.

  L 482: def trim_overlap(existing_text, new_chunk)
         üìù Finds the largest suffix of 'existing_text' that is a prefix of 'new_chunk'
            and removes that overlap from the start of 'new_chunk'.

  L 496: def stream_and_merge(llm, prompt, sampling_params)
         üìù 1) Streams the text,
            2) Removes chunk overlaps,
            3) Returns the merged text.

  L 510: async def async_stream_and_merge(llm, prompt, sampling_params)
         üìù Streams tokens asynchronously, removes chunk overlaps,
            and yields the cleaned chunk in real time for printing.

  L 524: def resolve_obj_by_qualname(qualname: str)
         ‚Üí Any
         üìù Resolve an object by its fully qualified name.


CLASS: HttpResponse
----------------------------------------
  L 122: __init__(self, resp)

  L 125: json(self)

  L 129: status_code(self)


CLASS: LazyImport
----------------------------------------
  L 296: __init__(self, module_name: str, class_name: str)

  L 307: __getattr__(self, name: str)

  L 311: __call__(self)


CLASS: TypeBasedDispatcher
----------------------------------------
  L 472: __init__(self, mapping: List[Tuple[Type, Callable]])

  L 475: __call__(self, obj: Any)
