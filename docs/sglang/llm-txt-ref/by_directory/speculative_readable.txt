================================================================================
FUNCTION INDEX: speculative module
================================================================================
Total Functions: 57
Documented: 7


============================================================
FILE: python/sglang/srt/speculative/build_eagle_tree.py
Functions: 3
============================================================

MODULE FUNCTIONS:
----------------------------------------
  L  17: def build_tree_kernel_efficient_preprocess(verified_id: torch.Tensor,
        score_list: List[torch.Tensor],
        token_list: List[torch.Tensor],
        parents_list: List[torch.Tensor],
        num_verify_tokens: int)

  L  51: def build_tree_kernel_efficient(verified_id: torch.Tensor,
        score_list: List[torch.Tensor],
        token_list: List[torch.Tensor],
        parents_list: List[torch.Tensor],
        seq_lens: torch.Tensor,
        seq_lens_sum: int,
        topk: int,
        spec_steps: int,
        num_verify_tokens: int,
        tree_mask_mode: TreeMaskMode,
        tree_mask_buf: Optional[torch.Tensor],
        position_buf: Optional[torch.Tensor])

  L 154: def test_build_tree_kernel_efficient()


============================================================
FILE: python/sglang/srt/speculative/eagle_draft_cuda_graph_runner.py
Functions: 5
============================================================


CLASS: EAGLEDraftCudaGraphRunner
----------------------------------------
  L  40: __init__(self, eagle_worker: EAGLEWorker)

  L 128: can_run(self, forward_batch: ForwardBatch)

  L 149: capture(self)

  L 152: capture_one_batch_size(self, num_seqs: int, forward: Callable)

  L 280: replay(self, forward_batch: ForwardBatch)


============================================================
FILE: python/sglang/srt/speculative/eagle_draft_extend_cuda_graph_runner.py
Functions: 5
============================================================


CLASS: EAGLEDraftExtendCudaGraphRunner
----------------------------------------
  L  37: __init__(self, eagle_worker: EAGLEWorker)

  L 155: can_run(self, forward_batch: ForwardBatch)

  L 176: capture(self)

  L 179: capture_one_batch_size(self, bs: int, forward: Callable)

  L 308: replay(self, forward_batch: ForwardBatch)


============================================================
FILE: python/sglang/srt/speculative/eagle_utils.py
Functions: 22
============================================================

MODULE FUNCTIONS:
----------------------------------------
  L 730: def create_extend_after_decode_spec_info(verified_id,
        seq_lens,
        accept_lens,
        positions,
        new_verified_id,
        bs_upper: tl.constexpr)
         @triton.jit

  L 756: def assign_req_to_token_pool(req_pool_indices,
        req_to_token,
        start_offset,
        end_offset,
        out_cache_loc,
        pool_len: tl.constexpr,
        bs_upper: tl.constexpr)
         @triton.jit

  L 791: def assign_draft_cache_locs(req_pool_indices,
        req_to_token,
        seq_lens,
        extend_lens,
        num_new_pages_per_topk,
        out_cache_loc,
        pool_len: tl.constexpr,
        topk: tl.constexpr,
        speculative_num_steps: tl.constexpr,
        page_size: tl.constexpr,
        bs_upper: tl.constexpr,
        iter_upper: tl.constexpr)
         @triton.jit

  L 867: def generate_draft_decode_kv_indices(req_pool_indices,
        req_to_token,
        paged_kernel_lens,
        kv_indices,
        kv_indptr,
        positions,
        pool_len: tl.constexpr,
        kv_indices_stride: tl.constexpr,
        kv_indptr_stride: tl.constexpr,
        bs_upper: tl.constexpr,
        iter_upper: tl.constexpr,
        num_tokens_upper: tl.constexpr,
        page_size: tl.constexpr)
         @triton.jit

  L 948: def align_evict_mask_to_page_size(seq_lens,
        evict_mask,
        page_size: tl.constexpr,
        num_draft_tokens: tl.constexpr,
        BLOCK_SIZE: tl.constexpr)
         @triton.jit

  L 973: def get_target_cache_loc(tgt_cache_loc,
        to_free_slots,
        accept_length,
        to_free_num_slots,
        out_cache_loc,
        num_verify_tokens: tl.constexpr,
        num_verify_tokens_upper: tl.constexpr,
        bs_upper: tl.constexpr)
         @triton.jit

  L1019: def get_src_tgt_cache_loc(seq_lens: torch.Tensor,
        out_cache_loc: torch.Tensor,
        accept_index: torch.Tensor,
        accept_length: torch.Tensor,
        draft_token_num: int,
        page_size: int)
         @torch.compile(dynamic=True)

  L1039: def filter_finished_cache_loc_kernel(out_cache_loc,
        tgt_cache_loc,
        accept_length,
        accept_length_filter,
        bs_upper: tl.constexpr,
        num_verify_tokens_upper: tl.constexpr)
         @triton.jit

  L1069: def create_accept_length_filter(accept_length: torch.Tensor,
        unfinished_index_device: torch.Tensor,
        seq_lens: torch.Tensor)
         @torch.compile(dynamic=True)

  L1083: def select_top_k_tokens(i: int,
        topk_p: torch.Tensor,
        topk_index: torch.Tensor,
        hidden_states: torch.Tensor,
        scores: torch.Tensor,
        topk: int)
         @torch.compile(dynamic=True)

  L1183: def traverse_tree(retrieve_next_token: torch.Tensor,
        retrieve_next_sibling: torch.Tensor,
        draft_tokens: torch.Tensor,
        grammar: BaseGrammarObject,
        allocate_token_bitmask: torch.Tensor)
         üìù Traverse the tree constructed by the draft model to generate the logits mask.

  L1249: def generate_token_bitmask(reqs: List[Req],
        verify_input: EagleVerifyInput,
        retrieve_next_token_cpu: torch.Tensor,
        retrieve_next_sibling_cpu: torch.Tensor,
        draft_tokens_cpu: torch.Tensor,
        vocab_size: int)
         üìù Generate the logit mask for structured output.
            Draft model's token can be either valid or invalid with respect to the grammar.
            We need to perform DFS to
            1. figure out which tokens are accepted by the grammar.
            2. if so, what is the corresponding logit mask.


CLASS: EagleDraftInput
----------------------------------------
  L  85: prepare_for_extend(self, batch: ScheduleBatch)

  L 102: create_idle_input(cls, device: torch.device, hidden_size: int, dtype: torch.dtype, topk: int, capture_hidden_mode: CaptureHiddenMode)

  L 120: prepare_extend_after_decode(self, batch: ScheduleBatch, speculative_num_steps: int)

  L 151: generate_attn_arg_prefill(self, req_pool_indices: torch.Tensor, paged_kernel_lens: torch.Tensor, paged_kernel_lens_sum: int, req_to_token: torch.Tensor)

  L 182: filter_batch(self, new_indices: torch.Tensor, has_been_filtered: bool)

  L 201: merge_batch(self, spec_info: EagleDraftInput)


CLASS: EagleVerifyInput
----------------------------------------
  L 250: create_idle_input(cls, topk: int, spec_steps: int, num_verify_tokens: int)

  L 273: prepare_for_verify(self, batch: ScheduleBatch, page_size: int)

  L 307: generate_attn_arg_prefill(self, req_pool_indices: torch.Tensor, paged_kernel_lens: torch.Tensor, paged_kernel_lens_sum: int, req_to_token: torch.Tensor)

  L 345: verify(self, batch: ScheduleBatch, logits_output: LogitsProcessorOutput, token_to_kv_pool_allocator: BaseTokenToKVPoolAllocator, page_size: int, vocab_mask: Optional[torch.Tensor])
         ‚Üí torch.Tensor
         üìù Verify and find accepted tokens based on logits output and batch
            (which contains spec decoding information).
            WARNING: This API in-place modifies the states of logits_output
            This API updates values inside logits_output based on the accepted
            tokens. I.e., logits_output.next_token_logits only contains
            accepted token logits.


============================================================
FILE: python/sglang/srt/speculative/eagle_worker.py
Functions: 18
============================================================

MODULE FUNCTIONS:
----------------------------------------
  L  62: def draft_tp_context(tp_group: GroupCoordinator)
         @contextmanager

  L1012: def load_token_map(token_map_path: str)
         ‚Üí List[int]

  L1024: def get_last_loc_large_page_size_top_k_1(req_to_token: torch.Tensor,
        req_pool_indices: torch.Tensor,
        seq_lens,
        speculative_num_steps: int)
         @torch.compile(dynamic=True)

  L1043: def get_last_loc_large_page_size_large_top_k(req_to_token: torch.Tensor,
        req_pool_indices: torch.Tensor,
        seq_lens: torch.Tensor,
        speculative_num_steps: int,
        topk: int,
        page_size: int)


CLASS: EAGLEWorker
----------------------------------------
  L  71: __init__(self, server_args: ServerArgs, gpu_id: int, tp_rank: int, dp_rank: Optional[int], moe_ep_rank: int, nccl_port: int, target_worker: TpModelWorker)

  L 184: init_attention_backend(self)

  L 322: init_cuda_graphs(self)
         üìù Capture cuda graphs.

  L 358: draft_model_runner(self)

  L 361: forward_batch_speculative_generation(self, batch: ScheduleBatch)
         ‚Üí Tuple[LogitsProcessorOutput, torch.Tensor, int, int, bool]
         üìù Run speculative decoding forward.
            NOTE: Many states of batch is modified as you go through. It is not guaranteed that
            the final output batch have the same state as the input.
            Args:
            batch: The batch to run forward. The state of the batch is modified as it runs.
            Returns:
            A tuple of the final logit output of the target model, next tokens accepted,
            the batch id (used for overlap schedule), and number of accepted tokens.

  L 409: check_forward_draft_extend_after_decode(self, batch: ScheduleBatch)

  L 427: forward_target_extend(self, batch: ScheduleBatch)
         ‚Üí Tuple[LogitsProcessorOutput, torch.Tensor, int, Optional[torch.Tensor]]
         üìù Run the target extend.
            Args:
            batch: The batch to run. States could be modified.
            Returns:
            logits_output: The output of logits. It will contain the full hidden states.
            next_token_ids: Next token ids generated.
            bid: The model batch ID. Used for overlap schedule.

  L 567: draft(self, batch: ScheduleBatch)

  L 645: draft_forward(self, forward_batch: ForwardBatch)

  L 704: verify(self, batch: ScheduleBatch, spec_info: EagleVerifyInput)

  L 781: add_logprob_values(self, batch: ScheduleBatch, res: EagleVerifyOutput, logits_output: LogitsProcessorOutput)

  L 860: forward_draft_extend(self, batch: ScheduleBatch, hidden_states: torch.Tensor, next_token_ids: torch.Tensor, seq_lens_cpu: Optional[torch.Tensor])
         üìù Run draft model extend. This API modifies the states of the batch.
            Args:
            batch: The batch to run.
            hidden_states: Hidden states from the target model forward
            next_token_ids: Next token ids generated from the target forward.

  L 911: forward_draft_extend_after_decode(self, batch: ScheduleBatch)

  L 997: capture_for_decode(self, logits_output: LogitsProcessorOutput, draft_input: EagleDraftInput)


============================================================
FILE: python/sglang/srt/speculative/spec_info.py
Functions: 4
============================================================


CLASS: SpeculativeAlgorithm
----------------------------------------
  L   9: is_none(self)

  L  12: is_eagle(self)

  L  15: is_eagle3(self)

  L  19: from_string(name: str)
