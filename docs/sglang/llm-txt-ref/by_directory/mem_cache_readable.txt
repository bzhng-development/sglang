================================================================================
FUNCTION INDEX: mem_cache module
================================================================================
Total Functions: 329
Documented: 48


============================================================
FILE: python/sglang/srt/mem_cache/allocator.py
Functions: 48
============================================================

MODULE FUNCTIONS:
----------------------------------------
  L 291: def alloc_extend_kernel(pre_lens_ptr,
        seq_lens_ptr,
        last_loc_ptr,
        free_page_ptr,
        out_indices,
        ret_values,
        bs_upper: tl.constexpr,
        page_size: tl.constexpr,
        max_num_extend_tokens: tl.constexpr)
         @triton.jit

  L 379: def alloc_decode_kernel(seq_lens_ptr,
        last_loc_ptr,
        free_page_ptr,
        out_indices,
        ret_values,
        bs_upper: tl.constexpr,
        page_size: tl.constexpr)
         @triton.jit


CLASS: BaseTokenToKVPoolAllocator
----------------------------------------
  L  38: __init__(self, size: int, page_size: int, dtype: torch.dtype, device: str, kvcache: KVCache, need_sort: bool)

  L  59: debug_print(self)
         ‚Üí str

  L  62: available_size(self)

  L  65: get_kvcache(self)

  L  68: restore_state(self, state)

  L  71: backup_state(self)

  L  74: free_group_begin(self)

  L  78: free_group_end(self)

  L  83: merge_and_sort_free(self)

  L  91: get_cpu_copy(self)

  L  95: load_cpu_copy(self)

  L  99: alloc_extend(self)

  L 102: alloc_decode(self)

  L 106: clear(self)

  L 110: alloc(self, need_size: int)

  L 114: free(self, free_index: torch.Tensor)


CLASS: PagedTokenToKVPoolAllocator
----------------------------------------
  L 429: __init__(self, size: int, page_size: int, dtype: torch.dtype, device: str, kvcache: KVCache, need_sort: bool)

  L 445: alloc(self, need_size: int)

  L 468: alloc_extend(self, prefix_lens: torch.Tensor, seq_lens: torch.Tensor, last_loc: torch.Tensor, extend_num_tokens: int)

  L 517: alloc_decode(self, seq_lens: torch.Tensor, last_loc: torch.Tensor)

  L 552: free(self, free_index: torch.Tensor)

  L 568: clear(self)

  L 577: get_cpu_copy(self, indices)

  L 580: load_cpu_copy(self, kv_cache_cpu, indices)


CLASS: SWATokenToKVPoolAllocator
----------------------------------------
  L 178: __init__(self, size: int, size_swa: int, dtype: torch.dtype, device: str, kvcache: SWAKVPool, need_sort: bool)

  L 214: available_size(self)

  L 217: full_available_size(self)

  L 220: swa_available_size(self)

  L 224: size_full(self)

  L 228: size_swa(self)

  L 231: debug_print(self)
         ‚Üí str

  L 239: get_kvcache(self)

  L 242: translate_loc_from_full_to_swa(self, kv_indices: torch.Tensor)

  L 246: alloc(self, need_size: int)

  L 257: free(self, free_index: torch.Tensor)

  L 270: free_swa(self, free_index: torch.Tensor)

  L 276: backup_state(self)

  L 279: restore_state(self, state)

  L 282: clear(self)


CLASS: TokenToKVPoolAllocator
----------------------------------------
  L 121: __init__(self, size: int, dtype: torch.dtype, device: str, kvcache: KVCache, need_sort: bool)

  L 132: clear(self)

  L 141: available_size(self)

  L 145: alloc(self, need_size: int)

  L 156: free(self, free_index: torch.Tensor)

  L 168: get_cpu_copy(self, indices)

  L 171: load_cpu_copy(self, kv_cache_cpu, indices)


============================================================
FILE: python/sglang/srt/mem_cache/allocator_ascend.py
Functions: 3
============================================================

MODULE FUNCTIONS:
----------------------------------------
  L  13: def alloc_extend_kernel_ascend(prefix_lens,
        seq_lens,
        last_loc,
        free_pages,
        out_indices,
        page_size,
        device)


CLASS: AscendPagedTokenToKVPoolAllocator
----------------------------------------
  L  69: alloc_extend(self, prefix_lens: torch.Tensor, seq_lens: torch.Tensor, last_loc: torch.Tensor, extend_num_tokens: int)

  L 115: alloc_decode(self, seq_lens: torch.Tensor, last_loc: torch.Tensor)


============================================================
FILE: python/sglang/srt/mem_cache/base_prefix_cache.py
Functions: 19
============================================================


CLASS: BasePrefixCache
----------------------------------------
  L  35: reset(self)

  L  39: match_prefix(self, key: List[int])
         ‚Üí MatchResult

  L  43: cache_finished_req(self, req: Req)

  L  47: cache_unfinished_req(self, req: Req)

  L  51: evict(self, num_tokens: int)

  L  55: inc_lock_ref(self, node: Any)

  L  59: dec_lock_ref(self, node: Any, swa_uuid_for_lock: Optional[str])

  L  62: evictable_size(self)

  L  65: full_evictable_size(self)

  L  68: swa_evictable_size(self)

  L  71: protected_size(self)

  L  74: full_protected_size(self)

  L  77: swa_protected_size(self)

  L  80: total_size(self)

  L  83: pretty_print(self)

  L  86: init_load_back(self, last_host_node: Any, host_hit_length: int)
         ‚Üí Tuple[torch.Tensor, Any]
         üìù Preparing KV cache loading from host to device.

  L  96: ready_to_load_host_cache(self)
         ‚Üí Any
         üìù Notify the cache controller to start the KV cache loading

  L 102: check_hicache_events(self)
         ‚Üí Any
         üìù Check HiCache related activities to update radix tree and synchronize across TP workers if needed

  L 108: take_events(self)


============================================================
FILE: python/sglang/srt/mem_cache/chunk_cache.py
Functions: 12
============================================================


CLASS: ChunkCache
----------------------------------------
  L  21: __init__(self, req_to_token_pool: ReqToTokenPool, token_to_kv_pool_allocator: BaseTokenToKVPoolAllocator, page_size: int)

  L  31: reset(self)

  L  34: match_prefix(self)
         ‚Üí MatchResult

  L  41: cache_finished_req(self, req: Req)

  L  50: cache_unfinished_req(self, req: Req, chunked)

  L  58: evict(self, num_tokens: int)

  L  61: inc_lock_ref(self, node: Any)

  L  64: dec_lock_ref(self, node: Any, swa_uuid_for_lock: Optional[str])

  L  67: pretty_print(self)


CLASS: SWAChunkCache
----------------------------------------
  L  74: __init__(self, req_to_token_pool: ReqToTokenPool, token_to_kv_pool_allocator: SWATokenToKVPoolAllocator, page_size: int)

  L  83: evict_swa(self, req: Req, prelen: int, attention_chunk_size: int)

  L  99: evict(self, num_tokens: int)


============================================================
FILE: python/sglang/srt/mem_cache/hicache_storage.py
Functions: 17
============================================================

MODULE FUNCTIONS:
----------------------------------------
  L  13: def get_hash_str(token_ids: List[int], prior_hash: str)
         ‚Üí str


CLASS: HiCacheFile
----------------------------------------
  L 133: __init__(self, storage_config: HiCacheStorageConfig, file_path: str)

  L 151: get(self, key: str, target_location: torch.Tensor, target_sizes: Optional[Any])
         ‚Üí torch.Tensor | None

  L 172: batch_get(self, keys: List[str], target_locations: List[torch.Tensor], target_sizes: Optional[Any])
         ‚Üí List[torch.Tensor | None]

  L 185: set(self, key: str, value: Optional[Any], target_location: Optional[Any], target_sizes: Optional[Any])
         ‚Üí bool

  L 205: batch_set(self, keys: List[str], values: Optional[Any], target_locations: Optional[Any], target_sizes: Optional[Any])
         ‚Üí bool

  L 217: exists(self, key: str)
         ‚Üí bool

  L 222: delete(self, key: str)
         ‚Üí None

  L 231: clear(self)
         ‚Üí bool


CLASS: HiCacheStorage
----------------------------------------
  L  44: get(self, key: str, target_location: Optional[Any], target_sizes: Optional[Any])
         ‚Üí torch.Tensor | None
         üìù Retrieve the value associated with the given key.
            Returns None if the key does not exist.

  L  57: batch_get(self, keys: List[str], target_locations: Optional[Any], target_sizes: Optional[Any])
         ‚Üí List[torch.Tensor | None] | int
         üìù Retrieve values for multiple keys.
            Returns a list of tensors or None for each key.

  L  70: set(self, key: str, value: Optional[Any], target_location: Optional[Any], target_sizes: Optional[Any])
         ‚Üí bool
         üìù Store the value associated with the given key.
            Returns True if the operation was successful, False otherwise.

  L  84: batch_set(self, keys: List[str], values: Optional[Any], target_locations: Optional[Any], target_sizes: Optional[Any])
         ‚Üí bool
         üìù Store multiple key-value pairs.
            Returns True if all operations were successful, False otherwise.

  L  98: exists(self, key: str)
         ‚Üí bool
         üìù Check if the key exists in the storage.
            Returns True if the key exists, False otherwise.

  L 106: delete(self, key: str)
         ‚Üí bool
         üìù Delete the entry associated with the given key.

  L 113: clear(self)
         ‚Üí bool
         üìù Clear all entries in the storage.

  L 119: batch_exists(self, keys: List[str])
         ‚Üí int
         üìù Check if the keys exist in the storage.
            return the number of consecutive existing keys from the start.
            Can be overridden by subclasses for more efficient implementation.


============================================================
FILE: python/sglang/srt/mem_cache/hiradix_cache.py
Functions: 21
============================================================


CLASS: HiRadixCache
----------------------------------------
  L  29: __init__(self, req_to_token_pool: ReqToTokenPool, token_to_kv_pool_allocator: BaseTokenToKVPoolAllocator, tp_cache_group: torch.distributed.ProcessGroup, page_size: int, hicache_ratio: float, hicache_size: int, hicache_write_policy: str, hicache_io_backend: str, hicache_mem_layout: str, hicache_storage_backend: Optional[str], hicache_storage_prefetch_policy: Optional[str], model_name: Optional[str], storage_backend_extra_config: Optional[str])

  L 112: reset(self)

  L 118: get_height(self, node: TreeNode)

  L 125: clear_storage_backend(self)

  L 134: write_backup(self, node: TreeNode, write_back)

  L 157: write_backup_storage(self, node: TreeNode)

  L 175: writing_check(self, write_back)

  L 200: loading_check(self)

  L 215: evictable_size(self)

  L 218: evict(self, num_tokens: int)

  L 270: evict_host(self, num_tokens: int)

  L 297: load_back(self, node: TreeNode, mem_quota: Optional[int])
         ‚Üí Optional[torch.Tensor]

  L 349: init_load_back(self, last_node: TreeNode, host_hit_length: int, mem_quota: Optional[int])

  L 372: ready_to_load_host_cache(self)

  L 377: check_hicache_events(self)

  L 383: drain_storage_control_queues(self)
         üìù Combine prefetch revoke, backup ack, and host mem release checks
            to minimize TP synchronization and Python overhead.

  L 430: can_terminate_prefetch(self, operation: PrefetchOperation)

  L 464: check_prefetch_progress(self, req_id: str)
         ‚Üí bool

  L 520: match_prefix(self, key: List[int])

  L 555: prefetch_from_storage(self, req_id: str, last_host_node: TreeNode, new_input_tokens: List[int], last_hash: Optional[str])

  L 682: insert(self, key: List, value, chunked)


============================================================
FILE: python/sglang/srt/mem_cache/lora_radix_cache.py
Functions: 21
============================================================

MODULE FUNCTIONS:
----------------------------------------
  L  32: def get_child_key(key: LoRAKey)


CLASS: LoRAKey
----------------------------------------
  L  22: __init__(self, lora_id: str, token_ids: List[int])

  L  28: __len__(self)


CLASS: LoRARadixCache
----------------------------------------
  L  79: __init__(self, req_to_token_pool: ReqToTokenPool, token_to_kv_pool_allocator: BaseTokenToKVPoolAllocator, page_size: int, disable: bool)

  L 104: reset(self)

  L 111: match_prefix(self, key: List[int])
         ‚Üí MatchResult

  L 116: match_prefix_with_lora_id(self, key: LoRAKey)
         ‚Üí MatchResult
         üìù Find the matching prefix from the lora radix tree.
            Args:
            key: A LoRAKey to find a matching prefix.
            Returns:
            A tuple of a tensor of matching prefix token IDs and
            the last node that contains the prefix values. Note that
            this API can modify the internal state of the Radix tree.
            The last node create a new child if the prefix is shorter
            than the last node's value.

  L 149: insert(self, key: LoRAKey, value)

  L 157: cache_finished_req(self, req: Req)
         üìù Cache request when it finishes.

  L 186: cache_unfinished_req(self, req: Req, chunked)
         üìù Cache request when it is unfinished.

  L 221: pretty_print(self)

  L 225: total_size(self)

  L 228: evict(self, num_tokens: int)

  L 251: inc_lock_ref(self, node: LoRATreeNode)

  L 265: dec_lock_ref(self, node: LoRATreeNode)

  L 279: evictable_size(self)

  L 282: protected_size(self)

  L 286: all_values_flatten(self)


CLASS: LoRATreeNode
----------------------------------------
  L  45: __init__(self, id: Optional[int])

  L  57: evicted(self)

  L  60: __lt__(self, other: 'LoRATreeNode')


============================================================
FILE: python/sglang/srt/mem_cache/memory_pool.py
Functions: 62
============================================================

MODULE FUNCTIONS:
----------------------------------------
  L 644: def set_mla_kv_buffer_kernel(kv_buffer_ptr,
        cache_k_nope_ptr,
        cache_k_rope_ptr,
        loc_ptr,
        buffer_stride: tl.constexpr,
        nope_stride: tl.constexpr,
        rope_stride: tl.constexpr,
        nope_dim: tl.constexpr,
        rope_dim: tl.constexpr,
        BLOCK: tl.constexpr)
         @triton.jit

  L 682: def set_mla_kv_buffer_triton(kv_buffer: torch.Tensor,
        loc: torch.Tensor,
        cache_k_nope: torch.Tensor,
        cache_k_rope: torch.Tensor)

  L1110: def copy_all_layer_kv_cache(data_ptrs,
        strides,
        tgt_loc_ptr,
        src_loc_ptr,
        num_locs,
        num_locs_upper: tl.constexpr)
         @triton.jit


CLASS: AscendMLAPagedTokenToKVPool
----------------------------------------
  L 885: __init__(self, size: int, page_size: int, dtype: torch.dtype, kv_lora_rank: int, qk_rope_head_dim: int, layer_num: int, device: str, enable_memory_saver: bool, start_layer: Optional[int], end_layer: Optional[int])

  L 947: get_kv_size_bytes(self)

  L 957: get_kv_buffer(self, layer_id: int)

  L 965: get_key_buffer(self, layer_id: int)

  L 973: get_value_buffer(self, layer_id: int)

  L 982: get_contiguous_buf_infos(self)

  L 995: set_kv_buffer(self, layer: RadixAttention, loc: torch.Tensor, cache_k: torch.Tensor, cache_v: torch.Tensor)


CLASS: AscendTokenToKVPool
----------------------------------------
  L 582: get_contiguous_buf_infos(self)

  L 608: set_kv_buffer(self, layer: RadixAttention, loc: torch.Tensor, cache_k: torch.Tensor, cache_v: torch.Tensor, k_scale: Optional[float], v_scale: Optional[float])


CLASS: DoubleSparseTokenToKVPool
----------------------------------------
  L1031: __init__(self, size: int, page_size: int, dtype: torch.dtype, head_num: int, head_dim: int, layer_num: int, device: str, heavy_channel_num: int, enable_memory_saver: bool, start_layer: Optional[int], end_layer: Optional[int])

  L1079: get_key_buffer(self, layer_id: int)

  L1082: get_value_buffer(self, layer_id: int)

  L1085: get_label_buffer(self, layer_id: int)

  L1088: get_kv_buffer(self, layer_id: int)

  L1094: set_kv_buffer(self, layer: RadixAttention, loc: torch.Tensor, cache_k: torch.Tensor, cache_v: torch.Tensor, cache_label: torch.Tensor)


CLASS: KVCache
----------------------------------------
  L 102: __init__(self, size: int, page_size: int, dtype: torch.dtype, layer_num: int, device: str, enable_memory_saver: bool, start_layer: Optional[int], end_layer: Optional[int])

  L 134: get_key_buffer(self, layer_id: int)
         ‚Üí torch.Tensor

  L 138: get_value_buffer(self, layer_id: int)
         ‚Üí torch.Tensor

  L 142: get_kv_buffer(self, layer_id: int)
         ‚Üí Tuple[torch.Tensor, torch.Tensor]

  L 146: set_kv_buffer(self, layer: RadixAttention, loc: torch.Tensor, cache_k: torch.Tensor, cache_v: torch.Tensor)
         ‚Üí None

  L 155: register_layer_transfer_counter(self, layer_transfer_counter)

  L 158: get_cpu_copy(self, indices)

  L 161: load_cpu_copy(self, kv_cache_cpu, indices)


CLASS: MHATokenToKVPool
----------------------------------------
  L 167: __init__(self, size: int, page_size: int, dtype: torch.dtype, head_num: int, head_dim: int, layer_num: int, device: str, enable_memory_saver: bool, start_layer: Optional[int], end_layer: Optional[int])

  L 267: get_kv_size_bytes(self)

  L 279: get_contiguous_buf_infos(self)

  L 305: maybe_get_custom_mem_pool(self)

  L 308: get_cpu_copy(self, indices)

  L 326: load_cpu_copy(self, kv_cache_cpu, indices)

  L 349: get_key_buffer(self, layer_id: int)

  L 364: get_value_buffer(self, layer_id: int)

  L 369: get_kv_buffer(self, layer_id: int)

  L 372: set_kv_buffer(self, layer: RadixAttention, loc: torch.Tensor, cache_k: torch.Tensor, cache_v: torch.Tensor, k_scale: Optional[float], v_scale: Optional[float], layer_id_override: Optional[int])

  L 412: move_kv_cache(self, tgt_loc: torch.Tensor, src_loc: torch.Tensor)


CLASS: MLATokenToKVPool
----------------------------------------
  L 710: __init__(self, size: int, page_size: int, dtype: torch.dtype, kv_lora_rank: int, qk_rope_head_dim: int, layer_num: int, device: str, enable_memory_saver: bool, start_layer: Optional[int], end_layer: Optional[int])

  L 779: get_kv_size_bytes(self)

  L 787: get_contiguous_buf_infos(self)

  L 796: maybe_get_custom_mem_pool(self)

  L 799: get_key_buffer(self, layer_id: int)

  L 807: get_value_buffer(self, layer_id: int)

  L 817: get_kv_buffer(self, layer_id: int)

  L 820: set_kv_buffer(self, layer: RadixAttention, loc: torch.Tensor, cache_k: torch.Tensor, cache_v: torch.Tensor)

  L 837: set_mla_kv_buffer(self, layer: RadixAttention, loc: torch.Tensor, cache_k_nope: torch.Tensor, cache_k_rope: torch.Tensor)

  L 856: get_cpu_copy(self, indices)

  L 871: load_cpu_copy(self, kv_cache_cpu, indices)


CLASS: ReqToTokenPool
----------------------------------------
  L  53: __init__(self, size: int, max_context_len: int, device: str, enable_memory_saver: bool)

  L  75: write(self, indices, values)

  L  78: available_size(self)

  L  81: alloc(self, need_size: int)
         ‚Üí List[int]

  L  90: free(self, free_index: Union[int, List[int]])

  L  96: clear(self)


CLASS: SWAKVPool
----------------------------------------
  L 426: __init__(self, size: int, size_swa: int, dtype: torch.dtype, head_num: int, head_dim: int, swa_attention_layer_ids: List[int], full_attention_layer_ids: List[int], enable_kvcache_transpose: bool, device: str)

  L 478: get_kv_size_bytes(self)

  L 483: get_contiguous_buf_infos(self)

  L 497: get_key_buffer(self, layer_id: int)

  L 504: get_value_buffer(self, layer_id: int)

  L 511: get_kv_buffer(self, layer_id: int)

  L 518: translate_loc_from_full_to_swa(self, kv_indices: torch.Tensor)

  L 522: set_kv_buffer(self, layer: RadixAttention, loc: torch.Tensor, cache_k: torch.Tensor, cache_v: torch.Tensor, k_scale: float, v_scale: float)


============================================================
FILE: python/sglang/srt/mem_cache/memory_pool_host.py
Functions: 48
============================================================

MODULE FUNCTIONS:
----------------------------------------
  L  38: def synchronized(debug_only)


CLASS: HostKVCache
----------------------------------------
  L  55: __init__(self, device_pool: KVCache, host_to_device_ratio: float, host_size: int, page_size: int, layout: str, pin_memory: bool, device: str)

  L 112: get_size_per_token(self)

  L 116: init_kv_buffer(self)

  L 120: load_to_device_per_layer(self, device_pool, host_indices, device_indices, layer_id, io_backend)
         ‚Üí None
         üìù Load KV data from the host memory pool to the device memory pool for a specific layer.

  L 129: backup_from_device_all_layer(self, device_pool, host_indices, device_indices, io_backend)
         ‚Üí None
         üìù Backup KV data from the device memory pool to the host memory pool for all layers.

  L 138: get_flat_data_page(self, index)
         ‚Üí torch.Tensor
         üìù Get a flat data page from the host memory pool.

  L 145: get_dummy_flat_data_page(self)
         ‚Üí torch.Tensor
         üìù Get a dummy flat data page from the host memory pool.
            This is used for prefetching or initializing empty pages.

  L 153: set_from_flat_data_page(self, index: int, data_page: torch.Tensor)
         ‚Üí None
         üìù Set a flat data page to the host memory pool.

  L 160: clear(self)

  L 167: available_size(self)

  L 171: alloc(self, need_size: int)
         ‚Üí torch.Tensor

  L 187: free(self, indices: torch.Tensor)
         ‚Üí int

  L 194: get_state(self, indices: torch.Tensor)
         ‚Üí MemoryStateInt

  L 203: is_reserved(self, indices: torch.Tensor)
         ‚Üí bool

  L 207: is_protected(self, indices: torch.Tensor)
         ‚Üí bool

  L 211: is_synced(self, indices: torch.Tensor)
         ‚Üí bool

  L 215: is_backup(self, indices: torch.Tensor)
         ‚Üí bool

  L 219: update_backup(self, indices: torch.Tensor)

  L 228: update_prefetch(self, indices: torch.Tensor)

  L 237: update_synced(self, indices: torch.Tensor)

  L 241: protect_write(self, indices: torch.Tensor)

  L 250: protect_load(self, indices: torch.Tensor)

  L 259: complete_io(self, indices: torch.Tensor)


CLASS: MHATokenToKVPoolHost
----------------------------------------
  L 271: __init__(self, device_pool: MHATokenToKVPool, host_to_device_ratio: float, host_size: int, page_size: int, layout: str, pin_memory: bool, device: str)

  L 303: get_size_per_token(self)

  L 310: get_ksize_per_token(self)

  L 313: init_kv_buffer(self)

  L 330: k_buffer(self)

  L 334: v_buffer(self)

  L 337: load_to_device_per_layer(self, device_pool, host_indices, device_indices, layer_id, io_backend)

  L 387: backup_from_device_all_layer(self, device_pool, host_indices, device_indices, io_backend)

  L 430: get_flat_data_page(self, index)
         ‚Üí torch.Tensor

  L 438: get_dummy_flat_data_page(self)
         ‚Üí torch.Tensor

  L 446: set_from_flat_data_page(self, index: int, data_page: torch.Tensor)
         ‚Üí None

  L 466: get_buffer_meta(self, keys, indices, local_rank)

  L 502: get_buffer_with_hash(self, keys, indices)


CLASS: MLATokenToKVPoolHost
----------------------------------------
  L 521: __init__(self, device_pool: MLATokenToKVPool, host_to_device_ratio: float, host_size: int, page_size: int, layout: str, pin_memory: bool, device: str)

  L 547: get_size_per_token(self)

  L 559: get_ksize_per_token(self)

  L 562: init_kv_buffer(self)

  L 591: load_to_device_per_layer(self, device_pool, host_indices, device_indices, layer_id, io_backend)

  L 627: backup_from_device_all_layer(self, device_pool, host_indices, device_indices, io_backend)

  L 666: get_flat_data_page(self, index)
         ‚Üí torch.Tensor

  L 674: get_dummy_flat_data_page(self)
         ‚Üí torch.Tensor

  L 687: set_from_flat_data_page(self, index: int, data_page: torch.Tensor)
         ‚Üí None

  L 705: get_buffer_meta(self, keys, indices, local_rank)

  L 729: get_buffer_with_hash(self, keys, indices)


============================================================
FILE: python/sglang/srt/mem_cache/multimodal_cache.py
Functions: 6
============================================================


CLASS: MultiModalCache
----------------------------------------
  L  14: __init__(self, max_size: int)

  L  40: put(self, mm_hash: int, embedding: torch.Tensor)
         ‚Üí bool

  L  49: has(self, mm_hash: int)
         ‚Üí bool

  L  52: get(self, mm_hash: int)
         ‚Üí torch.Tensor
         üìù Get embedding and update LRU order

  L  60: clear(self)

  L  67: __len__(self)


============================================================
FILE: python/sglang/srt/mem_cache/radix_cache.py
Functions: 22
============================================================


CLASS: RadixCache
----------------------------------------
  L 120: __init__(self, req_to_token_pool: ReqToTokenPool, token_to_kv_pool_allocator: BaseTokenToKVPoolAllocator, page_size: int, disable: bool, enable_kv_cache_events: bool)

  L 150: reset(self)

  L 160: match_prefix(self, key: List[int])
         ‚Üí MatchResult
         üìù Find the matching prefix from the radix tree.
            Args:
            key: A list of token IDs to find a matching prefix.
            Returns:
            A tuple of a tensor of matching prefix token IDs and
            the last node that contains the prefix values. Note that
            this API can modify the internal state of the Radix tree.
            The last node create a new child if the prefix is shorter
            than the last node's value.

  L 197: insert(self, key: List, value, chunked)

  L 205: cache_finished_req(self, req: Req)
         üìù Cache request when it finishes.

  L 242: cache_unfinished_req(self, req: Req, chunked)
         üìù Cache request when it is unfinished.

  L 289: pretty_print(self)

  L 293: total_size(self)

  L 296: evict(self, num_tokens: int)

  L 321: inc_lock_ref(self, node: TreeNode)

  L 335: dec_lock_ref(self, node: TreeNode)

  L 349: evictable_size(self)

  L 352: protected_size(self)

  L 356: all_values_flatten(self)

  L 543: take_events(self)
         üìù Atomically takes all events and clears the queue.
            Returns:
            A list of KV cache events.


CLASS: TreeNode
----------------------------------------
  L  47: __init__(self, id: Optional[int])

  L  70: evicted(self)

  L  74: backuped(self)

  L  77: protect_host(self)
         üìù Protect the host value from eviction.

  L  81: release_host(self)
         üìù Release the host value, allowing it to be evicted.

  L  88: get_last_hash_value(self)
         ‚Üí Optional[str]
         üìù Returns the hash value of the last page in this node.

  L  94: __lt__(self, other: 'TreeNode')


============================================================
FILE: python/sglang/srt/mem_cache/radix_cache_cpp.py
Functions: 12
============================================================


CLASS: RadixCacheCpp
----------------------------------------
  L  40: __init__(self, disable: bool, use_hicache: bool, req_to_token_pool: ReqToTokenPool, token_to_kv_pool: BaseTokenToKVPoolAllocator, tp_cache_group: torch.distributed.ProcessGroup, page_size: int, hicache_ratio: float, hicache_size: int, hicache_write_policy: str, enable_kv_cache_events: bool, hicache_oracle: bool, enable_write_cancel: bool)

  L  90: reset(self)

  L  96: match_prefix(self, key: List[int])
         ‚Üí MatchResult

  L 123: dec_lock_ref(self, node: TreeNodeCpp)
         üìù Decrement the reference count of a node to root of the radix tree.
            Args:
            node (TreeNodeCpp): The handle of the node to decrement the reference count for.

  L 131: inc_lock_ref(self, node: TreeNodeCpp)
         üìù Increment the reference count of from a node to root of the radix tree.
            Args:
            node (TreeNodeCpp): The handle of the node to increment the reference count for.

  L 139: evict(self, num_tokens: int)

  L 144: evictable_size(self)

  L 147: protected_size(self)

  L 150: total_size(self)

  L 153: cache_finished_req(self, req: Req)
         üìù Cache request when it finishes.

  L 184: cache_unfinished_req(self, req: Req, chunked)
         üìù Cache request when it is unfinished.

  L 228: pretty_print(self)


============================================================
FILE: python/sglang/srt/mem_cache/swa_radix_cache.py
Functions: 38
============================================================

MODULE FUNCTIONS:
----------------------------------------
  L 113: def gen_swa_uuid()
         ‚Üí int


CLASS: LRUList
----------------------------------------
  L 119: __init__(self, swa: bool)

  L 168: reset_node_mru(self, node)
         üìù Move a (existing) node to most recently used position

  L 179: reset_node_and_parents_mru(self, node, root_node)
         üìù Move an (existing) node and its parents to most recently used position. Child node is
            more recently used than parent node.

  L 196: insert_mru(self, node)
         üìù Insert a (new) node as most recently used

  L 209: remove_node(self, node: TreeNode)
         üìù Remove node from lru list

  L 220: get_lru_no_lock(self)
         ‚Üí Optional[TreeNode]
         üìù Get the least recently used node that is not locked

  L 226: get_leaf_lru_no_lock(self)
         ‚Üí Optional[TreeNode]
         üìù Get the least recently used leaf node that is not locked

  L 232: get_prev_no_lock(self, node: TreeNode, check_id: bool)
         ‚Üí Optional[TreeNode]
         üìù Get the previous (i.e. more recently used) node that is not locked

  L 250: get_prev_leaf_no_lock(self, node: TreeNode, check_id: bool)
         üìù Get the previous (i.e. more recently used) leaf node that is not locked

  L 266: in_list(self, node: Optional[TreeNode])
         üìù Check if the node is in the lru list

  L 275: sanity_check_evictable_size(self)
         üìù Check the evictable size (i.e. the size of the nodes that are not locked)

  L 287: sanity_check(self, tree_cache: 'SWARadixCache')
         üìù Check if the lru list is valid by rebuilding the lru list from the tree, heapifying it, and
            checking if the lru list is valid.


CLASS: SWARadixCache
----------------------------------------
  L 340: __init__(self, req_to_token_pool: ReqToTokenPool, token_to_kv_pool_allocator: SWATokenToKVPoolAllocator, sliding_window_size: int, page_size: int, disable: bool)

  L 371: reset(self)
         ‚Üí None

  L 385: match_prefix(self, key: List[int])
         ‚Üí MatchResult
         üìù Find the matching prefix from the radix tree.
            Args:
            key: A list of token IDs to find a matching prefix.
            Returns:
            A tuple of a tensor of matching prefix token IDs and
            the last node that contains the prefix values. Note that
            this API can modify the internal state of the Radix tree.
            The last node create a new child if the prefix is shorter
            than the last node's value.

  L 422: insert(self, key: List, value, prev_prefix_len: int)
         ‚Üí int

  L 430: cache_finished_req(self, req: Req)
         ‚Üí None
         üìù Cache request when it finishes.

  L 467: cache_unfinished_req(self, req: Req, chunked)
         ‚Üí None
         üìù Cache request when it is unfinished.

  L 521: pretty_print(self)
         ‚Üí None

  L 526: total_size(self)
         ‚Üí Tuple[int, int]

  L 529: evict(self, full_num_tokens: int, swa_num_tokens: int)
         ‚Üí None

  L 612: inc_lock_ref(self, node: TreeNode)
         ‚Üí Optional[int]
         üìù Increment the lock reference count for the node. Returns the swa_uuid_for_lock, which needs
            to be passed to dec_lock_ref.
            It locks the full_lock_ref for nodes between the [last node, root), exclusive.
            It locks the swa_lock_ref for nodes between the [last node, swa_uuid_for_lock], inclusive.

  L 653: dec_lock_ref(self, node: TreeNode, swa_uuid_for_lock: Optional[int])
         üìù Decrement the lock reference count for the node.
            It unlocks the full_lock_ref for nodes between the [last node, root), exclusive.
            It unlocks the swa_lock_ref for nodes between the [last node, swa_uuid_for_lock], inclusive.
            If swa_uuid_for_lock is None, it unlocks to the root, exclusive.

  L 690: sanity_check(self)

  L 694: evictable_size(self)
         ‚Üí Tuple[int, int]

  L 698: full_evictable_size(self)
         ‚Üí int

  L 701: swa_evictable_size(self)
         ‚Üí int

  L 705: full_lru_list_evictable_size(self)
         ‚Üí int

  L 709: swa_lru_list_evictable_size(self)
         ‚Üí int

  L 712: protected_size(self)
         ‚Üí Tuple[int, int]

  L 716: full_protected_size(self)
         ‚Üí int

  L 720: swa_protected_size(self)
         ‚Üí int

  L 724: all_values_flatten(self)
         ‚Üí torch.Tensor


CLASS: TreeNode
----------------------------------------
  L  47: __init__(self, id: Optional[int])

  L  81: evicted(self)

  L  85: backuped(self)

  L  88: __lt__(self, other: 'TreeNode')
