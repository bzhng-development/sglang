AST Function Index
Root: /Users/vincentzed/Documents/Github/open_source/sglang/python/sglang/srt
Excluded directories:

File: sampling/custom_logit_processor.py
  - name: _cache_from_str
    signature: (json_str: str)
    doc: Deserialize a json string to a Callable object.
  - name: __call__
    signature: (self, logits: torch.Tensor, custom_param_list: Optional[List[Dict[str, Any]]] = None)
    return: torch.Tensor
    class: CustomLogitProcessor
    doc: Define the callable behavior.
  - name: to_str
    signature: (cls)
    return: str
    class: CustomLogitProcessor
    doc: Serialize the callable function to a JSON-compatible string.
  - name: from_str
    signature: (cls, json_str: str)
    class: CustomLogitProcessor
    doc: Deserialize a callable function from a JSON string.
  - name: __call__
    signature: (self, logits: torch.Tensor, custom_param_list: Optional[List[Dict[str, Any]]] = None)
    return: torch.Tensor
    class: DisallowedTokensLogitsProcessor

File: sampling/penaltylib/__init__.py
  (no function definitions found)
File: sampling/penaltylib/frequency_penalty.py
  - name: __init__
    signature: (self, orchestrator: BatchedPenalizerOrchestrator)
    class: BatchedFrequencyPenalizer
  - name: _is_required
    signature: (self)
    return: bool
    class: BatchedFrequencyPenalizer
  - name: _prepare
    signature: (self)
    class: BatchedFrequencyPenalizer
  - name: _cumulate_output_tokens
    signature: (self, output_ids: torch.Tensor)
    class: BatchedFrequencyPenalizer
  - name: _apply
    signature: (self, logits: torch.Tensor)
    return: torch.Tensor
    class: BatchedFrequencyPenalizer
  - name: _filter
    signature: (self, keep_indices: torch.Tensor)
    class: BatchedFrequencyPenalizer
  - name: _merge
    signature: (self, their: 'BatchedFrequencyPenalizer')
    class: BatchedFrequencyPenalizer

File: sampling/penaltylib/min_new_tokens.py
  - name: __init__
    signature: (self, orchestrator: BatchedPenalizerOrchestrator)
    class: BatchedMinNewTokensPenalizer
  - name: _is_required
    signature: (self)
    return: bool
    class: BatchedMinNewTokensPenalizer
  - name: _prepare
    signature: (self)
    class: BatchedMinNewTokensPenalizer
  - name: _cumulate_output_tokens
    signature: (self, output_ids: torch.Tensor)
    class: BatchedMinNewTokensPenalizer
  - name: _apply
    signature: (self, logits: torch.Tensor)
    class: BatchedMinNewTokensPenalizer
  - name: _filter
    signature: (self, keep_indices: torch.Tensor)
    class: BatchedMinNewTokensPenalizer
  - name: _merge
    signature: (self, their: 'BatchedMinNewTokensPenalizer')
    class: BatchedMinNewTokensPenalizer

File: sampling/penaltylib/orchestrator.py
  - name: __init__
    signature: (self, vocab_size: int, batch: ScheduleBatch, penalizers: Set[Type['_BatchedPenalizer']])
    class: BatchedPenalizerOrchestrator
  - name: batch
    signature: (self)
    return: ScheduleBatch | None
    class: BatchedPenalizerOrchestrator
  - name: batch
    signature: (self, value: Optional[ScheduleBatch])
    class: BatchedPenalizerOrchestrator
  - name: reqs
    signature: (self)
    class: BatchedPenalizerOrchestrator
  - name: cumulate_output_tokens
    signature: (self, output_ids: torch.Tensor)
    class: BatchedPenalizerOrchestrator
    doc: Feed the output tokens to the penalizers.
  - name: apply
    signature: (self, logits: torch.Tensor)
    return: torch.Tensor
    class: BatchedPenalizerOrchestrator
    doc: Apply the penalizers to the logits.
  - name: filter
    signature: (self, keep_indices: torch.Tensor)
    class: BatchedPenalizerOrchestrator
    doc: Filter the penalizers based on the indices to keep in the batch.
  - name: merge
    signature: (self, their: 'BatchedPenalizerOrchestrator')
    class: BatchedPenalizerOrchestrator
    doc: Merge the penalizers of another orchestrator into this one.
  - name: is_prepared
    signature: (self)
    return: bool
    class: _BatchedPenalizer
  - name: is_required
    signature: (self)
    return: bool
    class: _BatchedPenalizer
  - name: prepare
    signature: (self)
    class: _BatchedPenalizer
  - name: prepare_if_required
    signature: (self)
    class: _BatchedPenalizer
  - name: teardown
    signature: (self)
    class: _BatchedPenalizer
  - name: cumulate_output_tokens
    signature: (self, output_ids: torch.Tensor)
    class: _BatchedPenalizer
  - name: apply
    signature: (self, logits: torch.Tensor)
    return: torch.Tensor
    class: _BatchedPenalizer
  - name: filter
    signature: (self, keep_indices: torch.Tensor)
    class: _BatchedPenalizer
  - name: merge
    signature: (self, their: '_BatchedPenalizer')
    class: _BatchedPenalizer
  - name: _is_required
    signature: (self)
    return: bool
    class: _BatchedPenalizer
    doc: Check if the penalizer is required to be prepared.
  - name: _prepare
    signature: (self)
    class: _BatchedPenalizer
    doc: Prepare the penalizer.
  - name: _cumulate_output_tokens
    signature: (self, output_ids: torch.Tensor)
    class: _BatchedPenalizer
    doc: Cumulate the output tokens.
  - name: _apply
    signature: (self, logits: torch.Tensor)
    return: torch.Tensor
    class: _BatchedPenalizer
    doc: Apply the penalizer to the logits.
  - name: _filter
    signature: (self, keep_indices: torch.Tensor)
    class: _BatchedPenalizer
    doc: Filter the penalizer (tensors or underlying data) based on the indices to keep in the batch.
  - name: _merge
    signature: (self, their: '_BatchedPenalizer')
    class: _BatchedPenalizer
    doc: Merge the penalizer with another penalizer.

File: sampling/penaltylib/presence_penalty.py
  - name: __init__
    signature: (self, orchestrator: BatchedPenalizerOrchestrator)
    class: BatchedPresencePenalizer
  - name: _is_required
    signature: (self)
    return: bool
    class: BatchedPresencePenalizer
  - name: _prepare
    signature: (self)
    class: BatchedPresencePenalizer
  - name: _cumulate_output_tokens
    signature: (self, output_ids: torch.Tensor)
    class: BatchedPresencePenalizer
  - name: _apply
    signature: (self, logits: torch.Tensor)
    return: torch.Tensor
    class: BatchedPresencePenalizer
  - name: _filter
    signature: (self, keep_indices: torch.Tensor)
    class: BatchedPresencePenalizer
  - name: _merge
    signature: (self, their: 'BatchedPresencePenalizer')
    class: BatchedPresencePenalizer

File: sampling/sampling_batch_info.py
  - name: from_schedule_batch
    signature: (cls, batch: ScheduleBatch, vocab_size: int)
    class: SamplingBatchInfo
  - name: __len__
    signature: (self)
    class: SamplingBatchInfo
  - name: update_regex_vocab_mask
    signature: (self)
    class: SamplingBatchInfo
  - name: update_penalties
    signature: (self)
    class: SamplingBatchInfo
  - name: apply_logits_bias
    signature: (self, logits: torch.Tensor)
    class: SamplingBatchInfo
  - name: filter_batch
    signature: (self, keep_indices: List[int], keep_indices_device: torch.Tensor)
    class: SamplingBatchInfo
  - name: _filter_batch_custom_logit_processor
    signature: (self, keep_indices: List[int], keep_indices_device: torch.Tensor)
    class: SamplingBatchInfo
    doc: Filter the custom logit processor and custom params
  - name: merge_custom_logit_processor
    signature: (lhs: Optional[Dict[int, Tuple[CustomLogitProcessor, torch.Tensor]]], rhs: Optional[Dict[int, Tuple[CustomLogitProcessor, torch.Tensor]]], bs1: int, bs2: int, device: str)
    class: SamplingBatchInfo
  - name: merge_batch
    signature: (self, other: 'SamplingBatchInfo')
    class: SamplingBatchInfo
  - name: merge_bias_tensor
    signature: (lhs: Optional[torch.Tensor], rhs: Optional[torch.Tensor], bs1: int, bs2: int, device: str, default: float)
    doc: Merge two bias tensors for batch merging.

File: sampling/sampling_params.py
  - name: __init__
    signature: (self, max_new_tokens: int = 128, stop: Optional[Union[str, List[str]]] = None, stop_token_ids: Optional[List[int]] = None, temperature: float = 1.0, top_p: float = 1.0, top_k: int = -1, min_p: float = 0.0, frequency_penalty: float = 0.0, presence_penalty: float = 0.0, repetition_penalty: float = 1.0, min_new_tokens: int = 0, n: int = 1, json_schema: Optional[str] = None, regex: Optional[str] = None, ebnf: Optional[str] = None, structural_tag: Optional[str] = None, ignore_eos: bool = False, skip_special_tokens: bool = True, spaces_between_special_tokens: bool = True, no_stop_trim: bool = False, custom_params: Optional[Dict[str, Any]] = None, stream_interval: Optional[int] = None, logit_bias: Optional[Dict[str, float]] = None)
    return: None
    class: SamplingParams
  - name: verify
    signature: (self, vocab_size)
    class: SamplingParams
  - name: normalize
    signature: (self, tokenizer)
    class: SamplingParams
