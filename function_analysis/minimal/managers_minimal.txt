managers/cache_controller.py:
  CacheOperation.__init__(self,host_indices,device_indices,node_id,priority)
  CacheOperation.__lt__(self,other)
  CacheOperation.merge(self,other)
  CacheOperation.split(self,factor)
  HiCacheController._3fs_zero_copy_page_get(self,operation,hash_values,host_indices)
  HiCacheController._3fs_zero_copy_page_set(self,hash_values,host_indices)
  HiCacheController.__init__(self,token_to_kv_pool_allocator,mem_pool_host,page_size,tp_group,load_cache_event,write_policy,io_backend,storage_backend,prefetch_threshold,model_name,storage_backend_extra_config)
  HiCacheController._generate_storage_config(self,model_name,storage_backend_extra_config)
  HiCacheController._generic_page_get(self,operation,hash_values,host_indices)
  HiCacheController._generic_page_set(self,hash_values,host_indices)
  HiCacheController._generic_storage_hit_query(self,operation)
  HiCacheController._mooncake_page_get(self,operation,hash_values,host_indices)
  HiCacheController._mooncake_page_set(self,hash_values,host_indices)
  HiCacheController._page_backup(self,operation)
  HiCacheController._page_transfer(self,operation)
  HiCacheController.backup_thread_func(self)
  HiCacheController.evict_device(self,device_indices,host_indices)
  HiCacheController.evict_host(self,host_indices,backup_only)
  HiCacheController.is_mooncake_backend(self)
  HiCacheController.load(self,host_indices,priority,node_id)
  HiCacheController.load_thread_func_layer_by_layer(self)
  HiCacheController.move_indices(self,host_indices,device_indices)
  HiCacheController.prefetch(self,request_id,host_indices,new_input_tokens,last_hash)
  HiCacheController.prefetch_io_aux_func(self)
  HiCacheController.prefetch_rate_limit_check(self)
  HiCacheController.prefetch_thread_func(self)
  HiCacheController.reset(self)
  HiCacheController.terminate_prefetch(self,operation)
  HiCacheController.write(self,device_indices,priority,node_id)
  HiCacheController.write_storage(self,host_indices,token_ids,hash_value)
  HiCacheController.write_thread_func_direct(self)
  LayerDoneCounter.__init__(self,num_layers)
  LayerDoneCounter.increment(self)
  LayerDoneCounter.next_producer(self)
  LayerDoneCounter.reset(self)
  LayerDoneCounter.set_consumer(self,index)
  LayerDoneCounter.update_producer(self)
  LayerDoneCounter.wait_until(self,threshold)
  PrefetchOperation.__init__(self,request_id,host_indices,token_ids,last_hash)
  PrefetchOperation.increment(self,num_tokens)
  PrefetchOperation.is_done(self)
  PrefetchOperation.mark_done(self)
  StorageOperation.__init__(self,host_indices,token_ids,last_hash,hash_value)
  StorageOperation.__lt__(self,other)
  TransferBuffer.__init__(self,stop_event,buffer_count,max_buffer_size)
  TransferBuffer.clear(self)
  TransferBuffer.empty(self)
  TransferBuffer.full(self)
  TransferBuffer.get(self,block,timeout)
  TransferBuffer.put(self,item,block,timeout)
managers/data_parallel_controller.py:
  DataParallelController.__init__(self,server_args,port_args,dp_balance_meta)
  DataParallelController.event_loop(self)
  DataParallelController.get_next_global_balance_id()
  DataParallelController.launch_dp_attention_schedulers(self,server_args,port_args)
  DataParallelController.launch_dp_schedulers(self,server_args,port_args)
  DataParallelController.launch_tensor_parallel_group(self,server_args,port_args,base_gpu_id,dp_rank)
  DataParallelController.launch_tensor_parallel_group_thread(self,server_args,port_args,base_gpu_id,dp_rank,ready_event)
  DataParallelController.minimum_tokens_scheduler(self,req)
  DataParallelController.round_robin_scheduler(self,req)
  DataParallelController.shortest_queue_scheduler(self,input_requests)
  LoadBalanceMethod.from_str(cls,method)
  run_data_parallel_controller_process(server_args,port_args,pipe_writer)
managers/detokenizer_manager.py:
  DetokenizerManager.__init__(self,server_args,port_args)
  DetokenizerManager.event_loop(self)
  DetokenizerManager.handle_batch_embedding_out(self,recv_obj)
  DetokenizerManager.handle_batch_token_id_out(self,recv_obj)
  DetokenizerManager.handle_freeze_gc_req(self,recv_req)
  DetokenizerManager.handle_multimodal_decode_req(self,recv_obj)
  DetokenizerManager.trim_matched_stop(self,output,finished_reason,no_stop_trim)
  LimitedCapacityDict.__init__(self,capacity,*args,**kwargs)
  LimitedCapacityDict.__setitem__(self,key,value)
  run_detokenizer_process(server_args,port_args)
managers/io_struct.py:
  BatchTokenizedEmbeddingReqInput.__getitem__(self,i)
  BatchTokenizedEmbeddingReqInput.__iter__(self)
  BatchTokenizedEmbeddingReqInput.__len__(self)
  BatchTokenizedGenerateReqInput.__getitem__(self,i)
  BatchTokenizedGenerateReqInput.__iter__(self)
  BatchTokenizedGenerateReqInput.__len__(self)
  EmbeddingReqInput.__getitem__(self,i)
  EmbeddingReqInput.contains_mm_input(self)
  EmbeddingReqInput.normalize_batch_and_arguments(self)
  EmbeddingReqInput.regenerate_rid(self)
  GenerateReqInput.__getitem__(self,i)
  GenerateReqInput._determine_batch_size(self)
  GenerateReqInput._expand_inputs(self,num)
  GenerateReqInput._handle_parallel_sampling(self)
  GenerateReqInput._normalize_audio_data(self,num)
  GenerateReqInput._normalize_batch_inputs(self)
  GenerateReqInput._normalize_custom_logit_processor(self,num)
  GenerateReqInput._normalize_image_data(self,num)
  GenerateReqInput._normalize_logprob_params(self,num)
  GenerateReqInput._normalize_lora_paths(self,num)
  GenerateReqInput._normalize_rid(self,num)
  GenerateReqInput._normalize_sampling_params(self,num)
  GenerateReqInput._normalize_single_inputs(self)
  GenerateReqInput._normalize_video_data(self,num)
  GenerateReqInput._validate_inputs(self)
  GenerateReqInput._validate_session_params(self)
  GenerateReqInput.contains_mm_input(self)
  GenerateReqInput.normalize_batch_and_arguments(self)
  GenerateReqInput.normalize_param(param,default_value,param_name)
  GenerateReqInput.regenerate_rid(self)
  LoadLoRAAdapterReqInput.to_ref(self)
  UnloadLoRAAdapterReqInput.to_ref(self)
managers/mm_utils.py:
  MultiModalityDataPaddingPattern.pad_input_tokens(self,input_ids,mm_inputs)
  MultiModalityDataPaddingPatternMultimodalTokens.pad_input_tokens(self,input_ids,mm_inputs)
  MultiModalityDataPaddingPatternTokenPairs.__init__(self,data_token_pairs,data_start_token_ids)
  MultiModalityDataPaddingPatternTokenPairs.pad_input_tokens(self,input_ids,mm_inputs)
  TransportProxyTensor.__getstate__(self)
  TransportProxyTensor.__new__(cls,data,name,fields,transport_mode,*args,**kwargs)
  TransportProxyTensor.__setstate__(self,state)
  TransportProxyTensor.fields(self)
  TransportProxyTensor.name(self)
  TransportProxyTensor.transport_mode(self)
  _adjust_embedding_length(embedding,mask,logger)
  _get_chunked_prefill_embedding(data_embedding_func,embedding_items,items_size,prefix_length,extend_length,items_offset_list)
  _get_multimodal_mask(input_ids,placeholder_tensor)
  _get_precomputed_embedding(items)
  data_hash(data)
  embed_mm_inputs(mm_inputs_list,extend_prefix_lens,extend_seq_lens,input_ids,input_embedding,multimodal_model,data_embedding_func_mapping,placeholder_tokens)
  general_mm_embed_routine(input_ids,forward_batch,language_model,multimodal_model,data_embedding_funcs,placeholder_tokens,**kwargs)
  get_embedding_and_mask(data_embedding_func,embedding_items,placeholder_tensor,input_ids,items_size,prefix_length,extend_length,items_offset_list)
  get_embedding_chunk(embedding,extend_prefix_len,extend_seq_len,items_offset)
  get_embedding_hash(embedding_items)
  get_multimodal_data_bounds(input_ids,pad_values,token_pairs)
  hash_feature(f)
  init_embedding_cache(max_size)
  tensor_hash(tensor_list)
managers/multimodal_processor.py:
  get_mm_processor(hf_config,server_args,processor,transport_mode)
  import_processors()
managers/schedule_batch.py:
  BaseFinishReason.__init__(self,is_error)
  BaseFinishReason.to_json(self)
  FINISH_ABORT.__init__(self,message,status_code,err_type)
  FINISH_ABORT.to_json(self)
  FINISH_LENGTH.__init__(self,length)
  FINISH_LENGTH.to_json(self)
  FINISH_MATCHED_STR.__init__(self,matched)
  FINISH_MATCHED_STR.to_json(self)
  FINISH_MATCHED_TOKEN.__init__(self,matched)
  FINISH_MATCHED_TOKEN.to_json(self)
  Modality.all()
  Modality.from_str(modality_str)
  MultimodalDataItem.__getattr__(self,name)
  MultimodalDataItem.__setitem__(self,key,value)
  MultimodalDataItem.from_dict(obj)
  MultimodalDataItem.is_audio(self)
  MultimodalDataItem.is_empty_list(l)
  MultimodalDataItem.is_image(self)
  MultimodalDataItem.is_modality(self,modality)
  MultimodalDataItem.is_valid(self)
  MultimodalDataItem.is_video(self)
  MultimodalDataItem.merge(self,other)
  MultimodalDataItem.set(self,key,value)
  MultimodalDataItem.set_pad_value(self)
  MultimodalDataItem.validate(self)
  MultimodalInputs.contains_audio_inputs(self)
  MultimodalInputs.contains_image_inputs(self)
  MultimodalInputs.contains_mm_input(self)
  MultimodalInputs.contains_video_inputs(self)
  MultimodalInputs.from_dict(obj)
  MultimodalInputs.merge(self,other)
  Req.__init__(self,rid,origin_input_text,origin_input_ids,sampling_params,return_logprob,top_logprobs_num,token_ids_logprob,stream,origin_input_ids_unpadded,lora_id,input_embeds,token_type_ids,session_id,custom_logit_processor,return_hidden_states,eos_token_ids,bootstrap_host,bootstrap_port,bootstrap_room,data_parallel_rank,vocab_size)
  Req.__repr__(self)
  Req.adjust_max_prefix_ids(self)
  Req.check_finished(self)
  Req.extend_image_inputs(self,image_inputs)
  Req.finished(self)
  Req.init_incremental_detokenize(self)
  Req.init_next_round_input(self,tree_cache)
  Req.load_kv_cache(self,req_to_token_pool,token_to_kv_pool_allocator)
  Req.log_time_stats(self)
  Req.offload_kv_cache(self,req_to_token_pool,token_to_kv_pool_allocator)
  Req.reset_for_retract(self)
  Req.seqlen(self)
  Req.set_finish_with_abort(self,error_msg)
  ScheduleBatch.__str__(self)
  ScheduleBatch._available_and_evictable_str(self)
  ScheduleBatch._evict_tree_cache_if_needed(self,num_tokens)
  ScheduleBatch._get_available_size()
  ScheduleBatch._is_available_size_sufficient(self,num_tokens)
  ScheduleBatch.alloc_paged_token_slots_decode(self,seq_lens,last_loc,backup_state)
  ScheduleBatch.alloc_paged_token_slots_extend(self,prefix_lens,seq_lens,last_loc,extend_num_tokens,backup_state)
  ScheduleBatch.alloc_req_slots(self,num_reqs)
  ScheduleBatch.alloc_token_slots(self,num_tokens,backup_state)
  ScheduleBatch.batch_size(self)
  ScheduleBatch.check_decode_mem(self,buf_multiplier)
  ScheduleBatch.copy(self)
  ScheduleBatch.filter_batch(self,chunked_req_to_exclude,keep_indices)
  ScheduleBatch.get_model_worker_batch(self,seq_lens_cpu_cache)
  ScheduleBatch.get_required_tokens(num_reqs)
  ScheduleBatch.init_new(cls,reqs,req_to_token_pool,token_to_kv_pool_allocator,tree_cache,model_config,enable_overlap,spec_algorithm,chunked_req)
  ScheduleBatch.is_empty(self)
  ScheduleBatch.merge_batch(self,other)
  ScheduleBatch.mix_with_running(self,running_batch)
  ScheduleBatch.new_page_count_next_decode(self)
  ScheduleBatch.prepare_encoder_info_decode(self)
  ScheduleBatch.prepare_encoder_info_extend(self,input_ids,seq_lens)
  ScheduleBatch.prepare_for_decode(self)
  ScheduleBatch.prepare_for_extend(self)
  ScheduleBatch.prepare_for_idle(self)
  ScheduleBatch.prepare_for_split_prefill(self)
  ScheduleBatch.retract_decode(self,server_args)
  get_last_loc(req_to_token,req_pool_indices_tensor,prefix_lens_tensor)
  get_last_loc_kernel(req_to_token,req_pool_indices_tensor,prefix_lens_tensor,result,num_tokens,req_to_token_stride,BLOCK_SIZE)
  get_last_loc_torch(req_to_token,req_pool_indices_tensor,prefix_lens_tensor)
  get_last_loc_triton(req_to_token,req_pool_indices_tensor,prefix_lens_tensor)
  write_req_to_token_pool_triton(req_to_token_ptr,req_pool_indices,pre_lens,seq_lens,extend_lens,out_cache_loc,req_to_token_ptr_stride)
managers/schedule_policy.py:
  PrefillAdder.__init__(self,page_size,tree_cache,token_to_kv_pool_allocator,running_batch,new_token_ratio,rem_input_tokens,rem_chunk_tokens,mixed_with_decode_tokens)
  PrefillAdder._lock_node(self,last_node)
  PrefillAdder._update_prefill_budget(self,prefix_len,extend_input_len,max_new_tokens)
  PrefillAdder.add_chunked_req(self,req)
  PrefillAdder.add_one_req(self,req,has_chunked_req)
  PrefillAdder.add_one_req_ignore_eos(self,req,has_chunked_req)
  PrefillAdder.add_req_state(r,insert_sort)
  PrefillAdder.budget_state(self)
  PrefillAdder.ceil_paged_tokens(self,tokens)
  PrefillAdder.cur_rem_tokens(self)
  PrefillAdder.rem_total_tokens(self)
  SchedulePolicy.__init__(self,policy,tree_cache,enable_hierarchical_cache)
  SchedulePolicy._calc_weight(cur_node,node_to_weight)
  SchedulePolicy._compute_prefix_matches(self,waiting_queue,policy)
  SchedulePolicy._determine_active_policy(self,waiting_queue)
  SchedulePolicy._get_dfs_priority(cur_node,node_to_priority,last_node_to_reqs,q)
  SchedulePolicy._sort_by_dfs_weight(waiting_queue,tree_cache)
  SchedulePolicy._sort_by_longest_output(waiting_queue)
  SchedulePolicy._sort_by_longest_prefix(waiting_queue,temporary_deprioritized)
  SchedulePolicy._sort_randomly(waiting_queue)
  SchedulePolicy._validate_and_adjust_policy(self,policy,tree_cache)
  SchedulePolicy.calc_priority(self,waiting_queue)
managers/scheduler.py:
  IdleSleeper.__init__(self,sockets)
  IdleSleeper.maybe_sleep(self)
  Scheduler.__init__(self,server_args,port_args,gpu_id,tp_rank,moe_ep_rank,pp_rank,dp_rank,dp_balance_meta)
  Scheduler._add_request_to_queue(self,req)
  Scheduler._extend_requests_to_queue(self,reqs,is_retracted)
  Scheduler._get_swa_token_info(self)
  Scheduler._get_token_info(self)
  Scheduler._pause_engine(self)
  Scheduler._prefetch_kvcache(self,req)
  Scheduler.abort_request(self,recv_req)
  Scheduler.check_memory(self)
  Scheduler.check_tree_cache(self)
  Scheduler.clear_hicache_storage_wrapped(self,recv_req)
  Scheduler.close_session(self,recv_req)
  Scheduler.current_scheduler_metrics_enabled(self)
  Scheduler.event_loop_normal(self)
  Scheduler.event_loop_overlap(self)
  Scheduler.event_loop_pp(self)
  Scheduler.expert_distribution_handle(self,recv_req)
  Scheduler.flush_cache(self)
  Scheduler.flush_cache_wrapped(self,recv_req)
  Scheduler.gather_dp_balance_info(holding_tokens_list)
  Scheduler.get_idle_batch(self)
  Scheduler.get_internal_state(self,recv_req)
  Scheduler.get_load(self)
  Scheduler.get_new_batch_prefill(self)
  Scheduler.get_next_batch_to_run(self)
  Scheduler.get_num_allocatable_reqs(self,running_bs)
  Scheduler.get_print_prefix(self)
  Scheduler.handle_batch_embedding_request(self,recv_req)
  Scheduler.handle_batch_generate_request(self,recv_req)
  Scheduler.handle_dp_balance_data(self,local_batch)
  Scheduler.handle_embedding_request(self,recv_req)
  Scheduler.handle_freeze_gc(self,recv_req)
  Scheduler.handle_generate_request(self,recv_req)
  Scheduler.handle_rpc_request(self,recv_req)
  Scheduler.init_disaggregation(self)
  Scheduler.init_memory_pool_and_cache(self)
  Scheduler.init_moe_config(self)
  Scheduler.init_tokenizer(self)
  Scheduler.load_lora_adapter(self,recv_req)
  Scheduler.maybe_send_health_check_signal(self)
  Scheduler.maybe_sleep_on_idle(self)
  Scheduler.move_ready_grammar_requests(self)
  Scheduler.open_session(self,recv_req)
  Scheduler.prepare_mlp_sync_batch(self,local_batch)
  Scheduler.prepare_mlp_sync_batch_raw(local_batch,dp_size,attn_tp_size,tp_group,get_idle_batch,disable_cuda_graph,spec_algorithm,speculative_num_draft_tokens,require_mlp_tp_gather,disable_overlap_schedule)
  Scheduler.process_batch_result(self,batch,result,launch_done)
  Scheduler.process_input_requests(self,recv_reqs)
  Scheduler.recv_requests(self)
  Scheduler.run_batch(self,batch)
  Scheduler.self_check_during_idle(self)
  Scheduler.set_internal_state(self,recv_req)
  Scheduler.set_next_batch_sampling_info_done(self,batch)
  Scheduler.slow_down(self,recv_req)
  Scheduler.unload_lora_adapter(self,recv_req)
  Scheduler.update_running_batch(self,batch)
  Scheduler.watchdog_thread(self)
  Scheduler.write_shared_dp_balance_info(new_recv_rid_lists,local_tokens)
  is_health_check_generate_req(recv_req)
  is_work_request(recv_req)
  run_scheduler_process(server_args,port_args,gpu_id,tp_rank,moe_ep_rank,pp_rank,dp_rank,pipe_writer,balance_meta)
managers/scheduler_input_blocker.py:
  SchedulerInputBlocker.__init__(self,noop)
  SchedulerInputBlocker._change_state(self,original,target)
  SchedulerInputBlocker._execute_block_req(self)
  SchedulerInputBlocker._execute_unblock_req(self)
  SchedulerInputBlocker._handle_arrive_unblock_barrier(self)
  SchedulerInputBlocker._handle_recv_req(self,recv_req)
  SchedulerInputBlocker.handle(self,recv_reqs)
  input_blocker_guard_region(send_to_scheduler)
managers/scheduler_metrics_mixin.py:
  KvMetrics.__init__(self)
  SchedulerMetricsMixin._emit_kv_metrics(self)
  SchedulerMetricsMixin._publish_kv_events(self)
  SchedulerMetricsMixin.init_kv_events(self,kv_events_config)
  SchedulerMetricsMixin.init_metrics(self,tp_rank,pp_rank,dp_rank)
  SchedulerMetricsMixin.log_decode_stats(self,can_run_cuda_graph,running_batch)
  SchedulerMetricsMixin.log_prefill_stats(self,adder,can_run_list,running_bs)
managers/scheduler_output_processor_mixin.py:
  SchedulerOutputProcessorMixin.add_input_logprob_return_values(self,i,req,output,logprob_pt,num_input_logprobs,last_prefill_chunk)
  SchedulerOutputProcessorMixin.add_logprob_return_values(self,i,req,pt,next_token_ids,num_input_logprobs,output)
  SchedulerOutputProcessorMixin.process_batch_result_decode(self,batch,result,launch_done)
  SchedulerOutputProcessorMixin.process_batch_result_prefill(self,batch,result,launch_done)
  SchedulerOutputProcessorMixin.stream_output(self,reqs,return_logprob,skip_req)
  SchedulerOutputProcessorMixin.stream_output_embedding(self,reqs)
  SchedulerOutputProcessorMixin.stream_output_generation(self,reqs,return_logprob,skip_req)
managers/scheduler_profiler_mixin.py:
  SchedulerProfilerMixin._profile_batch_predicate(self,batch)
  SchedulerProfilerMixin.init_profier(self)
  SchedulerProfilerMixin.init_profile(self,output_dir,start_step,num_steps,activities,with_stack,record_shapes,profile_by_stage,profile_id)
  SchedulerProfilerMixin.profile(self,recv_req)
  SchedulerProfilerMixin.start_profile(self,stage)
  SchedulerProfilerMixin.stop_profile(self,stage)
managers/scheduler_recv_skipper.py:
  SchedulerRecvSkipper.__init__(self,server_args)
  SchedulerRecvSkipper.handle(self,last_forward_mode)
  SchedulerRecvSkipper.maybe_create(server_args)
managers/scheduler_update_weights_mixin.py:
  SchedulerUpdateWeightsMixin.get_weights_by_name(self,recv_req)
  SchedulerUpdateWeightsMixin.init_weights_update_group(self,recv_req)
  SchedulerUpdateWeightsMixin.release_memory_occupation(self,recv_req)
  SchedulerUpdateWeightsMixin.resume_memory_occupation(self,recv_req)
  SchedulerUpdateWeightsMixin.save_remote_model(self,params)
  SchedulerUpdateWeightsMixin.save_sharded_model(self,params)
  SchedulerUpdateWeightsMixin.update_weights_from_disk(self,recv_req)
  SchedulerUpdateWeightsMixin.update_weights_from_distributed(self,recv_req)
  SchedulerUpdateWeightsMixin.update_weights_from_tensor(self,recv_req)
  _export_static_state(model)
  _import_static_state(model,static_params)
managers/session_controller.py:
  Session.__init__(self,capacity_of_str_len,session_id)
  Session.create_req(self,req,tokenizer)
  SessionReqNode.__init__(self,req,parent,childs)
  SessionReqNode.__str__(self)
  SessionReqNode._str_helper(self,prefix)
  SessionReqNode.abort(self)
  SessionReqNode.clear(self,req_dict)
  SessionReqNode.clear_childs(self,req_dict)
managers/template_manager.py:
  TemplateManager.__init__(self)
  TemplateManager._detect_reasoning_pattern(self,template)
  TemplateManager._load_explicit_chat_template(self,tokenizer_manager,chat_template_arg)
  TemplateManager._load_jinja_template(self,tokenizer_manager,template_path)
  TemplateManager._load_json_chat_template(self,template_path)
  TemplateManager._load_json_completion_template(self,template_path)
  TemplateManager._resolve_hf_chat_template(self,tokenizer_manager)
  TemplateManager.chat_template_name(self)
  TemplateManager.completion_template_name(self)
  TemplateManager.force_reasoning(self)
  TemplateManager.guess_chat_template_from_model_path(self,model_path)
  TemplateManager.initialize_templates(self,tokenizer_manager,model_path,chat_template,completion_template)
  TemplateManager.jinja_template_content_format(self)
  TemplateManager.load_chat_template(self,tokenizer_manager,chat_template_arg,model_path)
  TemplateManager.load_completion_template(self,completion_template_arg)
managers/tokenizer_manager.py:
  SignalHandler.__init__(self,tokenizer_manager)
  SignalHandler.running_phase_sigquit_handler(self,signum,frame)
  SignalHandler.sigterm_handler(self,signum,frame)
  TokenizerManager.__init__(self,server_args,port_args)
  TokenizerManager._create_tokenized_object(self,obj,input_text,input_ids,input_embeds,mm_inputs,token_type_ids)
  TokenizerManager._dump_data_to_file(self,data_list,filename,log_message)
  TokenizerManager._handle_abort_req(self,recv_obj)
  TokenizerManager._handle_batch_output(self,recv_obj)
  TokenizerManager._handle_open_session_req_output(self,recv_obj)
  TokenizerManager._handle_update_weights_from_disk_req_output(self,recv_obj)
  TokenizerManager._send_batch_request(self,obj,tokenized_objs,created_time)
  TokenizerManager._send_one_request(self,obj,tokenized_obj,created_time)
  TokenizerManager._upload_file_to_gcs(bucket_name,source_file_path,object_name)
  TokenizerManager._validate_batch_tokenization_constraints(self,batch_size,obj)
  TokenizerManager._validate_input_ids_in_vocab(self,input_ids,vocab_size)
  TokenizerManager._validate_one_request(self,obj,input_ids)
  TokenizerManager.abort_request(self,rid,abort_all)
  TokenizerManager.auto_create_handle_loop(self)
  TokenizerManager.background_task()
  TokenizerManager.collect_metrics(self,state,recv_obj,i)
  TokenizerManager.configure_logging(self,obj)
  TokenizerManager.convert_logprob_style(self,meta_info,state,top_logprobs_num,token_ids_logprob,return_text_in_logprobs,recv_obj,recv_obj_index)
  TokenizerManager.create_abort_task(self,obj)
  TokenizerManager.detokenize_logprob_tokens(self,token_logprobs_val,token_logprobs_idx,decode_to_text)
  TokenizerManager.detokenize_top_logprobs_tokens(self,token_logprobs_val,token_logprobs_idx,decode_to_text)
  TokenizerManager.dump_requests(self,state,out_dict)
  TokenizerManager.dump_requests_before_crash(self)
  TokenizerManager.get_log_request_metadata(self)
  TokenizerManager.record_request_for_crash_dump(self,state,out_dict)
  _Communicator.__init__(self,sender,fan_out)
  _Communicator.handle_recv(self,recv_obj)
  _determine_tensor_transport_mode(server_args)
  async TokenizerManager._batch_tokenize_and_process(self,batch_size,obj)
  async TokenizerManager._execute_profile(self,req)
  async TokenizerManager._handle_batch_request(self,obj,request,created_time)
  async TokenizerManager._tokenize_one_request(self,obj)
  async TokenizerManager._wait_for_model_update_from_disk(self,obj)
  async TokenizerManager._wait_one_response(self,obj,state,request)
  async TokenizerManager.abort_request()
  async TokenizerManager.clear_hicache_storage(self)
  async TokenizerManager.close_session(self,obj,request)
  async TokenizerManager.continue_generation(self)
  async TokenizerManager.dump_expert_distribution_record(self)
  async TokenizerManager.flush_cache(self)
  async TokenizerManager.freeze_gc(self)
  async TokenizerManager.generate_request(self,obj,request)
  async TokenizerManager.get_internal_state(self)
  async TokenizerManager.get_load(self)
  async TokenizerManager.get_weights_by_name(self,obj,request)
  async TokenizerManager.handle_loop(self)
  async TokenizerManager.init_weights_update_group(self,obj,request)
  async TokenizerManager.load_lora_adapter(self,obj,_)
  async TokenizerManager.open_session(self,obj,request)
  async TokenizerManager.pause_generation(self)
  async TokenizerManager.release_memory_occupation(self,obj,request)
  async TokenizerManager.resume_memory_occupation(self,obj,request)
  async TokenizerManager.score_request(self,query,items,label_token_ids,apply_softmax,item_first,request)
  async TokenizerManager.set_internal_state(self,obj)
  async TokenizerManager.sigterm_watchdog(self)
  async TokenizerManager.slow_down(self,obj,request)
  async TokenizerManager.start_expert_distribution_record(self)
  async TokenizerManager.start_profile(self,output_dir,start_step,num_steps,activities,with_stack,record_shapes,profile_by_stage)
  async TokenizerManager.stop_expert_distribution_record(self)
  async TokenizerManager.stop_profile(self)
  async TokenizerManager.unload_lora_adapter(self,obj,_)
  async TokenizerManager.update_weights_from_disk(self,obj,request)
  async TokenizerManager.update_weights_from_distributed(self,obj,request)
  async TokenizerManager.update_weights_from_tensor(self,obj,request)
  async _Communicator.__call__(self,obj)
  async print_exception_wrapper(func)
managers/tp_worker.py:
  TpModelWorker.__init__(self,server_args,gpu_id,tp_rank,moe_ep_rank,pp_rank,dp_rank,nccl_port,is_draft_worker,req_to_token_pool,token_to_kv_pool_allocator)
  TpModelWorker.can_run_lora_batch(self,lora_ids)
  TpModelWorker.forward_batch_embedding(self,model_worker_batch)
  TpModelWorker.forward_batch_generation(self,model_worker_batch,launch_done,skip_sample)
  TpModelWorker.get_attention_tp_cpu_group(self)
  TpModelWorker.get_attention_tp_group(self)
  TpModelWorker.get_memory_pool(self)
  TpModelWorker.get_pad_input_ids_func(self)
  TpModelWorker.get_tokens_per_layer_info(self)
  TpModelWorker.get_tp_group(self)
  TpModelWorker.get_weights_by_name(self,recv_req)
  TpModelWorker.get_worker_info(self)
  TpModelWorker.init_weights_update_group(self,recv_req)
  TpModelWorker.is_hybrid(self)
  TpModelWorker.load_lora_adapter(self,recv_req)
  TpModelWorker.register_hicache_layer_transfer_counter(self,counter)
  TpModelWorker.set_hicache_consumer(self,consumer_index)
  TpModelWorker.sliding_window_size(self)
  TpModelWorker.unload_lora_adapter(self,recv_req)
  TpModelWorker.update_weights_from_disk(self,recv_req)
  TpModelWorker.update_weights_from_distributed(self,recv_req)
  TpModelWorker.update_weights_from_tensor(self,recv_req)
managers/tp_worker_overlap_thread.py:
  TpModelWorkerClient.__delete__(self)
  TpModelWorkerClient.__init__(self,server_args,gpu_id,tp_rank,moe_ep_rank,pp_rank,dp_rank,nccl_port)
  TpModelWorkerClient.can_run_lora_batch(self,lora_ids)
  TpModelWorkerClient.forward_batch_generation(self,model_worker_batch)
  TpModelWorkerClient.forward_thread_func(self)
  TpModelWorkerClient.forward_thread_func_(self)
  TpModelWorkerClient.get_attention_tp_cpu_group(self)
  TpModelWorkerClient.get_attention_tp_group(self)
  TpModelWorkerClient.get_kv_cache(self)
  TpModelWorkerClient.get_memory_pool(self)
  TpModelWorkerClient.get_pad_input_ids_func(self)
  TpModelWorkerClient.get_tokens_per_layer_info(self)
  TpModelWorkerClient.get_tp_group(self)
  TpModelWorkerClient.get_weights_by_name(self,recv_req)
  TpModelWorkerClient.get_worker_info(self)
  TpModelWorkerClient.init_weights_update_group(self,recv_req)
  TpModelWorkerClient.is_hybrid(self)
  TpModelWorkerClient.load_lora_adapter(self,recv_req)
  TpModelWorkerClient.register_hicache_layer_transfer_counter(self,counter)
  TpModelWorkerClient.resolve_last_batch_result(self,launch_done)
  TpModelWorkerClient.set_hicache_consumer(self,consumer_index)
  TpModelWorkerClient.sliding_window_size(self)
  TpModelWorkerClient.unload_lora_adapter(self,recv_req)
  TpModelWorkerClient.update_weights_from_disk(self,recv_req)
  TpModelWorkerClient.update_weights_from_distributed(self,recv_req)
  TpModelWorkerClient.update_weights_from_tensor(self,recv_req)
  resolve_future_token_ids(input_ids,future_token_ids_map)
managers/utils.py:
  DPBalanceMeta.__getstate__(self)
  DPBalanceMeta.__init__(self,num_workers)
  DPBalanceMeta.__setstate__(self,state)
  DPBalanceMeta.destructor(self)
  DPBalanceMeta.get_shared_local_tokens(self)
  DPBalanceMeta.get_shared_onfly(self)
  DPBalanceMeta.set_shared_local_tokens(self,data)
  DPBalanceMeta.set_shared_onfly_info(self,data)
  get_logprob_dict_from_result(result)
  get_logprob_from_pp_outputs(next_pp_outputs)
  validate_input_length(req,max_req_input_len,allow_auto_truncate)
