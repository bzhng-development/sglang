models/arcee.py:
  ArceeAttention.__init__(self,config,hidden_size,num_heads,num_kv_heads,layer_id,rope_theta,rope_scaling,rope_is_neox_style,max_position_embeddings,quant_config,prefix,bias)
  ArceeAttention.forward(self,positions,hidden_states,forward_batch)
  ArceeDecoderLayer.__init__(self,config,layer_id,quant_config,prefix)
  ArceeDecoderLayer.forward(self,positions,hidden_states,forward_batch,residual)
  ArceeForCausalLM.__init__(self,config,quant_config,prefix)
  ArceeForCausalLM._init_model(self,config,quant_config,prefix)
  ArceeForCausalLM.end_layer(self)
  ArceeForCausalLM.forward(self,input_ids,positions,forward_batch,input_embeds,get_embedding,pp_proxy_tensors)
  ArceeForCausalLM.get_input_embeddings(self)
  ArceeForCausalLM.load_kv_cache_scales(self,quantization_param_path)
  ArceeForCausalLM.load_weights(self,weights)
  ArceeForCausalLM.start_layer(self)
  ArceeMLP.__init__(self,hidden_size,intermediate_size,hidden_act,quant_config,prefix,reduce_results)
  ArceeMLP.forward(self,x,forward_batch)
  ArceeModel.__init__(self,config,quant_config,prefix)
  ArceeModel.forward(self,input_ids,positions,forward_batch,input_embeds,pp_proxy_tensors)
  ArceeModel.load_kv_cache_scales(self,quantization_param_path)
models/baichuan.py:
  BaiChuanAttention.__init__(self,hidden_size,num_heads,position_embedding,rope_theta,max_position_embeddings,quant_config,layer_id,prefix)
  BaiChuanAttention.forward(self,positions,hidden_states,forward_batch)
  BaiChuanBaseForCausalLM.__init__(self,config,position_embedding,quant_config,prefix)
  BaiChuanBaseForCausalLM.forward(self,input_ids,positions,forward_batch)
  BaiChuanBaseForCausalLM.load_weights(self,weights)
  BaiChuanDecoderLayer.__init__(self,config,position_embedding,layer_id,quant_config,prefix)
  BaiChuanDecoderLayer.forward(self,positions,hidden_states,forward_batch,residual)
  BaiChuanMLP.__init__(self,hidden_size,intermediate_size,hidden_act,quant_config,prefix)
  BaiChuanMLP.forward(self,x)
  BaiChuanModel.__init__(self,config,position_embedding,quant_config,prefix)
  BaiChuanModel.forward(self,input_ids,positions,forward_batch)
  BaichuanForCausalLM.__init__(self,config,quant_config,prefix)
  _get_alibi_slopes(total_num_heads)
models/bailing_moe.py:
  BailingAttention.__init__(self,config,layer_id,quant_config,prefix)
  BailingAttention.forward(self,hidden_states,position_ids,forward_batch)
  BailingMLP.__init__(self,intermediate_size,config,quant_config,reduce_results,prefix)
  BailingMLP.forward(self,x)
  BailingMoE.__init__(self,config,layer_id,quant_config,prefix)
  BailingMoE.forward(self,hidden_states)
  BailingMoeBlock.__init__(self,config,layer_id,quant_config,prefix)
  BailingMoeBlock.forward(self,hidden_states,position_ids,residual,forward_batch)
  BailingMoeForCausalLM.__init__(self,config,quant_config)
  BailingMoeForCausalLM.forward(self,input_ids,positions,forward_batch,inputs_embeds)
  BailingMoeForCausalLM.load_weights(self,weights)
  BailingMoeModel.__init__(self,config,quant_config,prefix)
  BailingMoeModel.forward(self,input_ids,position_ids,forward_batch,input_embeds)
models/bert.py:
  BertAttention.__init__(self,hidden_size,num_attention_heads,layer_norm_eps,layer_id,quant_config,prefix)
  BertAttention.forward(self,hidden_states,forward_batch)
  BertEmbedding.__init__(self,config)
  BertEmbedding.forward(self,input_ids,positions,forward_batch)
  BertEncoder.__init__(self,config,quant_config,prefix)
  BertEncoder.forward(self,hidden_states,forward_batch)
  BertForSequenceClassification.__init__(self,config,quant_config,prefix)
  BertForSequenceClassification.forward(self,input_ids,positions,forward_batch,input_embeds,get_embedding)
  BertForSequenceClassification.load_weights(self,weights)
  BertForSequenceClassification.weight_filter()
  BertIntermediate.__init__(self,hidden_size,intermediate_size,hidden_act,quant_config,prefix)
  BertIntermediate.forward(self,hidden_states)
  BertLayer.__init__(self,config,layer_id,quant_config,prefix)
  BertLayer.forward(self,hidden_states,forward_batch)
  BertModel.__init__(self,config,quant_config,use_bert_pooler,prefix)
  BertModel.forward(self,input_ids,positions,forward_batch,input_embeds,get_embedding)
  BertModel.load_weights(self,weights)
  BertOutput.__init__(self,hidden_size,intermediate_size,layer_norm_eps,quant_config,prefix)
  BertOutput.forward(self,hidden_states,input_tensor)
  BertPooler.__init__(self,config)
  BertPooler.forward(self,hidden_states,forward_batch)
  BertSelfAttention.__init__(self,hidden_size,num_attention_heads,layer_id,quant_config,prefix)
  BertSelfAttention.forward(self,hidden_states,forward_batch)
  BertSelfOutput.__init__(self,hidden_size,layer_norm_eps,quant_config,prefix)
  BertSelfOutput.forward(self,hidden_states,input_tensor)
models/chatglm.py:
  ChatGLMForCausalLM.__init__(self,config,quant_config,prefix)
  ChatGLMForCausalLM.forward(self,input_ids,positions,forward_batch)
  ChatGLMForCausalLM.load_weights(self,weights)
  ChatGLMM.__init__(self,config,quant_config,prefix)
  ChatGLMM.forward(self,input_ids,position_ids,forward_batch)
  GLMAttention.__init__(self,config,layer_id,quant_config,prefix)
  GLMAttention.forward(self,hidden_states,position_ids,forward_batch)
  GLMBlock.__init__(self,config,layer_id,quant_config,prefix)
  GLMBlock.forward(self,hidden_states,position_ids,forward_batch)
  GLMMLP.__init__(self,config,quant_config,prefix)
  GLMMLP.forward(self,hidden_states)
  GLMTransformer.__init__(self,config,quant_config,prefix)
  GLMTransformer.forward(self,hidden_states,position_ids,forward_batch)
models/clip.py:
  CLIPEncoder.__init__(self,config,quant_config,prefix)
  CLIPEncoder.forward(self,inputs_embeds,attention_mask,causal_attention_mask,return_all_hidden_states)
  CLIPEncoderLayer.__init__(self,config,act_layer,norm_layer,attn_implementation,quant_config,prefix)
  CLIPEncoderLayer.forward(self,hidden_states,attention_mask,causal_attention_mask)
  CLIPMLP.__init__(self,config,act_layer,quant_config,prefix)
  CLIPMLP.forward(self,x)
  CLIPModel.__init__(self,config,quant_config,prefix)
  CLIPModel.forward(self,input_ids,positions,forward_batch,get_embedding)
  CLIPModel.load_weights(self,weights)
  CLIPModel.pad_input_ids(self,input_ids,image_inputs)
  CLIPTextEmbeddings.__init__(self,config)
  CLIPTextEmbeddings.forward(self,input_ids,position_ids,inputs_embeds)
  CLIPTextModel.__init__(self,config,quant_config,prefix)
  CLIPTextModel.forward(self,input_ids,position_ids)
  CLIPTextTransformer.__init__(self,config,quant_config,prefix)
  CLIPTextTransformer.device(self)
  CLIPTextTransformer.forward(self,input_ids,attention_mask,position_ids)
  CLIPVisionEmbeddings.__init__(self,config)
  CLIPVisionEmbeddings.forward(self,pixel_values)
  CLIPVisionModel.__init__(self,config,quant_config,prefix)
  CLIPVisionModel.device(self)
  CLIPVisionModel.forward(self,pixel_values)
  CLIPVisionTransformer.__init__(self,config,quant_config,prefix)
  CLIPVisionTransformer.device(self)
  CLIPVisionTransformer.forward(self,pixel_values)
  monkey_patch_weight_loader()
  prepare_weights(self,model_name_or_path,revision,fall_back_to_pt)
models/commandr.py:
  CohereAttention.__init__(self,config,layer_id,quant_config,prefix)
  CohereAttention._apply_qk_norm(self,q,k)
  CohereAttention.forward(self,positions,hidden_states,forward_batch)
  CohereDecoderLayer.__init__(self,config,layer_id,quant_config,prefix)
  CohereDecoderLayer.forward(self,positions,hidden_states,forward_batch,residual)
  CohereForCausalLM.__init__(self,config,quant_config,prefix)
  CohereForCausalLM.forward(self,input_ids,positions,forward_batch)
  CohereForCausalLM.load_weights(self,weights)
  CohereMLP.__init__(self,config,quant_config,prefix)
  CohereMLP.forward(self,x)
  CohereModel.__init__(self,config,quant_config,prefix)
  CohereModel.forward(self,input_ids,positions,forward_batch)
  LayerNorm.__init__(self,param_shape,eps)
  LayerNorm.forward(self,hidden_states,residuals)
  LayerNorm.weight_loader(self,param,loaded_weight)
  layer_norm_func(hidden_states,weight,variance_epsilon)
models/dbrx.py:
  DbrxAttention.__init__(self,config,layer_id,quant_config,prefix)
  DbrxAttention.forward(self,position_ids,hidden_states,forward_batch)
  DbrxBlock.__init__(self,config,layer_id,quant_config,prefix)
  DbrxBlock.forward(self,position_ids,hidden_states,forward_batch)
  DbrxExperts.__init__(self,config,quant_config,params_dtype,prefix)
  DbrxExperts.forward(self,hidden_states)
  DbrxExperts.weight_loader(self,param,loaded_weight,weight_name)
  DbrxForCausalLM.__init__(self,config,quant_config,prefix)
  DbrxForCausalLM.forward(self,input_ids,positions,forward_batch)
  DbrxForCausalLM.load_weights(self,weights)
  DbrxFusedNormAttention.__init__(self,config,layer_id,quant_config,prefix)
  DbrxFusedNormAttention.forward(self,position_ids,hidden_states,forward_batch)
  DbrxModel.__init__(self,config,quant_config,prefix)
  DbrxModel.forward(self,input_ids,position_ids,forward_batch,input_embeds)
  DbrxRouter.__init__(self,config,params_dtype,prefix)
  DbrxRouter.forward(self,hidden_states)
models/deepseek.py:
  DeepseekAttention.__init__(self,hidden_size,num_heads,num_kv_heads,layer_id,rope_theta,rope_scaling,max_position_embeddings,quant_config,prefix)
  DeepseekAttention.forward(self,positions,hidden_states,forward_batch)
  DeepseekDecoderLayer.__init__(self,config,layer_id,quant_config,prefix)
  DeepseekDecoderLayer.forward(self,positions,hidden_states,forward_batch,residual)
  DeepseekForCausalLM.__init__(self,config,quant_config,prefix)
  DeepseekForCausalLM.forward(self,input_ids,positions,forward_batch,input_embeds)
  DeepseekForCausalLM.get_input_embeddings(self)
  DeepseekForCausalLM.load_weights(self,weights)
  DeepseekMLP.__init__(self,hidden_size,intermediate_size,hidden_act,quant_config,reduce_results,prefix)
  DeepseekMLP.forward(self,x)
  DeepseekMoE.__init__(self,config,quant_config,prefix)
  DeepseekMoE.forward(self,hidden_states)
  DeepseekMoE.pack_params(self)
  DeepseekModel.__init__(self,config,quant_config,prefix)
  DeepseekModel.forward(self,input_ids,positions,forward_batch,input_embeds)
models/deepseek_janus_pro.py:
  AttentionPoolLatent.__init__(self,in_features,out_features,embed_dim,num_heads,feat_size,mlp_ratio,qkv_bias,qk_norm,latent_len,latent_dim,pos_embed,pool_type,norm_layer,drop)
  AttentionPoolLatent.forward(self,x)
  AttentionPoolLatent.init_weights(self)
  AttnBlock.__init__(self,in_channels,norm_type)
  AttnBlock.forward(self,x)
  CLIPVisionTower.__init__(self,model_name,image_size,select_feature,select_layer,select_layers,ckpt_path,pixel_mean,pixel_std,**kwargs)
  CLIPVisionTower.build_vision_tower(self,vision_tower_params)
  CLIPVisionTower.device(self)
  CLIPVisionTower.dtype(self)
  CLIPVisionTower.feature_select(self,image_forward_outs)
  CLIPVisionTower.forward(self,images)
  Decoder.__init__(self,z_channels,ch,ch_mult,num_res_blocks,norm_type,dropout,resamp_with_conv,out_channels)
  Decoder.forward(self,z)
  Decoder.last_layer(self)
  Downsample.__init__(self,in_channels,with_conv)
  Downsample.forward(self,x)
  DropPath.__init__(self,drop_prob,scale_by_keep)
  DropPath.extra_repr(self)
  DropPath.forward(self,x)
  Encoder.__init__(self,in_channels,ch,ch_mult,num_res_blocks,norm_type,dropout,resamp_with_conv,z_channels)
  Encoder.forward(self,x)
  LayerScale.__init__(self,dim,init_values,inplace)
  LayerScale.forward(self,x)
  Mlp.__init__(self,in_features,hidden_features,out_features,act_layer,norm_layer,bias,drop,use_conv)
  Mlp.forward(self,x)
  MlpProjector.__init__(self,cfg)
  MlpProjector.forward(self,x_or_tuple)
  MultiModalityCausalLM.__init__(self,config,quant_config)
  MultiModalityCausalLM.forward(self,input_ids,positions,forward_batch,get_embedding)
  MultiModalityCausalLM.get_image_feature(self,items)
  MultiModalityCausalLM.get_input_embeddings(self)
  MultiModalityCausalLM.load_weights(self,weights)
  MultiModalityCausalLM.pad_input_ids(self,input_ids,image_inputs)
  MultiModalityCausalLM.prepare_gen_img_embeds(self,image_ids)
  Normalize(in_channels,norm_type)
  Normalize.__init__(self,mean,std,inplace)
  Normalize.__repr__(self)
  Normalize.forward(self,tensor)
  PatchDropout.__init__(self,prob,num_prefix_tokens,ordered,return_indices)
  PatchDropout.forward(self,x)
  PatchEmbed.__init__(self,img_size,patch_size,in_chans,embed_dim,norm_layer,flatten,output_fmt,bias,strict_img_size,dynamic_img_pad)
  PatchEmbed._init_img_size(self,img_size)
  PatchEmbed.dynamic_feat_size(self,img_size)
  PatchEmbed.feat_ratio(self,as_scalar)
  PatchEmbed.forward(self,x)
  PatchEmbed.set_input_size(self,img_size,patch_size)
  ResnetBlock.__init__(self,in_channels,out_channels,conv_shortcut,dropout,norm_type)
  ResnetBlock.forward(self,x)
  Upsample.__init__(self,in_channels,with_conv)
  Upsample.forward(self,x)
  VQModel.__init__(self,config)
  VQModel.decode(self,quant)
  VQModel.decode_code(self,code_b,shape,channel_first)
  VQModel.encode(self,x)
  VQModel.forward(self,input)
  VQ_16(**kwargs)
  VectorQuantizer.__init__(self,n_e,e_dim,beta,entropy_loss_ratio,l2_norm,show_usage)
  VectorQuantizer.forward(self,z)
  VectorQuantizer.get_codebook_entry(self,indices,shape,channel_first)
  VisionTransformer.__init__(self,img_size,patch_size,in_chans,num_classes,global_pool,embed_dim,depth,num_heads,mlp_ratio,qkv_bias,qk_norm,init_values,class_token,no_embed_class,reg_tokens,pre_norm,fc_norm,dynamic_img_size,dynamic_img_pad,drop_rate,pos_drop_rate,patch_drop_rate,proj_drop_rate,attn_drop_rate,drop_path_rate,weight_init,embed_layer,_norm_layer,_act_layer,block_fn,mlp_layer,ignore_head)
  VisionTransformer._intermediate_layers(self,x,n)
  VisionTransformer._pos_embed(self,x)
  VisionTransformer.forward(self,x)
  VisionTransformer.forward_features(self,x)
  VisionTransformer.forward_head(self,x,pre_logits)
  VisionTransformer.get_classifier(self)
  VisionTransformer.group_matcher(self,coarse)
  VisionTransformer.init_weights(self,mode)
  VisionTransformer.no_weight_decay(self)
  VisionTransformer.reset_classifier(self,num_classes,global_pool)
  VisionTransformerBlock.__init__(self,dim,num_heads,mlp_ratio,qkv_bias,qk_norm,proj_drop,attn_drop,init_values,drop_path,act_layer,norm_layer,mlp_layer)
  VisionTransformerBlock.forward(self,x)
  _ntuple(n)
  _trunc_normal_(tensor,mean,std,a,b)
  compute_entropy_loss(affinity,loss_type,temperature)
  create_siglip_vit(model_name,image_size,select_layer,ckpt_path,**kwargs)
  drop_path(x,drop_prob,training,scale_by_keep)
  get_resize_mat(_old_size,_new_size)
  init_weights(self)
  init_weights_vit_timm(module,name)
  model_name_to_cls(cls_name)
  named_apply(fn,module,name,depth_first,include_root)
  nchw_to(x,fmt)
  nonlinearity(x)
  norm_cdf(x)
  parse(x)
  resample_abs_pos_embed(posemb,new_size,old_size,num_prefix_tokens,interpolation,antialias,verbose)
  resample_kernel(kernel)
  resample_patch_embed(patch_embed,new_size,interpolation,antialias,verbose)
  resize(x_np,_new_size)
  trunc_normal_tf_(tensor,mean,std,a,b)
  use_fused_attn(experimental)
  vision_head.__init__(self,params)
  vision_head.forward(self,x)
models/deepseek_nextn.py:
  DeepseekModelNextN.__init__(self,config,quant_config,prefix)
  DeepseekModelNextN.forward(self,input_ids,positions,forward_batch,input_embeds)
  DeepseekV3ForCausalLMNextN.__init__(self,config,quant_config,prefix)
  DeepseekV3ForCausalLMNextN.forward(self,input_ids,positions,forward_batch)
  DeepseekV3ForCausalLMNextN.load_weights(self,weights)
models/deepseek_v2.py:
  DeepseekV2AttentionMLA.__init__(self,config,hidden_size,num_heads,qk_nope_head_dim,qk_rope_head_dim,v_head_dim,q_lora_rank,kv_lora_rank,rope_theta,rope_scaling,max_position_embeddings,quant_config,reduce_results,layer_id,prefix,alt_stream)
  DeepseekV2AttentionMLA._chunked_prefix_attn_mha(self,q,accum_output,accum_lse,forward_batch)
  DeepseekV2AttentionMLA._dispatch_mla_subtype()
  DeepseekV2AttentionMLA._fuse_rope_for_trtllm_mla(self,forward_batch)
  DeepseekV2AttentionMLA.dispatch_attn_forward_method(self,forward_batch)
  DeepseekV2AttentionMLA.forward(self,positions,hidden_states,forward_batch,zero_allocator)
  DeepseekV2AttentionMLA.forward_absorb_core(self,q_pe,k_pe,q_nope_out,k_nope,forward_batch,zero_allocator)
  DeepseekV2AttentionMLA.forward_absorb_fused_mla_rope_core(self,q_input,key_cache_buf,val_cache_buf,attn_output,kv_indptr,kv_indices,k_pe_output,cos_sin_cache,positions,attn_logits,num_kv_split,sm_scale,enable_rope_fusion,k_input,forward_batch,zero_allocator)
  DeepseekV2AttentionMLA.forward_absorb_fused_mla_rope_cpu_core(self,q_input,k_input,v_input,forward_batch,zero_allocator)
  DeepseekV2AttentionMLA.forward_absorb_fused_mla_rope_cpu_prepare(self,positions,hidden_states,forward_batch,zero_allocator)
  DeepseekV2AttentionMLA.forward_absorb_fused_mla_rope_prepare(self,positions,hidden_states,forward_batch,zero_allocator)
  DeepseekV2AttentionMLA.forward_absorb_prepare(self,positions,hidden_states,forward_batch,zero_allocator)
  DeepseekV2AttentionMLA.forward_core(self,intermediate_state)
  DeepseekV2AttentionMLA.forward_normal_chunked_kv_core(self,q,k,v,forward_batch)
  DeepseekV2AttentionMLA.forward_normal_chunked_kv_prepare(self,positions,hidden_states,forward_batch,zero_allocator)
  DeepseekV2AttentionMLA.forward_normal_core(self,q,k,v,forward_batch)
  DeepseekV2AttentionMLA.forward_normal_prepare(self,positions,hidden_states,forward_batch,zero_allocator)
  DeepseekV2AttentionMLA.forward_prepare(self,positions,hidden_states,forward_batch,zero_allocator)
  DeepseekV2AttentionMLA.op_core(self,state)
  DeepseekV2AttentionMLA.op_prepare(self,state)
  DeepseekV2DecoderLayer.__init__(self,config,layer_id,quant_config,is_nextn,prefix,alt_stream)
  DeepseekV2DecoderLayer._is_layer_sparse(self,layer_id,is_nextn)
  DeepseekV2DecoderLayer.forward(self,positions,hidden_states,forward_batch,residual,zero_allocator)
  DeepseekV2DecoderLayer.op_comm_postprocess_layer(self,state)
  DeepseekV2DecoderLayer.op_comm_prepare_attn(self,state,positions,hidden_states,forward_batch,residual,zero_allocator,tbo_subbatch_index)
  DeepseekV2DecoderLayer.op_comm_prepare_mlp(self,state)
  DeepseekV2DecoderLayer.op_mlp(self,state)
  DeepseekV2ForCausalLM.__init__(self,config,quant_config,prefix)
  DeepseekV2ForCausalLM._weight_requant_ue8m0(self,is_nextn)
  DeepseekV2ForCausalLM.determine_num_fused_shared_experts(self,architecture)
  DeepseekV2ForCausalLM.end_layer(self)
  DeepseekV2ForCausalLM.forward(self,input_ids,positions,forward_batch,input_embeds,pp_proxy_tensors)
  DeepseekV2ForCausalLM.get_embed_and_head(self)
  DeepseekV2ForCausalLM.get_input_embeddings(self)
  DeepseekV2ForCausalLM.get_model_config_for_expert_location(cls,config)
  DeepseekV2ForCausalLM.load_weights(self,weights,is_nextn)
  DeepseekV2ForCausalLM.post_load_weights(self,is_nextn,weight_names)
  DeepseekV2ForCausalLM.routed_experts_weights_of_layer(self)
  DeepseekV2ForCausalLM.set_embed_and_head(self,embed,head)
  DeepseekV2ForCausalLM.start_layer(self)
  DeepseekV2MLP.__init__(self,hidden_size,intermediate_size,hidden_act,quant_config,reduce_results,prefix,tp_rank,tp_size)
  DeepseekV2MLP.forward(self,x,forward_batch,should_allreduce_fusion,use_reduce_scatter)
  DeepseekV2MoE.__init__(self,config,layer_id,quant_config,prefix,alt_stream,is_nextn)
  DeepseekV2MoE._forward_shared_experts(self,hidden_states)
  DeepseekV2MoE.forward(self,hidden_states,forward_batch,should_allreduce_fusion,use_reduce_scatter)
  DeepseekV2MoE.forward_cpu(self,hidden_states,should_allreduce_fusion)
  DeepseekV2MoE.forward_deepep(self,hidden_states,forward_batch)
  DeepseekV2MoE.forward_normal(self,hidden_states,should_allreduce_fusion,use_reduce_scatter)
  DeepseekV2MoE.forward_normal_dual_stream(self,hidden_states,should_allreduce_fusion,use_reduce_scatter)
  DeepseekV2MoE.get_moe_weights(self)
  DeepseekV2MoE.op_combine_a(self,state)
  DeepseekV2MoE.op_combine_b(self,state)
  DeepseekV2MoE.op_dispatch_a(self,state)
  DeepseekV2MoE.op_dispatch_b(self,state)
  DeepseekV2MoE.op_experts(self,state)
  DeepseekV2MoE.op_gate(self,state)
  DeepseekV2MoE.op_output(self,state)
  DeepseekV2MoE.op_select_experts(self,state)
  DeepseekV2MoE.op_shared_experts(self,state)
  DeepseekV2Model.__init__(self,config,quant_config,prefix)
  DeepseekV2Model.forward(self,input_ids,positions,forward_batch,input_embeds,pp_proxy_tensors)
  DeepseekV2Model.get_input_embeddings(self)
  MoEGate.__init__(self,config,prefix,is_nextn)
  MoEGate.forward(self,hidden_states)
  yarn_get_mscale(scale,mscale)
models/deepseek_vl2.py:
  DeepseekVL2ForCausalLM.__init__(self,config,quant_config)
  DeepseekVL2ForCausalLM._init_vision_module(self,vision_config,quant_config)
  DeepseekVL2ForCausalLM.forward(self,input_ids,positions,forward_batch,**kwargs)
  DeepseekVL2ForCausalLM.get_image_feature(self,items)
  DeepseekVL2ForCausalLM.load_weights(self,weights)
  DeepseekVL2ForCausalLM.pad_input_ids(self,input_ids,mm_inputs)
  DeepseekVL2MlpProjector.__init__(self,config,quant_config)
  DeepseekVL2MlpProjector.forward(self,x)
models/ernie4.py:
  Ernie4DecoderLayer.__init__(self,config,layer_id,quant_config,prefix,is_mtp)
  Ernie4DecoderLayer.forward(self,positions,hidden_states,forward_batch,residual)
  Ernie4Model.__init__(self,config,quant_config,prefix)
  Ernie4Model.forward(self,input_ids,positions,forward_batch,input_embeds)
  Ernie4Moe.__init__(self,config,layer_id,quant_config,prefix)
  Ernie4Moe.forward(self,hidden_states)
  Ernie4Moe.forward_normal(self,hidden_states)
  Ernie4_5_ForCausalLM.__init__(self,config,quant_config,prefix)
  Ernie4_5_ForCausalLM.forward(self,input_ids,positions,forward_batch)
  Ernie4_5_ForCausalLM.get_embed_and_head(self)
  Ernie4_5_ForCausalLM.load_weights(self,weights)
  Ernie4_5_MoeForCausalLM.load_weights(self,weights)
  MoEGate.__init__(self,config,prefix)
  MoEGate.forward(self,hidden_states)
models/ernie4_eagle.py:
  Ernie4ModelMTP.__init__(self,config,layer_id,prefix,quant_config)
  Ernie4ModelMTP.forward(self,input_ids,positions,forward_batch,input_embeds)
  Ernie4_5_MoeForCausalLMMTP.__init__(self,config,quant_config,prefix,mtp_layer_id)
  Ernie4_5_MoeForCausalLMMTP.forward(self,input_ids,positions,forward_batch)
  Ernie4_5_MoeForCausalLMMTP.get_embed_and_head(self)
  Ernie4_5_MoeForCausalLMMTP.load_weights(self,weights)
  Ernie4_5_MoeForCausalLMMTP.set_embed_and_head(self,embed,head)
models/exaone.py:
  ExaoneAttention.__init__(self,config,hidden_size,num_heads,num_kv_heads,layer_id,rope_theta,rope_scaling,rope_is_neox_style,max_position_embeddings,quant_config,prefix)
  ExaoneAttention.forward(self,positions,hidden_states,forward_batch)
  ExaoneDecoderLayer.__init__(self,config,layer_id,quant_config,prefix)
  ExaoneDecoderLayer.forward(self,positions,hidden_states,forward_batch,residual)
  ExaoneForCausalLM.__init__(self,config,quant_config,prefix)
  ExaoneForCausalLM.forward(self,input_ids,positions,forward_batch,input_embeds)
  ExaoneForCausalLM.load_weights(self,weights)
  ExaoneGatedMLP.__init__(self,hidden_size,intermediate_size,hidden_act,quant_config,prefix)
  ExaoneGatedMLP.forward(self,x)
  ExaoneModel.__init__(self,config,quant_config,prefix)
  ExaoneModel.forward(self,input_ids,positions,forward_batch,input_embeds)
models/gemma.py:
  GemmaAttention.__init__(self,hidden_size,num_heads,num_kv_heads,head_dim,layer_id,max_position_embeddings,rope_theta,quant_config,prefix)
  GemmaAttention.forward(self,positions,hidden_states,forward_batch)
  GemmaDecoderLayer.__init__(self,config,layer_id,quant_config,prefix)
  GemmaDecoderLayer.forward(self,positions,hidden_states,forward_batch,residual)
  GemmaForCausalLM.__init__(self,config,quant_config,prefix)
  GemmaForCausalLM.forward(self,input_ids,positions,forward_batch,input_embeds)
  GemmaForCausalLM.forward_split_prefill(self,input_ids,positions,forward_batch,split_interval,input_embeds)
  GemmaForCausalLM.load_weights(self,weights)
  GemmaMLP.__init__(self,hidden_size,intermediate_size,quant_config,prefix)
  GemmaMLP.forward(self,x)
  GemmaModel.__init__(self,config,quant_config,prefix)
  GemmaModel.forward(self,input_ids,positions,forward_batch,input_embeds)
models/gemma2.py:
  Gemma2Attention.__init__(self,layer_id,config,hidden_size,num_heads,num_kv_heads,head_dim,max_position_embeddings,rope_theta,quant_config,prefix)
  Gemma2Attention.forward(self,positions,hidden_states,forward_batch)
  Gemma2DecoderLayer.__init__(self,layer_id,config,quant_config,prefix)
  Gemma2DecoderLayer.forward(self,positions,hidden_states,forward_batch,residual)
  Gemma2ForCausalLM.__init__(self,config,quant_config,prefix)
  Gemma2ForCausalLM.forward(self,input_ids,positions,forward_batch,input_embeds)
  Gemma2ForCausalLM.forward_split_prefill(self,input_ids,positions,forward_batch,split_interval,input_embeds)
  Gemma2ForCausalLM.get_attention_sliding_window_size(self)
  Gemma2ForCausalLM.load_weights(self,weights)
  Gemma2MLP.__init__(self,hidden_size,intermediate_size,hidden_act,hidden_activation,quant_config,prefix)
  Gemma2MLP.forward(self,x)
  Gemma2Model.__init__(self,config,quant_config,prefix)
  Gemma2Model.forward(self,input_ids,positions,forward_batch,input_embeds)
  get_attention_sliding_window_size(config)
models/gemma2_reward.py:
  Gemma2ForSequenceClassification.__init__(self,config,quant_config,prefix)
  Gemma2ForSequenceClassification.forward(self,input_ids,positions,forward_batch,input_embeds,get_embedding)
  Gemma2ForSequenceClassification.load_weights(self,weights)
models/gemma3_causal.py:
  Gemma3Attention.__init__(self,layer_id,config,max_position_embeddings,quant_config,prefix)
  Gemma3Attention.forward(self,hidden_states,position_embeddings,forward_batch,**kwargs)
  Gemma3Attention.naive_attn_with_masks(self,q,k,v,out,**kwargs)
  Gemma3DecoderLayer.__init__(self,layer_id,config,quant_config,prefix)
  Gemma3DecoderLayer.forward(self,positions,hidden_states,position_embeddings_global,position_embeddings_local,forward_batch,**kwargs)
  Gemma3ForCausalLM.__init__(self,config,quant_config,prefix)
  Gemma3ForCausalLM.dtype(self)
  Gemma3ForCausalLM.forward(self,input_ids,positions,forward_batch,input_embeds,**kwargs)
  Gemma3ForCausalLM.forward_split_prefill(self,input_ids,positions,forward_batch,split_interval,input_embeds)
  Gemma3ForCausalLM.get_attention_sliding_window_size(self)
  Gemma3ForCausalLM.get_input_embeddings(self)
  Gemma3ForCausalLM.load_weights(self,weights)
  Gemma3MLP.__init__(self,hidden_size,intermediate_size,hidden_activation,quant_config,prefix)
  Gemma3MLP.forward(self,x)
  Gemma3RotaryEmbedding.__init__(self,config,device)
  Gemma3RotaryEmbedding._dynamic_frequency_update(self,position_ids,device)
  Gemma3RotaryEmbedding.forward(self,x,position_ids)
  Gemma3TextModel.__init__(self,config,quant_config,prefix)
  Gemma3TextModel.forward(self,input_ids,positions,forward_batch,input_embeds,**kwargs)
  Gemma3TextScaledWordEmbedding.__init__(self,num_embeddings,embedding_dim,padding_idx,embed_scale)
  Gemma3TextScaledWordEmbedding.forward(self,input_ids)
  extract_layer_index(prefix)
  get_attention_sliding_window_size(config)
models/gemma3_mm.py:
  Gemma3ForConditionalGeneration.__init__(self,config,quant_config,prefix)
  Gemma3ForConditionalGeneration.forward(self,input_ids,positions,forward_batch,input_embeds,**kwargs)
  Gemma3ForConditionalGeneration.get_attention_sliding_window_size(self)
  Gemma3ForConditionalGeneration.get_image_feature(self,items)
  Gemma3ForConditionalGeneration.get_input_embeddings(self)
  Gemma3ForConditionalGeneration.load_weights(self,weights)
  Gemma3ForConditionalGeneration.pad_input_ids(self,input_ids,image_inputs)
  Gemma3ForConditionalGeneration.prepare_attn_masks(self,input_ids,positions,mask_dtype,**kwargs)
  Gemma3ForConditionalGeneration.tie_weights(self)
  Gemma3MultiModalProjector.__init__(self,config)
  Gemma3MultiModalProjector.forward(self,vision_outputs)
models/gemma3n_audio.py:
  Gemma3nAudioAttention.__init__(self,config,quant_config,prefix)
  Gemma3nAudioAttention._convert_to_block(self,x)
  Gemma3nAudioAttention._extract_block_context(self,x)
  Gemma3nAudioAttention._pad_dim1(self,x,dim10_val,dim11_val)
  Gemma3nAudioAttention.forward(self,x,mask)
  Gemma3nAudioConformerAttention.__init__(self,config,quant_config,prefix)
  Gemma3nAudioConformerAttention.forward(self,audio_encodings,audio_mel_mask)
  Gemma3nAudioConformerBlock.__init__(self,config,quant_config,prefix)
  Gemma3nAudioConformerBlock.forward(self,audio_encodings,audio_mel_mask)
  Gemma3nAudioConformerFeedForward.__init__(self,config,quant_config,prefix)
  Gemma3nAudioConformerFeedForward.forward(self,audio_encodings)
  Gemma3nAudioConformerLightConv1d.__init__(self,config,quant_config,prefix)
  Gemma3nAudioConformerLightConv1d.forward(self,audio_encodings)
  Gemma3nAudioEncoder.__init__(self,config,quant_config,prefix)
  Gemma3nAudioEncoder.forward(self,audio_mel,audio_mel_mask)
  Gemma3nAudioRelativePositionEmbedding.__init__(self,config,quant_config,prefix)
  Gemma3nAudioRelativePositionEmbedding._get_timing_signal_1d_pos(self,position,dtype)
  Gemma3nAudioRelativePositionEmbedding._relative_shift(self,term_bd_before_shift,batch_size,num_heads,num_query_blocks,query_block_size,key_context_size,max_span_plus_1)
  Gemma3nAudioRelativePositionEmbedding.forward(self,queries,keys)
  Gemma3nAudioSSCPConvBlock.__init__(self,config,idx,input_freq_dim,manual_padding,quant_config,prefix)
  Gemma3nAudioSSCPConvBlock.forward(self,audio_encodings)
  Gemma3nAudioSubSampleConvProjection.__init__(self,config,quant_config,prefix)
  Gemma3nAudioSubSampleConvProjection.forward(self,audio_encodings)
  Gemma3nCumulativeGroupNorm.__init__(self,num_channels,feature_dims,eps)
  Gemma3nCumulativeGroupNorm.forward(self,x,mask)
models/gemma3n_causal.py:
  Gemma3nAltUp.__init__(self,config,quant_config,prefix)
  Gemma3nAltUp.compute_router_modalities(self,x)
  Gemma3nAltUp.correct(self,predictions,activated)
  Gemma3nAltUp.forward(self,hidden_states,activated)
  Gemma3nAltUp.predict(self,hidden_states)
  Gemma3nAltUp.scale_corrected_output(self,corrected)
  Gemma3nAttention.__init__(self,layer_id,config,max_position_embeddings,quant_config,prefix)
  Gemma3nAttention.forward(self,hidden_states,positions,forward_batch,**kwargs)
  Gemma3nDecoderLayer.__init__(self,layer_id,config,quant_config,prefix)
  Gemma3nDecoderLayer.forward(self,positions,hidden_states,per_layer_input,forward_batch,**kwargs)
  Gemma3nForCausalLM.__init__(self,config,quant_config,prefix)
  Gemma3nForCausalLM.dtype(self)
  Gemma3nForCausalLM.forward(self,input_ids,positions,forward_batch,input_embeds,per_layer_inputs,**kwargs)
  Gemma3nForCausalLM.get_attention_sliding_window_size(self)
  Gemma3nForCausalLM.get_input_embeddings(self)
  Gemma3nForCausalLM.load_weights(self,weights)
  Gemma3nLaurelBlock.__init__(self,config,quant_config,prefix)
  Gemma3nLaurelBlock.forward(self,x)
  Gemma3nRMSNorm.__init__(self,dim,eps,with_scale)
  Gemma3nRMSNorm.forward(self,x)
  Gemma3nTextMLP.__init__(self,hidden_size,intermediate_size,hidden_activation,activation_sparsity,quant_config,prefix)
  Gemma3nTextMLP._gaussian_topk(self,inputs)
  Gemma3nTextMLP.forward(self,x)
  Gemma3nTextModel.__init__(self,config,quant_config,prefix)
  Gemma3nTextModel.dtype(self)
  Gemma3nTextModel.forward(self,input_ids,positions,forward_batch,input_embeds,per_layer_inputs,**kwargs)
  Gemma3nTextModel.get_input_embeddings(self)
  Gemma3nTextModel.get_per_layer_inputs(self,input_ids)
  Gemma3nTextModel.project_per_layer_inputs(self,inputs_embeds,per_layer_inputs)
  get_attention_sliding_window_size(config)
models/gemma3n_mm.py:
  Gemma3nForConditionalGeneration.__init__(self,config,quant_config,prefix)
  Gemma3nForConditionalGeneration.forward(self,input_ids,positions,forward_batch,input_embeds,**kwargs)
  Gemma3nForConditionalGeneration.get_attention_sliding_window_size(self)
  Gemma3nForConditionalGeneration.get_audio_feature(self,items)
  Gemma3nForConditionalGeneration.get_hidden_dim(self,module_name)
  Gemma3nForConditionalGeneration.get_image_feature(self,items)
  Gemma3nForConditionalGeneration.get_input_embeddings(self)
  Gemma3nForConditionalGeneration.get_per_layer_inputs(self,input_ids)
  Gemma3nForConditionalGeneration.load_weights(self,weights)
  Gemma3nForConditionalGeneration.pad_input_ids(self,input_ids,mm_inputs)
  Gemma3nForConditionalGeneration.project_per_layer_inputs(self,inputs_embeds,per_layer_inputs)
  Gemma3nForConditionalGeneration.should_apply_lora(self,module_name)
  Gemma3nForConditionalGeneration.tie_weights(self)
  Gemma3nMultimodalEmbedder.__init__(self,multimodal_config,text_config,quant_config,prefix)
  Gemma3nMultimodalEmbedder.forward(self,input_ids,inputs_embeds)
models/glm4.py:
  Glm4Attention.__init__(self,config,layer_id,quant_config,prefix)
  Glm4Attention.forward(self,positions,hidden_states,forward_batch)
  Glm4DecoderLayer.__init__(self,config,layer_id,quant_config,prefix)
  Glm4DecoderLayer.forward(self,positions,hidden_states,forward_batch,residual)
  Glm4ForCausalLM.__init__(self,config,quant_config,prefix)
  Glm4ForCausalLM.forward(self,input_ids,positions,forward_batch)
  Glm4ForCausalLM.load_weights(self,weights)
  Glm4Model.__init__(self,config,quant_config,prefix)
  Glm4Model.dtype(self)
  Glm4Model.forward(self,input_ids,positions,forward_batch,input_embeds)
  Glm4Model.get_input_embeddings(self)
models/glm4_moe.py:
  Glm4MoeAttention.__init__(self,hidden_size,num_heads,num_kv_heads,layer_id,rope_theta,partial_rotary_factor,rope_scaling,max_position_embeddings,head_dim,rms_norm_eps,attention_bias,quant_config,use_qk_norm,prefix,alt_stream)
  Glm4MoeAttention._apply_qk_norm(self,q,k)
  Glm4MoeAttention.forward(self,positions,hidden_states,forward_batch)
  Glm4MoeAttention.forward_core(self,intermediate_state)
  Glm4MoeAttention.forward_prepare(self,positions,hidden_states,forward_batch)
  Glm4MoeAttention.op_core(self,state)
  Glm4MoeAttention.op_prepare(self,state)
  Glm4MoeDecoderLayer.__init__(self,config,layer_id,quant_config,is_nextn,prefix,alt_stream)
  Glm4MoeDecoderLayer.forward(self,positions,hidden_states,forward_batch,residual,zero_allocator)
  Glm4MoeForCausalLM.__init__(self,config,quant_config,prefix)
  Glm4MoeForCausalLM.determine_num_fused_shared_experts(self,architecture)
  Glm4MoeForCausalLM.get_input_embeddings(self)
  Glm4MoeForCausalLM.load_weights(self,weights,is_nextn)
  Glm4MoeGate.__init__(self,config,prefix,is_nextn)
  Glm4MoeGate.forward(self,hidden_states)
  Glm4MoeMLP.__init__(self,hidden_size,intermediate_size,hidden_act,quant_config,reduce_results,prefix,tp_rank,tp_size)
  Glm4MoeMLP.forward(self,x,forward_batch,should_allreduce_fusion)
  Glm4MoeModel.__init__(self,config,quant_config,prefix)
  Glm4MoeSparseMoeBlock.__init__(self,config,layer_id,quant_config,prefix,alt_stream,is_nextn)
  Glm4MoeSparseMoeBlock.forward_normal(self,hidden_states,should_allreduce_fusion,use_reduce_scatter)
  Glm4MoeSparseMoeBlock.forward_normal_dual_stream(self,hidden_states,should_allreduce_fusion,use_reduce_scatter)
models/glm4_moe_nextn.py:
  Glm4MoeForCausalLMNextN.__init__(self,config,quant_config,prefix)
  Glm4MoeForCausalLMNextN.forward(self,input_ids,positions,forward_batch)
  Glm4MoeForCausalLMNextN.load_weights(self,weights)
  Glm4MoeModelNextN.__init__(self,config,quant_config,prefix)
  Glm4MoeModelNextN.forward(self,input_ids,positions,forward_batch,input_embeds)
models/glm4v.py:
  Glm4vForConditionalGeneration.__init__(self,config,quant_config,prefix)
  Glm4vForConditionalGeneration._pad_vit_attn_dummy_heads(self,name,loaded_weight)
  Glm4vForConditionalGeneration._update_hf_config(self)
  Glm4vForConditionalGeneration.get_image_feature(self,items)
  Glm4vForConditionalGeneration.get_video_feature(self,items)
  Glm4vForConditionalGeneration.load_weights(self,weights)
  Glm4vPatchMerger.__init__(self,d_model,context_dim,quant_config,bias,prefix)
  Glm4vPatchMerger.forward(self,x)
  Glm4vRMSNorm.forward(self,x)
  Glm4vVisionBlock.__init__(self,config,norm_layer,quant_config,prefix)
  Glm4vVisionEmbeddings.__init__(self,config)
  Glm4vVisionEmbeddings.forward(self,embeddings,lengths,image_shapes,h_coords,w_coords)
  Glm4vVisionMLP.__init__(self,in_features,hidden_features,bias,quant_config,prefix)
  Glm4vVisionMLP.forward(self,x)
  Glm4vVisionModel.__init__(self,vision_config,norm_eps,quant_config,prefix)
  Glm4vVisionModel.device(self)
  Glm4vVisionModel.dtype(self)
  Glm4vVisionModel.forward(self,x,grid_thw)
  Glm4vVisionModel.rot_pos_emb(self,grid_thw)
  Glm4vVisionPatchEmbed.__init__(self,patch_size,temporal_patch_size,in_channels,hidden_size)
  Glm4vVisionPatchEmbed.forward(self,x)
  Glm4vVisionRotaryEmbedding.__init__(self,dim,theta)
  Glm4vVisionRotaryEmbedding.forward(self,seqlen)
  Glm4vVisionRotaryEmbedding.update_freqs_cache(self,seqlen)
models/glm4v_moe.py:
  Glm4vMoeForConditionalGeneration.__init__(self,config,quant_config,prefix)
  Glm4vMoeForConditionalGeneration.determine_num_fused_shared_experts(self,architecture)
  Glm4vMoeForConditionalGeneration.load_weights(self,weights,is_nextn)
models/gpt2.py:
  GPT2Attention.__init__(self,layer_id,config,quant_config,prefix)
  GPT2Attention.forward(self,hidden_states,forward_batch)
  GPT2Block.__init__(self,layer_id,config,act_layer,quant_config,prefix)
  GPT2Block.forward(self,hidden_states,forward_batch)
  GPT2LMHeadModel.__init__(self,config,quant_config,prefix)
  GPT2LMHeadModel.forward(self,input_ids,positions,forward_batch)
  GPT2LMHeadModel.load_weights(self,weights)
  GPT2MLP.__init__(self,intermediate_size,config,act_layer,quant_config,prefix)
  GPT2MLP.forward(self,hidden_states)
  GPT2Model.__init__(self,config,quant_config,prefix)
  GPT2Model.forward(self,input_ids,position_ids,forward_batch)
models/gpt_bigcode.py:
  GPTBigCodeAttention.__init__(self,layer_id,config,quant_config,prefix)
  GPTBigCodeAttention.forward(self,hidden_states,forward_batch)
  GPTBigCodeBlock.__init__(self,layer_id,config,quant_config,prefix)
  GPTBigCodeBlock.forward(self,hidden_states,forward_batch)
  GPTBigCodeForCausalLM.__init__(self,config,quant_config,prefix)
  GPTBigCodeForCausalLM.forward(self,input_ids,positions,forward_batch)
  GPTBigCodeForCausalLM.load_weights(self,weights)
  GPTBigCodeModel.__init__(self,config,quant_config,prefix)
  GPTBigCodeModel.forward(self,input_ids,position_ids,forward_batch)
  GPTBigMLP.__init__(self,intermediate_size,config,quant_config,prefix)
  GPTBigMLP.forward(self,hidden_states)
models/gpt_oss.py:
  GptOssAttention.__init__(self,hidden_size,num_heads,num_kv_heads,layer_id,rope_theta,rope_scaling,max_position_embeddings,head_dim,rms_norm_eps,attention_bias,quant_config,prefix,sliding_window_size,layer_type,params_dtype)
  GptOssAttention.forward(self,positions,hidden_states,forward_batch)
  GptOssAttention.forward_core(self,intermediate_state)
  GptOssAttention.forward_prepare(self,positions,hidden_states,forward_batch)
  GptOssConfig.__init__(self,**kwargs)
  GptOssDecoderLayer.__init__(self,config,layer_id,quant_config,prefix,sliding_window_size)
  GptOssDecoderLayer.forward(self,positions,hidden_states,forward_batch,residual)
  GptOssForCausalLM.__init__(self,config,quant_config,prefix)
  GptOssForCausalLM._get_default_weight_mapping(self)
  GptOssForCausalLM._load_mxfp4_experts_weights(self,weights)
  GptOssForCausalLM._load_normal_weights(self,weights,is_nextn,weight_name_mapping,other_loaded_param_names)
  GptOssForCausalLM._load_weights_mxfp4(self,weights,is_nextn,weight_name_mapping)
  GptOssForCausalLM.end_layer(self)
  GptOssForCausalLM.forward(self,input_ids,positions,forward_batch,input_embeds,pp_proxy_tensors)
  GptOssForCausalLM.get_attention_sliding_window_size(self)
  GptOssForCausalLM.get_embed_and_head(self)
  GptOssForCausalLM.get_model_config_for_expert_location(cls,config)
  GptOssForCausalLM.load_weights(self,weights,is_nextn,weight_name_mapping)
  GptOssForCausalLM.routed_experts_weights_of_layer(self)
  GptOssForCausalLM.set_eagle3_layers_to_capture(self,layer_ids)
  GptOssForCausalLM.set_embed_and_head(self,embed,head)
  GptOssForCausalLM.start_layer(self)
  GptOssModel.__init__(self,config,quant_config,prefix,decoder_layer_type)
  GptOssModel.forward(self,input_ids,positions,forward_batch,input_embeds,pp_proxy_tensors)
  GptOssSparseMoeBlock.__init__(self,layer_id,config,quant_config,prefix)
  GptOssSparseMoeBlock.forward(self,hidden_states,forward_batch,should_allreduce_fusion)
  GptOssSparseMoeBlock.forward_normal(self,hidden_states,should_allreduce_fusion)
  GptOssSparseMoeBlock.get_moe_weights(self)
  _WeightCreator.__init__(self,fn)
  _WeightCreator.maybe_materialize(obj)
  _canonicalize_weights(config,weights_in)
  _create_fused_set_kv_buffer_arg(value,layer,forward_batch)
  _dequant_mlp_weight(debug_name,w_blocks,w_scales)
  _enable_fused_set_kv_buffer()
  get_attention_sliding_window_size(config)
models/granite.py:
  GraniteAttention.__init__(self,config,hidden_size,num_heads,num_kv_heads,layer_id,rope_theta,rope_scaling,rope_is_neox_style,max_position_embeddings,quant_config,prefix)
  GraniteAttention.forward(self,positions,hidden_states,forward_batch)
  GraniteDecoderLayer.__init__(self,config,layer_id,quant_config,prefix)
  GraniteDecoderLayer.forward(self,positions,hidden_states,forward_batch,residual)
  GraniteForCausalLM.__init__(self,config,quant_config,prefix)
  GraniteForCausalLM.forward(self,input_ids,positions,forward_batch,input_embeds,get_embedding)
  GraniteForCausalLM.get_module_name_from_weight_name(self,name)
  GraniteForCausalLM.get_num_params(self)
  GraniteForCausalLM.get_weights_by_name(self,name,truncate_size,tp_size)
  GraniteForCausalLM.load_weights(self,weights)
  GraniteMLP.__init__(self,hidden_size,intermediate_size,hidden_act,quant_config,prefix)
  GraniteMLP.forward(self,x)
  GraniteModel.__init__(self,config,quant_config,prefix)
  GraniteModel.forward(self,input_ids,positions,forward_batch,input_embeds)
models/granitemoe.py:
  GraniteMoeAttention.__init__(self,hidden_size,num_heads,num_kv_heads,max_position,layer_id,rope_theta,quant_config,attention_multiplier,prefix)
  GraniteMoeAttention.forward(self,positions,hidden_states,forward_batch)
  GraniteMoeDecoderLayer.__init__(self,config,layer_id,quant_config,prefix)
  GraniteMoeDecoderLayer.forward(self,positions,hidden_states,forward_batch)
  GraniteMoeForCausalLM.__init__(self,config,quant_config,prefix)
  GraniteMoeForCausalLM.forward(self,input_ids,positions,forward_batch,input_embeds,get_embedding)
  GraniteMoeForCausalLM.load_weights(self,weights)
  GraniteMoeMoE.__init__(self,num_experts,top_k,hidden_size,intermediate_size,layer_id,params_dtype,quant_config,tp_size,prefix)
  GraniteMoeMoE.forward(self,hidden_states)
  GraniteMoeModel.__init__(self,config,quant_config,prefix)
  GraniteMoeModel.forward(self,input_ids,positions,forward_batch,inputs_embeds)
  GraniteMoeModel.get_input_embeddings(self,input_ids)
models/grok.py:
  Grok1Attention.__init__(self,config,hidden_size,num_heads,num_kv_heads,layer_id,max_position,rope_theta,quant_config,reduce_results,alt_stream,load_presharded_attn,prefix)
  Grok1Attention.forward(self,positions,hidden_states,forward_batch)
  Grok1DecoderLayer.__init__(self,config,layer_id,quant_config,load_presharded_moe,load_presharded_attn,load_presharded_mlp,alt_stream,skip_moe,prefix)
  Grok1DecoderLayer.forward(self,positions,hidden_states,forward_batch,residual,deferred_norm)
  Grok1DecoderLayer.moe_with_rmoe(self,x)
  Grok1ForCausalLM.__init__(self,config,quant_config,prefix)
  Grok1ForCausalLM.forward(self,input_ids,positions,forward_batch,input_embeds)
  Grok1ForCausalLM.get_num_params_analytical(self)
  Grok1ForCausalLM.get_num_params_torch(self)
  Grok1ForCausalLM.load_weight_wrapper(name,loaded_weight,*args,**kwargs)
  Grok1ForCausalLM.load_weights(self,weights,ignore_parent_name,check_hit_names,model_config)
  Grok1MLP.__init__(self,hidden_size,intermediate_size,layer_id,quant_config,prefix,reduce_results,use_presharded_weights,split_gate_up)
  Grok1MLP.forward(self,x)
  Grok1MoE.__init__(self,config,layer_id,num_experts,top_k,hidden_size,intermediate_size,params_dtype,quant_config,tp_size,reduce_results,use_presharded_weights,inplace,no_combine,prefix)
  Grok1MoE.forward(self,hidden_states)
  Grok1Model.__init__(self,config,quant_config,load_presharded_moe,load_presharded_embedding,load_presharded_attn,load_presharded_mlp,replicate_embedding,prefix)
  Grok1Model.forward(self,input_ids,positions,forward_batch,input_embeds)
  ScalingRotaryEmbedding.__init__(self,head_size,rotary_dim,max_position_embeddings,base,is_neox_style,scaling_factor,dtype,extra_method,extrapolation_factor,attn_factor,beta_fast,beta_slow)
  ScalingRotaryEmbedding._compute_cos_sin_cache(self)
  ScalingRotaryEmbedding._compute_inv_freq(self,scaling_factor)
  _prepare_presharded_weights(self,model_name_or_path,revision,fall_back_to_pt)
  _yarn_linear_ramp_mask(low,high,dim,dtype)
  get_rope_scaling(config)
models/hunyuan.py:
  HunYuanAttention.__init__(self,config,hidden_size,num_heads,num_kv_heads,rope_theta,rope_scaling,max_position_embeddings,quant_config,bias,prefix,attention_type,layer_id)
  HunYuanAttention.forward(self,positions,hidden_states,forward_batch,kv_states)
  HunYuanDecoderLayer.__init__(self,config,quant_config,prefix,layer_id)
  HunYuanDecoderLayer.forward(self,positions,hidden_states,forward_batch,residual,kv_states)
  HunYuanMLP.__init__(self,hidden_size,intermediate_size,hidden_act,quant_config,bias,prefix,reduce_results)
  HunYuanMLP.forward(self,x)
  HunYuanMoEV1ForCausalLM.__init__(self,config,quant_config)
  HunYuanMoEV1ForCausalLM._split_qkv_weight(self,qkv)
  HunYuanMoEV1ForCausalLM.forward(self,input_ids,positions,forward_batch,input_embeds)
  HunYuanMoEV1ForCausalLM.load_kv_cache_scales(self,quantization_param_path)
  HunYuanMoEV1ForCausalLM.load_weights(self,weights)
  HunYuanModel.__init__(self,config,quant_config,prefix)
  HunYuanModel.forward(self,input_ids,positions,forward_batch,input_embeds)
  HunYuanModel.get_input_embeddings(self,input_ids)
  HunYuanSparseMoeBlock.__init__(self,config,quant_config,layer_id)
  HunYuanSparseMoeBlock.forward(self,hidden_states)
  _get_cla_factor(config)
  _is_moe(config)
  check_head_dim(config)
  get_head_dim(config)
models/idefics2.py:
  Idefics2Encoder.__init__(self,config,quant_config,prefix)
  Idefics2Encoder.forward(self,inputs_embeds,cu_seqlens)
  Idefics2EncoderLayer.__init__(self,config,quant_config,prefix)
  Idefics2EncoderLayer.forward(self,hidden_states,cu_seqlens)
  Idefics2VisionEmbeddings.__init__(self,config)
  Idefics2VisionEmbeddings.forward(self,pixel_values,patch_attention_mask,tgt_sizes)
  Idefics2VisionEmbeddings.get_position_ids(self,pixel_values,patch_attention_mask,tgt_sizes)
  Idefics2VisionMLP.__init__(self,config,quant_config,prefix)
  Idefics2VisionMLP.forward(self,hidden_states)
  Idefics2VisionTransformer.__init__(self,config,quant_config,require_post_norm,prefix)
  Idefics2VisionTransformer.compute_cu_seqlens(self,tgt_sizes,input_embeds)
  Idefics2VisionTransformer.forward(self,pixel_values,patch_attention_mask,tgt_sizes)
  Idefics2VisionTransformer.get_input_embeddings(self)
models/internlm2.py:
  InternLM2Attention.__init__(self,hidden_size,num_heads,num_kv_heads,rope_theta,rope_scaling,max_position_embeddings,layer_id,quant_config,prefix)
  InternLM2Attention.forward(self,positions,hidden_states,forward_batch)
  InternLM2ForCausalLM.__init__(self,config,quant_config,prefix)
  InternLM2ForCausalLM.forward(self,input_ids,positions,forward_batch,input_embeds)
  InternLM2ForCausalLM.get_input_embeddings(self)
  InternLM2ForCausalLM.load_weights(self,weights)
  InternLM2MLP.__init__(self,hidden_size,intermediate_size,hidden_act,quant_config,prefix)
  InternLM2MLP.forward(self,x)
  InternLM2Model.__init__(self,config,quant_config,prefix)
  InternLM2Model.forward(self,input_ids,positions,forward_batch,input_embeds)
  InternLMDecoderLayer.__init__(self,config,layer_id,quant_config,prefix)
  InternLMDecoderLayer.forward(self,positions,hidden_states,forward_batch,residual)
models/internlm2_reward.py:
  InternLM2ForRewardModel.__init__(self,config,quant_config,prefix)
  InternLM2ForRewardModel.forward(self,input_ids,positions,forward_batch,input_embeds,get_embedding)
  InternLM2ForRewardModel.load_weights(self,weights)
models/interns1.py:
  InternS1ForConditionalGeneration.__init__(self,config,quant_config,use_flash_attn)
  InternS1ForConditionalGeneration._mapping_interns1_name(self,name)
  InternS1ForConditionalGeneration.extract_feature(self,pixel_values)
  InternS1ForConditionalGeneration.forward(self,input_ids,positions,forward_batch,input_embeds)
  InternS1ForConditionalGeneration.get_image_feature(self,items)
  InternS1ForConditionalGeneration.load_weights(self,weights)
  InternS1ForConditionalGeneration.pad_input_ids(self,input_ids,mm_inputs)
  InternS1ForConditionalGeneration.pixel_shuffle(self,x,scale_factor)
models/internvl.py:
  InternAttention.__init__(self,config,quant_config)
  InternAttention.forward(self,hidden_states,cu_seqlens)
  InternMLP.__init__(self,config)
  InternMLP.forward(self,hidden_states)
  InternRMSNorm.__init__(self,hidden_size,eps)
  InternRMSNorm.forward(self,hidden_states)
  InternVLChatModel.__init__(self,config,quant_config,use_flash_attn)
  InternVLChatModel.extract_feature(self,pixel_values)
  InternVLChatModel.forward(self,input_ids,positions,forward_batch,input_embeds)
  InternVLChatModel.get_image_feature(self,items)
  InternVLChatModel.load_weights(self,weights)
  InternVLChatModel.pad_input_ids(self,input_ids,mm_inputs)
  InternVLChatModel.pixel_shuffle(self,x,scale_factor)
  InternVisionEmbeddings.__init__(self,config)
  InternVisionEmbeddings._get_pos_embed(self,pos_embed,H,W)
  InternVisionEmbeddings.forward(self,pixel_values)
  InternVisionEncoder.__init__(self,config,quant_config)
  InternVisionEncoder.forward(self,inputs_embeds,output_hidden_states,return_dict)
  InternVisionEncoderLayer.__init__(self,config,drop_path_rate,quant_config)
  InternVisionEncoderLayer.forward(self,hidden_states,cu_seqlens)
  InternVisionModel.__init__(self,config,quant_config)
  InternVisionModel.forward(self,pixel_values,output_hidden_states,return_dict,pixel_embeds)
  InternVisionModel.get_input_embeddings(self)
  InternVisionModel.resize_pos_embeddings(self,old_size,new_size,patch_size)
models/kimi_vl.py:
  KimiVLForConditionalGeneration.__init__(self,config,quant_config,prefix,**kwargs)
  KimiVLForConditionalGeneration.forward(self,input_ids,positions,forward_batch,get_embedding)
  KimiVLForConditionalGeneration.get_image_feature(self,items)
  KimiVLForConditionalGeneration.load_weights(self,weights)
  KimiVLForConditionalGeneration.pad_input_ids(self,input_ids,mm_inputs)
  KimiVLMultiModalProjector.__init__(self,config)
  KimiVLMultiModalProjector.forward(self,image_features)
  get_spec_layer_idx_from_weight_name(config,weight_name)
models/kimi_vl_moonvit.py:
  Learnable2DInterpPosEmb.__init__(self,height,width,dim,interpolation_mode)
  Learnable2DInterpPosEmb.forward(self,x,grid_hws)
  Learnable2DInterpPosEmb.reset_parameters(self)
  MLP2.__init__(self,dims,activation,bias)
  MLP2.forward(self,x)
  MoonVisionPatchEmbed.__init__(self,out_dim,in_dim,patch_size,pos_emb_height,pos_emb_width)
  MoonVisionPatchEmbed.forward(self,x,grid_hw)
  MoonVitEncoder.__init__(self,hidden_dim,num_layers,block_cfg)
  MoonVitEncoder.forward(self,hidden_states,grid_hw)
  MoonVitEncoderLayer.__init__(self,num_heads,hidden_dim,mlp_dim,attn_implementation,activation,attn_bias)
  MoonVitEncoderLayer.attention_qkvpacked(self,x,cu_seqlens,rope_freqs_cis)
  MoonVitEncoderLayer.forward(self,hidden_states,cu_seqlens,rope_freqs_cis)
  MoonVitPretrainedModel.__init__(self,config,*inputs,**kwargs)
  MoonVitPretrainedModel.forward(self,pixel_values,grid_hw)
  MoonVitVLProjector.__init__(self,in_channels,merge_kernel_size,hidden_act,ln_eps,out_dim)
  MoonVitVLProjector.forward(self,hidden_states)
  Rope2DPosEmb.__init__(self,dim,max_height,max_width,theta_base,device)
  Rope2DPosEmb.extra_repr(self)
  Rope2DPosEmb.get_freqs_cis_by_idx(self,pos_idx,pos_idx_mask)
  Rope2DPosEmb.get_freqs_cis_by_seqlens(self,grid_hws)
  Rope2DPosEmb.precomputed_freqs_cis(self)
  _apply_rope_input_validation(x,freqs_cis)
  apply_rope(xq,xk,freqs_cis)
  multihead_attention(q,k,v,q_cu_seqlens,k_cu_seqlens)
  patch_merger(x,grid_hw,merge_kernel_size)
  sdpa_attention(q,k,v,q_cu_seqlens,k_cu_seqlens)
models/llama.py:
  LlamaAttention.__init__(self,config,hidden_size,num_heads,num_kv_heads,layer_id,rope_theta,rope_scaling,rope_is_neox_style,max_position_embeddings,quant_config,prefix,bias)
  LlamaAttention.forward(self,positions,hidden_states,forward_batch)
  LlamaDecoderLayer.__init__(self,config,layer_id,quant_config,prefix)
  LlamaDecoderLayer.forward(self,positions,hidden_states,forward_batch,residual)
  LlamaForCausalLM.__init__(self,config,quant_config,prefix)
  LlamaForCausalLM._init_model(self,config,quant_config,prefix)
  LlamaForCausalLM.end_layer(self)
  LlamaForCausalLM.forward(self,input_ids,positions,forward_batch,input_embeds,get_embedding,pp_proxy_tensors)
  LlamaForCausalLM.forward_split_prefill(self,input_ids,positions,forward_batch,split_interval,input_embeds)
  LlamaForCausalLM.get_embed(self)
  LlamaForCausalLM.get_embed_and_head(self)
  LlamaForCausalLM.get_input_embeddings(self)
  LlamaForCausalLM.get_module_name_from_weight_name(self,name)
  LlamaForCausalLM.get_num_params(self)
  LlamaForCausalLM.get_weights_by_name(self,name,truncate_size,tp_size)
  LlamaForCausalLM.load_kv_cache_scales(self,quantization_param_path)
  LlamaForCausalLM.load_weights(self,weights)
  LlamaForCausalLM.set_eagle3_layers_to_capture(self,layer_ids)
  LlamaForCausalLM.set_embed(self,embed)
  LlamaForCausalLM.set_embed_and_head(self,embed,head)
  LlamaForCausalLM.start_layer(self)
  LlamaMLP.__init__(self,hidden_size,intermediate_size,hidden_act,quant_config,prefix,reduce_results)
  LlamaMLP.forward(self,x,forward_batch,use_reduce_scatter)
  LlamaModel.__init__(self,config,quant_config,prefix)
  LlamaModel.forward(self,input_ids,positions,forward_batch,input_embeds,pp_proxy_tensors)
  LlamaModel.load_kv_cache_scales(self,quantization_param_path)
models/llama4.py:
  Llama4Attention.__init__(self,config,layer_id,hidden_size,num_heads,num_kv_heads,rope_theta,rope_scaling,max_position_embeddings,quant_config,bias,bias_o_proj,prefix)
  Llama4Attention._get_attn_scale(self,positions)
  Llama4Attention._mul_attn_scale(self,positions,q)
  Llama4Attention.forward(self,positions,hidden_states,forward_batch)
  Llama4DecoderLayer.__init__(self,config,layer_id,quant_config,prefix)
  Llama4DecoderLayer._is_moe_layer(self,layer_id)
  Llama4DecoderLayer.forward(self,positions,hidden_states,forward_batch,residual)
  Llama4ForCausalLM.__init__(self,config,quant_config,prefix)
  Llama4ForCausalLM._init_model(self,config,quant_config,prefix)
  Llama4ForCausalLM.get_input_embeddings(self)
  Llama4MoE.__init__(self,config,layer_id,quant_config,prefix)
  Llama4MoE._forward_core(self,hidden_states,forward_mode)
  Llama4MoE._forward_core_normal(self,hidden_states)
  Llama4MoE._forward_core_shared_routed_overlap(self,hidden_states)
  Llama4MoE.custom_routing_function(hidden_states,gating_output,topk,renormalize)
  Llama4MoE.forward(self,hidden_states,forward_batch,use_reduce_scatter)
  Llama4Model.__init__(self,config,quant_config,prefix)
  Llama4Model.forward(self,input_ids,positions,forward_batch,input_embeds,pp_proxy_tensors)
  _get_or_create_alt_stream(device_module)
models/llama_classification.py:
  LlamaForClassification.__init__(self,config,quant_config,prefix)
  LlamaForClassification.forward(self,input_ids,positions,forward_batch,input_embeds,get_embedding)
  LlamaForClassification.load_weights(self,weights)
models/llama_eagle.py:
  LlamaDecoderLayer.__init__(self,config,layer_id,quant_config,prefix)
  LlamaForCausalLMEagle.__init__(self,config,quant_config,prefix)
  LlamaForCausalLMEagle.load_weights(self,weights)
  LlamaModel.__init__(self,config,quant_config,prefix)
  LlamaModel.forward(self,input_ids,positions,forward_batch,input_embeds,pp_proxy_tensors)
models/llama_eagle3.py:
  LlamaDecoderLayer.__init__(self,config,layer_id,quant_config,prefix)
  LlamaDecoderLayer.forward(self,positions,embeds,hidden_states,forward_batch,residual)
  LlamaForCausalLMEagle3.__init__(self,config,quant_config,prefix)
  LlamaForCausalLMEagle3.get_hot_token_id(self)
  LlamaForCausalLMEagle3.load_weights(self,weights)
  LlamaModel.__init__(self,config,quant_config,prefix)
  LlamaModel.forward(self,input_ids,positions,forward_batch,input_embeds,pp_proxy_tensors)
models/llama_embedding.py:
  LlamaEmbeddingModel.__init__(self,config,quant_config,prefix)
  LlamaEmbeddingModel.forward(self,input_ids,positions,forward_batch,input_embeds,get_embedding)
  LlamaEmbeddingModel.load_weights(self,weights)
models/llama_reward.py:
  LlamaForSequenceClassification.__init__(self,config,quant_config,prefix)
  LlamaForSequenceClassification.forward(self,input_ids,positions,forward_batch,input_embeds,get_embedding)
  LlamaForSequenceClassification.load_weights(self,weights)
  LlamaForSequenceClassificationWithNormal_Weights.Weights.__init__(self,hidden_size,num_label)
  LlamaForSequenceClassificationWithNormal_Weights.Weights.forward(self,x)
  LlamaForSequenceClassificationWithNormal_Weights.__init__(self,config,quant_config,prefix)
  LlamaForSequenceClassificationWithNormal_Weights.forward(self,input_ids,positions,forward_batch,input_embeds,get_embedding)
  LlamaForSequenceClassificationWithNormal_Weights.load_weights(self,weights)
models/llava.py:
  LlavaBaseForCausalLM.encode_images(self,pixel_values)
  LlavaBaseForCausalLM.forward(self,input_ids,positions,forward_batch)
  LlavaBaseForCausalLM.load_weights(self,weights)
  LlavaBaseForCausalLM.num_patches_per_side(self)
  LlavaBaseForCausalLM.pad_input_ids(self,input_ids,image_inputs)
  LlavaForConditionalGeneration.__init__(self,config,quant_config,prefix)
  LlavaForConditionalGeneration._config_cls_name_to_arch_name_mapping(self,auto_model_type)
  LlavaForConditionalGeneration._get_sgl_model_cls(self,config,auto_model_type)
  LlavaForConditionalGeneration.dtype(self)
  LlavaForConditionalGeneration.forward(self,input_ids,positions,forward_batch,get_embedding)
  LlavaForConditionalGeneration.get_image_feature(self,items)
  LlavaForConditionalGeneration.load_weights(self,weights)
  LlavaForConditionalGeneration.pad_input_ids(self,input_ids,image_inputs)
  LlavaLlamaForCausalLM.__init__(self,config,quant_config,prefix)
  LlavaMistralForCausalLM.__init__(self,config,quant_config,prefix)
  LlavaQwenForCausalLM.__init__(self,config,quant_config,prefix)
models/llavavid.py:
  LlavaVidForCausalLM.__init__(self,config,quant_config,prefix)
  LlavaVidForCausalLM.encode_images(self,pixel_values)
  LlavaVidForCausalLM.forward(self,input_ids,positions,forward_batch)
  LlavaVidForCausalLM.load_weights(self,weights)
  LlavaVidForCausalLM.num_patches_per_side(self)
  LlavaVidForCausalLM.pad_input_ids(self,input_ids,image_inputs)
models/longcat_flash.py:
  LongcatFlashDecoderLayer.__init__(self,config,layer_id,quant_config,prefix,alt_stream)
  LongcatFlashDecoderLayer.forward(self,positions,hidden_states,forward_batch,residual,zero_allocator)
  LongcatFlashDecoderLayer.forward_mlp(self,hidden_states,positions,residual,forward_batch,zero_allocator)
  LongcatFlashForCausalLM.__init__(self,config,quant_config,prefix)
  LongcatFlashForCausalLM._weight_requant_ue8m0(self)
  LongcatFlashForCausalLM.forward(self,input_ids,positions,forward_batch,input_embeds)
  LongcatFlashForCausalLM.get_embed_and_head(self)
  LongcatFlashForCausalLM.get_input_embeddings(self)
  LongcatFlashForCausalLM.get_model_config_for_expert_location(cls,config)
  LongcatFlashForCausalLM.load_weights(self,weights)
  LongcatFlashForCausalLM.post_load_weights(self,weight_names)
  LongcatFlashForCausalLM.set_embed_and_head(self,embed,head)
  LongcatFlashMLP.__init__(self,hidden_size,intermediate_size,hidden_act,quant_config,reduce_results,prefix)
  LongcatFlashMLP.forward(self,x)
  LongcatFlashMoE.__init__(self,config,layer_id,quant_config,prefix)
  LongcatFlashMoE.forward(self,hidden_states)
  LongcatFlashMoE.get_moe_weights(self)
  LongcatFlashModel.__init__(self,config,quant_config,prefix)
  LongcatFlashModel.forward(self,input_ids,positions,forward_batch,input_embeds)
  LongcatFlashModel.get_input_embeddings(self)
  LongcatFlashRouter.__init__(self,config,zero_expert_num,rounter_params_dtype,prefix)
  LongcatFlashRouter.forward(self,hidden_states)
models/longcat_flash_nextn.py:
  LongcatFlashDenseDecoderLayer.__init__(self,config,layer_id,quant_config,prefix,alt_stream)
  LongcatFlashDenseDecoderLayer.forward(self,positions,hidden_states,forward_batch,residual,zero_allocator)
  LongcatFlashForCausalLMNextN.__init__(self,config,quant_config)
  LongcatFlashForCausalLMNextN._weight_requant_ue8m0(self)
  LongcatFlashForCausalLMNextN.forward(self,input_ids,positions,forward_batch)
  LongcatFlashForCausalLMNextN.load_weights(self,weights)
  LongcatFlashForCausalLMNextN.post_load_weights(self)
  LongcatFlashModelNextN.__init__(self,config,quant_config,prefix)
  LongcatFlashModelNextN.forward(self,input_ids,positions,forward_batch,input_embeds)
  LongcatFlashModelNextN.get_input_embeddings(self)
models/mimo.py:
  MiMoForCausalLM.__init__(self,config,quant_config,prefix)
  MiMoForCausalLM.forward(self,input_ids,positions,forward_batch,input_embeds,get_embedding)
  MiMoForCausalLM.get_embed_and_head(self)
  MiMoForCausalLM.get_input_embeddings(self,input_ids)
  MiMoForCausalLM.load_kv_cache_scales(self,quantization_param_path)
  MiMoForCausalLM.load_weights(self,weights)
  MiMoForCausalLM.set_embed_and_head(self,embed,head)
  MiMoModel.__init__(self,config,quant_config,prefix)
models/mimo_mtp.py:
  MiMoMTP.__init__(self,config,quant_config,prefix)
  MiMoMTP.forward(self,input_ids,positions,forward_batch)
  MiMoMTP.get_embed_and_head(self)
  MiMoMTP.load_weights(self,weights)
  MiMoMTP.map_model_name_to_mtp_param_name(self,name)
  MiMoMTP.set_embed_and_head(self,embed,head)
  MiMoMultiTokenPredictorLayer.__init__(self,config,prefix,quant_config)
  MiMoMultiTokenPredictorLayer.forward(self,input_ids,positions,forward_batch,input_embeds)
models/minicpm.py:
  MiniCPMAttention.__init__(self,hidden_size,num_heads,num_kv_heads,layer_id,rope_theta,rope_scaling,max_position_embeddings,quant_config,prefix)
  MiniCPMAttention.forward(self,positions,hidden_states,forward_batch)
  MiniCPMDecoderLayer.__init__(self,config,layer_id,quant_config,prefix)
  MiniCPMDecoderLayer.forward(self,positions,hidden_states,forward_batch,residual)
  MiniCPMForCausalLM.__init__(self,config,quant_config,prefix)
  MiniCPMForCausalLM.forward(self,input_ids,positions,forward_batch,input_embeds)
  MiniCPMForCausalLM.load_weights(self,weights)
  MiniCPMMLP.__init__(self,hidden_size,intermediate_size,hidden_act,quant_config,prefix)
  MiniCPMMLP.forward(self,x)
  MiniCPMModel.__init__(self,config,quant_config,prefix)
  MiniCPMModel.forward(self,input_ids,positions,forward_batch,input_embeds)
models/minicpm3.py:
  MiniCPM3AttentionMLA.__init__(self,config,hidden_size,num_heads,qk_nope_head_dim,qk_rope_head_dim,v_head_dim,q_lora_rank,kv_lora_rank,rope_theta,rope_scaling,max_position_embeddings,quant_config,layer_id,prefix)
  MiniCPM3AttentionMLA.forward(self,positions,hidden_states,forward_batch)
  MiniCPM3DecoderLayer.__init__(self,config,layer_id,quant_config,prefix)
  MiniCPM3DecoderLayer.forward(self,positions,hidden_states,forward_batch,residual)
  MiniCPM3ForCausalLM.__init__(self,config,quant_config,prefix)
  MiniCPM3ForCausalLM.forward(self,input_ids,positions,forward_batch,input_embeds)
  MiniCPM3ForCausalLM.load_weights(self,weights)
  MiniCPM3MLP.__init__(self,hidden_size,intermediate_size,hidden_act,quant_config,prefix)
  MiniCPM3MLP.forward(self,x)
  MiniCPM3Model.__init__(self,config,quant_config,prefix)
  MiniCPM3Model.forward(self,input_ids,positions,forward_batch,input_embeds)
  input_to_float8(x,dtype)
models/minicpmo.py:
  ConditionalChatTTS.__init__(self,config)
  ConditionalChatTTS.decode_to_mel_specs(self,result_list)
  ConditionalChatTTS.generate(self,input_ids,past_key_values,temperature,eos_token,streaming_tts_text_mask,force_no_stop,min_new_token,max_new_token,logits_warpers,logits_processors,show_tqdm)
  ConditionalChatTTS.merge_inputs_embeds(self,input_ids,lm_spk_emb_last_hidden_states)
  ConditionalChatTTS.prefill_audio_ids(self,input_ids,past_key_values,streaming_tts_text_mask,add_audio_bos)
  ConditionalChatTTS.prefill_text(self,input_ids,position_ids,past_key_values,lm_spk_emb_last_hidden_states)
  ConvNeXtBlock.__init__(self,dim,intermediate_dim,kernel,dilation,layer_scale_init_value)
  ConvNeXtBlock.forward(self,x,cond)
  CustomRepetitionPenaltyLogitsProcessorRepeat.__call__(self,input_ids,scores)
  CustomRepetitionPenaltyLogitsProcessorRepeat.__init__(self,penalty,max_input_ids,past_window)
  DVAE.__init__(self)
  DVAE.forward(self,inp,mode)
  DVAEDecoder.__init__(self,idim,odim,n_layer,bn_dim,hidden,kernel,dilation,up)
  DVAEDecoder.forward(self,x,conditioning)
  GFSQ.__call__(self,x)
  GFSQ.__init__(self,dim,levels,G,R,eps,transpose)
  GFSQ._embed(self,x)
  GFSQ.forward(self,x)
  MiniCPMO.__init__(self,config,quant_config)
  MiniCPMO._get_feat_extract_output_lengths(self,input_lengths)
  MiniCPMO.forward(self,input_ids,positions,forward_batch,**kwargs)
  MiniCPMO.get_audio_embedding(self,items,chunk_length)
  MiniCPMO.get_audio_embedding_streaming(self,items)
  MiniCPMO.get_audio_feature(self,items)
  MiniCPMO.get_image_feature(self,items)
  MiniCPMO.get_omni_embedding(self,items,chunk_length,stream_input)
  MiniCPMO.init_audio_module(self)
  MiniCPMO.init_llm(self,config,quant_config,prefix)
  MiniCPMO.init_resampler(self,embed_dim,vision_dim,quant_config,prefix)
  MiniCPMO.init_tts_module(self)
  MiniCPMO.init_vision_module(self,config,quant_config,prefix)
  MiniCPMO.load_weights(self,weights)
  MiniCPMO.pad_input_ids(self,input_ids,mm_input)
  MiniCPMO.subsequent_chunk_mask(self,size,chunk_size,num_left_chunks,device,num_lookhead)
  MiniCPMWhisperEncoder.__init__(self,config)
  MiniCPMWhisperEncoder.forward(self,input_features,attention_mask,head_mask,output_attentions,output_hidden_states,return_dict,past_key_values,use_cache)
  MiniCPMWhisperEncoderLayer.__init__(self,config,layer_idx)
  MiniCPMWhisperEncoderLayer.forward(self,hidden_states,attention_mask,layer_head_mask,output_attentions,past_key_values,use_cache)
  MultiModalProjector.__init__(self,in_dim,out_dim)
  MultiModalProjector.forward(self,audio_features)
  apply_spk_emb(input_ids,spk_emb,input_embeds,spk_emb_token_id,num_spk_embs)
  make_streaming_chunk_mask_generation(inputs_embeds,past_seen_tokens,streaming_tts_text_mask,streaming_reserved_length,streaming_audio_chunk_size,streaming_text_chunk_size,num_spk_emb,use_spk_emb)
models/minicpmv.py:
  BaseResampler.__init__(self,num_queries,embed_dim,num_heads,kv_dim,norm_layer,do_post_projection,quant_config,prefix)
  BaseResampler._init_weights(self,m)
  BaseResampler._repeat(self,query,N)
  MiniCPMBaseModel.__init__(self,config,quant_config,prefix)
  MiniCPMBaseModel._get_image_bounds(self,input_ids,pad_values,im_start_id,im_end_id,slice_start_id,slice_end_id)
  MiniCPMBaseModel._parse_and_validate_inputs(self,input_ids,**kwargs)
  MiniCPMBaseModel.forward(self,input_ids,positions,forward_batch,**kwargs)
  MiniCPMBaseModel.get_embedding(self,input_ids,image_inputs)
  MiniCPMBaseModel.get_image_feature(self,items)
  MiniCPMBaseModel.get_input_embeddings(self)
  MiniCPMBaseModel.get_vision_embedding(self,pixel_values,patch_attn_mask,tgt_sizes)
  MiniCPMBaseModel.init_llm(self,config,quant_config,prefix)
  MiniCPMBaseModel.init_resampler(self,embed_dim,vision_dim,quant_config,prefix)
  MiniCPMBaseModel.init_vision_module(self,config,quant_config,prefix)
  MiniCPMV.__call__(self,*args,**kwargs)
  MiniCPMV.__getattr__(self,name)
  MiniCPMV.__init__(self,config,quant_config,prefix)
  MiniCPMV.load_weights(self,weights)
  MiniCPMV2_6.__init__(self,config,quant_config,prefix)
  MiniCPMV2_6.get_image_feature(self,items)
  MiniCPMV2_6.get_vision_embedding(self,pixel_values,patch_attn_mask,tgt_sizes)
  MiniCPMV2_6.init_llm(self,config,quant_config,prefix)
  MiniCPMV2_6.init_resampler(self,embed_dim,vision_dim,quant_config,prefix)
  MiniCPMV2_6.init_vision_module(self,config,quant_config,prefix)
  MiniCPMV2_6.pad_input_ids(self,input_ids,image_inputs)
  Resampler2_5.__init__(self,num_queries,embed_dim,num_heads,kv_dim,norm_layer,max_size,quant_config,prefix)
  Resampler2_5._adjust_pos_cache(self,tgt_sizes,device)
  Resampler2_5._set_2d_pos_cache(self,max_size,device)
  Resampler2_5.forward(self,x,tgt_sizes)
  get_1d_sincos_pos_embed_from_grid(embed_dim,pos,version)
  get_2d_sincos_pos_embed(embed_dim,grid_size,cls_token,version)
  get_2d_sincos_pos_embed_from_grid(embed_dim,grid,version)
  get_version_by_config(config)
models/mistral.py:
  Mistral3ForConditionalGeneration.__call__(self,*args,**kwargs)
  Mistral3ForConditionalGeneration.__getattr__(self,name)
  Mistral3ForConditionalGeneration.__hasattr__(self,name)
  Mistral3ForConditionalGeneration.__init__(self,**kwargs)
  Mistral3ForConditionalGeneration.get_image_feature(self,items)
models/mixtral.py:
  MixtralAttention.__init__(self,hidden_size,num_heads,num_kv_heads,layer_id,max_position,rope_theta,quant_config,prefix)
  MixtralAttention.forward(self,positions,hidden_states,forward_batch)
  MixtralDecoderLayer.__init__(self,config,layer_id,quant_config,prefix)
  MixtralDecoderLayer.forward(self,positions,hidden_states,forward_batch,residual)
  MixtralForCausalLM.__init__(self,config,quant_config,prefix)
  MixtralForCausalLM.end_layer(self)
  MixtralForCausalLM.forward(self,input_ids,positions,forward_batch,input_embeds,pp_proxy_tensors)
  MixtralForCausalLM.load_weights(self,weights)
  MixtralForCausalLM.start_layer(self)
  MixtralMoE.__init__(self,num_experts,top_k,hidden_size,intermediate_size,layer_id,params_dtype,quant_config,tp_size,prefix)
  MixtralMoE.forward(self,hidden_states)
  MixtralModel.__init__(self,config,quant_config,prefix)
  MixtralModel.forward(self,input_ids,positions,forward_batch,input_embeds,pp_proxy_tensors)
models/mixtral_quant.py:
  MixtralAttention.__init__(self,hidden_size,num_heads,num_kv_heads,layer_id,max_position,rope_theta,quant_config,prefix)
  MixtralAttention.forward(self,positions,hidden_states,forward_batch)
  MixtralDecoderLayer.__init__(self,config,layer_id,quant_config,prefix)
  MixtralDecoderLayer.forward(self,positions,hidden_states,forward_batch,residual)
  MixtralMLP.__init__(self,num_experts,hidden_size,intermediate_size,quant_config,prefix)
  MixtralMLP.forward(self,hidden_states)
  MixtralMoE.__init__(self,config,quant_config,prefix)
  MixtralMoE.forward(self,hidden_states)
  MixtralModel.__init__(self,config,quant_config,prefix)
  MixtralModel.forward(self,input_ids,positions,forward_batch,input_embeds)
  QuantMixtralForCausalLM.__init__(self,config,quant_config,prefix)
  QuantMixtralForCausalLM.forward(self,input_ids,positions,forward_batch,input_embeds)
  QuantMixtralForCausalLM.load_weights(self,weights)
models/mllama.py:
  ColumnParallelConv2dPatch.__init__(self,in_channels,out_channels,kernel_size,stride,bias)
  ColumnParallelConv2dPatch.forward(self,x)
  MllamaCrossAttentionDecoderLayer.__init__(self,config,layer_id,quant_config,prefix)
  MllamaCrossAttentionDecoderLayer.forward(self,hidden_states,cross_attention_states,cross_attention_mask,full_text_row_masked_out_mask,forward_batch)
  MllamaForCausalLM.__init__(self,config,quant_config,prefix)
  MllamaForCausalLM.forward(self,input_ids,positions,cross_attention_states,cross_attention_mask,full_text_row_masked_out_mask,forward_batch,skip_cross_attention)
  MllamaForConditionalGeneration.__init__(self,config,quant_config,prefix)
  MllamaForConditionalGeneration._batch_image_inputs(self,forward_batch)
  MllamaForConditionalGeneration.flat_encoder_result(self,cross_attention_states,encoder_lens_need)
  MllamaForConditionalGeneration.forward(self,input_ids,positions,forward_batch)
  MllamaForConditionalGeneration.get_full_text_row_masked_out_mask(self,forward_batch)
  MllamaForConditionalGeneration.load_weights(self,weights)
  MllamaForConditionalGeneration.pad_input_ids(self,input_ids,mm_inputs)
  MllamaPrecomputedAspectRatioEmbedding.__init__(self,config,is_gated)
  MllamaPrecomputedAspectRatioEmbedding.forward(self,hidden_state,aspect_ratio_ids)
  MllamaPrecomputedPositionEmbedding.__init__(self,config)
  MllamaPrecomputedPositionEmbedding.forward(self,hidden_state,aspect_ratio_ids)
  MllamaTextCrossAttention.__init__(self,config,layer_id,quant_config,prefix)
  MllamaTextCrossAttention.forward(self,hidden_states,attention_mask,cross_attention_states,forward_batch)
  MllamaTextModel.__init__(self,config,quant_config,prefix)
  MllamaTextModel.forward(self,input_ids,positions,cross_attention_states,cross_attention_mask,full_text_row_masked_out_mask,forward_batch,skip_cross_attention)
  MllamaTextRMSNorm.__init__(self,hidden_size,eps)
  MllamaTextRMSNorm.extra_repr(self)
  MllamaTextRMSNorm.forward(self,hidden_states)
  MllamaVisionEncoder.__init__(self,config,quant_config,num_layers,is_gated,output_hidden_states,prefix)
  MllamaVisionEncoder.forward(self,hidden_states,attention_mask)
  MllamaVisionEncoderLayer.__init__(self,config,quant_config,is_gated,prefix)
  MllamaVisionEncoderLayer.forward(self,hidden_state,attention_mask)
  MllamaVisionMLP.__init__(self,config,quant_config,prefix)
  MllamaVisionMLP.forward(self,hidden_states)
  MllamaVisionModel.__init__(self,config,quant_config,prefix)
  MllamaVisionModel.apply_class_embedding(self,hidden_state)
  MllamaVisionModel.forward(self,pixel_values,aspect_ratio_ids,aspect_ratio_mask)
models/mllama4.py:
  Llama4ForConditionalGeneration.__init__(self,config,quant_config,prefix)
  Llama4ForConditionalGeneration._check_vision_weights_in_index(self,index_file)
  Llama4ForConditionalGeneration._handle_default_weight(self,name,loaded_weight,params_dict)
  Llama4ForConditionalGeneration._handle_expert_scale_params(self,name,loaded_weight,params_dict,num_experts,loaded_params)
  Llama4ForConditionalGeneration._handle_expert_weight_params(self,name,loaded_weight,params_dict,num_experts,loaded_params)
  Llama4ForConditionalGeneration._handle_expert_weights(self,name,loaded_weight,expert_params_mapping,params_dict,num_experts,loaded_params)
  Llama4ForConditionalGeneration._handle_other_expert_params(self,name,loaded_weight,expert_params_mapping,params_dict,loaded_params)
  Llama4ForConditionalGeneration._handle_scale_remapping(self,name,params_dict)
  Llama4ForConditionalGeneration._handle_stacked_params(self,name,loaded_weight,stacked_params_mapping,params_dict,loaded_params)
  Llama4ForConditionalGeneration._has_vision_weights(self,config)
  Llama4ForConditionalGeneration._should_skip_weight(self,name)
  Llama4ForConditionalGeneration._transform_expert_name(self,name,is_weight)
  Llama4ForConditionalGeneration._transform_weight_name(self,name)
  Llama4ForConditionalGeneration.forward(self,input_ids,positions,forward_batch,**kwargs)
  Llama4ForConditionalGeneration.get_embed(self)
  Llama4ForConditionalGeneration.get_embed_and_head(self)
  Llama4ForConditionalGeneration.get_image_feature(self,items)
  Llama4ForConditionalGeneration.load_weights(self,weights)
  Llama4ForConditionalGeneration.pad_input_ids(self,input_ids,mm_inputs)
  Llama4ForConditionalGeneration.permute(w,n_heads)
  Llama4ForConditionalGeneration.permute_qk_weight_for_rotary(self,name,loaded_weight)
  Llama4ForConditionalGeneration.set_eagle3_layers_to_capture(self,layer_ids)
  Llama4ForConditionalGeneration.set_embed(self,embed)
  Llama4ForConditionalGeneration.set_embed_and_head(self,embed,head)
  Llama4UnfoldConvolution.__init__(self,config,quant_config,prefix,use_data_parallel)
  Llama4UnfoldConvolution.forward(self,hidden_states)
  Llama4VisionEncoder.__init__(self,config,quant_config,prefix,use_data_parallel)
  Llama4VisionEncoder.forward(self,hidden_states,freqs_ci)
  Llama4VisionEncoderLayer.__init__(self,config,quant_config,prefix,use_data_parallel)
  Llama4VisionEncoderLayer.forward(self,hidden_state,freqs_ci)
  Llama4VisionMLP.__init__(self,input_size,intermediate_size,output_size,bias,output_activation,quant_config,prefix,use_data_parallel)
  Llama4VisionMLP.forward(self,hidden_states)
  Llama4VisionModel.__init__(self,config,quant_config,prefix)
  Llama4VisionModel.forward(self,pixel_values)
  Llama4VisionPixelShuffleMLP.__init__(self,config,quant_config,prefix,use_data_parallel)
  Llama4VisionPixelShuffleMLP.forward(self,encoded_patches)
  Llama4VisionRotaryEmbedding.__init__(self,config)
  Llama4VisionRotaryEmbedding.forward(self,hidden_states)
  apply_position_embedding(q,k,freqs_ci,shape)
  pixel_shuffle(input_tensor,shuffle_ratio)
models/nemotron_nas.py:
  DeciLMDecoderLayer.__init__(self,config,layer_idx,quant_config,prefix)
  DeciLMDecoderLayer.forward(self,positions,hidden_states,forward_batch,residual)
  DeciLMForCausalLM.__init__(self,config,quant_config,prefix)
  DeciLMForCausalLM._init_model(self,config,quant_config,prefix)
  DeciLMForCausalLM.forward(self,input_ids,positions,forward_batch,inputs_embeds,get_embedding,pp_proxy_tensors)
  DeciLMForCausalLM.get_input_embeddings(self,input_ids)
  DeciLMForCausalLM.load_weights(self,weights)
  DeciModel.__init__(self,config,quant_config,prefix,layer_type)
  DeciModel.forward(self,input_ids,positions,forward_batch,inputs_embeds,pp_proxy_tensors)
  DeciModel.get_input_embeddings(self,input_ids)
  DeciModel.get_layer(idx,prefix)
  _ffn_mult_to_intermediate_size(ffn_mult,n_embd)
  _find_multiple(n,k)
models/olmo.py:
  OlmoAttention.__init__(self,config,layer_id,quant_config,prefix)
  OlmoAttention.forward(self,positions,hidden_states,forward_batch)
  OlmoDecoderLayer.__init__(self,config,layer_id,quant_config,prefix)
  OlmoDecoderLayer.forward(self,positions,hidden_states,forward_batch)
  OlmoForCausalLM.__init__(self,config,quant_config,prefix)
  OlmoForCausalLM.forward(self,input_ids,positions,forward_batch,input_embeds)
  OlmoForCausalLM.load_weights(self,weights)
  OlmoMLP.__init__(self,config,quant_config,prefix)
  OlmoMLP.forward(self,x)
  OlmoModel.__init__(self,config,quant_config,prefix)
  OlmoModel.forward(self,input_ids,positions,forward_batch,input_embeds)
models/olmo2.py:
  Olmo2Attention.__init__(self,config,layer_id,quant_config,prefix)
  Olmo2Attention._apply_qk_norm(self,q,k)
  Olmo2Attention.forward(self,positions,hidden_states,forward_batch)
  Olmo2DecoderLayer.__init__(self,config,layer_id,quant_config,prefix)
  Olmo2DecoderLayer.forward(self,positions,hidden_states,forward_batch)
  Olmo2ForCausalLM.__init__(self,config,quant_config,prefix)
  Olmo2ForCausalLM.forward(self,input_ids,positions,forward_batch,input_embeds)
  Olmo2ForCausalLM.load_weights(self,weights)
  Olmo2MLP.__init__(self,config,quant_config,prefix)
  Olmo2MLP.forward(self,x)
  Olmo2Model.__init__(self,config,quant_config,prefix)
  Olmo2Model.forward(self,input_ids,positions,forward_batch,input_embeds)
models/olmoe.py:
  OlmoeAttention.__init__(self,layer_id,hidden_size,num_heads,num_kv_heads,rope_theta,rope_scaling,max_position_embeddings,quant_config,prefix)
  OlmoeAttention.forward(self,positions,hidden_states,forward_batch)
  OlmoeDecoderLayer.__init__(self,config,layer_id,quant_config,prefix)
  OlmoeDecoderLayer.forward(self,positions,hidden_states,forward_batch,residual)
  OlmoeForCausalLM.__init__(self,config,quant_config,prefix)
  OlmoeForCausalLM.forward(self,input_ids,positions,forward_batch,input_embeds)
  OlmoeForCausalLM.load_weights(self,weights)
  OlmoeMoE.__init__(self,num_experts,top_k,hidden_size,intermediate_size,params_dtype,quant_config,tp_size,layer_id,prefix)
  OlmoeMoE.forward(self,hidden_states)
  OlmoeModel.__init__(self,config,quant_config,prefix)
  OlmoeModel.forward(self,input_ids,positions,forward_batch,input_embeds)
models/persimmon.py:
  PersimmonAttention.__init__(self,config,quant_config,prefix,layer_id)
  PersimmonAttention._merge_heads(self,x)
  PersimmonAttention._split_heads(self,x)
  PersimmonAttention.forward(self,position_ids,forward_batch,hidden_states)
  PersimmonDecoderLayer.__init__(self,config,quant_config,prefix,idx)
  PersimmonDecoderLayer.forward(self,position_ids,forward_batch,hidden_states)
  PersimmonForCausalLM.__init__(self,config,quant_config,prefix)
  PersimmonForCausalLM.forward(self,input_ids,positions,forward_batch,inputs_embeds)
  PersimmonForCausalLM.get_input_embeddings(self,input_ids)
  PersimmonForCausalLM.load_weights(self,weights)
  PersimmonMLP.__init__(self,config,quant_config)
  PersimmonMLP.forward(self,hidden_states)
  PersimmonModel.__init__(self,config,quant_config,prefix)
  PersimmonModel.forward(self,input_ids,forward_batch,positions,inputs_embeds)
  PersimmonModel.get_input_embeddings(self,input_ids)
models/phi.py:
  PhiAttention.__init__(self,config,quant_config,prefix,layer_id)
  PhiAttention.forward(self,position_ids,forward_batch,hidden_states)
  PhiForCausalLM.__init__(self,config,quant_config,prefix)
  PhiForCausalLM.forward(self,input_ids,positions,forward_batch,inputs_embeds)
  PhiForCausalLM.get_input_embeddings(self,input_ids)
  PhiForCausalLM.load_weights(self,weights)
  PhiLayer.__init__(self,config,quant_config,prefix,idx)
  PhiLayer.forward(self,position_ids,forward_batch,hidden_states)
  PhiMLP.__init__(self,config,quant_config)
  PhiMLP.forward(self,hidden_states)
  PhiModel.__init__(self,config,quant_config,prefix)
  PhiModel.forward(self,input_ids,forward_batch,positions,inputs_embeds)
  PhiModel.get_input_embeddings(self,input_ids)
models/phi3_small.py:
  Phi3SmallDecoderLayer.__init__(self,config,layer_id,quant_config,prefix)
  Phi3SmallDecoderLayer.forward(self,positions,hidden_states,forward_batch)
  Phi3SmallForCausalLM.__init__(self,config,quant_config,prefix)
  Phi3SmallForCausalLM.compute_logits(self,input_ids,hidden_states,sampling_metadata)
  Phi3SmallForCausalLM.forward(self,input_ids,positions,forward_batch,inputs_embeds,get_embedding)
  Phi3SmallForCausalLM.get_decoder(self)
  Phi3SmallForCausalLM.get_input_embeddings(self,input_ids)
  Phi3SmallForCausalLM.get_output_embeddings(self)
  Phi3SmallForCausalLM.load_weights(self,weights)
  Phi3SmallForCausalLM.set_decoder(self,decoder)
  Phi3SmallForCausalLM.set_input_embeddings(self,value)
  Phi3SmallForCausalLM.set_output_embeddings(self,value)
  Phi3SmallMLP.__init__(self,config,quant_config,prefix)
  Phi3SmallMLP.forward(self,x)
  Phi3SmallModel.__init__(self,config,quant_config,prefix)
  Phi3SmallModel.forward(self,input_ids,positions,forward_batch,inputs_embeds)
  Phi3SmallModel.get_input_embeddings(self,input_ids)
  Phi3SmallSelfAttention.__init__(self,config,layer_id,quant_config,prefix)
  Phi3SmallSelfAttention.forward(self,positions,hidden_states,forward_batch)
  gegelu(input,limit)
  quick_gelu(x)
models/phi4mm.py:
  Phi4MMForCausalLM.__init__(self,config,quant_config,prefix)
  Phi4MMForCausalLM._should_skip(name)
  Phi4MMForCausalLM.forward(self,input_ids,positions,forward_batch,**kwargs)
  Phi4MMForCausalLM.get_audio_feature(self,items)
  Phi4MMForCausalLM.get_image_feature(self,items)
  Phi4MMForCausalLM.load_weights(self,weights)
  Phi4MMForCausalLM.pad_input_ids(self,input_ids,mm_inputs)
  Phi4MMForCausalLM.should_apply_lora(self,module_name)
  Phi4MMImageEncoder.__init__(self,config,quant_config,prefix,model_dir)
  Phi4MMImageEncoder.forward(self,pixel_values,image_sizes,image_attention_mask)
  Phi4MMImageEncoder.get_img_features(self,img_embeds,attention_mask)
models/phi4mm_audio.py:
  AudioEmbedding.__init__(self,config,**kwargs)
  AudioEmbedding.forward(self,audio_features,audio_attention_mask,audio_projection_mode)
  AudioEmbedding.get_audio_features(self,input_embeds,audio_attention_mask,audio_projection_mode)
  AudioEmbedding.set_audio_embed_sizes(self,audio_embed_sizes)
  AudioEmbedding.set_audio_embeds(self,input_embeds)
  ConformerEncoder.__init__(self,input_size,chunk_size,left_chunk,num_lang,attention_dim,attention_heads,linear_units,num_blocks,dropout_rate,input_layer,causal,batch_norm,cnn_out,cnn_layer_norm,ext_pw_out_channel,ext_pw_kernel_size,depthwise_seperable_out_channel,depthwise_multiplier,chunk_se,kernel_size,activation,conv_activation,conv_glu_type,bias_in_glu,linear_glu_in_convm,attention_glu_type,export,extra_layer_output_idx,extra_multi_layer_output_idxs,activation_checkpointing,relative_attention_bias_args,time_reduction,use_pt_scaled_dot_product_attention,nemo_conv_settings,conv2d_extra_padding,replication_pad_for_subsample_embedding,attention_group_size,encoder_embedding_config)
  ConformerEncoder.calculate_hs_mask(self,xs_pad,device,mask)
  ConformerEncoder.forward(self,xs_pad,masks)
  ConformerEncoder.init_relative_attention_bias(self,input_tensor)
  ConformerEncoderLayer.__init__(self,d_model,ext_pw_out_channel,depthwise_seperable_out_channel,depthwise_multiplier,n_head,d_ffn,ext_pw_kernel_size,kernel_size,dropout_rate,causal,batch_norm,activation,chunk_se,chunk_size,conv_activation,conv_glu_type,bias_in_glu,linear_glu_in_convm,attention_inner_dim,attention_glu_type,activation_checkpointing,export,use_pt_scaled_dot_product_attention,attn_group_sizes)
  ConformerEncoderLayer.forward(self,x,pos_k,pos_v,mask,relative_attention_bias)
  TransformerEncoderBase.__init__(self,input_size,chunk_size,left_chunk,attention_dim,attention_heads,input_layer,cnn_out,cnn_layer_norm,time_reduction,dropout_rate,padding_idx,relative_attention_bias_args,positional_dropout_rate,nemo_conv_settings,conv2d_extra_padding,attention_group_size,encoder_embedding_config)
  TransformerEncoderBase._chunk_size_selection(self,chunk_size,left_chunk)
  TransformerEncoderBase._forward_embeddings_core(self,input_tensor,masks)
  TransformerEncoderBase._get_embed_class(self,embed)
  TransformerEncoderBase._position_embedding(self,input_tensor)
  TransformerEncoderBase._streaming_mask(self,seq_len,batch_size,chunk_size,left_chunk)
  TransformerEncoderBase.compute_lens_change(self,feature_lens)
  TransformerEncoderBase.forward(self)
  TransformerEncoderBase.forward_embeddings(self,xs_pad,masks,chunk_size_nc,left_chunk_nc)
  TransformerEncoderBase.get_offset(self)
  WindowQformer.__init__(self,window_size,num_queries,num_blocks,attention_dim,attention_heads,linear_units,dropout_rate,normalize_before)
  WindowQformer.forward(self,audio_embed,mask,embed_len)
models/phi4mm_utils.py:
  AbsolutePositionalEncoding.__init__(self,d_model,dropout_rate,max_len)
  AbsolutePositionalEncoding.extend_pe(self,x)
  AbsolutePositionalEncoding.forward(self,x)
  AttBlock.memory_dims(self,max_len)
  AttModule.__init__(self)
  AttModule.forward(self,x,memory,pos_emb,att_mask)
  AttModule.set_export(self,mode)
  BlockBase.__init__(self,input_size,output_size)
  CausalConv1D.__init__(self,in_channels,out_channels,kernel_size,stride,padding,dilation,groups,bias,padding_mode,device,dtype)
  CausalConv1D.forward(self,x,cache)
  CausalConv1D.update_cache(self,x,cache)
  CausalConv2D.__init__(self,in_channels,out_channels,kernel_size,stride,padding,dilation,groups,bias,padding_mode,device,dtype)
  CausalConv2D.forward(self,x)
  ConvModule.__init__(self,input_dim,ext_pw_out_channel,depthwise_seperable_out_channel,ext_pw_kernel_size,kernel_size,depthwise_multiplier,dropout_rate,causal,batch_norm,chunk_se,chunk_size,activation,glu_type,bias_in_glu,linear_glu_in_convm,export)
  ConvModule._add_ext_pw_layer(self)
  ConvModule.forward(self,x)
  DepthWiseSeperableConv1d.__init__(self,input_dim,depthwise_seperable_out_channel,kernel_size,depthwise_multiplier,padding)
  DepthWiseSeperableConv1d.forward(self,x)
  FeedForward.__init__(self,d_model,d_inner,dropout_rate,activation,bias_in_glu)
  FeedForward.forward(self,x)
  GLU.__init__(self,dim,act_name)
  GLU.forward(self,x)
  GLULinear.__init__(self,input_dim,output_dim,glu_type,bias_in_glu)
  GLULinear.forward(self,x)
  GLUPointWiseConv.__init__(self,input_dim,output_dim,kernel_size,glu_type,bias_in_glu,causal)
  GLUPointWiseConv.forward(self,x)
  MeanVarianceNormLayer.__init__(self,input_size)
  MeanVarianceNormLayer.forward(self,input_)
  MultiHeadedAttention.__init__(self,n_head,n_feat,dropout_rate,attention_inner_dim,glu_type,bias_in_glu,use_pt_scaled_dot_product_attention,n_value,group_size)
  MultiHeadedAttention.forward(self,query,key,value,pos_k,pos_v,mask,relative_attention_bias)
  MultiSequential.forward(self,*args)
  NemoConvSubsampling.__init__(self,feat_in,feat_out,subsampling_factor,subsampling,conv_channels,subsampling_conv_chunking_factor,activation,is_causal)
  NemoConvSubsampling.change_subsampling_conv_chunking_factor(self,subsampling_conv_chunking_factor)
  NemoConvSubsampling.channel_chunked_conv(self,conv,chunk_size,x)
  NemoConvSubsampling.conv_split_by_batch(self,x)
  NemoConvSubsampling.conv_split_by_channel(self,x)
  NemoConvSubsampling.forward(self,x,mask)
  NemoConvSubsampling.get_sampling_frames(self)
  NemoConvSubsampling.get_streaming_cache_size(self)
  NemoConvSubsampling.reset_parameters(self)
  Swish.__init__(self)
  Swish.forward(self,x)
  T5RelativeAttentionLogitBias.__init__(self,num_heads,num_buckets,max_distance,symmetric)
  T5RelativeAttentionLogitBias._bucket_relative_position(self,relative_position)
  T5RelativeAttentionLogitBias.forward(self,x)
  _pre_hook(state_dict,prefix,local_metadata,strict,missing_keys,unexpected_keys,error_msgs)
  adaptive_enc_mask(x_len,chunk_start_idx,left_window,right_window)
  calc_length(lengths,all_paddings,kernel_size,stride,ceil_mode,repeat_num)
  get_activation(name)
  get_offset(input_layer,time_reduction)
  masked_softmax(scores,mask)
  unfold_tensor(xs_pad,max_seq_len)
models/phimoe.py:
  PhiMoE.__init__(self,num_experts,top_k,hidden_size,intermediate_size,layer_id,quant_config,prefix)
  PhiMoE.forward(self,hidden_states,forward_batch)
  PhiMoEAttention.__init__(self,hidden_size,num_heads,num_kv_heads,head_dim,max_position,rope_theta,layer_id,attention_bias,quant_config,rope_scaling,prefix)
  PhiMoEAttention.forward(self,positions,hidden_states,forward_batch)
  PhiMoEConfig.__init__(self,vocab_size,hidden_size,intermediate_size,num_hidden_layers,num_attention_heads,num_key_value_heads,head_dim,hidden_act,max_position_embeddings,initializer_range,rms_norm_eps,use_cache,pad_token_id,bos_token_id,eos_token_id,tie_word_embeddings,rope_theta,sliding_window,attention_dropout,num_experts_per_tok,num_local_experts,output_router_logits,router_aux_loss_coef,router_jitter_noise,attention_bias,lm_head_bias,**kwargs)
  PhiMoEDecoderLayer.__init__(self,config,layer_id,quant_config,prefix)
  PhiMoEDecoderLayer.forward(self,positions,hidden_states,residual,forward_batch)
  PhiMoEForCausalLM.__init__(self,config,quant_config,prefix)
  PhiMoEForCausalLM.forward(self,input_ids,positions,forward_batch,inputs_embeds,get_embedding)
  PhiMoEForCausalLM.load_weights(self,weights)
  PhiMoEModel.__init__(self,config,quant_config,prefix)
  PhiMoEModel.forward(self,input_ids,positions,forward_batch,input_embeds)
  phimoe_routing_function(hidden_states,gating_output,topk,renormalize)
  sparsemixer(scores,jitter_eps)
models/pixtral.py:
  PixtralHFMLP.__init__(self,config,quant_config,prefix)
  PixtralHFMLP.forward(self,x)
  PixtralHFTransformer.__init__(self,config,quant_config,num_hidden_layers_override,prefix)
  PixtralHFTransformer.forward(self,x,attention_mask,position_embeddings,return_all_hidden_states)
  PixtralHFTransformerBlock.__init__(self,config,layer_id,quant_config,prefix)
  PixtralHFTransformerBlock.forward(self,hidden_states,attention_mask,position_embeddings)
  PixtralHFVisionModel.__init__(self,config,quant_config,num_hidden_layers_override,prefix)
  PixtralHFVisionModel.device(self)
  PixtralHFVisionModel.dtype(self)
  PixtralHFVisionModel.forward(self,pixel_values,image_sizes,output_hidden_states,feature_sample_layers)
  PixtralHFVisionModel.load_weights(self,weights)
  PixtralHFVisionModel.pad_input_ids(self,input_ids,mm_inputs)
  resolve_visual_encoder_outputs(outputs,feature_sample_layers,post_norm,num_hidden_layers)
models/qwen.py:
  QWenAttention.__init__(self,hidden_size,num_heads,max_position_embeddings,layer_id,rope_theta,rope_scaling,quant_config,prefix)
  QWenAttention.forward(self,positions,hidden_states,forward_batch)
  QWenBlock.__init__(self,config,layer_id,quant_config,prefix)
  QWenBlock.forward(self,positions,hidden_states,forward_batch)
  QWenLMHeadModel.__init__(self,config,quant_config,prefix)
  QWenLMHeadModel.forward(self,input_ids,positions,forward_batch)
  QWenLMHeadModel.forward_split_prefill(self,input_ids,positions,forward_batch,split_interval)
  QWenLMHeadModel.load_weights(self,weights)
  QWenMLP.__init__(self,hidden_size,intermediate_size,hidden_act,quant_config,prefix)
  QWenMLP.forward(self,x)
  QWenModel.__init__(self,config,quant_config,prefix)
  QWenModel.forward(self,input_ids,positions,forward_batch)
models/qwen2.py:
  Qwen2Attention.__init__(self,hidden_size,num_heads,num_kv_heads,head_dim,layer_id,rope_theta,rope_scaling,max_position_embeddings,quant_config,dual_chunk_attention_config,prefix)
  Qwen2Attention.forward(self,positions,hidden_states,forward_batch)
  Qwen2DecoderLayer.__init__(self,config,layer_id,quant_config,prefix,alt_stream)
  Qwen2DecoderLayer.forward(self,positions,hidden_states,forward_batch,residual)
  Qwen2ForCausalLM.__init__(self,config,quant_config,prefix)
  Qwen2ForCausalLM.end_layer(self)
  Qwen2ForCausalLM.forward(self,input_ids,positions,forward_batch,input_embeds,get_embedding,pp_proxy_tensors)
  Qwen2ForCausalLM.forward_split_prefill(self,input_ids,positions,forward_batch,split_interval,input_embeds)
  Qwen2ForCausalLM.get_embed_and_head(self)
  Qwen2ForCausalLM.get_input_embedding(self,input_ids)
  Qwen2ForCausalLM.get_input_embeddings(self)
  Qwen2ForCausalLM.load_kv_cache_scales(self,quantization_param_path)
  Qwen2ForCausalLM.load_weights(self,weights)
  Qwen2ForCausalLM.set_eagle3_layers_to_capture(self,layer_ids)
  Qwen2ForCausalLM.set_embed_and_head(self,embed,head)
  Qwen2ForCausalLM.start_layer(self)
  Qwen2MLP.__init__(self,hidden_size,intermediate_size,hidden_act,quant_config,prefix)
  Qwen2MLP.forward(self,x)
  Qwen2Model.__init__(self,config,quant_config,prefix,decoder_layer_type,alt_stream)
  Qwen2Model.forward(self,input_ids,positions,forward_batch,input_embeds,pp_proxy_tensors)
  Qwen2Model.get_input_embedding(self,input_ids)
  Qwen2Model.get_input_embeddings(self)
  Qwen2Model.load_kv_cache_scales(self,quantization_param_path)
models/qwen2_5_vl.py:
  Qwen2_5_VLForConditionalGeneration.__init__(self,config,quant_config,prefix)
  Qwen2_5_VLForConditionalGeneration.forward(self,input_ids,positions,forward_batch,get_embedding)
  Qwen2_5_VLForConditionalGeneration.get_image_feature(self,items)
  Qwen2_5_VLForConditionalGeneration.get_input_embeddings(self)
  Qwen2_5_VLForConditionalGeneration.get_video_feature(self,items)
  Qwen2_5_VLForConditionalGeneration.load_weights(self,weights)
  Qwen2_5_VLForConditionalGeneration.pad_input_ids(self,input_ids,mm_inputs)
  Qwen2_5_VLMLP.__init__(self,in_features,hidden_features,bias,hidden_act,quant_config,prefix)
  Qwen2_5_VLMLP.forward(self,x)
  Qwen2_5_VisionBlock.__init__(self,dim,intermediate_dim,num_heads,hidden_act,norm_layer,attn_implementation,quant_config,prefix,num_dummy_heads)
  Qwen2_5_VisionBlock.forward(self,x,cu_seqlens,position_embeddings)
  Qwen2_5_VisionPatchMerger.__init__(self,dim,context_dim,spatial_merge_size,quant_config,prefix)
  Qwen2_5_VisionPatchMerger.forward(self,x)
  Qwen2_5_VisionTransformer.__init__(self,vision_config,norm_eps,quant_config,prefix)
  Qwen2_5_VisionTransformer.device(self)
  Qwen2_5_VisionTransformer.dtype(self)
  Qwen2_5_VisionTransformer.forward(self,x,grid_thw)
  Qwen2_5_VisionTransformer.get_window_index(self,grid_thw)
  Qwen2_5_VisionTransformer.rot_pos_emb(self,grid_thw)
models/qwen2_audio.py:
  Qwen2AudioForConditionalGeneration.__init__(self,config,quant_config,prefix)
  Qwen2AudioForConditionalGeneration.forward(self,input_ids,positions,forward_batch,**kwargs)
  Qwen2AudioForConditionalGeneration.get_audio_feature(self,items)
  Qwen2AudioForConditionalGeneration.load_weights(self,weights)
  Qwen2AudioForConditionalGeneration.pad_input_ids(self,input_ids,mm_inputs)
models/qwen2_eagle.py:
  Qwen2DecoderLayer.__init__(self,config,layer_id,quant_config,prefix)
  Qwen2ForCausalLMEagle.__init__(self,config,quant_config,prefix)
  Qwen2ForCausalLMEagle.load_weights(self,weights)
  Qwen2Model.__init__(self,config,quant_config,prefix)
  Qwen2Model.forward(self,input_ids,positions,forward_batch,input_embeds,pp_proxy_tensors)
models/qwen2_moe.py:
  Qwen2MoeAttention.__init__(self,hidden_size,num_heads,num_kv_heads,layer_id,rope_theta,rope_scaling,max_position_embeddings,qkv_bias,quant_config,dual_chunk_attention_config,prefix)
  Qwen2MoeAttention.forward(self,positions,hidden_states,forward_batch)
  Qwen2MoeDecoderLayer.__init__(self,config,layer_id,quant_config,prefix,alt_stream)
  Qwen2MoeDecoderLayer.forward(self,positions,hidden_states,forward_batch,residual)
  Qwen2MoeForCausalLM.__init__(self,config,quant_config,prefix)
  Qwen2MoeForCausalLM.end_layer(self)
  Qwen2MoeForCausalLM.forward(self,input_ids,positions,forward_batch,input_embeds,pp_proxy_tensors)
  Qwen2MoeForCausalLM.forward_split_prefill(self,input_ids,positions,forward_batch,split_interval,input_embeds)
  Qwen2MoeForCausalLM.get_model_config_for_expert_location(cls,config)
  Qwen2MoeForCausalLM.load_weights(self,weights)
  Qwen2MoeForCausalLM.set_eagle3_layers_to_capture(self,layer_ids)
  Qwen2MoeForCausalLM.start_layer(self)
  Qwen2MoeMLP.__init__(self,hidden_size,intermediate_size,hidden_act,quant_config,reduce_results,prefix)
  Qwen2MoeMLP.forward(self,x,use_reduce_scatter)
  Qwen2MoeModel.__init__(self,config,quant_config,prefix,decoder_layer_type,alt_stream)
  Qwen2MoeModel.forward(self,input_ids,positions,forward_batch,input_embeds,pp_proxy_tensors)
  Qwen2MoeSparseMoeBlock.__init__(self,layer_id,config,quant_config,prefix)
  Qwen2MoeSparseMoeBlock.forward(self,hidden_states,forward_batch,use_reduce_scatter)
models/qwen2_rm.py:
  Qwen2ForRewardModel.__init__(self,config,quant_config,prefix)
  Qwen2ForRewardModel.forward(self,input_ids,positions,forward_batch,input_embeds,get_embedding)
  Qwen2ForRewardModel.load_weights(self,weights)
models/qwen2_vl.py:
  Qwen2VLForConditionalGeneration.__init__(self,config,quant_config,prefix)
  Qwen2VLForConditionalGeneration._process_video_input(self,video_input)
  Qwen2VLForConditionalGeneration.forward(self,input_ids,positions,forward_batch,get_embedding)
  Qwen2VLForConditionalGeneration.get_image_feature(self,items)
  Qwen2VLForConditionalGeneration.get_input_embeddings(self)
  Qwen2VLForConditionalGeneration.get_video_feature(self,items)
  Qwen2VLForConditionalGeneration.load_weights(self,weights)
  Qwen2VLForConditionalGeneration.pad_input_ids(self,input_ids,mm_inputs)
  Qwen2VisionBlock.__init__(self,dim,num_heads,mlp_ratio,act_layer,norm_layer,attn_implementation,quant_config,prefix)
  Qwen2VisionBlock.forward(self,x,cu_seqlens,position_embeddings)
  Qwen2VisionMLP.__init__(self,in_features,hidden_features,act_layer,quant_config,prefix)
  Qwen2VisionMLP.forward(self,x)
  Qwen2VisionPatchEmbed.__init__(self,patch_size,temporal_patch_size,in_chans,embed_dim)
  Qwen2VisionPatchEmbed.forward(self,x)
  Qwen2VisionPatchMerger.__init__(self,d_model,context_dim,norm_layer,spatial_merge_size,quant_config,prefix)
  Qwen2VisionPatchMerger.forward(self,x)
  Qwen2VisionRotaryEmbedding.__init__(self,dim,theta)
  Qwen2VisionRotaryEmbedding.forward(self,seqlen)
  Qwen2VisionRotaryEmbedding.update_freqs_cache(self,seqlen)
  Qwen2VisionTransformer.__init__(self,vision_config,norm_eps,quant_config,prefix)
  Qwen2VisionTransformer.device(self)
  Qwen2VisionTransformer.dtype(self)
  Qwen2VisionTransformer.forward(self,x,grid_thw)
  Qwen2VisionTransformer.rot_pos_emb(self,grid_thw)
models/qwen3.py:
  Qwen3Attention.__init__(self,hidden_size,num_heads,num_kv_heads,layer_id,rope_theta,rope_scaling,head_dim,max_position_embeddings,quant_config,rms_norm_eps,attention_bias,prefix,alt_stream)
  Qwen3Attention._apply_qk_norm(self,q,k)
  Qwen3Attention.forward(self,positions,hidden_states,forward_batch)
  Qwen3DecoderLayer.__init__(self,config,layer_id,quant_config,prefix,alt_stream)
  Qwen3DecoderLayer.forward(self,positions,hidden_states,forward_batch,residual)
  Qwen3ForCausalLM.__init__(self,config,quant_config,prefix)
  Qwen3ForCausalLM.end_layer(self)
  Qwen3ForCausalLM.forward(self,input_ids,positions,forward_batch,input_embeds,get_embedding,pp_proxy_tensors)
  Qwen3ForCausalLM.forward_split_prefill(self,input_ids,positions,forward_batch,split_interval,input_embeds)
  Qwen3ForCausalLM.get_embed_and_head(self)
  Qwen3ForCausalLM.get_input_embeddings(self)
  Qwen3ForCausalLM.load_kv_cache_scales(self,quantization_param_path)
  Qwen3ForCausalLM.load_weights(self,weights)
  Qwen3ForCausalLM.set_eagle3_layers_to_capture(self,layer_ids)
  Qwen3ForCausalLM.set_embed_and_head(self,embed,head)
  Qwen3ForCausalLM.start_layer(self)
  Qwen3Model.__init__(self,config,quant_config,prefix)
models/qwen3_classification.py:
  Qwen3ForSequenceClassification.__init__(self,config,quant_config,prefix)
  Qwen3ForSequenceClassification.forward(self,input_ids,positions,forward_batch,input_embeds,get_embedding)
  Qwen3ForSequenceClassification.load_weights(self,weights)
models/qwen3_moe.py:
  Qwen3MoeAttention.__init__(self,hidden_size,num_heads,num_kv_heads,layer_id,rope_theta,rope_scaling,max_position_embeddings,head_dim,rms_norm_eps,attention_bias,quant_config,prefix,dual_chunk_attention_config,alt_stream)
  Qwen3MoeAttention._apply_qk_norm(self,q,k)
  Qwen3MoeAttention.forward(self,positions,hidden_states,forward_batch)
  Qwen3MoeAttention.forward_core(self,intermediate_state)
  Qwen3MoeAttention.forward_prepare(self,positions,hidden_states,forward_batch)
  Qwen3MoeAttention.op_core(self,state)
  Qwen3MoeAttention.op_prepare(self,state)
  Qwen3MoeDecoderLayer.__init__(self,config,layer_id,quant_config,prefix,alt_stream)
  Qwen3MoeDecoderLayer.forward(self,positions,hidden_states,forward_batch,residual)
  Qwen3MoeDecoderLayer.op_comm_postprocess_layer(self,state)
  Qwen3MoeDecoderLayer.op_comm_prepare_attn(self,state,positions,hidden_states,forward_batch,residual,tbo_subbatch_index)
  Qwen3MoeDecoderLayer.op_comm_prepare_mlp(self,state)
  Qwen3MoeDecoderLayer.op_mlp(self,state)
  Qwen3MoeForCausalLM.__init__(self,config,quant_config,prefix)
  Qwen3MoeForCausalLM.end_layer(self)
  Qwen3MoeForCausalLM.forward(self,input_ids,positions,forward_batch,input_embeds,pp_proxy_tensors)
  Qwen3MoeForCausalLM.forward_split_prefill(self,input_ids,positions,forward_batch,split_interval,input_embeds)
  Qwen3MoeForCausalLM.get_embed_and_head(self)
  Qwen3MoeForCausalLM.get_input_embeddings(self)
  Qwen3MoeForCausalLM.get_model_config_for_expert_location(cls,config)
  Qwen3MoeForCausalLM.load_weights(self,weights)
  Qwen3MoeForCausalLM.set_eagle3_layers_to_capture(self,layer_ids)
  Qwen3MoeForCausalLM.start_layer(self)
  Qwen3MoeModel.__init__(self,config,quant_config,prefix)
  Qwen3MoeSparseMoeBlock.__init__(self,layer_id,config,quant_config,prefix)
  Qwen3MoeSparseMoeBlock.forward(self,hidden_states,forward_batch,use_reduce_scatter)
  Qwen3MoeSparseMoeBlock.forward_deepep(self,hidden_states,forward_batch)
  Qwen3MoeSparseMoeBlock.forward_normal(self,hidden_states,use_reduce_scatter)
  Qwen3MoeSparseMoeBlock.get_moe_weights(self)
  Qwen3MoeSparseMoeBlock.op_combine_a(self,state)
  Qwen3MoeSparseMoeBlock.op_combine_b(self,state)
  Qwen3MoeSparseMoeBlock.op_dispatch_a(self,state)
  Qwen3MoeSparseMoeBlock.op_dispatch_b(self,state)
  Qwen3MoeSparseMoeBlock.op_experts(self,state)
  Qwen3MoeSparseMoeBlock.op_gate(self,state)
  Qwen3MoeSparseMoeBlock.op_output(self,state)
  Qwen3MoeSparseMoeBlock.op_select_experts(self,state)
models/registry.py:
  _ModelRegistry._normalize_archs(self,architectures)
  _ModelRegistry._raise_for_unsupported(self,architectures)
  _ModelRegistry._try_load_model_cls(self,model_arch)
  _ModelRegistry.get_supported_archs(self)
  _ModelRegistry.resolve_model_cls(self,architectures)
  import_model_classes()
models/roberta.py:
  RobertaClassificationHead.__init__(self,config)
  RobertaClassificationHead.forward(self,features,**kwargs)
  RobertaEmbedding.__init__(self,config)
  RobertaEmbedding.forward(self,input_ids,seq_lens,position_ids,forward_batch)
  XLMRobertaBaseModel.__init__(self,config,quant_config,prefix,add_pooling_layer)
  XLMRobertaBaseModel.forward(self,input_ids,positions,forward_batch,input_embeds,get_embedding)
  XLMRobertaBaseModel.load_weights(self,weights)
  XLMRobertaForSequenceClassification.__init__(self,config,quant_config,prefix)
  XLMRobertaForSequenceClassification.forward(self,input_ids,positions,forward_batch,input_embeds,get_embedding)
  XLMRobertaForSequenceClassification.load_weights(self,weights)
  XLMRobertaForSequenceClassification.weight_filter()
  XLMRobertaModel.__init__(self,config,quant_config,prefix)
  XLMRobertaModel.forward(self,input_ids,positions,forward_batch,input_embeds,get_embedding)
  XLMRobertaModel.load_weights(self,weights)
  create_position_ids_from_input_ids(input_ids,padding_idx,past_key_values_length)
models/siglip.py:
  SiglipEncoder.__init__(self,config,quant_config,prefix)
  SiglipEncoder.forward(self,inputs_embeds,attention_mask,causal_attention_mask,return_all_hidden_states)
  SiglipEncoderLayer.__init__(self,config,act_layer,norm_layer,attn_implementation,quant_config,prefix)
  SiglipEncoderLayer.forward(self,hidden_states,attention_mask,causal_attention_mask)
  SiglipMLP.__init__(self,config,act_layer,quant_config,prefix)
  SiglipMLP.forward(self,x)
  SiglipVisionEmbeddings.__init__(self,config)
  SiglipVisionEmbeddings.forward(self,pixel_values)
  SiglipVisionModel.__init__(self,config,quant_config,prefix)
  SiglipVisionModel.device(self)
  SiglipVisionModel.forward(self,pixel_values)
  SiglipVisionTransformer.__init__(self,config,quant_config,prefix)
  SiglipVisionTransformer.device(self)
  SiglipVisionTransformer.forward(self,pixel_values)
models/stablelm.py:
  StableLMEpochModel.__init__(self,config,quant_config,prefix)
  StableLMEpochModel.forward(self,input_ids,positions,forward_batch,input_embeds)
  StableLmForCausalLM.__init__(self,config,quant_config,prefix)
  StableLmForCausalLM.forward(self,input_ids,positions,forward_batch,input_embeds)
  StableLmForCausalLM.load_weights(self,weights)
  StablelmAttention.__init__(self,config,layer_id,quant_config,prefix)
  StablelmAttention.forward(self,positions,hidden_states,forward_batch)
  StablelmDecoderLayer.__init__(self,config,layer_id,quant_config,prefix)
  StablelmDecoderLayer.forward(self,positions,hidden_states,forward_batch)
  StablelmMLP.__init__(self,config,quant_config,prefix)
  StablelmMLP.forward(self,x)
models/step3_vl.py:
  Step3TextAttention.__init__(self,hidden_size,num_heads,num_kv_heads,head_dim,share_q_dim,layer_id,rope_theta,rope_scaling,max_position_embeddings,quant_config,rms_norm_eps,prefix)
  Step3TextAttention.forward(self,positions,hidden_states,forward_batch)
  Step3TextDecoderLayer.__init__(self,config,layer_id,quant_config,prefix)
  Step3TextDecoderLayer.forward(self,positions,hidden_states,forward_batch,residual)
  Step3TextDecoderLayer.moe_mlp_forward(self,hidden_states)
  Step3TextMLP.__init__(self,hidden_size,intermediate_size,hidden_act,quant_config,prefix)
  Step3TextMLP.forward(self,x)
  Step3TextMoEMLP.__init__(self,layer_id,config,quant_config,prefix)
  Step3TextMoEMLP.forward(self,hidden_states)
  Step3TextModel.__init__(self,config,quant_config,prefix)
  Step3TextModel.forward(self,input_ids,positions,forward_batch,input_embeds)
  Step3TextModel.get_input_embeddings(self)
  Step3VLForConditionalGeneration.__init__(self,config,quant_config,prefix)
  Step3VLForConditionalGeneration._flatten_embeddings(self,embeddings)
  Step3VLForConditionalGeneration._get_vision_model_output(self,input_tensor)
  Step3VLForConditionalGeneration._process_image_features(self,image_features)
  Step3VLForConditionalGeneration.forward(self,input_ids,positions,forward_batch,input_embeds)
  Step3VLForConditionalGeneration.get_image_feature(self,items)
  Step3VLForConditionalGeneration.get_model_config_for_expert_location(cls,config)
  Step3VLForConditionalGeneration.load_weights(self,weights)
  Step3VLForConditionalGeneration.match_expert_and_shard_ids(name_path,weight_path)
  Step3VLForConditionalGeneration.pad_input_ids(self,input_ids,mm_inputs)
  Step3VisionAttention.__init__(self,dim,num_heads,qkv_backend,quant_config,prefix)
  Step3VisionAttention.forward(self,hidden_states)
  Step3VisionEmbeddings.__init__(self,config)
  Step3VisionEmbeddings.forward(self,pixel_values)
  Step3VisionEncoder.__init__(self,config)
  Step3VisionEncoder.forward(self,inputs_embeds)
  Step3VisionEncoderLayer.__init__(self,config,attn_implementation)
  Step3VisionEncoderLayer.forward(self,hidden_states)
  Step3VisionMLP.__init__(self,dim,intermediate_size,bias,hidden_act,quant_config,prefix)
  Step3VisionMLP.forward(self,hidden_states)
  Step3VisionTransformer.__init__(self,config)
  Step3VisionTransformer.dtype(self)
  Step3VisionTransformer.forward(self,pixel_values)
  get_abs_pos(abs_pos,tgt_size)
models/torch_native_llama.py:
  LlamaAttention.__init__(self,config,hidden_size,num_heads,num_kv_heads,layer_id,rope_theta,rope_scaling,rope_is_neox_style,max_position_embeddings,quant_config,prefix)
  LlamaAttention.forward(self,positions,hidden_states,forward_batch)
  LlamaDecoderLayer.__init__(self,config,layer_id,quant_config,prefix)
  LlamaDecoderLayer.forward(self,positions,hidden_states,forward_batch,residual)
  LlamaMLP.__init__(self,hidden_size,intermediate_size,hidden_act,quant_config,prefix)
  LlamaMLP.forward(self,x)
  LlamaModel.__init__(self,config,quant_config)
  LlamaModel.forward(self,input_ids,positions,forward_batch,input_embeds)
  TorchNativeLlamaForCausalLM.__init__(self,config,quant_config)
  TorchNativeLlamaForCausalLM.forward(self,input_ids,positions,forward_batch,input_embeds)
  TorchNativeLlamaForCausalLM.get_module_name_from_weight_name(self,name)
  TorchNativeLlamaForCausalLM.get_num_params(self)
  TorchNativeLlamaForCausalLM.load_weights(self,weights)
  TorchNativeLlamaForCausalLM.load_weights_to_module(self,fqn,weights)
  gate_up_proj_weight_loader(self,param,loaded_weight,loaded_shard_id)
  qkv_proj_weight_loader(self,param,loaded_weight,loaded_shard_id)
models/transformers.py:
  HFColumnParallelLinear.forward(self,input)
  HFCompatibleLinear.forward(self,input)
  HFCompatibleLinear.parent_cls(self)
  HFRowParallelLinear.forward(self,input)
  TransformersForCausalLM.__init__(self,config,quant_config,prefix)
  TransformersForCausalLM._tensor_parallel(module,prefix)
  TransformersForCausalLM.forward(self,input_ids,positions,forward_batch,input_embeds,get_embedding)
  TransformersForCausalLM.load_weights(self,weights)
  TransformersForCausalLM.log_replacement(self,name,old_module,new_module)
  TransformersForCausalLM.replace_vocab_embed_class(self,module)
  TransformersForCausalLM.tensor_parallel(self,tp_size)
  maybe_prefix(prefix,name)
  replace_linear_class(linear,style,quant_config)
  sglang_flash_attention_forward(module,query,key,value,attention_mask,forward_batch,scaling,attention_instances,**kwargs)
models/vila.py:
  DownSample3x3BlockFix.forward(self,x)
  MultimodalProjector.__init__(self,config,*args,**kwargs)
  MultimodalProjector.device(self)
  MultimodalProjector.dtype(self)
  MultimodalProjector.forward(self,x)
  VILAConfig.__init__(self,text_config,vision_config,hidden_size,image_token_id,mm_hidden_size,mm_projector_type,mm_vision_select_feature,mm_vision_select_layer,video_token_id,**kwargs)
  VILAForConditionalGeneration.__init__(self,config,quant_config,prefix)
  VILAForConditionalGeneration._vision_tower_output_to_mm_projector_input(self,vision_tower_output)
  VILAForConditionalGeneration.dtype(self)
  VILAForConditionalGeneration.forward(self,input_ids,positions,forward_batch,get_embedding)
  VILAForConditionalGeneration.get_image_feature(self,mm_input)
  VILAForConditionalGeneration.load_weights(self,weights)
  VILAForConditionalGeneration.pad_input_ids(self,input_ids,mm_inputs)
models/xverse.py:
  XverseAttention.__init__(self,config,hidden_size,num_heads,num_kv_heads,layer_id,rope_theta,rope_scaling,rope_is_neox_style,max_position_embeddings,quant_config,prefix)
  XverseAttention.forward(self,positions,hidden_states,forward_batch)
  XverseDecoderLayer.__init__(self,config,layer_id,quant_config,prefix)
  XverseDecoderLayer.forward(self,positions,hidden_states,forward_batch,residual)
  XverseForCausalLM.__init__(self,config,quant_config,prefix)
  XverseForCausalLM.forward(self,input_ids,positions,forward_batch,input_embeds)
  XverseForCausalLM.load_weights(self,weights,name,loaded_weight)
  XverseForCausalLM.load_weights_per_param(name,loaded_weight)
  XverseMLP.__init__(self,hidden_size,intermediate_size,hidden_act,quant_config,prefix)
  XverseMLP.forward(self,x)
  XverseModel.__init__(self,config,quant_config,prefix)
  XverseModel.forward(self,input_ids,positions,forward_batch,input_embeds)
models/xverse_moe.py:
  XverseAttention.__init__(self,hidden_size,num_heads,num_kv_heads,layer_id,rope_theta,rope_scaling,max_position_embeddings,quant_config,prefix)
  XverseAttention.forward(self,positions,hidden_states,forward_batch)
  XverseDecoderLayer.__init__(self,config,layer_id,quant_config,prefix)
  XverseDecoderLayer.forward(self,positions,hidden_states,forward_batch,residual)
  XverseMLP.__init__(self,hidden_size,intermediate_size,hidden_act,quant_config,reduce_results,prefix)
  XverseMLP.forward(self,x)
  XverseMoE.__init__(self,config,quant_config,prefix)
  XverseMoE.forward(self,hidden_states)
  XverseMoE.pack_params(self)
  XverseModel.__init__(self,config,quant_config,prefix)
  XverseModel.forward(self,input_ids,positions,forward_batch)
  XverseMoeForCausalLM.__init__(self,config,quant_config,prefix)
  XverseMoeForCausalLM.forward(self,input_ids,positions,forward_batch)
  XverseMoeForCausalLM.load_weights(self,weights)
models/yivl.py:
  YiVLForCausalLM.__init__(self,config,quant_config,prefix)
  YiVLForCausalLM.load_weights(self,weights)
  YiVLMultiModalProjector.__init__(self,config)
  YiVLMultiModalProjector.forward(self,image_features)
