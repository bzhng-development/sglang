_custom_ops.py:
  all_reduce(fa,inp,out,reg_buffer,reg_buffer_sz_bytes)
  all_reduce_reg(fa,inp,out)
  all_reduce_unreg(fa,inp,reg_buffer,out)
  allocate_meta_buffer(size)
  dispose(fa)
  dispose(fa)
  get_graph_buffer_ipc_meta(fa)
  get_graph_buffer_ipc_meta(fa)
  get_meta_buffer_ipc_handle(inp)
  init_custom_ar(ipc_tensors,rank_data,rank,full_nvlink)
  init_custom_ar(meta,rank_data,handles,offsets,rank,full_nvlink)
  init_custom_qr(rank,world_size,qr_max_size)
  meta_size()
  meta_size()
  mscclpp_allreduce(context,inp,out,nthreads,nblocks)
  mscclpp_generate_unique_id()
  mscclpp_init_context(unique_id,rank,world_size,scratch,put_buffer,nranks_per_node,rank_to_node,rank_to_ib,context_selection)
  qr_all_reduce(fa,inp,out,quant_level,cast_bf2half)
  qr_destroy(fa)
  qr_get_handle(fa)
  qr_max_size()
  qr_open_handles(fa,handles)
  register_buffer(fa,ipc_tensors)
  register_buffer(fa,t,handles,offsets)
  register_graph_buffers(fa,handles,offsets)
  register_graph_buffers(fa,handles,offsets)
aio_rwlock.py:
  RWLock.__init__(self)
  RWLock.reader_lock(self)
  RWLock.writer_lock(self)
  _ReaderLock.__init__(self,rwlock)
  _WriterLock.__init__(self,rwlock)
  async RWLock.acquire_reader(self)
  async RWLock.acquire_writer(self)
  async RWLock.release_reader(self)
  async RWLock.release_writer(self)
  async _ReaderLock.__aenter__(self)
  async _ReaderLock.__aexit__(self,exc_type,exc_val,exc_tb)
  async _WriterLock.__aenter__(self)
  async _WriterLock.__aexit__(self,exc_type,exc_val,exc_tb)
bench_utils.py:
  bench_kineto(fn,kernel_names,num_tests,suppress_kineto_output,trace_path,flush_l2,with_multiple_kernels)
  suppress_stdout_stderr.__enter__(self)
  suppress_stdout_stderr.__exit__(self,*_)
code_completion_parser.py:
  completion_template_exists(template_name)
  generate_completion_prompt(prompt,suffix,template_name)
  generate_completion_prompt_from_request(request)
  is_completion_template_defined()
  register_completion_template(template,override)
conversation.py:
  Conversation.append_audio(self,audio)
  Conversation.append_image(self,image,detail)
  Conversation.append_message(self,role,message)
  Conversation.append_video(self,video)
  Conversation.copy(self)
  Conversation.dict(self)
  Conversation.get_prompt(self)
  Conversation.set_system_message(self,system_message)
  Conversation.to_gradio_chatbot(self)
  Conversation.to_openai_api_messages(self)
  Conversation.update_last_message(self,message)
  _get_full_multimodal_text_prompt(modality_token,modality_count,text_prompt)
  chat_template_exists(template_name)
  generate_chat_conv(request,template_name)
  generate_embedding_convs(texts,images,template_name)
  get_conv_template_by_model_path(model_path)
  get_model_type(model_path)
  match_deepseek_janus_pro(model_path)
  match_deepseek_vl(model_path)
  match_internvl(model_path)
  match_minicpm(model_path)
  match_phi_4_mm(model_path)
  match_qwen_chat_ml(model_path)
  match_vicuna(model_path)
  register_conv_template(template,override)
  register_conv_template_matching_function(func)
custom_op.py:
  CustomOp.__init__(self)
  CustomOp.dispatch_forward(self)
  CustomOp.enter_torch_compile(self,num_tokens)
  CustomOp.forward(self,*args,**kwargs)
  CustomOp.forward_cpu(self,*args,**kwargs)
  CustomOp.forward_cuda(self,*args,**kwargs)
  CustomOp.forward_hip(self,*args,**kwargs)
  CustomOp.forward_hpu(self,*args,**kwargs)
  CustomOp.forward_native(self,*args,**kwargs)
  CustomOp.forward_npu(self,*args,**kwargs)
  CustomOp.forward_xpu(self,*args,**kwargs)
  CustomOp.leave_torch_compile(self)
harmony_parser.py:
  CanonicalStrategy.__init__(self)
  CanonicalStrategy._extract_channel_type(self,header_text)
  CanonicalStrategy._is_commentary_filler_between_blocks(self,text,tokens,pos)
  CanonicalStrategy._is_standalone_structural_token(self,content)
  CanonicalStrategy._parse_block(self,text,tokens,start_pos)
  CanonicalStrategy._parse_partial_analysis(self,text,tokens,start_pos)
  CanonicalStrategy.parse(self,text)
  HarmonyParser.__init__(self)
  HarmonyParser.parse(self,chunk)
  TextStrategy.__init__(self)
  TextStrategy.parse(self,text)
  TextStrategy.set_buffer_context(self,buffer)
  iter_tokens(text,start_pos)
  prefix_hold(text,tokens)
hf_transformers_utils.py:
  attach_additional_stop_token_ids(tokenizer)
  check_gguf_file(model)
  download_from_hf(model_path,allow_patterns)
  get_config(model,trust_remote_code,revision,model_override_args,**kwargs)
  get_context_length(config)
  get_generation_config(model,trust_remote_code,revision,**kwargs)
  get_hf_text_config(config)
  get_processor(tokenizer_name,*args,tokenizer_mode,trust_remote_code,tokenizer_revision,use_fast,**kwargs)
  get_sparse_attention_config(model,sparse_attention_config_filename)
  get_tokenizer(tokenizer_name,*args,tokenizer_mode,trust_remote_code,tokenizer_revision,**kwargs)
  get_tokenizer_from_processor(processor)
host_shared_memory.py:
  HostSharedMemoryManager.__init__(self,base_name)
  HostSharedMemoryManager._malloc_raw(self,num_bytes)
  HostSharedMemoryManager.malloc(self,shape,dtype)
  get_host_shared_memory_manager()
  set_host_shared_memory_manager(instance)
jinja_template_utils.py:
  _is_attr_access(node,varname,key)
  _is_var_access(node,varname)
  _is_var_or_elems_access(node,varname,key)
  _try_extract_ast(chat_template)
  detect_jinja_template_content_format(chat_template)
  process_content_for_template_format(msg_dict,content_format,image_data,video_data,audio_data,modalities)
model_parallel.py:
  ColwiseParallelSharded._partition_linear_fn(self,name,module,device_mesh)
  RowwiseParallelMaybeWait._partition_linear_fn(self,name,module,device_mesh)
  RowwiseParallelMaybeWait._prepare_output_fn(output_layouts,use_local_output,mod,outputs,device_mesh)
  _shard_tensor(full_tensor,device_mesh,placements)
  tensor_parallel(module,device_mesh)
  tplize(mod)
offloader.py:
  BaseOffloader.post_init(self)
  BaseOffloader.wrap_modules(self,all_modules_generator,submodule_accessor,whitelist_param_names_creator)
  OffloaderV1.__init__(self,cpu_offload_max_bytes)
  OffloaderV1.forward(*args,**kwargs)
  OffloaderV1.maybe_offload_to_cpu(self,module)
  OffloaderV1.wrap_modules(self,all_modules_generator,submodule_accessor,whitelist_param_names_creator)
  OffloaderV2.__init__(self,group_size,num_in_group,prefetch_step,mode,dp_rank,dp_size)
  OffloaderV2.post_init(self)
  OffloaderV2.wrap_modules(self,all_modules_generator,submodule_accessor,whitelist_param_names_creator)
  _BaseParamOffloader.__init__(self,module,param_name)
  _BaseParamOffloader._param(self)
  _BaseParamOffloader.create(mode,**kwargs)
  _BaseParamOffloader.create_device_tensor(self)
  _BaseParamOffloader.post_init(self)
  _CpuParamOffloader.__init__(self,module,param_name)
  _CpuParamOffloader.create_device_tensor(self)
  _MetaParamOffloader.__init__(self,module,param_name)
  _MetaParamOffloader.create_device_tensor(self)
  _ModuleOffloader.__init__(self,mode,module,alt_stream,whitelist_param_names)
  _ModuleOffloader._create_device_tensors(self)
  _ModuleOffloader.offload(self)
  _ModuleOffloader.post_init(self)
  _ModuleOffloader.start_onload(self)
  _ModuleOffloader.wait_and_get_device_tensors(self)
  _ShardedGpuParamOffloader.__init__(self,module,param_name)
  _ShardedGpuParamOffloader.create_device_tensor(self)
  _ShardedGpuParamOffloader.post_init(self)
  _ShmCpuParamOffloader.__init__(self,module,param_name)
  _ShmCpuParamOffloader.create_device_tensor(self)
  _ShmCpuParamOffloader.post_init(self)
  _create_shared_buffer_tensors(local_tensor)
  _empty_strided_like(x,device,pin_memory)
  _even_chunk(x,chunks)
  _hook_module_forward_for_offloader(index,module,offloaders,prefetch_step)
  _hook_module_forward_raw(module,on_forward_end,get_parameter_and_buffer_dicts)
  _move_param_to_cpu(param,pin_memory)
  _move_param_to_meta(module,param_name)
  _on_forward_end()
  create_offloader_from_server_args(server_args,dp_rank)
  forward(*args,**kwargs)
  get_offloader()
  set_offloader(instance)
operations.py:
  _StageExecutor.__init__(self,debug_name,stages,inputs)
  _StageExecutor.done(self)
  _StageExecutor.next(self)
  _StageExecutor.num_stages(self)
  _StageExecutor.output(self)
  _StateDict.__delattr__(self,item)
  _StateDict.__getattr__(self,item)
  _StateDict.__init__(self)
  _StateDict.__setattr__(self,key,value)
  _StateDict.clear(self,expect_keys)
  _StateDict.get(self,item)
  _StateDict.pop(self,item)
  _StateDict.update(self,values)
  _annotate_region(debug_name)
  _chunk_by_separator(items,is_separator)
  _convert_operations_to_stages(operations)
  _decorate_operation(operation,debug_name_prefix)
  _decorate_operations(operations,debug_name_prefix)
  execute_operations(inputs,operations)
  execute_overlapped_operations(inputs_arr,operations_arr,delta_stages)
operations_strategy.py:
  OperationsStrategy.concat(cls,items)
  OperationsStrategy.init_new_tbo(layers,forward_mode)
  _assert_all_same(items)
  _compute_moe_deepseek_blog_decode(layer)
  _compute_moe_deepseek_blog_prefill(layer)
  _compute_moe_deepseek_layer_operations_strategy_tbo(layer,forward_mode)
  _compute_moe_qwen3_decode(layer)
  _compute_moe_qwen3_layer_operations_strategy_tbo(layer,forward_mode)
  _compute_moe_qwen3_prefill(layer)
patch_torch.py:
  _device_from_maybe_uuid(device_maybe_uuid)
  _device_to_uuid(device)
  _modify_tuple(t,index,modifier)
  _rebuild_cuda_tensor_modified(*args)
  _reduce_tensor_modified(*args,**kwargs)
  monkey_patch_torch_compile()
  monkey_patch_torch_reductions()
poll_based_barrier.py:
  PollBasedBarrier.__init__(self,noop)
  PollBasedBarrier._compute_global_arrived(self)
  PollBasedBarrier.local_arrive(self)
  PollBasedBarrier.poll_global_arrived(self)
reasoning_parser.py:
  BaseReasoningFormatDetector.__init__(self,think_start_token,think_end_token,force_reasoning,stream_reasoning)
  BaseReasoningFormatDetector.detect_and_parse(self,text)
  BaseReasoningFormatDetector.parse_streaming_increment(self,new_text)
  DeepSeekR1Detector.__init__(self,stream_reasoning,force_reasoning)
  GptOssDetector.__init__(self,stream_reasoning,force_reasoning)
  GptOssDetector.detect_and_parse(self,text)
  GptOssDetector.parse_streaming_increment(self,new_text)
  KimiDetector.__init__(self,stream_reasoning,force_reasoning)
  Qwen3Detector.__init__(self,stream_reasoning,force_reasoning)
  ReasoningParser.__init__(self,model_type,stream_reasoning,force_reasoning)
  ReasoningParser.parse_non_stream(self,full_text)
  ReasoningParser.parse_stream_chunk(self,chunk_text)
  StreamingParseResult.__init__(self,normal_text,reasoning_text)
server_args.py:
  DeprecatedAction.__call__(self,parser,namespace,values,option_string)
  DeprecatedAction.__init__(self,option_strings,dest,nargs,**kwargs)
  LoRAPathAction.__call__(self,parser,namespace,values,option_string)
  PortArgs.init_new(server_args,dp_rank)
  ServerArgs.__post_init__(self)
  ServerArgs.add_cli_args(parser)
  ServerArgs.adjust_mem_fraction_for_vlm(self,model_config)
  ServerArgs.check_lora_server_args(self)
  ServerArgs.check_server_args(self)
  ServerArgs.from_cli_args(cls,args)
  ServerArgs.get_hf_config(self)
  ServerArgs.model_specific_adjustments(self)
  ServerArgs.url(self)
  ServerArgs.validate_disagg_tp_size(self,prefill_tp,decode_tp)
  add_attention_backend_choices(choices)
  add_disagg_transfer_backend_choices(choices)
  add_load_format_choices(choices)
  add_quantization_method_choices(choices)
  auto_choose_speculative_params(self)
  prepare_server_args(argv)
  print_deprecated_warning(message)
torch_memory_saver_adapter.py:
  TorchMemorySaverAdapter.check_validity(self,caller_name)
  TorchMemorySaverAdapter.configure_subprocess(self)
  TorchMemorySaverAdapter.create(enable)
  TorchMemorySaverAdapter.enabled(self)
  TorchMemorySaverAdapter.pause(self,tag)
  TorchMemorySaverAdapter.region(self,tag)
  TorchMemorySaverAdapter.resume(self,tag)
  _TorchMemorySaverAdapterNoop.configure_subprocess(self)
  _TorchMemorySaverAdapterNoop.enabled(self)
  _TorchMemorySaverAdapterNoop.pause(self,tag)
  _TorchMemorySaverAdapterNoop.region(self,tag)
  _TorchMemorySaverAdapterNoop.resume(self,tag)
  _TorchMemorySaverAdapterReal.configure_subprocess(self)
  _TorchMemorySaverAdapterReal.enabled(self)
  _TorchMemorySaverAdapterReal.pause(self,tag)
  _TorchMemorySaverAdapterReal.region(self,tag)
  _TorchMemorySaverAdapterReal.resume(self,tag)
two_batch_overlap.py:
  MaybeTboDeepEPDispatcher.__init__(self,**kwargs)
  MaybeTboDeepEPDispatcher._execute(self,name,tbo_subbatch_index,**kwargs)
  MaybeTboDeepEPDispatcher.combine(self,**kwargs)
  MaybeTboDeepEPDispatcher.combine_a(self,**kwargs)
  MaybeTboDeepEPDispatcher.combine_b(self,**kwargs)
  MaybeTboDeepEPDispatcher.dispatch(self,**kwargs)
  MaybeTboDeepEPDispatcher.dispatch_a(self,**kwargs)
  MaybeTboDeepEPDispatcher.dispatch_b(self,**kwargs)
  TboCudaGraphRunnerPlugin.__init__(self)
  TboCudaGraphRunnerPlugin.capture_one_batch_size(self,batch,num_tokens)
  TboCudaGraphRunnerPlugin.replay_prepare(self,forward_mode,bs,num_token_non_padded,spec_info)
  TboDPAttentionPreparer._compute_global_forward_mode(forward_modes)
  TboDPAttentionPreparer._compute_local_forward_mode(local_batch)
  TboDPAttentionPreparer._is_all_same(x)
  TboDPAttentionPreparer.compute_output(self,partial_global_info)
  TboDPAttentionPreparer.prepare_all_gather(self,local_batch)
  TboForwardBatchPreparer._compute_split_token_index(cls,batch)
  TboForwardBatchPreparer.compute_tbo_children_num_token_non_padded(cls,batch)
  TboForwardBatchPreparer.compute_tbo_children_num_token_non_padded_raw(cls,tbo_split_token_index,num_token_non_padded)
  TboForwardBatchPreparer.derive_fields_related_to_seq_len_for_two_chunk(cls,batch,child_a,child_b,tbo_split_seq_index)
  TboForwardBatchPreparer.filter_batch(cls,batch,start_token_index,end_token_index,start_seq_index,end_seq_index,output_attn_backend,out_num_token_non_padded)
  TboForwardBatchPreparer.prepare(cls,batch,is_draft_worker)
  TboForwardBatchPreparer.prepare_raw(cls,batch,tbo_children_num_token_non_padded)
  _compute_extend_num_tokens(input_ids,forward_mode)
  _compute_mask_offset(seq_index,spec_info)
  _handle_key(name)
  _is_two_chunk_split_enabled(extend_lens)
  _model_forward_filter_inputs(hidden_states,residual,positions,output_forward_batch,tbo_subbatch_index)
  _model_forward_non_tbo(inputs,operations_strategy)
  _model_forward_tbo(inputs,operations_strategy,input_data_scatter_mode,layer_input_scatter_mode)
  _model_forward_tbo_merge_outputs(output_a,output_b)
  _model_forward_tbo_split_inputs(hidden_states,residual,positions,forward_batch,zero_allocator,input_data_scatter_mode,layer_input_scatter_mode)
  _model_forward_tbo_split_inputs_raw(hidden_states,residual,positions,forward_batch,zero_allocator)
  _post_transform(hidden_states,residual,forward_batch,**kwargs)
  _split_array_by_balanced_sum(arr)
  _split_array_by_cum_less_than_half(arr)
  _split_extend_seqs(arr)
  _update_device_and_sum_field_from_cpu_field(batch,cpu_field,device_field,sum_field)
  compute_split_indices_for_cuda_graph_replay(forward_mode,cuda_graph_num_tokens,spec_info)
  compute_split_seq_index(forward_mode,num_tokens,extend_lens,token_num_per_seq)
  compute_split_token_index(split_seq_index,forward_mode,extend_seq_lens,token_num_per_seq)
  get_token_num_per_seq(forward_mode,spec_info)
  model_forward_maybe_tbo(layers,enable_tbo,positions,forward_batch,hidden_states,input_data_scatter_mode,residual,zero_allocator)
  split_spec_info(spec_info,start_seq_index,end_seq_index,start_token_index,end_token_index)
utils.py:
  BumpAllocator.__init__(self,buffer_size,dtype,device)
  BumpAllocator.allocate(self,size)
  ConcurrentCounter.__init__(self,initial)
  ConcurrentCounter.__repr__(self)
  ConcurrentCounter.value(self)
  DynamicGradMode.__enter__(self)
  DynamicGradMode.__exit__(self,exc_type,exc_value,traceback)
  DynamicGradMode.__init__(self,mode)
  DynamicGradMode.__new__(cls,mode_or_orig_func)
  DynamicGradMode.clone(self)
  DynamicGradMode.set_inference_mode(mode)
  EmptyContextManager.__enter__(self)
  EmptyContextManager.__exit__(self,exc_type,exc_value,traceback)
  LayerFn.__call__(self,layer_id,prefix)
  LazyValue.__init__(self,creator)
  LazyValue.value(self)
  MultiprocessingSerializer.deserialize(data)
  MultiprocessingSerializer.serialize(obj,output_str)
  PackWeightMethod.__init__(self,weight_names,transpose_dims)
  PackWeightMethod.process_weights_after_loading(self,module)
  TimeInfo.__init__(self,name,interval,color,indent)
  TimeInfo.check(self)
  TimeInfo.pretty_print(self)
  Withable.__init__(self)
  Withable.value(self)
  Withable.with_value(self,new_value)
  _check(cc_major)
  _process_weight_after_loading(module,weight_names,transpose_dims)
  _to_hashable(o)
  add_api_key_middleware(app,api_key)
  add_prefix(name,prefix)
  add_prometheus_middleware(app)
  align(x,y)
  apply_module_patch(target_module,target_function,wrappers)
  assert_pkg_version(pkg,min_version,message)
  async ConcurrentCounter.decrement(self,n,notify_all)
  async ConcurrentCounter.increment(self,n,notify_all)
  async ConcurrentCounter.wait_for(self,condition)
  async ConcurrentCounter.wait_for_zero(self)
  async authentication(request,call_next)
  async health()
  async health_generate()
  bind_or_assign(target,source)
  bind_or_assign(target,source)
  bind_port(port)
  broadcast_pyobj(data,rank,dist_group,src,force_cpu_device)
  calculate_time(show,min_cost_ms)
  ceil_div(x,y)
  check_cuda_result(raw_output)
  configure_gc_logger()
  configure_gc_warning(warn_threshold_secs)
  configure_ipv6(dist_init_addr)
  configure_logger(server_args,prefix)
  cpu_has_amx_support()
  crash_on_warnings()
  create_checksum(directory)
  create_dummy_module(full_path,parent)
  create_placeholder_function(func_name)
  dataclass_to_string_truncated(data,max_length,skip_names)
  debug_timing(func)
  decode_video_base64(video_base64)
  decorator(func)
  decorator(func)
  delete_directory(dirpath)
  dim_is_supported(weight)
  direct_register_custom_op(op_name,op_func,mutates_args,fake_impl,target_lib)
  disable_request_logging()
  dispose_tensor(x)
  dump_to_file(dirpath,name,value)
  dynamic_import(func_path)
  empty_context(*args,**kwargs)
  enable_show_time_cost()
  fast_topk(values,topk,dim)
  find_local_repo_dir(repo_id,revision)
  find_process_using_port(port)
  flatten_nested_list(nested_list)
  format_tcp_address(ip,port)
  freeze_gc(context)
  gc_callback(phase,info)
  gc_callback(phase,info)
  gc_object_counts()
  get_amdgpu_memory_capacity()
  get_available_gpu_memory(device,gpu_id,distributed,empty_cache,cpu_group)
  get_bool_env_var(name,default)
  get_compiler_backend()
  get_cpu_ids_by_node()
  get_cuda_version()
  get_device(device_id)
  get_device_capability(device_id)
  get_device_core_count(device_id)
  get_device_count()
  get_device_memory_capacity(device)
  get_device_name(device_id)
  get_device_sm()
  get_free_port()
  get_hpu_memory_capacity()
  get_int_env_var(name,default)
  get_ip()
  get_local_ip_auto()
  get_local_ip_by_nic(interface)
  get_local_ip_by_remote()
  get_npu_compiler_config()
  get_npu_memory_capacity()
  get_nvgpu_memory_capacity()
  get_open_port()
  get_physical_cpus_by_numa()
  get_quant_method_with_embedding_replaced(self,layer,prefix)
  get_zmq_socket(context,socket_type,endpoint,bind)
  init_custom_process_group(backend,init_method,timeout,world_size,rank,store,group_name,pg_options)
  inner_func(*args,**kwargs)
  is_blackwell()
  is_cpu()
  is_cuda()
  is_cuda_alike()
  is_fa3_default_architecture(hf_config)
  is_flashinfer_available()
  is_habana_available()
  is_hip()
  is_host_cpu_x86()
  is_hpu()
  is_no_spec_infer_or_topk_one(server_args)
  is_non_idle_and_non_empty(forward_mode,hidden_states)
  is_npu()
  is_page_size_one(server_args)
  is_pin_memory_available()
  is_port_available(port)
  is_remote_url(url)
  is_shm_available(dtype,world_size,local_size)
  is_sm100_supported(device)
  is_sm90_supported(device)
  is_triton_3()
  is_triton_kernels_available()
  is_valid_ipv6_address(address)
  is_xpu()
  kill_itself_when_parent_died()
  kill_process_tree(parent_pid,include_parent,skip_pid)
  launch_dummy_health_check_server(host,port,enable_metrics)
  load_audio(audio_file,sr,mono)
  load_image(image_file)
  load_json_config(data)
  load_video(video_file,use_gpu)
  log_info_on_rank0(logger,msg)
  lru_cache_frozenset(maxsize)
  make_layers(num_hidden_layers,layer_fn,pp_rank,pp_size,prefix,return_tuple,offloader_kwargs)
  mark_end(name)
  mark_start(name,interval,color,indent)
  maybe_torch_compile(*args,**kwargs)
  maybe_wrap_ipv6_address(address)
  monkey_patch_p2p_access_check()
  monkey_patch_vllm_gguf_config()
  mxfp_supported()
  next_power_of_2(n)
  nullable_str(val)
  parse_connector_type(url)
  parse_lscpu_topology()
  parse_module_path(module_path,function_name,create_dummy)
  permute_weight(x)
  placeholder(*args,**kwargs)
  point_to_point_pyobj(data,rank,group,src,dst)
  prepack_weight_if_needed(weight)
  prepare_model_and_tokenizer(model_path,tokenizer_path)
  print_info_once(msg)
  print_warning_once(msg)
  pyspy_dump_schedulers()
  pytorch_profile(name,func,*args,data_size)
  random_uuid()
  read_system_prompt_from_file(model_name)
  replace_submodule(model,module_name,new_module)
  require_attn_tp_gather(server_args)
  require_gathered_buffer(server_args)
  require_mlp_sync(server_args)
  require_mlp_tp_gather(server_args)
  retry(fn,max_retry,initial_delay,max_delay,should_retry)
  round_up(x,y)
  set_cuda_arch()
  set_gpu_proc_affinity(tp_size,nnodes,gpu_id)
  set_prometheus_multiproc_dir()
  set_random_seed(seed)
  set_recv_opt()
  set_send_opt()
  set_ulimit(target_soft_limit)
  set_uvicorn_logging_configs()
  set_weight_attrs(weight,weight_attrs)
  support_triton(backend)
  supports_custom_op()
  suppress_other_loggers()
  use_intel_amx_backend(layer)
  wait_port_available(port,port_name,timeout_s,raise_exception)
  wrapper(*args,**kwargs)
  wrapper(*args,**kwargs)
  wrapper(func)
warmup.py:
  async execute_warmups(disaggregation_mode,warmup_names,tokenizer_manager)
  async voice_chat(disaggregation_mode,tokenizer_manager)
  decorator(fn)
  warmup(name)
